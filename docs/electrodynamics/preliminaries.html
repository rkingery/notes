<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.551">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Personal Notes - Preliminaries</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../electrodynamics/electrostatics.html" rel="next">
<link href="../classical-mechanics/continuum-mechanics.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../electrodynamics/preliminaries.html">Electrodynamics</a></li><li class="breadcrumb-item"><a href="../electrodynamics/preliminaries.html"><span class="chapter-title">Preliminaries</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Personal Notes</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Classical Mechanics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../classical-mechanics/newtonian-mechanics.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Newtonian Mechanics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../classical-mechanics/simple-systems.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Simple Systems</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../classical-mechanics/reference-frames.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Reference Frames</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../classical-mechanics/lagrangian-mechanics.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Lagrangian Mechanics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../classical-mechanics/hamiltonian-mechanics.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Hamiltonian Mechanics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../classical-mechanics/central-forces.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Central Forces</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../classical-mechanics/coupled-oscillations.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Coupled Oscillations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../classical-mechanics/rigid-bodies.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Rigid Bodies</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../classical-mechanics/canonical-transformations.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Canonical Transformations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../classical-mechanics/integrability-and-chaos.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Integrability and Chaos</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../classical-mechanics/continuum-mechanics.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Continuum Mechanics</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Electrodynamics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../electrodynamics/preliminaries.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Preliminaries</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../electrodynamics/electrostatics.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Electrostatics</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Circuit Analysis</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../circuits/circuit-abstraction.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">The Lumped Circuit Abstraction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../circuits/analysis.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Analyzing Circuits</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../circuits/nonlinear-methods.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Nonlinear Methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../circuits/digital-abstraction.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">The Digital Abstraction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../circuits/amplifiers.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Amplifiers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../circuits/first-order-systems.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">First-Order Systems</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../circuits/second-order-systems.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Second-Order Systems</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../circuits/ac-analysis.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">AC Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../circuits/op-amps.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Operational Amplifiers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../circuits/energy-power.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Energy and Power</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Quantum Mechanics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../quantum-mechanics/identical-particles.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Identical Particles</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../quantum-mechanics/second-quantization.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Second Quantization</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">Statistical Mechanics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../statistical-mechanics/thermodynamics.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Thermodynamics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../statistical-mechanics/probability.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Probability</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../statistical-mechanics/kinetic-theory.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Kinetic Theory</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../statistical-mechanics/classical-stat-mech.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Classical Statistical Mechanics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../statistical-mechanics/classical-gases.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Classical Gases</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../statistical-mechanics/quantum-stat-mech.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Quantum Statistical Mechanics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../statistical-mechanics/quantum-gases.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Quantum Gases</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#units" id="toc-units" class="nav-link active" data-scroll-target="#units">Units</a></li>
  <li><a href="#math-review" id="toc-math-review" class="nav-link" data-scroll-target="#math-review">Math Review</a>
  <ul class="collapse">
  <li><a href="#vectors" id="toc-vectors" class="nav-link" data-scroll-target="#vectors">Vectors</a></li>
  <li><a href="#tensors" id="toc-tensors" class="nav-link" data-scroll-target="#tensors">Tensors</a></li>
  <li><a href="#vector-calculus" id="toc-vector-calculus" class="nav-link" data-scroll-target="#vector-calculus">Vector Calculus</a></li>
  <li><a href="#coordinate-systems" id="toc-coordinate-systems" class="nav-link" data-scroll-target="#coordinate-systems">Coordinate Systems</a></li>
  <li><a href="#fourier-analysis" id="toc-fourier-analysis" class="nav-link" data-scroll-target="#fourier-analysis">Fourier Analysis</a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content column-page-right" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../electrodynamics/preliminaries.html">Electrodynamics</a></li><li class="breadcrumb-item"><a href="../electrodynamics/preliminaries.html"><span class="chapter-title">Preliminaries</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-title">Preliminaries</span></h1>
</div>



<div class="quarto-title-meta column-page-right">

    
  
    
  </div>
  


</header>


<p>In this course we’ll study the physical phenomena known as <em>electromagnetism</em>. At one level, electromagnetism can be thought of as the study of two types of closely-related forces, the <em>electrical force</em>, and the <em>magnetic force</em>. Originally, the electrical force was proposed to explain the fact that objects have a property known as <em>electric charge</em> which causes certain objects to repel each other and other objects to attract each other according to a particular force law, <em>Coulomb’s Law</em>.</p>
<p>The magnetic force arose from two different phenomena that later had to be unified. The first was the study of <em>ferromagnetic materials</em>, which were materials that tended to point in a particular direction, for example the needle of a compass which tends to point northward. The second was the behavior of <em>currents</em>, or charges moving through wires. Michael Faraday observed that a current moving through two wires causes them to attract or repel each other depending on the directions of the currents. This led to another force law, known as the <em>Biot-Savart Law</em>. It was later found that ferromagnets can also be thought of as tiny currents inside a material, thus unifying the two types of magnetism.</p>
<p>The fact that magnetism arises from moving electric charges also provided a way to unify the dynamics of electricity and magnetism. A few years later it was discovered that electromagnetism explains a completely different phenomenon as well, <em>light</em>. Light was found to be a form of electromagnetic radiation at a particular range of frequencies. The unification of these three phenomena (electricity, magnetism, and optics) into one theory was finally done by Maxwell with his well-known field equations. These equations are believed to fully describe all electromagnetic phenomena at the macroscopic level.</p>
<p>It was eventually realized with the advent of quantum mechanics that even Maxwell’s Equations needed to be modified at the microscopic level to account for quantum effects, like the discoveries that light is in fact made of photons and most materials are made of other fundamental particles like electrons and quarks. This more advanced topic is known as <em>quantum electrodynamics</em>.</p>
<p>In this course we’ll study the theory of <em>classical electrodynamics</em>. We will conver the subject at the graduate level, meaning we will go give a more advanced treatment to many subjects in the field than is perhaps typical in most electrodynamics texts.</p>
<section id="units" class="level2">
<h2 class="anchored" data-anchor-id="units">Units</h2>
<p>We’ll start by saying a word about <em>units</em>. Typically in physics we need not think much about units. Abstractly the formulas look the same, whether the quantities involved are measured in meters, feet, or lightyears. However, electromagnetism has the unusual quirk that different unit systems lead to slightly different looking formulas. The reasons for this are largely historical, and very little if any physics is involved in the way these formulas look in different systems of units. An important implication of this frustrating quirk is that we have to be much more careful at the outset to specify which units we’re using since it will affect the formulas involved in derivations and calculations. To start, we’ll very briefly look at several different systems of units before committing to one for the rest of the course.</p>
<p>The foundation of systems of units in electromagnetism are forces on and due to the presence of charges and currents. It was found early on that there are two types of electric charge, positive and negative. Two like charges repel, while two opposite charges attract. The force between those charges also depends on the distance between them in a specific way. Suppose two charges <span class="math inline">\(q_1\)</span> and <span class="math inline">\(q_2\)</span> are separated from each other by a distance <span class="math inline">\(r\)</span>. The magnitude of the force felt by the two charges is given by an inverse square law known as <em>Coulomb’s Law</em>, <span class="math display">\[
F = k_e \frac{q_1 q_2}{r^2} \ .
\]</span> The proportionality constant <span class="math inline">\(k_e\)</span> is known as the <em>electric constant</em> whose dimension and value depends on choice of units. The quantity <span class="math inline">\(k_e q_1 q_2\)</span> can be measured in the lab by measuring the strength of the force and the distance between the two charges.</p>
<p>A little while later people figured out how to run moving charges, or <em>currents</em>, through wires. In studying the behavior of current flowing through two nearby parallel wires, it was found that the wires repel each other when the currents move in the same direction, and repel each other when the currents move in the opposite direction. The force also seemed to depend on the distance between the wires. Suppose two parallel wires a distance <span class="math inline">\(r\)</span> apart are carrying currents <span class="math inline">\(I_1\)</span> and <span class="math inline">\(I_2\)</span>. Suppose each wire has the same fixed length <span class="math inline">\(\ell\)</span>. Then the force experienced by the two wires due to the currents is given by <em>Ampere’s Force Law</em>,</p>
<p><span class="math display">\[
\frac{dF}{d\ell} = 2k_m \frac{I_1 I_2}{r} \ .
\]</span> The proportionality constant <span class="math inline">\(k_m\)</span> is yet another constant that depends on units. The quantity <span class="math inline">\(k_m I_1 I_2\)</span> can be measured in the lab by measuring the strength of the force per unit length and the distance of separation between the two wires.</p>
<p>It was further realized later that these two phenomena can be generalized using the notion of <em>fields</em>. The force felt by a charge due to other charges can also be thought of as a force on a charge felt by an <em>electric field</em> <span class="math inline">\(\mathbf{E}(\mathbf{x},t)\)</span> that sums of the effects of all the other background charges. The force felt on a charge <span class="math inline">\(q\)</span> is evidently proportional to this electric field, <span class="math inline">\(\mathbf{F} \propto q \mathbf{E}\)</span>. A similar description can be made for the forces felt on a moving charge, i.e.&nbsp;a current, due to the presence of a <em>magnetic field</em> <span class="math inline">\(\mathbf{B}(\mathbf{x},t)\)</span> that sums up the effects of all other background currents. This force felt on a moving charge <span class="math inline">\(q\)</span> is proportional to both its velocity <span class="math inline">\(\mathbf{v}\)</span> and the magnetic field, with <span class="math inline">\(\mathbf{F} \propto q\mathbf{v} \times \mathbf{B}\)</span>. If we try to sum these two forces together to get the combined force on the moving charge we have to establish how the electric and magnetic fields dimensionally relate to each other. This combined force law is known as the <em>Lorentz Force Law</em>, given generally by <span class="math display">\[
\mathbf{F} = q \bigg(\mathbf{E} + \frac{\mathbf{v}}{\alpha} \times \mathbf{B}\bigg) \ .
\]</span> Here we introduce a new constant <span class="math inline">\(\alpha\)</span> to control the dimensional relationship between <span class="math inline">\(\mathbf{E}\)</span> and <span class="math inline">\(\mathbf{B}\)</span>. Initially this was ignored and <span class="math inline">\(\alpha=1\)</span> was chosen without people really thinking about it. But later on it was realized that the two fields should actually be thought of as essentially the same object and should thus have the same dimensions. For this to be true, <span class="math inline">\(\alpha\)</span> must be chosen to be some constant with dimensions of velocity.</p>
<p>The three parameters <span class="math inline">\(k_e, k_m, \alpha\)</span> are not completely independent though. Most importantly, dimensional analysis and experiment force <span class="math inline">\(k_e\)</span> and <span class="math inline">\(k_m\)</span> to be related in a very specific way, namely by <span class="math display">\[
c^2 = \frac{k_e}{k_m} \ ,
\]</span> where <span class="math inline">\(c\)</span> is the <em>speed of light</em> in vacuum, a fundamental constant measured to be <span class="math inline">\(c \approx 3 \cdot 10^{10} \ \frac{\text{cm}}{\text{s}}\)</span>. Several experiments already concluded that <span class="math inline">\(c\)</span> was indeed a universal constant with no dependence on choice of reference frame. This ratio evidently thus gives us a natural velocity scale, which coincidentally is what we’d need to fix <span class="math inline">\(\alpha\)</span> to make <span class="math inline">\(\mathbf{E}\)</span> and <span class="math inline">\(\mathbf{B}\)</span> to have the same units.</p>
<p>In the early days of electromagnetism the centimeter-gram-second or <em>CGS</em> system was already being widely used to measure mechanical quantities like length, mass, time, force, and energy. The unit of force was called the <em>dyne</em>, which comes out to <span class="math inline">\(1 \ \text{dyne} = 10^{-5} \ \text{N}\)</span>, while the unit of energy was called the <em>erg</em>, which comes out to <span class="math inline">\(1 \ \text{erg} = 10^{-7} \ \text{J}\)</span>. When electromagnetism came along it was realized these mechanical units needed to somehow be extended to cover electromagnetic phenomena as well, but that there were different all self consistent ways this could be done based on how <span class="math inline">\(k_e, k_m, \alpha\)</span> were specified.</p>
<p>Early on two unit systems arose to cover electromagnetism, one being used to measure electric quantities, and a completely different one used to measure magnetic quantities. The early system of units for electricity was called <em>electrostatic units</em> or the <em>ESU</em> system. This system defined <span class="math inline">\(k_e\equiv\alpha\equiv1\)</span>, which then forced <span class="math inline">\(k_m \equiv \frac{1}{c^2}\)</span>. This defined a natural unit of charge, later called the <em>electrostatic unit</em> or <em>esu</em>, with <span class="math inline">\(1 \ \text{esu} \approx 3.3 \cdot 10^{-10} \ \text{C}\)</span>. An analogous system arose to study magnetism, called <em>electromagnetic units</em> or the <em>EMU</em> system. This system defined <span class="math inline">\(k_m \equiv \alpha \equiv 1\)</span>, which then forced <span class="math inline">\(k_e = c^2\)</span>. This defined a natural unit of current, later called the <em>absolute amp</em> or <em>abamp</em>, with <span class="math inline">\(1 \ \text{abamp} = 10 \ \text{A}\)</span> exactly.</p>
<p>It was found to be cumbersome to go back and forth between the two subjects since one had to change units to compare results. It was also eventually realized that having the electric and magnetic fields be different dimensions didn’t make sense, as Einstein showed the two fields were really just the same field expressed in different reference frames. The two unit systems were then combined into yet a third system called the <em>Gaussian system</em>. The Gaussian system also uses CGS mechanical units, but takes <span class="math display">\[
k_e \equiv 1 \quad , \quad k_m \equiv \frac{1}{c^2} \quad , \quad \alpha \equiv c \ .
\]</span> This system had the benefit that the unit of charge was still the esu, but now the electric and magnetic fields have the same units. The unit of current is no longer the abamp, but instead the esu per second. The Gaussian system became popular among physicists, especially among theorists due to the fact that electricity and magnetism were treated on the same footing.</p>
<p>However, things played out differently on the engineering side. While physicists were studying electromagnetism in the lab, engineers were starting to use these ideas to build practical things like wires, motors, transformers, circuits, and radios. Engineers at the time didn’t like the fact that when that CGS units were poorly scaled to measure everyday things like the current through a telegraph wire or the voltage across a resistor. They instead chose to use a different system based on the meter, kilogram, and second, called the <em>MKS</em> system. The abamp was seen as too big for electrical applications of the time, so they defined a smaller unit of current called the <em>amp</em> or <em>Ampere</em>, defined by <span class="math inline">\(1 \ \text{A} \equiv 0.1 \ \text{abamp}\)</span>.</p>
<p>Later on, MKS units were extended to the rest of electromagnetism, but in a kind of quirky way. It was decided to define <span class="math display">\[
k_e \equiv \frac{1}{4\pi\varepsilon_0} \quad , \quad k_m \equiv \frac{\mu_0}{2\pi} \quad , \quad \alpha \equiv 1 \ .
\]</span> This odd definition was chosen out of the prevelant belief at the time that electromagnetic phenomena permuated in a fluid known as the <em>ether</em>, which they believed had a natural permittivity and permeability like any other material. This idea was later invalided through experiments, but the notation persists unfortunately. The division by <span class="math inline">\(4\pi\)</span> was arbitrary, done to <em>rationalize</em> out any factors of <span class="math inline">\(\pi\)</span> from Maxwell’s equations. As with the ESU and EMU systems, the electric and magnetic fields be of the same units wasn’t seen as an imperative, so no scaling by the speed of light was done either.</p>
<p>The constants <span class="math inline">\(\varepsilon_0\)</span> and <span class="math inline">\(\mu_0\)</span> were chosen as the more fundamental constants due to a misbelief that the vacuum was made of an electromagnetic fluid known as the <em>ether</em>, which was later falsified by experiment. These constants were tuned in the MKSA system specifically so that unit of current would come out to be exactly a tenth of an abamp. For this to work out consistently, they defined <span class="math display">\[
\mu_0 \equiv 4\pi \cdot 10^{-7} \ \frac{\text{N}}{\text{A}^2} \quad , \quad \varepsilon_0 \equiv \frac{10^7}{4\pi c^2} \approx 8.84 \cdot 10^{-14} \ \frac{\text{A}^2 \ \text{s}^4}{\text{kg} \ \text{m}^3} \ .
\]</span></p>
<p>This extended MKS system adds a fourth independent unit, the <em>Ampere</em>. All other electromagnetic quantities are then naturally defined in terms of the values of the meter, kilogram, second, and the Ampere. It’s this system, sometimes called the <em>MKSA</em> system, that later become the <em>SI system</em> used widely today in science and engineering.</p>
<p>On top of all these systems yet another system of units for electromagnetism was defined that closely relates to the Gaussian system. This system of units is called the <em>Heaviside-Lorentz</em> system. It also uses the CGS system and takes <span class="math inline">\(\alpha=c\)</span>, but it follows the MKSA system in choosing to rationalize out the factors of <span class="math inline">\(4\pi\)</span> from Maxwell’s equations. It thus chooses <span class="math display">\[
k_e \equiv \frac{1}{4\pi} \quad , \quad k_m \equiv \frac{1}{4\pi c^2} \quad , \quad \alpha \equiv c \ .
\]</span> As with the Gaussian system, in the Heaviside-Lorentz the electric and magnetic fields again have the same units. The only real difference is that the measured units change by a factor of <span class="math inline">\(4\pi\)</span>, and the factors of <span class="math inline">\(4\pi\)</span> are removed from Maxwell’s equations.</p>
<p>Nowadays, the ESU and EMU systems are rarely if ever used. The SI system is of course widely used, particularly among experimentalists and engineers, as well as in essentially all modern undergraduate electromagnetism textbooks. The Heaviside-Lorentz system is favored by the particle physics community, perhaps because they often set <span class="math inline">\(c=1\)</span>, which makes the formulas look similar to those in the SI system. The Gaussian system remains popular particularly among theoretical physicists due to its symmetric treatment of the electric and magnetic fields and its use of a single constant in formulas, the speed of light <span class="math inline">\(c\)</span>.</p>
<p>While each choice of units has its benefits depending on the field of study and the application, in this course we will stick primarily with the <em>Gaussian</em> system of units, which is well-suited to a theoretical study of electromagnetism. To go back and forth between Gaussian and SI units in various formulas, a useful trick that often works (but not always) is to make the identification <span class="math display">\[
\varepsilon_0 \leftrightarrow \frac{1}{4\pi} \quad , \quad \mu_0 \leftrightarrow \frac{4\pi}{c} \ .
\]</span></p>
<p>Below is a table of various electromagnetism formulas expressed in the three unit systems still in widespread use today. We’ll define or derive all of these formulas in more details in later lessons.</p>
<table class="table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Gaussian</th>
<th>Heaviside-Lorentz</th>
<th>SI</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Electric Field</strong></td>
<td><span class="math inline">\(\mathbf{E} = -\nabla \Phi + \frac{1}{c}\frac{\partial \mathbf{A}}{\partial t}\)</span></td>
<td><span class="math inline">\(\mathbf{E} = -\nabla \Phi + \frac{1}{c}\frac{\partial \mathbf{A}}{\partial t}\)</span></td>
<td><span class="math inline">\(\mathbf{E} = -\nabla \Phi + \frac{\partial \mathbf{A}}{\partial t}\)</span></td>
</tr>
<tr class="even">
<td><strong>Magnetic Field</strong></td>
<td><span class="math inline">\(\mathbf{B} = \nabla \times \mathbf{A}\)</span></td>
<td><span class="math inline">\(\mathbf{B} = \nabla \times \mathbf{A}\)</span></td>
<td><span class="math inline">\(\mathbf{B} = \nabla \times \mathbf{A}\)</span></td>
</tr>
<tr class="odd">
<td><strong>Coulomb’s Law</strong></td>
<td><span class="math inline">\(\mathbf{E} = \frac{q}{r^2} \mathbf{e}_r\)</span></td>
<td><span class="math inline">\(\mathbf{E} = \frac{1}{4\pi}\frac{q}{r^2} \mathbf{e}_r\)</span></td>
<td><span class="math inline">\(\mathbf{E} = \frac{1}{4\pi\varepsilon_0}\frac{q}{r^2} \mathbf{e}_r\)</span></td>
</tr>
<tr class="even">
<td><strong>Biot-Savart Law</strong></td>
<td><span class="math inline">\(d\mathbf{B} = \frac{I}{c} \frac{d\boldsymbol{\ell} \times \mathbf{e}_r}{r^2}\)</span></td>
<td><span class="math inline">\(d\mathbf{B} = \frac{I}{4\pi c} \frac{d\boldsymbol{\ell} \times \mathbf{e}_r}{r^2}\)</span></td>
<td><span class="math inline">\(d\mathbf{B} = \frac{\mu_0 I}{4\pi} \frac{d\boldsymbol{\ell} \times \mathbf{e}_r}{r^2}\)</span></td>
</tr>
<tr class="odd">
<td><strong>Lorentz Force Law</strong></td>
<td><span class="math inline">\(\mathbf{F} = q\mathbf{E} + q\frac{\mathbf{v}}{c} \times \mathbf{B}\)</span></td>
<td><span class="math inline">\(\mathbf{F} = q\mathbf{E} + q\frac{\mathbf{v}}{c} \times \mathbf{B}\)</span></td>
<td><span class="math inline">\(\mathbf{F} = q\mathbf{E} + q\mathbf{v} \times \mathbf{B}\)</span></td>
</tr>
<tr class="even">
<td><strong>Displacement Field</strong></td>
<td><span class="math inline">\(\mathbf{D} = \mathbf{E} + 4\pi \mathbf{P}\)</span></td>
<td><span class="math inline">\(\mathbf{D} = \mathbf{E} + \mathbf{P}\)</span></td>
<td><span class="math inline">\(\mathbf{D} = \varepsilon_0 \mathbf{E} + \mathbf{P}\)</span></td>
</tr>
<tr class="odd">
<td><strong>Magnetizing Field</strong></td>
<td><span class="math inline">\(\mathbf{H} = \mathbf{B} - 4\pi \mathbf{M}\)</span></td>
<td><span class="math inline">\(\mathbf{H} = \mathbf{B} - \mathbf{M}\)</span></td>
<td><span class="math inline">\(\mathbf{H} = \frac{1}{\mu_0}\mathbf{B} - \mathbf{M}\)</span></td>
</tr>
<tr class="even">
<td><strong>Gauss’s Law</strong></td>
<td><span class="math inline">\(\nabla \cdot \mathbf{E} = 4\pi \rho\)</span></td>
<td><span class="math inline">\(\nabla \cdot \mathbf{E} = \rho\)</span></td>
<td><span class="math inline">\(\nabla \cdot \mathbf{E} = \frac{\rho}{\varepsilon_0}\)</span></td>
</tr>
<tr class="odd">
<td><strong>Faraday’s Law</strong></td>
<td><span class="math inline">\(\nabla \times \mathbf{E} = -\frac{1}{c} \frac{\partial \mathbf{B}}{\partial t}\)</span></td>
<td><span class="math inline">\(\nabla \times \mathbf{E} = -\frac{1}{c}\frac{\partial \mathbf{B}}{\partial t}\)</span></td>
<td><span class="math inline">\(\nabla \times \mathbf{E} = -\frac{\partial \mathbf{B}}{\partial t}\)</span></td>
</tr>
<tr class="even">
<td><strong>Gauss’s Law for Magnetism</strong></td>
<td><span class="math inline">\(\nabla \cdot \mathbf{B} = 0\)</span></td>
<td><span class="math inline">\(\nabla \cdot \mathbf{B} = 0\)</span></td>
<td><span class="math inline">\(\nabla \cdot \mathbf{B} = 0\)</span></td>
</tr>
<tr class="odd">
<td><strong>Ampere-Maxwell Law</strong></td>
<td><span class="math inline">\(\nabla \times \mathbf{B} = \frac{4\pi}{c} \mathbf{J} + \frac{1}{c} \frac{\partial \mathbf{E}}{\partial t}\)</span></td>
<td><span class="math inline">\(\nabla \times \mathbf{B} = \frac{1}{c} \mathbf{J} + \frac{1}{c} \frac{\partial \mathbf{E}}{\partial t}\)</span></td>
<td><span class="math inline">\(\nabla \times \mathbf{B} = \mu_0 \mathbf{J} + \mu_0 \varepsilon_0 \frac{\partial \mathbf{E}}{\partial t}\)</span></td>
</tr>
<tr class="even">
<td><strong>Continuity Equation</strong></td>
<td><span class="math inline">\(\nabla \cdot \mathbf{J} = -\frac{\partial \rho}{\partial t}\)</span></td>
<td><span class="math inline">\(\nabla \cdot \mathbf{J} = -\frac{\partial \rho}{\partial t}\)</span></td>
<td><span class="math inline">\(\nabla \cdot \mathbf{J} = -\frac{\partial \rho}{\partial t}\)</span></td>
</tr>
<tr class="odd">
<td><strong>Ohm’s Law</strong></td>
<td><span class="math inline">\(\mathbf{J} = \sigma \mathbf{E}\)</span></td>
<td><span class="math inline">\(\mathbf{J} = \sigma \mathbf{E}\)</span></td>
<td><span class="math inline">\(\mathbf{J} = \sigma \mathbf{E}\)</span></td>
</tr>
<tr class="even">
<td><strong>Energy Density</strong></td>
<td><span class="math inline">\(u = \frac{1}{8\pi} (|\mathbf{E}|^2 + |\mathbf{B}|^2)\)</span></td>
<td><span class="math inline">\(u = \frac{1}{2} (|\mathbf{E}|^2 + |\mathbf{B}|^2)\)</span></td>
<td><span class="math inline">\(u = \frac{\varepsilon_0}{2} |\mathbf{E}|^2 + \frac{1}{2\mu_0} |\mathbf{B}|^2\)</span></td>
</tr>
<tr class="odd">
<td><strong>Poynting Vector</strong></td>
<td><span class="math inline">\(\mathbf{S} = \frac{c}{4\pi} \mathbf{E} \times \mathbf{B}\)</span></td>
<td><span class="math inline">\(\mathbf{S} = c \mathbf{E} \times \mathbf{B}\)</span></td>
<td><span class="math inline">\(\mathbf{S} = \frac{1}{\mu_0} \mathbf{E} \times \mathbf{B}\)</span></td>
</tr>
</tbody>
</table>
</section>
<section id="math-review" class="level2">
<h2 class="anchored" data-anchor-id="math-review">Math Review</h2>
<p>Here we give a very brief review of some important mathematical results that will be important in our study of electrodynamics. We will not prove anything here nor provide many if any examples, as this is all assumed to be review.</p>
<section id="vectors" class="level3">
<h3 class="anchored" data-anchor-id="vectors">Vectors</h3>
<p>As in mechanics, in electrodynamics we generally assume that physical objects live in a 3-dimensional real space, often denoted by the set <span class="math inline">\(\mathbb{R}^3\)</span>. A <em>vector</em> or <em>3-vector</em> we’ll define as a 3-component object <span class="math inline">\(\mathbf{v}\)</span> that lives in <span class="math inline">\(\mathbb{R}^3\)</span>. The 3 components of the vector depend on the choice of <em>coordinate system</em> or <em>basis</em> chosen. In Cartesian coordinates we can expand a vector as a superposition of unit vectors aligned with the coordinate axes, <span class="math display">\[
\mathbf{v} = v_x \mathbf{e}_x + v_y \mathbf{e}_y + v_z \mathbf{e}_z = v_1 \mathbf{e}_1 + v_2 \mathbf{e}_2 + v_3 \mathbf{e}_3 \ .
\]</span></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./resources/image-20240126183306137.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="300"></p>
</figure>
</div>
<p>The second representation of using numerical indices to represent the components in order will be useful for us, as we’ll often express superpositions like this using summation notation, or more conveniently using the <em>Einstein summation convention</em>, <span class="math display">\[
\mathbf{v} \equiv v_i \mathbf{e}_i \equiv \sum_{i=1}^3 v_i \mathbf{e}_i \ .
\]</span> Recall the summation convention says that if a term has a repeated index a summation over all values of that index is implied. In this case, <span class="math inline">\(v_i \mathbf{e}_i\)</span> has the repeated index <span class="math inline">\(i\)</span>, which is assumed to sum from 1 to 3. Any index that does not repeat does not get summed over. We’ll sometimes express a vector only by its components <span class="math inline">\(v_i\)</span>, where the basis is left unspecified. This is called <em>index notation</em>. It’s fully equivalent to vector notation but sometimes more convenient when doing complex vector calculations. We’ll go back and forth between these two notations in this course.</p>
<p>For a vector to be a valid physical object, we require it transform in a specific way under coordinate transformations. If <span class="math inline">\(S\)</span> is one coordinate system and <span class="math inline">\(S'\)</span> is another, we require that <span class="math inline">\(\mathbf{v}(\mathbf{x}') = \mathbf{J} \mathbf{v}(\mathbf{x})\)</span>, where <span class="math inline">\(\mathbf{v}(\mathbf{x}')\)</span> is the representation of <span class="math inline">\(\mathbf{v}\)</span> in the <span class="math inline">\(S'\)</span> coordinates and <span class="math inline">\(\mathbf{v}(\mathbf{x})\)</span> its representation in the <span class="math inline">\(S\)</span> coordinates. The object <span class="math inline">\(\mathbf{J} \equiv \frac{d\mathbf{x}'}{d\mathbf{x}}\)</span> is the <em>Jacobian matrix</em>, an invertible square matrix that describes how the coordinates transform from <span class="math inline">\(S\)</span> and <span class="math inline">\(S'\)</span>. Any superposition of vectors is a valid vector as well.</p>
<p>We can think of a vector as a one index, or <em>rank-1</em>, object that transforms as specified above. A simpler object with no index, or <em>rank-0</em>, defines a <em>scalar</em>. A <em>scalar</em> is a single number that doesn’t change under coordinate transformations. An important example of a scalar is the <em>dot product</em> or <em>inner product</em> between two vectors, defined in Euclidean space by <span class="math display">\[
\mathbf{v} \cdot \mathbf{w} \equiv v_i w_i = v_1 w_1 + v_2 w_2 + v_3 w_3 \ .
\]</span> Recall from elementary physics that we can also express the dot product in terms of the angle <span class="math inline">\(\theta\)</span> between the two vectors as <span class="math display">\[
\mathbf{v} \cdot \mathbf{w} = |\mathbf{v}| |\mathbf{w}| \cos\theta \ .
\]</span> Here <span class="math inline">\(|\mathbf{v}| \equiv \sqrt{\mathbf{v} \cdot \mathbf{v}}\)</span> is the <em>norm</em> or <em>magnitude</em> of <span class="math inline">\(\mathbf{v}\)</span>. This formula says that in some sense the dot product encodes information about both the magnitude of vectors as well as the angles between them. When <span class="math inline">\(|\mathbf{v}|=1\)</span> we say <span class="math inline">\(\mathbf{v}\)</span> is a <em>unit vector</em>, which in this course we’ll usually denote by <span class="math inline">\(\mathbf{e}_v\)</span>. Evidently the dot product of two vectors is zero if they’re perpendicular, in which case we call the two vectors <em>orthogonal</em>. When the two vectors are parallel or antiparallel their dot product is <span class="math inline">\(\pm 1\)</span>.</p>
<p>As long as coordinate transformations are rotations, the dot product will always be a scalar. As an exercise in using index notation let’s prove this. When working in index notation we need to convert every object we need to an indexed object. Since <span class="math inline">\(\mathbf{v}\)</span> and <span class="math inline">\(\mathbf{w}\)</span> are vectors, they both get one index. Since their components get summed over in the dot product, the indices on the two vectors should be the same. That is, <span class="math inline">\(\mathbf{v} \cdot \mathbf{w} \leftrightarrow v_i w_i\)</span>.</p>
<p>We’ll also need to index the Jacobian matrix <span class="math inline">\(\mathbf{J}\)</span>. Since matrices carry two indices, we’ll need two indices to index the Jacobian. It’s not hard to see that the matrix multiplication <span class="math inline">\(\mathbf{v}'=\mathbf{J}\mathbf{v}\)</span> in index notation can be expressed as <span class="math inline">\(v_i' = J_{ij} v_j\)</span>. We’ll need to make use of two other facts. First, <em>transposing</em> a matrix in index notation just swaps the indices, so <span class="math inline">\((J^\top)_{ij} = J_{ji}\)</span>. Second, the identity matrix <span class="math inline">\(\mathbf{I}\)</span> is expressed in index notation using the <em>Kronecker delta</em> <span class="math inline">\(\delta_{ij}\)</span>, defined to be 1 when <span class="math inline">\(i=j\)</span> and 0 otherwise.</p>
<p>We’re now ready to proceed with the proof. We need to show that under a coordinate transformation from <span class="math inline">\(S'\)</span> to <span class="math inline">\(S\)</span> the dot product stays invariant under rotations. Starting with the dot product in <span class="math inline">\(S'\)</span> coordinates, we have <span class="math display">\[
v_i' w_i' = v_i' w_j' = (J_{ij} v_j) (J_{ik} w_k) = J_{ij} J_{ik} v_i w_k  \ .
\]</span> Now, we need the right-hand side to equal <span class="math inline">\(v_i w_i\)</span>. The only way this can be true is if <span class="math inline">\(J_{ij} J_{ik} = \delta_{jk}\)</span>. Then we get <span class="math display">\[
v_i' w_i' = J_{ij} J_{ik} v_i w_k = \delta_{jk} v_i w_k = v_j w_j  \ .
\]</span> Now, the index being summed over is a <em>dummy index</em>, meaning it doesn’t matter how we label it as long as we’re consistent. We can thus freely relabel <span class="math inline">\(j\)</span> to <span class="math inline">\(i\)</span> and write <span class="math inline">\(v_i' w_i' = v_i w_i\)</span>, which is what we wanted to show.</p>
<p>For this proof to work, however, we had to impose the fact that <span class="math inline">\(J_{ij} J_{ik} = \delta_{jk}\)</span>. This is just saying that the Jacobian times its transpose should equal the identity, i.e.&nbsp;<span class="math inline">\(\mathbf{J}^\top \mathbf{J} = \mathbf{I}\)</span>. What kinds of transformations satisfy this property? Recall that this is just the definition of an <em>orthogonal transformation</em>. An orthogonal transformation is precisely a transformation that preserves the dot products between vectors. From the elementary definition of the dot product, this also means an orthogonal transformation preserves the <em>angles</em> between vectors. Note that such transformations need not preserve the <em>handedness</em> between the vectors. Since <span class="math inline">\(\det \mathbf{J} = \pm 1\)</span> for orthogonal transformations, there are two cases. It’s the <span class="math inline">\(+1\)</span> case that preserves handedness, while the <span class="math inline">\(-1\)</span> case flips the order between the vectors.</p>
<p>It’s fair to ask what happens when the coordinate transformation isn’t orthogonal. In that case, we define <span class="math inline">\(\mathbf{g} \equiv \mathbf{J}^\top \mathbf{J}\)</span>, in which case we then define <span class="math inline">\(\mathbf{x} \cdot \mathbf{y} \equiv x_i g_{ij} y_j\)</span>. Here <span class="math inline">\(\mathbf{g}\)</span> is called the <em>metric</em>. It says something about the geometry of the two coordinate transformations. With this generalized form of the dot product it again becomes a proper scalar regardless of what <span class="math inline">\(\mathbf{J}\)</span> is. We’ll see this more general dot product again when we get to relativistic electrodynamics towards the end of the course. Indeed, the presence of <span class="math inline">\(\mathbf{g}\)</span> is one of the defining features of relativity, both special and general relativity.</p>
<p>We know that vectors in 3 dimensions also have another kind of product that creates vectors from vectors. This other product is called the <em>cross product</em>, which in index notation can be defined by <span class="math display">\[
(\mathbf{x} \times \mathbf{y}) \equiv \varepsilon_{ijk} x_i y_j \mathbf{e}_k \ .
\]</span> Here <span class="math inline">\(\varepsilon_{ijk}\)</span> is the <em>Levi-Civita symbol</em>, defined to be <span class="math inline">\(+1\)</span> for even permutations of <span class="math inline">\(ijk\)</span>, <span class="math inline">\(-1\)</span> for odd permutations of <span class="math inline">\(ijk\)</span>, and <span class="math inline">\(0\)</span> when any of the indices are repeated. Written out in components, it’s not hard to show that <span class="math display">\[
\mathbf{v} \times \mathbf{w} = (v_y w_z - v_z w_y) \mathbf{e}_x + (v_z w_x - v_x w_z) \mathbf{e}_y + (v_x w_y - v_y w_x) \mathbf{e}_z \ .
\]</span> We know that the cross product between two vectors can also be expressed geometrically, where its magnitude is given by <span class="math display">\[
|\mathbf{v} \times \mathbf{w}| = |\mathbf{v}| |\mathbf{w}| \sin\theta \ ,
\]</span> while its direction is given by the <em>right-hand rule</em>. The cross product evidently defines a favored orientation in space. If a plane contains the two vectors <span class="math inline">\(\mathbf{v}\)</span> and <span class="math inline">\(\mathbf{w}\)</span>, its positive orientation or <em>normal</em> is the direction of <span class="math inline">\(\mathbf{v} \times \mathbf{w}\)</span>. Evidently, this version of the cross product says that the cross product of two parallel vectors is <span class="math inline">\(\mathbf{0}\)</span>. Note the cross product is neither commutative nor associative.</p>
<p>It’s worth pointing out that despite the hand-waving, the cross product is not <em>really</em> a vector in the sense we’ve defined what a vector really is, an object that transforms a certain way under coordinate transformations. The cross product in general does <em>not</em> transform correctly under coordinate transformations. For example, under an <em>inversion</em> <span class="math inline">\(\mathbf{v} \rightarrow -\mathbf{v}, \mathbf{w} \rightarrow -\mathbf{w}\)</span> their cross product remains <span class="math inline">\(\mathbf{v} \times \mathbf{w}\)</span>. It doesn’t become <span class="math inline">\(-\mathbf{v} \times \mathbf{w}\)</span> like we’d require. For this reason the cross product is properly thought of as a <em>pseudovector</em>, in that in a lot of ways it behaves like a vector, but not in all ways. In fact, properly speaking the cross product should be thought of as an antisymmetric tensor. We’ll say more about this below.</p>
<p>The Levi-Civita symbol is a useful symbol in its own right, independent of the cross product. We’ll need to understand its algebra a bit better since we’ll use this symbol frequently in this course. One useful fact is that swapping two indices introduces a negative sign. For example, swapping <span class="math inline">\(i \leftrightarrow j\)</span> gives <span class="math inline">\(\varepsilon_{jik} = -\varepsilon_{ijk}\)</span>. We can use this fact to show that the cross product is perpendicular to the plane spanned by the two vectors. We can do this by showing <span class="math inline">\(\mathbf{v} \cdot (\mathbf{v} \times \mathbf{w}) = 0\)</span>. That is, that <span class="math inline">\(\mathbf{v}\)</span> is <em>orthogonal</em> to <span class="math inline">\(\mathbf{v} \times \mathbf{w}\)</span>, which by the geometric version of the dot product means the two are perpendicular. In index notation, we have <span class="math display">\[
\mathbf{v} \cdot (\mathbf{v} \times \mathbf{w}) = \varepsilon_{ijk} v_j w_k (\mathbf{v} \cdot \mathbf{e}_i) = v_i \varepsilon_{ijk} v_j w_k = -v_i \varepsilon_{jik} v_j w_k = -v_j \varepsilon_{ijk} v_i w_k \ .
\]</span> Notice we have <span class="math inline">\(\varepsilon_{ijk} x_i x_j y_k = -\varepsilon_{ijk} x_i x_j y_k\)</span>, which can only be true of both are zero, as we wanted to show.</p>
<p>Another surprisingly useful identity of the Levi-Civita symbol is gotten by <em>contracting</em> their product to get <span class="math display">\[
\varepsilon_{ijk} \varepsilon_{k\ell m} = \delta_{i\ell} \delta_{jm} - \delta_{im} \delta_{j\ell} \ .
\]</span> As an application of this surprising identity, we’ll use it to prove the well-known <em>BAC-CAB</em> rule for triple products, <span class="math display">\[
\mathbf{a} \times (\mathbf{b} \times \mathbf{c}) = \mathbf{b} (\mathbf{a} \cdot \mathbf{c}) - \mathbf{c} (\mathbf{a} \cdot \mathbf{b}) \ .
\]</span> Let <span class="math inline">\(\mathbf{d} = \mathbf{a} \times (\mathbf{b} \times \mathbf{c})\)</span> for convenience. Writing this out in index notation and applying the previous identity, we have <span class="math display">\[
\begin{align*}
d_i &amp;= [\mathbf{a} \times (\mathbf{b} \times \mathbf{c})]_i \\
&amp;= \varepsilon_{ijk} a_j (\mathbf{b} \times \mathbf{c})_k \\
&amp;= \varepsilon_{ijk} \varepsilon_{k\ell m} a_j b_\ell c_m \\
&amp;= (\delta_{i\ell} \delta_{jm} - \delta_{im} \delta_{j\ell}) a_j b_\ell c_m \\
&amp;= \delta_{i\ell} \delta_{jm} a_j b_\ell c_m - \delta_{im} \delta_{j\ell} a_j b_\ell c_m \\
&amp;= a_j b_i c_j - a_j b_j c_i \\
&amp;= (\mathbf{a} \cdot \mathbf{c}) b_i - (\mathbf{a} \cdot \mathbf{b}) c_i \ .
\end{align*}
\]</span> Written back out in vector notation this gives exactly what we wanted to show.</p>
<p>The last curious fact of the Levi-Civita symbol that we’ll mention but not really use is that we can use it to write out the determinant of a <span class="math inline">\(3 \times 3\)</span> matrix. If a matrix <span class="math inline">\(\mathbf{A}\)</span> has column vectors <span class="math inline">\(\mathbf{a}, \mathbf{b}, \mathbf{c}\)</span>, then we have <span class="math display">\[
\det \mathbf{A} = \varepsilon_{ijk} a_i b_j c_k \ .
\]</span> While cute, this formula only works in 3 dimensions. In other dimensions we’d have to use generalizations of the Levi-Civita symbol to get a formula like this, and even then they’re not actually useful for <em>calculating</em> the determinant.</p>
</section>
<section id="tensors" class="level3">
<h3 class="anchored" data-anchor-id="tensors">Tensors</h3>
<p>Thus far we’ve seen objects with no indices and objects with one index that transform in a specified way under coordinate transformations. It’s fair to ask whether we can define matrices that transform in a specific way as well, and in fact we can. These two-index objects are called <em>rank-2 tensors</em>. They’re matrices <span class="math inline">\(\mathbf{T}\)</span> that obey the transformation law <span class="math display">\[
\mathbf{T}(\mathbf{x}') = \mathbf{J}^\top \mathbf{T}(\mathbf{x}') \mathbf{J} \ .
\]</span> This is just a direct generalization of the vector transformation law. It’s easier to see this in index notation. Vectors obey the transformation law <span class="math inline">\(v_i' = J_{ij} v_j\)</span>, while rank-2 tensors obey the transformation law <span class="math display">\[
T_{ij}' =  J_{ik} J_{j\ell} T_{k\ell} \ .
\]</span> Roughly speaking, this just says each dimension of the tensor transforms itself as a vector would.</p>
<p>While tensors didn’t show up transparently in elementary physics courses, they show up a lot in more advanced physics. A lot of physical quantities are tensors: the metric tensor, the moment of inertia tensor, the strain tensor, and so on. Another example is the <em>cross product</em>. The cross product seems like a vector, but it’s really not. In fact, we can define the cross product in a slightly different way using a rank-2 tensor as <span class="math display">\[
\varepsilon_{ijk} (\mathbf{v} \times \mathbf{w})_k = v_i w_j - v_j w_i
\]</span> In this variant definition the cross product is no longer a vector, but a rank-2 tensor whose upper diagonal components are the usual components of the cross product in 3 dimensions. Represented as a matrix <span class="math inline">\(\mathbf{A}\)</span>, it looks like <span class="math display">\[
A_{ij} \equiv \varepsilon_{ijk} (\mathbf{v} \times \mathbf{w})_k \doteq
\begin{pmatrix}
0 &amp; v_1 w_2 - v_2 w_1 &amp; v_1 w_3 - v_3 w_1  \\
v_2 w_1 - v_1 w_2 &amp; 0 &amp; v_2 w_3 - v_3 w_2 \\
v_3 w_1 - v_1 w_3 &amp;  &amp; 0 \\
\end{pmatrix}
\ .
\]</span> Here <span class="math inline">\(\mathbf{A}\)</span> is a rank-2 tensor that evidently satisfies the <em>antisymmetric</em> property <span class="math inline">\(A_{ij} = -A_{ji}\)</span>. Unlike with the regular cross product, this generalization of the cross product can be defined for any number of dimensions. To see why we can’t extend the usual cross product this way, notice that the components <span class="math inline">\(\mathbf{v} \times \mathbf{w}\)</span> lie in the upper diagonal of <span class="math inline">\(\mathbf{A}\)</span>. The diagonals are always zero, and the lower diagonal is just minus the upper diagonal, meaning there are only 3 independent components. For a general antisymmetric tensor in <span class="math inline">\(d\)</span> dimensions there will be <span class="math inline">\(\frac{1}{2}d(d-1)\)</span> such independent components in the upper diagonal. Insisteng that such a tensor be a vector is equivalent to requiring <span class="math inline">\(d=\frac{1}{2}d(d-1)\)</span>, which evidently can only be true when <span class="math inline">\(d=3\)</span>. Thus, the cross product can only be a vector in 3 dimensions.</p>
<p>One useful operation that we can do with tensors is <em>contraction</em>. Contraction is the tensor generalization of the inner product, obtained by setting two indices in a tensor equal and summing over them. Since rank-2 tensors only have 2 indices, contracting a rank-2 tensor will always give a scalar, which is of course just <em>trace</em> of <span class="math inline">\(\mathbf{T}\)</span>, i.e.&nbsp;<span class="math inline">\(T_{ii} = \text{tr} \ \mathbf{T}\)</span>. Just as the dot product of a vector with itself says something about its size (in fact it’s just its squared norm), the trace of a rank-2 tensor says something about its size. Since the trace has no free indices, it must be a rank-0 object, hence a proper scalar like the dot product.</p>
<p>Another operation we can do with tensors is take their <em>tensor product</em>. A tensor product is no more than component-wise concatenation. For example, if <span class="math inline">\(\mathbf{x}\)</span> and <span class="math inline">\(\mathbf{y}\)</span> are two vectors, we can define their tensor product in index notation by <span class="math display">\[
T_{ij} \equiv x_i x_j \ .
\]</span> Evidently the tensor product of two vectors gives a rank-2 tensor. In fact, it’s just the outer product of the two vectors. In this sense the tensor product is a generalization of the outer product, just as contraction is the generalization of the inner product. In more abstract notation we’d write the tensor product as <span class="math display">\[
\mathbf{T} = \mathbf{x} \otimes \mathbf{y} \equiv \mathbf{x} \mathbf{y} \ .
\]</span> The last expression <span class="math inline">\(\mathbf{x} \mathbf{y}\)</span> for the tensor product is called <em>dyadic notation</em>, where we omit the <span class="math inline">\(\otimes\)</span> symbol for brevity. It’s tempting to think that all rank-2 tensors can be formed from a tensor product of vectors, but this is false. Only special vectors can, called <em>product tensors</em>. Most rank-2 tensors are <em>mixed tensors</em>, meaning superpositions of vector outer products.</p>
<p>Using the tensor product we can define the notion of a <em>basis tensor</em> for a rank-2 tensor as <span class="math display">\[
\mathbf{e}_{ij} \equiv \mathbf{e}_i \mathbf{e}_j \equiv \mathbf{e}_i \otimes \mathbf{e}_j \ .
\]</span> Since this is just the outer products of the two basis vectors, they are 1 when at slot <span class="math inline">\((i,j)\)</span> and 0 otherwise. Using superposition just as we do for vectors, we can use these basis tensors to expand any rank-2 tensor as <span class="math display">\[
\mathbf{T} = T_{ij} \mathbf{e}_i \mathbf{e}_j \ .
\]</span> We can also take the tensor product of a rank-2 tensor with a vector, which would give a three-index object, or a <em>rank-3 tensor</em>. Taking the tensor product of two rank-2 tensors would give a <em>rank-4 tensor</em>. And so on. In fact we can define a tensor of any rank. A <em>rank-k</em> tensor is an object with <span class="math inline">\(k\)</span> indices that tranforms component-wise according to the law <span class="math display">\[
T_{i_1' i_2' \cdots i_k'} = R_{i_1' i_1} R_{i_2' i_2} \cdots R_{i_2' i_2} T_{i_1 i_2 \cdots i_k} \ .
\]</span> In this course we won’t generally work much with tensors of higher rank than 2, but they do show up, for example in the multipole expansions of the scalar and vector potentials. Tensor contraction can be defined naturally on these higher-rank tensors as well. Contracting two indices in a tensor will always reduce its rank by 2.</p>
</section>
<section id="vector-calculus" class="level3">
<h3 class="anchored" data-anchor-id="vector-calculus">Vector Calculus</h3>
<p>Calculus extends naturally to higher dimensions, but often in subtle ways. Most importantly, there are different types of derivatives and integrals defined in higher dimensions with different meaning and applications. Due to complications involved in using curvilinear coordinates in vector calculus we’ll state results in Cartesian coordinates and address the curvilinear situation later.</p>
<p>The fundamental object of vector calculus is the <em>differential</em> of a field. This says how much the field changes if its inputs are nudged in some direction by an infinitesimal amount. In Cartesian coordinates, it turns out the differential of a scalar field <span class="math inline">\(f(\mathbf{x})\)</span> is nothing more than a sum of partial differentials along each coordinate. That is, <span class="math display">\[
df = \frac{\partial f}{\partial x} dx + \frac{\partial f}{\partial y} dy + \frac{\partial f}{\partial z} dz \ .
\]</span> The right-hand side looks like a sort of dot product between the partial derivatives of <span class="math inline">\(f\)</span> and a differential displacement vector <span class="math inline">\(d\mathbf{x}\)</span>, or <em>vector line element</em>, defined in Cartesian coordinates by <span class="math display">\[
d\mathbf{x} \equiv dx \mathbf{e}_x + dy \mathbf{e}_y + dz \mathbf{e}_z \ .
\]</span> It’s the vector generalization of the differential <span class="math inline">\(dx\)</span> from ordinary calculus. The vector of partial derivatives can be written in a useful way by defining the <em>del operator</em> <span class="math inline">\(\nabla\)</span> by <span class="math display">\[
\nabla \equiv \partial_i \mathbf{e}_i \equiv \frac{\partial}{\partial x} \mathbf{e}_x + \frac{\partial}{\partial y} \mathbf{e}_y + \frac{\partial}{\partial z} \mathbf{e}_z \ .
\]</span> Here we introduce the convenient shorthand <span class="math inline">\(\partial_i \equiv \frac{\partial}{\partial x_i}\)</span> for the partial derivative with respect to component <span class="math inline">\(x_i\)</span>. Using the del operator we can define the vector of partial derivatives of a scalar field <span class="math inline">\(f\)</span> by <span class="math display">\[
\nabla f \equiv \partial_i f \ \mathbf{e}_i \equiv \frac{\partial f}{\partial x} \mathbf{e}_x + \frac{\partial f}{\partial y} \mathbf{e}_y + \frac{\partial f}{\partial z} \mathbf{e}_z \ .
\]</span> This quantity is evidently some kind of vector derivative, called the <em>gradient</em> of the field <span class="math inline">\(f\)</span>. Since <span class="math inline">\(f\)</span> is a scalar field, <span class="math inline">\(\nabla f\)</span> will be a vector field. Its components are the partial derivatives of <span class="math inline">\(f\)</span> in the <span class="math inline">\(x_i\)</span> direction at each <span class="math inline">\(\mathbf{x}\)</span>. The gradient always points perpendicular to the <em>level curves</em> where <span class="math inline">\(f=\text{const}\)</span>. To see why we can use the geometric formula for the dot product to express any change in the function along a level curve as <span class="math display">\[
\delta f = \nabla f \cdot \delta \mathbf{x} = |\nabla f| |\delta \mathbf{x}| \cos\theta \ .
\]</span> Since <span class="math inline">\(\delta f = 0\)</span> along the level curve by definition, it must be the case that <span class="math inline">\(\theta = \pm 90^\circ\)</span> along such curves, meaning that the gradient must always be orthogonal to the level curve.</p>
<p>Using the gradient, we can finally express the differential <span class="math inline">\(df\)</span> as a dot product of the gradient with the vector line element, <span class="math display">\[
df = \nabla f \cdot d\mathbf{x} \ .
\]</span> Unlike in ordinary calculus, however, in vector calculus this isn’t the only kind of derivative we can take. We can see this by looking at the definition of <span class="math inline">\(\nabla\)</span>. We can think of <span class="math inline">\(\nabla f\)</span> as multiplying a vector by a scalar. But we also know that we can take both the dot product and the cross product of two vectors, which along with <span class="math inline">\(\nabla\)</span> suggests there are two more derivative operations we can perform on vector fields.</p>
<p>If <span class="math inline">\(\mathbf{F}(\mathbf{x})\)</span> is a vector field, we can take its dot product of <span class="math inline">\(\nabla\)</span> with <span class="math inline">\(\mathbf{F}\)</span> to get a new scalar field known as the <em>divergence</em>, which is evidently defined in Cartesian coordinates by <span class="math display">\[
\nabla \cdot \mathbf{F} \equiv \partial_i F_i \equiv \frac{\partial f}{\partial x} + \frac{\partial f}{\partial y} + \frac{\partial f}{\partial z} \ .
\]</span> Though not obvious from the definition, the divergence represents the tendency of a vector to flow into or out of a point. A field where <span class="math inline">\(\nabla \cdot \mathbf{F} = 0\)</span> for all points in space has no divergence at all, meaning there are no sources or sinks in the field anywhere. Due to the fact that the magnetic field is the canonical example of a divergence-less vector field, such fields are often called <em>solenoidal</em>.</p>
<p>We can also take the cross product of <span class="math inline">\(\nabla\)</span> with <span class="math inline">\(\mathbf{F}(\mathbf{x})\)</span> to get a vector field known as the <em>curl</em>, defined in Cartesian coordinates by <span class="math display">\[
\nabla \times \mathbf{F} \equiv \varepsilon_{ijk} \partial_i F_j \mathbf{e}_k \ .
\]</span></p>
<p>Though again not obvious from the definition, the curl represents the tendency of a vector to rotate around a point in space. A field where <span class="math inline">\(\nabla \times \mathbf{F} = \mathbf{0}\)</span> at all points in space is called <em>irrotational</em> since it doesn’t experience any rotational motion at any point. It just flows inward or outward.</p>
<p>We can also take vector second derivatives as well. The most useful of these is obtained by taking the divergence of the gradient of a scalar field. This is called the <em>Laplacian</em>, defined in Cartesian coordinates by <span class="math display">\[
\nabla^2 f \equiv \nabla \cdot \nabla f = \partial_i \partial_i f = \frac{\partial^2 f}{\partial x^2} + \frac{\partial^2 f}{\partial y^2} + \frac{\partial^2 f}{\partial z^2} \ .
\]</span> There are a few other vector second derivatives as well, some of which turn out to be zero. These are <span class="math display">\[
\begin{align*}
\nabla \cdot (\nabla \times \mathbf{F}) &amp;= 0 \ , \\
\nabla \times \nabla f &amp;= \mathbf{0} \ , \\
\nabla \times (\nabla \times \mathbf{F}) &amp;= \nabla (\nabla \cdot \mathbf{F}) - \nabla^2 \mathbf{F} \ .
\end{align*}
\]</span> The Laplacian in the last expression is understood to be taken component-wise, as a vector with components <span class="math inline">\(\nabla^2 F_i\)</span>. Each of these identities can all be efficiently proven using index notation.</p>
<p>The gradient, divergence, and curl each has its own corresponding version of the fundamental theorem of calculus. To understand integration in higher dimensions though we first need to define what the differentials are. To integrate over a spatial volume we use the <em>volume element</em> <span class="math inline">\(d^3 \mathbf{x}\)</span>, defined in Cartesian components by <span class="math display">\[
d^3 \mathbf{x} \equiv dx dy dz \ .
\]</span> An important fact about the volume element is that its expression in a given coordinate system depends on the Jacobian. If <span class="math inline">\(\mathbf{u}(\mathbf{x})\)</span> is some coordinate transformation with Jacobian <span class="math inline">\(\mathbf{J} \equiv \frac{d\mathbf{u}}{d\mathbf{x}}\)</span>, then their volume elements are related by <span class="math display">\[
d^3 \mathbf{x} = du_1 du_2 du_3 = |\det \mathbf{J}| dx_1 dx_2 dx_3 \ .
\]</span> To find the <em>volume integral</em> of a scalar field <span class="math inline">\(f\)</span> over a region of space <span class="math inline">\(\mathcal{V}\)</span>, we can integrate each coordinate iteratively, <span class="math display">\[
\int_\mathcal{V} d^3 \mathbf{x} \ f(\mathbf{x}) = \iiint_\mathcal{V} dx dy dz \ f(x,y,z) \ .
\]</span> We can integrate a vector field over a volume too. In this case the integral is done component-wise, so little new is added.</p>
<p>Sometimes we’ll also need to integrate a field over a <em>surface</em> in space as well. Suppose we wish to integrate over some smooth, orientable surface <span class="math inline">\(\mathcal{S}\)</span> in space. We can define an <em>area element</em> <span class="math inline">\(d\mathbf{a}\)</span> on this surface by considering an infinitesimal patch of area <span class="math inline">\(da\)</span> on the surface and attaching an outward unit normal <span class="math inline">\(\mathbf{n}\)</span> to it to get <span class="math display">\[
d\mathbf{a} \equiv \mathbf{n} \ da \ .
\]</span> It’s fair to ask how <span class="math inline">\(da\)</span> itself is determined. When the surface is the <span class="math inline">\(xy\)</span>-plane it’s clear <span class="math inline">\(da = dxdy\)</span>. But for more general surfaces we’d need to parametrize <span class="math inline">\(\mathcal{S}\)</span> with two relative coordinates and express <span class="math inline">\(da\)</span> in terms of those. Evidently the area element <span class="math inline">\(d\mathbf{a}\)</span> is a kind of vector. We can thus also think of it as the cross product of two infinitesimal vectors on the surface. Importantly, this means <span class="math inline">\(d\mathbf{a}\)</span> will have both a magnitude and a direction that depend on where we are along the surface. When we require the surface be orientable, we mean that we can always use the right-hand rule to find the direction of <span class="math inline">\(\mathbf{n}\)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./resources/image-20240126183636267.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="300"></p>
</figure>
</div>
<p>To get the <em>surface integral</em> of a vector field <span class="math inline">\(\mathbf{F}\)</span> along the surface <span class="math inline">\(\mathcal{S}\)</span> we’d typically write <span class="math display">\[
\int_\mathcal{S} \mathbf{F} \cdot d\mathbf{a} = \int_\mathcal{S} \mathbf{F} \cdot \mathbf{n} \ da \ .
\]</span> The last form of vector integration we’ll find ourselves using frequently is <em>path integration</em>, which is the integration of a field along some arbitrary curve in space. This form of integration is done by considering the contribution of the field along each vector line element <span class="math inline">\(d\boldsymbol{\ell}\)</span> along some path <span class="math inline">\(\mathcal{C}\)</span>. For a vector field <span class="math inline">\(\mathbf{F}\)</span> each infinitesimal contribution is found by taking the dot product <span class="math inline">\(\mathbf{F} \cdot d\boldsymbol{\ell}\)</span>, which we can add up, or integrate, along the entire path to get a scalar-valued path integral, <span class="math display">\[
\int_\mathcal{C} \mathbf{F} \cdot d\boldsymbol{\ell} \ .
\]</span> To actually evaluate a path integral one needs to parametrize the line element somehow. For example, if we use Cartesian coordinates to parametrize the line element, we can find the path integral by <span class="math display">\[
\int_\mathcal{C} \mathbf{F} \cdot d\boldsymbol{\ell} = \int_{\mathcal{C}_x} dx \ F_x + \int_{\mathcal{C}_y} dy \ F_y + \int_{\mathcal{C}_z} dz \ F_z \ ,
\]</span> where <span class="math inline">\(\mathcal{C}_i\)</span> is the projection of the path onto the <span class="math inline">\(x_i\)</span> axis.</p>
<p>If we’re not interested in the direction of the contour but only its length, we can integrate over its norm instead. This norm is called the <em>scalar line element</em> and defined by <span class="math inline">\(ds \equiv |d\boldsymbol{\ell}|\)</span>. Integrating over <span class="math inline">\(ds\)</span> alone gives the <em>arc length</em> of the contour in space. Interestingly the scalar line element is very important in studying the geometry of a space. In general it depends on the metric <span class="math inline">\(\mathbf{g}\)</span> by <span class="math display">\[
ds^2 = dx_i g_{ij} dx_j \ .
\]</span> For Euclidean space the metric is always the identity, so we just have <span class="math inline">\(ds^2 = dx_i dx_i\)</span>. This is all we’ll need for most of this course, but in relativity (especially general relativity) this line element becomes fundamental.</p>
<p>Usually a path integral between two endpoints will depend on the exact path of the contour <span class="math inline">\(\mathcal{C}\)</span>. For some special fields though the path integral depends only on the endpoints, not on the path between them. When this is true we say the field is <em>conservative</em>. An implication of this is that if we integrate a conservative field around any <em>closed contour</em> the path integral vanishes, <span class="math display">\[
\oint \mathbf{F} \cdot d\mathbf{x} = 0 \ .
\]</span> It’s easy to see why this must be true. For any closed contour we can break it into two pieces. The line integral of each piece must be path independent, which means their sum, and hence the closed path integral, must vanish for conservative fields.</p>
<p>In vector calculus, each version of vector derivative has its own fundamental theorem of calculus that relates it to one or more of the integrals defined above. The fundamental theorem for gradients says the line integral of the gradient of a scalar field depends only on the endpoints, <span class="math display">\[
\int_{\mathbf{x}_1}^{\mathbf{x}_2} \nabla f(\mathbf{x}) \cdot d\mathbf{x} = f(\mathbf{x}_2) - f(\mathbf{x}_1) \ .
\]</span> Said differently, the gradient of a scalar field is always <em>conservative</em>. Conversely, any conservative vector field <span class="math inline">\(\mathbf{F}(\mathbf{x})\)</span> can be written as the gradient of some scalar field <span class="math inline">\(\phi(\mathbf{x})\)</span>, <span class="math display">\[
\mathbf{F} = -\nabla \phi \ .
\]</span> This fact we use extensively in electromagnetism. The minus sign is merely a physics convention. Since the curl of a gradient must vanish, this statement also says <span class="math inline">\(\mathbf{F}\)</span> must be irrotational, i.e.&nbsp;<span class="math inline">\(\nabla \times \mathbf{F} = \mathbf{0}\)</span>.</p>
<p>A more general extension of this special case is called the <em>Helmholtz theorem</em>. It says <em>any</em> smooth vector field <span class="math inline">\(\mathbf{F}(\mathbf{x})\)</span>, conservative or not, can be expressed as the <em>gradient</em> of some <em>scalar field</em> <span class="math inline">\(\phi(\mathbf{x})\)</span> plus the <em>curl</em> of some other <em>vector field</em> <span class="math inline">\(\mathbf{A}(\mathbf{x})\)</span>, i.e. <span class="math display">\[
\mathbf{F} = -\nabla \phi + \nabla \times \mathbf{A} \ .
\]</span> Though not obvious at this stage, this formula in fact can be inverted to find formulas for <span class="math inline">\(\phi\)</span> and <span class="math inline">\(\mathbf{A}\)</span> in terms of derivatives of <span class="math inline">\(\mathbf{F}\)</span>, <span class="math display">\[
\begin{align*}
\phi(\mathbf{x}) &amp;= \frac{1}{4\pi} \int_{\mathbb{R}^3} d^3 \mathbf{x}' \ \frac{\nabla' \cdot \mathbf{F}(\mathbf{x}')}{|\mathbf{x} - \mathbf{x}'|} \ , \\
\mathbf{A}(\mathbf{x}) &amp;= \frac{1}{4\pi} \int_{\mathbb{R}^3} d^3 \mathbf{x}' \ \frac{\nabla' \times \mathbf{F}(\mathbf{x}')}{|\mathbf{x} - \mathbf{x}'|} \ .
\end{align*}
\]</span> Here it’s implicitly assumed that <span class="math inline">\(\mathbf{F}\)</span> vanishes faster than <span class="math inline">\(\frac{1}{r}\)</span> at infinity. If not we have to include extra boundary terms. The symbol <span class="math inline">\(\nabla'\)</span> means to differentiate with respect to the integration variable <span class="math inline">\(\mathbf{x}'\)</span>.</p>
<p>The fundamental theorem for divergences is called the <em>divergence theorem</em>. It says that the divergence of a vector field is nothing more than the flow or <em>flux</em> of the field through the surface of a closed volume, <span class="math display">\[
\int_\mathcal{V} \nabla \cdot \mathbf{F} \ d^3\mathbf{x} = \int_S \mathbf{F} \cdot d\mathbf{a} \ .
\]</span> The fundamental theorem for curls is called <em>Stokes’ theorem</em>. It says the curl of a vector field is nothing more than the <em>circulation</em> of the field around the boundary of any closed surface, <span class="math display">\[
\int_\mathcal{S} (\nabla \times \mathbf{F}) \cdot \ d\mathbf{a} = \int_C \mathbf{F} \cdot d\mathbf{x} \ .
\]</span> Though perhaps not obvious at this stage, the divergence and Stokes’ theorems are precisely what we use to go back and forth between the integral and differential forms of Maxwell’s equations.</p>
<p>It’s interesting to note that all of these versions of the fundamental theorem of calculus say essentially the same thing: The integral of the derivative of a field over some space equals the value of that field along the boundary of that space. For gradients, the boundary of a contour is just two endpoints. For divergences, the boundary over a volume is a closed surface. For curls, the boundary of a surface is a closed contour.</p>
<p>Many of the usual derivative and integral rules extend to vector calculus as well using index notation. For example, the product rule for the product of a vector field <span class="math inline">\(\mathbf{F}\)</span> with a scalar field <span class="math inline">\(g\)</span> is <span class="math display">\[
d(\mathbf{F} g) = \mathbf{F} \ dg + g \ d\mathbf{F} \ .
\]</span> Dividing both sides by <span class="math inline">\(d\mathbf{x}\)</span> and integrating gives us one generalized version of integration by parts. Indeed, integrating both sides over a volume <span class="math inline">\(\mathcal{V}\)</span>, we get <span class="math display">\[
\int_\mathcal{V} \nabla(\mathbf{F} g) \cdot d^3\mathbf{x} = \int_\mathcal{V} \mathbf{F} \cdot \nabla g \ d^3 \mathbf{x} + \int_\mathcal{V} g \ \nabla \mathbf{F} \ d^3 \mathbf{x} \ .
\]</span> Rearranging terms and using the divergence theorem to express the left-hand integral as an integral over the bounding surface <span class="math inline">\(\mathcal{S}\)</span>, we get <span class="math display">\[
\int_\mathcal{V} \mathbf{F} \cdot \nabla g \ d^3 \mathbf{x} = \oint_\mathcal{S} \nabla(\mathbf{F} g) \cdot d\mathbf{a} - \int_\mathcal{V} g \ \nabla \mathbf{F} \ d^3 \mathbf{x} \ .
\]</span> Similar versions of integration by parts exist for the product of two scalar fields or two vector fields as well, both of which can be derived just as easily as the formula above.</p>
<p>We can define similar vector calculus operations for tensors as well, not just vectors. For example, if we have a rank-2 tensor <span class="math inline">\(\mathbf{T}\)</span> we can still imagine taking gradients <span class="math inline">\(\partial_k T_{ij}\)</span> to get a rank-3 tensor. By contracting the derivative with the tensor we get a different divergence for each index, <span class="math inline">\(\partial_i T_{ij}\)</span> and <span class="math inline">\(\partial_j T_{ij}\)</span>. Evidently the divergence of a rank-2 tensor gives a vector, not a scalar.</p>
<p>Strictly speaking we can’t speak of <em>the divergence</em> of a tensor since each index has its own divergence. We can though when the tensor is <em>symmetric</em>. If <span class="math inline">\(T_{ij} = T_{ji}\)</span> we can define a unique divergence operation by <span class="math display">\[
\nabla \cdot \mathbf{T} \equiv \partial_i T_{ij} = \partial_j T_{ij} \ .
\]</span></p>
<p>We could imagine taking the curl of a tensor as well. From index notation it’s clear that the curl of a rank-2 tensor will give another rank-2 tensor. We can even imagine defining tensor integrals as well in similar ways. In practice though we’ll only care about divergences and gradients of rank-2 tensors in this course, so we won’t go into any detail here.</p>
</section>
<section id="coordinate-systems" class="level3">
<h3 class="anchored" data-anchor-id="coordinate-systems">Coordinate Systems</h3>
<p>It will be frequently useful in electrodynamics to work in other coordinate systems. As with other areas of physics, the most important coordinate systems we work with are Cartesian, polar, cylindrical, and spherical coordinates. Cartesian coordinates are <em>rectangular</em>, which means their basis vectors don’t depend on position. They’re always constant. The remaining three coordinate systems, however, are <em>curvilinear</em>, meaning their basis vectors <em>do</em> depend on position. This means going back and forth between these coordinate systems can be cumbersome since additional scale factors get introduced. Below is a table that shows the relationship between these coordinate systems for various vector calculus expressions we’ll frequently use.</p>
<table class="table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Cartesian <span class="math inline">\((x,y,z)\)</span></th>
<th>Cylindrical <span class="math inline">\((\rho,\varphi,z)\)</span></th>
<th>Spherical <span class="math inline">\((r,\theta,\varphi)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Coordinates</strong></td>
<td><span class="math inline">\(\begin{align*} x&amp;=x \\ y&amp;=y \\ z&amp;=z \end{align*}\)</span></td>
<td><span class="math inline">\(\begin{align*} x&amp;=\rho\cos\varphi \\ y&amp;=\rho\sin\varphi \\ z&amp;=z \end{align*}\)</span></td>
<td><span class="math inline">\(\begin{align*} x&amp;=r\sin\theta\cos\varphi \\ y&amp;=r\sin\theta\sin\varphi \\ z&amp;=r\cos\theta \end{align*}\)</span></td>
</tr>
<tr class="even">
<td><strong>Basis Vectors</strong></td>
<td><span class="math inline">\(\begin{align*} \mathbf{e}_x&amp;=\mathbf{e}_x \\ \mathbf{e}_y&amp;=\mathbf{e}_y \\ \mathbf{e}_z&amp;=\mathbf{e}_z \end{align*}\)</span></td>
<td><span class="math inline">\(\begin{align*} \mathbf{e}_\rho &amp;= \cos\varphi \mathbf{e}_x + \sin\varphi \mathbf{e}_y \\ \mathbf{e}_\varphi &amp;= -\sin \varphi \mathbf{e}_x + \cos \varphi \mathbf{e}_y \\ \mathbf{e}_z&amp;=\mathbf{e}_z \end{align*}\)</span></td>
<td><span class="math inline">\(\begin{align*} \mathbf{e}_r &amp;= \sin\theta \cos\varphi \mathbf{e}_x + \sin\theta \sin\varphi \mathbf{e}_y + \cos\theta \mathbf{e}_z \\ \mathbf{e}_\theta &amp;= \cos\theta \cos\varphi \mathbf{e}_x + \cos\theta \sin\varphi \mathbf{e}_y - \sin\theta \mathbf{e}_z  \\ \mathbf{e}_\varphi &amp;= -\sin\varphi \mathbf{e}_x + \cos\varphi \mathbf{e}_y  \end{align*}\)</span></td>
</tr>
<tr class="odd">
<td><strong>Differential</strong></td>
<td><span class="math inline">\(d\mathbf{x} = dx \mathbf{e}_x + dy \mathbf{e}_y + dz \mathbf{e}_z\)</span></td>
<td><span class="math inline">\(d\mathbf{x} = d\rho \mathbf{e}_\rho + \rho d\varphi \mathbf{e}_\varphi + dz \mathbf{e}_z\)</span></td>
<td><span class="math inline">\(d\mathbf{x} = dr \mathbf{e}_r + r d\theta \mathbf{e}_\theta + r \sin \theta d\varphi \mathbf{e}_\varphi\)</span></td>
</tr>
<tr class="even">
<td><strong>Line Element</strong></td>
<td><span class="math inline">\(ds^2=dx^2 + dy^2 + dz^2\)</span></td>
<td><span class="math inline">\(ds^2=d\rho^2 + \rho^2 d\varphi^2 + dz^2\)</span></td>
<td><span class="math inline">\(ds^2=dr^2 + r^2 d\theta^2 + r^2 \sin^2 \theta d\varphi^2\)</span></td>
</tr>
<tr class="odd">
<td><strong>Volume Element</strong></td>
<td><span class="math inline">\(d^3 \mathbf{x} = dx dy dz\)</span></td>
<td><span class="math inline">\(d^3 \mathbf{x} = \rho d\rho d\varphi dz\)</span></td>
<td><span class="math inline">\(d^3 \mathbf{x} = r^2 \sin \theta dr d\theta d\varphi\)</span></td>
</tr>
<tr class="even">
<td><strong>Gradient</strong></td>
<td><span class="math inline">\(\nabla f = \partial_x f \mathbf{e}_x + \partial_y f \mathbf{e}_y + \partial_z f \mathbf{e}_z\)</span></td>
<td><span class="math inline">\(\nabla f = \partial_\rho f \mathbf{e}_\rho + \frac{1}{\rho} \partial_\varphi \mathbf{e}_\varphi + \partial_z f \mathbf{e}_z\)</span></td>
<td><span class="math inline">\(\nabla f = \partial_r f \mathbf{e}_r + \frac{1}{r} \partial_\theta f \mathbf{e}_\theta + \frac{1}{r \sin \theta} \partial_\varphi f \mathbf{e}_\varphi\)</span></td>
</tr>
<tr class="odd">
<td><strong>Divergence</strong></td>
<td><span class="math inline">\(\nabla \cdot \mathbf{F} = \partial_x F_x + \partial_y F_y + \partial_z F_z\)</span></td>
<td><span class="math inline">\(\nabla \cdot \mathbf{F} = \frac{1}{\rho} \partial_\rho(\rho F_\rho) + \frac{1}{\rho} \partial_\varphi F_\varphi + \partial_z F_z\)</span></td>
<td><span class="math inline">\(\nabla \cdot \mathbf{F} = \frac{1}{r^2} \partial_r (r^2 F_r) + \frac{1}{r \sin \theta} \partial_\theta (F_\theta \sin \theta) + \frac{1}{r \sin \theta} \partial_\varphi F_\varphi\)</span></td>
</tr>
<tr class="even">
<td><strong>Curl</strong></td>
<td><span class="math inline">\(\begin{align*}\nabla \times \mathbf{F} &amp;= \left( \partial_y F_z - \partial_z F_y \right) \mathbf{e}_x \\ &amp;+ \left( \partial_z F_x - \partial_x F_z \right) \mathbf{e}_y \\ &amp;+ \left( \partial_x F_y - \partial_y F_x \right) \mathbf{e}_z \end{align*}\)</span></td>
<td><span class="math inline">\(\begin{align*} \nabla \times \mathbf{F} &amp;= \left( \frac{1}{\rho} \partial_\varphi F_z - \partial_z F_\varphi \right) \mathbf{e}_\rho \\ &amp;+ \left( \partial_z F_\rho - \partial_\rho F_z \right) \mathbf{e}_\varphi \\ &amp;+ \frac{1}{\rho} \left( \partial_\rho (\rho F_\varphi) - \partial_\varphi F_\rho \right) \mathbf{e}_z \end{align*}\)</span></td>
<td><span class="math inline">\(\begin{align*} \nabla \times \mathbf{F} &amp;= \frac{1}{r \sin \theta} \left( \partial_\theta (F_\varphi \sin \theta) - \partial_\varphi F_\theta \right) \mathbf{e}_r \\ &amp;+ \frac{1}{r} \left( \frac{1}{\sin \theta} \partial_\varphi F_r - \partial_r (r F_\varphi) \right) \mathbf{e}_\theta \\ &amp;+ \frac{1}{r} \left( \partial_r (r F_\theta) - \partial_\theta F_r \right) \mathbf{e}_\varphi \end{align*}\)</span></td>
</tr>
<tr class="odd">
<td><strong>Laplacian</strong></td>
<td><span class="math inline">\(\nabla^2 f = \partial_x^2 f + \partial_y^2 f + \partial_z^2 f\)</span></td>
<td><span class="math inline">\(\nabla^2 f = \frac{1}{\rho} \partial_\rho \left( \rho \partial_\rho f \right) + \frac{1}{\rho^2} \partial_\varphi^2 f + \partial_z^2 f\)</span></td>
<td><span class="math inline">\(\nabla^2 f = \frac{1}{r^2} \partial_r^2 \left( r^2 \partial_r f \right) + \frac{1}{r^2 \sin \theta} \partial_\theta \left( \sin \theta \partial_\theta f \right) + \frac{1}{r^2 \sin^2 \theta} \partial_\varphi^2 f\)</span></td>
</tr>
</tbody>
</table>
</section>
<section id="fourier-analysis" class="level3">
<h3 class="anchored" data-anchor-id="fourier-analysis">Fourier Analysis</h3>
<p>We will at times find it convenient in this course to go back and forth between the time domain and the frequency domain. To express a continuous function of time as a function of frequency we can use the <em>Fourier transform</em>. For a sufficiently well-behaved time-dependent function <span class="math inline">\(f(t)\)</span>, we can define its Fourier transform <span class="math inline">\(f(\omega)\)</span> by <span class="math display">\[
f(\omega) \equiv \mathcal{F}[f(t)](\omega) \equiv \int_{-\infty}^\infty dt \ f(t) e^{-i\omega t} \ .
\]</span> The function <span class="math inline">\(f(\omega)\)</span>, which in general will be complex-valued, is thought of as a function of <em>frequency</em> <span class="math inline">\(\omega\)</span>. We can express the same thing using the <em>Fourier operator</em> <span class="math inline">\(\mathcal{F}\)</span>. Since the <span class="math inline">\(\mathcal{F}\)</span> is an integral transform it inherits many of the properties of the integral plus a few other convenient properties that are easy to prove from the definition. Here the <span class="math inline">\(\leftrightarrow\)</span> symbol means that right-hand side is the Fourier transform, or <em>Fourier dual</em>, of the left-hand side. That is, <span class="math inline">\(f(t) \leftrightarrow f(\omega)\)</span>, a very convenient simplification of notation.</p>
<ul>
<li>Linearity: <span class="math inline">\(\alpha f(t) + \beta g(t) \leftrightarrow \alpha f(\omega) + \beta g(\omega)\)</span>.</li>
<li>Time Scaling: <span class="math inline">\(f(\alpha t) \leftrightarrow \frac{1}{|\alpha|} f\big(\frac{\omega}{\alpha}\big)\)</span>.</li>
<li>Time Shifting: <span class="math inline">\(f(t-t_0) \leftrightarrow e^{i\omega t_0} f\big(\omega)\)</span>.</li>
<li>Time Reversal: <span class="math inline">\(f(-t) \leftrightarrow f(-\omega)\)</span>.</li>
<li>Complex Conjugation: <span class="math inline">\(f^*(t) \leftrightarrow f^*(\omega)\)</span>.</li>
<li>Differentiation: <span class="math inline">\(\frac{d}{dt} f(t) \leftrightarrow i\omega f(\omega)\)</span>.</li>
<li>Convolution: <span class="math inline">\(f \ast g \leftrightarrow f(\omega) g(\omega)\)</span>.</li>
</ul>
<p>The last operation is a very common integral transform known as <em>convolution</em>, defined by <span class="math display">\[
(f \ast g)(t) \equiv \int_{-\infty}^\infty dt' \ f(t') g(t-t') \ .
\]</span> The convolution operation shows up surprisingly often, particularly in the theory of Green’s functions, which we’ll work with later in this course. Convolutions act like a form of function multiplication in that the operation is both commutative and associative.</p>
<hr>
<p><strong>Example: Fourier Transform of a Gaussian</strong></p>
<p>As an example of using these Fourier transform properties let’s calculate the Fourier transform of the Gaussian probability density <span class="math display">\[
f(t) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\bigg(-\frac{1}{2} \frac{(t-t_0)^2}{\sigma^2}\bigg)
\]</span> First, using the linear, time scaling, and shifting properties together we must have <span class="math display">\[
f(\omega) = \frac{e^{i\omega t_0}}{\sqrt{2\pi\sigma^2}} \mathcal{F}\bigg[\exp\bigg(-\frac{1}{2} \frac{t^2}{\sigma^2}\bigg)\bigg] = \frac{1}{\pi} e^{i\omega t_0} \mathcal{F}\big[e^{-t^2}\big](\sqrt{2}\sigma\omega) \ .
\]</span> All that remains then is to find the transform of <span class="math inline">\(g(t) \equiv e^{-t^2}\)</span>. We can do this by completing the square and using the translational invariance of the Gaussian integral to get $$ <span class="math display">\[\begin{align*}
g(\omega) &amp;= \int_{-\infty}^\infty dt \ g(\omega) e^{-i\omega t} \\
&amp;= \int_{-\infty}^\infty dt \ e^{-t^2} e^{-i\omega t} \\
&amp;= \int_{-\infty}^\infty dt \ \exp(-\bigg(t-\frac{i\omega}{2}\bigg)^2) \\
&amp;= \sqrt{\pi} \exp(-\frac{\omega^2}{4}) \ .

\end{align*}\]</span> <span class="math display">\[
Thus, putting it all together, we have
\]</span> () = (it_0 - ) &nbsp;. $$ Evidently then, the Fourier transform of a Gaussian is another Gaussian. In a sense, the Gaussian is the unique class of functions whose Fourier transforms are also of the same class.</p>
<hr>
<p>An important fact about the Fourier transform is that it’s <em>invertible</em>, meaning we can define an <em>inverse Fourier transform operator</em> <span class="math inline">\(\mathcal{F}^{-1}\)</span> such that <span class="math inline">\(\mathcal{F} \mathcal{F}^{-1} = 1\)</span>. The inverse Fourier transform of <span class="math inline">\(f(t)\)</span> turns out to be given by the dual integral <span class="math display">\[
f(t) = \mathcal{F}^{-1}[f(\omega)](t) = \int_{-\infty}^\infty \frac{d\omega}{2\pi} \ f(\omega) e^{i\omega t} \ .
\]</span> Notice that unlike the Fourier transform, its inverse transform comes has a rescaled measure of <span class="math inline">\(\frac{d\omega}{2\pi}\)</span>. There’s nothing deep about this fact. It’s just a relic of the way we defined the Fourier transform above. We could define it in ways that remove the <span class="math inline">\(2\pi\)</span> as well. In fact, there are many different conventions used to define the Fourier transform, which can make it a bit annoying to look up these formulas in tables.</p>
<p>Evidently, to for the Fourier transform to be invertible we must have that <span class="math inline">\(f(t) = \mathcal{F}^{-1} \mathcal{F} [f(t')](t)\)</span>. Let’s see what this says by manipulating the formula a little bit. We have <span class="math display">\[
\begin{align*}
f(t) &amp;= \mathcal{F}^{-1} \mathcal{F} [f(t')](t) \\
&amp;= \int_{-\infty}^\infty \frac{d\omega}{2\pi} \ \int_{-\infty}^\infty dt' \ f(t') e^{-i\omega t'} e^{i\omega t} \\
&amp;= \int_{-\infty}^\infty dt' \ f(t') \int_{-\infty}^\infty \frac{d\omega}{2\pi} \ e^{i\omega(t-t')} \ .
\end{align*}
\]</span> Evidently, the inner integral acts as some kind of kernel function that picks out the value <span class="math inline">\(f(t)\)</span> from the integrand function <span class="math inline">\(f(t')\)</span>. Let’s give this kernel function a name, the <em>Dirac delta function</em>, <span class="math display">\[
\delta(t-t') \equiv \int_{-\infty}^\infty \frac{d\omega}{2\pi} \ e^{i\omega(t-t')} \ .
\]</span> This function evidently then has the defining property that <span class="math display">\[
\boxed{
f(t) = \int_{-\infty}^\infty dt' \ f(t') \delta(t-t')
}\ .
\]</span> In a sense, the delta function can be thought of as a sort of density function for a single point. When <span class="math inline">\(t \neq t'\)</span> the delta function must be zero. But to be a proper density this means that when <span class="math inline">\(t=t'\)</span>​ the delta function must be infinitely high so its area under the curve remains constant.</p>
<p>Notice that based on this definition the delta function must have units to cancel out the units of the differential <span class="math inline">\(dt'\)</span>. If <span class="math inline">\(dt'\)</span> has units of time, evidently <span class="math inline">\(\delta(t-t')\)</span> must have units of <em>frequency</em>.</p>
<p>In one sense, the delta function is just the Fourier transform of the constant <span class="math inline">\(f(t)=1\)</span>. In a more visual sense it’s an infinite spike. Indeed, we can imagine defining the delta function differently as a limiting case of a normalized Gaussian whose variance <span class="math inline">\(\sigma^2\)</span> goes to zero, <span class="math display">\[
\delta(t-t') = \lim_{\sigma \rightarrow 0} \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(t-t')^2}{2\sigma^2}} \ .
\]</span> This can be illustrated in the figure below.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../../Library/Application Support/typora-user-images/image-20240309160905585.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="300"></p>
</figure>
</div>
<p>Strictly speaking the delta function isn’t a proper function at all since it’s undefined when <span class="math inline">\(t=t'\)</span>​. It’s a so-called <em>generalized function</em>, meaning it’s a function that has meaning only when inside an integral. As physicists rarely do, we won’t really bother with these mathematical details in this course. Whatever it is, the delta function is a convenient mathematical object for us.</p>
<p>One fact worth remembering and easy to prove is how the delta function transforms under a time rescaling, <span class="math display">\[
\delta(at) = \frac{1}{|a|} \delta(t) \ .
\]</span> Another useful fact to remember is that the delta function is the identity of the convolution operation. That is, <span class="math inline">\(f \ast \delta = f\)</span>. This can easily be seen from the definition, which is just a special convolution operation.</p>
<p>Thus far we’ve talked about the Fourier transform in time. We can define a Fourier transform for a scalar field <span class="math inline">\(f(\mathbf{x})\)</span> as well by multiplying the transform of each component together. For a well-behaved scalar field <span class="math inline">\(f(\mathbf{x})\)</span>, we have <span class="math display">\[
f(\mathbf{k}) \equiv \mathcal{F}[f(\mathbf{x})](\mathbf{k}) \equiv \int_{\mathbb{R}^3} d^3 \mathbf{x} \ f(\mathbf{x}) e^{i \mathbf{k} \cdot \mathbf{x}} \ .
\]</span> Here <span class="math inline">\(\mathbf{k}\)</span> is the <em>wavevector</em>, a proper vector of three components. Note the subtle change in sign in this definition of the Fourier transform. This is a physics convention that makes the application of the Fourier transform easier to scalar fields <span class="math inline">\(f(\mathbf{x},t)\)</span>​ in space and time.</p>
<p>The inverse Fourier transform for a scalar field is defined in a similar way, by <span class="math display">\[
f(\mathbf{x}) = \mathcal{F}^{-1}[f(\mathbf{k})](\mathbf{x}) = \int_{\mathbb{R}^3} \frac{d^3 \mathbf{x}}{(2\pi)^3} \ f(\mathbf{x}) e^{-i \mathbf{k} \cdot \mathbf{x}} \ .
\]</span> The scalar field version of the Fourier transform satisfies essentially the same properties as the time-dependent version, just appropriately modified for use with vectors. The delta function extends to fields as well. We simply define the field version of the delta function as the product of its components. In Cartesian coordinates, this says <span class="math display">\[
\delta(\mathbf{x}-\mathbf{x}') \equiv \delta(x-x') \delta(y-y') \delta(z-z') \ .
\]</span> This definition evidently means <span class="math inline">\(\delta(\mathbf{x}-\mathbf{x}')\)</span> must have units of inverse volume.</p>
<p>In the case of fields, the delta function <span class="math inline">\(\delta(\mathbf{x}-\mathbf{x}')\)</span> picks out points in 3-dimensional space, activating only when <span class="math inline">\(\mathbf{x}=\mathbf{x}'\)</span>. It’s worth noting that since the delta function is really a density rather than an ordinary function, under a change of coordinates it transforms as a density, meaning we have to include the Jacobian factor in the definition. For example, in a change of coordinates of the form <span class="math inline">\(\mathbf{u}=\mathbf{u}(\mathbf{x})\)</span>, we have <span class="math display">\[
\delta(\mathbf{x}-\mathbf{x}') = \frac{1}{|\det \mathbf{J}|} \delta(u-u') \delta(v-v') \delta(w-w') \ .
\]</span> Here <span class="math inline">\(\mathbf{J} = \frac{d\mathbf{u}}{d\mathbf{x}}\)</span> is the Jacobian of the transformation from <span class="math inline">\(u\)</span>-coordinates to Cartesian <span class="math inline">\(x\)</span>​​-coordinates.</p>
<hr>
<p><strong>Example: Divergence of Inverse Square Fields</strong></p>
<p>As an exercise in much of what we’ve learned so far, let’s calculate the divergence of the vector field <span class="math inline">\(\mathbf{F}(\mathbf{x}) = \frac{\mathbf{e}_r}{r^2}\)</span>. We could proceed in one of two ways. One way would be to use Cartesian coordinates and index notation to churn it out the hard way. The other way would be to recognize this scalar field is spherically symmetric, so we should work in spherical coordinates. Adopting the second approach since it’s easier, we have <span class="math display">\[
\nabla \cdot \mathbf{F} = \frac{1}{r} \frac{\partial}{\partial r} \bigg(r^2 \frac{1}{r^2}\bigg) \ .
\]</span> It’s tempting to cancel out the factors of <span class="math inline">\(r^2\)</span> and conclude <span class="math inline">\(\nabla \cdot \mathbf{F} = 0\)</span>, but we have to be a little more careful than that. To see why let’s use the divergence theorem to express the same problem as an integral over some closed volume. We can pick any volume we like. To make things easy let’s suppose we’re integrating inside a sphere of radius <span class="math inline">\(R\)</span>. Then we have <span class="math display">\[
\int_S \mathbf{F} \cdot d\mathbf{a} = \int_\mathcal{V} \nabla \cdot \mathbf{F} \ d^3\mathbf{x} \ .
\]</span> Since <span class="math inline">\(\mathbf{F}\)</span> is spherically symmetric and we’re integrating over a sphere, we can write <span class="math inline">\(\mathbf{F} \cdot d\mathbf{a} = |\mathbf{F}| da\)</span> and integrate over the surface area of the sphere to get <span class="math display">\[
\int_S \mathbf{F} \cdot d\mathbf{a} = \int r^2 \bigg(\frac{1}{r^2}\bigg) \ d\Omega = 4\pi \ .
\]</span> This is in fact true for <em>any</em> surface of arbitrary radius so long as it contains the origin. This means the divergence of <span class="math inline">\(\mathbf{F}\)</span> can’t be zero, otherwise the surface integral would be zero. Moreover, it means the only contribution from the divergence can come at the point <span class="math inline">\(r=0\)</span> where the function blows up. We thus conclude that there must be a delta function multiplying <span class="math inline">\(4\pi\)</span> whose value is non-zero only when <span class="math inline">\(r=0\)</span>. That is, we have <span class="math display">\[
\nabla \cdot \bigg(\frac{\mathbf{e}_r}{r^2}\bigg) = 4\pi \delta(\mathbf{x}) \ .
\]</span> Note that using the spherical coordinate version of the gradient we have <span class="math inline">\(\nabla \frac{1}{r} = -\frac{\mathbf{e}_r}{r^2}\)</span>. We’ve thus shown another useful fact, that <span class="math display">\[
\nabla^2 \bigg(\frac{1}{r}\bigg) = -4\pi \delta(\mathbf{x}) \ .
\]</span> We will make good use of these two formulas in the rest of this course.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation column-page-right">
  <div class="nav-page nav-page-previous">
      <a href="../classical-mechanics/continuum-mechanics.html" class="pagination-link" aria-label="Continuum Mechanics">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">Continuum Mechanics</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../electrodynamics/electrostatics.html" class="pagination-link" aria-label="Electrostatics">
        <span class="nav-page-text"><span class="chapter-title">Electrostatics</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>