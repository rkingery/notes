<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.551">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Personal Notes - Preliminaries</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../electrodynamics/electrostatics.html" rel="next">
<link href="../classical-mechanics/continuum-mechanics.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../electrodynamics/preliminaries.html">Electromagnetism</a></li><li class="breadcrumb-item"><a href="../electrodynamics/preliminaries.html"><span class="chapter-title">Preliminaries</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Personal Notes</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Classical Mechanics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../classical-mechanics/newtonian-mechanics.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Newtonian Mechanics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../classical-mechanics/simple-systems.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Simple Systems</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../classical-mechanics/reference-frames.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Reference Frames</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../classical-mechanics/lagrangian-mechanics.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Lagrangian Mechanics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../classical-mechanics/hamiltonian-mechanics.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Hamiltonian Mechanics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../classical-mechanics/central-forces.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Central Forces</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../classical-mechanics/coupled-oscillations.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Coupled Oscillations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../classical-mechanics/rigid-bodies.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Rigid Bodies</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../classical-mechanics/canonical-transformations.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Canonical Transformations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../classical-mechanics/integrability-and-chaos.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Integrability and Chaos</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../classical-mechanics/continuum-mechanics.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Continuum Mechanics</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Electromagnetism</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../electrodynamics/preliminaries.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Preliminaries</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../electrodynamics/electrostatics.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Electrostatics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../electrodynamics/bvps-1.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Boundary Value Problems I</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../electrodynamics/bvps-2.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Boundary Value Problems II</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../electrodynamics/multipole-expansion.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Multipole Expansion</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../electrodynamics/magnetostatics.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Magnetostatics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../electrodynamics/maxwell-equations.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Maxwell’s Equations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../electrodynamics/orthogonal-functions.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Appendix I: Orthogonal Functions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../electrodynamics/complex-analysis.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Appendix II: Complex Analysis</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Circuit Analysis</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../circuits/circuit-abstraction.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">The Lumped Circuit Abstraction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../circuits/analysis.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Analyzing Circuits</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../circuits/nonlinear-methods.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Nonlinear Methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../circuits/digital-abstraction.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">The Digital Abstraction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../circuits/amplifiers.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Amplifiers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../circuits/first-order-systems.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">First-Order Systems</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../circuits/second-order-systems.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Second-Order Systems</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../circuits/ac-analysis.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">AC Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../circuits/op-amps.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Operational Amplifiers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../circuits/energy-power.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Energy and Power</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Quantum Mechanics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../quantum-mechanics/identical-particles.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Identical Particles</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../quantum-mechanics/second-quantization.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Second Quantization</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">Statistical Mechanics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../statistical-mechanics/thermodynamics.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Thermodynamics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../statistical-mechanics/probability.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Probability</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../statistical-mechanics/kinetic-theory.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Kinetic Theory</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../statistical-mechanics/classical-stat-mech.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Classical Statistical Mechanics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../statistical-mechanics/classical-gases.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Classical Gases</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../statistical-mechanics/quantum-stat-mech.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Quantum Statistical Mechanics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../statistical-mechanics/quantum-gases.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Quantum Gases</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#units" id="toc-units" class="nav-link active" data-scroll-target="#units">Units</a></li>
  <li><a href="#vectors" id="toc-vectors" class="nav-link" data-scroll-target="#vectors">Vectors</a></li>
  <li><a href="#vector-calculus" id="toc-vector-calculus" class="nav-link" data-scroll-target="#vector-calculus">Vector Calculus</a>
  <ul class="collapse">
  <li><a href="#differential-vector-calculus" id="toc-differential-vector-calculus" class="nav-link" data-scroll-target="#differential-vector-calculus">Differential Vector Calculus</a></li>
  <li><a href="#integral-vector-calculus" id="toc-integral-vector-calculus" class="nav-link" data-scroll-target="#integral-vector-calculus">Integral Vector Calculus</a></li>
  </ul></li>
  <li><a href="#tensors" id="toc-tensors" class="nav-link" data-scroll-target="#tensors">Tensors</a></li>
  <li><a href="#coordinate-systems" id="toc-coordinate-systems" class="nav-link" data-scroll-target="#coordinate-systems">Coordinate Systems</a></li>
  <li><a href="#complex-variables" id="toc-complex-variables" class="nav-link" data-scroll-target="#complex-variables">Complex Variables</a></li>
  <li><a href="#delta-function" id="toc-delta-function" class="nav-link" data-scroll-target="#delta-function">Delta Function</a></li>
  <li><a href="#temporary" id="toc-temporary" class="nav-link" data-scroll-target="#temporary">TEMPORARY</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content column-page-right" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../electrodynamics/preliminaries.html">Electromagnetism</a></li><li class="breadcrumb-item"><a href="../electrodynamics/preliminaries.html"><span class="chapter-title">Preliminaries</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-title">Preliminaries</span></h1>
</div>



<div class="quarto-title-meta column-page-right">

    
  
    
  </div>
  


</header>


<p>In this course we’ll study the physical phenomena known as <em>electromagnetism</em>. At one level, electromagnetism can be thought of as the study of two types of closely-related forces, the <em>electrical force</em>, and the <em>magnetic force</em>. Originally, the electrical force was proposed to explain the fact that objects have a property known as <em>electric charge</em> which causes certain objects to repel each other and other objects to attract each other according to a particular force law, <em>Coulomb’s Law</em>.</p>
<p>The magnetic force arose from two different phenomena that later had to be unified. The first was the study of <em>ferromagnetic materials</em>, which were materials that tended to point in a particular direction, for example the needle of a compass which tends to point northward. The second was the behavior of <em>currents</em>, or charges moving through wires. Michael Faraday observed that a current moving through two wires causes them to attract or repel each other depending on the directions of the currents. This led to another force law, known as the <em>Biot-Savart Law</em>. It was later found that ferromagnets can also be thought of as tiny currents inside a material, thus unifying the two types of magnetism.</p>
<p>The fact that magnetism arises from moving electric charges also provided a way to unify the dynamics of electricity and magnetism. A few years later it was discovered that electromagnetism explains a completely different phenomenon as well, <em>light</em>. Light was found to be a form of electromagnetic radiation at a particular range of frequencies. The unification of these three phenomena (electricity, magnetism, and optics) into one theory was finally done by Maxwell with his well-known field equations. These equations are believed to fully describe all electromagnetic phenomena at the macroscopic level.</p>
<p>It was eventually realized with the advent of quantum mechanics that even Maxwell’s Equations needed to be modified at the microscopic level to account for quantum effects, like the discoveries that light is in fact made of photons and most materials are made of other fundamental particles like electrons and quarks. This more advanced topic is known as <em>quantum electrodynamics</em>.</p>
<p>In this course we’ll study the theory of <em>classical electrodynamics</em>. We will conver the subject at the graduate level, meaning we will go give a more advanced treatment to many subjects in the field than is perhaps typical in most electrodynamics texts.</p>
<section id="units" class="level2">
<h2 class="anchored" data-anchor-id="units">Units</h2>
<p>We’ll start by saying a word about <em>units</em>. Typically in physics we need not think much about units. Abstractly the formulas look the same, whether the quantities involved are measured in meters, feet, or lightyears. However, electromagnetism has the unusual quirk that different unit systems lead to slightly different looking formulas. The reasons for this are largely historical, and very little if any physics is involved in the way these formulas look in different systems of units. An important implication of this frustrating quirk is that we have to be much more careful at the outset to specify which units we’re using since it will affect the formulas involved in derivations and calculations. To start, we’ll very briefly look at several different systems of units before committing to one for the rest of the course.</p>
<p>The foundation of systems of units in electromagnetism are forces on and due to the presence of charges and currents. It was found early on that there are two types of electric charge, positive and negative. Two like charges repel, while two opposite charges attract. The force between those charges also depends on the distance between them in a specific way. Suppose two charges <span class="math inline">\(q_1\)</span> and <span class="math inline">\(q_2\)</span> are separated from each other by a distance <span class="math inline">\(r\)</span>. The magnitude of the force felt by the two charges is given by an inverse square law known as <em>Coulomb’s Law</em>, <span class="math display">\[
F = k_e \frac{q_1 q_2}{r^2} \ .
\]</span> The proportionality constant <span class="math inline">\(k_e\)</span> is known as the <em>electric constant</em> whose dimension and value depends on choice of units. The quantity <span class="math inline">\(k_e q_1 q_2\)</span> can be measured in the lab by measuring the strength of the force and the distance between the two charges.</p>
<p>A little while later people figured out how to run moving charges, or <em>currents</em>, through wires. In studying the behavior of current flowing through two nearby parallel wires, it was found that the wires repel each other when the currents move in the same direction, and repel each other when the currents move in the opposite direction. The force also seemed to depend on the distance between the wires. Suppose two parallel wires a distance <span class="math inline">\(r\)</span> apart are carrying currents <span class="math inline">\(I_1\)</span> and <span class="math inline">\(I_2\)</span>. Suppose each wire has the same fixed length <span class="math inline">\(\ell\)</span>. Then the force experienced by the two wires due to the currents is given by <em>Ampere’s Force Law</em>,</p>
<p><span class="math display">\[
\frac{dF}{d\ell} = 2k_m \frac{I_1 I_2}{r} \ .
\]</span> The proportionality constant <span class="math inline">\(k_m\)</span> is yet another constant that depends on units. The quantity <span class="math inline">\(k_m I_1 I_2\)</span> can be measured in the lab by measuring the strength of the force per unit length and the distance of separation between the two wires.</p>
<p>It was further realized later that these two phenomena can be generalized using the notion of <em>fields</em>. The force felt by a charge due to other charges can also be thought of as a force on a charge felt by an <em>electric field</em> <span class="math inline">\(\mathbf{E}(\mathbf{x},t)\)</span> that sums of the effects of all the other background charges. The force felt on a charge <span class="math inline">\(q\)</span> is evidently proportional to this electric field, <span class="math inline">\(\mathbf{F} \propto q \mathbf{E}\)</span>. A similar description can be made for the forces felt on a moving charge, i.e.&nbsp;a current, due to the presence of a <em>magnetic field</em> <span class="math inline">\(\mathbf{B}(\mathbf{x},t)\)</span> that sums up the effects of all other background currents. This force felt on a moving charge <span class="math inline">\(q\)</span> is proportional to both its velocity <span class="math inline">\(\mathbf{v}\)</span> and the magnetic field, with <span class="math inline">\(\mathbf{F} \propto q\mathbf{v} \times \mathbf{B}\)</span>. If we try to sum these two forces together to get the combined force on the moving charge we have to establish how the electric and magnetic fields dimensionally relate to each other. This combined force law is known as the <em>Lorentz Force Law</em>, given generally by <span class="math display">\[
\mathbf{F} = q \bigg(\mathbf{E} + \frac{\mathbf{v}}{\alpha} \times \mathbf{B}\bigg) \ .
\]</span> Here we introduce a new constant <span class="math inline">\(\alpha\)</span> to control the dimensional relationship between <span class="math inline">\(\mathbf{E}\)</span> and <span class="math inline">\(\mathbf{B}\)</span>. Initially this was ignored and <span class="math inline">\(\alpha=1\)</span> was chosen without people really thinking about it. But later on it was realized that the two fields should actually be thought of as essentially the same object and should thus have the same dimensions. For this to be true, <span class="math inline">\(\alpha\)</span> must be chosen to be some constant with dimensions of velocity.</p>
<p>The three parameters <span class="math inline">\(k_e, k_m, \alpha\)</span> are not completely independent though. Most importantly, dimensional analysis and experiment force <span class="math inline">\(k_e\)</span> and <span class="math inline">\(k_m\)</span> to be related in a very specific way, namely by <span class="math display">\[
c^2 = \frac{k_e}{k_m} \ ,
\]</span> where <span class="math inline">\(c\)</span> is the <em>speed of light</em> in vacuum, a fundamental constant measured to be <span class="math inline">\(c \approx 3 \cdot 10^{10} \ \frac{\text{cm}}{\text{s}}\)</span>. Several experiments already concluded that <span class="math inline">\(c\)</span> was indeed a universal constant with no dependence on choice of reference frame. This ratio evidently thus gives us a natural velocity scale, which coincidentally is what we’d need to fix <span class="math inline">\(\alpha\)</span> to make <span class="math inline">\(\mathbf{E}\)</span> and <span class="math inline">\(\mathbf{B}\)</span> to have the same units.</p>
<p>In the early days of electromagnetism the centimeter-gram-second or <em>CGS</em> system was already being widely used to measure mechanical quantities like length, mass, time, force, and energy. The unit of force was called the <em>dyne</em>, which comes out to <span class="math inline">\(1 \ \text{dyne} = 10^{-5} \ \text{N}\)</span>, while the unit of energy was called the <em>erg</em>, which comes out to <span class="math inline">\(1 \ \text{erg} = 10^{-7} \ \text{J}\)</span>. When electromagnetism came along it was realized these mechanical units needed to somehow be extended to cover electromagnetic phenomena as well, but that there were different all self consistent ways this could be done based on how <span class="math inline">\(k_e, k_m, \alpha\)</span> were specified.</p>
<p>Early on two unit systems arose to cover electromagnetism, one being used to measure electric quantities, and a completely different one used to measure magnetic quantities. The early system of units for electricity was called <em>electrostatic units</em> or the <em>ESU</em> system. This system defined <span class="math inline">\(k_e\equiv\alpha\equiv1\)</span>, which then forced <span class="math inline">\(k_m \equiv \frac{1}{c^2}\)</span>. This defined a natural unit of charge, later called the <em>electrostatic unit</em> or <em>esu</em>, with <span class="math inline">\(1 \ \text{esu} \approx 3.3 \cdot 10^{-10} \ \text{C}\)</span>. An analogous system arose to study magnetism, called <em>electromagnetic units</em> or the <em>EMU</em> system. This system defined <span class="math inline">\(k_m \equiv \alpha \equiv 1\)</span>, which then forced <span class="math inline">\(k_e = c^2\)</span>. This defined a natural unit of current, later called the <em>absolute amp</em> or <em>abamp</em>, with <span class="math inline">\(1 \ \text{abamp} = 10 \ \text{A}\)</span> exactly.</p>
<p>It was found to be cumbersome to go back and forth between the two subjects since one had to change units to compare results. It was also eventually realized that having the electric and magnetic fields be different dimensions didn’t make sense, as Einstein showed the two fields were really just the same field expressed in different reference frames. The two unit systems were then combined into yet a third system called the <em>Gaussian system</em>. The Gaussian system also uses CGS mechanical units, but takes <span class="math display">\[
k_e \equiv 1 \quad , \quad k_m \equiv \frac{1}{c^2} \quad , \quad \alpha \equiv c \ .
\]</span> This system had the benefit that the unit of charge was still the esu, but now the electric and magnetic fields have the same units. The unit of current is no longer the abamp, but instead the esu per second. The Gaussian system became popular among physicists, especially among theorists due to the fact that electricity and magnetism were treated on the same footing.</p>
<p>However, things played out differently on the engineering side. While physicists were studying electromagnetism in the lab, engineers were starting to use these ideas to build practical things like wires, motors, transformers, circuits, and radios. Engineers at the time didn’t like the fact that when that CGS units were poorly scaled to measure everyday things like the current through a telegraph wire or the voltage across a resistor. They instead chose to use a different system based on the meter, kilogram, and second, called the <em>MKS</em> system. The abamp was seen as too big for electrical applications of the time, so they defined a smaller unit of current called the <em>amp</em> or <em>Ampere</em>, defined by <span class="math inline">\(1 \ \text{A} \equiv 0.1 \ \text{abamp}\)</span>.</p>
<p>Later on, MKS units were extended to the rest of electromagnetism, but in a kind of quirky way. It was decided to define <span class="math display">\[
k_e \equiv \frac{1}{4\pi\varepsilon_0} \quad , \quad k_m \equiv \frac{\mu_0}{2\pi} \quad , \quad \alpha \equiv 1 \ .
\]</span> This odd definition was chosen out of the prevelant belief at the time that electromagnetic phenomena permuated in a fluid known as the <em>ether</em>, which they believed had a natural permittivity and permeability like any other material. This idea was later invalided through experiments, but the notation persists unfortunately. The division by <span class="math inline">\(4\pi\)</span> was arbitrary, done to <em>rationalize</em> out any factors of <span class="math inline">\(\pi\)</span> from Maxwell’s equations. As with the ESU and EMU systems, the electric and magnetic fields be of the same units wasn’t seen as an imperative, so no scaling by the speed of light was done either.</p>
<p>The constants <span class="math inline">\(\varepsilon_0\)</span> and <span class="math inline">\(\mu_0\)</span> were chosen as the more fundamental constants due to a misbelief that the vacuum was made of an electromagnetic fluid known as the <em>ether</em>, which was later falsified by experiment. These constants were tuned in the MKSA system specifically so that unit of current would come out to be exactly a tenth of an abamp. For this to work out consistently, they defined <span class="math display">\[
\mu_0 \equiv 4\pi \cdot 10^{-7} \ \frac{\text{N}}{\text{A}^2} \quad , \quad \varepsilon_0 \equiv \frac{10^7}{4\pi c^2} \approx 8.84 \cdot 10^{-14} \ \frac{\text{A}^2 \ \text{s}^4}{\text{kg} \ \text{m}^3} \ .
\]</span></p>
<p>This extended MKS system adds a fourth independent unit, the <em>Ampere</em>. All other electromagnetic quantities are then naturally defined in terms of the values of the meter, kilogram, second, and the Ampere. It’s this system, sometimes called the <em>MKSA</em> system, that later become the <em>SI system</em> used widely today in science and engineering.</p>
<p>On top of all these systems yet another system of units for electromagnetism was defined that closely relates to the Gaussian system. This system of units is called the <em>Heaviside-Lorentz</em> system. It also uses the CGS system and takes <span class="math inline">\(\alpha=c\)</span>, but it follows the MKSA system in choosing to rationalize out the factors of <span class="math inline">\(4\pi\)</span> from Maxwell’s equations. It thus chooses <span class="math display">\[
k_e \equiv \frac{1}{4\pi} \quad , \quad k_m \equiv \frac{1}{4\pi c^2} \quad , \quad \alpha \equiv c \ .
\]</span> As with the Gaussian system, in the Heaviside-Lorentz the electric and magnetic fields again have the same units. The only real difference is that the measured units change by a factor of <span class="math inline">\(4\pi\)</span>, and the factors of <span class="math inline">\(4\pi\)</span> are removed from Maxwell’s equations.</p>
<p>Nowadays, the ESU and EMU systems are rarely if ever used. The SI system is of course widely used, particularly among experimentalists and engineers, as well as in essentially all modern undergraduate electromagnetism textbooks. The Heaviside-Lorentz system is favored by the particle physics community, perhaps because they often set <span class="math inline">\(c=1\)</span>, which makes the formulas look similar to those in the SI system. The Gaussian system remains popular particularly among theoretical physicists due to its symmetric treatment of the electric and magnetic fields and its use of a single constant in formulas, the speed of light <span class="math inline">\(c\)</span>.</p>
<p>While each choice of units has its benefits depending on the field of study and the application, in this course we will stick primarily with the <em>Gaussian</em> system of units, which is well-suited to a theoretical study of electromagnetism. To go back and forth between Gaussian and SI units in various formulas, a useful trick that often works (but not always) is to make the identification <span class="math display">\[
\varepsilon_0 \leftrightarrow \frac{1}{4\pi} \quad , \quad \mu_0 \leftrightarrow \frac{4\pi}{c} \ .
\]</span></p>
<p>Below is a table of various electromagnetism formulas expressed in the three unit systems still in widespread use today. We’ll define or derive all of these formulas in more details in later lessons.</p>
<table class="table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Gaussian</th>
<th>Heaviside-Lorentz</th>
<th>SI</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Electric Field</strong></td>
<td><span class="math inline">\(\mathbf{E} = -\nabla \Phi + \frac{1}{c}\frac{\partial \mathbf{A}}{\partial t}\)</span></td>
<td><span class="math inline">\(\mathbf{E} = -\nabla \Phi + \frac{1}{c}\frac{\partial \mathbf{A}}{\partial t}\)</span></td>
<td><span class="math inline">\(\mathbf{E} = -\nabla \Phi + \frac{\partial \mathbf{A}}{\partial t}\)</span></td>
</tr>
<tr class="even">
<td><strong>Magnetic Field</strong></td>
<td><span class="math inline">\(\mathbf{B} = \nabla \times \mathbf{A}\)</span></td>
<td><span class="math inline">\(\mathbf{B} = \nabla \times \mathbf{A}\)</span></td>
<td><span class="math inline">\(\mathbf{B} = \nabla \times \mathbf{A}\)</span></td>
</tr>
<tr class="odd">
<td><strong>Coulomb’s Law</strong></td>
<td><span class="math inline">\(\mathbf{E} = \frac{q}{r^2} \mathbf{e}_r\)</span></td>
<td><span class="math inline">\(\mathbf{E} = \frac{1}{4\pi}\frac{q}{r^2} \mathbf{e}_r\)</span></td>
<td><span class="math inline">\(\mathbf{E} = \frac{1}{4\pi\varepsilon_0}\frac{q}{r^2} \mathbf{e}_r\)</span></td>
</tr>
<tr class="even">
<td><strong>Biot-Savart Law</strong></td>
<td><span class="math inline">\(d\mathbf{B} = \frac{I}{c} \frac{d\boldsymbol{\ell} \times \mathbf{e}_r}{r^2}\)</span></td>
<td><span class="math inline">\(d\mathbf{B} = \frac{I}{4\pi c} \frac{d\boldsymbol{\ell} \times \mathbf{e}_r}{r^2}\)</span></td>
<td><span class="math inline">\(d\mathbf{B} = \frac{\mu_0 I}{4\pi} \frac{d\boldsymbol{\ell} \times \mathbf{e}_r}{r^2}\)</span></td>
</tr>
<tr class="odd">
<td><strong>Lorentz Force Law</strong></td>
<td><span class="math inline">\(\mathbf{F} = q\mathbf{E} + q\frac{\mathbf{v}}{c} \times \mathbf{B}\)</span></td>
<td><span class="math inline">\(\mathbf{F} = q\mathbf{E} + q\frac{\mathbf{v}}{c} \times \mathbf{B}\)</span></td>
<td><span class="math inline">\(\mathbf{F} = q\mathbf{E} + q\mathbf{v} \times \mathbf{B}\)</span></td>
</tr>
<tr class="even">
<td><strong>Displacement Field</strong></td>
<td><span class="math inline">\(\mathbf{D} = \mathbf{E} + 4\pi \mathbf{P}\)</span></td>
<td><span class="math inline">\(\mathbf{D} = \mathbf{E} + \mathbf{P}\)</span></td>
<td><span class="math inline">\(\mathbf{D} = \varepsilon_0 \mathbf{E} + \mathbf{P}\)</span></td>
</tr>
<tr class="odd">
<td><strong>Magnetizing Field</strong></td>
<td><span class="math inline">\(\mathbf{H} = \mathbf{B} - 4\pi \mathbf{M}\)</span></td>
<td><span class="math inline">\(\mathbf{H} = \mathbf{B} - \mathbf{M}\)</span></td>
<td><span class="math inline">\(\mathbf{H} = \frac{1}{\mu_0}\mathbf{B} - \mathbf{M}\)</span></td>
</tr>
<tr class="even">
<td><strong>Gauss’s Law</strong></td>
<td><span class="math inline">\(\nabla \cdot \mathbf{E} = 4\pi \rho\)</span></td>
<td><span class="math inline">\(\nabla \cdot \mathbf{E} = \rho\)</span></td>
<td><span class="math inline">\(\nabla \cdot \mathbf{E} = \frac{\rho}{\varepsilon_0}\)</span></td>
</tr>
<tr class="odd">
<td><strong>Faraday’s Law</strong></td>
<td><span class="math inline">\(\nabla \times \mathbf{E} = -\frac{1}{c} \frac{\partial \mathbf{B}}{\partial t}\)</span></td>
<td><span class="math inline">\(\nabla \times \mathbf{E} = -\frac{1}{c}\frac{\partial \mathbf{B}}{\partial t}\)</span></td>
<td><span class="math inline">\(\nabla \times \mathbf{E} = -\frac{\partial \mathbf{B}}{\partial t}\)</span></td>
</tr>
<tr class="even">
<td><strong>Gauss’s Law for Magnetism</strong></td>
<td><span class="math inline">\(\nabla \cdot \mathbf{B} = 0\)</span></td>
<td><span class="math inline">\(\nabla \cdot \mathbf{B} = 0\)</span></td>
<td><span class="math inline">\(\nabla \cdot \mathbf{B} = 0\)</span></td>
</tr>
<tr class="odd">
<td><strong>Ampere-Maxwell Law</strong></td>
<td><span class="math inline">\(\nabla \times \mathbf{B} = \frac{4\pi}{c} \mathbf{J} + \frac{1}{c} \frac{\partial \mathbf{E}}{\partial t}\)</span></td>
<td><span class="math inline">\(\nabla \times \mathbf{B} = \frac{1}{c} \mathbf{J} + \frac{1}{c} \frac{\partial \mathbf{E}}{\partial t}\)</span></td>
<td><span class="math inline">\(\nabla \times \mathbf{B} = \mu_0 \mathbf{J} + \mu_0 \varepsilon_0 \frac{\partial \mathbf{E}}{\partial t}\)</span></td>
</tr>
<tr class="even">
<td><strong>Continuity Equation</strong></td>
<td><span class="math inline">\(\nabla \cdot \mathbf{J} = -\frac{\partial \rho}{\partial t}\)</span></td>
<td><span class="math inline">\(\nabla \cdot \mathbf{J} = -\frac{\partial \rho}{\partial t}\)</span></td>
<td><span class="math inline">\(\nabla \cdot \mathbf{J} = -\frac{\partial \rho}{\partial t}\)</span></td>
</tr>
<tr class="odd">
<td><strong>Ohm’s Law</strong></td>
<td><span class="math inline">\(\mathbf{J} = \sigma \mathbf{E}\)</span></td>
<td><span class="math inline">\(\mathbf{J} = \sigma \mathbf{E}\)</span></td>
<td><span class="math inline">\(\mathbf{J} = \sigma \mathbf{E}\)</span></td>
</tr>
<tr class="even">
<td><strong>Energy Density</strong></td>
<td><span class="math inline">\(u = \frac{1}{8\pi} (|\mathbf{E}|^2 + |\mathbf{B}|^2)\)</span></td>
<td><span class="math inline">\(u = \frac{1}{2} (|\mathbf{E}|^2 + |\mathbf{B}|^2)\)</span></td>
<td><span class="math inline">\(u = \frac{\varepsilon_0}{2} |\mathbf{E}|^2 + \frac{1}{2\mu_0} |\mathbf{B}|^2\)</span></td>
</tr>
<tr class="odd">
<td><strong>Poynting Vector</strong></td>
<td><span class="math inline">\(\mathbf{S} = \frac{c}{4\pi} \mathbf{E} \times \mathbf{B}\)</span></td>
<td><span class="math inline">\(\mathbf{S} = c \mathbf{E} \times \mathbf{B}\)</span></td>
<td><span class="math inline">\(\mathbf{S} = \frac{1}{\mu_0} \mathbf{E} \times \mathbf{B}\)</span></td>
</tr>
</tbody>
</table>
</section>
<section id="vectors" class="level2">
<h2 class="anchored" data-anchor-id="vectors">Vectors</h2>
<p>We will now give a very brief review of some important mathematical results that will be important in our study of electrodynamics. We will not prove anything here nor provide many if any examples, as this is all assumed to be review.</p>
<p>As in mechanics, in electrodynamics we generally assume that physical objects live in a 3-dimensional real space, often denoted by the set <span class="math inline">\(\mathbb{R}^3\)</span>. A <em>vector</em> or <em>3-vector</em> we’ll define as a 3-component object <span class="math inline">\(\mathbf{v}\)</span> that lives in <span class="math inline">\(\mathbb{R}^3\)</span>. The 3 components of the vector depend on the choice of <em>coordinate system</em> or <em>basis</em> chosen. In Cartesian coordinates we can expand a vector as a superposition of unit vectors aligned with the coordinate axes, <span class="math display">\[
\mathbf{v} = v_x \mathbf{e}_x + v_y \mathbf{e}_y + v_z \mathbf{e}_z = v_1 \mathbf{e}_1 + v_2 \mathbf{e}_2 + v_3 \mathbf{e}_3 \ .
\]</span></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../resources/image-20240126183306137.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="300"></p>
</figure>
</div>
<p>The second representation of using numerical indices to represent the components in order will be useful for us, as we’ll often express superpositions like this using summation notation, or more conveniently using the <em>Einstein summation convention</em>, <span class="math display">\[
\mathbf{v} \equiv v_i \mathbf{e}_i \equiv \sum_{i=1}^3 v_i \mathbf{e}_i \ .
\]</span> Recall the summation convention says that if a term has a repeated index a summation over all values of that index is implied. In this case, <span class="math inline">\(v_i \mathbf{e}_i\)</span> has the repeated index <span class="math inline">\(i\)</span>, which is assumed to sum from 1 to 3. Any index that does not repeat does not get summed over. We’ll sometimes express a vector only by its components <span class="math inline">\(v_i\)</span>, where the basis is left unspecified. This is called <em>index notation</em>. It’s fully equivalent to vector notation but sometimes more convenient when doing complex vector calculations. We’ll go back and forth between these two notations in this course.</p>
<p>For a vector to be a valid physical object, we require it transform in a specific way under coordinate transformations. Suppose in one rectangular coordinate system we have coordinates <span class="math inline">\(x_i\)</span> and in another rotated coordinate system we have coordinates <span class="math inline">\(x_i'\)</span>. Then for <span class="math inline">\(\mathbf{v}\)</span> to be a valid vector we require that for any such choice of coordinates we have <span class="math display">\[
\mathbf{v} = v_i \mathbf{e}_i = v_i' \mathbf{e}_i' \ .
\]</span> We can express this more succinctly by saying that <span class="math display">\[
v_j' = \frac{\partial x_j'}{\partial x_i} v_i \ .
\]</span> This set of <span class="math inline">\(3^2 = 9\)</span> partial derivatives is called the <em>Jacobian</em> between the coordinates <span class="math inline">\(x_i\)</span> and <span class="math inline">\(x_i'\)</span>. Notice the implied summation going on over <span class="math inline">\(i\)</span>. This means the right-hand side will contain only 3 elements indexed by <span class="math inline">\(j\)</span>. These partial derivatives can be collected into a matrix called the <em>Jacobian matrix</em>, which is often denoted by <span class="math inline">\(\mathbf{J}\)</span> or <span class="math inline">\(\mathbf{J}(\mathbf{x},\mathbf{x}')\)</span>. The Jacobian is a surprisingly important object in vector calculus as we’ll see. Note that by definition, any linear superposition of valid vectors will also be a valid vector.</p>
<p>We can thus think of a vector as a one index, or <em>rank-1</em>, object that transforms in the manner specified above. A simpler object with no index, or <em>rank-0</em>, defines a <em>scalar</em>. A <em>scalar</em> is a single number that doesn’t change under coordinate transformations. An important example of a scalar is the <em>dot product</em> or <em>inner product</em> between two vectors, defined in Euclidean space by <span class="math display">\[
\mathbf{v} \cdot \mathbf{w} \equiv v_i w_i = v_1 w_1 + v_2 w_2 + v_3 w_3 \ .
\]</span> Recall from elementary physics that we can also express the dot product in terms of the angle <span class="math inline">\(\theta\)</span> between the two vectors as <span class="math display">\[
\mathbf{v} \cdot \mathbf{w} = |\mathbf{v}| |\mathbf{w}| \cos\theta \ .
\]</span> Here <span class="math inline">\(|\mathbf{v}| \equiv \sqrt{\mathbf{v} \cdot \mathbf{v}}\)</span> is the <em>norm</em> or <em>magnitude</em> of <span class="math inline">\(\mathbf{v}\)</span>. This formula says that in some sense the dot product encodes information about both the magnitude of vectors as well as the angles between them. When <span class="math inline">\(|\mathbf{v}|=1\)</span> we say <span class="math inline">\(\mathbf{v}\)</span> is a <em>unit vector</em>, which in this course we’ll usually denote by <span class="math inline">\(\mathbf{e}_v\)</span>. Evidently the dot product of two vectors is zero if they’re perpendicular, in which case we call the two vectors <em>orthogonal</em>. When the two vectors are parallel or antiparallel their dot product is <span class="math inline">\(\pm 1\)</span>.</p>
<p>As long as coordinate transformations are rotations, the dot product will always be a scalar. As an exercise in using index notation let’s prove this. When working in index notation we need to convert every object we need to an indexed object. Since <span class="math inline">\(\mathbf{v}\)</span> and <span class="math inline">\(\mathbf{w}\)</span> are vectors, they both get one index. Since their components get summed over in the dot product, the indices on the two vectors should be the same.</p>
<p>We’re now ready to proceed with the proof. We need to show that under a coordinate transformation the dot product stays invariant under rotations. Starting with the dot product in <span class="math inline">\(x_i'\)</span> coordinates, and denoting the partial derivatives in the Jacobian between <span class="math inline">\(x_i\)</span> and <span class="math inline">\(x_i'\)</span> coordinates by <span class="math inline">\(J_{ij}\)</span>, we have <span class="math display">\[
v_i' w_i' = v_i' w_j' = (J_{ij} v_j) (J_{ik} w_k) = J_{ij} J_{ik} v_i w_k  \ .
\]</span> Now, we need the right-hand side to equal <span class="math inline">\(v_i w_i\)</span>. The only way this can be true is if <span class="math inline">\(J_{ij} J_{ik} = \delta_{jk}\)</span>. Then we get <span class="math display">\[
v_i' w_i' = J_{ij} J_{ik} v_i w_k = \delta_{jk} v_i w_k = v_j w_j  \ .
\]</span> Now, the index being summed over is a <em>dummy index</em>, meaning it doesn’t matter how we label it as long as we’re consistent. We can thus freely relabel <span class="math inline">\(j\)</span> to <span class="math inline">\(i\)</span> and write <span class="math inline">\(v_i' w_i' = v_i w_i\)</span>, which is what we wanted to show.</p>
<p>For this proof to work, however, we had to impose the fact that <span class="math inline">\(J_{ij} J_{ik} = \delta_{jk}\)</span>. This is just saying that the Jacobian times its transpose should equal the identity, i.e.&nbsp;<span class="math inline">\(\mathbf{J}^\top \mathbf{J} = \mathbf{I}\)</span>. What kinds of transformations satisfy this property? Recall that this is just the definition of an <em>orthogonal transformation</em>. An orthogonal transformation is precisely a transformation that preserves the dot products between vectors. From the elementary definition of the dot product, this also means an orthogonal transformation preserves the <em>angles</em> between vectors. Note that such transformations need not preserve the <em>handedness</em> between the vectors. Since <span class="math inline">\(\det \mathbf{J} = \pm 1\)</span> for orthogonal transformations, there are two cases. It’s the <span class="math inline">\(+1\)</span> case that preserves handedness, while the <span class="math inline">\(-1\)</span> case flips the order between the vectors.</p>
<p>It’s fair to ask what happens when the coordinate transformation isn’t orthogonal. In that case, we define <span class="math inline">\(\mathbf{g} \equiv \mathbf{J}^\top \mathbf{J}\)</span>, in which case we then define <span class="math inline">\(\mathbf{x} \cdot \mathbf{y} \equiv x_i g_{ij} y_j\)</span>. Here <span class="math inline">\(\mathbf{g}\)</span> is called the <em>metric</em>. It says something about the geometry of the two coordinate transformations. With this generalized form of the dot product it again becomes a proper scalar regardless of what <span class="math inline">\(\mathbf{J}\)</span> is. We’ll see this more general dot product again when we get to relativistic electrodynamics towards the end of the course. Indeed, the presence of <span class="math inline">\(\mathbf{g}\)</span> is one of the defining features of relativity, both special and general relativity.</p>
<p>We know that vectors in 3 dimensions also have another kind of product that creates vectors from vectors. This other product is called the <em>cross product</em>, which in index notation can be defined by <span class="math display">\[
(\mathbf{x} \times \mathbf{y}) \equiv \varepsilon_{ijk} x_i y_j \mathbf{e}_k \ .
\]</span> Here <span class="math inline">\(\varepsilon_{ijk}\)</span> is the <em>Levi-Civita symbol</em>, defined to be <span class="math inline">\(+1\)</span> for even permutations of <span class="math inline">\(ijk\)</span>, <span class="math inline">\(-1\)</span> for odd permutations of <span class="math inline">\(ijk\)</span>, and <span class="math inline">\(0\)</span> when any of the indices are repeated. Written out in components, it’s not hard to show that <span class="math display">\[
\mathbf{v} \times \mathbf{w} = (v_y w_z - v_z w_y) \mathbf{e}_x + (v_z w_x - v_x w_z) \mathbf{e}_y + (v_x w_y - v_y w_x) \mathbf{e}_z \ .
\]</span> We know that the cross product between two vectors can also be expressed geometrically, where its magnitude is given by <span class="math display">\[
|\mathbf{v} \times \mathbf{w}| = |\mathbf{v}| |\mathbf{w}| \sin\theta \ ,
\]</span> while its direction is given by the <em>right-hand rule</em>. The cross product evidently defines a favored orientation in space. If a plane contains the two vectors <span class="math inline">\(\mathbf{v}\)</span> and <span class="math inline">\(\mathbf{w}\)</span>, its positive orientation or <em>normal</em> is the direction of <span class="math inline">\(\mathbf{v} \times \mathbf{w}\)</span>. Evidently, this version of the cross product says that the cross product of two parallel vectors is <span class="math inline">\(\mathbf{0}\)</span>. Note the cross product is neither commutative nor associative.</p>
<p>It’s worth pointing out that despite the hand-waving, the cross product is not <em>really</em> a vector in the sense we’ve defined what a vector really is, an object that transforms a certain way under coordinate transformations. The cross product in general does <em>not</em> transform correctly under coordinate transformations. For example, under an <em>inversion</em> <span class="math inline">\(\mathbf{v} \rightarrow -\mathbf{v}, \mathbf{w} \rightarrow -\mathbf{w}\)</span> their cross product remains <span class="math inline">\(\mathbf{v} \times \mathbf{w}\)</span>. It doesn’t become <span class="math inline">\(-\mathbf{v} \times \mathbf{w}\)</span> like we’d require. For this reason the cross product is properly thought of as a <em>pseudovector</em>, in that in a lot of ways it behaves like a vector, but not in all ways. In fact, properly speaking the cross product should be thought of as an antisymmetric tensor. We’ll say more about this below.</p>
<p>The Levi-Civita symbol is a useful symbol in its own right, independent of the cross product. We’ll need to understand its algebra a bit better since we’ll use this symbol frequently in this course. One useful fact is that swapping two indices introduces a negative sign. For example, swapping <span class="math inline">\(i \leftrightarrow j\)</span> gives <span class="math inline">\(\varepsilon_{jik} = -\varepsilon_{ijk}\)</span>. We can use this fact to show that the cross product is perpendicular to the plane spanned by the two vectors. We can do this by showing <span class="math inline">\(\mathbf{v} \cdot (\mathbf{v} \times \mathbf{w}) = 0\)</span>. That is, that <span class="math inline">\(\mathbf{v}\)</span> is <em>orthogonal</em> to <span class="math inline">\(\mathbf{v} \times \mathbf{w}\)</span>, which by the geometric version of the dot product means the two are perpendicular. In index notation, we have <span class="math display">\[
\mathbf{v} \cdot (\mathbf{v} \times \mathbf{w}) = \varepsilon_{ijk} v_j w_k (\mathbf{v} \cdot \mathbf{e}_i) = v_i \varepsilon_{ijk} v_j w_k = -v_i \varepsilon_{jik} v_j w_k = -v_j \varepsilon_{ijk} v_i w_k \ .
\]</span> Notice we have <span class="math inline">\(\varepsilon_{ijk} x_i x_j y_k = -\varepsilon_{ijk} x_i x_j y_k\)</span>, which can only be true of both are zero, as we wanted to show.</p>
<p>Another surprisingly useful identity of the Levi-Civita symbol is gotten by <em>contracting</em> their product to get <span class="math display">\[
\boxed{
\varepsilon_{ijk} \varepsilon_{k\ell m} = \delta_{i\ell} \delta_{jm} - \delta_{im} \delta_{j\ell}
} \ .
\]</span></p>
<section id="example-bac-cab-rule" class="level5">
<h5 class="anchored" data-anchor-id="example-bac-cab-rule">Example: BAC-CAB rule</h5>
<p>As an application of this identity, we’ll use it to prove the well-known <em>BAC-CAB</em> rule for triple products, <span class="math display">\[
\mathbf{a} \times (\mathbf{b} \times \mathbf{c}) = \mathbf{b} (\mathbf{a} \cdot \mathbf{c}) - \mathbf{c} (\mathbf{a} \cdot \mathbf{b}) \ .
\]</span> Let <span class="math inline">\(\mathbf{d} = \mathbf{a} \times (\mathbf{b} \times \mathbf{c})\)</span> for convenience. Writing this out in index notation and applying the previous identity, we have <span class="math display">\[
\begin{align*}
d_i &amp;= [\mathbf{a} \times (\mathbf{b} \times \mathbf{c})]_i \\
&amp;= \varepsilon_{ijk} a_j (\mathbf{b} \times \mathbf{c})_k \\
&amp;= \varepsilon_{ijk} \varepsilon_{k\ell m} a_j b_\ell c_m \\
&amp;= (\delta_{i\ell} \delta_{jm} - \delta_{im} \delta_{j\ell}) a_j b_\ell c_m \\
&amp;= \delta_{i\ell} \delta_{jm} a_j b_\ell c_m - \delta_{im} \delta_{j\ell} a_j b_\ell c_m \\
&amp;= a_j b_i c_j - a_j b_j c_i \\
&amp;= (\mathbf{a} \cdot \mathbf{c}) b_i - (\mathbf{a} \cdot \mathbf{b}) c_i \ .
\end{align*}
\]</span> Written back out in vector notation this gives exactly what we wanted to show.</p>
<hr>
<p>The last curious fact of the Levi-Civita symbol that we’ll mention but not really use is that we can use it to write out the determinant of a <span class="math inline">\(3 \times 3\)</span> matrix. If a matrix <span class="math inline">\(\mathbf{A}\)</span> has column vectors <span class="math inline">\(\mathbf{a}, \mathbf{b}, \mathbf{c}\)</span>, then we have <span class="math display">\[
\det \mathbf{A} = \varepsilon_{ijk} a_i b_j c_k \ .
\]</span> While cute, this formula only works in 3 dimensions. In other dimensions we’d have to use generalizations of the Levi-Civita symbol to get a formula like this, and even then they’re not actually useful for <em>calculating</em> the determinant.</p>
</section>
</section>
<section id="vector-calculus" class="level2">
<h2 class="anchored" data-anchor-id="vector-calculus">Vector Calculus</h2>
<p>Calculus extends naturally to higher dimensions, but often in subtle ways. Most importantly, there are different types of derivatives and integrals defined in higher dimensions with different meaning and applications. Due to complications involved in using curvilinear coordinates in vector calculus we’ll state results in Cartesian coordinates and address the others later.</p>
<section id="differential-vector-calculus" class="level3">
<h3 class="anchored" data-anchor-id="differential-vector-calculus">Differential Vector Calculus</h3>
<p>The fundamental object of vector calculus is the <em>differential</em> of a field. This says how much the field changes if its inputs are nudged in some direction by an infinitesimal amount. In Cartesian coordinates, it turns out the differential of a scalar field <span class="math inline">\(f(\mathbf{x})\)</span> is nothing more than a sum of partial differentials along each coordinate. That is, <span class="math display">\[
df = \frac{\partial f}{\partial x} dx + \frac{\partial f}{\partial y} dy + \frac{\partial f}{\partial z} dz \ .
\]</span> The right-hand side looks like a sort of dot product between the partial derivatives of <span class="math inline">\(f\)</span> and a differential displacement vector <span class="math inline">\(d\mathbf{x}\)</span>, or <em>vector line element</em>, defined in Cartesian coordinates by <span class="math display">\[
d\mathbf{x} \equiv dx \mathbf{e}_x + dy \mathbf{e}_y + dz \mathbf{e}_z \ .
\]</span> It’s the vector generalization of the differential <span class="math inline">\(dx\)</span> from ordinary calculus. The vector of partial derivatives can be written in a useful way by defining the <em>del operator</em> <span class="math inline">\(\nabla\)</span> by <span class="math display">\[
\nabla \equiv \partial_i \mathbf{e}_i \equiv \frac{\partial}{\partial x} \mathbf{e}_x + \frac{\partial}{\partial y} \mathbf{e}_y + \frac{\partial}{\partial z} \mathbf{e}_z \ .
\]</span> Here we introduce the convenient shorthand <span class="math inline">\(\partial_i \equiv \frac{\partial}{\partial x_i}\)</span> for the partial derivative with respect to component <span class="math inline">\(x_i\)</span>. Using the del operator we can define the vector of partial derivatives of a scalar field <span class="math inline">\(f\)</span> by <span class="math display">\[
\nabla f \equiv \partial_i f \ \mathbf{e}_i \equiv \frac{\partial f}{\partial x} \mathbf{e}_x + \frac{\partial f}{\partial y} \mathbf{e}_y + \frac{\partial f}{\partial z} \mathbf{e}_z \ .
\]</span> This quantity is evidently some kind of vector derivative, called the <em>gradient</em> of the field <span class="math inline">\(f\)</span>. Since <span class="math inline">\(f\)</span> is a scalar field, <span class="math inline">\(\nabla f\)</span> will be a vector field. Its components are the partial derivatives of <span class="math inline">\(f\)</span> in the <span class="math inline">\(x_i\)</span> direction at each <span class="math inline">\(\mathbf{x}\)</span>. The gradient always points perpendicular to the <em>level curves</em> where <span class="math inline">\(f=\text{const}\)</span>. To see why this is the case, we can use the geometric formula for the dot product to express any change in the function along a level curve as <span class="math display">\[
\delta f = \nabla f \cdot \delta \mathbf{x} = |\nabla f| |\delta \mathbf{x}| \cos\theta \ .
\]</span> Since <span class="math inline">\(\delta f = 0\)</span> along the level curve by definition, it must be the case that <span class="math inline">\(\theta = \pm 90^\circ\)</span> along such curves, meaning that the gradient must always be orthogonal to the level curve.</p>
<p>Using the gradient, we can finally express the differential <span class="math inline">\(df\)</span> as a dot product of the gradient with the vector line element, <span class="math display">\[
df = \nabla f \cdot d\mathbf{x} \ .
\]</span> Unlike in ordinary calculus, however, in vector calculus this isn’t the only kind of derivative we can take. We can see this by looking at the definition of <span class="math inline">\(\nabla\)</span>. We can think of <span class="math inline">\(\nabla f\)</span> as multiplying a vector by a scalar. But we also know that we can take both the dot product and the cross product of two vectors, which along with <span class="math inline">\(\nabla\)</span> suggests there are two more derivative operations we can perform on vector fields.</p>
<p>If <span class="math inline">\(\mathbf{F}(\mathbf{x})\)</span> is a vector field, we can take its dot product of <span class="math inline">\(\nabla\)</span> with <span class="math inline">\(\mathbf{F}\)</span> to get a new scalar field known as the <em>divergence</em>, which is evidently defined in Cartesian coordinates by <span class="math display">\[
\nabla \cdot \mathbf{F} \equiv \partial_i F_i \equiv \frac{\partial f}{\partial x} + \frac{\partial f}{\partial y} + \frac{\partial f}{\partial z} \ .
\]</span> Though not obvious from the definition, the divergence represents the tendency of a vector to flow into or out of a point. A field where <span class="math inline">\(\nabla \cdot \mathbf{F} = 0\)</span> for all points in space has no divergence at all, meaning there are no sources or sinks in the field anywhere. Due to the fact that the magnetic field is the canonical example of a divergence-less vector field, such fields are often called <em>solenoidal</em>.</p>
<p>We can also take the cross product of <span class="math inline">\(\nabla\)</span> with <span class="math inline">\(\mathbf{F}(\mathbf{x})\)</span> to get a vector field known as the <em>curl</em>, defined in Cartesian coordinates by <span class="math display">\[
\nabla \times \mathbf{F} \equiv \varepsilon_{ijk} \partial_i F_j \mathbf{e}_k \ .
\]</span></p>
<p>Though again not obvious from the definition, the curl represents the tendency of a vector to rotate around a point in space. A field where <span class="math inline">\(\nabla \times \mathbf{F} = \mathbf{0}\)</span> at all points in space is called <em>irrotational</em> since it doesn’t experience any rotational motion at any point. It just flows inward or outward.</p>
<p>We can also take vector second derivatives as well. The most useful of these is obtained by taking the divergence of the gradient of a scalar field. This is called the <em>Laplacian</em>, defined in Cartesian coordinates by <span class="math display">\[
\nabla^2 f \equiv \nabla \cdot \nabla f = \partial_i \partial_i f = \frac{\partial^2 f}{\partial x^2} + \frac{\partial^2 f}{\partial y^2} + \frac{\partial^2 f}{\partial z^2} \ .
\]</span> The Laplacian has the useful property of being rotationally invariant. That is, if <span class="math inline">\(\nabla\)</span> represents the del operator in some coordinate system <span class="math inline">\(\mathcal{S}\)</span> and <span class="math inline">\(\nabla'\)</span> the same operator in some rotated coordinate system <span class="math inline">\(\mathcal{S}'\)</span>, then <span class="math inline">\((\nabla')^2 = \nabla^2\)</span>. This follows from the fact that the Laplacian applied to any function gives a scalar, and scalars are by definition invariant under coordinate transformations.</p>
<p>There are a few other vector second derivatives as well, some of which turn out to be zero. These are <span class="math display">\[
\begin{align*}
\nabla \cdot (\nabla \times \mathbf{F}) &amp;= 0 \ , \\
\nabla \times \nabla f &amp;= \mathbf{0} \ , \\
\nabla \times (\nabla \times \mathbf{F}) &amp;= \nabla (\nabla \cdot \mathbf{F}) - \nabla^2 \mathbf{F} \ .
\end{align*}
\]</span> The Laplacian in the last expression is understood to be taken component-wise, as a vector with components <span class="math inline">\(\nabla^2 F_i\)</span>. Each of these identities can all be efficiently proven using index notation.</p>
</section>
<section id="integral-vector-calculus" class="level3">
<h3 class="anchored" data-anchor-id="integral-vector-calculus">Integral Vector Calculus</h3>
<p>The gradient, divergence, and curl each has its own corresponding version of the fundamental theorem of calculus. To understand integration in higher dimensions though we first need to define what the differentials are. To integrate over a spatial volume we use the <em>volume element</em> <span class="math inline">\(d^3 \mathbf{x}\)</span>, defined in Cartesian components by <span class="math display">\[
d^3 \mathbf{x} \equiv dx dy dz \ .
\]</span> An important fact about the volume element is that its expression in a given coordinate system depends on the Jacobian. If <span class="math inline">\(\mathbf{u}(\mathbf{x})\)</span> is some coordinate transformation with Jacobian <span class="math inline">\(\mathbf{J} \equiv \frac{d\mathbf{u}}{d\mathbf{x}}\)</span>, then their volume elements are related by <span class="math display">\[
d^3 \mathbf{x} = du_1 du_2 du_3 = |\det \mathbf{J}| dx_1 dx_2 dx_3 \ .
\]</span> To find the <em>volume integral</em> of a scalar field <span class="math inline">\(f\)</span> over a region of space <span class="math inline">\(\mathcal{V}\)</span>, we can integrate each coordinate iteratively, <span class="math display">\[
\int_\mathcal{V} d^3 \mathbf{x} \ f(\mathbf{x}) = \iiint_\mathcal{V} dx dy dz \ f(x,y,z) \ .
\]</span> We can integrate a vector field over a volume too. In this case the integral is done component-wise, so little new is added.</p>
<p>Sometimes we’ll also need to integrate a field over a <em>surface</em> in space as well. Suppose we wish to integrate over some smooth, orientable surface <span class="math inline">\(\mathcal{S}\)</span> in space. We can define an <em>area element</em> <span class="math inline">\(d\mathbf{a}\)</span> on this surface by considering an infinitesimal patch of area <span class="math inline">\(da\)</span> on the surface and attaching an outward unit normal <span class="math inline">\(\mathbf{n}\)</span> to it to get <span class="math display">\[
d\mathbf{a} \equiv \mathbf{n} \ da \ .
\]</span> It’s fair to ask how <span class="math inline">\(da\)</span> itself is determined. When the surface is the <span class="math inline">\(xy\)</span>-plane it’s clear <span class="math inline">\(da = dxdy\)</span>. But for more general surfaces we’d need to parametrize <span class="math inline">\(\mathcal{S}\)</span> with two relative coordinates and express <span class="math inline">\(da\)</span> in terms of those. Evidently the area element <span class="math inline">\(d\mathbf{a}\)</span> is a kind of vector. We can thus also think of it as the cross product of two infinitesimal vectors on the surface. Importantly, this means <span class="math inline">\(d\mathbf{a}\)</span> will have both a magnitude and a direction that depend on where we are along the surface. When we require the surface be orientable, we mean that we can always use the right-hand rule to find the direction of <span class="math inline">\(\mathbf{n}\)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../resources/image-20240126183636267.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="300"></p>
</figure>
</div>
<p>To get the <em>surface integral</em> of a vector field <span class="math inline">\(\mathbf{F}\)</span> along the surface <span class="math inline">\(\mathcal{S}\)</span> we’d typically write <span class="math display">\[
\int_\mathcal{S} \mathbf{F} \cdot d\mathbf{a} = \int_\mathcal{S} \mathbf{F} \cdot \mathbf{n} \ da \ .
\]</span> The last form of vector integration we’ll find ourselves using frequently is <em>contour integration</em>, which is the integration of a field along some arbitrary curve in space. We can integrate a vector field <span class="math inline">\(\mathbf{F}\)</span> along some <em>path</em> or <em>contour</em> <span class="math inline">\(\mathcal{C}\)</span> in space by defining a <em>line element</em> <span class="math inline">\(d\boldsymbol{\ell}\)</span> along the contour, defined in Cartesian coordinates by <span class="math display">\[
d\boldsymbol{\ell} \equiv d\mathbf{x} = dx \mathbf{e}_x + dy \mathbf{e}_y + dy \mathbf{e}_y \ .
\]</span> The contour integral is just an infinitesimal sum of the projection of the field along the contour, i.e. <span class="math display">\[
\int_\mathcal{C} \mathbf{F}(\mathbf{x}) \cdot d\boldsymbol{\ell} \ .
\]</span> The usual way to evaluate a contour integral is to parametrize the path with some real parameter <span class="math inline">\(\tau\)</span> from some starting point <span class="math inline">\(\tau=a\)</span> to some ending point <span class="math inline">\(\tau = b\)</span>. Then we have <span class="math display">\[
\int_\mathcal{C} \mathbf{F}(\mathbf{x}) \cdot d\boldsymbol{\ell} \equiv \int_a^b d\tau \ \mathbf{F}(\mathbf{x}(\tau)) \cdot \frac{d\mathbf{x}}{d\tau} \ .
\]</span> We can also integrate a scalar field <span class="math inline">\(f\)</span> over the same contour by defining a similar contour integral of the form <span class="math display">\[
\int_\mathcal{C} ds \ f(\mathbf{x}) =  \int_a^b d\tau \ f(\mathbf{x}(\tau)) \bigg |\frac{d\mathbf{x}}{d\tau} \bigg | \ .
\]</span> Here <span class="math inline">\(ds\)</span> is the scalar line element defined in Cartesian coordinates by <span class="math display">\[
ds = |d\boldsymbol{\ell}| = \sqrt{dx^2 + dy^2 + dy^2} \ .
\]</span> Integrating over <span class="math inline">\(ds\)</span> alone gives the <em>arc length</em> of the contour. Interestingly the scalar line element is very important in studying the geometry of a space. In general it depends on the metric <span class="math inline">\(\mathbf{g}\)</span> by <span class="math display">\[
ds^2 = dx_i g_{ij} dx_j \ .
\]</span> For Euclidean space the metric is always the identity, so we just have <span class="math inline">\(ds^2 = dx_i dx_i\)</span>. This is all we’ll need for most of this course, but in relativity (especially general relativity) this line element becomes fundamental.</p>
<p>Usually a path integral between two endpoints will depend on the exact path of the contour <span class="math inline">\(\mathcal{C}\)</span>. For some special fields though the path integral depends only on the endpoints, not on the path between them. When this is true we say the field is <em>conservative</em>. An implication of this is that if we integrate a conservative field around any <em>closed contour</em> where the path integral vanishes, <span class="math display">\[
\oint \mathbf{F} \cdot d\mathbf{x} = 0 \ .
\]</span> It’s easy to see why this must be true. For any closed contour we can break it into two pieces. The line integral of each piece must be path independent, which means their sum, and hence the closed path integral, must vanish for conservative fields.</p>
<p>In vector calculus, each version of vector derivative has its own fundamental theorem of calculus that relates it to one or more of the integrals defined above. The fundamental theorem for gradients says the line integral of the gradient of a scalar field depends only on the endpoints, <span class="math display">\[
\int_{\mathbf{x}_1}^{\mathbf{x}_2} \nabla f(\mathbf{x}) \cdot d\mathbf{x} = f(\mathbf{x}_2) - f(\mathbf{x}_1) \ .
\]</span> This means that the gradient of a scalar field is always <em>conservative</em>. In fact, it turns out any conservative vector field <span class="math inline">\(\mathbf{F}(\mathbf{x})\)</span> can be written as the gradient of some scalar field <span class="math inline">\(\phi(\mathbf{x})\)</span>, <span class="math display">\[
\mathbf{F} = -\nabla \phi \ .
\]</span> This fact we use extensively in electromagnetism. The minus sign is merely a physics convention. Since the curl of a gradient must vanish, this statement also says <span class="math inline">\(\mathbf{F}\)</span> must be irrotational, i.e.&nbsp;<span class="math inline">\(\nabla \times \mathbf{F} = \mathbf{0}\)</span>.</p>
<p>A more general extension of this special case is called the <em>Helmholtz theorem</em>. It says <em>any</em> smooth vector field <span class="math inline">\(\mathbf{F}(\mathbf{x})\)</span>, conservative or not, can be expressed as the <em>gradient</em> of some <em>scalar field</em> <span class="math inline">\(\phi(\mathbf{x})\)</span> plus the <em>curl</em> of some other <em>vector field</em> <span class="math inline">\(\mathbf{A}(\mathbf{x})\)</span>, i.e. <span class="math display">\[
\mathbf{F} = -\nabla \phi + \nabla \times \mathbf{A} \ .
\]</span> Though not obvious, this formula in fact can be inverted to find formulas for <span class="math inline">\(\phi\)</span> and <span class="math inline">\(\mathbf{A}\)</span> in terms of derivatives of <span class="math inline">\(\mathbf{F}\)</span>, <span class="math display">\[
\begin{align*}
\phi(\mathbf{x}) &amp;= \frac{1}{4\pi} \int_{\mathbb{R}^3} d^3 \mathbf{x}' \ \frac{\nabla' \cdot \mathbf{F}(\mathbf{x}')}{|\mathbf{x} - \mathbf{x}'|} \ , \\
\mathbf{A}(\mathbf{x}) &amp;= \frac{1}{4\pi} \int_{\mathbb{R}^3} d^3 \mathbf{x}' \ \frac{\nabla' \times \mathbf{F}(\mathbf{x}')}{|\mathbf{x} - \mathbf{x}'|} \ .
\end{align*}
\]</span> Here it’s implicitly assumed that <span class="math inline">\(\mathbf{F}\)</span> vanishes faster than <span class="math inline">\(\frac{1}{r}\)</span> at infinity. If not we have to include extra boundary terms. The symbol <span class="math inline">\(\nabla'\)</span> means to differentiate with respect to the integration variable <span class="math inline">\(\mathbf{x}'\)</span>.</p>
<p>The fundamental theorem for divergences is called the <em>divergence theorem</em>. It says that the divergence of a vector field is nothing more than the flow or <em>flux</em> of the field through the surface of a closed volume, <span class="math display">\[
\int_\mathcal{V} \nabla \cdot \mathbf{F} \ d^3\mathbf{x} = \int_S \mathbf{F} \cdot d\mathbf{a} \ .
\]</span> The fundamental theorem for curls is called <em>Stokes’ theorem</em>. It says the curl of a vector field is nothing more than the <em>circulation</em> of the field around the boundary of any closed surface, <span class="math display">\[
\int_\mathcal{S} (\nabla \times \mathbf{F}) \cdot \ d\mathbf{a} = \int_C \mathbf{F} \cdot d\mathbf{x} \ .
\]</span> It’s interesting to note that all of these versions of the fundamental theorem of calculus say essentially the same thing: The integral of the derivative of a field over some space equals the value of that field along the boundary of that space. For gradients, the boundary of a contour is just two endpoints. For divergences, the boundary over a volume is a closed surface. For curls, the boundary of a surface is a closed contour.</p>
<p>We can use the divergence theorem to derive two more important integral formulas that we’ll use, the <em>Green’s Identities</em>. What we’ll do is let <span class="math inline">\(\mathbf{F} = \psi \nabla \phi\)</span>, where <span class="math inline">\(\psi\)</span> and <span class="math inline">\(\phi\)</span> are two scalar fields that may or may not be different. We want to plug this into the divergence theorem, but first we need to figure out the product rule formula for <span class="math inline">\(\nabla \cdot (\psi \nabla \phi)\)</span>. This can be done, for example, using index notation. It turns out that <span class="math display">\[
\nabla \cdot (\psi \nabla \phi) = \nabla \psi \cdot \nabla \phi + \psi \nabla^2 \phi \ .
\]</span> Plugging this into the divergence theorem formula, we then get <em>Green’s First Identity</em>, which says that <span class="math display">\[
\int_\mathcal{V} d^3 \mathbf{x} \ (\nabla \psi \cdot \nabla \phi + \psi \nabla^2 \phi) = \oint_\mathcal{S} da \ \psi \frac{\partial \phi}{\partial n} \ .
\]</span> Here we’ve defined the <em>normal derivative</em> <span class="math inline">\(\frac{\partial \phi}{\partial n} \equiv \nabla \phi \cdot \mathbf{n}\)</span>, which just says how much <span class="math inline">\(\phi\)</span> changes in the direction normal to the boundary surface <span class="math inline">\(\mathcal{S}\)</span>. If we now swap <span class="math inline">\(\psi\)</span> and <span class="math inline">\(\phi\)</span> and difference the two formulas, we get another identity, called <em>Green’s Second Identity</em>, given by <span class="math display">\[
\int_\mathcal{V} d^3 \mathbf{x} \ (\phi \nabla^2 \psi - \psi \nabla^2 \phi) = \oint_\mathcal{S} da \ \bigg[\phi \frac{\partial \psi}{\partial n} - \psi \frac{\partial \phi}{\partial n} \bigg] \ .
\]</span> We’ll see frequent use of each of these integral formulas throughout the course.</p>
</section>
</section>
<section id="tensors" class="level2">
<h2 class="anchored" data-anchor-id="tensors">Tensors</h2>
<p>Thus far we’ve seen objects with no indices and objects with one index that transform in a specified way under coordinate transformations. It’s fair to ask whether we can define matrices that transform in a specific way as well, and in fact we can. These two-index objects are called <em>rank-2 tensors</em>. They’re matrices <span class="math inline">\(\mathbf{T}\)</span> that obey the transformation law <span class="math display">\[
\mathbf{T}(\mathbf{x}') = \mathbf{J}^\top \mathbf{T}(\mathbf{x}') \mathbf{J} \ .
\]</span> This is just a direct generalization of the vector transformation law. It’s easier to see this in index notation. Vectors obey the transformation law <span class="math inline">\(v_i' = J_{ij} v_j\)</span>, while rank-2 tensors obey the transformation law <span class="math display">\[
T_{ij}' =  J_{ik} J_{j\ell} T_{k\ell} \ .
\]</span> Roughly speaking, this just says each dimension of the tensor transforms itself as a vector would.</p>
<p>While tensors didn’t show up transparently in elementary physics courses, they show up a lot in more advanced physics. A lot of physical quantities are tensors: the metric tensor, the moment of inertia tensor, the strain tensor, and so on. Another example is the <em>cross product</em>. The cross product seems like a vector, but it’s really not. In fact, we can define the cross product in a slightly different way using a rank-2 tensor as <span class="math display">\[
\varepsilon_{ijk} (\mathbf{v} \times \mathbf{w})_k = v_i w_j - v_j w_i
\]</span> In this variant definition the cross product is no longer a vector, but a rank-2 tensor whose upper diagonal components are the usual components of the cross product in 3 dimensions. Represented as a matrix <span class="math inline">\(\mathbf{A}\)</span>, it looks like <span class="math display">\[
A_{ij} \equiv \varepsilon_{ijk} (\mathbf{v} \times \mathbf{w})_k \doteq
\begin{pmatrix}
0 &amp; v_1 w_2 - v_2 w_1 &amp; v_1 w_3 - v_3 w_1  \\
v_2 w_1 - v_1 w_2 &amp; 0 &amp; v_2 w_3 - v_3 w_2 \\
v_3 w_1 - v_1 w_3 &amp;  &amp; 0 \\
\end{pmatrix}
\ .
\]</span> Here <span class="math inline">\(\mathbf{A}\)</span> is a rank-2 tensor that evidently satisfies the <em>antisymmetric</em> property <span class="math inline">\(A_{ij} = -A_{ji}\)</span>. Unlike with the regular cross product, this generalization of the cross product can be defined for any number of dimensions. To see why we can’t extend the usual cross product this way, notice that the components <span class="math inline">\(\mathbf{v} \times \mathbf{w}\)</span> lie in the upper diagonal of <span class="math inline">\(\mathbf{A}\)</span>. The diagonals are always zero, and the lower diagonal is just minus the upper diagonal, meaning there are only 3 independent components. For a general antisymmetric tensor in <span class="math inline">\(d\)</span> dimensions there will be <span class="math inline">\(\frac{1}{2}d(d-1)\)</span> such independent components in the upper diagonal. Insisteng that such a tensor be a vector is equivalent to requiring <span class="math inline">\(d=\frac{1}{2}d(d-1)\)</span>, which evidently can only be true when <span class="math inline">\(d=3\)</span>. Thus, the cross product can only be a vector in 3 dimensions.</p>
<p>One useful operation that we can do with tensors is <em>contraction</em>. Contraction is the tensor generalization of the inner product, obtained by setting two indices in a tensor equal and summing over them. Since rank-2 tensors only have 2 indices, contracting a rank-2 tensor will always give a scalar, which is of course just <em>trace</em> of <span class="math inline">\(\mathbf{T}\)</span>, i.e.&nbsp;<span class="math inline">\(T_{ii} = \text{tr} \ \mathbf{T}\)</span>. Just as the dot product of a vector with itself says something about its size (in fact it’s just its squared norm), the trace of a rank-2 tensor says something about its size. Since the trace has no free indices, it must be a rank-0 object, hence a proper scalar like the dot product.</p>
<p>Another operation we can do with tensors is take their <em>tensor product</em>. A tensor product is no more than component-wise concatenation. For example, if <span class="math inline">\(\mathbf{x}\)</span> and <span class="math inline">\(\mathbf{y}\)</span> are two vectors, we can define their tensor product in index notation by <span class="math display">\[
T_{ij} \equiv x_i x_j \ .
\]</span> Evidently the tensor product of two vectors gives a rank-2 tensor. In fact, it’s just the outer product of the two vectors. In this sense the tensor product is a generalization of the outer product, just as contraction is the generalization of the inner product. In more abstract notation we’d write the tensor product as <span class="math display">\[
\mathbf{T} = \mathbf{x} \otimes \mathbf{y} \equiv \mathbf{x} \mathbf{y} \ .
\]</span> The last expression <span class="math inline">\(\mathbf{x} \mathbf{y}\)</span> for the tensor product is called <em>dyadic notation</em>, where we omit the <span class="math inline">\(\otimes\)</span> symbol for brevity. It’s tempting to think that all rank-2 tensors can be formed from a tensor product of vectors, but this is false. Only special vectors can, called <em>product tensors</em>. Most rank-2 tensors are <em>mixed tensors</em>, meaning superpositions of vector outer products.</p>
<p>Using the tensor product we can define the notion of a <em>basis tensor</em> for a rank-2 tensor as <span class="math display">\[
\mathbf{e}_{ij} \equiv \mathbf{e}_i \mathbf{e}_j \equiv \mathbf{e}_i \otimes \mathbf{e}_j \ .
\]</span> Since this is just the outer products of the two basis vectors, they are 1 when at slot <span class="math inline">\((i,j)\)</span> and 0 otherwise. Using superposition just as we do for vectors, we can use these basis tensors to expand any rank-2 tensor as <span class="math display">\[
\mathbf{T} = T_{ij} \mathbf{e}_i \mathbf{e}_j \ .
\]</span> We can also take the tensor product of a rank-2 tensor with a vector, which would give a three-index object, or a <em>rank-3 tensor</em>. Taking the tensor product of two rank-2 tensors would give a <em>rank-4 tensor</em>. And so on. In fact we can define a tensor of any rank. A <em>rank-k</em> tensor is an object with <span class="math inline">\(k\)</span> indices that tranforms component-wise according to the law <span class="math display">\[
T_{i_1' i_2' \cdots i_k'} = J_{i_1' i_1} J_{i_2' i_2} \cdots J_{i_2' i_2} T_{i_1 i_2 \cdots i_k} \ .
\]</span> In this course we won’t generally work much with tensors of higher rank than 2, but they do occasionally show up in electromagnetism, for example in the multipole expansions of the scalar and vector potentials. Tensor contraction can be defined naturally on these higher-rank tensors as well. Contracting two indices in a tensor will always reduce its rank by 2.</p>
<p>We can define similar vector calculus operations for tensors as well, not just vectors. For example, if we have a rank-2 tensor <span class="math inline">\(\mathbf{T}\)</span> we can still imagine taking gradients <span class="math inline">\(\partial_k T_{ij}\)</span> to get a rank-3 tensor. By contracting the derivative with the tensor we get a different divergence for each index, <span class="math inline">\(\partial_i T_{ij}\)</span> and <span class="math inline">\(\partial_j T_{ij}\)</span>. Evidently the divergence of a rank-2 tensor gives a vector, not a scalar.</p>
<p>Strictly speaking we can’t speak of <em>the divergence</em> of a tensor since each index has its own divergence. We can though when the tensor is <em>symmetric</em>. If <span class="math inline">\(T_{ij} = T_{ji}\)</span> we can define a unique divergence operation by <span class="math display">\[
\nabla \cdot \mathbf{T} \equiv \partial_i T_{ij} = \partial_j T_{ij} \ .
\]</span></p>
<p>We could imagine taking the curl of a tensor as well. From index notation it’s clear that the curl of a rank-2 tensor will give another rank-2 tensor. We can even imagine defining tensor integrals as well in similar ways. In practice though we’ll only care about divergences and gradients of rank-2 tensors in this course, so we won’t go into any detail here.</p>
<ul>
<li>Rewrite this section. It turns out higher-rank tensors do show up in this course, a lot in the multipole expansion especially.</li>
<li>Need to define symmetric and antisymmetric tensors for tensors of higher rank.</li>
<li>Need to talk about irreducible tensors, i.e.&nbsp;symmetric traceless tensors, and their decomposition in terms of irreducible components. This is essential to deriving the multipole expansion.</li>
</ul>
</section>
<section id="coordinate-systems" class="level2">
<h2 class="anchored" data-anchor-id="coordinate-systems">Coordinate Systems</h2>
<p>It will be frequently useful in electrodynamics to work in other coordinate systems. As with other areas of physics, the most important coordinate systems we work with are Cartesian, polar, cylindrical, and spherical coordinates. Cartesian coordinates are <em>rectangular</em>, which means their basis vectors don’t depend on position. They’re always constant. The remaining three coordinate systems, however, are <em>curvilinear</em>, meaning their basis vectors <em>do</em> depend on position. This means going back and forth between these coordinate systems can be cumbersome since additional scale factors get introduced. Below is a table that shows the relationship between these coordinate systems for various vector calculus expressions we’ll frequently use.</p>
<table class="table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Cartesian <span class="math inline">\((x,y,z)\)</span></th>
<th>Cylindrical <span class="math inline">\((\varrho,\varphi,z)\)</span></th>
<th>Spherical <span class="math inline">\((r,\theta,\varphi)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Coordinates</strong></td>
<td><span class="math inline">\(\begin{align*} x&amp;=x \\ y&amp;=y \\ z&amp;=z \end{align*}\)</span></td>
<td><span class="math inline">\(\begin{align*} x&amp;=\varrho\cos\varphi \\ y&amp;=\varrho\sin\varphi \\ z&amp;=z \end{align*}\)</span></td>
<td><span class="math inline">\(\begin{align*} x&amp;=r\sin\theta\cos\varphi \\ y&amp;=r\sin\theta\sin\varphi \\ z&amp;=r\cos\theta \end{align*}\)</span></td>
</tr>
<tr class="even">
<td><strong>Basis Vectors</strong></td>
<td><span class="math inline">\(\begin{align*} \mathbf{e}_x&amp;=\mathbf{e}_x \\ \mathbf{e}_y&amp;=\mathbf{e}_y \\ \mathbf{e}_z&amp;=\mathbf{e}_z \end{align*}\)</span></td>
<td><span class="math inline">\(\begin{align*} \mathbf{e}_\varrho &amp;= \cos\varphi \mathbf{e}_x + \sin\varphi \mathbf{e}_y \\ \mathbf{e}_\varphi &amp;= -\sin \varphi \mathbf{e}_x + \cos \varphi \mathbf{e}_y \\ \mathbf{e}_z&amp;=\mathbf{e}_z \end{align*}\)</span></td>
<td><span class="math inline">\(\begin{align*} \mathbf{e}_r &amp;= \sin\theta \cos\varphi \mathbf{e}_x + \sin\theta \sin\varphi \mathbf{e}_y + \cos\theta \mathbf{e}_z \\ \mathbf{e}_\theta &amp;= \cos\theta \cos\varphi \mathbf{e}_x + \cos\theta \sin\varphi \mathbf{e}_y - \sin\theta \mathbf{e}_z  \\ \mathbf{e}_\varphi &amp;= -\sin\varphi \mathbf{e}_x + \cos\varphi \mathbf{e}_y  \end{align*}\)</span></td>
</tr>
<tr class="odd">
<td><strong>Differential</strong></td>
<td><span class="math inline">\(d\mathbf{x} = dx \mathbf{e}_x + dy \mathbf{e}_y + dz \mathbf{e}_z\)</span></td>
<td><span class="math inline">\(d\mathbf{x} = d\varrho \mathbf{e}_\varrho + \varrho d\varphi \mathbf{e}_\varphi + dz \mathbf{e}_z\)</span></td>
<td><span class="math inline">\(d\mathbf{x} = dr \mathbf{e}_r + r d\theta \mathbf{e}_\theta + r \sin \theta d\varphi \mathbf{e}_\varphi\)</span></td>
</tr>
<tr class="even">
<td><strong>Line Element</strong></td>
<td><span class="math inline">\(ds^2=dx^2 + dy^2 + dz^2\)</span></td>
<td><span class="math inline">\(ds^2=d\varrho^2 + \varrho^2 d\varphi^2 + dz^2\)</span></td>
<td><span class="math inline">\(ds^2=dr^2 + r^2 d\theta^2 + r^2 \sin^2 \theta d\varphi^2\)</span></td>
</tr>
<tr class="odd">
<td><strong>Volume Element</strong></td>
<td><span class="math inline">\(d^3 \mathbf{x} = dx dy dz\)</span></td>
<td><span class="math inline">\(d^3 \mathbf{x} = \varrho d\varrho d\varphi dz\)</span></td>
<td><span class="math inline">\(d^3 \mathbf{x} = r^2 \sin \theta dr d\theta d\varphi\)</span></td>
</tr>
<tr class="even">
<td><strong>Gradient</strong></td>
<td><span class="math inline">\(\nabla f = \partial_x f \mathbf{e}_x + \partial_y f \mathbf{e}_y + \partial_z f \mathbf{e}_z\)</span></td>
<td><span class="math inline">\(\nabla f = \partial_\varrho f \mathbf{e}_\varrho + \frac{1}{\varrho} \partial_\varphi \mathbf{e}_\varphi + \partial_z f \mathbf{e}_z\)</span></td>
<td><span class="math inline">\(\nabla f = \partial_r f \mathbf{e}_r + \frac{1}{r} \partial_\theta f \mathbf{e}_\theta + \frac{1}{r \sin \theta} \partial_\varphi f \mathbf{e}_\varphi\)</span></td>
</tr>
<tr class="odd">
<td><strong>Divergence</strong></td>
<td><span class="math inline">\(\nabla \cdot \mathbf{F} = \partial_x F_x + \partial_y F_y + \partial_z F_z\)</span></td>
<td><span class="math inline">\(\nabla \cdot \mathbf{F} = \frac{1}{\varrho} \partial_\varrho(\varrho F_\varrho) + \frac{1}{\varrho} \partial_\varphi F_\varphi + \partial_z F_z\)</span></td>
<td><span class="math inline">\(\nabla \cdot \mathbf{F} = \frac{1}{r^2} \partial_r (r^2 F_r) + \frac{1}{r \sin \theta} \partial_\theta (F_\theta \sin \theta) + \frac{1}{r \sin \theta} \partial_\varphi F_\varphi\)</span></td>
</tr>
<tr class="even">
<td><strong>Curl</strong></td>
<td><span class="math inline">\(\begin{align*}\nabla \times \mathbf{F} &amp;= \left( \partial_y F_z - \partial_z F_y \right) \mathbf{e}_x \\ &amp;+ \left( \partial_z F_x - \partial_x F_z \right) \mathbf{e}_y \\ &amp;+ \left( \partial_x F_y - \partial_y F_x \right) \mathbf{e}_z \end{align*}\)</span></td>
<td><span class="math inline">\(\begin{align*} \nabla \times \mathbf{F} &amp;= \left( \frac{1}{\varrho} \partial_\varphi F_z - \partial_z F_\varphi \right) \mathbf{e}_\varrho \\ &amp;+ \left( \partial_z F_\varrho - \partial_\varrho F_z \right) \mathbf{e}_\varphi \\ &amp;+ \frac{1}{\varrho} \left( \partial_\varrho (\varrho F_\varphi) - \partial_\varphi F_\varrho \right) \mathbf{e}_z \end{align*}\)</span></td>
<td><span class="math inline">\(\begin{align*} \nabla \times \mathbf{F} &amp;= \frac{1}{r \sin \theta} \left( \partial_\theta (F_\varphi \sin \theta) - \partial_\varphi F_\theta \right) \mathbf{e}_r \\ &amp;+ \frac{1}{r} \left( \frac{1}{\sin \theta} \partial_\varphi F_r - \partial_r (r F_\varphi) \right) \mathbf{e}_\theta \\ &amp;+ \frac{1}{r} \left( \partial_r (r F_\theta) - \partial_\theta F_r \right) \mathbf{e}_\varphi \end{align*}\)</span></td>
</tr>
<tr class="odd">
<td><strong>Laplacian</strong></td>
<td><span class="math inline">\(\nabla^2 f = \partial_x^2 f + \partial_y^2 f + \partial_z^2 f\)</span></td>
<td><span class="math inline">\(\nabla^2 f = \frac{1}{\varrho} \partial_\varrho \left(\varrho \partial_\varrho f \right) + \frac{1}{\varrho^2} \partial_\varphi^2 f + \partial_z^2 f\)</span></td>
<td><span class="math inline">\(\nabla^2 f = \frac{1}{r^2} \partial_r^2 \left( r^2 \partial_r f \right) + \frac{1}{r^2 \sin \theta} \partial_\theta \left( \sin \theta \partial_\theta f \right) + \frac{1}{r^2 \sin^2 \theta} \partial_\varphi^2 f\)</span></td>
</tr>
</tbody>
</table>
<p>Note the formulas for these expressions in the the two-dimensional polar coordinate system <span class="math inline">\((\varrho,\varphi)\)</span> can be obtained by taking the formulas for cylindrical coordinates and setting all the <span class="math inline">\(z\)</span>-components equal to zero.</p>
</section>
<section id="complex-variables" class="level2">
<h2 class="anchored" data-anchor-id="complex-variables">Complex Variables</h2>
<p>In electromagnetism we’ll often find ourselves dealing with not only real variables and real-valued functions, but complex variables and complex-valued functions. Here we’ll briefly touch on the basics of complex variables and functions.</p>
<p>A <em>complex variable</em> is any variable <span class="math inline">\(z\)</span> of the form <span class="math display">\[
z = x + iy \ ,
\]</span> where <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> are real numbers and <span class="math inline">\(i \equiv \sqrt{-1}\)</span> is the imaginary number. We call <span class="math inline">\(x \equiv \text{Re} \ z\)</span> the <em>real part</em> of <span class="math inline">\(z\)</span> and <span class="math inline">\(y \equiv \text{Im} \ z\)</span> the <em>imaginary part</em> of <span class="math inline">\(z\)</span>. Geometrically, we can imagine any complex variable <span class="math inline">\(z\)</span> as a representing a point in a 2-dimensional <em>complex plane</em>, usually denoted by the symbol <span class="math inline">\(\mathbb{C}\)</span>. The <span class="math inline">\(x\)</span>-axis represents the real part of <span class="math inline">\(z\)</span> and the <span class="math inline">\(y\)</span>-axis the imaginary part of <span class="math inline">\(z\)</span>.</p>
<p>Every complex variable has a dual variable <span class="math inline">\(z^*\)</span> called the <em>complex conjugate</em>, defined by <span class="math display">\[
z^* \equiv x - iy \ .
\]</span> By adding and subtracting <span class="math inline">\(z\)</span> and <span class="math inline">\(z^*\)</span> together, we also get the following relations for the real and imaginary parts of <span class="math inline">\(z\)</span>, <span class="math display">\[
x = \text{Re} \ z = \frac{z + z^*}{2} \quad , \quad y = \text{Im} \ z = \frac{z - z^*}{2i} \ .
\]</span> Geometrically, the complex conjugate is obtained by flipping <span class="math inline">\(z\)</span> across the real axis in the complex plane. When we say that <span class="math inline">\(z^*\)</span> is dual to <span class="math inline">\(z\)</span>, we mean that their product will always be a non-negative real number, with <span class="math inline">\(zz^* = x^2 + y^2\)</span>. In the complex plane, this number represents the squared radial distance of <span class="math inline">\(z\)</span> from the origin. We can thus define a <em>modulus</em> or length by <span class="math display">\[
|z| \equiv \sqrt{zz^*} = \sqrt{x^2 + y^2} \ .
\]</span> Just as we can have real-valued functions of a real variable, we can have complex-valued functions of a real variable, and even complex functions of a complex variable. We’ll talk about these functions more generally in the appendix.</p>
<p>For now we only mention the most important complex-valued function in this course, and indeed in all of science, the <em>complex exponential</em>. For a real variable <span class="math inline">\(x\)</span>, we define the complex exponential function by <span class="math inline">\(f(x) = e^{i x}\)</span>. As written this function seems mysterious and perhaps not that important, but as we’ll see it’s very important.</p>
<p>Observe that since <span class="math inline">\(i^2 = -1\)</span>, then <span class="math inline">\(i^3 = -i\)</span>, <span class="math inline">\(i^4 = 1\)</span>, etc. In general, <span class="math inline">\(i^n = \pm 1\)</span> if <span class="math inline">\(n\)</span> is even and <span class="math inline">\(i^n = \pm i\)</span> if <span class="math inline">\(n\)</span> is odd. This means if we expand the complex exponential as a Taylor series and rearrange terms, we have <span class="math display">\[
\begin{align*}
e^{ix} &amp;= 1 + ix + \frac{i^2}{2!} x^2 + \frac{i^3}{3!} x^3 + \frac{i^4}{4!} x^4 + \frac{i^5}{5!} x^5 + \cdots \\
&amp;= 1 + ix - \frac{x^2}{2!} - \frac{ix^3}{3!} + \frac{x^4}{4!} + \frac{ix^5}{5!} + \cdots \\
&amp;= \bigg(1 - \frac{x^2}{2!} + \frac{x^4}{4!} + \cdots\bigg) + i\bigg(x - \frac{x^3}{3!} + \frac{x^5}{5!} + \cdots\bigg) \\
&amp;= \cos x + i \sin x \ .
\end{align*}
\]</span> In the last step, we recognized the fact that the even powers in the series expansion were just those for <span class="math inline">\(\cos x\)</span>, and the odd terms were just those for <span class="math inline">\(i \sin x\)</span>. This proves the well-known <em>Euler identity</em>, <span class="math display">\[
\boxed{
e^{ix} = \cos x + i \sin x
} \ .
\]</span> Notice that according to this formula, the modulus of <span class="math inline">\(e^{ix}\)</span> is given by <span class="math display">\[
|e^{ix}| = e^{ix} (e^{ix})^* = \cos^2 x + \sin^2 x  = 1 \ .
\]</span> This means that the complex exponential in effect behaves like a rotation in the complex plane. Indeed, the path traversed by <span class="math inline">\(e^{ix}\)</span> as <span class="math inline">\(x\)</span> increases traces a counterclockwise circle of radius one in the complex plane.</p>
<p>If we take any complex variable <span class="math inline">\(z\)</span> and multiply it by <span class="math inline">\(e^{i\varphi}\)</span>, then <span class="math inline">\(z\)</span> rotates counter-clockwise by an angle <span class="math inline">\(\varphi\)</span> in the complex plane. An immediate consequence of this fact is that any complex variable can be represented by the polar formula <span class="math display">\[
z = r e^{i\varphi} \ ,
\]</span> where <span class="math inline">\(r = |z|\)</span> represents the distance of <span class="math inline">\(z\)</span> from the origin in the complex plane, while <span class="math inline">\(\varphi\)</span> represents its angle above the <span class="math inline">\(x\)</span>-axis, called the <em>argument</em> or <em>phase</em> of <span class="math inline">\(z\)</span>, often denoted by <span class="math inline">\(\phi \equiv \text{Arg} \ z\)</span>.</p>
<p>By writing <span class="math inline">\(z = x + iy\)</span>, it’s not hard to see that the phase will depend on the quadrant <span class="math inline">\(z\)</span> is in, with <span class="math display">\[
\varphi = \text{Arg} \ z = \begin{cases}
\tan^{-1} \frac{y}{x} &amp; x &gt; 0 \ , \\
\pi + \tan^{-1} \frac{y}{x} &amp; x &lt; 0 \ , y &gt; 0 \ , \\
-\pi + \tan^{-1} \frac{y}{x} &amp; x &lt; 0 \ , y &lt; 0 \ .
\end{cases}
\]</span> One useful fact to remember about phases is that when two complex variables are multiplied together their phases add. To see why this is true, let <span class="math inline">\(z_1 = r_1 e^{i \phi_1}\)</span> and <span class="math inline">\(z_2 = r_2 e^{i \phi_2}\)</span>. Then the product <span class="math inline">\(z_1 z_2\)</span> can be written as <span class="math display">\[
z_1 z_2 = r_1 r_2 e^{i (\varphi_1 + \varphi_2)} \ .
\]</span> From this, we can see that the modulus of the product is <span class="math inline">\(|z_1 z_2| = r_1 r_2\)</span>, and the phase of the product is <span class="math display">\[
\text{Arg} \ z_1 z_2 = \text{Arg} \ z_1 + \text{Arg} \ z_2 \ .
\]</span> In a similar manner, it’s easy to see that when dividing two complex numbers their phases get subtracted, <span class="math display">\[
\text{Arg} \ \frac{z_1}{z_2} = \text{Arg} \ z_1 - \text{Arg} \ z_2 \ .
\]</span> Last, note that if we substitute <span class="math inline">\(x=\pi\)</span> into the complex exponential function and move everything to one side, we get <span class="math display">\[
e^{i\pi} + 1 = 0 \ .
\]</span> This curious identity has sometimes been called the most beautiful in mathematics, since it’s the only valid equation that includes only the fundamental numbers <span class="math inline">\(0,1,\pi,e\)</span> and <span class="math inline">\(i\)</span>, with each number occurring exactly once in the equation.</p>
</section>
<section id="delta-function" class="level2">
<h2 class="anchored" data-anchor-id="delta-function">Delta Function</h2>
<p>A very important mathematical object in electromagnetism and physics more generally is the <em>Dirac delta function</em> <span class="math inline">\(\delta(x-x')\)</span>, defined by the property that for any real-valued function <span class="math inline">\(f(x)\)</span>, <span class="math display">\[
\boxed{
f(x) = \int_{-\infty}^\infty dx' \ f(x') \delta(x-x')
} \ .
\]</span> Notice from this definition the delta function must have units to cancel out the units of <span class="math inline">\(dx'\)</span>. If <span class="math inline">\(dx'\)</span> has units of length, for example, then evidently <span class="math inline">\(\delta(x-x')\)</span> must have units of inverse length.</p>
<p>Evidently, the delta function acts as a sort of sifting function that picks out a point <span class="math inline">\(x\)</span> from an integral and evaluates whatever function is inside the integral at that point. In particular, when <span class="math inline">\(x=0\)</span> we have <span class="math display">\[
f(0) = \int_{-\infty}^\infty dx \ f(x) \delta(x) \ .
\]</span> By taking <span class="math inline">\(f(x) = 1\)</span>, we can see that the delta function satisfies <span class="math display">\[
\int_{-\infty}^\infty dx' \ \delta(x-x') = 1 \ .
\]</span> In fact, we don’t even need to integrate over the whole real line. All that’s required is that <span class="math inline">\(x\)</span> is included in the interval. If we consider some small interval <span class="math inline">\(x - \varepsilon \leq x \leq x + \varepsilon\)</span>, we still have <span class="math display">\[
1 = \int_{x-\varepsilon}^{x+\varepsilon} dx' \ \delta(x-x') \ .
\]</span> By letting <span class="math inline">\(\varepsilon \rightarrow 0\)</span>, we can see that <span class="math inline">\(\delta(x-x') = 0\)</span> when <span class="math inline">\(x' \neq x\)</span>, but still must integrate to one. This means we can informally think of the delta function as an infinite spike at the point <span class="math inline">\(x' = x\)</span> that instantly dies off to zero away from the point <span class="math inline">\(x\)</span>. That is, we can think of the delta function as a sort of density for a single point.</p>
<p>We can use this infinite spike idea if we like to “define” a delta function as a limit of Gaussian functions of the form <span class="math display">\[
p(x) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-(x-x')^2 / 2\sigma^2} \ .
\]</span> Recall that this function represents the probability density of a Gaussian random variable <span class="math inline">\(x\)</span>. In particular, this means this function also integrates to one, is peaked at <span class="math inline">\(x' = x\)</span>, and dies off to zero at a rate characterized by the parameter <span class="math inline">\(\sigma\)</span>. The larger <span class="math inline">\(\sigma\)</span> is the more spread out the Gaussian will be, and vice versa. As we let <span class="math inline">\(\sigma \to 0\)</span> the Gaussian becomes infinitely sharp at <span class="math inline">\(x'=x\)</span> and dies off quickly to zero away from this point. This means we can also “define” the delta function as the limit of <span class="math inline">\(p(x)\)</span> as <span class="math inline">\(\sigma \to 0\)</span>, <span class="math display">\[
\delta(x-x') = \lim_{\sigma \rightarrow 0} \frac{1}{\sqrt{2\pi\sigma^2}} e^{-(x-x')^2/2\sigma^2} \ .
\]</span> We use the term “define” in quotations here because strictly speaking this limit isn’t well-defined at <span class="math inline">\(x'=x\)</span>, which means the delta function itself isn’t well-defined. Instead it’s a so-called <em>generalized function</em> or <em>distribution</em>, meaning it’s an object that has meaning only when integrated against some <em>test function</em> <span class="math inline">\(f(x)\)</span>. If we like we can formalize the above limit by <span class="math display">\[
\int_{-\infty}^\infty dx' f(x) \delta(x-x') = \lim_{\sigma \to \infty} \frac{1}{\sqrt{2\pi\sigma^2}} \int_{-\infty}^\infty dx' f(x') e^{-(x-x')^2/2\sigma^2} \ .
\]</span> From this formula, it’s clear that the delta function must be an even function, so <span class="math inline">\(\delta(-x) = \delta(x)\)</span>. In particular, this means that we can always swap <span class="math inline">\(x\)</span> and <span class="math inline">\(x'\)</span> using the relation <span class="math inline">\(\delta(x-x') = \delta(x'-x)\)</span>.</p>
<p>Another useful fact about the delta function relates to how it transforms under a rescaling of coordinates <span class="math inline">\(u=ax\)</span>. We have <span class="math display">\[
\delta(ax) = \frac{1}{|a|} \delta(x) \ .
\]</span> This can easily be proven by integrating against a test function <span class="math inline">\(f(x)\)</span> and changing variables using <span class="math inline">\(u=ax\)</span>. The absolute value in the denominator follows from the fact that the delta function must be an even function. This property can be extended to delta functions of the form <span class="math inline">\(\delta(g(x))\)</span> as well. If <span class="math inline">\(g(x)\)</span> has roots <span class="math inline">\(a_n\)</span> with non-zero derivatives at each <span class="math inline">\(a_n\)</span>, we have <span class="math display">\[
\delta(g(x)) = \sum_n \frac{\delta(x-a_n)}{\big|\frac{d}{dx} g(a_n)\big|} \ .
\]</span> This can be proven by Taylor expanding <span class="math inline">\(g(x)\)</span> around each root and using the scaling property above on each root.</p>
<p>We can define the derivative of a delta function as well by choosing a test function <span class="math inline">\(f(x)\)</span> and integrating by parts to get <span class="math display">\[
\int_{-\infty}^\infty dx \ f(x) \frac{d}{dx} \delta(x-x') = - \int_{-\infty}^\infty dx \ \frac{d}{dx} f(x) \cdot \delta(x-x') = -\frac{d}{dx} f(x') \ .
\]</span> Note for this to be well-defined we require that <span class="math inline">\(f(x)\)</span> vanish as <span class="math inline">\(x \to \pm \infty\)</span>.</p>
<p>We can also define the delta function in another useful way using the <em>Fourier transform</em>. We won’t go into details on the Fourier transform here. See the appendix for details. In brief, the Fourier transform of a function <span class="math inline">\(f(x)\)</span> can be obtained by multiplying by <span class="math inline">\(e^{-ikx}\)</span> and integrating over the real line to get another function <span class="math inline">\(f(k)\)</span> in terms of this new variable <span class="math inline">\(k\)</span>, <span class="math display">\[
f(k) \equiv \int_{-\infty}^\infty dx \ f(x) e^{-ikx} \ .
\]</span> It turns out the Fourier transform is invertible, meaning we can recover <span class="math inline">\(f(x)\)</span> from <span class="math inline">\(f(k)\)</span> by another integral. If we multiply <span class="math inline">\(f(k)\)</span> by <span class="math inline">\(\frac{1}{2\pi} e^{ikx}\)</span> and integrate over <span class="math inline">\(x\)</span>, we can recover <span class="math inline">\(f(x)\)</span> by the <em>inverse Fourier transform</em> <span class="math display">\[
f(x) = \int_{-\infty}^\infty \frac{dk}{2\pi} \ f(k) e^{ikx} \ .
\]</span> If we plug the first integral for <span class="math inline">\(f(k)\)</span> into this integral, using <span class="math inline">\(x'\)</span> instead of <span class="math inline">\(x\)</span>, we get the <em>completeness relation</em> <span class="math display">\[
f(x) = \int_{-\infty}^\infty \frac{dk}{2\pi} \bigg(\int_{-\infty}^\infty dx' \ f(x') e^{-ikx'}\bigg) e^{ikx} \ .
\]</span> Suppose we interchange the order of integration to integrate first over <span class="math inline">\(k\)</span>. Then we get <span class="math display">\[
f(x) = \int_{-\infty}^\infty dx' f(x') \int_{-\infty}^\infty \frac{dk}{2\pi} \ e^{ik(x-x')} \ .
\]</span> The only way this can be true evidently is if the inner integral is the delta function <span class="math inline">\(\delta(x-x')\)</span>. We thus must have <span class="math display">\[
\boxed{
\delta(x-x') = \int_{-\infty}^\infty \frac{dk}{2\pi} \ e^{ik(x-x')}
} \ .
\]</span> Note that this integral isn’t well-defined in the usual sense, since the complex exponentials are oscillating sine and cosine functions, and hence don’t converge at infinity. We think of this integral instead as a formal relation that tells us when we can justify replacing it by a delta function.</p>
<p>The delta function extends naturally to higher dimensions. In three dimensions, we can define the delta function <span class="math inline">\(\delta(\mathbf{x}-\mathbf{x}')\)</span> by <span class="math display">\[
f(\mathbf{x}) = \int d^3\mathbf{x}' \ f(\mathbf{x}') \delta(\mathbf{x}-\mathbf{x}') \ .
\]</span> The integral is assumed to be over all space, but it doesn’t matter. So long as <span class="math inline">\(\mathbf{x}\)</span> is contained inside the integration volume this relation will still hold.</p>
<p>Again, if we set <span class="math inline">\(f(\mathbf{x}) = 1\)</span> we can write <span class="math display">\[
1 = \int d^3\mathbf{x}' \ \delta(\mathbf{x}-\mathbf{x}') \ .
\]</span> This means we can think of the 3-dimensional delta function as an infinite spike in three dimensions, which can be defined, for instance, by a limit of 3-dimensional Gaussian functions.</p>
<p>The specific form of <span class="math inline">\(\delta(\mathbf{x}-\mathbf{x}')\)</span> in terms of coordinates will depend on the coordinate system used. For instance, if working in Cartesian coordinates, we can write <span class="math inline">\(d^3\mathbf{x}' = dx'dy'dz'\)</span>, in which case it’s clear we must have <span class="math display">\[
\delta(\mathbf{x}-\mathbf{x}') = \delta(x-x') \delta(y-y') \delta(z-z') \ .
\]</span> Since densities transform with volume element and the delta function is a kind of density, when working in other coordinate systems the delta function will depend on the Jacobian. If <span class="math inline">\((u,v,w)\)</span> is some other coordinate system with a volume element of the form <span class="math inline">\(d^3\mathbf{x}' = |\text{det} \ \mathbf{J}| du' dv' dw'\)</span>, then we have <span class="math display">\[
\delta(\mathbf{x}-\mathbf{x}') = \frac{1}{|\text{det} \ \mathbf{J}|} \delta(u-u') \delta(v-v') \delta(w-w') \ .
\]</span> For example, in spherical coordinates we have <span class="math inline">\(|\text{det} \ \mathbf{J}| = r^2 \sin\theta\)</span>, which means the delta function is given by <span class="math display">\[
\delta(\mathbf{x}-\mathbf{x}') = \frac{1}{r^2 \sin\theta} \delta(r-r') \delta(\theta-\theta') \delta(\varphi-\varphi') \ .
\]</span> Let’s now work a simple example that puts together some of the topics covered in this chapter.</p>
<section id="example-divergence-of-inverse-square-fields" class="level5">
<h5 class="anchored" data-anchor-id="example-divergence-of-inverse-square-fields">Example: Divergence of Inverse Square Fields</h5>
<p>Suppose we wanted to calculate the divergence of the following vector field, <span class="math display">\[
\mathbf{F}(\mathbf{x}) = \frac{\mathbf{e}_r}{r^2} \ .
\]</span> We could proceed in one of two ways. One way would be to use Cartesian coordinates and index notation to churn it out the hard way. The other way would be to recognize this scalar field is spherically symmetric, so we should work in spherical coordinates more easily. Adopting the second approach, we can write <span class="math display">\[
\nabla \cdot \mathbf{F} = \frac{1}{r} \frac{\partial}{\partial r} \bigg(r^2 \frac{1}{r^2}\bigg) \ .
\]</span> It’s tempting to cancel out the factors of <span class="math inline">\(r^2\)</span> and conclude <span class="math inline">\(\nabla \cdot \mathbf{F} = 0\)</span>, but we have to be a little more careful than that. To see why, let’s use the divergence theorem to express the same problem as an integral over some closed surface. We can pick any surface we like as long as it includes the origin. Let’s suppose we’re integrating inside a sphere of radius <span class="math inline">\(R\)</span>. Then we have <span class="math display">\[
\int_S \mathbf{F} \cdot d\mathbf{a} = \int_\mathcal{V} \nabla \cdot \mathbf{F} \ d^3\mathbf{x} \ .
\]</span> Since <span class="math inline">\(\mathbf{F}\)</span> is spherically symmetric and we’re integrating over a sphere, we can write <span class="math inline">\(\mathbf{F} \cdot d\mathbf{a} = |\mathbf{F}| da\)</span> and integrate over the surface area of the sphere to get <span class="math display">\[
\int_S \mathbf{F} \cdot d\mathbf{a} = \int r^2 \bigg(\frac{1}{r^2}\bigg) \ d\Omega = 4\pi \ .
\]</span> Here the notation <span class="math inline">\(d\Omega \equiv \sin\theta d\theta d\varphi\)</span> is called the <em>solid angle</em>, and has units of <em>steradians</em>.</p>
<p>The result we just derived true for <em>any</em> surface of arbitrary radius so long as it contains the origin. This means the divergence of <span class="math inline">\(\mathbf{F}\)</span> can’t be zero, otherwise the surface integral would be zero. Moreover, it means the only contribution from the divergence can come at the point <span class="math inline">\(r=0\)</span> where the function blows up. We thus conclude that there must be a delta function multiplying <span class="math inline">\(4\pi\)</span> whose value is non-zero only when <span class="math inline">\(r=0\)</span>. That is, we have <span class="math display">\[
\nabla \cdot \bigg(\frac{\mathbf{e}_r}{r^2}\bigg) = 4\pi \delta(\mathbf{x}) \ .
\]</span> It’s not hard to see that if we shift the divergence point from the origin to some other point <span class="math inline">\(\mathbf{x}'\)</span> and define <span class="math inline">\(\boldsymbol{\xi} \equiv \mathbf{x} - \mathbf{x}'\)</span>, then the above result doesn’t change except with <span class="math inline">\(r\)</span> replaced by <span class="math inline">\(|\boldsymbol{\xi}|\)</span> and the unit vector <span class="math inline">\(\mathbf{e}_r\)</span> replaced by <span class="math inline">\(\mathbf{e}_\xi = \frac{\boldsymbol{\xi}}{|\boldsymbol{\xi}|}\)</span>. That is, <span class="math display">\[
\boxed{
\nabla \cdot \bigg(\frac{\mathbf{x} - \mathbf{x}'}{|\mathbf{x} - \mathbf{x}'|^3}\bigg) = 4\pi \delta(\mathbf{x} - \mathbf{x}')
} \ .
\]</span> Last, notice that <span class="math inline">\(\nabla \frac{1}{r} = -\frac{\mathbf{e}_r}{r^2}\)</span>. This means we’ve also established that <span class="math display">\[
\nabla^2 \bigg(\frac{1}{r}\bigg) = -4\pi \delta(\mathbf{x})
\]</span> Again shifting by <span class="math inline">\(\mathbf{x}'\)</span>, it’s easy to see this also implies that <span class="math display">\[
\boxed{
\nabla^2 \bigg(\frac{1}{|\mathbf{x} - \mathbf{x}'|}\bigg) = -4\pi \delta(\mathbf{x} - \mathbf{x}')
}\ .
\]</span> We will make good use of these formulas in the rest of this course, particularly in electrostatics.</p>
</section>
</section>
<section id="temporary" class="level2">
<h2 class="anchored" data-anchor-id="temporary">TEMPORARY</h2>
<p>The coefficient <span class="math inline">\(c_{-1}\)</span> in the Laurent Series is called a <em>residue</em> of the function <span class="math inline">\(f(z)\)</span>. In the previous example the function <span class="math inline">\(f(z) = e^{1/z}\)</span> evidently has a residue of <span class="math inline">\(c_{-1} = 1\)</span>. These residues that turn out to be very useful for our purposes due to a useful integral theorem we’ll see shortly.</p>
<p>Many complex functions have residues at different points. Anywhere the function has a pole there will be at least one residue. For example, the function <span class="math display">\[
f(z) = \frac{1}{(z-a)(z-b)}
\]</span> has two simple poles, one at <span class="math inline">\(z=a\)</span> and another at <span class="math inline">\(z=b\)</span>. There’s a trick we can use to quickly figure out the residues in a case like this. Notice if we ignore the <span class="math inline">\(z - a\)</span> term in the denominator what remains is <span class="math inline">\(\frac{1}{z - b}\)</span>. When <span class="math inline">\(z=a\)</span> this remaining term is a residue, with <span class="math display">\[
c_{-1} = \frac{1}{a - b} \ .
\]</span> Similarly, if we ignore the <span class="math inline">\(z - b\)</span> term what remains is <span class="math inline">\(\frac{1}{z-a}\)</span>. When <span class="math inline">\(z=b\)</span> this remaining term is another residue, with <span class="math display">\[
c_{-1} = \frac{1}{b - a} \ .
\]</span> The two residues associated with this function are thus <span class="math inline">\(c_{-1} = \pm \frac{1}{b-a}\)</span>. This can also be seen by writing down the full Laurent series at <span class="math inline">\(z=a\)</span> and <span class="math inline">\(z=b\)</span> and picking off the <span class="math inline">\(c_{-1}\)</span> coefficients directly.</p>
<p>We can also have complex functions with higher order poles. For example, consider the function <span class="math display">\[
f(z) = \frac{1}{(z-a)^2(z-b)} \ .
\]</span> Clearly there are poles at <span class="math inline">\(z=a\)</span> and <span class="math inline">\(z=b\)</span>, but the fact that the <span class="math inline">\(z-a\)</span> term is squared in the denominator means there are effectively two poles at <span class="math inline">\(z=a\)</span>. We call such a point <span class="math inline">\(z=a\)</span> in this case a pole of order 2. In general, if a function with <span class="math inline">\(n\)</span> poles at a single point <span class="math inline">\(z=a\)</span> we call that point a <em>pole of order</em> <span class="math inline">\(n\)</span>. We can find the residues of <span class="math inline">\(f(z)\)</span> for poles of order <span class="math inline">\(n\)</span> using the formula <span class="math display">\[
c_{-1} = \frac{1}{(n-1)!} \frac{d^{n-1}}{d z^{n-1}} \bigg |_{z=a} (z-a)^n f(z) \ .
\]</span> In the previous example, the pole of order 1 at <span class="math inline">\(z=b\)</span> has a residue of <span class="math inline">\(c_{-1} = \frac{1}{(a-b)^2}\)</span>, while the pole of order 2 at <span class="math inline">\(z=a\)</span> has a residue given by <span class="math display">\[
c_{-1} = \frac{d}{dz} (z-a)^2 \frac{1}{(z-a)^2(z-b)} \bigg |_{z=a} = -\frac{1}{(a-b)^2} \ .
\]</span> To understand why residues are important in complex analysis we need to talk a bit about the integration of complex functions. Since complex functions are secretly functions of two real variables, when we integrate a complex function we’re actually integrating over a plane instead of a line. This means complex integrals are always necessarily <em>contour integrals</em> over the complex plane, meaning the result of an integral will always depend on the <em>path</em> chosen.</p>
<p>We can define a contour integral in the complex plane just as we would any other contour integral. If <span class="math inline">\(f(z)\)</span> is some function we wish to integrate and <span class="math inline">\(\mathcal{C}\)</span> is some contour, we parametrize <span class="math inline">\(z = z(\tau)\)</span> where <span class="math inline">\(\tau\)</span> is some real parameter traversing the contour from <span class="math inline">\(\tau=a\)</span> to <span class="math inline">\(\tau=b\)</span>. Then we can define the complex contour integral via <span class="math display">\[
\int_\mathcal{C} dz \ f(z) \equiv \int_a^b d\tau \ f(z(\tau)) \frac{dz}{d\tau} \ .
\]</span> It turns out that analytic functions in complex analysis are the analogue of conservative functions in vector calculus, in that their closed loop integrals always vanish. If <span class="math inline">\(f(z)\)</span> is analytic, for any closed loop in the complex plane we have <span class="math display">\[
\oint dz \ f(z) = 0 \ .
\]</span> This result is known as <em>Cauchy’s Theorem</em> in complex analysis. If a function has poles we need to modify this result somewhat. This is what leads us to the <em>Residue Theorem</em>.</p>
<p>The residue theorem says that any closed loop integral is proportional to the residues contained inside the closed loop. More formally, suppose <span class="math inline">\(f(z)\)</span> is a complex function with poles at <span class="math inline">\(n\)</span> points <span class="math inline">\(z=a_n\)</span> in the complex plane all contained inside the closed loop. If we denote the residue at <span class="math inline">\(z=a_i\)</span> by <span class="math inline">\(R_i\)</span>, the residue theorem says that <span class="math display">\[
\oint dz \ f(z) = 2\pi i \sum_{i=1}^n R_i \ .
\]</span> This means that to calculate any closed loop integral of a complex function, we need only find the residues for each pole inside the closed loop and add them together to get the result, up to a factor of <span class="math inline">\(2\pi i\)</span>. Let’s work a couple of examples.</p>
<p>First, consider the simple function <span class="math inline">\(f(z) = \frac{1}{z}\)</span>. This function clearly only has a simple pole at <span class="math inline">\(z=0\)</span> with residue <span class="math inline">\(c_{-1} = 1\)</span>. Suppose we wish to integrate this function in a closed loop around the origin. The loop could be anything, a circle, a square, whatever, as long as the origin is inside the closed loop. Then the residue theorem simply says that <span class="math display">\[
\oint \frac{dz}{z} = 2\pi i \ .
\]</span> What if we chose a closed loop that didn’t contain the origin? In that case the integral would be zero, since there are no poles inside the loop and hence no residues inside.</p>
<p>As a slightly more interesting example, consider now the function <span class="math display">\[
f(z) = \frac{e^z}{(z-1)(z+1)} \ .
\]</span> This function has two simple poles at <span class="math inline">\(z = \pm 1\)</span> with residues <span class="math inline">\(c_{-1} = \frac{e}{2}, -\frac{1}{2e}\)</span>. Suppose we wanted to integrate this function over a closed loop that’s a circle of some radius <span class="math inline">\(R &gt; 1\)</span> centered at <span class="math inline">\(z=0\)</span>. Since both residues are contained inside this loop, we have <span class="math display">\[
\oint dz \ \frac{e^z}{(z-1)(z+1)} = 2\pi i \bigg(\frac{e}{2} - \frac{1}{2e}\bigg) \ .
\]</span> The residue theorem turns out to be surprisingly useful, even for calculating integrals of functions of a real variable. This is where we find the most use of residues in electromagnetism. Let’s work an example of such a scenario.</p>
<section id="example-evaluating-a-real-integral-using-the-residue-theorem" class="level4">
<h4 class="anchored" data-anchor-id="example-evaluating-a-real-integral-using-the-residue-theorem">Example: Evaluating a real integral using the residue theorem</h4>
<p>Suppose we have the following real integral we need to evaluate, <span class="math display">\[
\int_{-\infty}^\infty dx \ \frac{\cos x}{x^2 + 1} \ .
\]</span> This integral turns out to be very difficult to evaluate using traditional means, but we can relatively easily turn it into a complex integral and use the residue theorem to evaluate it. Let’s consider instead the complex integral <span class="math display">\[
\oint dz \ \frac{e^{iz}}{z^2 + 1} \ .
\]</span> Now let’s look closer at the integrand of this complex integral, <span class="math display">\[
f(z) = \frac{e^{iz}}{z^2 + 1} = \frac{e^{iz}}{(z + i)(z - i)} \ .
\]</span> This function evidently has two poles of order 1 at <span class="math inline">\(z = \pm i\)</span> with residues <span class="math display">\[
\begin{align*}
c_{-1} &amp;= - \frac{i}{2e} \ \text{when} \ z = i \ , \\
c_{-1} &amp;= \frac{ie}{2} \ \text{when} \ z = -i \ . \\
\end{align*}
\]</span> Now, we want to relate the complex integral to the real integral we wish to evaluate. To do this, what we can do is choose a closed contour that traverses the real line and then circles back over in a semi-circle to close the path. We’ll thus express the closed contour in two pieces: one piece <span class="math inline">\(\mathcal{R}\)</span> that runs from <span class="math inline">\(-R\)</span> to <span class="math inline">\(R\)</span> on the real axis, and another piece <span class="math inline">\(\mathcal{S}\)</span> that connects <span class="math inline">\(z=R\)</span> to <span class="math inline">\(z=-R\)</span> via a semicircular of radius <span class="math inline">\(R\)</span> in the upper half plane. See the figure below to get an idea.</p>
<p>FIGURE</p>
<p>This means the closed loop integral breaks up into two pieces, <span class="math display">\[
\oint dz \ \frac{e^{iz}}{z^2 + 1} = \int_{-R}^R dz \ \frac{e^{iz}}{z^2 + 1} + \int_\mathcal{S} dz \ \frac{e^{iz}}{z^2 + 1} \ .
\]</span> Notice now that if we send <span class="math inline">\(R \rightarrow \infty\)</span> and take the real part that the first integral on the right-hand side just gives us back the integral we wish to evaluate, which is what we want, <span class="math display">\[
\int_{-\infty}^\infty dx \ \frac{\cos x}{x^2 + 1} = \text{Re} \lim_{R \rightarrow \infty} \int_{-R}^R dz \ \frac{e^{iz}}{z^2 + 1} \ .
\]</span> We now need to evaluate the contour integral using the residue theorem. We’ll suppose that <span class="math inline">\(R &gt; 1\)</span> since we’re going to send it to infinity anyway. This means the only residue contained inside the closed loop above is at <span class="math inline">\(z=i\)</span>, so we have <span class="math display">\[
\oint dz \ \frac{e^{iz}}{z^2 + 1} = 2\pi i \bigg(- \frac{i}{2e}\bigg) = \frac{\pi}{e} \ .
\]</span> To deal with the contour integral along the semi-circular arc <span class="math inline">\(\mathcal{S}\)</span>, we can parametrize the arc by letting <span class="math inline">\(z = R e^{i\varphi}\)</span>, where <span class="math inline">\(\varphi\)</span> is an angle parameter that runs from <span class="math inline">\(\varphi = 0\)</span> to <span class="math inline">\(\varphi = \pi\)</span>. We then have <span class="math display">\[
\int_\mathcal{S} dz \ \frac{e^{iz}}{z^2 + 1} = \int_0^\pi d\varphi \ \frac{e^{i z(\varphi)}}{z^2(\varphi) + 1} \frac{dz}{d\varphi} =
\int_0^\pi d\varphi \ \frac{\exp(iRe^{i\varphi})}{(Re^{i\varphi})^2 + 1} (i R e^{i\varphi}) \ .
\]</span> Now, if we let <span class="math inline">\(R \rightarrow \infty\)</span> this integral will go to zero, since <span class="math inline">\(|e^{iz}| = 1\)</span> and hence <span class="math display">\[
\bigg |\int_0^\pi d\varphi \ \frac{\exp(iRe^{i\varphi})}{(Re^{i\varphi})^2 + 1} (i R e^{i\varphi}) \bigg | \sim \frac{R}{R^2 + 1} \rightarrow 0 \ .
\]</span> Putting this all together, as <span class="math inline">\(R \rightarrow \infty\)</span> we’re left with <span class="math display">\[
\int_{-\infty}^\infty dz \ \frac{e^{iz}}{z^2 + 1} = \frac{\pi}{e} \ .
\]</span> Finally, taking the real part of both sides, we have our answer for the original integral we sought to evaluate, <span class="math display">\[
\int_{-\infty}^\infty dx \ \frac{\cos x}{x^2 + 1} = \frac{\pi}{e} \ .
\]</span></p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation column-page-right">
  <div class="nav-page nav-page-previous">
      <a href="../classical-mechanics/continuum-mechanics.html" class="pagination-link" aria-label="Continuum Mechanics">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">Continuum Mechanics</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../electrodynamics/electrostatics.html" class="pagination-link" aria-label="Electrostatics">
        <span class="nav-page-text"><span class="chapter-title">Electrostatics</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>