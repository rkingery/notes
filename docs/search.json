[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Personal Notes",
    "section": "",
    "text": "Preface\nThis page contains notes I’ve taken over time for several different subjects of interest. Currently these subjects include\n\nClassical Mechanics\nElectrodynamics\nCircuit Analysis\nQuantum Mechanics\nStatistical Mechanics\n\nFeel free to use whatever you find helpful.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "classical-mechanics/newtonian-mechanics.html",
    "href": "classical-mechanics/newtonian-mechanics.html",
    "title": "Newtonian Mechanics",
    "section": "",
    "text": "Point Particles\nIn nature, an object is made of matter. It can be composed of many different molecules arranged in intricate and complicated ways. Further, each molecule is itself made of atoms, and each atom is itself made up of subatomic particles. Trying to model the motion of an object would be extremely cumbersome if we insisted on modeling the dynamics of each subatomic particle.\nInstead, it’s convenient to make abstractions. The most convenient abstraction to make is that we can describe the global behavior of an object as if it were a point object with no width. It can’t spin or deform. It’s one indivisible thing. We call these point particles.\nWe’ll think of a point particle as following some trajectory in the 3-dimensional Euclidean space \\(\\mathbb{R}^{3}\\). The trajectory or position is a time-dependent vector\n\\[\n\\mathbf{x}(t) = x(t)\\mathbf{e}_x + y(t)\\mathbf{e}_y + z(t)\\mathbf{e}_z.\n\\] A moving particle also has associated to it a velocity vector given by\n\\[\n\\mathbf{v} = \\mathbf{\\dot x} = \\frac{d\\mathbf{x}}{dt}.\n\\] Perhaps the most fundamental goal of classical mechanics is to find these two vectors as a function of time. In the Newtonian formulation, if we want to find a particle’s trajectory, we start with the particle’s acceleration vector \\[\n\\mathbf{a} = \\mathbf{\\dot v} = \\mathbf{\\ddot x} = \\frac{d^2\\mathbf{x}}{dt^2},\n\\] and match it with the force vector \\(\\mathbf{F}\\) via Newton’s Second Law to get a second-order differential equation for \\(\\mathbf{x}(t)\\).",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Newtonian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/newtonian-mechanics.html#newtons-laws",
    "href": "classical-mechanics/newtonian-mechanics.html#newtons-laws",
    "title": "Newtonian Mechanics",
    "section": "Newton’s Laws",
    "text": "Newton’s Laws\nNewton’s Laws efficiently encapsulate the fundamental physics of classical mechanics. They’re stated below specifically for a point particle, or body, but can be extended to more complex systems as well.\n\nA body remains at rest, or in motion at a constant speed in a straight line, unless acted upon by a force. That is,\n\\[\n\\mathbf{F} = \\mathbf{0} \\Rightarrow \\mathbf{v}=const.\n\\]\nWhen a body is acted upon by a force, the time rate of change of its acceleration is proportional to the force. That is, \\[\n\\mathbf{F} = m \\mathbf{a}.\n\\]\nIf two bodies exert forces on each other, these forces have the same magnitude but opposite directions. That is, \\[\n\\mathbf{F}_{12} = \\mathbf{F}_{21}.\n\\]\n\n\n\n\n\n\nForces are vectors, which means they obey the superposition principle, and can be analyzed in components. Position, velocity, and acceleration are vectors as well. The proportionality constant between \\(\\mathbf{F}\\) and \\(\\mathbf{a}\\) is called the mass \\(m\\). Loosely speaking, the mass of an object is a measure of its inertia or resistance to motion.\nThe functional form of the forces themselves depend on the particular type of forces applied. Some common forces are:\n\nGravitational Force: \\(\\mathbf{F} = -\\frac{GMm}{r^2} \\mathbf{e}_r\\)\nCoulomb Force: \\(\\mathbf{F} = k_e \\frac{Qq}{r^2} \\mathbf{e}_r\\)\nHarmonic Oscillator: \\(\\mathbf{F} = -k\\mathbf{x}\\)\nLorentz Force: \\(\\mathbf{F} = q\\mathbf{E} + \\frac{q}{c}\\mathbf{v} \\times \\mathbf{B}\\)\nThrust: \\(\\mathbf{F} = - |\\mathbf{v}_{ex}| \\dot m \\mathbf{e}_v\\)\n\n\n\n\n\nNormal Forces: \\(\\mathbf{F} = \\mathbf{N}\\)\nTension Forces: \\(\\mathbf{F} = \\mathbf{T}\\)\nFrictional Forces: \\(\\mathbf{F} = -\\mu |\\mathbf{N}| \\mathbf{e}_v\\)\nDrag Forces: \\(\\mathbf{F} = -f(\\mathbf{v}) \\mathbf{e}_v \\approx -a\\mathbf{v} -b|\\mathbf{v}|^2\\mathbf{e}_v\\)\nCentrifugal Forces: \\(\\mathbf{F} = m\\boldsymbol{\\omega} \\times (\\mathbf{x} \\times \\boldsymbol{\\omega})\\)\nCoriolis Forces: \\(\\mathbf{F} = 2m \\mathbf{v} \\times \\boldsymbol{\\omega}\\)\nBuoyant Forces: \\(\\mathbf{F} = - \\rho_{liq} V_{sub} \\mathbf{g}\\)",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Newtonian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/newtonian-mechanics.html#conservation-laws",
    "href": "classical-mechanics/newtonian-mechanics.html#conservation-laws",
    "title": "Newtonian Mechanics",
    "section": "Conservation Laws",
    "text": "Conservation Laws\nA quantity Q is said to be conserved if its time derivative is zero, \\(\\dot Q = 0\\). That is, Q is conserved it it’s constant in time.\n\nMomentum\nFor an object moving at velocity \\(\\mathbf{v}\\), define its linear momentum \\(\\mathbf{p}\\) by\n\\[\n\\mathbf{p} = m \\mathbf{v}.\n\\] If the mass \\(m\\) is constant, we evidently have \\[\n\\mathbf{F} = \\mathbf{\\dot p}.\n\\] If \\(\\mathbf{F} = \\mathbf{0}\\), then \\(\\mathbf{p}=const\\), hence momentum is conserved if there are no forces applied. This is the conservation of momentum.\n\n\nAngular Momentum\nDefine the angular momentum \\(\\mathbf{L}\\) of an object by \\[\n\\mathbf{L} = \\mathbf{x} \\times \\mathbf{p}.\n\\] Similarly, define the torque or moment \\(\\mathbf{N}\\) by \\[\\mathbf{N} = \\mathbf{x} \\times \\mathbf{F}.\\]\nNote both angular momentum and torque depend on the choice of coordinate system used since the position vector \\(\\mathbf{x}\\) depends on choice of origin. Now, observe that \\[\n\\mathbf{\\dot L} = \\mathbf{\\dot x} \\times \\mathbf{p} + \\mathbf{x} \\times \\mathbf{\\dot p} = m \\mathbf{v} \\times \\mathbf{v} + \\mathbf{x} \\times \\mathbf{F} = \\mathbf{N}.\n\\] Thus, \\(\\mathbf{N} = \\mathbf{\\dot L}\\). If \\(\\mathbf{N} = \\mathbf{0}\\), then \\(\\mathbf{L}=const\\), hence angular momentum must be conserved if there are no torques applied. This is the conservation of angular momentum.\n\n\nWork and Energy\nDefine the work done on an object as it moves along a path \\(\\gamma\\) from \\(A\\) to \\(B\\) by\n\\[\nW = \\int_A^B \\mathbf{F} \\cdot d\\mathbf{x}.\n\\]\n\n\n\n\n\nIn general, work depends on the path taken to get from \\(A\\) to \\(B\\), hence it isn’t a unique property of the system.\nObserve that \\[\ndW = \\mathbf{F} \\cdot d\\mathbf{x} = \\mathbf{F} \\cdot \\mathbf{v} dt = d\\bigg(\\frac{1}{2}m\\mathbf{v}^2 \\bigg).\n\\] Define the kinetic energy of the system by \\(T = \\frac{1}{2} m \\mathbf{v}^2\\). Then we evidently have \\(dW=dT\\). That is, the work done on the system to get from \\(A\\) to \\(B\\) via \\(\\gamma\\) is just the change in kinetic energy between \\(A\\) and \\(B\\), \\[\nW = \\Delta T = T_B - T_A.\n\\] When the work done is independent of the path taken it’s a state function of the kinetic energy. In this case, the force \\(\\mathbf{F}\\) is said to be conservative.\nBy the Helmholtz theorem, the following conditions are all equivalent:\n\n\\(\\mathbf{F}\\) is conservative,\n\\(W\\) is path-independent,\n\\(\\nabla \\times \\mathbf{F} = \\mathbf{0}\\),\nThere is a scalar potential \\(V=V(\\mathbf{x})\\) such that \\(\\mathbf{F} = -\\nabla V\\).\n\nThe scalar potential \\(V\\) is called the potential energy of the system. Evidently, if \\(\\mathbf{F}\\) is conservative, we have \\[\nW = \\int_A^B \\mathbf{F} \\cdot d\\mathbf{x} = -\\int_A^B \\nabla V \\cdot d\\mathbf{x} = -\\int_A^B dV = V_A - V_B = -\\Delta V = \\Delta T.\n\\] That is, \\(\\Delta T + \\Delta V = 0\\). Define the total mechanical energy \\(E\\) of the system by \\[\nE = T + V.\n\\] Then \\(\\Delta E = \\Delta (T + V) = 0\\). That is, energy is conserved when the forces on the system are conservative. This is the conservation of energy.\nEnergy isn’t generally conserved if the forces aren’t conservative. Examples of non-conservative forces include any force that’s a function of velocity. These include dissipative forces like friction or drag, as well as magnetic forces.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Newtonian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/newtonian-mechanics.html#using-newtons-laws",
    "href": "classical-mechanics/newtonian-mechanics.html#using-newtons-laws",
    "title": "Newtonian Mechanics",
    "section": "Using Newton’s Laws",
    "text": "Using Newton’s Laws\nThe primary goal of mechanics is to understand how systems evolve with time. To understand a particle’s given trajectory in Newtonian Mechanics, we need to\n\nWrite down all the forces acting on the particle,\nUse \\(\\mathbf{F} = m \\mathbf{a}\\) to set up the equations of motion,\nSolve the equations of motion for the trajectory \\(\\mathbf{x}(t)\\), either analytically or (usually) numerically.\n\nHere are some examples.\n\n\nExample: Projectile motion\nSuppose a cannon is launched from the origin at an angle \\(\\theta\\) above the ground with initial velocity \\(\\mathbf{v}_0\\).\n\n\n\n\n\n\nWrite down the equations of motion. Assume drag is negligible.\nThe forces are \\(\\mathbf{F} = \\mathbf{g} = -g\\mathbf{e}_y\\). Then, \\[\n\\mathbf{a} = \\ddot x\\mathbf{e}_x + \\ddot y\\mathbf{e}_y = -g\\mathbf{e}_y \\quad \\Longrightarrow \\quad   \\ddot x = 0, \\ \\ \\ddot y = -mg.\n\\]\nFind the trajectory \\(\\mathbf{x}(t) = x(t)\\mathbf{e}_x + y(t)\\mathbf{e}_y\\).\nIntegrating each element twice gives \\[\n\\begin{align*}\nx(t) &= x_0 + v_{0x}t = v_0t \\cos \\theta, \\\\\ny(t) &= y_0 + v_{0y}t - \\frac{1}{2} gt^2 = v_{0}t\\sin \\theta - \\frac{1}{2} gt^2.\n\\end{align*}\n\\]\nFind the range, i.e. the value \\(R=x(T)\\) when the cannon hits the ground. Which launch angle maximizes the range?\nFirst, we need to find the time \\(T\\) when \\(y(T) = 0\\). Setting \\[\ny(T) = 0 = v_0 T \\sin \\theta - \\frac{1}{2} gT^2 \\Longrightarrow T = 0, \\frac{2v_0 \\sin \\theta}{g}.\n\\] The \\(T=0\\) case is trivial. Plugging the other one in to \\(x(T)\\) finally gives the range, \\[\nR = x(T) = v_0T \\cos \\theta = \\frac{2v_0^2 \\sin \\theta}{g} \\cos \\theta = \\frac{v_0^2 \\sin 2\\theta}{g}.\n\\] Note that the range is maximized when \\(\\sin 2 \\theta = 1\\), which is when the launch angle is \\(\\theta = 45^\\circ\\).\nFind the shape of the motion \\(y = y(x)\\).\nWe need to eliminate \\(t\\) in both equations and solve for \\(y=y(x(t))\\). Solving \\(x(t)\\) for \\(t\\) gives, \\[\nx = v_0 t\\cos \\theta \\Longrightarrow t = \\frac{x}{v_0 \\cos \\theta}.\n\\] Plugging this into \\(y\\) then gives \\[\ny = v_{0}\\frac{x}{v_0 \\cos \\theta}\\sin \\theta - \\frac{1}{2} g\\bigg(\\frac{x}{v_0 \\cos \\theta}\\bigg)^2 =  \\tan \\theta \\cdot x - \\frac{g}{2v_0^2 \\cos^2 \\theta} x^2.\n\\] This is a downward sloping parabola with vertex at \\(\\big(\\frac{v_0^2 \\sin 2\\theta}{2g}, \\frac{v_0^2 \\sin^2 \\theta}{g}\\big)\\).\nFind any conserved quantities.\n\nMomentum: Since \\(\\mathbf{F} \\neq \\mathbf{0}\\), momentum isn’t conserved. However, \\(p_x\\) is conserved.\nAngular Momentum: Since \\(\\mathbf{N} = \\mathbf{x} \\times \\mathbf{F} = \\mathbf{x} \\times m\\mathbf{g} \\neq 0\\), angular momentum is not conserved.\nEnergy: Since \\(V=mgy\\), the force \\(\\mathbf{F}\\) is conservative, hence energy is conserved.\n\n\n\n\n\nExample: Block sliding on a ramp with friction\nA block of mass \\(m\\) is sliding down a ramp inclined from the horizontal at an angle \\(\\theta\\). Assume the system has a coefficient of friction \\(\\mu\\), and that the block starts from rest at the top of the ramp.\n\n\n\n\n\n\nWrite down the equations of motion.\nChoose a coordinate system such that \\(x\\) is pointing downwards parallel to the ramp and \\(y\\) is pointing outwards perpendicular to the ramp. There are three forces acting, gravity, the normal force, and the frictional force, so \\[\n\\mathbf{F} = \\mathbf{N} + m\\mathbf{g} - \\mu \\mathbf{N} \\mathbf{e}_v = N\\mathbf{e}_y + mg(\\sin\\theta\\mathbf{e}_x - \\cos\\theta\\mathbf{e}_y) - \\mu N \\mathbf{e}_x.\n\\] Resolving into components, we have \\[\n\\begin{align*}\nm \\ddot x &= mg\\sin\\theta - \\mu N, \\\\\nm \\ddot y &= N - mg\\cos\\theta = 0.\n\\end{align*}\n\\] The second equation follows from the assumption that the block is constrained to stay on the ramp.\nFind the trajectory \\(\\mathbf{x}(t) = x(t)\\mathbf{e}_x + y(t)\\mathbf{e}_y\\).\nTo solve, we need to eliminate the normal force \\(N\\). Using the EOM for \\(\\ddot y\\), we get \\(N = mg\\cos\\theta\\). Plugging this into the equation for \\(\\ddot x\\) then gives\n\\[\n\\begin{align*}\n\\ddot x &= g(\\sin\\theta - \\mu\\cos\\theta) = const, \\\\\n\\ddot y &= 0.\n\\end{align*}\n\\] Suppose the block starts at the top of the ramp, which we’ll call the origin. Then integrating, we get,\n\\[\n\\begin{align*}\nx(t) &= v_0 t + \\frac{1}{2}g(\\sin\\theta - \\mu\\cos\\theta)t^2, \\\\\ny(t) &= 0.\n\\end{align*}\n\\] Notice \\(x(t)\\) is just the equation of an object falling under a modified gravity \\[\n\\mathbf{g}'=-g(\\sin\\theta - \\mu\\cos\\theta)\\mathbf{e}_x.\n\\]\nFind the angle \\(\\theta\\) at which the block will start sliding.\nThe block will move if \\(\\ddot x \\geq 0\\), i.e. when \\(\\mu \\leq \\tan\\theta\\). It will start moving at the angle when \\(\\tan\\theta=\\mu\\) exactly, i.e. when \\[\n\\theta = \\arctan\\mu.\n\\]\nFind any conserved quantities.\n\nMomentum: Since \\(\\mathbf{F} \\neq \\mathbf{0}\\), momentum is not conserved. However, \\(p_y\\) is conserved.\nAngular momentum: Since \\(\\mathbf{N} = \\mathbf{x} \\times \\mathbf{F} \\neq \\mathbf{0}\\), angular momentum is not conserved.\nEnergy: Since friction is present, \\(\\mathbf{F}\\) is a dissipative force, hence it’s not conservative, and energy is not conserved.\n\nFind the rate of energy dissipation as the block slides down the ramp.\nFriction dissipates as a heat \\(Q\\). If the block slides a distance \\(L\\), this means \\(E(0) = E(L) + Q\\). Since the block starts from rest, \\(E(0) = 0\\). At \\(x=L\\), the work done is \\[\nW = \\int_0^L F_x dx = \\int_0^L mg(\\sin\\theta - \\mu\\cos\\theta)dx = mgL(\\sin\\theta - \\mu\\cos\\theta) = T(L) - 0 = T(L),\n\\] so the energy when the block gets to the bottom is \\[\nE(L) = T(L) + V(L,0) = mgL(\\sin\\theta - \\mu\\cos\\theta) - mgL\\sin\\theta = -\\mu mgL\\cos\\theta.\n\\] Finally, using this to solve for \\(Q\\), the heat dissipated over the entire trajectory, we get \\[\nQ = E(0) - E(L) = \\mu mgL\\cos\\theta.\n\\] The most important sanity check here is to notice there’s no heat dissipation if there is no friction.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Newtonian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/newtonian-mechanics.html#curvilinear-coordinates",
    "href": "classical-mechanics/newtonian-mechanics.html#curvilinear-coordinates",
    "title": "Newtonian Mechanics",
    "section": "Curvilinear Coordinates",
    "text": "Curvilinear Coordinates\nFor many problems, it’s more convenient to take advantage of the underlying symmetry by using special coordinate systems. Other than rectangular coordinates \\((x,y,z)\\), the most common coordinate systems worth being familiar with are polar coordinates \\((r,\\varphi)\\), cylindrical coordinates \\((\\rho,\\varphi,z)\\), and spherical coordinates \\((r,\\theta,\\varphi)\\).\n\nPolar Coordinates\nFor problems with circular symmetry it’s convenient to use polar coordinates \\((r,\\varphi)\\), defined by\n\\[\n\\begin{align*}\nx &=  r\\cos\\varphi, \\\\\ny &=  r\\sin\\varphi. \\\\\n\\end{align*}\n\\] where \\(r \\geq 0\\) and \\(0 \\leq \\varphi \\leq 2\\pi\\). We can assign basis vectors to polar coordinates \\(\\mathbf{e}_r, \\mathbf{e}_\\varphi\\) to each point as usual.\n\n\n\n\n\nThe thing to keep in mind is that these curvilinear basis vectors are now functions of position,\n\\[\n\\begin{align*}\n\\mathbf{e}_r &= \\mathbf{e}_r(r, \\varphi), \\\\\n\\mathbf{e}_\\varphi &= \\mathbf{e}_\\varphi(r, \\varphi).\n\\end{align*}\n\\] We can figure out how these basis vectors change by taking their differentials, which follow from the figure above,\n\\[\n\\begin{align*}\nd\\mathbf{e}_r &= \\mathbf{e}_\\varphi d\\varphi, \\\\\nd\\mathbf{e}_\\varphi &= -\\mathbf{e}_r d\\varphi.\n\\end{align*}\n\\] Using these differential forms, we can conclude that the motion vectors change as follows,\n\\[\n\\begin{align*}\n\\mathbf{x} &= r\\mathbf{e}_r, \\\\\n\\mathbf{v} &= \\dot r \\mathbf{e}_r + r\\dot \\varphi \\mathbf{e}_\\varphi, \\\\\n\\mathbf{a} &= (\\ddot r - r\\dot \\varphi^2)\\mathbf{e}_r + (2\\dot r \\dot \\varphi + r\\ddot \\varphi)\\mathbf{e}_\\varphi.\n\\end{align*}\n\\]\n\n\nExample: Circular orbits\nSuppose an object moves in a circular orbit of radius \\(r\\) at a constant angular velocity \\(\\omega\\) due to a central force \\(\\mathbf{F} = -F\\mathbf{e}_r\\).\n\n\n\n\n\n\nFind the equations of motion. Since the object moves at constant \\(\\omega\\), we have \\(\\dot \\varphi = \\omega = const\\). Using the polar equations for velocity and acceleration, we have \\[\n\\begin{align*}\n\\mathbf{v} &= \\dot r \\mathbf{e}_r, \\\\\n\\mathbf{a} &= -r\\omega^2\\mathbf{e}_r + r \\dot \\omega\\mathbf{e}_\\varphi = - \\frac{F}{m}\\mathbf{e}_r.\n\\end{align*}\n\\] Note we can re-write these equations to get \\(F = m\\omega^2 r\\).\nFind the period \\(\\tau\\) of the orbit.\nWe want the time it takes for \\(\\Delta \\varphi = 2\\pi\\). Since \\(\\Delta \\varphi = \\omega\\tau\\), solving for \\(\\tau\\) gives \\[\\tau = \\frac{2\\pi}{\\omega}.\\]\nSuppose the central force is the gravitational force, \\(F = \\frac{GMm}{r^2}\\). Find the angular velocity, the period, and the orbital velocity as a function of \\(G, M, r\\).\nWe have \\[\nF = \\frac{GMm}{r^2} = m\\omega^2 r \\ \\Longrightarrow \\ \\omega = \\sqrt{\\frac{GM}{r^3}} \\ \\Longrightarrow \\ \\tau = \\frac{2\\pi}{\\sqrt{GM}} r^{3/2}.\n\\] This is just a special case of Kepler’s third law, \\(\\tau^2 \\propto r^3\\). The orbital velocity is given by \\[\nv = r\\omega = \\sqrt{\\frac{GM}{r}}.\n\\]\n\n\n\n\nExample: Simple pendulum\nConsider the problem of the simple pendulum, where a mass \\(m\\) swings on a massless string of length \\(\\ell\\) under the force of gravity. The string is fixed at one point. Assume no damping is present.\n\n\n\n\n\n\nFind the equations of motion from the forces directly.\nThere are two forces in this problem, gravity and the tension in the string, \\[\n\\mathbf{F} = \\mathbf{T} + m\\mathbf{g} = -T\\mathbf{e}_r + mg(\\cos\\theta \\mathbf{e}_r - \\sin\\theta\\mathbf{e}_\\theta).\n\\] Dividing by \\(m\\) and setting equal to the polar form of \\(\\mathbf{a}\\), we have \\[\n\\mathbf{a} = (-T+mg\\cos\\theta)\\mathbf{e}_r - mg\\sin\\theta\\mathbf{e}_\\theta = -m\\ell^2 \\dot \\theta^2 \\mathbf{e}_r + m\\ell^2 \\ddot \\theta \\mathbf{e}_\\theta.\n\\] This gives two equations of motion, one for the tension and one for the angular acceleration, \\[\n\\begin{align*}\nT &= m\\ell^2 \\dot\\theta^2 + mg\\cos\\theta, \\\\\n\\ddot \\theta &= -\\frac{g}{\\ell} \\sin\\theta. \\\\\n\\end{align*}\n\\]\nFind the equations of motion again, but this time using torques.\nRecall \\(\\mathbf{N} = I \\boldsymbol{\\dot \\omega}\\), where \\(I\\) is the scalar moment of inertia and \\(\\boldsymbol{\\omega}\\) is the angular velocity vector. In this case, \\(I=m\\ell^2\\) and \\(\\boldsymbol{\\dot \\omega} = \\ddot \\theta \\mathbf{e}_z\\). Then we have \\[\nI \\boldsymbol{\\dot \\omega} = m\\ell^2 \\ddot \\theta \\mathbf{e}_z \\equiv \\ell\\mathbf{e}_r \\times m\\mathbf{g} = -mg\\ell\\sin\\theta \\mathbf{e}_z = \\mathbf{N},\n\\] which can be solve to get \\(\\ddot \\theta = -\\frac{g}{\\ell}\\sin\\theta\\). Notice how in this approach we don’t need to worry about the tension at all.\nSuppose \\(\\theta\\) is small. Write down the equations of motion, solve them, and find the period.\nWhen \\(\\theta \\ll 1\\) the small angle approximation applies, \\(\\sin\\theta \\approx \\theta\\). In this case, the equation of motion reduces to \\[\\ddot \\theta = -\\frac{g}{\\ell} \\theta,\\] which is just simple harmonic oscillation with angular frequency \\(\\omega = \\sqrt{\\frac{g}{\\ell}}\\). The solution to SHO is \\[\n\\theta(t) = A\\sin(\\omega t + \\phi),\n\\] where \\(A\\) is some amplitude and \\(\\phi\\) is some phase determined by the initial conditions. Finally, solving for the period, we have \\[\n\\tau = \\frac{2\\pi}{\\omega} = 2\\pi\\sqrt{\\frac{\\ell}{g}}.\n\\]\n\n\n\n\n\nCylindrical Coordinates\nCylindrical coordinates extend polar coodinates by adding in the z-axis from the rectangular system,\n\\[\n\\begin{align*}\nx &=  r\\cos\\varphi, \\\\\ny &=  r\\sin\\varphi, \\\\\nz &= z.\n\\end{align*}\n\\] The basis vectors are \\(\\mathbf{e}_r, \\mathbf{e}_\\varphi, \\mathbf{e}_z\\). Their differential forms are just \\[\n\\begin{align*}\nd\\mathbf{e}_r &= \\mathbf{e}_\\varphi d\\varphi, \\\\\nd\\mathbf{e}_\\varphi &= -\\mathbf{e}_r d\\varphi \\\\\nd\\mathbf{e}_z &= 0.\n\\end{align*}\n\\] The motion vectors in cylindrical coordinates are thus given by, \\[\n\\begin{align*}\n\\mathbf{x} &= r\\mathbf{e}_r, \\\\\n\\mathbf{v} &= \\dot r \\mathbf{e}_r + r\\dot \\varphi \\mathbf{e}_\\varphi + \\dot z \\mathbf{e}_z , \\\\\n\\mathbf{a} &= (\\ddot r - r\\dot \\varphi^2)\\mathbf{e}_r + (2\\dot r \\dot \\varphi + r\\ddot \\varphi)\\mathbf{e}_\\varphi + \\ddot z \\mathbf{e}_z.\n\\end{align*}\n\\]\n\n\nSpherical Coordinates\nSpherical coordinates extend polar coordinates in a slightly different way. The radius \\(r\\) is now 3-dimensional, and there are two angles, a polar angle \\(0 \\leq \\theta \\leq \\pi\\) and an azimuthal angle \\(0 \\leq \\varphi \\leq 2\\pi\\). The conversion to rectangular coordinates is given by, \\[\n\\begin{align*}\nx &=  r\\sin\\theta\\cos\\varphi, \\\\\ny &=  r\\sin\\theta\\sin\\varphi, \\\\\nz &= r\\cos\\theta. \\\\\n\\end{align*}\n\\] The basis vectors are \\(\\mathbf{e}_r, \\mathbf{e}_\\theta, \\mathbf{e}_\\varphi\\). Deriving the differential forms of these is a good bit more complex. Here they are, \\[\n\\begin{aligned}\nd\\mathbf{e}_r &= \\dot\\theta \\sin\\varphi d\\mathbf{e}_\\theta + \\dot\\varphi d\\mathbf{e}_\\varphi, \\\\\nd\\mathbf{e}_\\theta &= - \\dot\\theta \\sin\\varphi d\\mathbf{e}_r - \\dot\\theta \\cos\\varphi d\\mathbf{e}_\\varphi, \\\\\nd\\mathbf{e}_\\varphi &= - \\dot\\varphi \\mathbf{e}_r + \\dot\\theta \\cos\\varphi \\mathbf{e}_\\theta. \\\\\n\\end{aligned}\n\\] These can then be used to get the motion vectors in spherical coordinates, \\[\n\\begin{align*}\n\\mathbf{r} &= r \\mathbf{e}_r, \\\\\n\\mathbf{v} &= \\dot{r} \\mathbf{e}_r + r \\dot\\theta \\sin\\varphi \\mathbf{e}_{\\theta} + r \\dot\\varphi \\mathbf{e}_{\\varphi}, \\\\\n\\mathbf{a} &= (\\ddot{r} - r \\dot{\\theta}^2 \\sin^2\\varphi - r \\dot{\\varphi}^2) \\mathbf{e}_r \\\\\n&\\quad + (r \\ddot\\theta \\sin\\varphi + 2 \\dot{r} \\dot\\theta \\sin\\varphi + 2 r \\dot\\theta \\dot\\varphi \\cos\\varphi) \\mathbf{e}_{\\theta} \\\\\n&\\quad + (r \\ddot\\varphi + 2 \\dot{r} \\dot\\varphi - r \\dot{\\theta}^2 \\sin\\varphi \\cos\\varphi) \\mathbf{e}_{\\varphi}. \\\\\n\\end{align*}\n\\]",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Newtonian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/newtonian-mechanics.html#many-particle-systems",
    "href": "classical-mechanics/newtonian-mechanics.html#many-particle-systems",
    "title": "Newtonian Mechanics",
    "section": "Many-Particle Systems",
    "text": "Many-Particle Systems\nThus far we’ve worked with single-particle systems. Let’s now consider a system of \\(N\\) particles with positions \\(\\mathbf{x}_1, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N\\) respectively. We can use the principle of superposition to extend the laws derived above for single particles.\nFor \\(N\\)-particle systems it’s convenient to characterize the system’s position using the center of mass vector \\(\\mathbf{R}\\), \\[\n\\mathbf{R} \\equiv \\frac{1}{M}\\sum_{i=1}^N m_i \\mathbf{x}_i,\n\\] where \\(M\\) is just the total mass of the system, \\(M \\equiv \\sum m_i\\). The center of mass is just the mass-weighted average of all the particle position vectors.\nSuppose an external force \\(\\mathbf{F}^{ext}\\) is acting on the system, and suppose each particle \\(i\\) imparts a force \\(\\mathbf{F}_{ij}\\) on particle \\(j \\neq i\\). Here’s what this would look like for \\(N=3\\) particles.\n\n\n\n\n\nBy superposition, the total force acting on the entire system is thus, \\[\n\\mathbf{F} = \\mathbf{F}^{ext} + \\sum_{i \\neq j} \\mathbf{F}_{ij} = \\sum m_i \\mathbf{a}_i = M\\mathbf{\\ddot R}.\n\\] Now, by Newton’s third law, \\(\\mathbf{F}_{ij} = -\\mathbf{F}_{ji}\\). This means all the internal forces cancel in pairs, so we have \\[\n\\mathbf{F}^{ext} = M\\mathbf{\\ddot R}.\n\\] That is, the system as a whole moves as if it were a point mass \\(M\\) with an external force \\(\\mathbf{F}^{ext}\\) acting on its center of mass \\(\\mathbf{R}\\).\nIf the total momentum is defined as \\(\\mathbf{P} = M \\mathbf{\\dot R}\\), this expression then says \\(\\mathbf{F}^{ext} = \\mathbf{\\dot P}\\). Thus, if no external forces act on the system, then its total linear momentum \\(\\mathbf{P}\\) is conserved.\nLet’s now consider the total torques on the system. Suppose the system experiences an external torque \\(\\mathbf{N}^{ext}\\), and that each particle \\(i\\) exerts a torque \\(\\mathbf{N}_{ij}\\) on particle \\(j\\). Then by superposition, the total torque on the system is \\[\n\\mathbf{N} = \\mathbf{N}^{ext} + \\sum_{i \\neq j} \\mathbf{N}_{ij} = \\mathbf{N}^{ext} + \\sum_{i \\neq j} \\mathbf{x}_i \\times \\mathbf{F}_{ij},\n\\] Again, we can use the fact that each \\(\\mathbf{F}_{ij} = -\\mathbf{F}_{ji}\\). If we do this, we can re-write the total torque as\n\\[\n\\mathbf{N} = \\mathbf{N}^{ext} + \\sum_{i&lt;j} (\\mathbf{x}_{i}-\\mathbf{x}_{j}) \\times \\mathbf{F}_{ij} = \\mathbf{N}^{ext}.\n\\] Now, if we further assume that each internal force acts centrally, i.e. \\(\\mathbf{F}_{ij} = \\mathbf{F}_{ij}(\\mathbf{x}_{i}-\\mathbf{x}_{j})\\), then the internal cross products all vanish, and we just get \\(\\mathbf{N} = \\mathbf{N}^{ext}\\). That is, if all the internal forces are central, then the total torque on the system is just the external torque.\nIf the total angular momentum on the system is defined as \\(\\mathbf{L} = \\mathbf{R} \\times \\mathbf{P}\\), this expression says \\(\\mathbf{\\dot L} = \\mathbf{N}^{ext}\\). Thus, if no external torques act on the system, then its total angular momentum \\(\\mathbf{L}\\) is conserved.\nIt’s insightful to separate each particle’s motion vectors explicitly into a center of mass component and a relative component,\n\\[\n\\begin{align*}\n\\mathbf{x}_i &= \\mathbf{R} + \\boldsymbol{\\mathscr{r}}_i, \\\\\n\\mathbf{v}_i &= \\mathbf{V} + \\boldsymbol{\\mathscr{v}}_i. \\\\\n\\end{align*}\n\\]\n\n\n\n\n\nLet’s re-write the total angular momentum \\(\\mathbf{L}\\) in terms of these vectors,\n\\[\n\\begin{align*}\n\\mathbf{L} &= \\sum \\mathbf{x}_i \\times \\mathbf{p}_i = \\sum (\\mathbf{R} + \\boldsymbol{\\mathscr{r}}_i) \\times m_i(\\mathbf{V} + \\boldsymbol{\\mathscr{v}}_i) \\\\\n&= M\\mathbf{R} \\times \\mathbf{V} + \\sum m_i \\boldsymbol{\\mathscr{r}}_i \\times \\boldsymbol{\\mathscr{v}}_i + \\mathbf{R} \\times \\bigg(\\sum m_i \\boldsymbol{\\mathscr{v}}_i \\bigg) + \\bigg(\\sum m_i \\boldsymbol{\\mathscr{r}}_i \\bigg)\\times \\mathbf{V} \\\\\n&= \\mathbf{R} \\times \\mathbf{P} + \\sum m_i \\boldsymbol{\\mathscr{r}}_i \\times \\boldsymbol{\\mathscr{v}}_i \\\\\n&\\equiv \\mathbf{L}^{orb} + \\mathbf{L}^{spin}. \\\\\n\\end{align*}\n\\] We’ve thus been able to separate the angular momentum into two components, an orbital angular momentum \\(\\mathbf{L}^{orb} = \\mathbf{R} \\times \\mathbf{P}\\), and a spin angular momentum \\(\\mathbf{L}^{spin} = \\sum m_i \\boldsymbol{\\mathscr{r}}_i \\times \\boldsymbol{\\mathscr{v}}_i\\). The orbital angular momentum describes how the center of mass of the object tends to rotate about some external point. The spin angular momentum describes how the system itself tends to rotate about its center of mass.\n\n\n\n\n\nLast, let’s look at the total energies of the system. For a system with \\(N\\) particles, the potential energy will be a function of all the position vectors, \\(V = V(\\mathbf{x}_1, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N)\\). It won’t generally simplify. But the kinetic energy we can simplify. Writing it in terms of its relative and center of mass velocities, we have\n\\[\n\\begin{align*}\nT &= \\frac{1}{2}\\sum m_i \\mathbf{v}_i^2 = \\sum m_i (\\mathbf{V} + \\boldsymbol{\\mathscr{v}}_i)^2 \\\\\n&= \\frac{1}{2}M\\mathbf{V}^2 + \\frac{1}{2}\\sum m_i\\boldsymbol{\\mathscr{v}}_i^2 + \\mathbf{V} \\cdot \\bigg(\\sum m_i \\boldsymbol{\\mathscr{v}}_i\\bigg) \\\\\n&= \\frac{1}{2}M\\mathbf{V}^2 + \\frac{1}{2}\\sum m_i\\boldsymbol{\\mathscr{v}}_i^2 \\\\\n&= T^{CM} + T^{rel}.\n\\end{align*}\n\\] Thus, the kinetic energy separates into a sum of the kinetic energy on the center of mass \\(T^{CM} = \\frac{1}{2}M\\mathbf{V}^2\\), and the kinetic energy of the relative components \\(T^{rel} = \\frac{1}{2}\\sum m_i\\boldsymbol{\\mathscr{v}}_i^2\\). Evidently, the total energy is \\[\nE = T + V = T^{CM} + T^{rel} + V(\\mathbf{x}_1, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N).\n\\] It’s conserved provided the external force \\(\\mathbf{F}^{ext}\\) is conservative.\n\n\nExample: Rockets\nSuppose a rocket of mass \\(m_0=m(t) + m_{ex}(t)\\) is moving through free space with no external forces acting on it. It’s expelling fuel for trust at some constant speed \\(v_{ex}\\) with respect to the rocket.\n\n\n\n\n\n\nWhat is the force of thrust on the rocket?\nNo external forces are present, so \\(\\mathbf{F}^{ext} = \\mathbf{0}\\). The internal forces are the thrust of the rocket, and the force of the exhaust. In the frame of the rocket they cancel out, \\(\\mathbf{F}_{th} = \\mathbf{F}_{ex}\\), so we have \\[\n\\mathbf{F}_{th} = -\\mathbf{F}_{ex} = -\\mathbf{\\dot p}_{ex} = -\\frac{d}{dt}(m_{ex} \\mathbf{v}_{ex}) = -\\dot m_{ex} \\mathbf{v}_{ex}.\n\\] Now, since \\(m_0 = m + m_{ex}\\), \\(\\dot m = -\\dot m_{ex}\\), and \\(\\mathbf{v}_{ex} = -v_{ex}\\mathbf{e}_v\\), we have \\[\n\\mathbf{F}_{th} = -\\dot m v_{ex} \\mathbf{e}_v.\n\\]\nFind the velocity \\(\\mathbf{v}(t)\\) of the rocket.\nUsing the fact that \\(\\mathbf{F}_{th} = m\\mathbf{a}\\), we have \\(-\\dot m v_{ex} = m \\dot v\\), a first-order differential equation in \\(v(t)\\), \\[\n\\dot v + v_{ex} \\frac{\\dot m}{m} = 0.\n\\] Integrating both sides and solving for \\(v(t)\\), we get \\[\nv(t) = v_0 - v_{ex} \\int_{m_0}^m \\frac{dm}{m} = -v_{ex} \\log \\frac{m(t)}{m_0}.\n\\] Or, expressing in the form of the well-known rocket equation, \\[\n\\Delta v = v_{ex} \\log\\frac{m_0}{m(t)}.\n\\]\nFind the position \\(\\mathbf{x}(t)\\) of the rocket, assuming fuel is expelled form the rocket at a constant rate.\nAssume \\(\\dot m = -k = const\\). Since there are no external forces, the rocket must be traveling along some line. Suppose without loss of generality then that \\(\\mathbf{x}(t) =  z(t)\\mathbf{e}_z\\). Then we have, \\[\n\\begin{align*}\nz(t) &= \\int_0^t v(t) dt = v_{ex} \\int_0^t dt \\log\\frac{m_0}{m_0-kt} \\\\\n&= v_{ex} \\bigg[t - \\bigg(\\frac{m_0-kt}{k} \\bigg) \\log \\bigg(\\frac{m_0}{m_0-kt} \\bigg) \\bigg] \\\\\n&= v_{ex} t - \\frac{v_{ex}}{k}(m_0 - kt)\\log\\bigg(\\frac{m_0}{m_0-kt} \\bigg).\n\\end{align*}\n\\]",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Newtonian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/simple-systems.html",
    "href": "classical-mechanics/simple-systems.html",
    "title": "Simple Systems",
    "section": "",
    "text": "Independent Forces\nThe first and simplest case we’ll consider are forces that don’t depend on position or velocity, \\[\nm \\mathbf{a} = \\mathbf{F}_0(t).\n\\] We can solve these systems directly by integrating both sides, i.e. reducing to quadrature. We have,\n\\[\n\\begin{align*}\n\\mathbf{a}(t) &= \\frac{1}{m}\\mathbf{F}_0(t), \\\\\n\\mathbf{v}(t) &= \\mathbf{v}_0 + \\frac{1}{m}\\int_0^t dt'\\mathbf{F}_0(t'), \\\\\n\\mathbf{x}(t) &= \\mathbf{x}_0 + \\mathbf{v}_0t + \\frac{1}{m}\\int_0^t dt' \\int_0^{t'} dt''\\mathbf{F}_0(t''). \\\\\n\\end{align*}\n\\] The simplest of these cases are when there are no forces at all, and when the forces are constant. If there are no forces at all acting on the system, \\(\\mathbf{F}_0 = \\mathbf{0}\\), in which case the equations of motion reduce to\n\\[\n\\begin{align*}\n\\mathbf{a}(t) &= 0, \\\\\n\\mathbf{v}(t) &= \\mathbf{v}_0, \\\\\n\\mathbf{x}(t) &= \\mathbf{x}_0 + \\mathbf{v}_0t. \\\\\n\\end{align*}\n\\] This is just a statement of Newton’s First Law. If no forces act on a particle, it continues linearly along its path at constant velocity. The next simplest case is when \\(\\mathbf{F}_0=const\\). In this case, the equations of motion become\n\\[\n\\begin{align*}\n\\mathbf{a}(t) &= \\frac{1}{m}\\mathbf{F}_0, \\\\\n\\mathbf{v}(t) &= \\mathbf{v}_0 + \\frac{1}{m}\\mathbf{F}_0 t, \\\\\n\\mathbf{x}(t) &= \\mathbf{x}_0 + \\mathbf{v}_0t + \\frac{1}{2m^2}\\mathbf{F}_0^2. \\\\\n\\end{align*}\n\\] This case includes the gravitional force near the surface of the Earth, in which case \\(\\mathbf{F}_0=m\\mathbf{g}\\). It also includes the problem of an electric charge placed close to a large conducting sheet with a uniform electric field, where \\(\\mathbf{F}_0=q\\mathbf{E}_0\\).\nIn these problems, the motion will always be along a parabolic arc. The parabola will slope toward the force if the force is attractive, and away from the force if it’s repulsive.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Simple Systems</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/simple-systems.html#independent-forces",
    "href": "classical-mechanics/simple-systems.html#independent-forces",
    "title": "Simple Systems",
    "section": "",
    "text": "Example: Free-fall near Earth\nSuppose an object of mass \\(m\\) is falling freely near the Earth’s surface. In this case, \\(\\mathbf{F}_0 = m\\mathbf{g}\\), so\n\\[\n\\begin{align*}\n\\mathbf{a}(t) &= \\mathbf{g}, \\\\\n\\mathbf{v}(t) &= \\mathbf{v}_0 - \\mathbf{g}t, \\\\\n\\mathbf{x}(t) &= \\mathbf{x}_0 + \\mathbf{v}_0t + \\frac{1}{2}\\mathbf{g}t^2.\n\\end{align*}\n\\] The motion in this case will always lie in the plane spanned by \\(\\mathbf{v}_0\\) and \\(\\mathbf{g}\\). This means without loss of generality we can assume motion lies in the xy-plane with \\(\\mathbf{g} = -g\\mathbf{e}_y\\). Then \\(y\\) can be solved as a function of \\(x\\) to give \\[\ny(x) = v_{0}\\frac{x}{v_0 \\cos \\theta}\\sin \\theta - \\frac{1}{2} g\\bigg(\\frac{x}{v_0 \\cos \\theta}\\bigg)^2,\n\\] which is of course a downward-sloping parabola centered at the vertex \\(\\big(\\frac{v_0^2 \\sin 2\\theta}{2g}, \\frac{v_0^2 \\sin^2 \\theta}{g}\\big)\\).",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Simple Systems</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/simple-systems.html#drag-forces",
    "href": "classical-mechanics/simple-systems.html#drag-forces",
    "title": "Simple Systems",
    "section": "Drag Forces",
    "text": "Drag Forces\nThe next type of forces we’ll consider are those which are functions of velocity,\n\\[\nm\\mathbf{a} = \\mathbf{F}(\\mathbf{v}).\n\\] In the 1-dimensional case, this reduces to,\n\\[\nma = F(v).\n\\] Provided \\(v\\) is small, we can approximate \\(F(v)\\) by its first few terms. I’ll write it as,\n\\[\nF(v) \\approx a - bv - cv^2.\n\\] Typically, drag forces shouldn’t apply a force when the particle is at rest, which means \\(a=0\\). The remaining two terms cover two distinct regimes of drag:\n\nLinear or viscous drag: \\(F(v) = -bv\\), where \\(b &gt; 0\\).\nQuadratic or air drag: \\(F(v) = -cv^2\\), where \\(c &gt; 0\\).\n\n\nLinear Drag\nIt’s convenient to analyze these two distinct cases separately. Let’s first look at linear drag. In that case \\(c=0\\), and we end up with the linear differential equation \\[\nm \\ddot x + b \\dot x = 0.\n\\] To solve this equation, re-write it in terms of \\(v = \\dot x\\),\n\\[\n\\frac{dv}{dt} = -\\frac{b}{m} v.\n\\] Integrating both sides, we get\n\\[\nv(t) = v_0 e^{-\\frac{b}{m} t}.\n\\] For \\(x(t)\\) just integrate both sides again to get\n\\[\nx(t) = x_0 + \\int_0^t v_0 e^{-\\frac{b}{m} t'} dt' = x_0 + \\frac{mv_0}{b}\\big(1 - e^{-\\frac{b}{m} t}\\big).\n\\] Evidently, such forces cause a moving particle to slowly come to rest, since \\(v \\rightarrow 0\\) as \\(t \\rightarrow \\infty\\). The position where the particle comes to rest is evidently \\(x_f = x_0 + \\frac{mv_0}{b}\\). The \\(\\frac{1}{e}\\) decay time is \\(\\tau = \\frac{m}{b}\\). This suggests that \\(b\\) functions as a sort of drag coefficient, since a large \\(b\\) causes the system to dissipate faster.\n\n\n\n\n\nLinear drag is frequently used to model objects moving through a viscous medium at low speeds. Suppose a spherical object of radius \\(R\\) is moving slowly in a viscous medium with viscosity \\(\\eta\\). Then the drag force on the object is given by Stokes’ Law,\n\\[\n\\mathbf{F}_d = -6\\pi\\eta R \\mathbf{v}.\n\\] This force is linear in velocity, hence we can write \\(F_d = -6\\pi\\eta R v\\), which says the drag constant \\(b\\) is just\n\\[\nb = 6\\pi\\eta R.\n\\]\n\n\nExample: Dropping a ball in syrup\nSuppose a ball of radius \\(R\\) and mass \\(m\\) is dropped in a viscous syrup from rest at \\(x=0\\). Find the velocity and position of the ball as it moves through the fluid.\n\n\n\n\n\nThis is a 1-dimensional motion problem since the ball is dropped from rest under gravity, with \\(F=F_d + mg\\). Here Stoke’s law applies, so the drag force is \\(F_d = -bv = -b\\dot x\\). Plugging into Newton’s Second Law, we have \\[\nm\\ddot x + b \\dot x = g.\n\\] Re-writing this in terms of \\(v = \\dot x\\), we get \\[\nm \\dot v + bv = g,\n\\] which is a first order linear differential equation for the velocity \\(v(t)\\). Its general solution is given by \\[\nv(t) = v_0 e^{-\\frac{b}{m}t} + \\frac{mg}{b}(1-e^{-\\frac{b}{m}t}).\n\\] Notice that as \\(t \\rightarrow \\infty\\), \\(v(t) \\rightarrow \\frac{mg}{b}\\). That is, \\(v(t)\\) tends toward a terminal velocity \\[\nv_t = \\frac{mg}{b} = \\frac{mg}{6\\pi\\eta R}.\n\\] Since the ball is dropped from rest, \\(v_0=0\\). The velocity of the ball is thus given by \\[\nv(t) = v_t(1-e^{-\\frac{b}{m}t}).\n\\] Using this we can solve for the position to get \\[\nx(t) = v_t\\bigg(t - \\frac{b}{m}(1 - e^{-\\frac{b}{m}t})\\bigg).\n\\] Notice that drag causes the ball to fall much slower than it would in free-fall. Instead of being a quadratic function of time, \\(x(t)\\) is now approximately a linear function of time, with \\(x(t) \\sim v_t t\\) for large \\(t\\).\n\n\n\n\n\n\n\n\n\nQuadratic Drag\nWe’ll now look at quadratic drag, where \\(b=0\\). Then we get the differential equation, \\[\nm\\ddot x + c \\dot x^2 = 0.\n\\] This is no longer a linear differential equation due to the appearance of \\(\\dot x^2\\), but surprisingly we can still solve it using separation of variables. Again, let \\(v = \\dot x\\). Then we get \\[\nm\\dot v + cv^2 = 0.\n\\] Rearranging and solving for \\(v(t)\\), we have \\[\n\\frac{dv}{dt} = -\\frac{c}{m}v^2 \\quad \\Longrightarrow \\quad\n\\int_{v_0}^{v} \\frac{dv}{v^2} = -\\frac{c}{m} t \\quad \\Longrightarrow \\quad\nv(t) = \\frac{1}{\\frac{1}{v_0} + \\frac{c}{m}t}.\n\\] Integrating both sides and solving for the position, we get \\[\nx(t) = x_0 + \\int_0^t \\frac{dt}{\\frac{1}{v_0} + \\frac{c}{m}t} = x_0 + \\frac{m}{c}\\log\\bigg( 1 + \\frac{cv_0}{m}t \\bigg).\n\\] In this case, \\(v \\rightarrow 0\\), but \\(x \\rightarrow \\infty\\) as \\(t \\rightarrow \\infty\\). Evidently, while linear drag is strong enough to slow a moving particle back down to rest, quadratic drag is not.\n\n\n\n\n\nQuadratic drag is often used to model the drag experienced by objects moving through air or other media where pressure is more important than viscosity. For an object moving through air, drag is well-modeled by the drag equation, \\[\n\\mathbf{F}_d = -\\frac{1}{2}C \\rho A v^2 \\mathbf{e}_v,\n\\] where \\(\\rho\\) is the density of air, \\(A\\) is the cross-sectional area of the object in the direction of motion, and \\(C\\) is the drag coefficient. Since this force is proportional to \\(v^2\\), we evidently have \\[\nc = \\frac{1}{2}C \\rho A.\n\\]\n\n\nReynold’s Number\nIn practice, how can we tell if drag is in the linear or quadratic situation? A simple way to do this is by looking at the Reynold’s Number. Let’s go back to the full quadratic equation for drag, with \\(a\\) set to \\(0\\), \\[\nF_d = -bv - cv^2.\n\\] Notice that the ratio \\(\\frac{cv}{b}\\) gives the relative importance of the two drag terms. Using Stoke’s Law and the Drag Equation for the drag constants, we can re-write this expression as \\[\n\\frac{cv}{b} = \\frac{\\frac{1}{2}C \\rho Av}{6\\pi\\eta R} = \\frac{C \\rho Rv}{3\\eta}.\n\\] This ratio is usually rescaled by a factor of \\(\\frac{3}{C}\\) to get the Reynold’s number \\(r\\), \\[\nr = \\frac{\\rho Rv}{\\eta}.\n\\] The Reynold’s number is usually what’s used in practice to decide whether we’re in the linear or quadratic drag regime.\n\nWhen the Reynold’s number is low, \\(r \\ll 1\\), \\(v \\ll \\frac{\\eta}{R\\rho}\\), and we’re in the linear regime.\nWhen the Reynold’s number is high, \\(r \\gg 1\\), \\(v \\gg \\frac{\\eta}{R\\rho}\\), and we’re in the quadratic regime.\nThe edge case is when \\(r \\approx 1\\), or \\(v \\approx \\frac{\\eta}{R\\rho}\\). Then, we have to include both the linear and quadratic drag terms in the equation of motion. In this general case, there’s no analytic solution and we have to solve things numerically.\n\nThe Reynold’s number is usually easy to calculate since we can often at least roughly estimate the object’s velocity and radius, and we can usually look up the medium’s viscosity and density. For example, a baseball thrown in air at 100 mph would have a Reynold’s number of about \\(r \\approx 3 \\cdot 10^5 \\gg 1\\), which is solidly in the quadratic drag regime.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Simple Systems</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/simple-systems.html#harmonic-oscillation",
    "href": "classical-mechanics/simple-systems.html#harmonic-oscillation",
    "title": "Simple Systems",
    "section": "Harmonic Oscillation",
    "text": "Harmonic Oscillation\nThe next case we’ll consider is when the force is linear in position, \\[\n\\mathbf{F} = -k \\mathbf{x}.\n\\] This relationship is called Hooke’s Law. In the 1-dimensional case, it reduces to the equation of motion \\[\nm \\ddot x + kx = 0.\n\\] This is a second-order linear differential equation for \\(x(t)\\). The general solution to this differential equation depends on the sign of \\(k\\). If \\(k &lt; 0\\), we have \\[\nx(t) = c_1 e^{\\frac{k}{m}t} + c_2 e^{-\\frac{k}{m}t}.\n\\] Since \\(x \\rightarrow \\infty\\) pretty quickly as \\(t \\rightarrow \\infty\\), this kind of solution is usually non-physical, except perhaps in situations where \\(x\\) is bounded between some known range.\nThe most important case by far is when \\(k &gt; 0\\). In this setting, it’s typical to define \\(\\omega^2 \\equiv \\frac{k}{m}\\) and re-rewrite the equation as \\[\n\\ddot x + \\omega^2 x = 0.\n\\] This is called the simple harmonic oscillator or SHO. The canonical example of SHO is of course the motion of a mass attached to an ideal spring with spring constant \\(k\\).\nThe general solution to SHO is a linear combination of sine and cosine functions, \\[\nx(t) = c_1 \\cos \\omega t + c_2 \\sin \\omega t.\n\\] This trajectory is oscillatory and stable since it only involves sines and cosines, both of which are bounded periodic functions. It’s custom to re-write this equation in a more useful form using trig identities,\n\n\n\n\n\n\\[\n\\begin{align*}\nx(t) &= c_1 \\cos \\omega t + c_2 \\sin \\omega t \\\\\n&= A\\bigg(\\frac{c_1}{A}\\cos \\omega t + \\frac{c_2}{A}\\sin\\omega t \\bigg) \\\\\n&= A(\\cos\\delta \\cos \\omega t + \\sin\\delta\\sin\\omega t) \\\\\n&= A\\cos(\\omega t - \\delta). \\\\\n\\end{align*}\n\\] In this form, \\(A\\) is the amplitude of oscillation and \\(\\delta\\) is the phase of oscillation. The period of oscillation is given by \\[\n\\tau = \\frac{2\\pi}{\\omega} = 2\\pi\\sqrt{\\frac{m}{k}}.\n\\]\n\n\n\n\n\nIt’s usually convenient when dealing with harmonic oscillators to work in the complex plane. Consider the complex form of SHO, given by the differential equation \\[\n\\ddot z + \\omega^2 z = 0,\n\\] where \\(z = x+iy = |z|e^{i\\theta}\\) is a complex variable. Its general solution is given as a linear combination of complex exponentials, \\[\nz(t) = \\tilde c_1 e^{i\\omega t} + \\tilde c_2 e^{-i\\omega t}.\n\\] If we demand that the real solution we seek be given by \\(x(t) = \\text{Re}(z(t))\\), then\n\\[\n\\begin{align*}\nx(t) &= \\Re(c_1 e^{i \\omega t}) + \\Re(c_2 e^{-i \\omega t}) \\\\\n&= \\frac{1}{2}(c_1 + c_2^*)e^{i \\omega t} + \\frac{1}{2}(c_1^* + c_2)e^{-i \\omega t} \\\\\n&= \\frac{1}{2} C e^{i \\omega t} + \\frac{1}{2} C^* e^{-i \\omega t} \\\\\n&= A \\cdot \\Re(e^{i(\\omega t - \\delta)}) \\\\\n&= A \\cos(\\omega t - \\delta),\n\\end{align*}\n\\] where \\(C \\equiv Ae^{i \\delta}\\) is some complex number whose real and imaginary parts are \\(c_1+c_2^*\\) and \\(c_1^*+c_2\\) respectively. For the full complex solution we can similarly write \\[\nz(t) = A e^{i(\\omega t - \\delta)}\n\\] Evidently then, SHO is just a CCW circular rotation in the complex plane with radius \\(A\\).\n\n\n\n\n\n\n\nExample: Bottle sloshing in a bucket\nSuppose a bottle of mass \\(m\\) floats calmly in a bucket of water of density \\(\\rho\\) at some equilibrium depth of \\(d=d_0\\). Suppose we push down slightly on the bottle, perturbing its depth to \\(d = d_0 + x\\). The bottle will begin to oscillate. Find its period of oscillation \\(\\tau\\).\n\n\n\n\n\nThe forces on the bottle are gravity downward and an opposing buoyant force upward, \\[\nF = mg - \\rho g V_{sub} = mg - \\rho g A(d_0 + x).\n\\] At equilibrium, the forces must balance, so \\(0 = mg - \\rho g A d_0\\), which means \\(d_0 = \\frac{m}{\\rho A}\\) is the equilibrium depth. Simplifying, this says the equation of motion is given by \\[\nm \\ddot x = mg - \\rho g A(d_0 + x) = -\\rho g A x = -\\frac{mg}{d_0} x.\n\\] This is just SHO with spring constant \\(k = \\frac{mg}{d_0}\\), or angular frequency \\(\\omega = \\frac{g}{d}\\). Thus, the period of the bottle’s oscillation when \\(x\\) is small is given by \\[\n\\tau = \\frac{2 \\pi}{\\omega} = 2\\pi\\sqrt{\\frac{d_0}{g}}.\n\\]\n\n\n\nTwo-Dimensional Harmonic Oscillation\nSuppose now we allow a mass to move in two dimensions. Hooke’s Law becomes\n\\[\n\\begin{align*}\nm \\ddot x &= -k_x x, \\\\\nm \\ddot y &= -k_y y.\n\\end{align*}\n\\] Since the equation of motions are uncoupled, the solutions are simply given by\n\\[\n\\begin{align*}\nx(t) &= A_x \\cos(\\omega_x t - \\delta_x), \\\\\ny(t) &= A_y \\cos(\\omega_y t - \\delta_y).\n\\end{align*}\n\\] Despite what intuition might suggest, the motion of the mass is now quite non-trivial. In fact, the behavior of the trajectory depends entirely on the ratio of the frequencies \\(\\frac{\\omega_x}{\\omega_y}\\) and the relative phase between the two oscillations \\(\\delta = \\delta_x - \\delta_y\\).\nThe motion will only be periodic if \\(\\frac{\\omega_x}{\\omega_y}\\) is rational, i.e. if the frequencies are integer multiples of each other. The curves traced out by \\((x(t), y(t))\\) when \\(\\frac{\\omega_x}{\\omega_y}\\) is rational are called Lissajous curves. They can get quite complicated, but they’ll always be periodic. Here’s what a few of them look like for different\\(\\frac{\\omega_x}{\\omega_y}\\) and \\(\\delta\\).\n\n\n\n\n\n\n\nExample: Charged particle in a uniform magnetic field\nSuppose a particle with charge \\(q\\) and mass \\(m\\) is moving in the presence of a constant magnetic field \\(\\mathbf{B}\\). Find its equations of motion, solve for the trajectory, and describe what it looks like.\n\n\n\n\n\nIf \\(\\mathbf{v}\\) is the velocity of the particle, the magnetic force is given by \\(\\mathbf{F} = \\frac{q}{c} \\mathbf{v} \\times \\mathbf{B}\\). Suppose \\(\\mathbf{B} = B \\mathbf{e}_z\\). Then \\[\n\\mathbf{F} = \\frac{q}{c}\\mathbf{v} \\times \\mathbf{B} = \\frac{qB}{c}(\\dot y \\mathbf{e}_x - \\dot x \\mathbf{e}_y),\n\\] The equations of motion are thus\n\\[\n\\begin{align*}\nm \\ddot x &= \\frac{qB}{c} \\dot y , \\\\\nm \\ddot y &= -\\frac{qB}{c} \\dot x , \\\\\nm \\ddot z &=  0. \\\\\n\\end{align*}\n\\] Define \\(\\omega \\equiv \\frac{qB}{c}\\). The first two equations can be decoupled to give two independent SHO equations in the velocities,\n\\[\n\\begin{align*}\n\\ddot v_x &= -\\omega^2 v_x , \\\\\n\\ddot v_y &= -\\omega^2 v_y , \\\\\n\\end{align*}\n\\] with solutions\n\\[\n\\begin{align*}\nv_x(t) &= V_x \\cos(\\omega t - \\delta_x) , \\\\\nv_y(t) &= V_y \\cos(\\omega t - \\delta_y)  , \\\\\n\\end{align*}\n\\] Now, since \\(\\ddot v_x = \\omega \\dot v_y\\), we must have \\(V_x = V_y\\) and \\(\\delta_y = \\delta_x - \\frac{\\pi}{2}\\). Taking \\(\\delta_x=0\\) and \\(V_x = R\\omega\\) for convenience, we get\n\\[\n\\begin{align*}\nv_x(t) &= R\\omega \\cos(\\omega t) , \\\\\nv_y(t) &= -R\\omega \\sin(\\omega t)  , \\\\\n\\end{align*}\n\\] Finally, integrating the velocity equations gives the trajectory,\n\\[\n\\begin{align*}\nx(t) &=  x_0 + R \\sin(\\omega t), \\\\\ny(t) &= (y_0 - R) + R \\cos(\\omega t) , \\\\\nz(t) &=  z_0 + v_{0z} t. \\\\\n\\end{align*}\n\\] This is just a helix of radius \\(R\\) directed along the z-axis. That is, the particle will just spiral around in a helix directed along the line of the magnetic field. The frequency \\(\\omega\\) is called the cyclotron frequency. Since charge can be positive or negative, it carries a sign, which determines which way the particle will spiral. Notice that \\(R\\) is just the radius of orbit. It’s customarily expressed in terms of the tangential velocity \\(v_\\perp = \\sqrt{v_x^2 + v_y^2} = R\\omega\\), \\[\nR = \\frac{mcv_\\perp}{qB}.\n\\]",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Simple Systems</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/simple-systems.html#damped-harmonic-oscillation",
    "href": "classical-mechanics/simple-systems.html#damped-harmonic-oscillation",
    "title": "Simple Systems",
    "section": "Damped Harmonic Oscillation",
    "text": "Damped Harmonic Oscillation\nLet’s now combine the forces of linear drag with the forces of harmonic oscillation. In the 1-dimensional case, this gives the damped harmonic oscillator or DHO, \\[\nm \\ddot x + bx + kx = 0.\n\\] Define \\(\\beta \\equiv \\frac{b}{2m}\\) and \\(\\omega_0 \\equiv \\sqrt{\\frac{k}{m}}\\), called the damping constant and the natural frequency respectively. Then we can write the DHO equation of motion as \\[\n\\ddot x + 2\\beta x + \\omega_0^2 x = 0.\n\\] It’ll be insightful to solve this in its complex form. Consider instead the equation \\[\n\\ddot z + 2\\beta z + \\omega_0^2 z = 0,\n\\] where \\(z\\) is complex-valued. Let’s try and assume a trial solution of the form \\(z = A e^{i\\omega t - \\delta}\\). Plugging this into the differential equation, we get \\[\n(-\\omega^2 + 2\\beta + \\omega_0^2)A e^{i\\omega t - \\delta} = 0.\n\\] In the non-trivial case \\(A \\neq 0\\), this implies \\((-\\omega^2 + 2\\beta + \\omega_0^2) = 0\\), which we can solve for \\(\\omega\\) to get \\[\n\\omega = i\\beta \\pm \\sqrt{\\omega_0^2 - \\beta^2} \\equiv i\\beta \\pm \\omega',\n\\] where \\(\\omega' \\equiv \\sqrt{\\omega_0^2 - \\beta^2}\\). Plugging this into \\(z\\) then gives \\[\nz(t) = e^{-\\beta t}(c_1 e^{i\\omega' t} + c_2 e^{-i\\omega' t}).\n\\] When dealing with damped systems, it’s customary to define a quality factor \\(Q \\equiv \\frac{\\omega_0}{2\\beta}\\), which expresses in relative terms how much the system is being damped. We can re-write \\(\\omega'\\) in terms of the Q-factor as \\[\n\\omega' = \\omega_0 \\sqrt{1 - \\bigg(\\frac{1}{2Q}\\bigg)^2}.\n\\] Evidently, the form of the solutions divide into three cases depending on the sign of \\(\\omega'\\):\n\nUnderdamping (\\(\\omega' &gt; 0\\) or \\(Q &lt; \\frac{1}{2}\\)): In this case, \\(\\omega'\\) is real, which means we have a real solution \\[\nx(t) = A e^{-\\beta t} \\cos(\\omega't - \\delta).\n\\] This is an exponentially damped sinusoidal oscillation, where \\(x \\rightarrow 0\\) with time constant \\(\\tau = \\frac{1}{\\beta}\\). Notice \\(\\omega' &lt; \\omega_0\\), which means the actual frequency of the oscillation is less than the natural frequency. When \\(Q \\gg 1\\) this distinction disappears, since \\(\\omega' \\approx \\omega_0\\). In practice this occurs frequently for underdamped solutions, and \\(Q\\) need not even be large for \\(\\omega' \\approx \\omega_0\\).\n\n\n\n\n\nOverdamping (\\(\\omega' &lt; 0\\) or \\(Q &gt; \\frac{1}{2}\\)): In this case, \\(\\omega'\\) is complex. Define \\(\\kappa \\equiv i\\omega'\\), which is real-valued. Then we have a solution of the form \\[\nx(t) = e^{-\\beta t}(c_1 e^{\\kappa t} + c_2 e^{-\\kappa t}).\n\\] Since \\(\\kappa &lt; \\beta\\), \\(x \\rightarrow 0\\) monotonically, with time constant \\(\\tau = \\frac{1}{\\beta - \\kappa}\\).\n\n\n\n\n\nCritical damping (\\(\\omega' = 0\\) or \\(Q = \\frac{1}{2}\\)): This is the edge case where \\(\\omega_0 = \\beta\\) exactly. Here the solution is degenerate, with \\[\nx(t) = (c_1 + c_2 t) e^{-\\beta t}.\n\\] Again, \\(x \\rightarrow 0\\), but with time constant \\(\\tau = \\frac{1}{\\beta}\\). Evidently, the critically damped solution decays faster than the overdamped solution.\n\n\n\n\n\n\nIn all three cases the system must eventually come to rest due to the presence of damping. Only the “high Q” systems are allowed to oscillate. Note that as \\(\\beta \\rightarrow 0\\), \\(Q \\rightarrow \\infty\\). In this limit the solution turns into regular SHO, with \\(\\omega' \\rightarrow \\omega_0\\).",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Simple Systems</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/simple-systems.html#driven-damped-harmonic-oscillation",
    "href": "classical-mechanics/simple-systems.html#driven-damped-harmonic-oscillation",
    "title": "Simple Systems",
    "section": "Driven Damped Harmonic Oscillation",
    "text": "Driven Damped Harmonic Oscillation\nLet’s now add in the independent force term to the mix. In the 1-dimensional case, we get the equation of motion \\[\nm \\ddot x + b \\dot x + kx = F_0(t).\n\\] This is called the driven damped harmonic oscillator or DDHO. We imagine \\(F_0(t)\\) to be some external driving force acting on the system. It’s again convenient to rewrite things by defining \\(\\beta = \\frac{b}{2m}\\), \\(\\omega_0^2 = \\frac{k}{m}\\), and \\(f(t) = \\frac{F_0(t)}{m}\\). Then we have the linear differential equation \\[\n\\ddot x + 2\\beta\\dot x + \\omega_0^2 x = f(t).\n\\] Recall that the solutions of linear differential equations can be decomposed into two pieces, a homogenous solution and a particular solution. The homogenous solution is the general solution to \\[\n\\ddot x_h + 2\\beta\\dot x_h + \\omega_0^2 x_h = 0.\n\\] But this is just a DHO. We solved that part already. All we need to do now is find any particular solution that will solve \\[\n\\ddot x_p + 2\\beta\\dot x_p + \\omega_0^2 x_p = f(t).\n\\] Provided we do that, the full, general solution will be \\(x(t) = x_h(t) + x_p(t)\\). There are several ways to find a particular solution, including guessing methods and more systematic methods like Green functions and Fourier transforms. We’ll briefly touch on some of these.\n\n\nExample: Underdamped hanging spring\nSuppose a spring is suspended vertically from a ceiling under the presence of gravity. Find the position \\(x=x(t)\\). Also, find the amount that gravity changes the spring’s equilibrium length.\n\n\n\n\n\nThe forces in this problem are gravity, linear drag, and a spring force, so if \\(x\\) points downward, \\[\nF = mg - bv - kx.\n\\] The equation of motion is thus given by \\[\nm \\ddot x + b \\dot x + kx = mg.\n\\] This is just DDHO with \\(f(t) = g\\). We thus seek a particular solution \\(x_p(t)\\) such that \\[\n\\ddot x_p + 2\\beta\\dot x_p + \\omega_0^2 x_p = g.\n\\] Assume a trial solution of the form \\(x_p = c\\). Then, \\[\n\\omega_0^2 c = g \\Longrightarrow c = \\frac{g}{\\omega_0^2} = \\frac{gm}{k}.\n\\] Supposing the spring is underdamped, then \\[\nx(t) = Ae^{-\\beta t} \\cos(\\omega' t - \\delta) + \\frac{gm}{k}.\n\\] The new equilibrium occurs when the object is at rest, i.e. when \\(\\ddot x = \\dot x = 0\\). This occurs at \\(x = \\frac{gm}{k}\\) relative to the free equilibrium \\(x=0\\).\n\n\n\nSinusoidal Driving Forces\nThe most interesting driving forces in practice are ones that are periodic. Periodic driving functions lead to the important concept of resonance, which is a phenomenon that occurs when the driving frequency matches the natural frequency.\nConsider a sinusoidal driving force of the form \\(f(t) = f_0 \\cos\\omega t\\). In complex form, we can then write \\[\n\\ddot z + 2\\beta\\dot z + \\omega_0^2 z = f_0 e^{i \\omega t}.\n\\] Assume a particular solution of the form \\(z(t) = \\tilde A e^{i \\omega t}\\) where \\(\\tilde A = Ae^{-i\\delta}\\). Plugging this in, we have \\[\n(-\\omega^2 + 2\\beta\\omega i + \\omega_0^2)\\tilde A e^{-i\\omega t} = f_0 e^{i\\omega t},\n\\] which we can solve for the complex amplitude \\(\\tilde A\\) to get \\[\n\\tilde A = \\frac{f_0}{(\\omega_0^2-\\omega^2) + 2\\beta\\omega i}.\n\\] With the help of little trig, we can decompose this solution to get the real amplitude and phase,\n\n\n\n\n\n\\[\nA = \\frac{f_0}{\\sqrt{(\\omega_0^2-\\omega^2)^2 + 4\\beta^2\\omega^2}}, \\quad \\delta = \\tan^{-1} \\frac{2\\beta\\omega}{\\omega_0^2-\\omega^2}.\n\\]\nWith these, the real particular solution is given by \\(x_p(t) = A \\cos(\\omega t - \\delta)\\). Since the homogenous solution decays to zero exponentially, \\(x \\rightarrow x_p\\) as \\(t \\rightarrow \\infty\\). That is, \\(x_p(t)\\) describes the steady state solution of the DDHO. In this sense, the system evidently “forgets” its own natural frequency and starts to oscillate at the driving frequency as time goes on and the transient state dies off.\n\n\n\n\n\nInterestingly, the memory of the transient dynamics is preserved in the amplitude and phase. As a rule of thumb, the number of oscillations \\(N\\) until \\(x \\approx x_p\\) is basically just the Q-factor, \\[\nN \\approx \\frac{Q}{\\pi}.\n\\] Let’s now look more deeply at the amplitude and phase. It’s worth asking how they depend on the external driving frequency \\(\\omega\\).\n\nWhen \\(\\omega \\ll \\omega_0\\), \\(A \\approx \\frac{f_0}{\\omega_0^2}\\) and \\(\\delta \\approx 0\\).\nWhen \\(\\omega \\gg \\omega_0\\), \\(A \\approx 0\\) and \\(\\delta \\approx \\pi\\).\nWhen \\(\\omega \\approx \\omega_0\\), \\(A \\approx \\frac{f_0}{2\\beta\\omega_0}\\) and \\(\\delta \\approx \\frac{\\pi}{2}\\).\n\n\n\n\n\n\nEvidently, \\(A\\) is maximized at \\(\\omega_R = \\sqrt{\\omega_0^2-2\\beta^2} = \\omega_0 \\sqrt{1-\\frac{1}{2Q^2}}\\). When \\(Q&gt;1\\), \\(\\omega_R \\approx \\omega_0\\), so this distinction doesn’t really matter. This frequency \\(\\omega_R \\approx \\omega_0\\) is called the resonance frequency of the system. When the driver is operating near the resonance frequency, the system responds extremely well to the driving force. It turns out that when a spectrum of frequencies is dumped on an oscillating system, the system tends to pick out the resonance frequencies and respond to those. This fact makes resonance a very important topic in physics and engineering.\nIn practice, high-Q systems are very common. In those cases, \\(A\\) dies off quickly when the driving frequencies aren’t close to \\(\\omega_0\\). That means practically all the interesting behavior of a high-Q systems is in the band around the resonance frequency. Suppose \\(\\Delta \\equiv \\omega - \\omega_0\\) is small. Then we can write \\[\n(\\omega_0^2-\\omega^2) = (\\omega_0-\\omega)(\\omega_0+\\omega) = -\\Delta(2\\omega_0+\\Delta) \\approx -2\\omega_0 \\Delta.\n\\] That means we can write the complex amplitude \\(\\tilde A\\) as \\[\n\\tilde A = \\frac{f_0}{(\\omega_0^2-\\omega^2) + 2\\beta\\omega i} \\approx -\\frac{\\frac{f_0}{2\\omega_0}}{\\Delta-\\beta i} = \\frac{f_0}{2\\omega_0}\\bigg(-\\frac{\\Delta}{\\Delta^2+\\beta^2} + i\\frac{\\beta}{\\Delta^2+\\beta^2} \\bigg).\n\\] This function on the right is called the Lorentzian. Using this, we can see \\[\nA \\approx \\frac{f_0}{2\\omega_0} \\frac{1}{\\sqrt{\\Delta^2 + \\beta^2}} \\quad \\Longrightarrow \\quad A^2 \\approx \\bigg(\\frac{f_0}{2\\omega_0}\\bigg)^2 \\frac{1}{\\Delta^2 + \\beta^2}.\n\\] Since the energy in a harmonic oscillator is just \\(E = \\frac{1}{2}kA^2 \\propto A^2\\), it’s common to look at plots of \\(A^2\\) when plotting these resonance curves. Evidently, \\(A^2 \\rightarrow 0\\) as \\(\\Delta \\rightarrow \\infty\\), and it’s maximized when \\(\\Delta = 0\\), which is when \\(\\omega = \\omega_0\\) and \\(A_{max}^2 = \\big(\\frac{f_0}{2\\omega_0 \\beta}\\big)^2\\).\nIt’s common to measure the width of the resonance curve by using the full width at half maximum or FWHM. The FWHM is defined as the difference between the left and right points around the maximum whose height is half the maximum, \\[\nFWHM \\equiv \\Delta \\omega \\equiv \\omega_R - \\omega_L, \\quad \\text{where} \\quad A^2(\\omega_L) = A^2(\\omega_R) = \\frac{1}{2}A_{max}.\n\\] Solving for these left and right points gives \\(\\omega_L = \\omega_0 - \\beta\\) and \\(\\omega_R = \\omega_0 + \\beta\\), so \\[\n\\Delta \\omega = (\\omega_0 + \\beta) - (\\omega_0 - \\beta) = 2\\beta.\n\\] The resolving power of the resonance curve is then \\[\n\\frac{\\omega_0}{\\Delta} = \\frac{\\omega_0}{2\\beta} = Q.\n\\] Evidently then, \\(Q\\) represents the resolving power of the resonance curve. The higher the Q-factor is, the more sharply peaked the resonance curve is, and the easier we can pinpoint the resonance frequency exactly. Indeed, this is why \\(Q\\) is called a quality factor.\n\n\n\n\n\nOne very important system where we want a high-Q is a clock. To keep precise time, we need to make sure that it’s oscillating pretty much exactly at its resonance frequencies. This is because we need to keep a regular period, so \\(\\tau = \\frac{2\\pi}{\\omega}\\) can’t be allowed to vary very much from the true period \\(\\tau_0 = \\frac{2\\pi}{\\omega_0}\\). There’s a tradeoff though. Since the decay time of the transient behavior is \\(N\\tau_0 \\equiv \\frac{1}{\\beta}\\), it takes about \\(N=\\frac{Q}{\\pi}\\) cycles of ringing for the system to come to steady state. So the better precision we want, the longer we’ll have to wait for the system to come to steady state.\nNote that \\(Q\\) also affects the phase curve of the system, since \\[\n\\delta = \\tan^{-1} \\frac{2\\beta\\omega}{\\omega_0^2-\\omega^2} \\approx \\tan^{-1} \\frac{2\\omega}{Q\\Delta}.\n\\] Evidently as \\(Q\\) increases, the system becomes more responsive to sudden changes in phase around \\(\\omega_0\\).\n\n\n\n\n\n\n\nArbitrary Driving Forces\nThe situation where resonance occurs in a DDHO system is not just confined to sinusoidal driving forces. Using Fourier analysis, we can decompose more arbitrary driving forces into a sum of sinusoidal driving forces of different frequencies. The simplest of these cases is when the driving force is periodic with some period \\(\\tau\\). Even if the driver isn’t sinusoidal, we can decompose it into a linear combination of cosines of different frequencies, i.e. a Fourier Series, \\[\nf(t) = \\sum_{n=-\\infty}^{\\infty} f_n e^{i \\omega n t},\n\\] where each \\(f_n\\) can be found via the formula \\[\nf_n = \\langle f(t), e^{i \\omega n t} \\rangle = \\frac{\\omega}{\\pi} \\int_0^{\\tau} f(t) e^{i \\omega n t} dt.\n\\] Using the principle of superposition, we could then find the solution for each of the sinusoidal drivers term by term, and then sum them together to get the full solution. Each term will have amplitude and phase \\[\nA_n = \\frac{f_n}{\\sqrt{(\\omega_0^2-\\omega^2 n^2)^2 + (2\\beta\\omega n)^2}}, \\quad \\delta_n = \\tan^{-1} \\frac{2\\beta\\omega n}{\\omega_0^2-\\omega^2n^2}.\n\\] Plugging these in will yield a general solution of the form \\[\nx(t) = x_h(t) + \\sum_{n=1}^{\\infty} A_n \\cos(\\omega n t - \\delta_n).\n\\] Each component will yield its own resonance frequency where \\(\\omega n \\approx -\\omega_0\\). As a function of the main driving frequency, this means there will resonances at each \\(\\omega_n = \\frac{\\omega_0}{n}\\). The resonance curve for \\(A^2\\) can be found via Parseval’s Theorem, which says \\[\nA^2 = \\langle x^2(t) \\rangle = \\frac{1}{2} \\sum_{n=0}^\\infty A_n^2.\n\\] The peaks evidently go to zero as \\(n \\rightarrow \\infty\\) since each \\(A_n^2 \\propto f_n^2\\) and each \\(f_n \\rightarrow 0\\) by the Riemann–Lebesgue lemma.\n\n\n\n\n\nWhat if the driving force isn’t periodic? In this case we have a few options. One would be to decompose it into its Fourier transform, \\[\nf(t) = \\int_{-\\infty}^{\\infty} f(\\omega) e^{i\\omega t} dt.\n\\] Then each term gives a set of complex amplitudes and phases that can be solved for and stitched back together to get \\(x(t)\\). Another solution that’s perhaps more common is to use Green’s functions. Instead of decomposing the driver into a linear combination of periodic functions, we’ll decompose it into a linear combination of impulse responses or delta functions, \\[\nf(t) = \\int_{-\\infty}^{\\infty} f(t') \\delta(t-t') dt'.\n\\] To find the solution \\(x(t)\\), we first need to find the particular solution \\(G(t-t')\\) to the DDHO with an impulse response, \\[\n\\ddot G + 2\\beta\\dot G + \\omega_0^2 G = \\delta(t - t').\n\\] Once this is found, we can stitch together the full solution as \\[\nx(t) = \\int_{-\\infty}^{\\infty} f(t') G(t-t') dt'.\n\\] Note the Green’s function solution already incorporates in the homogeneous solution since \\(G(t-t')\\) must itself satisfy the initial conditions.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Simple Systems</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/reference-frames.html",
    "href": "classical-mechanics/reference-frames.html",
    "title": "Reference Frames",
    "section": "",
    "text": "Orthogonal Transformations\nSuppose \\(\\mathbf{x}\\) is some vector, and \\(\\{\\mathbf{e}_i\\}\\) and \\(\\{\\mathbf{e}_i'\\}\\) are two orthonormal bases for \\(\\mathbb{R}^3\\), then \\[\n\\mathbf{x} = \\sum_{j=1}^3 x_j \\mathbf{e}_j = \\sum_{i'=1}^3 x_{i'} \\mathbf{e}_{i'},\n\\] where \\(x_i = \\mathbf{x} \\cdot \\mathbf{e}_i\\) and \\(x_i' = \\mathbf{x} \\cdot \\mathbf{e}_i'\\).\nNotation: From now on we’ll use the Einstein summation convention. If a repeated index occurs in a sum, we’ll omit the \\(\\sum\\) symbol. For example, we can re-write the above line as the following, where it’s understood we’re summing over \\(j\\) and \\(i'\\) in each case, \\[\n\\mathbf{x} = x_j \\mathbf{e}_j = x_{i'} \\mathbf{e}_{i'}.\n\\] Now, observe we can write one component in terms of the other as \\[\nx_i' = \\mathbf{x} \\cdot \\mathbf{e}_{i'} = (\\mathbf{e}_j \\cdot \\mathbf{e}_{i'}) x_j \\equiv R_{i'j} x_j,\n\\] where \\(R_{i'j} = \\mathbf{e}_j \\cdot \\mathbf{e}_i'\\) defines a matrix \\(\\mathbf{R}\\) called an orthogonal transformation.\nNotice that if we take the inner product of two vectors \\(\\mathbf{x}\\) and \\(\\mathbf{y}\\), we get \\[\n\\mathbf{x} \\cdot \\mathbf{y} = x_{i'} \\delta_{i' j'} x_{j'} = R_{ii'} \\delta_{i'j'} R_{j'j} x_i x_j = \\mathbf{x} \\cdot (\\mathbf{R}^\\top \\mathbf{R}) \\mathbf{y}.\n\\] Thus, an orthogonal transformation \\(\\mathbf{R}\\) satisfies the property that \\[\n\\mathbf{R}^\\top \\mathbf{R} = \\mathbf{I}, \\quad \\text{or} \\quad R_{ij} R_{jk} = \\delta_{ik}.\n\\] Due to the inner product preserving nature of orthogonal transformations, they can in a sense be used to define what we mean by a scalar or vector or tensor in classical mechanics. They’re objects that transform a certain way under an orthogonal transformation:\nNotice since \\(\\mathbf{R}^\\top \\mathbf{R} = \\mathbf{I}\\), we can take the determinant of both sides to get \\(\\det(\\mathbf{R}^\\top \\mathbf{R}) = \\det^2(\\mathbf{R}) = 1\\), which implies that \\(\\det(\\mathbf{R}) = \\pm 1\\). This fact divides orthogonal transformations into two distinct classes:\nMost vector operations are proper, in the sense that they preserve the handedness of the underlying coordinate system. If \\(\\mathbf{v}\\) is a vector, they’ll transform under a reflection to \\(-\\mathbf{v}\\). The one major exception is the cross product, which reverses the handedness. Under a reflection, it keeps its sign, \\[\n\\mathbf{v} \\times \\mathbf{w} \\Rightarrow (-\\mathbf{v}) \\times (-\\mathbf{w}) = \\mathbf{v} \\times \\mathbf{w}.\n\\] For this reason, cross products are sometimes called pseudovectors or axial vectors to distinguish them from ordinary vectors that transform under a reflection as \\(\\mathbf{v} \\Rightarrow -\\mathbf{v}\\).\nAside: It turns out that the set of all orthogonal transformations on \\(\\mathbb{R}^3\\) form a group \\(G\\), in the sense that it satisfies the following special “symmetry” properties:\nThe group of orthogonal transformations under matrix multiplication is called the orthogonal group, denoted \\(O(3)\\). The subset of \\(O(3)\\) where \\(\\det(\\mathbf{R})=1\\) happens to form a subgroup, i.e. a subset of \\(O(3)\\) that’s closed under group operations. It’s called the special orthogonal group, denoted \\(SO(3)\\). This is essentially the group of all rotations in 3 dimensions. The orthogonal groups turn out to be very important in understanding the theory of angular momentum, especially in quantum mechanics.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reference Frames</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/reference-frames.html#orthogonal-transformations",
    "href": "classical-mechanics/reference-frames.html#orthogonal-transformations",
    "title": "Reference Frames",
    "section": "",
    "text": "A scalar is any object \\(\\alpha\\) that is invariant under an orthogonal transformation, \\[\n\\alpha' = \\alpha.\n\\]\nA vector is any object \\(\\mathbf{v}\\) that transforms under an orthogonal transformation as, \\[\nv_{i'} = R_{i'i} v_i.\n\\]\nA tensor of order \\(k\\) is any object \\(\\mathbf{T}\\) that transforms under an orthogonal transformation as, \\[\nT_{i_1' i_2' \\cdots i_k'} = R_{i_1' i_1} R_{i_2' i_2} \\cdots R_{i_k' i_k} T_{i_1 i_2 \\cdots i_k}.\n\\]\n\n\n\nProper Rotations (\\(\\det(\\mathbf{R}) = 1\\)): These correspond to pure rotations in space. They preserve the handedness of the underlying coordinate system.\nImproper Rotations (\\(\\det(\\mathbf{R}) = -1\\)): These correspond to reflections in space, which are transformations \\(\\mathbf{v} \\Rightarrow -\\mathbf{v}\\) combined with a pure rotation. These transformations permute the handedness of the underlying coordinate system.\n\n\n\n\n\n\n\n\n\nClosure: If \\(A, B \\in G\\) , then \\(AB \\in G\\) also.\nAssociativity: For any \\(A,B,C \\in G\\), we have \\((AB)C = A(BC)\\).\nIdentity: There is a unique element \\(I \\in G\\) satisfying \\(IA = AI\\) for any \\(A \\in G\\).\nInvertibility: For any \\(A \\in G\\), there is an inverse element \\(A^{-1}\\) such that \\(A^{-1} A = A A^{-1} = I\\).\n\n\n\nExample: Rotations in two dimensions\nWe can easily figure out what proper rotations look like in 2D space by looking at how to relate one basis with another. Suppose \\(\\{\\mathbf{e}_x, \\mathbf{e}_y \\}\\) is the standard basis for \\(\\mathbb{R}^2\\), and \\(\\{\\mathbf{e}_{x'}, \\mathbf{e}_{y'}\\}\\) is some other orthonormal basis. Suppose \\(\\varphi\\) is the angle between \\(\\mathbf{e}_x\\) and \\(\\mathbf{e}_{x'}\\). Using a little geometry, we have,\n\n\n\n\n\n\\[\n\\begin{align*}\nR_{x'x} &= \\mathbf{e}_{x'} \\cdot \\mathbf{e}_x = \\cos\\varphi,\n&R_{x'y} &= \\mathbf{e}_{x'} \\cdot \\mathbf{e}_y = \\sin\\varphi, \\\\\nR_{y'x} &= \\mathbf{e}_{y'} \\cdot \\mathbf{e}_x = -\\sin\\varphi,\n&R_{y'y} &= \\mathbf{e}_{y'} \\cdot \\mathbf{e}_y = \\cos\\varphi. \\\\\n\\end{align*}\n\\] We can thus express any proper rotation in \\(\\mathbb{R}^2\\) using a \\(2 \\times 2\\) matrix of the form \\[\n\\mathbf{R}(\\varphi) =\n\\begin{pmatrix}\n\\cos\\varphi & \\sin\\varphi \\\\\n-\\sin\\varphi & \\cos\\varphi\n\\end{pmatrix}.\n\\] This is the matrix that rotates the underlying basis \\(\\{\\mathbf{e}_x, \\mathbf{e}_y \\}\\) to the new, rotated basis \\(\\{\\mathbf{e}_{x'}, \\mathbf{e}_{y'} \\}\\).\n\n\nActive vs Passive Transformations\nThe previous example suggests that we can think about a rotation in space two different ways. One way is to rotate the underlying basis and keep the vector \\(\\mathbf{v}\\) fixed. That is, \\(\\mathbf{e}_i \\Rightarrow R_{i'i} \\mathbf{e}_i\\).. This way of looking at a rotation is called a passive transformation. It rotates the coordinate system under \\(\\mathbf{v}\\), not \\(\\mathbf{v}\\) itself.\nAnother way of looking at a rotation is to imagine keeping the coordinate system fixed, but rotating the components of the vector \\(\\mathbf{v}\\) directly. That is, \\(v_i \\Rightarrow R_{i'i}v_i\\). This way of looking at a rotation is called an active transformation. Despite sounding semantically different, these two ways are physically equivalent. Note though that if a vector rotates actively under \\(\\mathbf{R}(-\\varphi)\\), it will rotate passively under \\(\\mathbf{R}(\\varphi)\\).\n\n\n\n\n\nIt’s usually more convenient to assume rotations are active transformations. The major exception is when dealing with rigid bodies, where it’s more convenient to passively transform to body coordinates. Note the same logic applies to 3D transformations. In that case, there are now three angles of rotation to deal with, not just one.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reference Frames</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/reference-frames.html#linearly-accelerating-frames",
    "href": "classical-mechanics/reference-frames.html#linearly-accelerating-frames",
    "title": "Reference Frames",
    "section": "Linearly Accelerating Frames",
    "text": "Linearly Accelerating Frames\nLet’s now examine the motion of systems in non-inertial reference frames. In examining accelerating frames, we’ll treat them as static coordinate systems, completely ignoring the forces that cause the reference frame to accelerate in the first place. We’ll start with linearly accelerating frames.\nSuppose a system is “locked into” a reference frame \\(S_{rel}\\), which is itself moving at a velocity \\(\\mathbf{v}_0\\) with respect to an inertial lab frame \\(S\\). We’ll seek out the equations of motion with respect to the non-inertial frame \\(S_{rel}\\).\n\n\n\n\n\nEvidently, \\(\\mathbf{x} = \\mathbf{x}_{rel} + \\mathbf{v}_0t\\), which means \\(\\mathbf{v} = \\mathbf{v}_{rel} + \\mathbf{v}_0\\), and \\(\\mathbf{a} = \\mathbf{a}_{rel} + \\mathbf{a}_0\\). When \\(\\mathbf{a}_0=\\mathbf{0}\\) we recover the special case of a Galilean transformation. In that case, \\(\\mathbf{F} = m \\mathbf{a} = m \\mathbf{a}_{rel}\\), which means \\(S_{rel}\\) is by definition an inertial frame.\nIf \\(\\mathbf{a}_0 \\neq \\mathbf{0}\\), we get \\(\\mathbf{F} = m(\\mathbf{a}_0 + \\mathbf{a}_{rel})\\), or \\(m\\mathbf{a}_{rel} = \\mathbf{F} - m \\mathbf{a}_0\\). We can think about this in another way, by defining a relative force \\(\\mathbf{F}_{rel} = m\\mathbf{a}_{rel}\\) and thinking of it as being composed of an inertial force \\(\\mathbf{F}\\) along with a fictitious force \\(\\mathbf{F}_{lin} = -m\\mathbf{a}_0\\), \\[\n\\mathbf{F}_{rel} = \\mathbf{F} + \\mathbf{F}_{lin} = \\mathbf{F} - m \\mathbf{a}_0.\n\\] One special case of a linear accelerating frame is an object free-falling under gravity. In that case, \\(\\mathbf{a}_0=-\\mathbf{g}\\) is constant. In some sense, this means we can treat gravity as a kind of generalized coordinate transformation that shifts the acceleration from \\(\\mathbf{a}\\) to \\(\\mathbf{a}_{rel} = \\mathbf{a} + \\mathbf{g}\\). This curious fact arises due to the equivalence principle, which says the gravitational force is proportional to the inertial mass \\(m\\). This curious fact causes the \\(m\\) to cancel from both sides of \\(m\\mathbf{a} = m\\mathbf{g}\\). As far as we know, gravity is the only force in nature with this special property. The equivalence principle is essentially the launch point to Einstein’s general theory of relativity.\n\n\n\n\n\n\n\nExample: Pendulum in an accelerating railcar\nA railcar is moving along the x-axis at a constant acceleration \\(\\mathbf{a}_0\\) with respect to the lab frame. Inside the railcar, a pendulum with mass \\(m\\) and length \\(\\ell\\) is attached to the ceiling and allowed to swing freely. Find the equations of motion for the swinging pendulum. Also, find the equilibrium position of the pendulum.\n\n\n\n\n\nWorking in the frame of the railcar, we have \\(\\mathbf{F}_{rel} = \\mathbf{F} + \\mathbf{F}_{lin}\\). The inertial forces on the pendulum are the string tension \\(\\mathbf{T}\\) and gravity \\(m\\mathbf{g}\\). We thus have \\[\nm\\mathbf{a}_{rel} = \\mathbf{T} + m\\mathbf{g} - m\\mathbf{a}_0 \\equiv \\mathbf{T} + m\\mathbf{g}_{eff},\n\\] where \\(\\mathbf{g}_{eff} \\equiv \\mathbf{g} - \\mathbf{a}_0\\) acts as an effective gravity on the pendulum inside the moving railcar. We can thus use the standard method to solve for the pendulum, but replacing \\(\\mathbf{g}\\) with \\(\\mathbf{g}_{eff}\\), to get \\[\n\\ddot \\theta = -\\omega^2 \\sin \\theta, \\quad \\text{where} \\quad \\omega^2 \\equiv \\frac{|\\mathbf{g}_{eff}|}{\\ell} = \\frac{\\sqrt{g^2 + a_0^2}}{\\ell}.\n\\] The equilibrium position occurs when \\(\\mathbf{F}_{rel}=\\mathbf{0}\\), which is when \\(\\mathbf{T} = -m\\mathbf{g}_{eff}\\). Using a little trig, we can see the equilibrium angle will be shifted to the angle \\(\\theta_{eq}\\) given by\n\n\n\n\n\n\\[\n\\theta_{eq} = \\tan^{-1} \\frac{g}{a_0}.\n\\]\nNotice when \\(a_0\\) we get \\(\\theta_{eq}=0\\), which is what we’d expect if the railcar weren’t accelerating.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reference Frames</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/reference-frames.html#rotating-frames",
    "href": "classical-mechanics/reference-frames.html#rotating-frames",
    "title": "Reference Frames",
    "section": "Rotating Frames",
    "text": "Rotating Frames\nLet’s now look at reference frames that are rotating about some axis. Without loss of generality, we’ll consider a reference frame \\(S_{rot}\\) that’s rotating about the z-axis with respect to the lab frame \\(S\\) at some angular velocity \\(\\boldsymbol{\\omega} = \\dot \\varphi \\mathbf{e}_z\\).\n\n\n\n\n\nLet \\(\\mathbf{A}\\) be some vector in this rotating frame that’s at an angle \\(\\theta\\) with the axis of rotation. The amount that \\(\\mathbf{A}\\) changes due to the frame’s rotation by an amount \\(\\delta\\varphi\\) is given by \\[\n\\delta A = A_\\perp \\delta\\varphi = A\\sin\\theta\\delta\\varphi = |\\mathbf{A} \\times \\delta\\boldsymbol{\\varphi}|,\n\\] so by the right-hand rule we have \\(\\delta\\mathbf{A} = \\delta\\boldsymbol{\\varphi} \\times \\mathbf{A}\\). Dividing both sides by \\(dt\\), we finally have \\[\n\\frac{d\\mathbf{A}}{dt} = \\boldsymbol{\\omega} \\times \\mathbf{A}.\n\\] Remark:  Since velocities add as vectors, so too do angular velocities. This means if \\(S'\\) is a frame rotating relative \\(S\\), and \\(S''\\) is yet another frame that’s rotating to \\(S'\\), then we have \\[\n\\mathbf{v}_S'' = \\mathbf{v}_S' + \\mathbf{v}_{S'}'' \\quad \\Longrightarrow \\quad  \\boldsymbol{\\omega}_S'' \\times \\mathbf{r}_S = \\boldsymbol{\\omega}' \\times \\mathbf{r}_S + \\boldsymbol{\\omega}'' \\times \\mathbf{r}_{S'} \\quad \\Longrightarrow \\quad  \\boldsymbol{\\omega}_S'' = \\boldsymbol{\\omega}_S' + \\boldsymbol{\\omega}_{S'}''.\n\\] This fact allows us to easily solve problems involving complex hierarchies of rotations.\nNow, suppose \\(S_{rot}\\) is rotating with angular velocity \\(\\boldsymbol{\\omega}\\) with respect to the origin of \\(S\\). With respect to an observer in each frame, a vector \\(\\mathbf{A} = A_i \\mathbf{e}_i = A_i^{rot}\\mathbf{e}_i = \\mathbf{A}_{rel}\\) changes as\n\\[\n\\begin{align*}\n\\frac{d\\mathbf{A}}{dt}\\bigg|_{rot} &= \\dot A_i^{rot} \\mathbf{e}_i^{rot}, \\\\\n\\frac{d\\mathbf{A}}{dt}\\bigg|_{lab} &= \\dot A_i^{rot} \\mathbf{e}_i^{rot} + A_i^{rot} \\mathbf{\\dot e}_i^{rot}, \\\\\n\\frac{d\\mathbf{e}_i^{rot}}{dt}\\bigg|_{lab} &= \\boldsymbol{\\omega} \\times \\mathbf{e}_i^{rot}.\n\\end{align*}\n\\] Thus, we have \\[\n\\frac{d\\mathbf{A}}{dt}\\bigg|_{lab} = \\frac{d\\mathbf{A}}{dt}\\bigg|_{rot} + \\boldsymbol{\\omega} \\times \\mathbf{A}_{rot}\n\\] This evidently defines a transport operation between the lab frame and the rotating frame. Namely, time derivatives in the lab frame are related to time derivatives in the rotating frame via \\[\n\\frac{d}{dt}\\bigg|_{lab} = \\frac{d}{dt}\\bigg|_{rot} + \\boldsymbol{\\omega} \\times.\n\\] This result is sometimes called the transport theorem.\nUsing the transport theorem we can now derive what the equations of motion look like inside the rotating frame. Plugging \\(\\mathbf{x}\\) into the transport equation, we get \\[\n\\frac{d\\mathbf{x}}{dt}\\bigg|_{lab} = \\frac{d\\mathbf{x}}{dt}\\bigg|_{rot} + \\boldsymbol{\\omega} \\times \\mathbf{x}_{rot},\n\\] or \\[\n\\mathbf{v} = \\mathbf{v}_{rot} + \\boldsymbol{\\omega} \\times \\mathbf{x}_{rot}.\n\\] To get the acceleration \\(\\mathbf{a}\\), we need to apply the transport equation again to the velocity vector,\n\\[\n\\begin{align*}\n\\frac{d\\mathbf{v}}{dt}\\bigg|_{lab} &= \\bigg(\\frac{d}{dt}\\bigg|_{rot} + \\boldsymbol{\\omega} \\times \\bigg) (\\mathbf{v}_{rot} + \\boldsymbol{\\omega} \\times \\mathbf{x}_{rot}) \\\\\n&= \\mathbf{\\dot v}_{rot} + \\boldsymbol{\\omega} \\times \\mathbf{v}_{rot} + \\boldsymbol{\\dot \\omega} \\times \\mathbf{x}_{rot} + \\boldsymbol{\\omega} \\times \\mathbf{v}_{rot} + \\boldsymbol{\\omega} \\times (\\boldsymbol{\\omega} \\times \\mathbf{x}_{rot}).\n\\end{align*}\n\\] Or after cleaning up a bit, \\[\n\\mathbf{a} = \\mathbf{a}_{rot} + 2 \\boldsymbol{\\omega} \\times \\mathbf{v}_{rot} + \\boldsymbol{\\dot \\omega} \\times \\mathbf{x}_{rot} + \\boldsymbol{\\omega} \\times (\\boldsymbol{\\omega} \\times \\mathbf{x}_{rot}).\n\\]\nSince \\(\\mathbf{F} = m \\mathbf{a}\\) in the lab frame, we can multiply both sides by \\(m\\) and re-arrange terms to get the force vector \\(\\mathbf{F}_{rot}\\), \\[\n\\mathbf{F}_{rot} = \\mathbf{F} + m \\boldsymbol{\\omega} \\times (\\mathbf{x}_{rot} \\times \\boldsymbol{\\omega}) + 2m \\mathbf{v}_{rot} \\times \\boldsymbol{\\omega} + m \\mathbf{x}_{rot} \\times \\boldsymbol{\\dot \\omega}.\n\\] Evidently, there are three distinct fictitious force terms. Naturally, they each have special names:\n\nCentrifugal Force: \\(\\mathbf{F}_{cf} = m \\boldsymbol{\\omega} \\times (\\mathbf{x}_{rot} \\times \\boldsymbol{\\omega}) = m(\\boldsymbol{\\omega} \\cdot \\mathbf{x}_{rot})\\mathbf{x}_{rot} - m\\omega^2 \\mathbf{x}_{rot}\\).\nCoriolis Force: \\(\\mathbf{F}_{cor} = 2m \\mathbf{v}_{rot} \\times \\boldsymbol{\\omega}\\).\nEuler Force: \\(\\mathbf{F}_{eul} = m \\mathbf{x}_{rot} \\times \\boldsymbol{\\dot \\omega}\\).\n\nIn terms of these forces, we can finally write the force experienced in the rotating frame as \\[\n\\mathbf{F}_{rot} = \\mathbf{F} + \\mathbf{F}_{cf} + \\mathbf{F}_{cor} + \\mathbf{F}_{eul}.\n\\] The centrifugal force tends to push a rotating object outward radially from the origin, similar to how a centrifuge works. In the simple case when the position is perpendicular to the axis of rotation, the centrifugal force reduces to the more familiar form from elementary physics, \\[\n\\mathbf{F}_{cf} = - m\\omega^2 \\mathbf{x}_{rot} = -\\frac{mv_{rot}^2}{r_{rot}} \\mathbf{e}_r.\n\\] The Coriolis force tends to deflect a moving object away from its line of motion. It arises due to the fact that as the object moves, the frame under it is rotating underneath, which causes an apparent deflection sideward.\n\n\nExample: Throwing a baseball from the North Pole\nSuppose a baseball is thrown from the North Pole for a distance \\(\\ell\\) and a constant velocity \\(\\mathbf{v}_0\\) with respect to the lab frame. Find the deflection angle \\(\\delta\\theta\\) of the ball caused by the Coriolis force.\n\n\n\n\n\nThe rotating frame in this case is the Earth itself. The Earth rotates counterclockwise about the North Pole with an angular velocity of \\(\\omega_\\oplus = \\frac{2\\pi}{\\text{1 day}} \\approx 7 \\cdot 10^{-5} \\frac{\\text{rad}}{\\text{sec}}\\). Suppose \\(\\mathbf{e}_z\\) is the direction pointing skyward, with the origin at the North Pole. Then \\(\\boldsymbol{\\omega} = \\omega_{\\oplus} \\mathbf{e}_z\\). Suppose the ball is thrown initially along the positive x-axis, so \\(\\mathbf{x} = \\ell \\mathbf{e}_x\\). Since \\(\\mathbf{v} = \\mathbf{v}_{rot} + \\boldsymbol{\\omega} \\times \\mathbf{x}_{rot}\\), we have \\[\n\\mathbf{v}_0 = \\mathbf{v}_{rot} + \\omega_{\\oplus} v_0 t (\\mathbf{e}_z \\times \\mathbf{e}_x) = \\mathbf{v}_{rot} + \\omega_{\\oplus} v_0 t \\mathbf{e}_y.\n\\] On time scales \\(t \\ll \\text{1 day}\\), we can say \\(\\mathbf{v}_{rot} \\approx \\mathbf{v}_0\\) since in that case \\(\\omega_{\\oplus} t\\) becomes small. Then we have \\[\n\\mathbf{F}_{cor} = 2m \\mathbf{v}_{rot} \\times \\boldsymbol{\\omega} \\approx 2m v_0 \\omega_{\\oplus} (\\mathbf{e}_x \\times \\mathbf{e}_z) = -2m v_0 \\omega_{\\oplus} \\mathbf{e}_y,\n\\] Evidently, the Coriolis force in this case is constant, which means the acceleration \\(\\mathbf{a}_{cor}\\) is constant too. We thus get a simple constant equation of motion in \\(y\\), \\[\n\\ddot y = -2v_0 \\omega_{\\oplus}.\n\\] Solving this EOM gives a deflection distance of \\[\nd = |y| = \\frac{1}{2}(2v_0 \\omega_{\\oplus})^2 = v_0 \\omega_{\\oplus} t^2.\n\\] Finally, we can use this to calculate the deflection angle \\(\\delta\\theta\\), \\[\n\\delta\\theta \\approx \\frac{d}{\\ell} = \\frac{\\omega_{\\oplus}v_0 t^2}{v_0 t} = \\omega_{\\oplus} t.\n\\] To plug in some numbers, suppose the ball stays in the air for \\(t = \\text{100 sec}\\). Then we’d get \\(\\delta\\theta \\approx 0.4^\\circ\\), indeed a very small deflection.\n\n\n\nExample: Hurricanes\nIt turns out that hurricanes rotate the direction they do due to the Coriolis force of the Earth. Pressure gradients cause water currents flowing east-west to spiral inward. In the Northern hemisphere, water deflects rightward, causing the gradients (or “hurricanes”) to spiral counterclockwise. Whereas in the Southern hemisphere, water deflects leftward, causing gradients (or “typhoons”) to spiral clockwise.\n\n\n\n\n\n\n\n\nExample: The Foucalt pendulum\nThe Foucalt pendulum is a classic problem that’s often used to demonstrate that the Earth rotates. Suppose a very long pendulum of length \\(l\\) and mass \\(m\\) is fixed near the Earth’s surface at some latitude \\(\\lambda\\) above the equator. Here’s a picture of what’s going on.\n\n\n\n\n\nIt’s reasonable to assume that \\(\\omega_{\\oplus}\\) is constant, so the Euler force is zero. It’s also reasonable to assume the centrifugal force is zero since \\(\\omega_{\\oplus}\\) is small. Thus, in the frame of the rotating Earth, we’re left with the inertial forces on the pendulum and the Coriolis force, \\[\nm\\mathbf{a}_{rot} = m\\mathbf{g} + \\mathbf{T} - 2m\\boldsymbol{\\omega} \\times \\mathbf{v}_{rot}.\n\\] Choose the axes such that the z-axis is pointing outward from the Earth’s surface at the pendulum and the other axes are planar to the surface. Now, we can write \\(\\mathbf{g} = -g \\mathbf{e}_z\\), and using some trig it’s not too hard to show that \\[\n\\mathbf{T} \\approx -\\frac{T}{\\ell} (x \\mathbf{e}_x + y \\mathbf{e}_y + \\ell \\mathbf{z}).\n\\] Using the latitude angle \\(\\lambda\\) we can also express the angular velocity \\(\\boldsymbol{\\omega}\\) as \\[\n\\boldsymbol{\\omega} = -\\omega_{\\oplus}\\cos\\lambda\\mathbf{e}_x + \\omega_{\\oplus}\\sin\\lambda\\mathbf{e}_z.\n\\] Since the pendulum approximately speaking only moves in the xy-plane, we also have \\[\n\\mathbf{v}_{rot} = \\dot x \\mathbf{e}_x + \\dot y \\mathbf{e}_y.\n\\] Together, these together imply \\[\n\\boldsymbol{\\omega} \\times \\mathbf{v}_{rot} \\approx -\\dot y \\omega_{\\oplus} \\sin\\lambda \\mathbf{e}_x + \\dot x \\omega_{\\oplus} \\sin\\lambda \\mathbf{e}_y - \\dot y \\omega_{\\oplus} \\cos\\lambda \\mathbf{e}_z.\n\\] This means \\[\n\\mathbf{a}_{rot} = \\bigg(-\\frac{Tx}{m\\ell} + 2\\dot y \\omega_{\\oplus} \\sin\\lambda \\bigg) \\mathbf{e}_x + \\bigg(-\\frac{Ty}{m\\ell} - 2\\dot x \\omega_{\\oplus} \\sin\\lambda \\bigg) \\mathbf{e}_x,\n\\] which gives equations of motion\n\\[\n\\begin{align*}\n\\ddot x &= -\\frac{T}{m\\ell} \\cdot x + 2\\omega_{\\oplus}\\sin\\lambda \\cdot \\dot y \\\\\n\\ddot y &= -\\frac{T}{m\\ell} \\cdot y - 2\\omega_{\\oplus}\\sin\\lambda \\cdot \\dot x. \\\\\n\\end{align*}\n\\] If we define \\(\\omega_0^2 \\equiv \\frac{T}{m\\ell} = \\frac{g}{\\ell}\\), we can re-arrange and write the equations of motion in the form\n\\[\n\\begin{align*}\n\\ddot x + \\omega_0^2 \\cdot x &= 2\\omega_z \\dot y \\\\\n\\ddot y + \\omega_0^2 \\frac{T}{m\\ell} \\cdot y &= -2\\omega_z \\dot x, \\\\\n\\end{align*}\n\\] where \\(\\omega_z = \\omega_{\\oplus}\\sin\\lambda\\). If we combine these two equations, this is equivalent to a complex DHO problem with imaginary damping, \\[\n\\ddot z + 2i\\omega_z \\dot z + \\omega_0^2 z = 0.\n\\] This means solutions will have the form \\[\nz(t) = e^{-i\\omega_z t}(A e^{i\\omega't} + B e^{-i\\omega't}).\n\\] where \\(\\omega' \\equiv \\sqrt{\\omega_z^2 + \\omega_0^2}\\). If we assume the pendulum swings much faster than the Earth rotates, we have \\(\\omega_0 \\gg \\omega_{\\oplus}\\), which means we can approximate \\(z(t)\\) as \\[\nz(t) \\approx e^{-i\\omega_z t}(A e^{i\\omega_0 t} + B e^{-i\\omega_0 t}).\n\\] If we define \\(z'(t) \\equiv A e^{i\\omega_0 t} + B e^{-i\\omega_0 t}\\), then \\(z(t) = e^{-i\\omega_z t} z'(t)\\), and we can write the real solutions as\n\\[\n\\begin{align*}\nx(t) &= x'(t) \\cos\\omega_z t + y'(t) \\sin\\omega_z t, \\\\\ny(t) &= -x'(t) \\sin\\omega_z t + y'(t) \\cos\\omega_z t. \\\\\n\\end{align*}\n\\] This says that the plane of oscillation itself undergoes a rotation in the xy-plane. That is, the plane of the pendulum’s orbit precesses with a frequency given by \\[\n\\omega_z = \\omega_{\\oplus} \\sin\\lambda = 2\\pi\\frac{\\sin\\lambda}{\\text{1 day}}.\n\\] For example, at a latitude of \\(\\lambda = 34.5^\\circ\\), the pendulum precesses counterclockwise with a frequency of \\(\\omega_z \\approx \\text{3.86 rad/sec}\\), or about \\(8.5^\\circ\\) per hour. It appears precession is non-existent at the equator and highest at the poles, where precession happens exactly with the Earth’s rotation.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reference Frames</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/reference-frames.html#general-non-inertial-frames",
    "href": "classical-mechanics/reference-frames.html#general-non-inertial-frames",
    "title": "Reference Frames",
    "section": "General Non-Inertial Frames",
    "text": "General Non-Inertial Frames\nMore generally, we can combine linearly accelerating and rotating frames by just adding the fictitious forces together. If \\(S_{rel}\\) is both accelerating and rotating about some axis with respect to \\(S\\), we’d have \\[\n\\mathbf{F}_{rel} = \\mathbf{F} + \\mathbf{F}_{lin} + \\mathbf{F}_{cf} + \\mathbf{F}_{cor} + \\mathbf{F}_{eul}.\n\\] This general form for a force in a non-inertial frame can be used to analyze a surprisingly large number of practical problems, where complicated forces can often be decomposed into a sum of linear forces and rotational forces.\nOne fact to be aware of about non-inertial frames is that energy need not be conserved. It’s only true in inertial frames that energy must be conserved. This has to do with the fact that in the relative frame we’re ignoring the forces on the relative frame itself, i.e. the forces that cause the frame to accelerate or rotate. We can generally recover the conservation of energy by transforming back to an inertial frame.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reference Frames</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/lagrangian-mechanics.html",
    "href": "classical-mechanics/lagrangian-mechanics.html",
    "title": "Lagrangian Mechanics",
    "section": "",
    "text": "Configuration Space\nMany forces acting on a system do no work. They serve only to keep particles confined to some surface in space. Such forces are called forces of constraint. Examples of forces of constraint include the tension in a string and the normal force keeping an object on a physical surface.\nSuppose we have a system of \\(N\\) particles with positions \\(\\mathbf{x}_1, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N\\) respectively. Taken together, these positions can be thought of as defining a trajectory in the \\(3N\\)-dimensional space \\(\\mathbb{R}^{3N}\\). A holonomic constraint is a constraint that keeps the \\(N\\) particles confined to some lower-dimensional sub-manifold \\(\\mathcal{Q}\\) of \\(\\mathbb{R}^{3N}\\). Equivalently, it’s a (possibly time-dependent) function of the form \\[\nf(\\mathbf{x}_1, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N, t) = 0.\n\\] The dimension of \\(\\mathcal{Q}\\) is \\(n=3N-C\\), where \\(C\\) is the total number of constraints on the system. These are the number of degrees of freedom of the system. This sub-manifold is called the configuration space of the system. Since \\(\\mathcal{Q}\\) is \\(n\\)-dimensional, we should be able to parametrize it with \\(n\\) coordinates \\(q_1, q_2, \\cdots, q_n\\). We call these generalized coordinates. They’re not ordinary coordinates in real space. They’re a way of describing where in configuration space the system is at a given point in time.\nHolonomicity requires that we be able to find a 1-1 map going back and forth between generalized coordinates and the position vectors, \\[\nq_i = q_i(\\mathbf{x}_1, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N, t), \\quad \\mathbf{x}_\\alpha = \\mathbf{x}_\\alpha(q_1, q_2, \\cdots, q_n, t).\n\\] When the holonomic constraint isn’t time-dependent, they’re called scleronomic constraints. Otherwise they’re called rheonomic constraints. A system that’s not holonomic is called non-holonomic.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lagrangian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/lagrangian-mechanics.html#configuration-space",
    "href": "classical-mechanics/lagrangian-mechanics.html#configuration-space",
    "title": "Lagrangian Mechanics",
    "section": "",
    "text": "Example: Simple Pendulum\nAs an easy example, consider the simple pendulum. Since there’s only one particle, \\(N=1\\). Since the length of the pendulum is fixed, that’s one constraint. Since the motion is confined to a plane, that’s another constraint. We thus have \\(n=3N-C=3-2=1\\) degrees of freedom, which we can of course take to be the angle \\(\\theta\\).\n\n\n\nExample: Rigid Bodies\nA more interesting example is the rigid body. A rigid body is a system of \\(N\\) particles whose particles are always a fixed distance apart, i.e. \\(d_{ij} = |\\mathbf{x}_i - \\mathbf{x}_j|\\) is fixed for all \\(i, j\\). This fixed distance requirement introduces a lot of constraints on the system. To see this, suppose \\(N=4\\). Then there are \\(C=6\\) constraints, since each particle must connect to each other particle. This means there are \\(n=3N-C=6\\) degrees of freedom.\n\n\n\n\n\nIt turns out this fact extends to rigid bodies with arbitrarily many particles as well since adding a new particle gives 3 more coordinates, but also 3 more constraints. A rigid body will always have exactly 6 degrees of freedom, which we usually take to be the 3 center of mass coordinates and the three Euler angles.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lagrangian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/lagrangian-mechanics.html#principle-of-virtual-work",
    "href": "classical-mechanics/lagrangian-mechanics.html#principle-of-virtual-work",
    "title": "Lagrangian Mechanics",
    "section": "Principle of Virtual Work",
    "text": "Principle of Virtual Work\nSuppose we have a system of \\(N\\) particles in mechanical equilibrium, so \\(\\mathbf{F}_i=\\mathbf{0}\\) for all \\(i\\). Let’s imagine we perturb each particle \\(\\mathbf{x}_i\\) by some amount \\(\\delta \\mathbf{x}_i\\), but only in a way that doesn’t change the configuration space. This means each perturbation must be a function of the generalized coordinates, \\(\\delta \\mathbf{x}_i = \\delta \\mathbf{x}_i(q_1, q_2, \\cdots, q_n, t)\\). Define the virtual work done on the system by, \\[\n\\delta W \\equiv \\sum \\mathbf{F}_i \\cdot \\delta\\mathbf{x}_i\n\\] Now, let’s decompose each force \\(\\mathbf{F}_i\\) into a sum of two components, an applied force \\(\\mathbf{F}_i^{app}\\) and a constraint force \\(\\mathbf{F}_i^{con}\\). The applied forces are the ones that do work on each particle, while the constraint forces are the ones that keep them confined to the configuration space. If the system is exactly in equilibrium, then \\(\\mathbf{F}_i = \\mathbf{F}_i^{app} + \\mathbf{F}_i^{con} = \\mathbf{0}\\), which means \\(\\delta W = 0\\) in equilibrium. But since constraint forces do no work, we get \\[\n\\delta W = \\sum \\mathbf{F}_i^{app} \\cdot \\delta\\mathbf{x}_i = 0\n\\] This is called the principle of virtual work.\nNote: Sometimes constraint forces do in fact do work on a system. One major example is a system in rolling motion, e.g. a wheel rolling down a ramp. We’ll mostly ignore these situations in this lesson.\nMore generally, if a system is not in equilibrium, we have \\(\\mathbf{F}_i = m_i \\mathbf{\\dot v}_i\\). If we insist the principle of virtual work must apply to these situations as well, we have \\[\n\\begin{align*}\n0 = \\delta W &= \\sum_i (\\mathbf{F}_i^{app} - m_i \\mathbf{\\dot v}_i) \\cdot \\delta \\mathbf{x}_i \\\\\n&= \\sum_i (\\mathbf{F}_i^{app} - m_i \\mathbf{\\dot v}_i) \\cdot \\sum_j\\frac{\\partial \\mathbf{x}_i}{\\partial q_j} \\delta q_j \\\\\n&= \\sum_j \\bigg(\\sum_i \\mathbf{F}_i^{app} \\cdot \\frac{\\partial \\mathbf{x}_i}{\\partial q_j}  - m_i \\mathbf{\\dot v}_i \\cdot \\frac{\\partial \\mathbf{x}_i}{\\partial q_j} \\bigg) \\delta q_j \\\\\n&= \\sum_j \\bigg[ Q_j - \\bigg(\\frac{d}{dt} \\frac{\\partial T}{\\partial \\dot q_j} - \\frac{\\partial T}{\\partial q_j} \\bigg) \\bigg] \\delta q_j.\n\\end{align*}\n\\] Here I defined \\(Q_j \\equiv \\mathbf{F}_i^{app} \\cdot \\frac{\\partial \\mathbf{x}_i}{\\partial q_j}\\). This term is called the generalized force. It acts as a force, but on the generalized coordinates instead of the position vectors directly. The other thing I did was re-wrote the momentum term by using the total kinetic energy \\(T = \\frac{1}{2} \\sum_i m_i \\mathbf{v}_i^2\\). Now, if we insist that all the \\(q_i\\) are independent of each other, then the terms in the sum must vanish individually, which means for all \\(j=1,\\cdots,n\\) we have \\[\nQ_j = \\frac{d}{dt} \\frac{\\partial T}{\\partial \\dot q_j} - \\frac{\\partial T}{\\partial q_j}.\n\\] In the special case where the forces on the system are conservative, we can use the potential energy \\(V\\) to express the generalized forces as \\(Q_j = -\\frac{\\partial V}{\\partial q_i}\\). Defining a function \\(L \\equiv T - V\\) called the Lagrangian and re-arranging terms, we finally have \\[\n\\frac{\\partial L}{\\partial q_j} - \\frac{d}{dt} \\frac{\\partial L}{\\partial \\dot q_j} = 0.\n\\] This gives a set of \\(n\\) equations for the generalized coordinates, called Lagrange’s equations.\nTo see why Lagrange’s equations are useful, consider the case when \\(T=\\frac{1}{2} \\sum_i m_i \\dot x_i^2\\) and \\(V = V(x_1, x_2, \\cdots, x_n)\\). Then we have a Lagrangian of the form \\[\nL = T - V = \\frac{1}{2} \\sum_i m_i \\dot x_i^2 - V(x_1, x_2, \\cdots, x_n),\n\\] which we can plug into the Euler-Lagrange Equations to get \\[\nm \\ddot x_i = - \\frac{\\partial V}{\\partial x_i} \\quad \\forall i=1,2,\\cdots,n.\n\\] But this is just \\(\\mathbf{F} = m \\mathbf{a}\\)! Evidently we’ve managed to reproduce Newton’s Laws from Lagrange’s equations. This in some sense suggest that Lagrange’s equations might be more general than Newton’s Laws, and in fact they are as we’ll see later.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lagrangian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/lagrangian-mechanics.html#solving-lagranges-equations",
    "href": "classical-mechanics/lagrangian-mechanics.html#solving-lagranges-equations",
    "title": "Lagrangian Mechanics",
    "section": "Solving Lagrange’s Equations",
    "text": "Solving Lagrange’s Equations\nThe Lagrangian formulation is very useful for solving problems that would be very complicated to solve using Newtonian approaches. This is particular true when there are complex constraints present. It’s thus very helpful to see a bunch of examples showing how to solve problems using Lagrangian methods.\nTo solve a problem using Lagrange’s equations we need to do the following steps:\n\nFigure out how many degrees of freedom the system has using \\(n=3N-C\\).\nIdentify the generalized coordinates \\(q_1,q_2,\\cdots,q_n\\).\nExpress the velocity vectors as a function of the generalized coordinates, \\(\\mathbf{v}_i = \\mathbf{v}_i(q_1,q_2,\\cdots,q_n)\\).\nWrite down the kinetic energy \\(T = \\frac{1}{2}\\sum_i m_i \\mathbf{v_i}^2(q_1,q_2,\\cdots,q_n)\\), the potential energy \\(V=V(q_1,q_2,\\cdots,q_n)\\), and finally the Lagrangian \\[\nL = T - V.\n\\]\nUse Lagrange’s equations to derive the equations of motion for the generalized coordinates, \\[\n\\frac{\\partial L}{\\partial q_j} - \\frac{d}{dt} \\frac{\\partial L}{\\partial \\dot q_j} = 0 \\quad \\forall j=1,2\\cdots,n.\n\\]\nIntegrate the equations of motion to get the generalized trajectories \\(q_1(t),q_2(t),\\cdots,q_n(t)\\).\nIf desired, convert back to real space coordinates via \\(\\mathbf{x}_\\alpha = \\mathbf{x}_\\alpha(q_1,q_2,\\cdots,q_n)\\).\n\n\n\nExample: The Simple Spring\nSuppose a mass \\(m\\) is attached to an ideal spring with spring constant \\(k\\).\n\n\n\n\n\nIn this case, \\(N = 1\\), and the spring is constrained to move along, say, the x-axis, so \\(C=2\\), and there’s just \\(n=3N-C=1\\) degree of freedom (as expected). If the generalized coordinate is just \\(q=x\\), we have \\[\nT = \\frac{1}{2} m \\dot q^2, \\quad V = \\frac{1}{2}kq^2,\n\\] which means the Lagrangian is \\[\nL = \\frac{1}{2} m \\dot q^2 - \\frac{1}{2}kq^2.\n\\] Solving Lagrange’s equation in this case gives \\[\n-\\frac{\\partial}{\\partial q} \\frac{k q^2}{2} - \\frac{d}{dt} \\frac{\\partial}{\\partial \\dot q} \\frac{m\\dot q^2}{2} = 0 \\quad \\Rightarrow \\quad m\\ddot q = -k q.\n\\] We’ve already seen the solution to this equation is just the SHO solution \\[\nq(t) = A\\cos(\\omega t - \\delta), \\quad \\omega^2 \\equiv \\frac{k}{m}.\n\\] If desired, in this case we could convert back to real coordinates via \\[\n\\mathbf{x}(t) = q(t) \\mathbf{e}_x = A\\cos(\\omega t - \\delta)\\mathbf{e}_x.\n\\]\n\n\n\nExample: Simple Pendulum\nSuppose a mass \\(m\\) is attached to a massless string of fixed length \\(\\ell\\) and allowed to swing.\n\n\n\n\n\nIn this problem, there’s \\(N=1\\) particle. The string being fixed adds one constraint, and motion being confined to the plane adds another, so we have \\(n=1\\) degrees of freedom here, which we’ll take to be the angle \\(q=\\theta\\). Using polar coordinates, we can write the kinetic and potential energies as \\[\nT = \\frac{1}{2} m\\ell^2 \\dot q^2, \\quad V = -mg\\ell\\cos q,\n\\] which gives a Lagrangian \\[\nL = \\frac{1}{2} m\\ell^2 \\dot q^2 + mg\\ell\\cos q.\n\\] Solving Lagrange’s equation, we get the equation of motion \\[\nm\\ell^2 \\ddot q + mg\\ell\\sin q = 0,\n\\] which is of course the usual equation of motion for the pendulum when \\(q=\\theta\\).\n\n\n\nExample: Central Potential\nSuppose a particle of mass \\(m\\) is in the presence of a central force field \\(V=V(r)\\). There’s one constraint since the problem must be spherically symmetric, which means we have \\(n=2\\) degrees of freedom. Working in spherical coordinates, the kinetic and potential energies are given by \\[\nT = \\frac{1}{2} m (\\dot r^2 + r \\dot \\varphi^2), \\quad V = V(r).\n\\] Plugging these into Lagrange’s equation and solving gives two equations of motion for \\(r\\) and \\(\\varphi\\), \\[\nm \\ddot r = mr \\dot\\varphi^2 - \\frac{dV}{dr}\\\\\n\\frac{d}{dt} mr^2 \\dot\\varphi = 0.\n\\] The second equation is interesting. It says the quantity \\(\\ell = mr^2 \\dot\\varphi\\) must be conserved. But this is just the angular momentum of the system! Evidently, conservation laws somehow fall out of Lagrange’s equations provided the right generalized coordinates are chosen.\n\n\n\nExample: Double Pendulum\nThe examples considered so far are pretty easy to solve using Newtonian methods. Here’s an example where it’s far easier to write down the equations of motion in the Lagrangian formulation. Consider the double pendulum, where a mass is attached to the end of another pendulum and both are allowed to swing. Suppose both masses have mass \\(m\\) and both strings are a fixed length \\(\\ell\\).\n\n\n\n\n\nHere there are \\(N=2\\) particles, each of which has two constraints. That means there are \\(n=2\\) total degrees of freedom in this system. From the above diagram we can see \\[\n\\begin{align*}\n&x_1 = \\ell \\sin\\theta_1, \\quad &&x_2 = \\ell(\\sin\\theta_1 + \\sin\\theta_2), \\\\\n&y_1 = -\\ell \\cos\\theta_1, \\quad &&y_2 = -\\ell(\\cos\\theta_1 + \\cos\\theta_2). \\\\\n\\end{align*}\n\\] We’ll choose the two angles \\(\\theta_1, \\theta_2\\) to be the generalized coordinates. The energies for each mass are given by \\[\n\\begin{align*}\nT_1 &= \\frac{1}{2}m (\\dot x_1^2 + \\dot y_1^2) = \\frac{1}{2}m \\ell^2 \\dot \\theta_1^2, \\quad &&\nT_2 = \\frac{1}{2}m (\\dot x_2^2 + \\dot y_2^2) = \\frac{1}{2}m \\ell^2\\big(\\dot\\theta_1^2 + \\dot\\theta_2^2 + 2\\cos(\\theta_1-\\theta_2)\\dot\\theta_1\\dot\\theta_2\\big), \\\\\nV_1 &= mgy_1 = -mg\\ell\\cos\\theta_1, \\quad && V_2 = mgy_2 = -mg\\ell(\\cos\\theta_1 + \\cos\\theta_2).\\\\\n\\end{align*}\n\\]\nPutting these all into the Lagrangian and simplifying, we evidently get \\[\nL = \\frac{1}{2}m\\ell^2\\big(2\\dot \\theta_1^2 + \\dot \\theta_2^2 + 2\\dot\\theta_1\\dot\\theta_2\\cos(\\theta_1-\\theta_2) \\big) + mg\\ell(2\\cos\\theta_1 + \\cos\\theta_2).\n\\] This then gives the following two equations of motion \\[\n\\begin{align*}\n-m\\ell^2\\dot\\theta_1\\dot\\theta_2\\sin(\\theta_1-\\theta_2) - 2mg\\ell\\sin\\theta_1 &= m\\ell^2 \\frac{d}{dt} \\big(\\dot\\theta_1 + 2\\dot\\theta_2\\cos(\\theta_1-\\theta_2)\\big), \\\\\nm\\ell^2\\dot\\theta_1\\dot\\theta_2\\sin(\\theta_1-\\theta_2) - mg\\ell\\sin\\theta_2 &= m\\ell^2 \\frac{d}{dt} \\big(\\dot\\theta_2 + 2\\dot\\theta_1\\cos(\\theta_1-\\theta_2) \\big). \\\\\n\\end{align*}\n\\]",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lagrangian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/lagrangian-mechanics.html#principle-of-least-action",
    "href": "classical-mechanics/lagrangian-mechanics.html#principle-of-least-action",
    "title": "Lagrangian Mechanics",
    "section": "Principle of Least Action",
    "text": "Principle of Least Action\nA more general, first principles way to derive Lagrange’s equations is via an action principle. Action principles are a very general and powerful tool that applies across pretty much all of modern physics. Suppose we have \\(n\\) generalized coordinates \\(q_1,q_2,\\cdots,q_n\\). For simplicity I’ll write these as a vector, \\[\n\\mathbf{q} = (q_1,q_2,\\cdots,q_n).\n\\] Define the action \\(S\\) as a functional of \\(\\mathbf{q}\\) of the form \\[\nS[\\mathbf{q}] \\equiv \\int_{t_1}^{t_2} L(\\mathbf{q}, \\mathbf{\\dot q}, t) dt.\n\\] We assume the times \\(t_1\\) and \\(t_2\\) are fixed. The integrand function \\(L(\\mathbf{q}, \\mathbf{\\dot q}, t)\\) is called the Lagrangian. Note in general the Lagrangian can depend explicitly on time.\n\n\n\n\n\nSimilar to how it’s useful to analyze a function by looking at its behavior around its minima, we’ll want to analyze the functional \\(S\\) by looking at its behavior around the stationary points of \\(\\mathbf{q}\\). To do so, consider a small perturbation \\(\\delta\\mathbf{q} \\equiv \\varepsilon\\boldsymbol{\\eta}\\) of the coordinates, where \\(\\boldsymbol{\\eta} = \\boldsymbol{\\eta}(t)\\) is a function that vanishes at the endpoints \\(t_1\\) and \\(t_2\\), and \\(\\varepsilon \\ll 1\\). To proceed, we’ll assume the following fundamental principle:\nPrinciple of Least Action:  Physical trajectories evolve in such a way that the action remains stationary, i.e. \\[\n\\delta S[\\mathbf{q}] \\equiv \\frac{\\partial S}{\\partial \\varepsilon} \\bigg|_{\\varepsilon=0} = 0.\n\\] This means if we want to figure out how physical trajectories evolve, we need to find the optimal \\(\\mathbf{q}\\) that make the action \\(S\\) stationary. To do that, let’s set \\(\\delta S[\\mathbf{q}] = 0\\) and solve. We have \\[\n0 = \\delta S[\\mathbf{q}] = \\int_{t_1}^{t_2} \\delta L(\\mathbf{q}, \\mathbf{\\dot q}, t) dt = \\int_{t_1}^{t_2}\\bigg(\\frac{\\partial L}{\\partial\\mathbf{q}} \\cdot \\delta \\mathbf{q} + \\frac{\\partial L}{\\partial\\mathbf{\\dot q}} \\cdot \\delta \\mathbf{\\dot q} \\bigg) \\cdot \\delta\\mathbf{q} dt\n\\] Now, if we perform integration by parts on the second term, we can move the time derivative from \\(\\delta\\mathbf{\\dot q}\\) to the derivative \\(\\frac{\\partial L}{\\partial\\mathbf{\\dot q}}\\) at the cost of a minus sign, so we have \\[\n0 = \\delta S[\\mathbf{q}] = \\int_{t_1}^{t_2}\\bigg(\\frac{\\partial L}{\\partial\\mathbf{q}} - \\frac{d}{dt}\\frac{\\partial L}{\\partial\\mathbf{\\dot q}} \\bigg) \\cdot \\delta \\mathbf{q} dt.\n\\] Note the boundary terms vanish since we require \\(\\boldsymbol{\\eta}\\) to vanish at the endpoints. Assuming each of the coordinates in \\(\\mathbf{q}\\) are functionally independent the integrand must vanish identically, so we have \\[\n\\frac{\\partial L}{\\partial\\mathbf{q}} - \\frac{d}{dt}\\frac{\\partial L}{\\partial\\mathbf{\\dot q}} = \\mathbf{0}.\n\\] Of course, this is just the vector formulation of Lagrange’s equations. We’ve thus fully recovered Lagrange’s equations, and by extension Newton’s Laws for conservative systems, purely from the Principle of Least Action.\nNotice how general this derivation was. We didn’t even assume any specific form of the Lagrangian like \\(L = T-V\\). We only assumed it was a function of the generalized positions, velocities, and time. If we believe the Principle of Least Action, evidently any Lagrangian \\(L(\\mathbf{q}, \\mathbf{\\dot q}, t)\\) will produce equations of motion for some system, not necessarily mechanical, or even classical.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lagrangian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/lagrangian-mechanics.html#symmetries-and-conservation-laws",
    "href": "classical-mechanics/lagrangian-mechanics.html#symmetries-and-conservation-laws",
    "title": "Lagrangian Mechanics",
    "section": "Symmetries and Conservation Laws",
    "text": "Symmetries and Conservation Laws\nIt’s a deep fact of physics that the symmetries of a system are intimately connected with its conservation laws. It’s both practically and theoretically useful to better understand this connection.\n\nCyclic Coordinates\nConsider a general Lagrangian of the form \\(L = L(\\mathbf{q}, \\mathbf{\\dot q}, t)\\). Without loss of generality, suppose the Lagrangian happens to not be a function of the coordinate \\(q_1\\), so \\[\nL = L(q_2,\\cdots,q_n,\\dot q_1,\\dot q_2, \\cdots, \\dot q_n, t).\n\\] Note it can still be a function of the first coordinate’s velocity \\(\\dot q_1\\). In this situation, we’d say the coordinate \\(q_1\\) is a cyclic coordinate or ignorable coordinate. Evidently, it follows that \\[\n\\frac{\\partial L}{\\partial q_1} = 0 \\quad \\Longrightarrow \\quad 0 = \\frac{d}{dt} \\frac{\\partial L}{\\partial \\dot q_1} \\quad \\Longrightarrow \\quad p_1 \\equiv \\frac{\\partial L}{\\partial \\dot q_1} = const.\n\\] We call \\(p_1\\) the conjugate momentum to \\(q_1\\). We’ve thus shown that if \\(q_1\\) is cyclic, then its conjugate momentum \\(p_1\\) is conserved.\n\n\nExample: Free Particle\nFor a free particle, we have \\(L = \\frac{1}{2}m \\dot x^2\\). Since \\(L\\) is not a function of \\(x\\), evidently \\(x\\) is cyclic, which means its conjugate momentum \\(p_x\\) is conserved, \\[\np_x = \\frac{\\partial L}{\\partial \\dot x} = m \\dot x = const.\n\\] Notice in this case the conjugate momentum is the same thing as the ordinary linear momentum. This need not always be true. The conjugate momentum is more general than this.\n\n\n\nExample: Central Force in a Plane\nIn this case the Lagrangian is given by \\[\nL = \\frac{1}{2} m (\\dot r^2 + r^2 \\dot\\varphi^2) - V(r).\n\\] Since \\(\\varphi\\) is cyclic, its conjugate momentum \\(p_\\varphi\\) must evidently be conserved, \\[\np_\\varphi = \\frac{\\partial L}{\\partial \\dot \\varphi} = mr^2\\dot\\varphi = const.\n\\] Notice this is just the \\(z\\)-component of angular momentum \\(L_z = \\ell\\).\n\n\n\n\nNoether’s Theorem\nWe can still have conserved quantities in a given system even if none of its generalized coordinates are explicitly cyclic. This will happen, for example, if we didn’t happen to choose the natural choice of coordinates for some given problem, the ones that take advantage of the system’s symmetries.\nTo find conserved quantities, we need to find the symmetries. Formally, we’ll say a symmetry is any continuous transformation on the generalized coordinates that leaves the Lagrangian invariant. That is, for some parameter \\(s\\), if \\(\\mathbf{q}\\) is continuously transformed to \\(\\mathbf{q}_s\\), then \\(s\\) is a symmetry provided \\[\nL(\\mathbf{q}_s, \\mathbf{\\dot q}_s, t) = L(\\mathbf{q}, \\mathbf{\\dot q}, t).\n\\] Noether’s Theorem: If \\(s\\) is a symmetry of a system, then the quantity given by \\[\nQ \\equiv \\mathbf{p} \\cdot \\frac{\\partial \\mathbf{q}}{\\partial s} = p_i \\frac{\\partial q_i}{\\partial s}\n\\] must be conserved under transformation by \\(s\\). We call \\(Q\\) the Noether charge associated with \\(s\\).\n\nProof: To prove this theorem we need to show that \\(\\dot Q = 0\\). Since \\(s\\) is a symmetry, we must have \\[\n\\frac{\\partial}{\\partial s} L(\\mathbf{q}_s, \\mathbf{\\dot q}_s, t) = \\frac{\\partial}{\\partial s} L(\\mathbf{q}, \\mathbf{\\dot q}, t) = 0.\n\\] Using the chain rule together with Lagrange’s equations on \\(L(\\mathbf{q}_s, \\mathbf{\\dot q}_s, t)\\), we finally get \\[\n\\begin{align*}\n\\mathbf{0} &= \\frac{\\partial}{\\partial s} L(\\mathbf{q}_s, \\mathbf{\\dot q}_s, t) \\\\\n&= \\frac{\\partial L}{\\partial \\mathbf{q}_s} \\cdot \\frac{\\partial \\mathbf{q}_s}{\\partial s} + \\frac{\\partial L}{\\partial \\mathbf{\\dot q}_s} \\cdot \\frac{\\partial \\mathbf{\\dot q}_s}{\\partial s} \\\\\n&= \\frac{d}{dt} \\frac{\\partial L}{\\partial \\mathbf{\\dot q}_s} \\cdot \\frac{\\partial \\mathbf{q}_s}{\\partial s} + \\frac{\\partial L}{\\partial \\mathbf{\\dot q}_s} \\cdot \\frac{d}{dt} \\frac{\\partial \\mathbf{q}_s}{\\partial s} \\\\\n&= \\frac{d}{dt} \\bigg(\\frac{\\partial L}{\\partial \\mathbf{\\dot q}_s} \\cdot \\frac{\\partial \\mathbf{q}_s}{\\partial s}\\bigg) \\\\\n&= \\frac{d}{dt} \\bigg(\\mathbf{p} \\cdot \\frac{\\partial \\mathbf{q}}{\\partial s}\\bigg). \\tag*{$\\square$}\n\\end{align*}\n\\]\n\n\nExample: Conservation of Linear Momentum\nSuppose a single particle is moving through space. Suppose the space is homogeneous, that is, the particle’s Lagrangian is invariant to translations in space, \\[\nL(\\mathbf{x}, \\mathbf{\\dot x}, t) = L(\\mathbf{x} + \\delta\\mathbf{x}, \\mathbf{\\dot x}, t).\n\\] This is equivalent to saying the particle has a symmetry of the form \\(\\mathbf{x}(s) = \\mathbf{x} + s\\boldsymbol{\\varepsilon}\\), where \\(\\boldsymbol{\\varepsilon}\\) is constant. In this case, we’d evidently have \\[\nQ = \\mathbf{p} \\cdot \\frac{\\partial \\mathbf{x}}{\\partial s} = \\mathbf{p} \\cdot \\boldsymbol{\\varepsilon} = const.\n\\] Since \\(\\boldsymbol{\\varepsilon}\\) is an arbitrary constant, we must have \\(\\mathbf{p} = m \\mathbf{\\dot x} = const\\). That is, the linear momentum of the particle is conserved. Equivalently, if space is homogeneous, then the total linear momentum will be conserved.\n\n\n\nExample: Conservation of Angular Momentum\nSuppose again a single particle is moving through space. Suppose this time that space is isotropic, that is, the particle’s Lagrangian is invariant to rotations in space, \\[\nL(\\mathbf{x}, \\mathbf{\\dot x}, t) = L\\big(\\delta\\mathbf{R}\\mathbf{x}, \\mathbf{\\dot x}, t\\big).\n\\] Now, we can always think of a rotation in space as a rotation about some axis. For simplicity we’ll choose that axis to be the \\(z\\)-axis, in which case we can think of \\(\\delta\\mathbf{R}\\) as rotating \\(\\mathbf{x}\\) by some azimuthal angle \\(\\delta\\varphi\\). Take as generalized coordinates the spherical coordinates \\(r, \\theta, \\varphi\\). Then rotational invariance is equivalent to saying the particle has a symmetry of the form \\(\\varphi(s) = \\varphi + s\\). We thus have \\[\nQ = p_r \\frac{\\partial r}{\\partial s} + p_\\theta \\frac{\\partial \\theta}{\\partial s} + p_\\varphi \\frac{\\partial \\varphi}{\\partial s} = p_\\varphi = const.\n\\] That is, the angular momentum \\(L_z = mr^2 \\dot \\varphi = const\\). Since choosing the \\(z\\)-axis as the rotation axis was arbitrary, this says the total angular momentum \\(\\mathbf{L} = const\\). That is, the angular momentum of the particle is conserved. Equivalently, if space is isotropic, then the total angular momentum will be conserved.\n\nWhat about energy though? When is it conserved? It turns out that energy conservation is connected to time translation invariance, which is a little bit more subtle. Suppose a Lagrangian had a time translational symmetry of the form \\(t(s) = t + s\\). Since all of \\(L\\), \\(\\mathbf{q}\\), and \\(\\mathbf{\\dot q}\\) depend explicitly on time, this means we’d have \\[\nL\\big(\\mathbf{q}(t), \\mathbf{\\dot q}(t), t\\big) = L\\big(\\mathbf{q}(t + s), \\mathbf{\\dot q}(t + s), t + s\\big).\n\\] Following along the proof of Noether’s Theorem, we’d have \\[\n0 = \\frac{\\partial L}{\\partial s} = \\frac{\\partial L}{\\partial t} \\frac{\\partial t}{\\partial s} = \\frac{\\partial L}{\\partial t}.\n\\] That is, \\(\\frac{\\partial L}{\\partial t} = 0\\), which means now time is cyclic, and the Lagrangian doesn’t have any explicit time dependence. Now, if we take the total time derivative of the Lagrangian, we get \\[\n\\begin{align*}\n\\frac{dL}{dt} &= \\frac{\\partial L}{\\partial \\mathbf{q}} \\cdot \\mathbf{\\dot q} + \\frac{\\partial L}{\\partial \\mathbf{\\dot q}} \\cdot \\mathbf{\\ddot q} + \\frac{\\partial L}{\\partial t} \\\\\n&= \\frac{d}{dt} \\frac{\\partial L}{\\partial \\mathbf{\\dot q}} \\cdot \\mathbf{\\dot q} + \\frac{\\partial L}{\\partial \\mathbf{\\dot q}} \\cdot \\mathbf{\\ddot q} + \\frac{\\partial L}{\\partial t} \\\\\n&= \\mathbf{\\dot p} \\cdot \\mathbf{\\dot q} + \\mathbf{p} \\cdot \\mathbf{\\ddot q} + \\frac{\\partial L}{\\partial t} \\\\\n&= \\frac{d}{dt} \\mathbf{p} \\cdot \\mathbf{\\dot q} + \\frac{\\partial L}{\\partial t}.\n\\end{align*}\n\\] When time is cyclic, we must have \\[\nH \\equiv \\mathbf{p} \\cdot \\mathbf{\\dot q} - L = const.\n\\] This function is called the Hamiltonian. We’ve just shown that when a system is time translation invariant, its Hamiltonian must be conserved, whatever that is.\nTo see what exactly \\(H\\) is, let’s consider a Lagrangian of the form \\[\nL = T - V = \\frac{1}{2} \\mathbf{\\dot q} \\cdot \\mathbf{T}(\\mathbf{q}) \\cdot \\mathbf{\\dot q} - V(\\mathbf{q}).\n\\] In this case, the Hamiltonian would be \\[\n\\begin{align*}\nH &= \\frac{\\partial L}{\\partial \\mathbf{\\dot q}} \\cdot \\mathbf{\\dot q} - L \\\\\n&= \\mathbf{\\dot q} \\cdot \\mathbf{T}(\\mathbf{q}) \\cdot \\mathbf{\\dot q} - \\frac{1}{2} \\mathbf{\\dot q} \\cdot \\mathbf{T}(\\mathbf{q}) \\cdot \\mathbf{\\dot q} + V(\\mathbf{q}) \\\\\n&= \\frac{1}{2} \\mathbf{\\dot q} \\cdot \\mathbf{T}(\\mathbf{q}) \\cdot \\mathbf{\\dot q} + V(\\mathbf{q}) \\\\\n&= T + V. \\\\\n\\end{align*}\n\\] That is, if \\(L = T-V\\), then \\(H=T+V\\). But \\(T+V\\) is just the total energy \\(E\\). We thus finally have the conservation of energy. If \\(L = T-V\\) and time is homogeneous, then the total energy \\(E\\) is conserved.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lagrangian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/lagrangian-mechanics.html#non-conservative-forces",
    "href": "classical-mechanics/lagrangian-mechanics.html#non-conservative-forces",
    "title": "Lagrangian Mechanics",
    "section": "Non-Conservative Forces",
    "text": "Non-Conservative Forces\nAs we’ve derived them, Lagrange’s equations only hold for systems with conservative forces. In some special cases, we can augment non-conservative forces into Lagrange’s equations as well. Suppose for example we had \\(L = T - U\\), where \\(U = U(\\mathbf{q}, \\mathbf{\\dot q}, t)\\) is some kind of generalized potential energy. Then the generalized forces have the form \\[\n\\mathbf{Q} = - \\frac{\\partial U}{\\partial \\mathbf{q}} + \\frac{d}{dt} \\frac{\\partial U}{\\partial \\mathbf{\\dot q}}.\n\\] In this case, we can solve Lagrange’s equations for \\(L = T-U\\) and everything would work fine even though \\(U\\) is not a proper potential energy anymore.\n\n\nExample: Charged Particle in an Electromagnetic Field\nSuppose a particle of mass \\(m\\) and charge \\(q\\) is moving in the presence of an electromagnetic field. We already know that such a particle obeys the Lorentz force law \\[\n\\mathbf{F} = q \\mathbf{E}(\\mathbf{x},t) + \\frac{q}{c} \\mathbf{v} \\times \\mathbf{B}(\\mathbf{x},t).\n\\] Can we derive this from a Lagrangian? Notice that this force isn’t conservative since it’s a function of the particle’s velocity. However, we can still derive a generalized potential energy \\(U=U(\\mathbf{x},\\mathbf{v},t)\\) as follows. We know from electrodynamics that we can express the electric field \\(\\mathbf{E}\\) and magnetic field \\(\\mathbf{B}\\) as derivatives of a scalar potential \\(\\phi\\) and a vector potential \\(\\mathbf{A}\\), \\[\n\\begin{align*}\n\\mathbf{E}(\\mathbf{x},t) &= - \\nabla \\phi(\\mathbf{x},t) - \\frac{1}{c} \\frac{\\partial}{\\partial t} \\mathbf{A}(\\mathbf{x},t), \\\\\n\\mathbf{B}(\\mathbf{x},t) &= \\nabla \\times \\mathbf{A}(\\mathbf{x},t). \\\\\n\\end{align*}\n\\] Let’s define \\[\nU(\\mathbf{x},\\mathbf{v},t) = q \\phi(\\mathbf{x},t) - \\frac{q}{c} \\mathbf{v} \\cdot \\mathbf{A}(\\mathbf{x},t).\n\\] Then the Lagrangian for this system is then given by \\(L=T-U\\), or \\[\nL = \\frac{1}{2} m \\mathbf{v}^2 - q \\phi + \\frac{q}{c} \\mathbf{v} \\cdot \\mathbf{A}.\n\\] Though a little painful, it’s not hard to show that solving Lagrange’s equations reproduces the above Lorentz force law.\n\nMore generally, we can always just manually add in any non-conservative forces to the equations of motion after Lagrange’s equations have been solved, but they’d need to be converted to generalized forces first. Given some force \\(\\mathbf{F}\\), we can augment Lagrange’s equations by writing \\[\n\\frac{\\partial L}{\\partial\\mathbf{q}} - \\frac{d}{dt}\\frac{\\partial L}{\\partial\\mathbf{\\dot q}} = \\mathbf{Q},\n\\] where \\(\\mathbf{Q} = \\mathbf{F} \\cdot \\frac{\\partial \\mathbf{x}}{\\partial \\mathbf{q}}\\) is the associated generalized force.\nIn the special case that a non-conservative force is linear in the generalized velocities, we can augment the Lagrangian by defining the Rayleigh dissipation function \\(\\mathcal{F}\\) given by \\[\n\\mathcal{F} \\equiv \\frac{1}{2} \\mathbf{\\dot q} \\cdot \\mathbf{B}(\\mathbf{q}) \\cdot \\mathbf{\\dot q} = \\sum_{i,j} b_{ij}(\\mathbf{q}) \\dot q_i \\dot q_j.\n\\] In this case, the generalized forces are just the gradients of \\(\\mathcal{F}\\), \\[\n\\mathbf{Q} = -\\frac{\\partial \\mathcal{F}}{\\partial \\mathbf{q}} = -\\mathbf{B} \\cdot \\mathbf{\\dot q},\n\\] which we can plug into the modified Lagrange’s equations to give \\[\n\\frac{\\partial L}{\\partial\\mathbf{q}} - \\frac{d}{dt}\\frac{\\partial L}{\\partial\\mathbf{\\dot q}} = \\frac{\\partial \\mathcal{F}}{\\partial\\mathbf{\\dot q}}.\n\\]\n\n\n\nExample: Damped Hanging Spring\nSuppose we have a spring with mass \\(m\\) and spring constant \\(k\\) allowed to hang from the top of a closed lid of thick syrup. Assume the viscosity of the syrup is high enough that Stoke’s Law holds.\nIn this case, we simply have \\[\n\\begin{align*}\nT &= \\frac{1}{2} m \\dot x^2, \\\\\nV &= -mgx - \\frac{1}{2} kx^2, \\\\\nL &= \\frac{1}{2} m \\dot x^2 + mgx + \\frac{1}{2} kx^2, \\\\\n\\mathcal{F} &= \\frac{1}{2} b \\dot x^2. \\\\\n\\end{align*}\n\\] Plugging these into the modified Lagrange’s equations finally gives the DDHO equation of motion \\[\nm \\ddot x + b \\dot x + kx = mg.\n\\]",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lagrangian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/lagrangian-mechanics.html#invariant-transformations",
    "href": "classical-mechanics/lagrangian-mechanics.html#invariant-transformations",
    "title": "Lagrangian Mechanics",
    "section": "Invariant Transformations",
    "text": "Invariant Transformations\nIt’s natural to ask what kinds of transformations of a Lagrangian leave it invariant. We already saw that when a system has certain symmetries that the Lagrangian will be invariant under those symmetry transformations. In that case, the Lagrangian itself didn’t change. More general, we could ask what kinds of transformations will leave the equations of motion unchanged, even if the Lagrangian itself did change.\nOne natural question to ask is how the Lagrangian behaves under a coordinate transformation. After all, the choice of coordinates should not affect the physical behavior of the system. Suppose we have two sets of coordinates to describe the system, \\(\\mathbf{q}\\) and \\(\\mathbf{Q}\\). They’re related by a transformation \\(\\mathbf{Q} = \\mathbf{Q}(\\mathbf{q})\\), called a point transformation. The transformed velocities \\(\\mathbf{\\dot Q}\\) are a function of both \\(\\mathbf{q}\\) and \\(\\mathbf{\\dot q}\\), since \\[\n\\mathbf{\\dot Q} = \\mathbf{\\dot Q}(\\mathbf{q}, \\mathbf{\\dot q}) = \\mathbf{\\dot q}\\frac{\\partial \\mathbf{Q}}{\\partial \\mathbf{q}}.\n\\] Suppose the Lagrangian in each coordinate system is given by \\(L_q = L(\\mathbf{q}, \\mathbf{\\dot q}, t)\\) and \\(L_Q = L(\\mathbf{Q}, \\mathbf{\\dot Q}, t)\\) respectively. Assume that \\(L_q\\) satisfies Lagrange’s equations, so \\[\n\\frac{\\partial L_q}{\\partial \\mathbf{q}} + \\frac{d}{dt} \\frac{\\partial L_q}{\\partial \\mathbf{\\dot q}} = \\mathbf{0}.\n\\] What then can we conclude about \\(L_Q\\)? If we express \\(L_Q\\) in terms of \\(\\mathbf{q}\\), we’d have \\[\nL_Q = L\\big(\\mathbf{q}(\\mathbf{Q}), \\mathbf{\\dot q}(\\mathbf{Q}, \\mathbf{\\dot Q}), t\\big).\n\\] Taking derivatives of \\(L_Q\\) with respect to \\(\\mathbf{Q}\\), then \\[\n\\begin{align*}\n\\frac{\\partial L_Q}{\\partial \\mathbf{Q}} &=  \\frac{\\partial \\mathbf{q}}{\\partial \\mathbf{Q}} \\cdot \\frac{\\partial L_q}{\\partial \\mathbf{q}} + \\frac{\\partial \\mathbf{\\dot q}}{\\partial \\mathbf{Q}} \\cdot \\frac{\\partial L_q}{\\partial \\mathbf{\\dot q}} \\\\\n&= \\frac{\\partial \\mathbf{q}}{\\partial \\mathbf{Q}} \\cdot \\frac{d}{dt} \\frac{\\partial L_q}{\\partial \\mathbf{\\dot q}} + \\frac{d}{dt} \\frac{\\partial \\mathbf{q}}{\\partial \\mathbf{Q}} \\cdot \\frac{\\partial L_q}{\\partial \\mathbf{\\dot q}} \\\\\n&= \\frac{d}{dt} \\bigg(\\frac{\\partial \\mathbf{q}}{\\partial \\mathbf{Q}} \\cdot \\frac{\\partial L_q}{\\partial \\mathbf{\\dot q}}\\bigg) \\\\\n&= \\frac{d}{dt} \\bigg(\\frac{\\partial \\mathbf{\\dot q}}{\\partial \\mathbf{\\dot Q}} \\cdot \\frac{\\partial L_q}{\\partial \\mathbf{\\dot q}}\\bigg) \\\\\n&= \\frac{d}{dt} \\frac{\\partial L_Q}{\\partial \\mathbf{\\dot Q}}.\n\\end{align*}\n\\] Thus, if \\(L_q\\) satisfies Lagrange’s equations with respect to \\(\\mathbf{q}\\), then \\(L_Q\\) satisfies Lagrange’s equations with respect to \\(\\mathbf{Q}\\). That is, the equations of motion are invariant to point transformations of the coordinates.\nThis fact means we’re essentially free to write the Lagrangian of a system in whatever set of coordinates we wish. The underlying physics will stay the same. In relativistic language, this result says that the Lagrangian is a proper scalar. It doesn’t transform under coordinate transformations.\nIt’s also natural to ask if we can add functions to a Lagrangian in a way that leave the equations of motion invariant. This leads to the notion of a gauge transformation. To leave the equations of motion invariant, it’s important that any such transformation leave the action stationary.\nSuppose we transformed a valid Lagrangian by adding a total time derivative to it, \\[\n\\tilde L(\\mathbf{q}, \\mathbf{\\dot q}, t) = L(\\mathbf{q}, \\mathbf{\\dot q}, t) + \\frac{d}{dt} F(t).\n\\] If we assume the original equations of motion satisfy the principle of least action, we have \\(\\delta S=0\\), where \\[\nS = \\int_{t_1}^{t_2} L(\\mathbf{q}, \\mathbf{\\dot q}, t) dt.\n\\] Evidently, the modified action \\(\\tilde S\\) has the form \\[\n\\begin{align*}\n\\tilde S &= \\int_{t_1}^{t_2} \\tilde L(\\mathbf{q}, \\mathbf{\\dot q}, t) dt \\\\\n&= \\int_{t_1}^{t_2} \\bigg(L(\\mathbf{q}, \\mathbf{\\dot q}, t) +  \\frac{d}{dt} F(t) \\bigg)dt \\\\\n&= \\int_{t_1}^{t_2} L(\\mathbf{q}, \\mathbf{\\dot q}, t)dt + F(t) \\bigg|_{t_1}^{t_2} \\\\\n&= S + \\Delta F.\n\\end{align*}\n\\] Since \\(\\Delta F\\) is a constant that depends only on the endpoints, we must have \\[\n\\delta S = 0 \\quad \\Longleftrightarrow \\quad \\delta\\tilde S = 0.\n\\] That is, adding a total time derivative to the Lagrangian leaves the equations of motion invariant.\n\n\nExample: Gauge Transformations\nIn electrodynamics, Maxwell’s Equations are known to be invariant under a change of gauge. We can add the derivative of any scalar field \\(\\lambda(\\mathbf{x},t)\\) to the electromagnetic potentials in the following way and leave Maxwell’s Equations invariant, \\[\n\\begin{align*}\n\\phi'(\\mathbf{x},t) &= \\phi(\\mathbf{x},t) - \\frac{1}{c} \\frac{\\partial}{\\partial t} \\lambda(\\mathbf{x},t), \\\\\n\\mathbf{A}'(\\mathbf{x},t) &= \\mathbf{A}(\\mathbf{x},t) + \\nabla \\lambda(\\mathbf{x},t). \\\\\n\\end{align*}\n\\] Suppose we had a particle moving in the presence of an electromagnetic field. We already showed such a Lagrangian would have the form \\[\nL = \\frac{1}{2} m \\mathbf{v}^2 - q \\phi(\\mathbf{x},t) + \\frac{q}{c} \\mathbf{v} \\cdot \\mathbf{A}(\\mathbf{x},t).\n\\] Let’s ask what happens to the Lagrangian if we gauge-transform the potentials. Evidently, \\[\n\\begin{align*}\nL' &= \\frac{1}{2} m \\mathbf{v}^2 - q \\phi' + \\frac{q}{c} \\mathbf{v} \\cdot \\mathbf{A}' \\\\\n&= \\frac{1}{2} m \\mathbf{v}^2 - q \\bigg(\\phi - \\frac{1}{c} \\frac{\\partial \\lambda}{\\partial t} \\bigg) + \\frac{q}{c} \\mathbf{v} \\cdot (\\mathbf{A} + \\nabla \\lambda) \\\\\n&= \\bigg(\\frac{1}{2} m \\mathbf{v}^2 - q\\phi + \\frac{q}{c}\\mathbf{v} \\cdot \\mathbf{A}\\bigg) + \\frac{q}{c} \\bigg(\\mathbf{v} \\cdot \\nabla \\lambda + \\frac{\\partial \\lambda}{\\partial t}\\bigg) \\\\\n&= L + \\frac{q}{c} \\frac{d\\lambda}{dt}.\n\\end{align*}\n\\] Since the gauge-transformed Lagrangian is just the original Lagrangian plus a total time derivative, we can conclude the the Lorentz force law must be gauge invariant as well. Of course, this was already obvious from the fact that \\(\\mathbf{E}\\) and \\(\\mathbf{B}\\) were gauge invariant in Maxwell’s equations.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lagrangian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/lagrangian-mechanics.html#examples",
    "href": "classical-mechanics/lagrangian-mechanics.html#examples",
    "title": "Lagrangian Mechanics",
    "section": "Examples",
    "text": "Examples\nIt’s good to get very comfortable being able to find the equations of motion of systems using Lagrange’s equations. Here are some more complicated examples, many of which would be highly non-trival to solve using Newton’s Laws.\n\n\nExample: Uniform Rod on a Frictionless Table\n\n\n\n\n\n\n\n\nExample: Atwood Machine\n\n\n\n\n\n\n\n\nExample: Particle on a Cylinder\n\n\n\n\n\n\n\n\nExample: Block Sliding on Moving Wedge\n\n\n\n\n\n\n\n\nExample: Bead on a Wire",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lagrangian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/coupled-oscillations.html",
    "href": "classical-mechanics/coupled-oscillations.html",
    "title": "Coupled Oscillations",
    "section": "",
    "text": "One-Dimensional Systems\nConsider a system with one degree of freedom \\(q\\) in the presence of a potential energy \\(V(q)\\). We say such a system has an equilibrium point at \\(q=q_0\\) provided \\[\nF = -\\frac{dV}{dq} \\bigg|_{q=q_0} = 0.\n\\] Equivalently, \\(q_0\\) is an equilibrium point if it’s a stationary point of \\(V(q)\\). We say \\(q_0\\) is stable if it’s a local minimum of \\(V(q)\\), unstable if it’s a local maximum of \\(V(q)\\), and semi-stable if it’s a saddlepoint. In general, a potential energy \\(V(q)\\) may have many different equilibrium points.\nNow, if we expand \\(V(q)\\) in a Taylor Series about \\(q_0\\), we get \\[\nV(q) = V(q_0) + \\frac{dV}{dq}\\bigg|_{q_0} (q - q_0) + \\frac{1}{2} \\frac{d^2 V}{dq^2}\\bigg|_{q_0} (q - q_0)^2 + O\\big((q-q_0)^3\\big).\n\\] Since only differences in potential energy can affect the dynamics of a system, we can suppose without loss of generality that \\(V(q_0) = 0\\). Since \\(q_0\\) is an equilibrium point, we must also have \\(\\frac{dV}{dq}\\big|_{q_0} = 0\\). We’re thus left with \\[\nV(q) = \\frac{1}{2} \\frac{d^2 V}{dq^2}\\bigg|_{q_0} (q - q_0)^2 + O\\big((q-q_0)^3\\big).\n\\] We can always re-center the system so that \\(q_0=0\\). If we define \\(k \\equiv \\frac{d^2 V}{dq^2}\\big|_{q_0}\\), we evidently have \\[\nV(q) = \\frac{1}{2} k q^2.\n\\] But this is just the potential energy for Hooke’s Law, since \\(F = -\\frac{dV}{dq} = -kq\\). We’ve thus evidently defined Hooke’s Law from the assumption that a system is undergoing small motions near an equilibrium point.\nMotions will only be small oscillations if the equilibrium point \\(q_0\\) is stable, which is equivalent to requiring that \\(k &gt; 0\\) since \\(V(q_0)\\) is locally convex. If \\(k &lt; 0\\) the motion will be unstable since \\(V(q_0)\\) is locally concave. If \\(k=0\\) we run into a special case where we have to consider higher orders in the Taylor Series expansion. In this case, motion will be very near constant around \\(q_0\\), but can either grow or decay as \\(q\\) gets farther from \\(q_0\\).\nWe can also plug \\(V(q)\\) into the Lagrangian and get \\[\nL \\approx \\frac{1}{2}m \\dot q^2 - \\frac{1}{2} k q^2,\n\\] which is of course just the Lagrangian for SHO. We’ve thus derived the following important fact: Any 1-dimensional system undergoing small oscillations near a stable equilibrium point can be well-approximated by a simple harmonic oscillator.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Coupled Oscillations</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/coupled-oscillations.html#one-dimensional-systems",
    "href": "classical-mechanics/coupled-oscillations.html#one-dimensional-systems",
    "title": "Coupled Oscillations",
    "section": "",
    "text": "Example: Kepler Orbits\nRecall for Kepler orbits we have a Lagrangian \\(L = \\frac{1}{2}m\\dot r^2 - V_{eff}(r)\\), where \\[\nV_{eff}(r) = \\frac{\\ell^2}{2mr^2} - \\frac{GMm}{r}.\n\\] This effective potential has a stable equilibrium when the orbits are circular, i.e. \\(r=r_0\\).\nSetting the first derivative of \\(V_{eff}(q)\\) to zero gives \\[\n\\frac{dV_{eff}}{dr}\\bigg|_{r_0} = -\\frac{\\ell^2}{mr_0^3} + \\frac{GMm}{r_0^2} = 0 \\quad \\Longrightarrow \\quad r_0 = \\frac{\\ell^2}{GMm^2}.\n\\] Setting the second derivative to \\(k\\) gives \\[\nk = \\frac{d^2V_{eff}}{dr^2}\\bigg|_{r_0} = 3\\frac{\\ell^2}{mr_0^4} - 2\\frac{GMm}{r_0^3} = \\frac{GMm}{r_0^3} &gt; 0.\n\\] Thus, the Kepler orbit undergoes stable oscillations about the point \\(r=r_0\\), with a force law \\(F(r) \\approx -k(r-r_0)\\). The oscillation frequency and period are given by \\[\n\\omega = \\sqrt{\\frac{k}{m}} = \\sqrt{GM}{r_0^3} \\quad \\Longrightarrow \\quad \\tau = \\frac{2\\pi}{\\sqrt{GM}} r_0^{3/2},\n\\] which is just Kepler’s Third Law for circular orbits.\n\n\n\nExample: Two Coupled Springs\nBefore deriving the general form for the solution of coupled linear systems, let’s try to solve the problem of two springs attached to each other in sequence. Assume both masses have mass \\(m\\). Assume the springs attached to the walls have spring constant \\(k\\), and the coupling spring constant between the two masses is \\(k_{12}\\).\n\n\n\n\n\nDenote the position of mass one relative to its equilibrium as \\(x_1\\), and the position of mass two relative to its equilibrium by \\(x_2\\). Then the Lagrangian is \\[\nL = \\frac{1}{2} m (\\dot x_1^2 + \\dot x_2^2) - \\frac{1}{2}(kx_1^2 + k_{12}(x_2-x_1)^2 + kx_2^2).\n\\] The equations of motion are thus given by \\[\n\\begin{align*}\nm \\ddot x_1 &= -kx_1 + k_{12}(x_2 - x_1), \\\\\nm \\ddot x_2 &= -kx_1 - k_{12}(x_2 - x_1).\n\\end{align*}\n\\] This is a coupled system of two linear differential equations. To solve, let’s suppose that both solutions are sinusoidal with the same frequency \\(\\omega\\), say \\(x_1 = A_1 \\cos\\omega t\\) and \\(x_2 = A_2 \\cos\\omega t\\). Then we have",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Coupled Oscillations</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/coupled-oscillations.html#general-problem",
    "href": "classical-mechanics/coupled-oscillations.html#general-problem",
    "title": "Coupled Oscillations",
    "section": "General Problem",
    "text": "General Problem\nLet’s now consider a system with \\(n\\) degrees of freedom \\(q_1, q_2, \\cdots, q_n\\) given by a Lagrangian \\[\nL = \\frac{1}{2} \\dot q_i T_{ij}(q_1,\\cdots,q_n) \\dot q_j - V(q_1,\\cdots,q_n).\n\\] Let’s re-write this in vector notation by defining \\(\\mathbf{q} \\equiv (q_1,q_2,\\cdots,q_n)\\) and \\(\\mathbf{T} \\equiv (T_{ij})\\). Then we have \\[\nL = \\frac{1}{2}\\mathbf{\\dot q}^\\top \\mathbf{T}(\\mathbf{q}) \\mathbf{\\dot q} - V(\\mathbf{q}).\n\\] Now, suppose \\(\\mathbf{q}_0\\) is an equilibrium point of the system. Since the kinetic energy depends on \\(\\mathbf{q}\\) we’ll have to Taylor expand the entire Lagrangian about \\(\\mathbf{q}_0\\). For \\(V(\\mathbf{q})\\) we have \\[\nV(\\mathbf{q}) = V(\\mathbf{q}_0) + \\nabla V^\\top(\\mathbf{q}_0) (\\mathbf{q}-\\mathbf{q}_0) + \\frac{1}{2} (\\mathbf{q}-\\mathbf{q}_0)^\\top \\mathbf{H}(\\mathbf{q_0}) (\\mathbf{q}-\\mathbf{q}_0) + O\\big(||\\mathbf{q}-\\mathbf{q}_0||^3\\big).\n\\] Again, only differences in potential energy matter, so we can define \\(V(\\mathbf{q}_0) = 0\\). Furthermore, since \\(\\mathbf{q}_0\\) is an equilibrium point, we must have \\(\\nabla V(\\mathbf{q}_0) = \\mathbf{0}\\). Let’s define \\(\\mathbf{K} \\equiv \\mathbf{H}(\\mathbf{q}_0)\\). Then, to second-order in \\(\\mathbf{q}-\\mathbf{q}_0\\) we have \\[\nV(\\mathbf{q}) \\approx \\frac{1}{2} (\\mathbf{q}-\\mathbf{q}_0)^\\top \\mathbf{K} (\\mathbf{q}-\\mathbf{q}_0).\n\\] For the kinetic energy term, expanding \\(\\mathbf{T}(\\mathbf{q})\\) about \\(\\mathbf{q}_0\\) in a similar manner gives \\[\n\\mathbf{T}(\\mathbf{q}) = \\mathbf{T}(\\mathbf{q}_0) + O\\big(||\\mathbf{q}-\\mathbf{q}_0|| \\big).\n\\] Defining \\(\\mathbf{M} \\equiv \\mathbf{T}(\\mathbf{q}_0)\\) and dropping terms of higher order, we have \\(\\mathbf{T}(\\mathbf{q}) \\approx \\mathbf{M}\\). Plugging both of these terms into the Lagrangian and keeping only terms quadratic in \\(\\mathbf{q}\\) and \\(\\mathbf{q}_0\\), we finally have, \\[\nL \\approx \\frac{1}{2} \\mathbf{\\dot q}^\\top \\mathbf{M} \\mathbf{\\dot q} - \\frac{1}{2} (\\mathbf{q}-\\mathbf{q}_0)^\\top \\mathbf{K} (\\mathbf{q}-\\mathbf{q}_0).\n\\] This is the most general form of the Lagrangian for a many-body mechanical system when expanded to quadratic order about an equilibrium point. Most of the time we’ll want to re-center so that \\(\\mathbf{q}_0 = \\mathbf{0}\\). In that case, the Lagrangian reduces to just \\[\nL \\approx \\frac{1}{2} \\mathbf{\\dot q}^\\top \\mathbf{M} \\mathbf{\\dot q} - \\frac{1}{2} \\mathbf{q}^\\top \\mathbf{K} \\mathbf{q}.\n\\] Notice this looks exactly like the scalar Lagrangian for SHO, \\(L = \\frac{1}{2}m \\dot q^2 - \\frac{1}{2} k q^2\\), except everything is in matrix-vector notation now.\nWe can solve Lagrange’s equations in matrix-vector notation now, \\[\n\\frac{dL}{d\\mathbf{q}} + \\frac{d}{dt}\\frac{dL}{d\\mathbf{\\dot q}} = \\mathbf{0}.\n\\] Solving this system simply gives the vector equations of motion \\[\n\\mathbf{M}\\mathbf{\\ddot q} = -\\mathbf{K}\\mathbf{q},\n\\] which is the \\(n\\)-dimensional generalization of Hooke’s Law.\nAssuming \\(\\mathbf{M}\\) is invertible, we can define \\(\\mathbf{\\Omega}^2 \\equiv \\mathbf{M}^{-1} \\mathbf{K}\\), and write \\[\n\\mathbf{\\ddot q} = -\\mathbf{\\Omega}^2 \\mathbf{q}.\n\\] The nature of the solutions will depend on the definiteness of \\(\\mathbf{\\Omega}^2\\). Evidently, if \\(\\mathbf{\\Omega}^2\\) is positive definite, the solutions will be stable. If \\(\\mathbf{\\Omega}^2\\) is negative definite, the solutions will be unstable.\nSkip to the rest of the theory before doing more examples…\nPer ChatGPT: The general solution to the coupled oscillator \\(M \\ddot x = -K x\\) in closed form can be written as \\[\nx(t) = V \\cos(\\Omega t) c + V \\sin(\\Omega t) d,\n\\] where \\(V\\) is the matrix of eigenvectors of \\(\\Omega^2 = M^{-1} K\\), and \\(c, d\\) are initial condition vectors.\nVerify this!!!",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Coupled Oscillations</span>"
    ]
  },
  {
    "objectID": "electrodynamics/preliminaries.html",
    "href": "electrodynamics/preliminaries.html",
    "title": "Preliminaries",
    "section": "",
    "text": "Units\nWe’ll start by saying a word about units. Typically in physics we need not think much about units. Abstractly the formulas look the same, whether the quantities involved are measured in meters, feet, or lightyears. However, electromagnetism has the unusual quirk that different unit systems lead to slightly different looking formulas. The reasons for this are largely historical, and very little if any physics is involved in the way these formulas look in different systems of units. An important implication of this frustrating quirk is that we have to be much more careful at the outset to specify which units we’re using since it will affect the formulas involved in derivations and calculations. To start, we’ll very briefly look at several different systems of units before committing to one for the rest of the course.\nThe foundation of systems of units in electromagnetism are forces on and due to the presence of charges and currents. It was found early on that there are two types of electric charge, positive and negative. Two like charges repel, while two opposite charges attract. The force between those charges also depends on the distance between them in a specific way. Suppose two charges \\(q_1\\) and \\(q_2\\) are separated from each other by a distance \\(r\\). The magnitude of the force felt by the two charges is given by an inverse square law known as Coulomb’s Law, \\[\nF = k_e \\frac{q_1 q_2}{r^2} \\ .\n\\] The proportionality constant \\(k_e\\) is known as the electric constant whose dimension and value depends on choice of units. The quantity \\(k_e q_1 q_2\\) can be measured in the lab by measuring the strength of the force and the distance between the two charges.\nA little while later people figured out how to run moving charges, or currents, through wires. In studying the behavior of current flowing through two nearby parallel wires, it was found that the wires repel each other when the currents move in the same direction, and repel each other when the currents move in the opposite direction. The force also seemed to depend on the distance between the wires. Suppose two parallel wires a distance \\(r\\) apart are carrying currents \\(I_1\\) and \\(I_2\\). Suppose each wire has the same fixed length \\(\\ell\\). Then the force experienced by the two wires due to the currents is given by Ampere’s Force Law,\n\\[\n\\frac{dF}{d\\ell} = 2k_m \\frac{I_1 I_2}{r} \\ .\n\\] The proportionality constant \\(k_m\\) is yet another constant that depends on units. The quantity \\(k_m I_1 I_2\\) can be measured in the lab by measuring the strength of the force per unit length and the distance of separation between the two wires.\nIt was further realized later that these two phenomena can be generalized using the notion of fields. The force felt by a charge due to other charges can also be thought of as a force on a charge felt by an electric field \\(\\mathbf{E}(\\mathbf{x},t)\\) that sums of the effects of all the other background charges. The force felt on a charge \\(q\\) is evidently proportional to this electric field, \\(\\mathbf{F} \\propto q \\mathbf{E}\\). A similar description can be made for the forces felt on a moving charge, i.e. a current, due to the presence of a magnetic field \\(\\mathbf{B}(\\mathbf{x},t)\\) that sums up the effects of all other background currents. This force felt on a moving charge \\(q\\) is proportional to both its velocity \\(\\mathbf{v}\\) and the magnetic field, with \\(\\mathbf{F} \\propto q\\mathbf{v} \\times \\mathbf{B}\\). If we try to sum these two forces together to get the combined force on the moving charge we have to establish how the electric and magnetic fields dimensionally relate to each other. This combined force law is known as the Lorentz Force Law, given generally by \\[\n\\mathbf{F} = q \\bigg(\\mathbf{E} + \\frac{\\mathbf{v}}{\\alpha} \\times \\mathbf{B}\\bigg) \\ .\n\\] Here we introduce a new constant \\(\\alpha\\) to control the dimensional relationship between \\(\\mathbf{E}\\) and \\(\\mathbf{B}\\). Initially this was ignored and \\(\\alpha=1\\) was chosen without people really thinking about it. But later on it was realized that the two fields should actually be thought of as essentially the same object and should thus have the same dimensions. For this to be true, \\(\\alpha\\) must be chosen to be some constant with dimensions of velocity.\nThe three parameters \\(k_e, k_m, \\alpha\\) are not completely independent though. Most importantly, dimensional analysis and experiment force \\(k_e\\) and \\(k_m\\) to be related in a very specific way, namely by \\[\nc^2 = \\frac{k_e}{k_m} \\ ,\n\\] where \\(c\\) is the speed of light in vacuum, a fundamental constant measured to be \\(c \\approx 3 \\cdot 10^{10} \\ \\frac{\\text{cm}}{\\text{s}}\\). Several experiments already concluded that \\(c\\) was indeed a universal constant with no dependence on choice of reference frame. This ratio evidently thus gives us a natural velocity scale, which coincidentally is what we’d need to fix \\(\\alpha\\) to make \\(\\mathbf{E}\\) and \\(\\mathbf{B}\\) to have the same units.\nIn the early days of electromagnetism the centimeter-gram-second or CGS system was already being widely used to measure mechanical quantities like length, mass, time, force, and energy. The unit of force was called the dyne, which comes out to \\(1 \\ \\text{dyne} = 10^{-5} \\ \\text{N}\\), while the unit of energy was called the erg, which comes out to \\(1 \\ \\text{erg} = 10^{-7} \\ \\text{J}\\). When electromagnetism came along it was realized these mechanical units needed to somehow be extended to cover electromagnetic phenomena as well, but that there were different all self consistent ways this could be done based on how \\(k_e, k_m, \\alpha\\) were specified.\nEarly on two unit systems arose to cover electromagnetism, one being used to measure electric quantities, and a completely different one used to measure magnetic quantities. The early system of units for electricity was called electrostatic units or the ESU system. This system defined \\(k_e\\equiv\\alpha\\equiv1\\), which then forced \\(k_m \\equiv \\frac{1}{c^2}\\). This defined a natural unit of charge, later called the electrostatic unit or esu, with \\(1 \\ \\text{esu} \\approx 3.3 \\cdot 10^{-10} \\ \\text{C}\\). An analogous system arose to study magnetism, called electromagnetic units or the EMU system. This system defined \\(k_m \\equiv \\alpha \\equiv 1\\), which then forced \\(k_e = c^2\\). This defined a natural unit of current, later called the absolute amp or abamp, with \\(1 \\ \\text{abamp} = 10 \\ \\text{A}\\) exactly.\nIt was found to be cumbersome to go back and forth between the two subjects since one had to change units to compare results. It was also eventually realized that having the electric and magnetic fields be different dimensions didn’t make sense, as Einstein showed the two fields were really just the same field expressed in different reference frames. The two unit systems were then combined into yet a third system called the Gaussian system. The Gaussian system also uses CGS mechanical units, but takes \\[\nk_e \\equiv 1 \\quad , \\quad k_m \\equiv \\frac{1}{c^2} \\quad , \\quad \\alpha \\equiv c \\ .\n\\] This system had the benefit that the unit of charge was still the esu, but now the electric and magnetic fields have the same units. The unit of current is no longer the abamp, but instead the esu per second. The Gaussian system became popular among physicists, especially among theorists due to the fact that electricity and magnetism were treated on the same footing.\nHowever, things played out differently on the engineering side. While physicists were studying electromagnetism in the lab, engineers were starting to use these ideas to build practical things like wires, motors, transformers, circuits, and radios. Engineers at the time didn’t like the fact that when that CGS units were poorly scaled to measure everyday things like the current through a telegraph wire or the voltage across a resistor. They instead chose to use a different system based on the meter, kilogram, and second, called the MKS system. The abamp was seen as too big for electrical applications of the time, so they defined a smaller unit of current called the amp or Ampere, defined by \\(1 \\ \\text{A} \\equiv 0.1 \\ \\text{abamp}\\).\nLater on, MKS units were extended to the rest of electromagnetism, but in a kind of quirky way. It was decided to define \\[\nk_e \\equiv \\frac{1}{4\\pi\\varepsilon_0} \\quad , \\quad k_m \\equiv \\frac{\\mu_0}{2\\pi} \\quad , \\quad \\alpha \\equiv 1 \\ .\n\\] This odd definition was chosen out of the prevelant belief at the time that electromagnetic phenomena permuated in a fluid known as the ether, which they believed had a natural permittivity and permeability like any other material. This idea was later invalided through experiments, but the notation persists unfortunately. The division by \\(4\\pi\\) was arbitrary, done to rationalize out any factors of \\(\\pi\\) from Maxwell’s equations. As with the ESU and EMU systems, the electric and magnetic fields be of the same units wasn’t seen as an imperative, so no scaling by the speed of light was done either.\nThe constants \\(\\varepsilon_0\\) and \\(\\mu_0\\) were chosen as the more fundamental constants due to a misbelief that the vacuum was made of an electromagnetic fluid known as the ether, which was later falsified by experiment. These constants were tuned in the MKSA system specifically so that unit of current would come out to be exactly a tenth of an abamp. For this to work out consistently, they defined \\[\n\\mu_0 \\equiv 4\\pi \\cdot 10^{-7} \\ \\frac{\\text{N}}{\\text{A}^2} \\quad , \\quad \\varepsilon_0 \\equiv \\frac{10^7}{4\\pi c^2} \\approx 8.84 \\cdot 10^{-14} \\ \\frac{\\text{A}^2 \\ \\text{s}^4}{\\text{kg} \\ \\text{m}^3} \\ .\n\\]\nThis extended MKS system adds a fourth independent unit, the Ampere. All other electromagnetic quantities are then naturally defined in terms of the values of the meter, kilogram, second, and the Ampere. It’s this system, sometimes called the MKSA system, that later become the SI system used widely today in science and engineering.\nOn top of all these systems yet another system of units for electromagnetism was defined that closely relates to the Gaussian system. This system of units is called the Heaviside-Lorentz system. It also uses the CGS system and takes \\(\\alpha=c\\), but it follows the MKSA system in choosing to rationalize out the factors of \\(4\\pi\\) from Maxwell’s equations. It thus chooses \\[\nk_e \\equiv \\frac{1}{4\\pi} \\quad , \\quad k_m \\equiv \\frac{1}{4\\pi c^2} \\quad , \\quad \\alpha \\equiv c \\ .\n\\] As with the Gaussian system, in the Heaviside-Lorentz the electric and magnetic fields again have the same units. The only real difference is that the measured units change by a factor of \\(4\\pi\\), and the factors of \\(4\\pi\\) are removed from Maxwell’s equations.\nNowadays, the ESU and EMU systems are rarely if ever used. The SI system is of course widely used, particularly among experimentalists and engineers, as well as in essentially all modern undergraduate electromagnetism textbooks. The Heaviside-Lorentz system is favored by the particle physics community, perhaps because they often set \\(c=1\\), which makes the formulas look similar to those in the SI system. The Gaussian system remains popular particularly among theoretical physicists due to its symmetric treatment of the electric and magnetic fields and its use of a single constant in formulas, the speed of light \\(c\\).\nWhile each choice of units has its benefits depending on the field of study and the application, in this course we will stick primarily with the Gaussian system of units, which is well-suited to a theoretical study of electromagnetism. To go back and forth between Gaussian and SI units in various formulas, a useful trick that often works (but not always) is to make the identification \\[\n\\varepsilon_0 \\leftrightarrow \\frac{1}{4\\pi} \\quad , \\quad \\mu_0 \\leftrightarrow \\frac{4\\pi}{c} \\ .\n\\]\nBelow is a table of various electromagnetism formulas expressed in the three unit systems still in widespread use today. We’ll define or derive all of these formulas in more details in later lessons.",
    "crumbs": [
      "Electrodynamics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Preliminaries</span>"
    ]
  },
  {
    "objectID": "electrodynamics/preliminaries.html#units",
    "href": "electrodynamics/preliminaries.html#units",
    "title": "Preliminaries",
    "section": "",
    "text": "Gaussian\nHeaviside-Lorentz\nSI\n\n\n\n\nElectric Field\n\\(\\mathbf{E} = -\\nabla \\Phi + \\frac{1}{c}\\frac{\\partial \\mathbf{A}}{\\partial t}\\)\n\\(\\mathbf{E} = -\\nabla \\Phi + \\frac{1}{c}\\frac{\\partial \\mathbf{A}}{\\partial t}\\)\n\\(\\mathbf{E} = -\\nabla \\Phi + \\frac{\\partial \\mathbf{A}}{\\partial t}\\)\n\n\nMagnetic Field\n\\(\\mathbf{B} = \\nabla \\times \\mathbf{A}\\)\n\\(\\mathbf{B} = \\nabla \\times \\mathbf{A}\\)\n\\(\\mathbf{B} = \\nabla \\times \\mathbf{A}\\)\n\n\nCoulomb’s Law\n\\(\\mathbf{E} = \\frac{q}{r^2} \\mathbf{e}_r\\)\n\\(\\mathbf{E} = \\frac{1}{4\\pi}\\frac{q}{r^2} \\mathbf{e}_r\\)\n\\(\\mathbf{E} = \\frac{1}{4\\pi\\varepsilon_0}\\frac{q}{r^2} \\mathbf{e}_r\\)\n\n\nBiot-Savart Law\n\\(d\\mathbf{B} = \\frac{I}{c} \\frac{d\\boldsymbol{\\ell} \\times \\mathbf{e}_r}{r^2}\\)\n\\(d\\mathbf{B} = \\frac{I}{4\\pi c} \\frac{d\\boldsymbol{\\ell} \\times \\mathbf{e}_r}{r^2}\\)\n\\(d\\mathbf{B} = \\frac{\\mu_0 I}{4\\pi} \\frac{d\\boldsymbol{\\ell} \\times \\mathbf{e}_r}{r^2}\\)\n\n\nLorentz Force Law\n\\(\\mathbf{F} = q\\mathbf{E} + q\\frac{\\mathbf{v}}{c} \\times \\mathbf{B}\\)\n\\(\\mathbf{F} = q\\mathbf{E} + q\\frac{\\mathbf{v}}{c} \\times \\mathbf{B}\\)\n\\(\\mathbf{F} = q\\mathbf{E} + q\\mathbf{v} \\times \\mathbf{B}\\)\n\n\nDisplacement Field\n\\(\\mathbf{D} = \\mathbf{E} + 4\\pi \\mathbf{P}\\)\n\\(\\mathbf{D} = \\mathbf{E} + \\mathbf{P}\\)\n\\(\\mathbf{D} = \\varepsilon_0 \\mathbf{E} + \\mathbf{P}\\)\n\n\nMagnetizing Field\n\\(\\mathbf{H} = \\mathbf{B} - 4\\pi \\mathbf{M}\\)\n\\(\\mathbf{H} = \\mathbf{B} - \\mathbf{M}\\)\n\\(\\mathbf{H} = \\frac{1}{\\mu_0}\\mathbf{B} - \\mathbf{M}\\)\n\n\nGauss’s Law\n\\(\\nabla \\cdot \\mathbf{E} = 4\\pi \\rho\\)\n\\(\\nabla \\cdot \\mathbf{E} = \\rho\\)\n\\(\\nabla \\cdot \\mathbf{E} = \\frac{\\rho}{\\varepsilon_0}\\)\n\n\nFaraday’s Law\n\\(\\nabla \\times \\mathbf{E} = -\\frac{1}{c} \\frac{\\partial \\mathbf{B}}{\\partial t}\\)\n\\(\\nabla \\times \\mathbf{E} = -\\frac{1}{c}\\frac{\\partial \\mathbf{B}}{\\partial t}\\)\n\\(\\nabla \\times \\mathbf{E} = -\\frac{\\partial \\mathbf{B}}{\\partial t}\\)\n\n\nGauss’s Law for Magnetism\n\\(\\nabla \\cdot \\mathbf{B} = 0\\)\n\\(\\nabla \\cdot \\mathbf{B} = 0\\)\n\\(\\nabla \\cdot \\mathbf{B} = 0\\)\n\n\nAmpere-Maxwell Law\n\\(\\nabla \\times \\mathbf{B} = \\frac{4\\pi}{c} \\mathbf{J} + \\frac{1}{c} \\frac{\\partial \\mathbf{E}}{\\partial t}\\)\n\\(\\nabla \\times \\mathbf{B} = \\frac{1}{c} \\mathbf{J} + \\frac{1}{c} \\frac{\\partial \\mathbf{E}}{\\partial t}\\)\n\\(\\nabla \\times \\mathbf{B} = \\mu_0 \\mathbf{J} + \\mu_0 \\varepsilon_0 \\frac{\\partial \\mathbf{E}}{\\partial t}\\)\n\n\nContinuity Equation\n\\(\\nabla \\cdot \\mathbf{J} = -\\frac{\\partial \\rho}{\\partial t}\\)\n\\(\\nabla \\cdot \\mathbf{J} = -\\frac{\\partial \\rho}{\\partial t}\\)\n\\(\\nabla \\cdot \\mathbf{J} = -\\frac{\\partial \\rho}{\\partial t}\\)\n\n\nOhm’s Law\n\\(\\mathbf{J} = \\sigma \\mathbf{E}\\)\n\\(\\mathbf{J} = \\sigma \\mathbf{E}\\)\n\\(\\mathbf{J} = \\sigma \\mathbf{E}\\)\n\n\nEnergy Density\n\\(u = \\frac{1}{8\\pi} (|\\mathbf{E}|^2 + |\\mathbf{B}|^2)\\)\n\\(u = \\frac{1}{2} (|\\mathbf{E}|^2 + |\\mathbf{B}|^2)\\)\n\\(u = \\frac{\\varepsilon_0}{2} |\\mathbf{E}|^2 + \\frac{1}{2\\mu_0} |\\mathbf{B}|^2\\)\n\n\nPoynting Vector\n\\(\\mathbf{S} = \\frac{c}{4\\pi} \\mathbf{E} \\times \\mathbf{B}\\)\n\\(\\mathbf{S} = c \\mathbf{E} \\times \\mathbf{B}\\)\n\\(\\mathbf{S} = \\frac{1}{\\mu_0} \\mathbf{E} \\times \\mathbf{B}\\)",
    "crumbs": [
      "Electrodynamics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Preliminaries</span>"
    ]
  },
  {
    "objectID": "electrodynamics/preliminaries.html#math-review",
    "href": "electrodynamics/preliminaries.html#math-review",
    "title": "Preliminaries",
    "section": "Math Review",
    "text": "Math Review\nHere we give a very brief review of some important mathematical results that will be important in our study of electrodynamics. We will not prove anything here nor provide many if any examples, as this is all assumed to be review.\n\nVectors\nAs in mechanics, in electrodynamics we generally assume that physical objects live in a 3-dimensional real space, often denoted by the set \\(\\mathbb{R}^3\\). A vector or 3-vector we’ll define as a 3-component object \\(\\mathbf{v}\\) that lives in \\(\\mathbb{R}^3\\). The 3 components of the vector depend on the choice of coordinate system or basis chosen. In Cartesian coordinates we can expand a vector as a superposition of unit vectors aligned with the coordinate axes, \\[\n\\mathbf{v} = v_x \\mathbf{e}_x + v_y \\mathbf{e}_y + v_z \\mathbf{e}_z = v_1 \\mathbf{e}_1 + v_2 \\mathbf{e}_2 + v_3 \\mathbf{e}_3 \\ .\n\\]\n\n\n\n\n\nThe second representation of using numerical indices to represent the components in order will be useful for us, as we’ll often express superpositions like this using summation notation, or more conveniently using the Einstein summation convention, \\[\n\\mathbf{v} \\equiv v_i \\mathbf{e}_i \\equiv \\sum_{i=1}^3 v_i \\mathbf{e}_i \\ .\n\\] Recall the summation convention says that if a term has a repeated index a summation over all values of that index is implied. In this case, \\(v_i \\mathbf{e}_i\\) has the repeated index \\(i\\), which is assumed to sum from 1 to 3. Any index that does not repeat does not get summed over. We’ll sometimes express a vector only by its components \\(v_i\\), where the basis is left unspecified. This is called index notation. It’s fully equivalent to vector notation but sometimes more convenient when doing complex vector calculations. We’ll go back and forth between these two notations in this course.\nFor a vector to be a valid physical object, we require it transform in a specific way under coordinate transformations. If \\(S\\) is one coordinate system and \\(S'\\) is another, we require that \\(\\mathbf{v}(\\mathbf{x}') = \\mathbf{J} \\mathbf{v}(\\mathbf{x})\\), where \\(\\mathbf{v}(\\mathbf{x}')\\) is the representation of \\(\\mathbf{v}\\) in the \\(S'\\) coordinates and \\(\\mathbf{v}(\\mathbf{x})\\) its representation in the \\(S\\) coordinates. The object \\(\\mathbf{J} \\equiv \\frac{d\\mathbf{x}'}{d\\mathbf{x}}\\) is the Jacobian matrix, an invertible square matrix that describes how the coordinates transform from \\(S\\) and \\(S'\\). Any superposition of vectors is a valid vector as well.\nWe can think of a vector as a one index, or rank-1, object that transforms as specified above. A simpler object with no index, or rank-0, defines a scalar. A scalar is a single number that doesn’t change under coordinate transformations. An important example of a scalar is the dot product or inner product between two vectors, defined in Euclidean space by \\[\n\\mathbf{v} \\cdot \\mathbf{w} \\equiv v_i w_i = v_1 w_1 + v_2 w_2 + v_3 w_3 \\ .\n\\] Recall from elementary physics that we can also express the dot product in terms of the angle \\(\\theta\\) between the two vectors as \\[\n\\mathbf{v} \\cdot \\mathbf{w} = |\\mathbf{v}| |\\mathbf{w}| \\cos\\theta \\ .\n\\] Here \\(|\\mathbf{v}| \\equiv \\sqrt{\\mathbf{v} \\cdot \\mathbf{v}}\\) is the norm or magnitude of \\(\\mathbf{v}\\). This formula says that in some sense the dot product encodes information about both the magnitude of vectors as well as the angles between them. When \\(|\\mathbf{v}|=1\\) we say \\(\\mathbf{v}\\) is a unit vector, which in this course we’ll usually denote by \\(\\mathbf{e}_v\\). Evidently the dot product of two vectors is zero if they’re perpendicular, in which case we call the two vectors orthogonal. When the two vectors are parallel or antiparallel their dot product is \\(\\pm 1\\).\nAs long as coordinate transformations are rotations, the dot product will always be a scalar. As an exercise in using index notation let’s prove this. When working in index notation we need to convert every object we need to an indexed object. Since \\(\\mathbf{v}\\) and \\(\\mathbf{w}\\) are vectors, they both get one index. Since their components get summed over in the dot product, the indices on the two vectors should be the same. That is, \\(\\mathbf{v} \\cdot \\mathbf{w} \\leftrightarrow v_i w_i\\).\nWe’ll also need to index the Jacobian matrix \\(\\mathbf{J}\\). Since matrices carry two indices, we’ll need two indices to index the Jacobian. It’s not hard to see that the matrix multiplication \\(\\mathbf{v}'=\\mathbf{J}\\mathbf{v}\\) in index notation can be expressed as \\(v_i' = J_{ij} v_j\\). We’ll need to make use of two other facts. First, transposing a matrix in index notation just swaps the indices, so \\((J^\\top)_{ij} = J_{ji}\\). Second, the identity matrix \\(\\mathbf{I}\\) is expressed in index notation using the Kronecker delta \\(\\delta_{ij}\\), defined to be 1 when \\(i=j\\) and 0 otherwise.\nWe’re now ready to proceed with the proof. We need to show that under a coordinate transformation from \\(S'\\) to \\(S\\) the dot product stays invariant under rotations. Starting with the dot product in \\(S'\\) coordinates, we have \\[\nv_i' w_i' = v_i' w_j' = (J_{ij} v_j) (J_{ik} w_k) = J_{ij} J_{ik} v_i w_k  \\ .\n\\] Now, we need the right-hand side to equal \\(v_i w_i\\). The only way this can be true is if \\(J_{ij} J_{ik} = \\delta_{jk}\\). Then we get \\[\nv_i' w_i' = J_{ij} J_{ik} v_i w_k = \\delta_{jk} v_i w_k = v_j w_j  \\ .\n\\] Now, the index being summed over is a dummy index, meaning it doesn’t matter how we label it as long as we’re consistent. We can thus freely relabel \\(j\\) to \\(i\\) and write \\(v_i' w_i' = v_i w_i\\), which is what we wanted to show.\nFor this proof to work, however, we had to impose the fact that \\(J_{ij} J_{ik} = \\delta_{jk}\\). This is just saying that the Jacobian times its transpose should equal the identity, i.e. \\(\\mathbf{J}^\\top \\mathbf{J} = \\mathbf{I}\\). What kinds of transformations satisfy this property? Recall that this is just the definition of an orthogonal transformation. An orthogonal transformation is precisely a transformation that preserves the dot products between vectors. From the elementary definition of the dot product, this also means an orthogonal transformation preserves the angles between vectors. Note that such transformations need not preserve the handedness between the vectors. Since \\(\\det \\mathbf{J} = \\pm 1\\) for orthogonal transformations, there are two cases. It’s the \\(+1\\) case that preserves handedness, while the \\(-1\\) case flips the order between the vectors.\nIt’s fair to ask what happens when the coordinate transformation isn’t orthogonal. In that case, we define \\(\\mathbf{g} \\equiv \\mathbf{J}^\\top \\mathbf{J}\\), in which case we then define \\(\\mathbf{x} \\cdot \\mathbf{y} \\equiv x_i g_{ij} y_j\\). Here \\(\\mathbf{g}\\) is called the metric. It says something about the geometry of the two coordinate transformations. With this generalized form of the dot product it again becomes a proper scalar regardless of what \\(\\mathbf{J}\\) is. We’ll see this more general dot product again when we get to relativistic electrodynamics towards the end of the course. Indeed, the presence of \\(\\mathbf{g}\\) is one of the defining features of relativity, both special and general relativity.\nWe know that vectors in 3 dimensions also have another kind of product that creates vectors from vectors. This other product is called the cross product, which in index notation can be defined by \\[\n(\\mathbf{x} \\times \\mathbf{y}) \\equiv \\varepsilon_{ijk} x_i y_j \\mathbf{e}_k \\ .\n\\] Here \\(\\varepsilon_{ijk}\\) is the Levi-Civita symbol, defined to be \\(+1\\) for even permutations of \\(ijk\\), \\(-1\\) for odd permutations of \\(ijk\\), and \\(0\\) when any of the indices are repeated. Written out in components, it’s not hard to show that \\[\n\\mathbf{v} \\times \\mathbf{w} = (v_y w_z - v_z w_y) \\mathbf{e}_x + (v_z w_x - v_x w_z) \\mathbf{e}_y + (v_x w_y - v_y w_x) \\mathbf{e}_z \\ .\n\\] We know that the cross product between two vectors can also be expressed geometrically, where its magnitude is given by \\[\n|\\mathbf{v} \\times \\mathbf{w}| = |\\mathbf{v}| |\\mathbf{w}| \\sin\\theta \\ ,\n\\] while its direction is given by the right-hand rule. The cross product evidently defines a favored orientation in space. If a plane contains the two vectors \\(\\mathbf{v}\\) and \\(\\mathbf{w}\\), its positive orientation or normal is the direction of \\(\\mathbf{v} \\times \\mathbf{w}\\). Evidently, this version of the cross product says that the cross product of two parallel vectors is \\(\\mathbf{0}\\). Note the cross product is neither commutative nor associative.\nIt’s worth pointing out that despite the hand-waving, the cross product is not really a vector in the sense we’ve defined what a vector really is, an object that transforms a certain way under coordinate transformations. The cross product in general does not transform correctly under coordinate transformations. For example, under an inversion \\(\\mathbf{v} \\rightarrow -\\mathbf{v}, \\mathbf{w} \\rightarrow -\\mathbf{w}\\) their cross product remains \\(\\mathbf{v} \\times \\mathbf{w}\\). It doesn’t become \\(-\\mathbf{v} \\times \\mathbf{w}\\) like we’d require. For this reason the cross product is properly thought of as a pseudovector, in that in a lot of ways it behaves like a vector, but not in all ways. In fact, properly speaking the cross product should be thought of as an antisymmetric tensor. We’ll say more about this below.\nThe Levi-Civita symbol is a useful symbol in its own right, independent of the cross product. We’ll need to understand its algebra a bit better since we’ll use this symbol frequently in this course. One useful fact is that swapping two indices introduces a negative sign. For example, swapping \\(i \\leftrightarrow j\\) gives \\(\\varepsilon_{jik} = -\\varepsilon_{ijk}\\). We can use this fact to show that the cross product is perpendicular to the plane spanned by the two vectors. We can do this by showing \\(\\mathbf{v} \\cdot (\\mathbf{v} \\times \\mathbf{w}) = 0\\). That is, that \\(\\mathbf{v}\\) is orthogonal to \\(\\mathbf{v} \\times \\mathbf{w}\\), which by the geometric version of the dot product means the two are perpendicular. In index notation, we have \\[\n\\mathbf{v} \\cdot (\\mathbf{v} \\times \\mathbf{w}) = \\varepsilon_{ijk} v_j w_k (\\mathbf{v} \\cdot \\mathbf{e}_i) = v_i \\varepsilon_{ijk} v_j w_k = -v_i \\varepsilon_{jik} v_j w_k = -v_j \\varepsilon_{ijk} v_i w_k \\ .\n\\] Notice we have \\(\\varepsilon_{ijk} x_i x_j y_k = -\\varepsilon_{ijk} x_i x_j y_k\\), which can only be true of both are zero, as we wanted to show.\nAnother surprisingly useful identity of the Levi-Civita symbol is gotten by contracting their product to get \\[\n\\varepsilon_{ijk} \\varepsilon_{k\\ell m} = \\delta_{i\\ell} \\delta_{jm} - \\delta_{im} \\delta_{j\\ell} \\ .\n\\] As an application of this surprising identity, we’ll use it to prove the well-known BAC-CAB rule for triple products, \\[\n\\mathbf{a} \\times (\\mathbf{b} \\times \\mathbf{c}) = \\mathbf{b} (\\mathbf{a} \\cdot \\mathbf{c}) - \\mathbf{c} (\\mathbf{a} \\cdot \\mathbf{b}) \\ .\n\\] Let \\(\\mathbf{d} = \\mathbf{a} \\times (\\mathbf{b} \\times \\mathbf{c})\\) for convenience. Writing this out in index notation and applying the previous identity, we have \\[\n\\begin{align*}\nd_i &= [\\mathbf{a} \\times (\\mathbf{b} \\times \\mathbf{c})]_i \\\\\n&= \\varepsilon_{ijk} a_j (\\mathbf{b} \\times \\mathbf{c})_k \\\\\n&= \\varepsilon_{ijk} \\varepsilon_{k\\ell m} a_j b_\\ell c_m \\\\\n&= (\\delta_{i\\ell} \\delta_{jm} - \\delta_{im} \\delta_{j\\ell}) a_j b_\\ell c_m \\\\\n&= \\delta_{i\\ell} \\delta_{jm} a_j b_\\ell c_m - \\delta_{im} \\delta_{j\\ell} a_j b_\\ell c_m \\\\\n&= a_j b_i c_j - a_j b_j c_i \\\\\n&= (\\mathbf{a} \\cdot \\mathbf{c}) b_i - (\\mathbf{a} \\cdot \\mathbf{b}) c_i \\ .\n\\end{align*}\n\\] Written back out in vector notation this gives exactly what we wanted to show.\nThe last curious fact of the Levi-Civita symbol that we’ll mention but not really use is that we can use it to write out the determinant of a \\(3 \\times 3\\) matrix. If a matrix \\(\\mathbf{A}\\) has column vectors \\(\\mathbf{a}, \\mathbf{b}, \\mathbf{c}\\), then we have \\[\n\\det \\mathbf{A} = \\varepsilon_{ijk} a_i b_j c_k \\ .\n\\] While cute, this formula only works in 3 dimensions. In other dimensions we’d have to use generalizations of the Levi-Civita symbol to get a formula like this, and even then they’re not actually useful for calculating the determinant.\n\n\nTensors\nThus far we’ve seen objects with no indices and objects with one index that transform in a specified way under coordinate transformations. It’s fair to ask whether we can define matrices that transform in a specific way as well, and in fact we can. These two-index objects are called rank-2 tensors. They’re matrices \\(\\mathbf{T}\\) that obey the transformation law \\[\n\\mathbf{T}(\\mathbf{x}') = \\mathbf{J}^\\top \\mathbf{T}(\\mathbf{x}') \\mathbf{J} \\ .\n\\] This is just a direct generalization of the vector transformation law. It’s easier to see this in index notation. Vectors obey the transformation law \\(v_i' = J_{ij} v_j\\), while rank-2 tensors obey the transformation law \\[\nT_{ij}' =  J_{ik} J_{j\\ell} T_{k\\ell} \\ .\n\\] Roughly speaking, this just says each dimension of the tensor transforms itself as a vector would.\nWhile tensors didn’t show up transparently in elementary physics courses, they show up a lot in more advanced physics. A lot of physical quantities are tensors: the metric tensor, the moment of inertia tensor, the strain tensor, and so on. Another example is the cross product. The cross product seems like a vector, but it’s really not. In fact, we can define the cross product in a slightly different way using a rank-2 tensor as \\[\n\\varepsilon_{ijk} (\\mathbf{v} \\times \\mathbf{w})_k = v_i w_j - v_j w_i\n\\] In this variant definition the cross product is no longer a vector, but a rank-2 tensor whose upper diagonal components are the usual components of the cross product in 3 dimensions. Represented as a matrix \\(\\mathbf{A}\\), it looks like \\[\nA_{ij} \\equiv \\varepsilon_{ijk} (\\mathbf{v} \\times \\mathbf{w})_k \\doteq\n\\begin{pmatrix}\n0 & v_1 w_2 - v_2 w_1 & v_1 w_3 - v_3 w_1  \\\\\nv_2 w_1 - v_1 w_2 & 0 & v_2 w_3 - v_3 w_2 \\\\\nv_3 w_1 - v_1 w_3 &  & 0 \\\\\n\\end{pmatrix}\n\\ .\n\\] Here \\(\\mathbf{A}\\) is a rank-2 tensor that evidently satisfies the antisymmetric property \\(A_{ij} = -A_{ji}\\). Unlike with the regular cross product, this generalization of the cross product can be defined for any number of dimensions. To see why we can’t extend the usual cross product this way, notice that the components \\(\\mathbf{v} \\times \\mathbf{w}\\) lie in the upper diagonal of \\(\\mathbf{A}\\). The diagonals are always zero, and the lower diagonal is just minus the upper diagonal, meaning there are only 3 independent components. For a general antisymmetric tensor in \\(d\\) dimensions there will be \\(\\frac{1}{2}d(d-1)\\) such independent components in the upper diagonal. Insisteng that such a tensor be a vector is equivalent to requiring \\(d=\\frac{1}{2}d(d-1)\\), which evidently can only be true when \\(d=3\\). Thus, the cross product can only be a vector in 3 dimensions.\nOne useful operation that we can do with tensors is contraction. Contraction is the tensor generalization of the inner product, obtained by setting two indices in a tensor equal and summing over them. Since rank-2 tensors only have 2 indices, contracting a rank-2 tensor will always give a scalar, which is of course just trace of \\(\\mathbf{T}\\), i.e. \\(T_{ii} = \\text{tr} \\ \\mathbf{T}\\). Just as the dot product of a vector with itself says something about its size (in fact it’s just its squared norm), the trace of a rank-2 tensor says something about its size. Since the trace has no free indices, it must be a rank-0 object, hence a proper scalar like the dot product.\nAnother operation we can do with tensors is take their tensor product. A tensor product is no more than component-wise concatenation. For example, if \\(\\mathbf{x}\\) and \\(\\mathbf{y}\\) are two vectors, we can define their tensor product in index notation by \\[\nT_{ij} \\equiv x_i x_j \\ .\n\\] Evidently the tensor product of two vectors gives a rank-2 tensor. In fact, it’s just the outer product of the two vectors. In this sense the tensor product is a generalization of the outer product, just as contraction is the generalization of the inner product. In more abstract notation we’d write the tensor product as \\[\n\\mathbf{T} = \\mathbf{x} \\otimes \\mathbf{y} \\equiv \\mathbf{x} \\mathbf{y} \\ .\n\\] The last expression \\(\\mathbf{x} \\mathbf{y}\\) for the tensor product is called dyadic notation, where we omit the \\(\\otimes\\) symbol for brevity. It’s tempting to think that all rank-2 tensors can be formed from a tensor product of vectors, but this is false. Only special vectors can, called product tensors. Most rank-2 tensors are mixed tensors, meaning superpositions of vector outer products.\nUsing the tensor product we can define the notion of a basis tensor for a rank-2 tensor as \\[\n\\mathbf{e}_{ij} \\equiv \\mathbf{e}_i \\mathbf{e}_j \\equiv \\mathbf{e}_i \\otimes \\mathbf{e}_j \\ .\n\\] Since this is just the outer products of the two basis vectors, they are 1 when at slot \\((i,j)\\) and 0 otherwise. Using superposition just as we do for vectors, we can use these basis tensors to expand any rank-2 tensor as \\[\n\\mathbf{T} = T_{ij} \\mathbf{e}_i \\mathbf{e}_j \\ .\n\\] We can also take the tensor product of a rank-2 tensor with a vector, which would give a three-index object, or a rank-3 tensor. Taking the tensor product of two rank-2 tensors would give a rank-4 tensor. And so on. In fact we can define a tensor of any rank. A rank-k tensor is an object with \\(k\\) indices that tranforms component-wise according to the law \\[\nT_{i_1' i_2' \\cdots i_k'} = R_{i_1' i_1} R_{i_2' i_2} \\cdots R_{i_2' i_2} T_{i_1 i_2 \\cdots i_k} \\ .\n\\] In this course we won’t generally work much with tensors of higher rank than 2, but they do show up, for example in the multipole expansions of the scalar and vector potentials. Tensor contraction can be defined naturally on these higher-rank tensors as well. Contracting two indices in a tensor will always reduce its rank by 2.\n\n\nVector Calculus\nCalculus extends naturally to higher dimensions, but often in subtle ways. Most importantly, there are different types of derivatives and integrals defined in higher dimensions with different meaning and applications. Due to complications involved in using curvilinear coordinates in vector calculus we’ll state results in Cartesian coordinates and address the curvilinear situation later.\nThe fundamental object of vector calculus is the differential of a field. This says how much the field changes if its inputs are nudged in some direction by an infinitesimal amount. In Cartesian coordinates, it turns out the differential of a scalar field \\(f(\\mathbf{x})\\) is nothing more than a sum of partial differentials along each coordinate. That is, \\[\ndf = \\frac{\\partial f}{\\partial x} dx + \\frac{\\partial f}{\\partial y} dy + \\frac{\\partial f}{\\partial z} dz \\ .\n\\] The right-hand side looks like a sort of dot product between the partial derivatives of \\(f\\) and a differential displacement vector \\(d\\mathbf{x}\\), or vector line element, defined in Cartesian coordinates by \\[\nd\\mathbf{x} \\equiv dx \\mathbf{e}_x + dy \\mathbf{e}_y + dz \\mathbf{e}_z \\ .\n\\] It’s the vector generalization of the differential \\(dx\\) from ordinary calculus. The vector of partial derivatives can be written in a useful way by defining the del operator \\(\\nabla\\) by \\[\n\\nabla \\equiv \\partial_i \\mathbf{e}_i \\equiv \\frac{\\partial}{\\partial x} \\mathbf{e}_x + \\frac{\\partial}{\\partial y} \\mathbf{e}_y + \\frac{\\partial}{\\partial z} \\mathbf{e}_z \\ .\n\\] Here we introduce the convenient shorthand \\(\\partial_i \\equiv \\frac{\\partial}{\\partial x_i}\\) for the partial derivative with respect to component \\(x_i\\). Using the del operator we can define the vector of partial derivatives of a scalar field \\(f\\) by \\[\n\\nabla f \\equiv \\partial_i f \\ \\mathbf{e}_i \\equiv \\frac{\\partial f}{\\partial x} \\mathbf{e}_x + \\frac{\\partial f}{\\partial y} \\mathbf{e}_y + \\frac{\\partial f}{\\partial z} \\mathbf{e}_z \\ .\n\\] This quantity is evidently some kind of vector derivative, called the gradient of the field \\(f\\). Since \\(f\\) is a scalar field, \\(\\nabla f\\) will be a vector field. Its components are the partial derivatives of \\(f\\) in the \\(x_i\\) direction at each \\(\\mathbf{x}\\). The gradient always points perpendicular to the level curves where \\(f=\\text{const}\\). To see why we can use the geometric formula for the dot product to express any change in the function along a level curve as \\[\n\\delta f = \\nabla f \\cdot \\delta \\mathbf{x} = |\\nabla f| |\\delta \\mathbf{x}| \\cos\\theta \\ .\n\\] Since \\(\\delta f = 0\\) along the level curve by definition, it must be the case that \\(\\theta = \\pm 90^\\circ\\) along such curves, meaning that the gradient must always be orthogonal to the level curve.\nUsing the gradient, we can finally express the differential \\(df\\) as a dot product of the gradient with the vector line element, \\[\ndf = \\nabla f \\cdot d\\mathbf{x} \\ .\n\\] Unlike in ordinary calculus, however, in vector calculus this isn’t the only kind of derivative we can take. We can see this by looking at the definition of \\(\\nabla\\). We can think of \\(\\nabla f\\) as multiplying a vector by a scalar. But we also know that we can take both the dot product and the cross product of two vectors, which along with \\(\\nabla\\) suggests there are two more derivative operations we can perform on vector fields.\nIf \\(\\mathbf{F}(\\mathbf{x})\\) is a vector field, we can take its dot product of \\(\\nabla\\) with \\(\\mathbf{F}\\) to get a new scalar field known as the divergence, which is evidently defined in Cartesian coordinates by \\[\n\\nabla \\cdot \\mathbf{F} \\equiv \\partial_i F_i \\equiv \\frac{\\partial f}{\\partial x} + \\frac{\\partial f}{\\partial y} + \\frac{\\partial f}{\\partial z} \\ .\n\\] Though not obvious from the definition, the divergence represents the tendency of a vector to flow into or out of a point. A field where \\(\\nabla \\cdot \\mathbf{F} = 0\\) for all points in space has no divergence at all, meaning there are no sources or sinks in the field anywhere. Due to the fact that the magnetic field is the canonical example of a divergence-less vector field, such fields are often called solenoidal.\nWe can also take the cross product of \\(\\nabla\\) with \\(\\mathbf{F}(\\mathbf{x})\\) to get a vector field known as the curl, defined in Cartesian coordinates by \\[\n\\nabla \\times \\mathbf{F} \\equiv \\varepsilon_{ijk} \\partial_i F_j \\mathbf{e}_k \\ .\n\\]\nThough again not obvious from the definition, the curl represents the tendency of a vector to rotate around a point in space. A field where \\(\\nabla \\times \\mathbf{F} = \\mathbf{0}\\) at all points in space is called irrotational since it doesn’t experience any rotational motion at any point. It just flows inward or outward.\nWe can also take vector second derivatives as well. The most useful of these is obtained by taking the divergence of the gradient of a scalar field. This is called the Laplacian, defined in Cartesian coordinates by \\[\n\\nabla^2 f \\equiv \\nabla \\cdot \\nabla f = \\partial_i \\partial_i f = \\frac{\\partial^2 f}{\\partial x^2} + \\frac{\\partial^2 f}{\\partial y^2} + \\frac{\\partial^2 f}{\\partial z^2} \\ .\n\\] There are a few other vector second derivatives as well, some of which turn out to be zero. These are \\[\n\\begin{align*}\n\\nabla \\cdot (\\nabla \\times \\mathbf{F}) &= 0 \\ , \\\\\n\\nabla \\times \\nabla f &= \\mathbf{0} \\ , \\\\\n\\nabla \\times (\\nabla \\times \\mathbf{F}) &= \\nabla (\\nabla \\cdot \\mathbf{F}) - \\nabla^2 \\mathbf{F} \\ .\n\\end{align*}\n\\] The Laplacian in the last expression is understood to be taken component-wise, as a vector with components \\(\\nabla^2 F_i\\). Each of these identities can all be efficiently proven using index notation.\nThe gradient, divergence, and curl each has its own corresponding version of the fundamental theorem of calculus. To understand integration in higher dimensions though we first need to define what the differentials are. To integrate over a spatial volume we use the volume element \\(d^3 \\mathbf{x}\\), defined in Cartesian components by \\[\nd^3 \\mathbf{x} \\equiv dx dy dz \\ .\n\\] An important fact about the volume element is that its expression in a given coordinate system depends on the Jacobian. If \\(\\mathbf{u}(\\mathbf{x})\\) is some coordinate transformation with Jacobian \\(\\mathbf{J} \\equiv \\frac{d\\mathbf{u}}{d\\mathbf{x}}\\), then their volume elements are related by \\[\nd^3 \\mathbf{x} = du_1 du_2 du_3 = |\\det \\mathbf{J}| dx_1 dx_2 dx_3 \\ .\n\\] To find the volume integral of a scalar field \\(f\\) over a region of space \\(\\mathcal{V}\\), we can integrate each coordinate iteratively, \\[\n\\int_\\mathcal{V} d^3 \\mathbf{x} \\ f(\\mathbf{x}) = \\iiint_\\mathcal{V} dx dy dz \\ f(x,y,z) \\ .\n\\] We can integrate a vector field over a volume too. In this case the integral is done component-wise, so little new is added.\nSometimes we’ll also need to integrate a field over a surface in space as well. Suppose we wish to integrate over some smooth, orientable surface \\(\\mathcal{S}\\) in space. We can define an area element \\(d\\mathbf{a}\\) on this surface by considering an infinitesimal patch of area \\(da\\) on the surface and attaching an outward unit normal \\(\\mathbf{n}\\) to it to get \\[\nd\\mathbf{a} \\equiv \\mathbf{n} \\ da \\ .\n\\] It’s fair to ask how \\(da\\) itself is determined. When the surface is the \\(xy\\)-plane it’s clear \\(da = dxdy\\). But for more general surfaces we’d need to parametrize \\(\\mathcal{S}\\) with two relative coordinates and express \\(da\\) in terms of those. Evidently the area element \\(d\\mathbf{a}\\) is a kind of vector. We can thus also think of it as the cross product of two infinitesimal vectors on the surface. Importantly, this means \\(d\\mathbf{a}\\) will have both a magnitude and a direction that depend on where we are along the surface. When we require the surface be orientable, we mean that we can always use the right-hand rule to find the direction of \\(\\mathbf{n}\\).\n\n\n\n\n\nTo get the surface integral of a vector field \\(\\mathbf{F}\\) along the surface \\(\\mathcal{S}\\) we’d typically write \\[\n\\int_\\mathcal{S} \\mathbf{F} \\cdot d\\mathbf{a} = \\int_\\mathcal{S} \\mathbf{F} \\cdot \\mathbf{n} \\ da \\ .\n\\] The last form of vector integration we’ll find ourselves using frequently is path integration, which is the integration of a field along some arbitrary curve in space. This form of integration is done by considering the contribution of the field along each vector line element \\(d\\boldsymbol{\\ell}\\) along some path \\(\\mathcal{C}\\). For a vector field \\(\\mathbf{F}\\) each infinitesimal contribution is found by taking the dot product \\(\\mathbf{F} \\cdot d\\boldsymbol{\\ell}\\), which we can add up, or integrate, along the entire path to get a scalar-valued path integral, \\[\n\\int_\\mathcal{C} \\mathbf{F} \\cdot d\\boldsymbol{\\ell} \\ .\n\\] To actually evaluate a path integral one needs to parametrize the line element somehow. For example, if we use Cartesian coordinates to parametrize the line element, we can find the path integral by \\[\n\\int_\\mathcal{C} \\mathbf{F} \\cdot d\\boldsymbol{\\ell} = \\int_{\\mathcal{C}_x} dx \\ F_x + \\int_{\\mathcal{C}_y} dy \\ F_y + \\int_{\\mathcal{C}_z} dz \\ F_z \\ ,\n\\] where \\(\\mathcal{C}_i\\) is the projection of the path onto the \\(x_i\\) axis.\nIf we’re not interested in the direction of the contour but only its length, we can integrate over its norm instead. This norm is called the scalar line element and defined by \\(ds \\equiv |d\\boldsymbol{\\ell}|\\). Integrating over \\(ds\\) alone gives the arc length of the contour in space. Interestingly the scalar line element is very important in studying the geometry of a space. In general it depends on the metric \\(\\mathbf{g}\\) by \\[\nds^2 = dx_i g_{ij} dx_j \\ .\n\\] For Euclidean space the metric is always the identity, so we just have \\(ds^2 = dx_i dx_i\\). This is all we’ll need for most of this course, but in relativity (especially general relativity) this line element becomes fundamental.\nUsually a path integral between two endpoints will depend on the exact path of the contour \\(\\mathcal{C}\\). For some special fields though the path integral depends only on the endpoints, not on the path between them. When this is true we say the field is conservative. An implication of this is that if we integrate a conservative field around any closed contour the path integral vanishes, \\[\n\\oint \\mathbf{F} \\cdot d\\mathbf{x} = 0 \\ .\n\\] It’s easy to see why this must be true. For any closed contour we can break it into two pieces. The line integral of each piece must be path independent, which means their sum, and hence the closed path integral, must vanish for conservative fields.\nIn vector calculus, each version of vector derivative has its own fundamental theorem of calculus that relates it to one or more of the integrals defined above. The fundamental theorem for gradients says the line integral of the gradient of a scalar field depends only on the endpoints, \\[\n\\int_{\\mathbf{x}_1}^{\\mathbf{x}_2} \\nabla f(\\mathbf{x}) \\cdot d\\mathbf{x} = f(\\mathbf{x}_2) - f(\\mathbf{x}_1) \\ .\n\\] Said differently, the gradient of a scalar field is always conservative. Conversely, any conservative vector field \\(\\mathbf{F}(\\mathbf{x})\\) can be written as the gradient of some scalar field \\(\\phi(\\mathbf{x})\\), \\[\n\\mathbf{F} = -\\nabla \\phi \\ .\n\\] This fact we use extensively in electromagnetism. The minus sign is merely a physics convention. Since the curl of a gradient must vanish, this statement also says \\(\\mathbf{F}\\) must be irrotational, i.e. \\(\\nabla \\times \\mathbf{F} = \\mathbf{0}\\).\nA more general extension of this special case is called the Helmholtz theorem. It says any smooth vector field \\(\\mathbf{F}(\\mathbf{x})\\), conservative or not, can be expressed as the gradient of some scalar field \\(\\phi(\\mathbf{x})\\) plus the curl of some other vector field \\(\\mathbf{A}(\\mathbf{x})\\), i.e. \\[\n\\mathbf{F} = -\\nabla \\phi + \\nabla \\times \\mathbf{A} \\ .\n\\] Though not obvious at this stage, this formula in fact can be inverted to find formulas for \\(\\phi\\) and \\(\\mathbf{A}\\) in terms of derivatives of \\(\\mathbf{F}\\), \\[\n\\begin{align*}\n\\phi(\\mathbf{x}) &= \\frac{1}{4\\pi} \\int_{\\mathbb{R}^3} d^3 \\mathbf{x}' \\ \\frac{\\nabla' \\cdot \\mathbf{F}(\\mathbf{x}')}{|\\mathbf{x} - \\mathbf{x}'|} \\ , \\\\\n\\mathbf{A}(\\mathbf{x}) &= \\frac{1}{4\\pi} \\int_{\\mathbb{R}^3} d^3 \\mathbf{x}' \\ \\frac{\\nabla' \\times \\mathbf{F}(\\mathbf{x}')}{|\\mathbf{x} - \\mathbf{x}'|} \\ .\n\\end{align*}\n\\] Here it’s implicitly assumed that \\(\\mathbf{F}\\) vanishes faster than \\(\\frac{1}{r}\\) at infinity. If not we have to include extra boundary terms. The symbol \\(\\nabla'\\) means to differentiate with respect to the integration variable \\(\\mathbf{x}'\\).\nThe fundamental theorem for divergences is called the divergence theorem. It says that the divergence of a vector field is nothing more than the flow or flux of the field through the surface of a closed volume, \\[\n\\int_\\mathcal{V} \\nabla \\cdot \\mathbf{F} \\ d^3\\mathbf{x} = \\int_S \\mathbf{F} \\cdot d\\mathbf{a} \\ .\n\\] The fundamental theorem for curls is called Stokes’ theorem. It says the curl of a vector field is nothing more than the circulation of the field around the boundary of any closed surface, \\[\n\\int_\\mathcal{S} (\\nabla \\times \\mathbf{F}) \\cdot \\ d\\mathbf{a} = \\int_C \\mathbf{F} \\cdot d\\mathbf{x} \\ .\n\\] Though perhaps not obvious at this stage, the divergence and Stokes’ theorems are precisely what we use to go back and forth between the integral and differential forms of Maxwell’s equations.\nIt’s interesting to note that all of these versions of the fundamental theorem of calculus say essentially the same thing: The integral of the derivative of a field over some space equals the value of that field along the boundary of that space. For gradients, the boundary of a contour is just two endpoints. For divergences, the boundary over a volume is a closed surface. For curls, the boundary of a surface is a closed contour.\nMany of the usual derivative and integral rules extend to vector calculus as well using index notation. For example, the product rule for the product of a vector field \\(\\mathbf{F}\\) with a scalar field \\(g\\) is \\[\nd(\\mathbf{F} g) = \\mathbf{F} \\ dg + g \\ d\\mathbf{F} \\ .\n\\] Dividing both sides by \\(d\\mathbf{x}\\) and integrating gives us one generalized version of integration by parts. Indeed, integrating both sides over a volume \\(\\mathcal{V}\\), we get \\[\n\\int_\\mathcal{V} \\nabla(\\mathbf{F} g) \\cdot d^3\\mathbf{x} = \\int_\\mathcal{V} \\mathbf{F} \\cdot \\nabla g \\ d^3 \\mathbf{x} + \\int_\\mathcal{V} g \\ \\nabla \\mathbf{F} \\ d^3 \\mathbf{x} \\ .\n\\] Rearranging terms and using the divergence theorem to express the left-hand integral as an integral over the bounding surface \\(\\mathcal{S}\\), we get \\[\n\\int_\\mathcal{V} \\mathbf{F} \\cdot \\nabla g \\ d^3 \\mathbf{x} = \\oint_\\mathcal{S} \\nabla(\\mathbf{F} g) \\cdot d\\mathbf{a} - \\int_\\mathcal{V} g \\ \\nabla \\mathbf{F} \\ d^3 \\mathbf{x} \\ .\n\\] Similar versions of integration by parts exist for the product of two scalar fields or two vector fields as well, both of which can be derived just as easily as the formula above.\nWe can define similar vector calculus operations for tensors as well, not just vectors. For example, if we have a rank-2 tensor \\(\\mathbf{T}\\) we can still imagine taking gradients \\(\\partial_k T_{ij}\\) to get a rank-3 tensor. By contracting the derivative with the tensor we get a different divergence for each index, \\(\\partial_i T_{ij}\\) and \\(\\partial_j T_{ij}\\). Evidently the divergence of a rank-2 tensor gives a vector, not a scalar.\nStrictly speaking we can’t speak of the divergence of a tensor since each index has its own divergence. We can though when the tensor is symmetric. If \\(T_{ij} = T_{ji}\\) we can define a unique divergence operation by \\[\n\\nabla \\cdot \\mathbf{T} \\equiv \\partial_i T_{ij} = \\partial_j T_{ij} \\ .\n\\]\nWe could imagine taking the curl of a tensor as well. From index notation it’s clear that the curl of a rank-2 tensor will give another rank-2 tensor. We can even imagine defining tensor integrals as well in similar ways. In practice though we’ll only care about divergences and gradients of rank-2 tensors in this course, so we won’t go into any detail here.\n\n\nCoordinate Systems\nIt will be frequently useful in electrodynamics to work in other coordinate systems. As with other areas of physics, the most important coordinate systems we work with are Cartesian, polar, cylindrical, and spherical coordinates. Cartesian coordinates are rectangular, which means their basis vectors don’t depend on position. They’re always constant. The remaining three coordinate systems, however, are curvilinear, meaning their basis vectors do depend on position. This means going back and forth between these coordinate systems can be cumbersome since additional scale factors get introduced. Below is a table that shows the relationship between these coordinate systems for various vector calculus expressions we’ll frequently use.\n\n\n\n\n\n\n\n\n\n\nCartesian \\((x,y,z)\\)\nCylindrical \\((\\rho,\\varphi,z)\\)\nSpherical \\((r,\\theta,\\varphi)\\)\n\n\n\n\nCoordinates\n\\(\\begin{align*} x&=x \\\\ y&=y \\\\ z&=z \\end{align*}\\)\n\\(\\begin{align*} x&=\\rho\\cos\\varphi \\\\ y&=\\rho\\sin\\varphi \\\\ z&=z \\end{align*}\\)\n\\(\\begin{align*} x&=r\\sin\\theta\\cos\\varphi \\\\ y&=r\\sin\\theta\\sin\\varphi \\\\ z&=r\\cos\\theta \\end{align*}\\)\n\n\nBasis Vectors\n\\(\\begin{align*} \\mathbf{e}_x&=\\mathbf{e}_x \\\\ \\mathbf{e}_y&=\\mathbf{e}_y \\\\ \\mathbf{e}_z&=\\mathbf{e}_z \\end{align*}\\)\n\\(\\begin{align*} \\mathbf{e}_\\rho &= \\cos\\varphi \\mathbf{e}_x + \\sin\\varphi \\mathbf{e}_y \\\\ \\mathbf{e}_\\varphi &= -\\sin \\varphi \\mathbf{e}_x + \\cos \\varphi \\mathbf{e}_y \\\\ \\mathbf{e}_z&=\\mathbf{e}_z \\end{align*}\\)\n\\(\\begin{align*} \\mathbf{e}_r &= \\sin\\theta \\cos\\varphi \\mathbf{e}_x + \\sin\\theta \\sin\\varphi \\mathbf{e}_y + \\cos\\theta \\mathbf{e}_z \\\\ \\mathbf{e}_\\theta &= \\cos\\theta \\cos\\varphi \\mathbf{e}_x + \\cos\\theta \\sin\\varphi \\mathbf{e}_y - \\sin\\theta \\mathbf{e}_z  \\\\ \\mathbf{e}_\\varphi &= -\\sin\\varphi \\mathbf{e}_x + \\cos\\varphi \\mathbf{e}_y  \\end{align*}\\)\n\n\nDifferential\n\\(d\\mathbf{x} = dx \\mathbf{e}_x + dy \\mathbf{e}_y + dz \\mathbf{e}_z\\)\n\\(d\\mathbf{x} = d\\rho \\mathbf{e}_\\rho + \\rho d\\varphi \\mathbf{e}_\\varphi + dz \\mathbf{e}_z\\)\n\\(d\\mathbf{x} = dr \\mathbf{e}_r + r d\\theta \\mathbf{e}_\\theta + r \\sin \\theta d\\varphi \\mathbf{e}_\\varphi\\)\n\n\nLine Element\n\\(ds^2=dx^2 + dy^2 + dz^2\\)\n\\(ds^2=d\\rho^2 + \\rho^2 d\\varphi^2 + dz^2\\)\n\\(ds^2=dr^2 + r^2 d\\theta^2 + r^2 \\sin^2 \\theta d\\varphi^2\\)\n\n\nVolume Element\n\\(d^3 \\mathbf{x} = dx dy dz\\)\n\\(d^3 \\mathbf{x} = \\rho d\\rho d\\varphi dz\\)\n\\(d^3 \\mathbf{x} = r^2 \\sin \\theta dr d\\theta d\\varphi\\)\n\n\nGradient\n\\(\\nabla f = \\partial_x f \\mathbf{e}_x + \\partial_y f \\mathbf{e}_y + \\partial_z f \\mathbf{e}_z\\)\n\\(\\nabla f = \\partial_\\rho f \\mathbf{e}_\\rho + \\frac{1}{\\rho} \\partial_\\varphi \\mathbf{e}_\\varphi + \\partial_z f \\mathbf{e}_z\\)\n\\(\\nabla f = \\partial_r f \\mathbf{e}_r + \\frac{1}{r} \\partial_\\theta f \\mathbf{e}_\\theta + \\frac{1}{r \\sin \\theta} \\partial_\\varphi f \\mathbf{e}_\\varphi\\)\n\n\nDivergence\n\\(\\nabla \\cdot \\mathbf{F} = \\partial_x F_x + \\partial_y F_y + \\partial_z F_z\\)\n\\(\\nabla \\cdot \\mathbf{F} = \\frac{1}{\\rho} \\partial_\\rho(\\rho F_\\rho) + \\frac{1}{\\rho} \\partial_\\varphi F_\\varphi + \\partial_z F_z\\)\n\\(\\nabla \\cdot \\mathbf{F} = \\frac{1}{r^2} \\partial_r (r^2 F_r) + \\frac{1}{r \\sin \\theta} \\partial_\\theta (F_\\theta \\sin \\theta) + \\frac{1}{r \\sin \\theta} \\partial_\\varphi F_\\varphi\\)\n\n\nCurl\n\\(\\begin{align*}\\nabla \\times \\mathbf{F} &= \\left( \\partial_y F_z - \\partial_z F_y \\right) \\mathbf{e}_x \\\\ &+ \\left( \\partial_z F_x - \\partial_x F_z \\right) \\mathbf{e}_y \\\\ &+ \\left( \\partial_x F_y - \\partial_y F_x \\right) \\mathbf{e}_z \\end{align*}\\)\n\\(\\begin{align*} \\nabla \\times \\mathbf{F} &= \\left( \\frac{1}{\\rho} \\partial_\\varphi F_z - \\partial_z F_\\varphi \\right) \\mathbf{e}_\\rho \\\\ &+ \\left( \\partial_z F_\\rho - \\partial_\\rho F_z \\right) \\mathbf{e}_\\varphi \\\\ &+ \\frac{1}{\\rho} \\left( \\partial_\\rho (\\rho F_\\varphi) - \\partial_\\varphi F_\\rho \\right) \\mathbf{e}_z \\end{align*}\\)\n\\(\\begin{align*} \\nabla \\times \\mathbf{F} &= \\frac{1}{r \\sin \\theta} \\left( \\partial_\\theta (F_\\varphi \\sin \\theta) - \\partial_\\varphi F_\\theta \\right) \\mathbf{e}_r \\\\ &+ \\frac{1}{r} \\left( \\frac{1}{\\sin \\theta} \\partial_\\varphi F_r - \\partial_r (r F_\\varphi) \\right) \\mathbf{e}_\\theta \\\\ &+ \\frac{1}{r} \\left( \\partial_r (r F_\\theta) - \\partial_\\theta F_r \\right) \\mathbf{e}_\\varphi \\end{align*}\\)\n\n\nLaplacian\n\\(\\nabla^2 f = \\partial_x^2 f + \\partial_y^2 f + \\partial_z^2 f\\)\n\\(\\nabla^2 f = \\frac{1}{\\rho} \\partial_\\rho \\left( \\rho \\partial_\\rho f \\right) + \\frac{1}{\\rho^2} \\partial_\\varphi^2 f + \\partial_z^2 f\\)\n\\(\\nabla^2 f = \\frac{1}{r^2} \\partial_r^2 \\left( r^2 \\partial_r f \\right) + \\frac{1}{r^2 \\sin \\theta} \\partial_\\theta \\left( \\sin \\theta \\partial_\\theta f \\right) + \\frac{1}{r^2 \\sin^2 \\theta} \\partial_\\varphi^2 f\\)\n\n\n\n\n\nFourier Analysis\nWe will at times find it convenient in this course to go back and forth between the time domain and the frequency domain. To express a continuous function of time as a function of frequency we can use the Fourier transform. For a sufficiently well-behaved time-dependent function \\(f(t)\\), we can define its Fourier transform \\(f(\\omega)\\) by \\[\nf(\\omega) \\equiv \\mathcal{F}[f(t)](\\omega) \\equiv \\int_{-\\infty}^\\infty dt \\ f(t) e^{-i\\omega t} \\ .\n\\] The function \\(f(\\omega)\\), which in general will be complex-valued, is thought of as a function of frequency \\(\\omega\\). We can express the same thing using the Fourier operator \\(\\mathcal{F}\\). Since the \\(\\mathcal{F}\\) is an integral transform it inherits many of the properties of the integral plus a few other convenient properties that are easy to prove from the definition. Here the \\(\\leftrightarrow\\) symbol means that right-hand side is the Fourier transform, or Fourier dual, of the left-hand side. That is, \\(f(t) \\leftrightarrow f(\\omega)\\), a very convenient simplification of notation.\n\nLinearity: \\(\\alpha f(t) + \\beta g(t) \\leftrightarrow \\alpha f(\\omega) + \\beta g(\\omega)\\).\nTime Scaling: \\(f(\\alpha t) \\leftrightarrow \\frac{1}{|\\alpha|} f\\big(\\frac{\\omega}{\\alpha}\\big)\\).\nTime Shifting: \\(f(t-t_0) \\leftrightarrow e^{i\\omega t_0} f\\big(\\omega)\\).\nTime Reversal: \\(f(-t) \\leftrightarrow f(-\\omega)\\).\nComplex Conjugation: \\(f^*(t) \\leftrightarrow f^*(\\omega)\\).\nDifferentiation: \\(\\frac{d}{dt} f(t) \\leftrightarrow i\\omega f(\\omega)\\).\nConvolution: \\(f \\ast g \\leftrightarrow f(\\omega) g(\\omega)\\).\n\nThe last operation is a very common integral transform known as convolution, defined by \\[\n(f \\ast g)(t) \\equiv \\int_{-\\infty}^\\infty dt' \\ f(t') g(t-t') \\ .\n\\] The convolution operation shows up surprisingly often, particularly in the theory of Green’s functions, which we’ll work with later in this course. Convolutions act like a form of function multiplication in that the operation is both commutative and associative.\n\nExample: Fourier Transform of a Gaussian\nAs an example of using these Fourier transform properties let’s calculate the Fourier transform of the Gaussian probability density \\[\nf(t) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\bigg(-\\frac{1}{2} \\frac{(t-t_0)^2}{\\sigma^2}\\bigg)\n\\] First, using the linear, time scaling, and shifting properties together we must have \\[\nf(\\omega) = \\frac{e^{i\\omega t_0}}{\\sqrt{2\\pi\\sigma^2}} \\mathcal{F}\\bigg[\\exp\\bigg(-\\frac{1}{2} \\frac{t^2}{\\sigma^2}\\bigg)\\bigg] = \\frac{1}{\\pi} e^{i\\omega t_0} \\mathcal{F}\\big[e^{-t^2}\\big](\\sqrt{2}\\sigma\\omega) \\ .\n\\] All that remains then is to find the transform of \\(g(t) \\equiv e^{-t^2}\\). We can do this by completing the square and using the translational invariance of the Gaussian integral to get $$ \\[\\begin{align*}\ng(\\omega) &= \\int_{-\\infty}^\\infty dt \\ g(\\omega) e^{-i\\omega t} \\\\\n&= \\int_{-\\infty}^\\infty dt \\ e^{-t^2} e^{-i\\omega t} \\\\\n&= \\int_{-\\infty}^\\infty dt \\ \\exp(-\\bigg(t-\\frac{i\\omega}{2}\\bigg)^2) \\\\\n&= \\sqrt{\\pi} \\exp(-\\frac{\\omega^2}{4}) \\ .\n\n\\end{align*}\\] \\[\nThus, putting it all together, we have\n\\] () = (it_0 - )  . $$ Evidently then, the Fourier transform of a Gaussian is another Gaussian. In a sense, the Gaussian is the unique class of functions whose Fourier transforms are also of the same class.\n\nAn important fact about the Fourier transform is that it’s invertible, meaning we can define an inverse Fourier transform operator \\(\\mathcal{F}^{-1}\\) such that \\(\\mathcal{F} \\mathcal{F}^{-1} = 1\\). The inverse Fourier transform of \\(f(t)\\) turns out to be given by the dual integral \\[\nf(t) = \\mathcal{F}^{-1}[f(\\omega)](t) = \\int_{-\\infty}^\\infty \\frac{d\\omega}{2\\pi} \\ f(\\omega) e^{i\\omega t} \\ .\n\\] Notice that unlike the Fourier transform, its inverse transform comes has a rescaled measure of \\(\\frac{d\\omega}{2\\pi}\\). There’s nothing deep about this fact. It’s just a relic of the way we defined the Fourier transform above. We could define it in ways that remove the \\(2\\pi\\) as well. In fact, there are many different conventions used to define the Fourier transform, which can make it a bit annoying to look up these formulas in tables.\nEvidently, to for the Fourier transform to be invertible we must have that \\(f(t) = \\mathcal{F}^{-1} \\mathcal{F} [f(t')](t)\\). Let’s see what this says by manipulating the formula a little bit. We have \\[\n\\begin{align*}\nf(t) &= \\mathcal{F}^{-1} \\mathcal{F} [f(t')](t) \\\\\n&= \\int_{-\\infty}^\\infty \\frac{d\\omega}{2\\pi} \\ \\int_{-\\infty}^\\infty dt' \\ f(t') e^{-i\\omega t'} e^{i\\omega t} \\\\\n&= \\int_{-\\infty}^\\infty dt' \\ f(t') \\int_{-\\infty}^\\infty \\frac{d\\omega}{2\\pi} \\ e^{i\\omega(t-t')} \\ .\n\\end{align*}\n\\] Evidently, the inner integral acts as some kind of kernel function that picks out the value \\(f(t)\\) from the integrand function \\(f(t')\\). Let’s give this kernel function a name, the Dirac delta function, \\[\n\\delta(t-t') \\equiv \\int_{-\\infty}^\\infty \\frac{d\\omega}{2\\pi} \\ e^{i\\omega(t-t')} \\ .\n\\] This function evidently then has the defining property that \\[\n\\boxed{\nf(t) = \\int_{-\\infty}^\\infty dt' \\ f(t') \\delta(t-t')\n}\\ .\n\\] In a sense, the delta function can be thought of as a sort of density function for a single point. When \\(t \\neq t'\\) the delta function must be zero. But to be a proper density this means that when \\(t=t'\\)​ the delta function must be infinitely high so its area under the curve remains constant.\nNotice that based on this definition the delta function must have units to cancel out the units of the differential \\(dt'\\). If \\(dt'\\) has units of time, evidently \\(\\delta(t-t')\\) must have units of frequency.\nIn one sense, the delta function is just the Fourier transform of the constant \\(f(t)=1\\). In a more visual sense it’s an infinite spike. Indeed, we can imagine defining the delta function differently as a limiting case of a normalized Gaussian whose variance \\(\\sigma^2\\) goes to zero, \\[\n\\delta(t-t') = \\lim_{\\sigma \\rightarrow 0} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(t-t')^2}{2\\sigma^2}} \\ .\n\\] This can be illustrated in the figure below.\n\n\n\n\n\nStrictly speaking the delta function isn’t a proper function at all since it’s undefined when \\(t=t'\\)​. It’s a so-called generalized function, meaning it’s a function that has meaning only when inside an integral. As physicists rarely do, we won’t really bother with these mathematical details in this course. Whatever it is, the delta function is a convenient mathematical object for us.\nOne fact worth remembering and easy to prove is how the delta function transforms under a time rescaling, \\[\n\\delta(at) = \\frac{1}{|a|} \\delta(t) \\ .\n\\] Another useful fact to remember is that the delta function is the identity of the convolution operation. That is, \\(f \\ast \\delta = f\\). This can easily be seen from the definition, which is just a special convolution operation.\nThus far we’ve talked about the Fourier transform in time. We can define a Fourier transform for a scalar field \\(f(\\mathbf{x})\\) as well by multiplying the transform of each component together. For a well-behaved scalar field \\(f(\\mathbf{x})\\), we have \\[\nf(\\mathbf{k}) \\equiv \\mathcal{F}[f(\\mathbf{x})](\\mathbf{k}) \\equiv \\int_{\\mathbb{R}^3} d^3 \\mathbf{x} \\ f(\\mathbf{x}) e^{i \\mathbf{k} \\cdot \\mathbf{x}} \\ .\n\\] Here \\(\\mathbf{k}\\) is the wavevector, a proper vector of three components. Note the subtle change in sign in this definition of the Fourier transform. This is a physics convention that makes the application of the Fourier transform easier to scalar fields \\(f(\\mathbf{x},t)\\)​ in space and time.\nThe inverse Fourier transform for a scalar field is defined in a similar way, by \\[\nf(\\mathbf{x}) = \\mathcal{F}^{-1}[f(\\mathbf{k})](\\mathbf{x}) = \\int_{\\mathbb{R}^3} \\frac{d^3 \\mathbf{x}}{(2\\pi)^3} \\ f(\\mathbf{x}) e^{-i \\mathbf{k} \\cdot \\mathbf{x}} \\ .\n\\] The scalar field version of the Fourier transform satisfies essentially the same properties as the time-dependent version, just appropriately modified for use with vectors. The delta function extends to fields as well. We simply define the field version of the delta function as the product of its components. In Cartesian coordinates, this says \\[\n\\delta(\\mathbf{x}-\\mathbf{x}') \\equiv \\delta(x-x') \\delta(y-y') \\delta(z-z') \\ .\n\\] This definition evidently means \\(\\delta(\\mathbf{x}-\\mathbf{x}')\\) must have units of inverse volume.\nIn the case of fields, the delta function \\(\\delta(\\mathbf{x}-\\mathbf{x}')\\) picks out points in 3-dimensional space, activating only when \\(\\mathbf{x}=\\mathbf{x}'\\). It’s worth noting that since the delta function is really a density rather than an ordinary function, under a change of coordinates it transforms as a density, meaning we have to include the Jacobian factor in the definition. For example, in a change of coordinates of the form \\(\\mathbf{u}=\\mathbf{u}(\\mathbf{x})\\), we have \\[\n\\delta(\\mathbf{x}-\\mathbf{x}') = \\frac{1}{|\\det \\mathbf{J}|} \\delta(u-u') \\delta(v-v') \\delta(w-w') \\ .\n\\] Here \\(\\mathbf{J} = \\frac{d\\mathbf{u}}{d\\mathbf{x}}\\) is the Jacobian of the transformation from \\(u\\)-coordinates to Cartesian \\(x\\)​​-coordinates.\n\nExample: Divergence of Inverse Square Fields\nAs an exercise in much of what we’ve learned so far, let’s calculate the divergence of the vector field \\(\\mathbf{F}(\\mathbf{x}) = \\frac{\\mathbf{e}_r}{r^2}\\). We could proceed in one of two ways. One way would be to use Cartesian coordinates and index notation to churn it out the hard way. The other way would be to recognize this scalar field is spherically symmetric, so we should work in spherical coordinates. Adopting the second approach since it’s easier, we have \\[\n\\nabla \\cdot \\mathbf{F} = \\frac{1}{r} \\frac{\\partial}{\\partial r} \\bigg(r^2 \\frac{1}{r^2}\\bigg) \\ .\n\\] It’s tempting to cancel out the factors of \\(r^2\\) and conclude \\(\\nabla \\cdot \\mathbf{F} = 0\\), but we have to be a little more careful than that. To see why let’s use the divergence theorem to express the same problem as an integral over some closed volume. We can pick any volume we like. To make things easy let’s suppose we’re integrating inside a sphere of radius \\(R\\). Then we have \\[\n\\int_S \\mathbf{F} \\cdot d\\mathbf{a} = \\int_\\mathcal{V} \\nabla \\cdot \\mathbf{F} \\ d^3\\mathbf{x} \\ .\n\\] Since \\(\\mathbf{F}\\) is spherically symmetric and we’re integrating over a sphere, we can write \\(\\mathbf{F} \\cdot d\\mathbf{a} = |\\mathbf{F}| da\\) and integrate over the surface area of the sphere to get \\[\n\\int_S \\mathbf{F} \\cdot d\\mathbf{a} = \\int r^2 \\bigg(\\frac{1}{r^2}\\bigg) \\ d\\Omega = 4\\pi \\ .\n\\] This is in fact true for any surface of arbitrary radius so long as it contains the origin. This means the divergence of \\(\\mathbf{F}\\) can’t be zero, otherwise the surface integral would be zero. Moreover, it means the only contribution from the divergence can come at the point \\(r=0\\) where the function blows up. We thus conclude that there must be a delta function multiplying \\(4\\pi\\) whose value is non-zero only when \\(r=0\\). That is, we have \\[\n\\nabla \\cdot \\bigg(\\frac{\\mathbf{e}_r}{r^2}\\bigg) = 4\\pi \\delta(\\mathbf{x}) \\ .\n\\] Note that since \\(\\nabla \\frac{1}{r} = -\\frac{\\mathbf{e}_r}{r^2}\\) we’ve shown another useful fact, that \\[\n\\nabla^2 \\bigg(\\frac{1}{r}\\bigg) = -4\\pi \\delta(\\mathbf{x}) \\ .\n\\] We will make good use of these two formulas in the rest of this course.",
    "crumbs": [
      "Electrodynamics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Preliminaries</span>"
    ]
  },
  {
    "objectID": "electrodynamics/electrostatics.html",
    "href": "electrodynamics/electrostatics.html",
    "title": "Electrostatics",
    "section": "",
    "text": "Electric Field\nWe can start the subject in fact any number of ways, for example by just stating Maxwell’s equations and studying their implications. We’ll instead stick to the more usual convention, where we start by assuming the force laws of classical mechanics along with some empirical facts about electric charges and the forces between them.\nWe’ll assume that forces are vectors, meaning they have magnitude and direction. Being vectors, forces obey the principle of superposition, meaning the combined effect of two forces exerted on a body is given by their vector sum.\nIn the 18th century, it was discovered that aside from mass, every physical body has associated to it another scalar quantity called electric charge, which can take on any real value, positive, negative, or zero. From these facts and other experiments, Coulomb discovered that the force between two static, charged bodies satisfies the following properties:",
    "crumbs": [
      "Electrodynamics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Electrostatics</span>"
    ]
  },
  {
    "objectID": "electrodynamics/electrostatics.html#electric-field",
    "href": "electrodynamics/electrostatics.html#electric-field",
    "title": "Electrostatics",
    "section": "",
    "text": "The force between the two charges depends on the magnitude of each charge. The larger the magnitude, the stronger the force between them.\nThe force obeys an inverse square law nature similar to gravity. That is, the strength of the force between the two charges varies with the inverse square of the distance between them.\nAs with gravity, the force is directed along the line of force joining the two charges.\nThe force is attractive if the two bodies have charges of opposite sign, and repulsive if the two bodies have charges of the same sign. If either body has zero charge there is no force between them.\n\n\nCoulomb’s law\nWe can state this more mathematically via Coulomb’s Law. Suppose one body has a charge \\(q_1\\) and is located at a position \\(\\mathbf{x}_1\\), while a second body has a charge \\(q_2\\) and is located at a position \\(\\mathbf{x}_2\\). Let \\(\\mathbf{r}_{12} \\equiv \\mathbf{x}_1 - \\mathbf{x}_2\\) by the separation vector between the two bodies. Then the force on charge \\(q_1\\) due to charge \\(q_2\\) is given by \\[\n\\mathbf{F}_{12} = k_e \\frac{q_1 q_2}{|\\mathbf{r}_{12}|^2} \\mathbf{e}_{12} \\ .\n\\] Here \\(k_e\\) is a proportionality constant that depends on the choice of units used. In this course we’ll use the Gaussian systems of units, where \\(k_e \\equiv 1\\) and CGS units are used to measure force and distance. This means in Gaussian units Coulomb’s Law can be written simply as \\[\n\\boxed{\\mathbf{F}_{12} = \\frac{q_1 q_2}{|\\mathbf{r}_{12}|^2} \\mathbf{e}_{12}\n} \\ ,\n\\] where it’s assumed that forces are measured in dynes and distances in centimeters. This means that in the Gaussian system charge evidently must inherit units of \\(\\sqrt{\\text{dyne} \\cdot \\text{cm}^2}\\). This derived unit of charge is called the electrostatic unit or esu, where \\(1 \\ \\text{esu} \\approx 3.3 \\cdot 10^{-10} \\ \\text{C}\\)​ in SI units.\n\n\nElectric Fields\nWhile we could proceed to study this force between charges perfectly well, it’s more useful to make another abstraction, the field abstraction. Suppose we again have two charged bodies \\(q\\) and \\(q'\\) located in space at positions \\(\\mathbf{x}\\) and \\(\\mathbf{x}'\\) respectively. Due to Coulomb’s Law, charge \\(q\\) will feel a force \\(\\mathbf{F}\\) due to charge \\(q'\\). If we look at the quantity \\(\\mathbf{E} \\equiv \\mathbf{F}/q\\) in the limit that \\(q\\) becomes infinitesimally small, it’s empirically found that this stabilizes out to a constant, well-defined value. This quantity \\(\\mathbf{E}\\) we call the electric field due to the presence of \\(q'\\). It’s a vector field satisfying the equation \\[\n\\mathbf{F} = q \\mathbf{E}(\\mathbf{x}) \\ .\n\\] Notice that by definition the electric field as defined depends only on \\(q'\\), not on \\(q\\). We can think of the presence of \\(q'\\) giving rise to an electric field that takes on a vector value at any point \\(\\mathbf{x}\\) in space. If a charge \\(q\\) is located at \\(\\mathbf{x}\\) it will feel a force of \\(\\mathbf{F} = q\\mathbf{E}\\)​ due to the presence of this field. Strictly speaking, for this definition to make sense we require that \\(q\\) be an infinitesimal charge, since otherwise its presence would alter the behavior of the electric field. Such an infintesimal charge is called a test charge.\nMatching the expression \\(\\mathbf{F} = q\\mathbf{E}\\) with Coulomb’s Law, the electric field at \\(\\mathbf{x}\\) due to \\(q'\\) can evidently be expressed as \\[\n\\mathbf{E}(\\mathbf{x}) = \\frac{q'}{|\\boldsymbol{\\xi}|^2} \\mathbf{e}_\\xi \\ ,\n\\] where we’ve defined \\(\\boldsymbol{\\xi} \\equiv \\mathbf{x} - \\mathbf{x'}\\) to be the separation vector between a field point of interest \\(\\mathbf{x}\\) and the charge’s source point \\(\\mathbf{x}'\\).\nBefore continuing, it’s worth taking the time to be careful what we mean by the notation we’re using since we’ll use it for the rest of this course. We will almost always assume the source point \\(\\mathbf{x}'\\) is the position vector of the source charge \\(q'\\) giving rise to the electric field \\(\\mathbf{E}\\). We’ll assume the field point \\(\\mathbf{x}\\) is the position vector at which the electric field takes on its given value. The separation vector \\(\\boldsymbol{\\xi}\\) will always be the vector pointing from the source point \\(\\mathbf{x}'\\) to the field point \\(\\mathbf{x}\\). This is most easily shown in the figure below.\n\n\n\n\n\nWe’ll often find it more useful to express the electric field equivalently but slightly differently way. Using the fact that the separation vector can be written as \\(\\boldsymbol{\\xi} = |\\mathbf{x}-\\mathbf{x}'| \\mathbf{e}_\\xi\\), we can write the electric field due to \\(q'\\) as \\[\n\\mathbf{E}(\\mathbf{x}) = q' \\frac{\\mathbf{x}-\\mathbf{x}'}{|\\mathbf{x}-\\mathbf{x}'|^3} \\ .\n\\] Since forces obey the principle of superposition and electric field is proportional to force, the electric field must evidently obey the principle of superposition as well. Suppose that instead of a single source charge \\(q'\\) we have \\(N\\) source charges \\(q_1, q_2, \\cdots, q_N\\) located at positions \\(\\mathbf{x}_1, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N\\) respectively. Then the combined electric field due to all source charges must be given by the sum of their individual electric fields, \\[\n\\mathbf{E}(\\mathbf{x}) = \\sum_{i=1}^N \\mathbf{E}_i(\\mathbf{x}) = \\sum_{i=1}^N q_i \\frac{\\mathbf{x}-\\mathbf{x}_i}{|\\mathbf{x}-\\mathbf{x}_i|^3} \\ .\n\\] In this case the idea is still the same. If we place an infinitesimal test charge \\(q\\) at a field point \\(\\mathbf{x}\\), the force it feels due to all of the combined source charges is \\(\\mathbf{F} = q\\mathbf{E}\\).\nGiven that the electric field is a mathematical vector field, we can always visualize it as a vector-valued function of position. Each point \\(\\mathbf{x}\\) in space has associated to it an output vector \\(\\mathbf{E}(\\mathbf{x})\\). It’s traditional though, and very convenient, to visualize electric fields using field lines. The idea is to imagine placing vector field arrows at each point in space and then connecting them together with lines running along the directions of the arrows.\nAs a good rule of thumb for drawing field lines, they should always start at positive charges and end at negative charges, or go to infinity. Field lines should never cross each other. The density of the field lines at a point indicates the strength of the field at that point. In this way, we could loosely speaking define the electric field at a point as the flux density of field lines, or number of field lines per unit area, passing near that point.\n\nWork example: finding electric field of discrete charges (cube maybe?)\n\n\n\nCoulomb vs Gravity\nGiven that Coulomb’s Law looks so similar to Newton’s Law of Gravitation, it’s fair to ask how the forces compare to each other. Let’s suppose we have two particles separated by a distance \\(r_{12}\\) with masses \\(m_1, m_2\\) and charges \\(q_1, q_2\\) respectively. The two particles will feel both a graviational force \\(\\mathbf{F}_g\\) and a Coulomb force \\(\\mathbf{F}_e\\). We can get an idea of their relative strengths by looking at their ratio, \\[\n\\frac{|\\mathbf{F}_e|}{|\\mathbf{F}_g|} = k_e \\frac{q_1 q_2}{r_{12}} \\bigg / G \\frac{m_1 m_2}{r_{12}} = \\frac{k_e q_1 q_2}{G m_1 m_2} \\ .\n\\] To get a feel for these values let’s pick a representative particle, the electrons. Then we’d have masses \\(m_1 = m_2 = m_e\\) and charges \\(q_1 = q_2 = e\\). In CGS units, these values are \\[\nk_e = 1 \\ , \\ G \\approx 6.7 \\cdot 10^{-8} \\ , \\ m_e \\approx 9 \\cdot 10^{-28} \\ , \\ e \\approx -5 \\cdot 10^{-10} \\ .\n\\] Plugging these numbers in, we have \\[\n\\frac{|\\mathbf{F}_e|}{|\\mathbf{F}_g|} = \\frac{e^2}{G m_e^2} \\approx 4 \\cdot 10^{42} \\ .\n\\] Evidently, for two electrons the Coulomb force is 42 orders of magnitude stronger than the gravitational force. The difference between the two forces is so stark we can practically speaking neglect the effects of gravity when studying the interactions between electrons, or indeed any fundamental particle. Indeed, this is one reason why in quantum mechanics we rarely consider gravity. On the other hand, larger objects like people, planets, or galaxies tend to be electrically neutral or very close to it. This means in those cases gravity is all there is, and for large masses gravity can obviously be quite substantial.\n\n\nCharge Distributions\nIn classical electromagnetism we rarely find ourselves dealing with point charges. We’re generally dealing with macroscopic materials containing many charged particles packed densely together. In such cases it’s more convenient to treat those charges not as a sum over all the point charges, but instead as a continuous distribution of charge characterized by some charge density \\(\\rho\\).\nSuppose we have some macroscopic material sitting in space with a charge density \\(\\rho\\). That is, \\(\\rho(\\mathbf{x}')\\) is a function that says how much charge per unit volume is in the region of space near a source point \\(\\mathbf{x}'\\). This density will give rise to an infinitesimal charge \\(dq' = \\rho(\\mathbf{x}') d^3 \\mathbf{x}'\\) at that point. By Coulomb’s Law, this charge will then give rise to an infinitesimal electric field \\(d\\mathbf{E}\\) given by \\[\nd\\mathbf{E}(\\mathbf{x}) = dq' \\frac{\\mathbf{x}-\\mathbf{x}'}{|\\mathbf{x}-\\mathbf{x}'|^3} = d^3 \\mathbf{x}' \\ \\rho(\\mathbf{x}') \\frac{\\mathbf{x}-\\mathbf{x}'}{|\\mathbf{x}-\\mathbf{x}'|^3} \\ .\n\\] To get the electric field generated by the entire material, we need only use the superposition and integrate over the entire volume \\(\\mathcal{V}'\\)​ of the material to get \\[\n\\boxed{\n\\mathbf{E}(\\mathbf{x}) = \\int_{\\mathcal{V}'} d^3 \\mathbf{x}' \\ \\rho(\\mathbf{x}') \\frac{\\mathbf{x}-\\mathbf{x}'}{|\\mathbf{x}-\\mathbf{x}'|^3}\n}\\ .\n\\] This idea can be seen in the figure below. The gray blog is the macroscopic material. Inside this material is an infinitesimal charge \\(dq'\\) located at the source point \\(\\mathbf{x}'\\) which defines an electric field. At any given field point \\(\\mathbf{x}\\) the field value due to \\(dq'\\) is \\(d\\mathbf{E}(\\mathbf{x})\\). The combined effect of all of these charges gives the full field.\n\n\n\n\n\nSince we can always just define the charge density outside the material to be zero, we don’t have to integrate only over \\(\\mathcal{V}'\\). We can integrate over all space, so long as we’re mindful of where the charge density is non-zero.\n\n\nLower Dimensions\nIn a sense, the name of the game in electrostatics is to find the electric field of some charge distribution. Before showing how to do that though, it’s worth noting that in many cases we won’t always be interested in 3-dimensional charge distributions like we’ve defined. Sometimes we’ll be interested in lower-dimensional charge distributions as well, like the charge distribution of a line of charge or a two-dimensional surface of charge. In these cases it’ll be convenient to slightly modify our equation for the electric field by using different kinds of charge densities.\nWe already saw one example of this, the point charge. While we derived the equation for the electric field point charge without the use of charge densities, we can express those equations naturally using charge densities as well. The charge density of a point is proportional to a delta function. If we have a point charge \\(q'\\) located at \\(\\mathbf{x}'\\), its charge distribution at an arbitrary point \\(\\mathbf{x}''\\) can be expressed as \\[\n\\rho(\\mathbf{x}'') = q' \\delta(\\mathbf{x}''-\\mathbf{x}') \\ .\n\\] Integrating the electric field over all space and using the sifting property of delta functions gives us our original equation for the electric field of a point charge, \\[\n\\mathbf{E}(\\mathbf{x}) = \\int_{\\mathcal{V}'} d^3 \\mathbf{x}'' \\ q' \\delta(\\mathbf{x}''-\\mathbf{x}') \\frac{\\mathbf{x}-\\mathbf{x}''}{|\\mathbf{x}-\\mathbf{x}''|^3} = q' \\frac{\\mathbf{x}-\\mathbf{x}'}{|\\mathbf{x}-\\mathbf{x}'|^3} \\ .\n\\] If we instead suppose a distribution of charge is concentrated along some curve \\(\\mathcal{C}'\\) in space, it’s more convenient to define a 1-dimensional charge density, or line density, \\(\\lambda(\\mathbf{x}')\\) via the relation \\(dq' = \\lambda(\\mathbf{x}') d\\ell'\\), where we imagine \\(d\\ell'\\) being an infinitesimal segment along the curve of charge. Then the electric field would be \\[\n\\mathbf{E}(\\mathbf{x}) = \\int_{\\mathcal{C}'} d \\ell' \\ \\lambda(\\mathbf{x}') \\frac{\\mathbf{x}-\\mathbf{x}'}{|\\mathbf{x}-\\mathbf{x}'|^3} \\ .\n\\] This is an abstraction to be sure, but often a convenient one, for example if we’re interested in the electric field due to a wire of charge. For wires we imagine the thickness being negligible compared to the lengths, meaning treating them as 1-dimensional curves of charge is convenient and useful.\nFIGURE\nSimilarly, we can imagine a distribution of charge concentrated along some surface \\(\\mathcal{S}'\\) in space. In this case, it’s convenient to define a 2-dimensional charge density, or surface density, \\(\\sigma(\\mathbf{x}')\\) via \\(dq' = \\sigma(\\mathbf{x}') da'\\), where \\(da'\\) is an infinitesimal patch of area inside the surface of charge. Then the electric field would be \\[\n\\mathbf{E}(\\mathbf{x}) = \\int_{\\mathcal{S}'} da' \\ \\sigma(\\mathbf{x}') \\frac{\\mathbf{x}-\\mathbf{x}'}{|\\mathbf{x}-\\mathbf{x}'|^3} \\ .\n\\] Again, this is only an abstraction, but a convenient one. We’ll often imagine sheets of charge where the length and width of the sheet are much larger than its thickness. In such cases it’s convenient to treet the sheet as 2-dimensional.\nFIGURE\n\nVerify line/surface density equations, especially the differentials….\nWork examples: electric field of line of charge, disk of charge, hollow sphere of charge\n\n\n\n\n\n\n\n\n\nimage-20240308152108598",
    "crumbs": [
      "Electrodynamics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Electrostatics</span>"
    ]
  },
  {
    "objectID": "electrodynamics/electrostatics.html#gausss-law",
    "href": "electrodynamics/electrostatics.html#gausss-law",
    "title": "Electrostatics",
    "section": "Gauss’s Law",
    "text": "Gauss’s Law\nWhile Coulomb’s Law is perhaps the most intuitive way to find the electric field of some charge distribution, it’s usually not the best way, nor is it the most illuminating. Typically in physics we find it useful to express equations for fields in terms of field equations, which are differential equations that can be solved to find the field of interest. Electrostatics turns out to have two field equations, one involving the divergence of the electric field, and one involving its curl. Here we’ll derive the equation for the divergence, known as Gauss’s Law. We’ll come back to the equation for the curl shortly.\nThe idea is to go back to thinking about the electric field in terms of field lines. Recall that we could think of the electric field as the flux density of electric field lines generated by the source charge distribution. This suggest it’s useful to define what we mean by the flux of a vector field, or more correctly the flux through a surface.\nSuppose \\(\\mathcal{S}\\) is some surface of interest, closed or not. The electrostatic flux through \\(\\mathcal{S}\\)​ is defined to be \\[\n\\Phi_\\mathbf{E}(\\mathbf{x}) \\equiv \\int_\\mathcal{S} \\mathbf{E} \\cdot d\\mathbf{a} \\ .\n\\] Intuitively, this just says we can think of electrostatic flux as the net number of field lines passing through the surface area of \\(\\mathcal{S}\\)​. The more net field lines passing through the surface, the higher the flux. This is why we can think of the electric field as the electrostatic flux density, since it’s in a sense just the flux per unit area through some given surface.\nNote the use of the phrase net number of field lines here is important because flux is actually a signed quantity since each field line can pass through the surface on either side, which flips the sign of \\(\\mathbf{E} \\cdot d\\mathbf{a}\\)​​. If a field line passes through the surface and back out the other direction, it contributes nothing to the flux.\nAlso note that the definition of flux as given depends entirely on which surface \\(\\mathcal{S}\\) we choose. We should expect that in general \\(\\Phi_\\mathbf{E}(\\mathbf{x})\\) will be different for different surfaces in space. However, as we’ll soon see the flux is indeed unique for closed surfaces that enclose the same charge distribution.\nWhat we’d like to do is find a way to relate the flux to the source charge density \\(\\rho\\) in some way, since we’re in practice usually trying to find \\(\\mathbf{E}\\) given some known distribution of source charges. To do that let’s start by trying to find the flux of a point charge \\(q\\) located at the origin. For the flux surface we’ll choose a sphere of radius \\(r\\) enclosing the point charge. For a point charge centered at the origin, we must have \\[\n\\mathbf{E}(\\mathbf{x}) = q \\frac{\\mathbf{x}}{|\\mathbf{x}|^3} = \\frac{q}{r^2} \\mathbf{e}_r \\ .\n\\] Here we employ the usual convention that \\(r = |\\mathbf{x}|\\) is the Euclidean distance to the field point \\(\\mathbf{x}\\). For a sphere of radius \\(r\\) the area element is \\(d\\mathbf{a} = r^2 d\\Omega \\mathbf{e}_r\\). Integrating over all \\(\\mathbf{E} \\cdot d\\mathbf{a}\\) to get the flux, we then have \\[\n\\oint_\\mathcal{S} \\mathbf{E} \\cdot d\\mathbf{a} = \\int d\\Omega \\ r^2 \\frac{q}{r^2} \\mathbf{e}_r \\cdot \\mathbf{e}_r = 4\\pi q \\ .\n\\] Thus, for a point charge, the flux through a sphere enclosing the charge is just \\(4\\pi q\\). This is in fact true for any closed surface enclosing the charge, not just a sphere.\nTo see why, suppose \\(\\mathcal{S}\\) is some general closed surface, shaped like a potato let’s say. Then \\[\n\\mathbf{E} \\cdot d\\mathbf{a} = |\\mathbf{E}| |\\mathbf{n}| \\cos\\alpha da = \\frac{q}{r^2} \\cos\\alpha da \\ ,\n\\] where \\(\\alpha\\) is the outward angle between \\(\\mathbf{E}\\) and the surface normal \\(\\mathbf{n}\\) at the field point \\(\\mathbf{x}\\). But, we also must have a new area element of \\(da = \\frac{r^2}{\\cos\\alpha} d\\Omega\\) since the surface is no longer spherical. All together, this means the non-spherical behavior of the surface becomes immaterial to the flux, and we again get \\[\n\\oint_\\mathcal{S} \\mathbf{E} \\cdot d\\mathbf{a} = \\int d\\Omega \\ \\frac{r^2}{\\cos\\alpha} \\frac{q}{r^2} \\cos\\alpha = 4\\pi q \\ .\n\\] What about if the charge is outside the closed surface though? What happens then? Intuitively we should expect the flux to be zero, since any field line flowing into the surface must also flow out at some point. Indeed this is what happens. Any flux of \\(\\mathbf{E} \\cdot d\\mathbf{a}\\) passing into the surface will have a corresponding flux \\(-\\mathbf{E} \\cdot d\\mathbf{a}\\) on the opposite side where the field line passes back out of the surface. This can most easly be shown from the figure below.\n\n\n\n\n\nThus, the flux for a point charge through any closed surface is \\(4\\pi q\\) if the point charge is inside the surface, and zero if the point charge is outside the closed surface.\nFrom here we can easily use the principle of superposition to find the flux of any charge distribution through a closed surface. If \\(Q_{\\text{enc}}\\) is the total charge enclosed by a closed surface \\(\\mathcal{S}\\), then we have \\[\n\\boxed{\n\\oint_\\mathcal{S} \\mathbf{E} \\cdot d\\mathbf{a} = 4\\pi Q_{\\text{enc}}\n} \\ .\n\\] In this we’ve defined one version of Gauss’s Law, the integral form. This says how the total flux of the electric field through a closed surface depends on the charges contained inside it.\nBefore using this formula to solve several important electrostatics problems let’s quickly get what we originally sought in this section: a differential equation for the electric field in terms of the charge distribution. To do that we’ll express the enclosed charge as a volume integral of the charge density, \\[\nQ_{\\text{enc}} = \\int_\\mathcal{V} d^3\\mathbf{x} \\ \\rho(\\mathbf{x}) \\ ,\n\\] where \\(\\mathcal{V}\\) is the volume enclosed by the closed surface \\(\\mathcal{S}\\). Next, we’ll use the divergence theorem to rewrite the flux integral as a volume integral of the divergence of \\(\\mathbf{E}\\), \\[\n\\oint_\\mathcal{S} \\mathbf{E} \\cdot d\\mathbf{a} = \\int_\\mathcal{V} d^3\\mathbf{x} \\ \\nabla \\cdot \\mathbf{E} \\ .\n\\] Plugging these two into the integral form of Gauss’s Law and moving everything to one side, we then have \\[\n\\int_\\mathcal{V} d^3\\mathbf{x} \\ \\big[\\nabla \\cdot \\mathbf{E} - 4\\pi\\rho\\big] = 0 \\ .\n\\] Now, the only way this integral can be zero is for the integrand to be be zero as well. This then implies \\[\n\\boxed{\n\\nabla \\cdot \\mathbf{E} = 4\\pi\\rho\n} \\ .\n\\] This is the differential form of Gauss’s Law. It gives us a differential equation to find \\(\\mathbf{E}\\) if \\(\\rho\\) is known. Of course, actually solving this equation is easier said than done. We’ll come back to that later.\nFor now let’s show how we can use the integral form of Gauss’s Law to solve a few convenient problems. Gauss’s Law is most useful when a problem has certain symmetries we can recognize.\n\nWork the three common examples: line charge, sheet, sphere",
    "crumbs": [
      "Electrodynamics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Electrostatics</span>"
    ]
  },
  {
    "objectID": "electrodynamics/electrostatics.html#electric-potential",
    "href": "electrodynamics/electrostatics.html#electric-potential",
    "title": "Electrostatics",
    "section": "Electric Potential",
    "text": "Electric Potential\nLet’s now look at the field equation for the curl of the electric field. From the Helmholtz theorem, we know that any vector field can be fully determined by knowing both its divergence and its curl. This means that once we figure out what the curl of the electric field is we’ve fully specified what the electric field must be from two partial differential equations.\nThere are a few ways we can proceed. One way is to just directly take the curl of the integral expression for the electric field and grind out an answer. This works fine, but we’ll take an easier approach. Recall from classical mechanics that a force \\(\\mathbf{F}\\) is conservative if and only if its curl vanishes, \\(\\nabla \\times \\mathbf{F} = \\mathbf{0}\\). We also know that any central force, a force that depends only on the relative distance between particles, is conservative. The Coulomb force is clearly a central force since it only depends on the relative distance between charges. In particular, this means we automatically must have that the curl of the electric field vanishes in electrostatics, \\[\n\\boxed{\n\\nabla \\times \\mathbf{E} = \\mathbf{0}\n} \\ .\n\\] This completes our picture of field equations we need to fully determine the electric field in electrostatics. All that remains at this point is analyzing the two field equations to see what they’re telling us. We’ve already done that with the divergence, deriving Gauss’s Law. Let’s now look into the curl equation to see what it implies.\nWe know from vector calculus that any vector field whose curl vanishes must have a scalar potential whose gradient fully determines the vector field. The potential for the electric field is called the electrostatic potential \\(\\phi(\\mathbf{x})\\), with \\[\n\\mathbf{E} = -\\nabla \\phi \\ .\n\\] Since the force exerted by the field on a point charge \\(q\\) is given by \\(\\mathbf{F} = q\\mathbf{E}\\) and \\(\\mathbf{F}\\) is conservative, we know that it has a potential energy \\(U(\\mathbf{x})\\) that must evidently be proportional to \\(\\phi(\\mathbf{x})\\), \\[\nU(\\mathbf{x}) = q\\phi(\\mathbf{x}) \\ .\n\\] This means we can interpret the elecrostatic potential as the potential energy per unit charge exerted on a test particle placed in the electric field. The units for the electric potential are evidently energy per unit charge. In SI units this means the potential has units of Joules per Coulomb, which is called the Volt. In Gaussian units the potential has units of ergs per ESU, sometimes called the stat-volt, with \\(1 \\ \\frac{\\text{erg}}{\\text{esu}} \\approx 300 \\ \\text{V}\\)​​.\n\nIntegral Form\nIn the simplest place where the charge distribution is just a single point charge \\(q'\\) we already know what \\(\\mathbf{E}\\) is from Coulomb’s Law. We can use that to figure out what the electric potential for a point charge is. Observe if we can recover \\(\\mathbf{E}\\) by taking \\[\n\\phi(\\mathbf{x}) = \\frac{q'}{|\\mathbf{x}-\\mathbf{x}'|} \\ .\n\\] Using the same logic as we did did for the electric field, this means that the electric potential due to a charge distribution \\(\\rho\\) is just \\[\n\\boxed{\n\\phi(\\mathbf{x}) = \\int_{\\mathcal{V}'} d^3 \\mathbf{x}' \\ \\frac{\\rho(\\mathbf{x}')}{|\\mathbf{x}-\\mathbf{x}'|}\n}\\ .\n\\] Unlike the integral for the electric field, for the electric potential we now only have one scalar integral to evaluate instead of 3. Obviously, this greatly simplifies the problem we need to solve. Let’s work a few examples to see that. But first let’s say a word about what the “field lines” look like for the electric potential.\nSince the electric field is the gradient of the potential, and gradients always point normal to their contour surfaces, the potential must evidently be contour surfaces for the electric field. These surface of constant potential are called equipotentials. They’ll always be surfaces perpendicular to the electric field lines.\n\nWork the previous examples again, using electric fields to find the potentials\n\n\n\nPoisson’s Equation\nUsing the electrostatic potential we can combine the two field equations for the electric field into one field equation for the potential. Since the existence of the potential already satisfies the curl constraint, we just need to plug it into Gauss’s Law to satisfy the divergence constraint. Using \\(\\mathbf{E} = -\\nabla \\phi\\), we have \\[\n\\nabla \\cdot \\mathbf{E} = \\nabla \\cdot (-\\nabla \\phi) = 4\\pi\\rho \\ .\n\\] Recognizing that this is just the Laplacian for the potential, we thus have \\[\n\\boxed{\n\\nabla^2 \\phi = -4\\pi\\rho\n} \\ .\n\\] This is called Poisson’s Equation. It gives us a second order PDE we can use to find the potential if the source charge distribution is known. In deriving Poisson’s Equation, we’ve converted two first order differential equations for the vector field \\(\\mathbf{E}\\) into a single second order differential equation for the scalar field \\(\\phi\\). This means that solving Poisson’s Equation given some set of boundary conditions will fully give us all of the information we need to determine \\(\\phi\\), and hence \\(\\mathbf{E}\\) as well. For this reason, Poisson’s Equation could easily be considered the single most important equation in electrostatics.\nPerhaps the most important reason the potential is nice is that instead of solving for 3 equations, the 3 components of the electric field, with the potential we only need solve a single equation. In this sense, the electric field is evidently redundant, since each of its components are obtained from the same scalar field.\nIf we like, we can also invert the equation \\(\\mathbf{E} = -\\nabla \\phi\\) to get an equation for \\(\\phi\\) in terms of \\(\\mathbf{E}\\). Suppose \\(\\mathbf{x}_g\\) is some chosen fixed reference point, called the ground point. Then by the fundamental theorem of calculus we have \\[\n\\phi(\\mathbf{x}) = -\\int_{\\mathbf{x}_g}^{\\mathbf{x}} \\mathbf{E}(\\mathbf{x}') \\cdot d\\boldsymbol{\\ell}' \\ .\n\\] Usually we’ll choose the ground point such that \\(\\phi(\\mathbf{x}_g) \\equiv 0\\). This can be any point we like, but for our purposes it’ll usually be most convenient to choose the ground point at infinity. But in many practical applications the ground point may be chosen arbitrarily to simplify the problem.\nFor example, when dealing with electric circuits the ground point is usually taken to be the negative terminal point. Such a potential difference is often called a voltage in electronics. Voltages are frequently among the most important electricity-related quantities measured in the lab, along with currents, which we’ll get to later.",
    "crumbs": [
      "Electrodynamics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Electrostatics</span>"
    ]
  },
  {
    "objectID": "electrodynamics/electrostatics.html#electrostatic-energy",
    "href": "electrodynamics/electrostatics.html#electrostatic-energy",
    "title": "Electrostatics",
    "section": "Electrostatic Energy",
    "text": "Electrostatic Energy\nWhen talking about energy in electrostatics we have to be a bit careful which energy we’re talking about. We’ve already seen one form of energy: The potential energy arising due to the work done in moving a charge \\(q\\) through an external electric field. This is just \\(U = q\\phi\\), where \\(\\phi\\) is the electric potential associated to the external electric field \\(\\mathbf{E}\\)​​. Note this field is assumed to be due to all the other source charges in space, ignoring \\(q\\). In the continuum limit we can express this as an integral over the charge density, \\[\nU = \\int d^3\\mathbf{x} \\ \\rho(\\mathbf{x}) \\phi(\\mathbf{x}) \\ .\n\\] This isn’t the only form of potential energy we can think about though. In fact, it’s often more useful to ask a different question: What is the work done to assemble the source charge distribution that gives rise to \\(\\mathbf{E}\\) in the first place? To answer this question it helps to imagine bringing each source charge in from space one-by-one and placing it at its source point. Each placement will give rise to its own potential energy. Adding all of these energies together will give us what we seek.\nSuppose we have some set of source charges \\(q_1, q_2, \\cdots, q_N\\) giving rise to the source charge distribution. Suppose initially that all of these source charges are placed at infinity, where we’ll define the potential energy to be zero.\nNow suppose we bringing in only the first charge \\(q_1\\) and place it at position \\(\\mathbf{x}_1\\). Since there’s no electric potential initially, the work done to place this first charge must evidently be zero, \\(W_1 = 0\\)​.\nNow suppose we’ve placed charge \\(q_1\\) and now bring in the second charge \\(q_2\\) and place it at \\(\\mathbf{x}_2\\). In this case there’s now an electric potential due to \\(q_1\\) that we have to overcome in order to place \\(q_2\\). Thus, the work done to place \\(q_2\\) is \\[\nW_2 = q_2 \\frac{q_1}{|\\mathbf{x}_2 - \\mathbf{x}_1|} \\ .\n\\] We’ve now placed charges \\(q_1\\) and \\(q_2\\). Let’s now bring in charge \\(q_3\\) and place it at \\(\\mathbf{x}_3\\). By superposition, the work done to place \\(q_3\\) is just the sum of the potential energies due to the point charges \\(q_1\\) and \\(q_2\\) already placed. That is, \\[\nW_3 = q_3 \\frac{q_1}{|\\mathbf{x}_3 - \\mathbf{x}_1|} + q_3 \\frac{q_2}{|\\mathbf{x}_3 - \\mathbf{x}_2|} \\ .\n\\] FIGURE\nHopefully by now we can spot the pattern. Suppose we want to place the \\(j\\)th charge \\(q_j\\) in place at \\(\\mathbf{x}_j\\). By superposition, \\[\nW_j = q_j \\sum_{i&lt;j} \\frac{q_i}{|\\mathbf{x}_j - \\mathbf{x}_i|} = \\frac{1}{2} q_j \\sum_{i \\neq j} \\frac{q_i}{|\\mathbf{x}_j - \\mathbf{x}_i|} \\ .\n\\] In the last equation we used the fact that we can always write \\(\\sum_{i &lt; j} = \\frac{1}{2} \\sum_{i \\neq j}\\) to simplify the summation somewhat. This can easily be seen, for example, by placing the summation elements inside a matrix and observing that the condition \\(i &lt; j\\) means to sum only the entries in the upper triangle, and since \\(i,j\\) are symmetric in this case, that’s just half the sum of the upper and lower triangles (excluding the diagonal) since the matrix will be symmetric as well.\nNow, the work done to place all of these charges in place is just the sum of all these contributions, \\[\nW = \\sum_{j=1}^N U_j = \\frac{1}{2} \\sum_{j=1}^N q_j \\sum_{i \\neq j} \\frac{q_i}{|\\mathbf{x}_j - \\mathbf{x}_i|} = \\frac{1}{2} \\sum_{j=1}^N q_j \\phi_i(\\mathbf{x}_j) \\ .\n\\] This work done we can think of as the potential energy \\(U\\) stored in all of the source charges. In the continuum limit we can replace the sum over the source charges with an integral over the source charge distribution to get \\[\nU = \\frac{1}{2} \\int d^3\\mathbf{x} \\ \\rho(\\mathbf{x}) \\phi(\\mathbf{x}) \\ .\n\\] It’s worth stopping for a moment to ask how this potential energy differs from our first definition of potential energy as the work required to move a test charge in the presence of the external electric field. Evidently the first definition of potential energy is essentially just half the second, even though they mean very different things.\nIt’s useful to write the potential energy to place the source charges it in a more illuminating way. From Gauss’s Law, we know that \\(\\nabla \\cdot \\mathbf{E} = 4\\pi \\rho\\). Solving for \\(\\rho\\) and using integration by parts, we can evidently rewrite \\(U\\) as \\[\n\\begin{align*}\nU &= \\frac{1}{2} \\int d^3\\mathbf{x} \\ \\rho(\\mathbf{x}) \\phi(\\mathbf{x}) \\\\\n&= \\frac{1}{2} \\int d^3\\mathbf{x} \\ \\frac{\\nabla \\cdot \\mathbf{E}(\\mathbf{x})}{4\\pi} \\phi(\\mathbf{x}) \\\\\n&= \\frac{1}{8\\pi} \\int d^3\\mathbf{x} \\ \\mathbf{E}(\\mathbf{x}) \\cdot \\big(-\\nabla \\phi(\\mathbf{x})\\big) \\\\\n&= \\frac{1}{8\\pi} \\int d^3\\mathbf{x} \\ \\mathbf{E}(\\mathbf{x}) \\cdot \\mathbf{E}(\\mathbf{x}) \\ .\n\\end{align*}\n\\] Here we assume the surface term from the integration by parts vanishes as we integrate over all space. This will be true so long as \\(\\phi \\mathbf{E}\\) goes to zero faster than \\(\\frac{1}{r^2}\\), which is a realistic assumption for well-localized charge distributions. In the end, we evidently get that the potential energy to assemble all of the source charges is proportional to the square of the electric field, \\[\nU = \\int d^3\\mathbf{x} \\ \\frac{1}{8\\pi} |\\mathbf{E}(\\mathbf{x})|^2 \\ .\n\\] This result is interesting in that it gives us another way to interpret this form of potential energy. We can think of the work done to assemble all of the source charges equivalently as the potential energy stored in the electric field itself. It’s useful to define the integrand as an energy density \\(u(\\mathbf{x})\\), in which case we can write \\[\n\\boxed{\nu(\\mathbf{x}) \\equiv \\frac{1}{8\\pi} |\\mathbf{E}(\\mathbf{x})|^2\n} \\ .\n\\] At this point it’s worth stopping to more closely analyze a few of the assumptions we made in deriving this second form of the potential energy stored in the electric field. We made two important assumptions:\n\nThe surface term in the integration by parts will vanish. This will be true so long as we integrate to infinity and the term \\(\\phi \\mathbf{E}\\) goes to zero faster than \\(\\frac{1}{r^2}\\). As long as the source charge distribution is well-localized this is realistic, since we’d then expect that \\(\\phi \\mathbf{E} \\sim \\frac{1}{r^3}\\) at infinity. This isn’t true, however, for infinite charge distributions like the infinite line charge or the infinite sheet. In cases like that we must either include the surface integral term, or use the first integral form to find \\(U\\)​.\nSelf energies are ignorable. Notice in our transition from the finite sum to the integral form we “smeared out” the requirement that \\(i \\neq j\\) in the sum for the electric potential. As long as we imagine only integrating over field points away from the source charge distribution this is fine. If we don’t though the potential energy will actually be infinite! To see why, observe if we attempt to find the potential energy for a point charge at the origin using the second form we get \\[\nU = \\int d^3\\mathbf{x} \\ \\frac{1}{8\\pi} |\\mathbf{E}(\\mathbf{x})|^2 = \\int_0^\\infty 4\\pi r^2 dr \\ \\frac{1}{8\\pi} \\bigg(\\frac{q}{r^2}\\bigg)^2 = \\infty \\ .\n\\] However, if we use the first integral form for the potential energy we’d get \\[\nU = \\frac{1}{2} \\int d^3\\mathbf{x} \\ \\rho(\\mathbf{x}) \\phi(\\mathbf{x}) = \\frac{1}{2} \\int_0^\\infty 4\\pi r^2 dr \\ q \\delta(\\mathbf{x}) \\frac{q}{r} = 0 \\ ,\n\\] as we’d expect. Clearly then there’s a problem arising from the inclusion of the self energies in the second form of the integral. So what’s going on? One way to think about it is that the self energy terms include the energy necessary to introduce each charge from the vaccuum. In this sense, self energies are tied up with vacuum energies, the energy stored in the vacuum of space itself. Understanding the vacuum energy requires quantum field theory, and is still an active area of research to this day.",
    "crumbs": [
      "Electrodynamics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Electrostatics</span>"
    ]
  },
  {
    "objectID": "circuits/circuit-abstraction.html",
    "href": "circuits/circuit-abstraction.html",
    "title": "The Lumped Circuit Abstraction",
    "section": "",
    "text": "Maxwell’s Equations\nMaxwell’s Equations are taught in electrodynamics courses. In SI units, they’re given as follows.\nRather than use these equations directly we’ll derive three simpler laws that hold for circuits:",
    "crumbs": [
      "Circuit Analysis",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>The Lumped Circuit Abstraction</span>"
    ]
  },
  {
    "objectID": "circuits/circuit-abstraction.html#maxwells-equations",
    "href": "circuits/circuit-abstraction.html#maxwells-equations",
    "title": "The Lumped Circuit Abstraction",
    "section": "",
    "text": "Name\nDifferential Form\nIntegral Form\n\n\n\n\nGauss’s Law\n\\(\\nabla \\cdot \\mathbf{E} = \\frac{\\rho}{\\varepsilon_0}\\)\n\\(\\oint \\mathbf{E} \\cdot d\\mathbf{a} = \\frac{q}{\\varepsilon_0}\\)\n\n\nFaraday’s Law\n\\(\\nabla \\times \\mathbf{E} = -\\frac{\\partial \\mathbf{B}}{\\partial t}\\)\n\\(\\oint \\mathbf{E} \\cdot d\\boldsymbol{\\ell} = -\\frac{\\partial \\Phi_M}{\\partial t}\\)\n\n\nNo Magnetic Monopoles\n\\(\\nabla \\cdot \\mathbf{B} = 0\\)\n\\(\\oint \\mathbf{B} \\cdot d\\mathbf{a} = 0\\)\n\n\nAmpere’s Law\n\\(\\nabla \\times \\mathbf{B} = \\mu_0 \\mathbf{J} + \\frac{1}{\\varepsilon_0 \\mu_0} \\frac{\\partial \\mathbf{E}}{\\partial t}\\)\n\\(\\oint \\mathbf{B} \\cdot d\\boldsymbol{\\ell} = \\mu_0 I + \\frac{1}{\\varepsilon_0 \\mu_0} \\frac{\\partial \\Phi_E}{\\partial t}\\)\n\n\nContinuity Equation\n\\(\\frac{\\partial \\rho}{\\partial t} - \\nabla \\cdot \\mathbf{J} = 0\\)\n\\(\\frac{\\partial q}{\\partial t} - \\oint \\mathbf{J} \\cdot d\\mathbf{a} = 0\\)\n\n\n\n\n\nOhm’s Law: \\(v = iR\\).\nKirchoff’s Voltage Law (KVL): \\(\\sum_{loop} v = 0\\).\nKirchoff’s Current Law (KCL): \\(\\sum_{node} i = 0\\).",
    "crumbs": [
      "Circuit Analysis",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>The Lumped Circuit Abstraction</span>"
    ]
  },
  {
    "objectID": "circuits/circuit-abstraction.html#ohms-law",
    "href": "circuits/circuit-abstraction.html#ohms-law",
    "title": "The Lumped Circuit Abstraction",
    "section": "Ohm’s Law",
    "text": "Ohm’s Law\nFor many materials, a linear relation holds between the electric field \\(\\mathbf{E}\\) inside the material and its current density \\(\\mathbf{J}\\). This is the Generalized Ohm’s Law: \\[\\mathbf{E} = \\rho \\mathbf{J},\\] where \\(\\rho\\) is the material’s resistivity. Consider a piece of cylindrical material, called a resistor, with a current \\(i\\) pumped through its ends.\n\n\n\n\n\nSince \\(\\mathbf{E} = E \\mathbf{e}_y\\) and \\(\\mathbf{J} = J \\mathbf{e}_y\\), and \\(A\\) and \\(\\ell\\) are constant, we have\n\\[\\begin{align*}\n\ni &= \\oint \\mathbf{J} \\cdot d\\mathbf{a} = J \\cdot A, \\\\\\\n\nv &= \\oint \\mathbf{E} \\cdot d\\mathbf{\\ell} = E \\cdot l.\n\n\\end{align*}\\]\nThus, we have \\(v = \\frac{\\rho \\ell}{A}i \\equiv Ri\\), where \\(R \\equiv \\frac{\\rho \\ell}{A}\\) is a constant, called the resistence of the material. The relation then becomes \\[v = iR,\\] which is the standard Ohm’s Law. Note Ohm’s Law as stated is only true for resistive materials.",
    "crumbs": [
      "Circuit Analysis",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>The Lumped Circuit Abstraction</span>"
    ]
  },
  {
    "objectID": "circuits/circuit-abstraction.html#the-lumped-circuit-abstraction",
    "href": "circuits/circuit-abstraction.html#the-lumped-circuit-abstraction",
    "title": "The Lumped Circuit Abstraction",
    "section": "The Lumped Circuit Abstraction",
    "text": "The Lumped Circuit Abstraction\nTo easily and reliably analyze circuits we make a number of simplifying assumptions, or abstractions. By restricting ourselves to situations where these abstractions hold, we set up a simpler playground in which to work.\nThe most fundamental abstraction in circuit analysis is the lumped circuit abstraction or LCA. In the LCA, we assume a circuit is made of a set of lumped elements that are connected to each other with ideal wires (i.e. wires with no voltage drop across any two points and a uniform current throughout).\nAs an example, let’s consider a lightbulb connected to a battery supplying a voltage \\(v\\), which causes a current \\(i\\) to flow across the bulb from the positive terminal of the battery to the negative terminal.\n\n\n\n\n\nWe’d like to solve for the current \\(i\\) as a function of the input voltage \\(v\\). How should we do this? The hard way would be to just use Maxwell’s Equations. But this is unnecessary.\nNotice that we don’t care about many of the physical properties of the circuit, including the bulb’s shape, temperature, filament design, or what the wires are made of. We only care about the bulb’s resistance, since Ohm’s law says \\(v=iR\\). We can thus abstract the details of the bulb and the battery away, treating the bulb as a resistor and the battery as a voltage source.\n\n\n\n\n\nOnce we’ve done this, we can simply solve for the current in terms of the voltage simply as \\[i = \\frac{v}{R}.\\]\nA more abstract way to express this simple circuit is to use special symbols for the resistor and the voltage source. We’d write the exact same setup like this.\n\n\n\n\n\nNow, how do we know we can do this? How do we even know that \\(v\\) and \\(i\\) are even defined? After all, neither voltage nor current need exist in a well-defined way. However, under certain conditions, they do exist. Consider the following setup, where a current \\(i\\) flows through a wire from \\(A\\) to \\(B\\). The voltage across the wire is \\(v\\). The cross-sectional areas through \\(A\\) and \\(B\\) are \\(s_A\\) and \\(s_B\\), respectively.\n\n\n\n\n\nBy the continuity equation, we have \\[i_A - i_B \\equiv \\int_{s_A} \\mathbf{J} \\cdot d\\mathbf{a} - \\int_{s_B} \\mathbf{J} \\cdot d\\mathbf{a} = \\frac{\\partial q}{\\partial t}.\\] Provided no charge can build up inside the wire, we have \\[\\frac{\\partial q}{\\partial t} = 0 \\Rightarrow i_A = i_B \\equiv i.\\] That is, we have a well-defined current \\(i\\) flowing through the wire provided we forbid a buildup of charge inside the wire.\nBy Faraday’s Law, we also have \\[v_A - v_B \\equiv \\int_A^B \\mathbf{E} \\cdot d \\boldsymbol{\\ell} = -\\frac{\\partial \\Phi_M}{\\partial t}.\\] Provided magnetic flux is constant outside the wires, we can conclude \\[\\frac{\\partial \\Phi_M}{\\partial t} = 0 \\Rightarrow v_A = v_b \\equiv v.\\] That is, we have a well-defined voltage \\(v\\) across the wire provided we forbid any change in magnetic flux outside the wire.\nThe last condition we must require is that currents move much slower than the speed of light. This says that currents aren’t allowed to radiate.\nThe requirement that circuits obey each of these properties is called the lumped matter discipline:\n\nElements are discrete and independent of each other.\nNo charge can build up inside of wires.\nMagnetic flux is constant outside of the circuit.\nCurrents must move much slower than the speed of light.",
    "crumbs": [
      "Circuit Analysis",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>The Lumped Circuit Abstraction</span>"
    ]
  },
  {
    "objectID": "circuits/circuit-abstraction.html#lumped-elements",
    "href": "circuits/circuit-abstraction.html#lumped-elements",
    "title": "The Lumped Circuit Abstraction",
    "section": "Lumped Elements",
    "text": "Lumped Elements",
    "crumbs": [
      "Circuit Analysis",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>The Lumped Circuit Abstraction</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/thermodynamics.html",
    "href": "statistical-mechanics/thermodynamics.html",
    "title": "Thermodynamics",
    "section": "",
    "text": "Thermodynamic Systems\nIn thermodynamics we seek to describe the macroscopic properties of a thermodynamic system. Unlike in classical mechanics, we won’t think of a system as a particle or a collection of particles, but rather as an object describable by a set of macroscopic properties. By macroscopic we mean properties that describe the state of the entire system, like its temperature, pressure, volume, etc. These properties are called state variables or thermodynamic coordinates.\nIn thermodynamics we’re interested in studying a few different kinds of systems, depending on what is allowed to flow into and out of the system. We assume the system is submerged in some external environment, called a heat bath.\nWe say a system is in equilibrium when its internal temperature has had sufficient time to relax to some steady state value. More precisely, the internal temperature doesn’t change appreciably over some given observation time. In a large sense, thermodynamics is about the study of equilibrium. We require that an equilibrium state exist for the system before we can even talk about thermodynamic variables. Of course, we haven’t even defined what temperature is, or shown that it must exist. We’ll do that in the next section.\nThe specific variables we seek to measure depend on the type of system under consideration. Here are some examples of mechanical variables that might depend on the system:\nOn top of these mechanical variables that vary by system, we also may be interested in a system’s thermal variables, i.e. variables that arise due to the system’s internal interactions. The macroscopic thermal variables might be temperature, entropy, or heat.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Thermodynamics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/thermodynamics.html#thermodynamic-systems",
    "href": "statistical-mechanics/thermodynamics.html#thermodynamic-systems",
    "title": "Thermodynamics",
    "section": "",
    "text": "An isolated system is a system in which no energy exchange is allowed with the heat bath, either through heat or work. Isolated systems have the property that total energy is conserved.\nAn adiabatic system is a system in which no heat exchange is allowed with the heat bath. An exchange of work is still allowed, which means total energy isn’t conserved.\nA closed system is a system in which energy is allowed to be exchanged with the heat bath, either through heat or work. The total energy of the closed system plus the heat bath is conserved.\nA diathermic system is a system in which heat is allowed to be exchanged with the heat bath, but work may or may not be exchanged.\n\n\n\n\nGas in a container: We might be interested in its volume or the pressure it exerts on the container.\nA wire under tension: We might be interested in its length or the tension forces exerted on it.\nA magnet in a field: We might be interested in its magnetization or its external magnetic field.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Thermodynamics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/thermodynamics.html#zeroth-law",
    "href": "statistical-mechanics/thermodynamics.html#zeroth-law",
    "title": "Thermodynamics",
    "section": "Zeroth Law",
    "text": "Zeroth Law\nSuppose we have three distinct systems \\(A\\), \\(B\\), and \\(C\\). The zeroth law of thermodynamics states that if \\(A\\) is in equilibrium with \\(B\\), and \\(B\\) is in equilibrium with \\(C\\), then \\(A\\) is in equilibrium with \\(C\\). That is, the property of equilibrium is transitive.\n\n\n\n\n\nNotice that for any two systems to be in equilibrium with each other they must be allowed to exchange heat. If they were isolated, even the smallest change to one system wouldn’t affect the other. The zeroth law evidently implies that this holds for any number of systems in equilibrium. You can’t isolate any one from the other, since heat can always flow through any two pairs of systems in equilibrium with each other.\nThe zeroth law implies the existence of a thermal quantity called the empirical temperature that’s the same among systems in equilibrium, a quantity that doesn’t change when no net heat is flowing between any two systems.\nTheorem: Suppose two systems \\(A\\) and \\(B\\) are in thermodynamic equilibrium with each other. Suppose \\(A\\) has thermodynamic coordinates \\(A_1, A_2, \\cdots, A_n\\) and \\(B\\) has thermodynamic coordinates \\(B_1, B_2, \\cdots, B_m\\). Then there exists a value \\(\\theta\\), called the empirical temperature, that depends only on the state of each system, and in equilibrium satisfies the property that for some functions of the coordinates \\[\n\\theta = \\theta_A(A_1, A_2, \\cdots, A_n) = \\theta_B(B_1, B_2, \\cdots, B_m).\n\\] Proof: Suppose a third system \\(C\\) is in equilibrium with \\(A\\) and \\(B\\) with coordinates \\(C_1, C_2, \\cdots, C_k\\). Since \\(A\\) is in equilibrium with \\(C\\), there must be some function of constraint \\(f_{AC}\\) such that \\[\nf_{AC}(A_1, A_2, \\cdots, A_n, C_1, C_2, \\cdots, C_k) = 0.\n\\] Similarly, if \\(B\\) is in thermal equilibrium with \\(C\\) then there is some other constraint function \\(f_{BC}\\) such that \\[\nf_{BC}(B_1, B_2, \\cdots, B_m, C_1, C_2, \\cdots, C_k) = 0.\n\\] Now, we can imagine solving for each function in terms of a common variable \\(C_1\\) to get new functions \\[\n\\begin{align*}\nC_1 &= g_{AC}(A_1, A_2, \\cdots, A_n, C_2, \\cdots, C_k), \\\\\nC_1 &= g_{BC}(B_1, B_2, \\cdots, B_m, C_2, \\cdots, C_k). \\\\\n\\end{align*}\n\\] Setting these two functions equal thus says that \\[\ng_{AC}(A_1, A_2, \\cdots, A_n, C_2, \\cdots, C_k) - g_{BC}(B_1, B_2, \\cdots, B_m, C_2, \\cdots, C_k) = 0.\n\\] By the zeroth law, we also know that \\(A\\) must be in thermal equilibrium with \\(B\\). This means there’s yet another function \\(f_{AB}\\) such that \\[\nf_{AB}(A_1, A_2, \\cdots, A_n, B_1, B_2, \\cdots, B_m) = 0.\n\\] Taken together, this says that we can take \\(f_{AB}\\) and spread it out into two functions \\(g_{AC}\\) and \\(g_{BC}\\), where \\(g_{AC}\\) depends only on the coordinates of \\(A\\) and \\(C\\), and \\(g_{BC}\\) depends only on the coordinates \\(B\\) and \\(C\\). If we imagine using the coordinates of \\(C\\) as some kind of reference values we can treat them as constants. That means we’re left with an expression of the form \\[\ng_{AC}(A_1, A_2, \\cdots, A_n, \\text{const}) - g_{BC}(B_1, B_2, \\cdots, B_k, \\text{const}) = 0.\n\\] This says we have a function of \\(A\\) that must equal a similar function of \\(B\\) at thermal equilibrium, \\[\n\\theta \\equiv \\theta_A(A_1, A_2, \\cdots, A_n) = \\theta_B(B_1, B_2, \\cdots, B_m). \\qquad \\text{Q.E.D.}\n\\] The empirical temperature is evidently reference dependent since we had to fix values for some third system \\(C\\) just to properly define it. We can choose \\(C\\) to be anything we like as long as we agree on a convention. The most common is the triple point of water, the state where water coexists in its gas, liquid, and solid forms simultaneously. This occurs at a temperature of about \\(T = 273.16 \\ \\degree \\text{K}\\) and pressure of about \\(p = 0.006 \\text{ atm}\\).\n\n\n\n\n\nThe condition that \\(\\theta = \\theta_A\\) says that in the space of coordinates of \\(A\\), in thermal equilibrium the system must be constrained to a surface of constant \\(\\theta_A = \\theta\\). This surface is called an isotherm, a surface of constant temperature. Similarly for \\(B\\).\nAnalogy: Think of defining temperature similarly to how one might empirically define mass by using a scale. You first establish a reference mass \\(C\\), for example some standard block of metal in a vault, and then use that to talk about how much the masses \\(A\\) and \\(B\\) weigh in units of \\(C\\).\n\nIdeal Gas\nOne practically useful way to define an empirical temperature scale uses the properties of the ideal gas. An ideal gas is a large number of dilute particles that satisfy the property that the product of the gas’s pressure \\(P\\) and volume \\(V\\) is proportional temperature in the dilute limit, i.e. \\[\n\\lim_{V \\rightarrow \\infty} PV = \\lim_{P \\rightarrow 0} PV \\propto \\theta.\n\\] We’ll assume the gas is allowed to interact diathermally with the heat bath. That is, the gas is allowed to exchange energy with its environment, but nothing else.\nSuppose now that we submerge the gas in one heat bath and record values for \\(P, V, \\theta\\) once the system has reached equilibrium. Then, we take the gas and submerge it again in a different reference heat bath. Once the system has again reached equilibrium, we again record the new values \\(P_0, V_0, \\theta_0\\). Now, since the gas is ideal, we must have \\[\n\\frac{\\theta}{\\theta_0} = \\frac{PV}{P_0 V_0}.\n\\] Provided we’ve fixed a value for \\(\\theta_0\\), we can thus define the temperature \\(T\\) of the system by \\[\nT \\equiv \\theta \\equiv \\theta_0 \\frac{PV}{P_0 V_0} = \\frac{\\theta_0}{P_0} \\frac{PV}{V_0}.\n\\] In the Kelvin scale, \\(\\theta_0\\) and \\(P_0\\) are again defined by the triple point of water. This means that to measure the temperature, we’d need to first measure the pressure and volume of the gas in the heat bath of interest, and then compare that with the volume the same gas would have at the triple point.\nFor an ideal gas, we evidently have the relation then that \\(PV \\propto T\\). It turns out that \\(PV\\) is also proportional to the number of particles \\(N\\) in the gas, \\(PV \\propto N\\). We can write the full ideal gas law in the form \\[\n\\boxed{PV = Nk_B T} \\ ,\n\\] where \\(k_B\\) is a proportionality constant, called the Boltzmann constant. Its value is measured to be \\[\n\\boxed{k_B = 1.381 \\cdot 10^{-23} \\frac{\\text{J}}{\\degree \\text{K}} \\approx \\frac{1}{40} \\frac{\\text{eV}}{\\degree \\text{K}}} \\ .\n\\]",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Thermodynamics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/thermodynamics.html#first-law",
    "href": "statistical-mechanics/thermodynamics.html#first-law",
    "title": "Thermodynamics",
    "section": "First Law",
    "text": "First Law\nIn classical mechanics the conservation of energy is a fundamental principle of a microscopic system. We’d like to extend this idea to thermodynamics as well. Observations indicate that a similar principle operates at the level of macroscopic systems provided that the system is properly insulated, that is, when the only sources of energy are of mechanical origin.\n\nWork, Energy, Heat\nSuppose a thermodynamic system \\(A\\) is adiabatically isolated from its environment. If such a system is changed by some amount of work \\(\\Delta W\\), then the amount of work is only dependent on its initial and final state. That is, if \\(a_i=(A_{1,i}, \\cdots, A_{n,i})\\) is the initial state and \\(a_f=(A_{1,f}, \\cdots, A_{n,f})\\), then \\[\n\\Delta W = \\Delta E = E(a_f) - E(a_i),\n\\] where \\(E = E(a)\\) is some scalar function of state called the internal energy of the system. It’s the total energy of the system \\(A\\) when it’s adiabatically isolated.\nHaving a system be adiabatically isolated is a strong assumption that we’d like to relax, but doing so then means the system can exchange energy with its environment, which means \\(\\Delta W \\neq \\Delta E\\). There’s a flow of energy \\(\\Delta Q\\) in and out of the system now, called the heat. It’s the heat plus the work that’s conserved, \\[\n\\Delta E = \\Delta Q + \\Delta W.\n\\] This experimental fact is called the first law of thermodynamics. We assume this quantity called heat exists in such a fashion that the internal energy stays conserved. It’s not a theorem.\nAside: Note the work \\(\\Delta W\\) is done on the system, not by the system. Many engineering texts adopt the opposite convention, where they like to think of work being done by the system (e.g. by an engine). In that case, the \\(\\Delta W\\) would change its sign, in which case we’d write \\(\\Delta E = \\Delta Q - \\Delta W\\).\nSince thermodynamic state variables only make sense when a system is in equilibrium, if we want to think about the first law in differential form we have to imagine we can change the system differentially in such a way that it stays in equilibrium. Doing so is called a quasi-static process. We vary the system very slowly from its initial to its final state, allowing the system to come to equilibrium again at each point. This allows us to fill in the path continuously with points so we can then talk about differential changes.\nIn differential form, the first law of thermodynamics has the form \\[\n\\boxed{dE = \\delta Q + \\delta W} \\ .\n\\] The notation \\(\\delta Q\\) and \\(\\delta W\\) is used to make it explicit that those variables are path dependent. That is, they’re not a function of only the initial and final states. This means we can’t integrate them directly to get the total heat or work done. However, the energy is a state variable, it is a function only of its end points, and so we can integrate \\(dE\\) to get the total internal energy \\(\\Delta E\\), \\[\n\\Delta E = \\int dE = \\int (\\delta Q + \\delta W).\n\\]\n\n\nTypes of Work\nThe work done on the system is inherently mechanical in that it’s a sum of forces times displacements. Since we want to imagine generalized forces and generalized displacements, we’ll write it in the notation \\[\n\\delta W = \\sum_i J_i d X_i,\n\\] where \\(J_i\\) is a generalized force conjugate to some generalized displacement variable \\(X_i\\). Here are some of the most common conjugate force-displacement pairs:\n\n\n\n\n\n\n\n\nSystem\nGeneralized Force: \\(J\\)\nGeneralized Displacement: \\(X\\)\n\n\n\n\nWire\nTension: \\(F\\)\nLength: \\(L\\)\n\n\nFilm\nSurface Tension: \\(\\sigma\\)\nArea: \\(A\\)\n\n\nFluid\nPressure: \\(-P\\)\nVolume: \\(V\\)\n\n\nMagnet\nMagnetic Field: \\(B\\)\nMagnetization: \\(M\\)\n\n\nDielectric\nElectric Field: \\(E\\)\nPolarization: \\(P\\)\n\n\nChemical Reaction\nChemical Potential: \\(\\mu\\)\nParticle Number: \\(N\\)\n\n\n\nThe generalized forces have the property that their values are independent of the size of the system. Doubling the size of the system doesn’t double the forces acting on it. These are called intensive variables. Conversely, the generalized displacements are directly proportional to the size of the system. If the system’s size is doubled, so too are the displacements. These are called extensive variables. Intensive and extensive variables always tend to occur in conjugate pairs like this.\nUsing the new notation, we can re-write the work in the form \\[\n\\delta W = \\sum_{i=1}^k J_i dX_i.\n\\] For reasons we’ll get into soon, it’s also convenient to break up the work component into non-chemical and chemical work components. If we explicitly split off the chemical work terms, we’d instead write \\[\n\\delta W = \\sum_{i=1}^n J_i dX_i + \\sum_{j=1}^m \\mu_i dN_i.\n\\] Of course, we still don’t know how to simplify \\(\\delta Q\\) into a useful form. We’ll deal with that soon. For simplicity, in the rest of this section we’ll express things in vector notation by letting \\(J, dX, \\mu, dN\\) represent the vectorized forms of their component terms. Then we can just write the total work as just \\[\n\\delta W = J \\cdot dX + \\mu \\cdot dN.\n\\]\n\n\nHeat Capacities\nSuppose we pump some amount of heat \\(\\delta Q\\) into the system. Provided heat is a function of temperature, we’d have \\(\\Delta Q = C \\Delta T\\), where \\(C = C(T)\\) is some function of temperature, called the heat capacity. The functional form of \\(C\\) depends on the nature of the system. Evidently, the heat capacity is given by \\[\n\\boxed{C(T) \\equiv \\frac{\\delta Q}{dT}} \\ .\n\\] Since heat is path dependent, the heat capacity must be too. If \\(\\gamma\\) is some path taken to get from the initial to the final point in state space, then we might write \\(C = C_\\gamma\\) to be explicit about this. The most important case is when we’re dealing with a gas. If a gas is only has work done \\(\\delta W = -PdV\\), then we can think of the gas as only being a function of two state variables, \\(P\\) and \\(V\\). Two paths of interest in \\(pV\\)-space are paths of constant \\(P\\) or \\(V\\). Using the first law, the heat capacity \\(C_V\\) at constant volume is evidently \\[\nC_V = \\frac{\\delta Q_V}{dT} = \\frac{dE + PdV}{dT} \\bigg |_V = \\frac{\\partial E}{\\partial T}\\bigg |_V.\n\\] Similarly, the heat capacity \\(C_P\\) at constant pressure is evidently \\[\nC_P = \\frac{\\delta Q_P}{dT} = \\frac{dE + PdV}{dT} \\bigg |_P =  \\frac{\\partial E}{\\partial T}\\bigg |_P + P \\frac{\\partial V}{\\partial T} \\bigg |_P.\n\\] It turns out that the two \\(\\frac{\\partial E}{\\partial T}\\) derivatives are the same. This follows empirically from the Joule Free Expansion Experiment. Suppose we have two chambers connected by a thin hole that’s initially closed. Initially, all the gas is in the left chamber at an equilibrium temperature \\(T\\). Suppose the hole is then suddenly opened, allowing the gas to adiabatically expand into the right chamber.\n\n\n\n\n\nSince the gas isn’t pushing on anything, it can’t do any work. Since the process is adiabatic, no heat is flowing either. This means the total energy isn’t changing either. Once the system has settle down to equilibrium, the temperature in the two chambers must be the same. This evidently implies the energy must be a function of temperature alone, i.e. \\[\nE = E(T) = E(PV).\n\\] Using this fact, for an ideal gas we can evidently write \\[\nC_p - C_V = P \\frac{\\partial V}{\\partial T} \\bigg |_P.\n\\] Since \\(V = \\frac{Nk_B T}{P}\\), this reduces to just \\[\nC_P - C_V = N k_B.\n\\] It turns out that in fact \\(E \\propto PV\\). This result is called the equipartition theorem. It must be taken as an empirical law in thermodynamics, but it can be proven with statistical mechanics. The equipartition theorem says that an ideal gas whose individual particles each have \\(n\\) degrees of freedom will have a total energy given by \\[\n\\boxed{E = \\frac{n}{2} Nk_B T = \\frac{n}{2} PV} \\ .\n\\] For example, a monoatomic gas is a gas whose particles only have \\(n=3\\) translational degree of freedom. In that case, we’d have \\(E = \\frac{3}{2} PV\\). A diatomic gas is a gas whose particles also have two rotational degrees of freedom plus one vibrational degree of freedom, giving \\(n=7\\) total degrees of freedom, and \\(E = \\frac{7}{2} PV\\).\nUsing the equipartition theorem, we can find the heat capacity of an ideal gas directly. Since \\[\n\\frac{d E}{d T} = \\frac{n}{2} Nk_B,\n\\] we evidently have \\[\nC_V = \\frac{n}{2} Nk_B, \\quad C_P = \\bigg(\\frac{n}{2}+1\\bigg) Nk_B.\n\\] Notice that these heat capacities are extensive since they’re both proportional to \\(N\\). In practice we’re interested in an intensive measure of how responsive heat is to changes in temperature. We can achieve this by dividing by \\(N\\) to get a specific heat. More commonly, specific heats are measured per unit mass, not per particle. If the system has mass \\(m\\), its specific heat capacity is defined by \\(c \\equiv \\frac{C}{m}\\).\nUsually it’s the specific heats that are tabulated for various substances. We’d need to look them up to do any kind of numerical calculations. The most useful specific heat to remember is the specific heat of water at standard temperature and pressure or STP, i.e. when \\(P \\approx 1 \\text{ atm}, T \\approx 300 \\ \\degree K\\). In energy units of calories, the specific heat of water at STP is just \\(c_P = 1 \\ \\frac{\\mathrm{cal}}{\\mathrm{g} \\mathrm{\\degree K}}\\). Note that the specific heat does depend on the phase of a substance. For example, ice has a specific heat of \\(c_P = 0.5 \\ \\frac{\\mathrm{cal}}{\\mathrm{g} \\mathrm{\\degree K}}\\).\nAnother important quantity that’s similar to the specific heat is the latent heat. It’s an intensive measure of how much heat is needed for a system to fully undergo a phase change. The most common definition is the change in heat per unit mass, \\[\n\\boxed{L \\equiv \\frac{\\Delta Q}{m}} \\ .\n\\] In general, latent heat values will be different than the specific heat values. They’ll also be different for different phase changes. For example, the latent heat of melting ice is \\(L = 80 \\ \\frac{\\text{cal}}{g}\\), while the latent heat of boiling water is \\(L = 540 \\ \\frac{\\text{cal}}{g}\\). Again, we’d look these up in tables when we need them.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Thermodynamics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/thermodynamics.html#second-law",
    "href": "statistical-mechanics/thermodynamics.html#second-law",
    "title": "Thermodynamics",
    "section": "Second Law",
    "text": "Second Law\nWe saw that were able to break the work \\(\\delta W\\) up into a sum of generalized force-displacement pairs as \\(\\delta W = \\sum J_i dX_i\\). We’d like to be able to break up the heat \\(\\delta Q\\) somehow. It’s reasonable to assume that \\(T\\) is the generalized force for heat, but what is the generalized displacement? This leads us to the second law and the concept of entropy.\n\nEngines\nThe second law of thermodynamics arose historically out of an interest among engineers in converting back and forth between heat and mechanical work. A device that converts heat into mechanical work is called an engine. A device that converts mechanical work into heat is called a heat pump or a refrigerator (the difference between the two being whether we want to pump heat into or out of a system).\nSuppose an engine takes in heat \\(Q_H\\) from a heat reservoir, outputs some amount of work \\(W\\), and dumps any remaining output heat \\(Q_C\\) into a cold reservoir. By the first law, \\(Q_H = Q_C + W\\). Define the efficiency \\(\\eta\\) of the engine as the ratio of work extracted to the total amount of heat put in, \\[\n\\boxed{\\eta \\equiv \\frac{W}{Q_H}} \\ .\n\\] Since \\(W = Q_H - Q_C\\), we can also write the efficiency as \\[\n\\eta = 1 - \\frac{Q_C}{Q_H}.\n\\] Since we must have \\(Q_C \\leq Q_H\\) by the first law, this means \\(0 \\leq \\eta \\leq 1\\) generally speaking. A perfectly efficient engine would convert all heat into work, in which case \\(\\eta = 1\\).\nWe can define a similar measure of efficiency for a heat pump or a refrigerator. In that case, we’re interested in how much heat we can extract per unit work put in. This measure is called the coefficient of performance \\(\\omega\\), given by \\(\\omega_{fr} \\equiv \\frac{Q_C}{W}\\) for a refrigerator, and \\(\\omega_{hp} \\equiv \\frac{Q_H}{W}\\) for a heat pump. Again using the fact that \\(Q_H = Q_C + W\\), it’s easy to show that \\(\\omega_{fr} \\geq 1\\) and \\(0 \\leq \\omega_{hp} \\leq 1\\).\nHere’s a diagram showing the difference between an engine and a refrigerator. Notice that the refrigerator is just an engine with the arrows reversed. We’ll exploit this fact a good bit shortly.\n\n\n\n\n\n\n\nStatement of Second Law\nThe second law of thermodynamics can be stated in several ways that are all equivalent. I’ll state it first using the definition given by Kelvin, and then use that to prove it’s equivalent to a different statement made by Clausius.\nSecond Law (Kelvin): No thermodynamic process is possible whose sole result is the complete conversion of heat to work or work to heat. Equivalently, there is no ideal engine with efficiency \\(\\eta = 1\\).\nSecond Law (Clausius): No thermodynamic process is possible whose sole result is the transfer of heat from a colder body to a hotter body. Equivalently, there is no ideal refrigerator with performance \\(\\omega = \\infty\\).\nProof: We’ll prove these are equivalent by showing if Kelvin is false, then so is Clausius, and vice versa.\n\nIf Kelvin is false, so is Clausius: If Kelvin is false, then there exists an engine with that outputs heat \\(Q\\) to work \\(W\\) with 100% efficiency. We can use this \\(W\\) to then power a refrigerator. Suppose the refrigerator pumps heat \\(Q_C\\) from a cold reservoir to a new heat \\(Q_H\\) that dumps into the same hot reservoir as the engine. Then on net we have a system that pumps in a heat \\(Q_C\\) and pumps out a heat \\(Q_H-Q\\). That is, we’ve built a refrigerator that pumps heat from a cold body to a warm body, violating Clausius. \\(\\text{Q.E.D.}\\)\n\n\n\n\n\nIf Clausius is false, so is Kelvin: If Clausius is false, then it’s possible to build a heat pump to pump heat from a cold reservoir to a hot reservoir with no input work required. Let’s hook an engine up to the same reservoir, taking an input heat \\(Q_H\\) from the hot reservoir and converting it to some combination of work \\(W\\) and output heat \\(Q_C\\). Then on net we have a system that takes in heat \\(Q_H-Q\\) and converts it purely into work, i.e. \\(W = Q_H - Q\\), which violates Kelvin. \\(\\text{Q.E.D.}\\)\n\n\n\n\n\n\n\n\nCarnot Engines\nIf we can’t have an engine with perfect efficiency, what’s the highest possible efficiency we can possibly have? As we’ll soon prove, the highest efficiency engine is a Carnot engine. A Carnot engine is defined to be any engine that’s reversible, runs in a cycle, and whose reservoir temperatures are held fixed, with the hot reservoir at \\(T_H\\) and the cold reservoir at \\(T_C\\).\n\n\n\n\n\nA thermodynamic process is called reversible if it can be run backward in time by simply reversing the inputs and outputs. It’s the thermodynamic equivalent of frictionless motion in classical mechanics. Since reversibility implies the system stays in equilibrium, reversible processes must be quasi-static. However, not all quasi-static processes need be reversible. Any process that dissipates energy to its environment, even if done quasi-statically, is not reversible.\nTheorem: Of all engines operating between two reservoir temperatures \\(T_H\\) and \\(T_C\\), the Carnot engine is the most efficient.\nProof: Suppose we had some arbitrary non-Carnot engine with efficiency \\(\\eta\\) that takes in heat \\(Q_H'\\) from the hot reservoir, generates work \\(W\\), and dumps the remaining heat \\(Q_C'\\) into the cold reservoir. Using the same trick, hook a reversed Carnot engine (i.e. a Carnot refrigerator) up to take in the output work \\(W\\) and use it to pump heat \\(Q_C\\) from the cold reservoir to a heat \\(Q_H\\) in the hot reservoir. On net, this gives a cycle that takes in heat \\(Q_H'-Q_H\\) and converts it to heat \\(Q_C'-Q_C\\) .\n\n\n\n\n\nBut by the second law, we must have \\(Q_H'-Q_H \\geq Q_C'-Q_C\\). Dividing both sides by \\(W\\) and reorganizing, we get \\[\n\\eta = \\frac{W}{Q_H'} \\leq \\frac{W}{Q_H} = \\eta_{carnot}.\n\\] That is, the Carnot engine is more efficient. \\(Q.E.D.\\)\nCorollary: All Carnot engines between \\(T_H\\) and \\(T_C\\) have the same efficiency.\nProof: Follow the previous proof, but this time hook up another Carnot engine to the Carnot refrigerator to get \\(\\eta = \\eta_{carnot}\\). \\(Q.E.D.\\)\nWe can use the Carnot engine to construct yet another temperature scale, except this time we can do it without reference to any material properties at all. This is called the thermodynamic temperature scale. What we can do is hook two Carnot engines up in series as follows. Suppose a Carnot engine \\(CE_1\\) takes heat from \\(T_1\\) to \\(T_2\\), and Carnot engine \\(CE_2\\) takes heat from \\(T_2\\) to \\(T_3\\). We can also think of the whole thing as a single Carnot engine \\(CE\\) that takes heat from \\(T_1\\) to \\(T_3\\).\n\n\n\n\n\nNow, if we look at the heat output for each engine, we have \\[\n\\begin{align*}\nCE_1: Q_2 &= Q_1 - W_{12} = Q_1(1 - \\eta_{12}), \\\\\nCE_2: Q_3 &= Q_2 - W_{23} = Q_2(1 - \\eta_{23}), \\\\\nCE: Q_3 &= Q_1 - W_{13} = Q_1(1 - \\eta_{13}). \\\\\n\\end{align*}\n\\] We can equate both terms for \\(Q_3\\) and simplify to get \\[\n1 - \\eta_{13} = (1 - \\eta_{12})(1 - \\eta_{23}).\n\\] Now, if we divide both sides by \\(1 - \\eta_{23}\\) we get \\[\n1 - \\eta_{12} = \\frac{Q_2}{Q_1} = \\frac{f(T_1)}{f(T_2)}.\n\\] The system must satisfy this constraint for any function \\(f(T)\\) we choose. We might as well just choose \\(f(T) \\equiv T\\), in which case we get \\[\n\\eta_{12} = 1 - \\frac{T_2}{T_1}.\n\\] That is, any Carnot engine between \\(T_H\\) and \\(T_C\\) must have a Carnot efficiency given by \\[\n\\boxed{\\eta_c \\equiv 1 - \\frac{T_C}{T_H}} \\ .\n\\] Notice that since \\(T_C &lt; T_H\\), the Carnot efficiency can never be \\(1\\). For reasonable temperature ranges, say from freezing to boiling at STP, we’d have \\(\\eta_c \\approx 0.268\\). That’s under 27% efficiency! In fact, the Carnot engine, while the best we can do efficiency-wise, it’s not practical for real engines. One major reason for this is that isothermal processes are really slow, meaning it takes too impractically long to complete a single cycle.\nSince the Carnot efficiency \\(\\eta_c\\) between two temperatures is fixed, we can use it to define a temperature scale provided we fix a base temperature \\(T_0\\). We can define the temperature \\(T\\) as the value that gives a Carnot efficiency \\(\\eta_c\\) between \\(T\\) and \\(T_0\\). That is, \\[\nT \\equiv T_0 (1 - \\eta_c).\n\\] The thermodynamic definition also implies that temperature \\(T\\) must be positive. If we had \\(T &lt; 0\\), then an engine operating between it and a positive temperature could extract heat from both reservoirs and convert the sum total to work, in violating of the second law.\n\nExample: Carnot Cycle of an Ideal Gas\nTo make the topic somewhat more concrete, suppose we have an ideal gas inside a piston, consisting of a single type of molecule with no exchange of particles taking place. Then the only work being done is the work done by the piston to change the volume \\(V\\) and pressure \\(P\\) of the gas. Then by the first law, \\[\ndE = \\delta Q + \\delta W = \\delta Q - PdV.\n\\] This means the state variables are \\((P, V)\\). In \\(PV\\)-space, the Carnot engine will be a cycle consisting of two isotherms at \\(T_H\\) and \\(T_C\\) that are connected by curves where \\(\\delta Q = 0\\), called adiabatics.\nSuppose a cycle starts on the upper left point, say \\((P_A, V_A)\\). It expands isothermally to \\((P_B, V_B)\\), then adiabatically expands to \\((P_C, V_C)\\), then isothermally compresses to \\((P_D, V_D)\\), before finally adiabatically compressing back to \\((P_A, V_A)\\).\n\n\n\n\n\nAlong the isotherms, the ideal gas law says the curves must be hyperbolas, \\[\nPV = N k_B T_H, \\quad PV = N k_B T_C.\n\\] Along the adiabatics, the condition \\(\\delta Q = 0\\) along with the equipartition theorem implies \\[\ndE = \\frac{n}{2} d(PV) = -PdV \\quad \\Longrightarrow \\quad \\bigg(\\frac{n}{2}+1\\bigg) PdV = -\\frac{n}{2} VdP.\n\\] This is a differential equation for \\(P(V)\\). Using separation of variables on both sides gives \\[\nPV^\\gamma = P_0 V_0^\\gamma = const, \\quad \\text{where} \\quad \\gamma \\equiv \\frac{2}{n}\\bigg(\\frac{n}{2}+1\\bigg).\n\\] For example, with a monoatomic gas we’d have \\(\\gamma = \\frac{5}{3}\\), so the adiabatics are \\(PV^{5/3} = const\\). For the two adiabatic curves in the cycle, taking \\((P_0, V_0)\\) to be the two initial points along the curves gives \\[\nPV^\\gamma = P_B V_B^\\gamma, \\quad PV^\\gamma = P_D V_D^\\gamma.\n\\] Note that since the Carnot cycle is reversible, the total work done during a full cycle is zero.\n\n\n\nEntropy\nWe’re finally ready to construct the state function that’s conjugate to temperature. Let’s look again at the previous theorem that said \\(\\eta \\leq \\eta_c\\) for any engine between \\(T_H\\) and \\(T_C\\). We can rewrite this inequality in the form \\[\n\\frac{W}{Q_H} = 1 - \\frac{Q_C}{Q_H} \\leq 1 - \\frac{T_C}{T_H}.\n\\] Rearranging both sides, we get \\[\n\\frac{Q_H}{T_H} - \\frac{Q_C}{T_C} \\leq 0.\n\\] What’s interesting to notice here is that the quantity \\(\\frac{Q}{T}\\), whatever it is, depends only on the initial and final points. That is, it’s a state function. In fact, the above statement is extremely general.\nClausius’ Theorem: For any cyclic process (not necessarily quasi-static), if \\(\\delta Q\\) is an increment of heat delivered to a system at some temperature \\(T\\), then the sum total ratio of heat to temperature across the entire cycle is negative, i.e. \\[\n\\boxed{\\oint \\frac{\\delta Q}{T} \\leq 0} \\ .\n\\] Proof: What we’ll do is imagine pumping a heat increment \\(\\delta Q\\) into the system by hook a Carnot engine with hot reservoir temperature \\(T_0\\) , which takes input heat \\(\\delta Q_0\\) and uses that to generate some amount of work \\(\\delta W\\), expelling the remaining heat into the system as \\(\\delta Q\\) at a cold reservoir temperature \\(T\\).\n\n\n\n\n\nNow, since the engine is a Carnot engine, we have \\[\n1 - \\eta = \\frac{\\delta Q}{\\delta Q_0} = \\frac{T}{T_0} \\quad \\Longrightarrow \\quad \\delta Q_0 = T_0 \\frac{\\delta Q}{T}.\n\\] At the end of a full cycle, the net effect of the combined process is the extraction of heat \\(Q_0 = \\oint \\delta Q_0\\) from the hot reservoir, which is converted purely to external work \\(W = \\oint \\delta W\\). The total work \\(W\\) is the sum of the work done by the engine and the work done by the system. Now, by the second law, we must have \\(Q_0 = W \\leq 0\\), i.e. \\[\nQ_0 = T_0 \\oint \\frac{\\delta Q}{T} \\leq 0 \\quad \\Longrightarrow \\quad \\oint \\frac{\\delta Q}{T} \\leq 0. \\quad \\text{Q.E.D.}\n\\] Corollary: For a reversible process, we must have exact equality, i.e. \\[\n\\oint \\frac{\\delta Q_{rev}}{T} = 0.\n\\] Proof: This is easy to see. If we run the process forward we get \\(\\frac{\\delta Q_{rev}}{T} \\leq 0\\). By reversibility though, we can also run the process backwards, in which case \\(\\delta Q_{rev} \\rightarrow -\\delta Q_{rev}\\), and so \\(\\frac{\\delta Q_{rev}}{T} \\geq 0\\). This implies the integral between any two points \\(A\\) and \\(B\\) must be path independent, since for any two paths \\(\\mathcal{C}\\) and \\(\\mathcal{C}'\\), we have \\[\n\\int_A^B \\frac{\\delta Q_{rev}^{{\\mathcal{C}}}}{T_{{\\mathcal{C}}}} + \\int_B^A \\frac{\\delta Q_{rev}^{{\\mathcal{C}'}}}{T_{{\\mathcal{C}'}}} = 0 \\quad \\Longrightarrow \\quad \\oint \\frac{\\delta Q_{rev}}{T} = 0. \\quad \\text{Q.E.D.}\n\\] This corollary implies the existence a state function \\(S\\), defined by the path integral \\[\n\\boxed{\\Delta S \\equiv \\int_A^B \\frac{\\delta Q_{rev}}{T}} \\ .\n\\] This state function is called the entropy of the system. Since \\(\\delta Q_{rev} = TdS\\), we’ve finally found the conjugate variable to temperature . It’s just the entropy. Plugging this into the first law, we finally have that for any quasi-static, reversible process in equilibrium, \\[\n\\boxed{dE = TdS + J \\cdot dX + \\mu \\cdot dN} \\ .\n\\] This formula is without doubt the most useful identity in thermodynamics. Notice that this implies that we only need \\(n+m+1\\) total quantities to completely specify the state of the system. We can obtain the rest by partial differentiation. Assuming the mechanical displacements are independent, we have \\[\nT = \\frac{\\partial E}{\\partial S} \\bigg |_{X,N} \\ , \\quad J_i = \\frac{\\partial E}{\\partial X_i} \\bigg |_{S, \\ \\{X_k: \\ k \\neq i\\}, \\ N} \\ , \\quad \\mu_j = \\frac{\\partial E}{\\partial X_i} \\bigg |_{S, \\ X, \\ \\{N_k: \\ k \\neq j\\}} \\ .\n\\] Corollary: For an irreversible process, we have the inequality \\[\n\\int_A^B \\frac{\\delta Q}{T} \\leq \\Delta S.\n\\] Proof: This proof is similar to the previous corollary. What we’ll do is close the cycle by taking a reversible process backwards, which by Clausius’ theorem gives \\[\n\\int_A^B \\frac{\\delta Q}{T} + \\int_B^A \\frac{\\delta Q_{rev}}{T} \\leq 0. \\quad \\text{Q.E.D.}\n\\] In differential form, this corollary implies that \\(dS \\geq \\frac{\\delta Q}{T}\\) for any transformation. Suppose we take some number of adiabatically isolated systems each in equilibrium and bring them all together to thermally interact. Such a system is called a closed system, in that the subsystems are allowed to interact thermally, but not exchange matter. Once the joint system has settled down to equilibrium, the total heat must still be \\(\\delta Q = 0\\), which means that \\(\\delta S \\geq 0\\).\nThis result implies that the net adiabatic system attains its maximum entropy at equilibrium, since any spontaneous change can only act to further increase \\(S\\). This implies that the second law is not time reversible. The direction of increasing entropy points out the arrow of time in its path to equilibrium.\nAnalogy: Compare the statement that entropy increases up to thermal equilibrium with a mechanical statement. Suppose we drop an object some distance above the Earth’s surface, allowing it to free fall under gravity. As the object falls, it will only settle down once it’s reached its mechanical equilibrium, when the total forces are zero. This happens when the potential energy is minimized. In this sense, the statement that entropy increases is no more mysterious than the observation that objects tend to fall downwards under gravity so as to minimize their potential energy.\n\nExample: Entropy of a Monatomic Ideal Gas\nSuppose we have a monatomic ideal gas in a closed system with work \\(\\delta W = -PdV\\). Then \\[\ndE = TdS - PdV.\n\\] What is the change \\(\\Delta S\\) in the entropy along any path in \\(PV\\)-space?\nSolving for \\(dS\\) and using the fact that \\(dE = \\frac{3}{2} Nk_B dT\\) gives \\[\ndS = \\frac{1}{T}dE - \\frac{P}{T} dV = Nk_B \\bigg[\\frac{3}{2} \\frac{dT}{T} + \\frac{dV}{V} \\bigg].\n\\] Integrating both sides and simplifying terms, we finally have \\[\n\\Delta S = Nk_B \\bigg[\\frac{3}{2} \\log \\frac{T}{T_0} + \\log \\frac{V}{V_0} \\bigg] = Nk_B \\log\\bigg[ \\frac{V}{V_0} \\bigg(\\frac{T}{T_0}\\bigg)^{3/2} \\bigg].\n\\] It’s interesting to note from this formula that the entropy is extensive since it depends linearly on \\(N\\). It also seems to increase logarithmically with the volume and the temperature. Since \\(k_B\\) has units of energy over temperature, so too does the entropy.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Thermodynamics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/thermodynamics.html#thermodynamic-potentials",
    "href": "statistical-mechanics/thermodynamics.html#thermodynamic-potentials",
    "title": "Thermodynamics",
    "section": "Thermodynamic Potentials",
    "text": "Thermodynamic Potentials\nLet’s look more closely again at the differential of the energy. We have \\[\ndE = TdS + J \\cdot dX + \\mu \\cdot dN.\n\\] This differential implies that \\(E = E(S, X, N)\\) explicitly, with \\(T, J, \\mu\\) determined implicitly by partial differentiation. Suppose, however, that we wanted the energy as an explicit function of other variables instead. For example, it may be easier to control the temperature or pressure of a gas in the lab than entropy or volume. We can go back and forth between conjugate pairs using Legendre transformations.\nSuppose we have some function \\(f(x, y)\\). Suppose \\(x\\) is conjugate to another variable \\(p\\) in the sense that \\[\ndf = pdx + vdy.\n\\] Notice if we add and subtract \\(xdp\\) to both sides and rearrange, we get a new differential of the form \\[\ndg \\equiv d(f-px) = -xdp + vdy.\n\\] This evidently defines a new function \\(g(p,y) = f(x,y) - px\\) that’s now an explicit function of \\(p\\) and \\(y\\). This new function is called a Legendre transformation of \\(f(x,y)\\). We created a new dual function by swapping \\(x\\) with its conjugate variable \\(p\\). This dual function is completely equivalent in content to the original function since we can always go back and forth between the two via the same kind of transformation.\nWe can apply the Legendre transformation to the energy \\(E=E(S,J,N)\\) to get the energy as a function of the other state variables. The only thing is that these new functions won’t be the original energy exactly, but rather shifted versions of the energy called thermodynamic potentials. In total there are four valid thermodynamic potentials other than the energy: enthalpy, Helmholtz free energy, Gibbs free energy, and the grand potential. Note that all of these potentials still have units of energy.\n\nEnthalpy\nSuppose we wanted to swap \\(J\\) with \\(X\\) to express the energy as a function \\(H = H(S, X, N)\\). We can figure out the form of \\(H\\) by doing a Legendre transformation between \\(J\\) and \\(X\\). Adding \\(X \\cdot dJ\\) to both sides of the first law and rearranging gives \\[\ndH = d(E - J \\cdot X) = TdS - X \\cdot dJ + \\mu \\cdot dN.\n\\] That is, the equation for \\(H\\) is evidently \\[\n\\boxed{H \\equiv E - J \\cdot X} \\ .\n\\] This function is called the enthalpy. We can think of it as a form of energy where the mechanical work gets subtracted out. When dealing with a gas, we’d have \\(J \\cdot dX = -PdV\\), in which case the enthalpy would be \\[\nH = E + pV.\n\\] The enthalpy is perhaps most useful when dealing with adiabatic systems. In that case, \\(\\delta Q = 0\\) means the enthalpy is just the work done, i.e. \\(dH = -X \\cdot dJ + \\mu \\cdot dN\\). Adiabatic processes tend to happen very quickly, like the combustion of gas in a cylinder.\n\n\nHelmholtz Free Energy\nSuppose now we wanted to instead swap \\(T\\) with \\(S\\) to get a function \\(F = F(T, X, N)\\). If we add and subtract \\(SdT\\) to both sides of \\(dE\\) and rearrange, we get \\[\ndF = -SdT + J \\cdot dX + \\mu \\cdot dN.\n\\] The function \\(F\\) is called the Helmholtz free energy, evidently given by \\[\n\\boxed{F = E - TS} \\ .\n\\] We can think of the Helmholtz free energy as a kind of energy in which the heat has been subtracted out of the system. The Helmholtz free energy is perhaps most useful when dealing with isothermal processes, in which case \\(dF\\) reduces to just \\(dF = J \\cdot dX + \\mu \\cdot dN\\). Isothermal processes happen very slowly, so slowly they’re impractical for real-world engines.\n\n\nGibbs Free Energy\nSuppose now we wanted to swap both \\(q\\) with \\(J\\) as well as \\(T\\) with \\(S\\) to get a function \\(G = G(T, J, N)\\). If we start with the enthalpy \\(dH\\) and add and subtract \\(SdT\\) to both sides and rearrange, we get \\[\ndG = d(H - TS) = -SdT - X \\cdot dJ + \\mu \\cdot dN.\n\\] The function \\(G\\) is called the Gibbs free energy, evidently given by \\[\n\\boxed{G = H - TS = E - TS - J \\cdot X} \\ .\n\\] We can think of the Gibbs free energy as a kind of energy in which both the mechanical work done as well as the heat have been subtracted out of the system. When dealing with a gas, \\(G\\) takes the form \\[\nG = E - TS + PV.\n\\] The Helmholtz free energy is perhaps most useful when dealing with processes that take place at fixed temperature and pressure, e.g. processes that take place at STP. These often include, for example, biological processes, like the thermodynamics in and around a cell.\n\n\nGrand Potential\nSo far we haven’t touched the chemical work terms at all. Suppose now though that we want a kind of Gibbs free energy that swaps \\(\\mu\\) with \\(N\\) instead of \\(J\\) with \\(X\\) to get a function \\(\\mathcal{G} = \\mathcal{G}(T,X,\\mu)\\). If we this time start with the Helmholtz free energy and add and subtract \\(N \\cdot d\\mu\\) to both sides and re-arrange, we get \\[\nd\\mathcal{G} = d(F - \\mu \\cdot N) = -SdT + J \\cdot dX - N \\cdot d\\mu.\n\\] This function \\(\\mathcal{G}\\) is called the grand potential, evidently given by \\[\n\\boxed{\\mathcal{G} = F - \\mu \\cdot N = E - TS - \\mu \\cdot N} \\ .\n\\] We can think of the grand potential as a kind of energy in which both the heat and the chemical work have been subtracted out of the system.\n\n\nExtensivity\nIf you look carefully, you’ll see that all of the thermodynamic potentials we defined are a function of at least one extensive variable. It’s fair to ask why we didn’t consider a potential function of all the intensive variables, i.e. some \\(L = L(T,J,\\mu)\\). The reason for this has to do with a mathematical relationship known as extensivity. We say a system is extensive if its energy satisfies the property of homogeneity. That is, for any scalar \\(\\lambda\\), we must have \\[\nE(\\lambda S, \\lambda X, \\lambda N) = \\lambda E(S, X, N).\n\\] Note that extensivity is not a required property of every thermodynamic system. It doesn’t follows from the laws of thermodynamics. It’s in fact an extra constraint that’s satisfied by most systems of real world interest. One example of a system that’s not extensive is a star where gravitational work is being done.\nWe can derive a useful relationship by differentiating both sides of this definition with respect to \\(\\lambda\\), \\[\n\\begin{align*}\n\\frac{\\partial}{\\partial\\lambda} \\lambda E(S, X, N) &= \\frac{\\partial}{\\partial\\lambda} E(\\lambda S, \\lambda X, \\lambda N), \\\\\n\\Longrightarrow E(S, X, N) &= \\frac{\\partial E}{\\partial S} \\bigg |_{X,N} S + \\frac{\\partial E}{\\partial X} \\bigg |_{S,N} \\cdot X + \\frac{\\partial E}{\\partial N} \\bigg |_{S,X} \\cdot N, \\\\\n\\Longrightarrow E(S, X, N) &= TS + J \\cdot X + \\mu \\cdot N. \\\\\n\\end{align*}\n\\] That is, for an extensive system, the energy is just given directly by \\[\n\\boxed{E = TS + J \\cdot X + \\mu \\cdot N} \\ .\n\\] If we take the differential of both sides and apply the first law, we get \\[\n\\begin{align*}\ndE &= d(TS) + d(J \\cdot X) + d(\\mu \\cdot N) \\\\\n&= (TdS + J \\cdot dX + \\mu \\cdot dN) + (SdT + X \\cdot dJ + N \\cdot d\\mu) \\\\\n&= TdS + J \\cdot dX + \\mu \\cdot dN. \\\\\n\\end{align*}\n\\] This means the second term must be zero for an extensive system, \\[\n\\boxed{SdT + X \\cdot dJ + N \\cdot d\\mu = 0} \\ .\n\\] This relation is called the Gibbs-Dunham relation. Notice it’s just the differential of a function \\(L = L(T,J,\\mu)\\) of the intensive variables. We’ve thus shown that no thermodynamic potential of the intensive variables alone can exist for an extensive system.\nExtensivity gives us a new constraint that we can often use to solve problems. Here’s an example.\nThe Gibbs free energy can be used to give a useful interpretation of the chemical potential \\(\\mu\\) of a gas. By extensivity, we must have \\[\nG = E - TS - J \\cdot X = \\mu N.\n\\] That is, the chemical potential of a gas can be thought of as the Gibbs free energy per particle. If there is a mixture of \\(m\\) types of particles in the gas, then \\(\\mu_i\\) is the Gibbs free energy per particle \\(i\\).\n\nExample: Chemical potential along isotherms\nSuppose we wanted to find \\(\\mu\\) for an ideal gas consisting of a single molecule. Since an ideal gas is extensive, along an isotherm we must have the simplified constraint \\[\n-VdP + N d\\mu = 0.\n\\] Now, by the ideal gas law, \\(\\frac{V}{N} = \\frac{k_B T}{P}\\). We can thus re-write this expression as \\[\nd\\mu = \\frac{k_B T}{P} dP.\n\\] Integrating both sides and solve for \\(\\mu\\), we finally have that along an isotherm \\[\n\\mu = \\mu_0 + k_B T \\log \\frac{P}{P_0}.\n\\] Evidently, the chemical potential is an increasing function of temperature, pressure, and volume.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Thermodynamics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/thermodynamics.html#maxwell-relations",
    "href": "statistical-mechanics/thermodynamics.html#maxwell-relations",
    "title": "Thermodynamics",
    "section": "Maxwell Relations",
    "text": "Maxwell Relations\nRecall from calculus that for any function with continuous second partial derivatives, the mixed second partial derivatives commute. For example, a function \\(z = f(x,y)\\) would have \\[\n\\frac{\\partial^2 z}{\\partial x \\partial y} = \\frac{\\partial^2 z}{\\partial y \\partial x}.\n\\] We generally assume that the state functions in thermodynamics are sufficiently smooth enough that their mixed partial derivatives all commute like this. This condition imposes another set of constraints on the potentials, which we can use to find interesting, non-trivial relationships between various state variables. They’re called the Maxwell relations. If \\(dE = TdS + J \\cdot dX + \\mu \\cdot dN\\), then there are in total 3 Maxwell relations per potential, which means there are \\(3 \\cdot 5 = 15\\) relations across all 5 potentials, though some of these are duplicates. Here are the differential forms of all 5 potentials again, \\[\n\\boxed{\n\\begin{align*}\ndE &= \\quad TdS + J \\cdot dX + \\mu \\cdot dN \\\\\ndH &= \\quad TdS - X \\cdot dJ + \\mu \\cdot dN \\\\\ndF &= \\;-SdT + J \\cdot dX + \\mu \\cdot dN \\\\\ndG &= \\;-SdT - X \\cdot dJ + \\mu \\cdot dN \\\\\nd\\mathcal{G} &= \\;-SdT + J \\cdot dX - N \\cdot d\\mu \\\\\n\\end{align*}\n} \\ .\n\\]\nIn the simple case of a closed system, we’d have \\(dN=0\\), which reduces the total number of relations to \\(1 \\cdot 4 = 4\\). Those 4 Maxwell relations are evidently \\[\n\\boxed{\n\\begin{align*}\n&\\frac{\\partial^2 E}{\\partial S \\partial X}& &=& &\\frac{\\partial T}{\\partial X} \\bigg |_{S,N}& &=& &\\frac{\\partial J}{\\partial S} \\bigg |_{X,N}& \\\\\n&\\frac{\\partial^2 H}{\\partial S \\partial J}& &=& -&\\frac{\\partial T}{\\partial J} \\bigg |_{S,N}& &=& &\\frac{\\partial X}{\\partial S} \\bigg |_{J,N}& \\\\\n&\\frac{\\partial^2 F}{\\partial T \\partial X}& &=& -&\\frac{\\partial S}{\\partial X} \\bigg |_{T,N}& &=& &\\frac{\\partial J}{\\partial T} \\bigg |_{X,N}& \\\\\n&\\frac{\\partial^2 G}{\\partial T \\partial J}& &=& &\\frac{\\partial S}{\\partial J} \\bigg |_{T,N}& &=& &\\frac{\\partial X}{\\partial T} \\bigg |_{J,N}& \\\\\n\\end{align*}\n} \\ .\n\\] Though the relations themselves are non-intuitive, the process for deriving them is straight forward. Suppose for example we wanted to find a Maxwell relation for \\[\n\\frac{\\partial \\mu}{\\partial P} \\bigg |_{T,N}.\n\\] To get a relation like this, we’d need a potential that’s an explicit function of \\(P, T, N\\). That’s of course the Gibbs free energy. In this case, we’d have \\[\n\\frac{\\partial \\mu}{\\partial P} \\bigg |_{T,N} = \\frac{\\partial}{\\partial P} \\bigg |_{T,N} \\frac{\\partial G}{\\partial N} \\bigg |_{T,P} = \\frac{\\partial}{\\partial N} \\bigg |_{T,P} \\frac{\\partial G}{\\partial P} \\bigg |_{T,N} = \\frac{\\partial V}{\\partial N} \\bigg |_{T,P}.\n\\] Compare this relation with the one for an extensive system that we saw in a previous example, \\[\n\\frac{\\partial \\mu}{\\partial P} \\bigg |_{T,N} = \\frac{V}{N}.\n\\]",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Thermodynamics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/thermodynamics.html#stability-conditions",
    "href": "statistical-mechanics/thermodynamics.html#stability-conditions",
    "title": "Thermodynamics",
    "section": "Stability Conditions",
    "text": "Stability Conditions\nThermodynamics depends on systems being in equilibrium. We already know that systems at equilibrium with each other will have the same temperature, but what else can we say?\n\nMechanical Stability\nRecall from classical mechanics what it means for a classical system to be in mechanical equilibrium. A classical system is said to be in mechanical equilibrium when the total forces acting on the system are zero, i.e. \\(\\mathbf{F} = \\mathbf{0}\\). For conservative systems, that’s equivalent to saying the potential \\(V=V(\\mathbf{x})\\) has gradient zero, i.e. \\(\\nabla V(\\mathbf{x}) = \\mathbf{0}\\).\nThe equilibrium point \\(\\mathbf{x}^*\\) is a stable equilibrium if \\(V(\\mathbf{x}^* )\\) is a local minimum. A sufficient condition for this to be true is that the second-order deviations around \\(V(\\mathbf{x}^* )\\) are positive, or equivalently that the Hessian of \\(V(\\mathbf{x})\\) is positive definite about \\(\\mathbf{x}^*\\), i.e. \\[\n\\delta^2 V \\equiv \\delta\\mathbf{x} \\cdot \\frac{d^2}{d\\mathbf{x}^2} V(\\mathbf{x}^*) \\cdot \\delta\\mathbf{x} = \\sum_{i,j=1}^3\\frac{\\partial^2 V}{\\partial x_i \\partial x_j}\\delta x_i \\delta x_j &gt; 0 \\quad \\forall\\delta\\mathbf{x} \\neq \\mathbf{0}.\n\\] Intuitively, a stable equilibrium means that if the system is nudged by a small displacement it will experience a tension force pulling it back to equilibrium. Think of a spring as the canonical example.\n\n\nThermodynamic Stability\nWe’d like to derive an analogue of this formula to characterize what it means for a thermodynamic system to be in a stable equilibrium. To do that, it’s convenient to symmetrize the positive definite expression with respect to \\(\\mathbf{F}\\) and \\(\\mathbf{x}\\). Notice that if we let \\[\n\\delta \\mathbf{F} \\equiv \\frac{d^2 V}{d\\mathbf{x}^2} \\cdot \\delta\\mathbf{x} = \\sum_{j=1}^3 \\frac{\\partial^2 V}{\\partial x_i \\partial x_j} \\delta x_j,\n\\] then we can re-write the condition for mechanical stability as \\[\n\\delta \\mathbf{F} \\cdot \\delta\\mathbf{x} = \\sum_{i=1}^3 \\delta F_i \\delta x_i &gt; 0.\n\\] We can extend this same idea to thermodynamical systems, except there we require that all equilibrium points be stable. That is, the stability condition is required to be in thermodynamic equilibrium.\nTheorem: Any thermodynamic system in equilibrium must satisfy the stability condition \\[\n\\boxed{\\delta T \\delta S + \\delta J \\cdot \\delta X + \\delta \\mu \\cdot \\delta N \\geq 0} \\ .\n\\] Proof: Consider an isolated system in equilibrium. Then any two subsystems \\(A\\) and \\(B\\) must be in equilibrium with each other. It must be the case then that their intensive quantities are identical, i.e. \\[\nT \\equiv T_A = T_B, \\quad J \\equiv J_A = J_B, \\quad \\mu \\equiv \\mu_A = \\mu_B.\n\\] It must also be the case that their extensive quantities add to give the ones for the full system, \\[\nE \\equiv E_A + E_B, \\quad S \\equiv S_A + S_B, \\quad X \\equiv X_A + X_B, \\quad N \\equiv N_A + N_B.\n\\] Suppose that \\(B\\) spontaneously transfers energy to \\(A\\) in the form of both heat and work. Let’s look at the first order change in the system’s total entropy. Evidently, we’d have \\[\n\\begin{align*}\n\\delta S &= \\delta S_A + \\delta S_B \\\\\n&= \\delta\\bigg(\\frac{E_A}{T_A} - \\frac{J_A}{T_A} \\cdot X_A - \\frac{\\mu_A}{T_A} \\cdot N_A \\bigg) + \\delta\\bigg(\\frac{E_B}{T_B} - \\frac{J_B}{T_B} \\cdot X_B - \\frac{\\mu_B}{T_B} \\cdot N_B \\bigg) \\\\\n&= 2\\bigg[\\delta\\bigg(\\frac{1}{T_A}\\bigg) \\delta E_A - \\delta\\bigg(\\frac{J_A}{T_A}\\bigg)\\cdot \\delta X_A - \\delta\\bigg(\\frac{\\mu_A}{T_A}\\bigg)\\cdot \\delta N_A \\bigg] \\\\\n&= -\\frac{2}{T_A}\\bigg[\\delta T_A \\bigg(\\frac{\\delta E_A - J_A \\cdot \\delta X_A - \\mu_A \\cdot \\delta N_A}{T_A}\\bigg) + \\delta J_A \\cdot \\delta X_A + \\delta\\mu_A \\cdot \\delta N_A\\bigg] \\\\\n&= -\\frac{2}{T_A}\\big[\\delta T_A \\delta S_A + \\delta J_A \\cdot \\delta X_A + \\delta \\mu_A \\cdot \\delta N_A\\big].\n\\end{align*}\n\\] To be in equilibrium, any change to the system should lead to a decrease in entropy since entropy is maximized at equilibrium. This implies that \\(\\delta S \\leq 0\\), or equivalently that \\[\n\\delta T_A \\delta S_A + \\delta J_A \\cdot \\delta X_A + \\delta \\mu_A \\cdot \\delta N_A \\geq 0.\n\\] This condition should apply for any subsystem, which means it should apply to the whole system as well, \\[\n\\delta T \\delta S + \\delta J \\cdot \\delta X + \\delta \\mu \\cdot \\delta N \\geq 0.\n\\] The above condition was obtained assuming the system’s extensive variables \\(E,q,N\\) were held constant. In fact, since all coordinates appear symmetrically in the expression, the same result is obtained for any other set of constraints as well. \\(\\text{Q.E.D.}\\)\nAnother way of expressing the stability condition is that any second order deviations in the energy around equilibrium must be positive, i.e. \\(\\delta^2 E \\geq 0\\). This also means that the energy function should be convex about its equilibrium states.\n\n\nClosed Systems\nSuppose a system is closed, so \\(dN = 0\\). Then the first law says \\(dE = TdS + J \\cdot dX\\), and the stability condition says \\(\\delta T \\delta S + \\delta J \\cdot \\delta X \\geq 0\\). We can always solve for any two variables in terms of the rest. For example, we can write \\[\n\\begin{align*}\n\\delta S &= \\frac{\\partial S}{\\partial T} \\bigg |_{X,N} \\delta T + \\frac{\\partial S}{\\partial X} \\bigg |_{T,N} \\delta X, \\\\\n\\delta J &= \\frac{\\partial J}{\\partial T} \\bigg |_{X,N} \\delta T + \\frac{\\partial J}{\\partial X} \\bigg |_{T,N} \\delta X. \\\\\n\\end{align*}\n\\] Substituting these into the stability condition, we can write \\[\n\\begin{align*}\n0 &\\leq \\delta T \\bigg(\\frac{\\partial S}{\\partial T} \\bigg |_{X,N} \\delta T + \\frac{\\partial S}{\\partial X} \\bigg |_{T,N} \\delta X\\bigg) + \\bigg(\\frac{\\partial J}{\\partial T} \\bigg |_{X,N} \\delta T + \\frac{\\partial J}{\\partial X} \\bigg |_{T,N} \\delta X\\bigg) \\delta X \\\\\n&\\leq \\frac{\\partial S}{\\partial T} \\bigg |_{X,N} \\delta T^2 + \\bigg(\\frac{\\partial S}{\\partial X} \\bigg |_{T,N} + \\frac{\\partial J}{\\partial T} \\bigg |_{X,N} \\bigg) \\delta T \\delta X + \\frac{\\partial J}{\\partial X} \\bigg |_{T,N} \\delta X^2 \\\\\n&\\leq \\frac{\\partial S}{\\partial T} \\bigg |_{X,N} \\delta T^2 + \\frac{\\partial J}{\\partial X} \\bigg |_{T,N} \\delta X^2. \\\\\n\\end{align*}\n\\] The last line follows from the fact that \\(\\frac{\\partial S}{\\partial X} \\big |_{T,N} = -\\frac{\\partial J}{\\partial T} \\big |_{X,N}\\) via a Maxwell relation. Let’s look at this in two cases, first when along curves of constant \\(X\\), and then along curves of constant \\(T\\). In the first case we’d have \\(\\delta X = 0\\), which says \\[\n\\frac{\\partial S}{\\partial T} \\bigg |_{X,N} \\delta T^2 \\geq 0.\n\\] This says that along curves of constant \\(X\\), the entropy must be an increasing function of temperature. This evidently implies that the heat capacity along constant \\(X\\) must be non-negative, since \\[\nC_q = \\frac{\\delta Q}{\\partial T} \\bigg |_{X,N} = T \\frac{\\partial S}{\\partial T} \\bigg |_{X,N} \\geq 0.\n\\] Let’s now look at curves of constant \\(T\\), i.e. the isotherms. In that case we’d have \\[\n\\frac{\\partial J}{\\partial X} \\bigg |_{T,N} \\delta X^2 \\geq 0,\n\\] which evidently implies \\(J\\) must be an increasing function of \\(X\\) along the isotherms. In the case of a gas, this condition just says that pressure \\(p\\) must be a decreasing function of \\(V\\) along isotherms, which we’ve already seen.\n\nExample: Stability of Gases\nSuppose we have some gas that’s kept a constant temperature \\(T\\) and particle number \\(N\\). If we apply the stability condition to a gas, in general we’d have \\[\n\\delta T \\delta S - \\delta P \\delta V + \\delta \\mu \\delta N \\geq 0.\n\\] Since \\(\\delta T = \\delta N = 0\\), this simplifies to just \\(-\\delta P \\delta V \\geq 0\\), or equivalently \\[\n\\delta P = \\frac{\\partial P}{\\partial V} \\bigg |_{T,N} \\delta V \\leq 0.\n\\] This says that evidently \\(P\\) must be a decreasing function of \\(V\\). If we define the compressibility \\(\\kappa\\) of a gas by \\[\n\\kappa \\equiv -\\frac{1}{V} \\frac{\\partial V}{\\partial P} \\bigg |_{T,N},\n\\] then the stability condition evidently says that \\(\\kappa \\geq 0\\) at equilibrium. That is, the gas must be compressible, i.e. increasing the pressure on the gas should decrease its volume.\nIt’s interesting to examine the special isotherm \\(T=T_c\\) where \\(\\frac{\\partial P}{\\partial V} \\big |_{T,N} = 0\\). Along this isotherm there’s a flat spot near some critical point \\((P_c,V_c)\\). Around this point \\(\\delta P = 0\\), which means we need to look at the higher-order deviations in \\(P(V)\\). If we expand to third order about \\(V_c\\), we’d have \\[\n\\delta P \\approx \\frac{\\partial P}{\\partial V} \\bigg |_{T_c,N} \\delta V + \\frac{1}{2} \\frac{\\partial^2 P}{\\partial V^2} \\bigg |_{T_c,N} \\delta V^2 + \\frac{1}{6} \\frac{\\partial^3 P}{\\partial V^3} \\bigg |_{T_c,N} \\delta V^3.\n\\] To satisfy the stability condition we can only keep terms with odd powers in \\(\\delta V\\), since otherwise \\(\\delta P \\delta V\\) wouldn’t be non-negative. Evidently then, to maintain stability, about the critical point we must have \\[\n\\delta P \\approx \\frac{1}{6} \\frac{\\partial^3 P}{\\partial V^3} \\bigg |_{T_c,N} \\delta V^3, \\quad \\text{where} \\quad \\frac{\\partial^3 P}{\\partial V^3} \\bigg |_{T_c,N} \\geq 0.\n\\] This means that the isotherm along \\(T=T_c\\) must be a decreasing cubic with stationary point at \\((P_c,V_c)\\).\nIn reality, this condition requires that \\(P(V)\\) be an analytic function around \\(T_c\\). But it turns out that it’s not analytic around this point. There’s a phase transition. In fact, near \\(T_c\\) it’s the case that \\(\\delta P \\propto \\delta V^\\gamma\\), where \\(\\gamma \\approx 4.7\\) is an experimentally determined constant. To understand this better we’d need field theory.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Thermodynamics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/thermodynamics.html#third-law",
    "href": "statistical-mechanics/thermodynamics.html#third-law",
    "title": "Thermodynamics",
    "section": "Third Law",
    "text": "Third Law\nSuppose we take a reversible system and change its state from \\(x_1\\) to \\(x_2\\). Then its entropy changes by \\[\n\\Delta S = S_2 - S_1 = \\int_{x_1}^{x_2} \\frac{\\delta Q_{rev}}{T}.\n\\] We can say this for any positive temperature \\(T\\). Now suppose we allow \\(T \\rightarrow 0\\). What happens to \\(\\Delta S\\)? It turns out experimentally that \\(\\Delta S \\rightarrow 0\\). This is an independent fact due to Nernst, which gives us a narrow statement of the third law of thermodynamics.\nThird Law (Nernst): The entropy of all systems at zero absolute temperature is a universal constant that can be taken to be zero. That is, between any two states we must have \\[\n\\boxed{\\lim_{T \\rightarrow 0} \\Delta S = 0} \\ .\n\\] This statement turns out to be experimentally equivalent to an even stronger statement. Not only does \\(\\Delta S \\rightarrow 0\\), but in fact \\(S \\rightarrow 0\\) for any substance.\nThird Law (General): The entropy of all substances at zero absolute temperature is the same universal constant, which can be defined to be zero. That is, for any system, \\[\n\\boxed{\\lim_{T \\rightarrow 0} S = S_0 \\equiv 0} \\ .\n\\] This extended version of the third law can be experimentally tested by looking at the behavior of certain materials like sulfur or phosphine, which can exist near absolute zero in multiple crystalline structures called allotropes. Each allotrope has its own heat capacity \\(C(T)\\). It’s been shown that as \\(T \\rightarrow 0\\), each of these paths sends \\(C \\rightarrow 0\\), which implies \\(S \\rightarrow 0\\) as well.\n\n\n\n\n\nHere are a few notable consequences that follow from the third law. First, since \\(S \\rightarrow 0\\) as \\(T \\rightarrow 0\\), it must also be true that any partial derivative of \\(S\\) must go to zero as well, \\[\n\\lim_{T \\rightarrow 0} \\frac{\\partial S}{\\partial X} \\bigg |_T = 0.\n\\] The heat capacities must go to zero as well since \\[\n\\Delta S = \\int_0^T \\frac{C(T')}{T'} dT' \\rightarrow 0.\n\\] This integral would diverge as \\(T \\rightarrow 0\\) unless \\(C \\rightarrow 0\\) as well.\nThe thermal expansion coefficients must also go to zero since by a Maxwell relation we have \\[\n\\alpha \\equiv \\frac{1}{X} \\frac{\\partial X}{\\partial T} \\bigg |_J = \\frac{1}{X} \\frac{\\partial S}{\\partial J} \\bigg |_T \\rightarrow 0.\n\\] The last consequence of note is that it must be impossible to cool any system to absolute zero in a finite number of steps, which for practical purposes means it’s impossible to cool a system to zero exactly. For example, suppose we tried to cool a gas by adiabatically reducing its pressure. Since all \\(S(T)\\) curves must intersect at \\(0\\), any successive step would involve progressively smaller changes in \\(S\\) and \\(T\\) as \\(T \\rightarrow 0\\).\n\n\n\n\n\nIt’s worth mentioning that in a certain sense the third law is less reliable than the other laws of thermodynamics since at its root its validity rests entirely on quantum mechanics, and the quantum mechanical behavior of different systems can vary wildly near absolute zero. This contrasts with the other laws, which at a microscopic level only depend on things like the conservation of energy, or the emergent effect of a large number of degrees of freedom. We’ll see a microscopic derivation of each of these laws in future chapters.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Thermodynamics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/probability.html",
    "href": "statistical-mechanics/probability.html",
    "title": "Probability",
    "section": "",
    "text": "Univariate Probability",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/probability.html#univariate-probability",
    "href": "statistical-mechanics/probability.html#univariate-probability",
    "title": "Probability",
    "section": "",
    "text": "Probability Measures\nAt its root, probability is based on the study of events or random variables. Suppose \\(\\mathcal{S}\\) is the set of all possible outcomes of an experiment, called the sample space. Any subset \\(E \\subset \\mathcal{S}\\) is called an event. A probability measure is a set function \\(\\mathbb{Pr}(E)\\) that maps events to numerical values between zero and one. It’s meant to formalize the concept of chance. If an event has probability one, we think of that event as being 100% certain to occur. If it has probability zero, we think of the event as having 0% chance to occur. Any values in between mean we’re uncertain whether the event will occur.\nFormally, a probability measure on a sample space \\(\\mathcal{S}\\) satisfies the following properties:\n\nPositivity: For any event \\(E \\subset \\mathcal{S}\\), \\(\\mathbb{Pr}(E) \\geq 0\\).\nAdditivity: If \\(A \\subset \\mathcal{S}\\) and \\(B \\subset \\mathcal{S}\\) are distinct, disjoint events, then \\(\\mathbb{Pr}(A \\text{ or } B) = \\mathbb{Pr}(A) + \\mathbb{Pr}(B)\\).\nNormalization: For the entire sample space \\(\\mathcal{S}\\), \\(\\mathbb{Pr}(\\mathcal{S}) = 1\\).\n\nWhile this is a nice formal definition of probability, it’s not practically useful for saying how we should design a probability measure in a practical setting. There are two common approaches for designing probability measures:\n\nThe objective approach: In this approach, we imagine running a bunch of experiments and counting the frequency of occurrences of an event. That is, if we run a large number \\(N\\) of experiments and observe an event \\(A\\) occurs exactly \\(N_A\\) times, then we define \\(\\mathbb{Pr}(A)\\) by the ratio \\[\n\\boxed{\\mathbb{Pr}(A) \\equiv \\lim_{N \\rightarrow \\infty} \\frac{N_A}{N}} \\ .\n\\] The fact that the ratio \\(\\frac{N_A}{N}\\) stabilizes to a fixed value as \\(N\\) gets infinitely large follows from the law of large numbers, which we’ll take as a kind of experimental fact.\nThe subjective approach: In this approach we take a more theoretical view by looking for a “maximally random” probability distribution that matches what we know to be true. That is, we seek to find the maximum entropy probability distribution that satisfies some given set of known constraints. We’ll talk more about the principle of maximum entropy when we get to information theory. The subjective approach is the one used most heavily in statistical mechanics.\n\n\n\nRandom Variables\nA random variable is a variable \\(X\\) that doesn’t take on a fixed value, but rather a random value determined by a probability distribution. If \\(E \\subset \\mathcal{S}\\) is an event, a random variable encodes that event using a numerical variable \\(X=X(E)\\). More formally, \\(X(E)\\) is a function that maps events to a numerical value. It could be a real number, a complex number, or a real or complex vector, for example.\nA one-dimensional random variable is a mapping \\(X(E)\\) from events \\(E \\subset \\mathcal{S}\\) into the real numbers \\(\\mathbb{R}\\). In this case, we can define a cumulative distribution function or CDF as the function \\[\n\\boxed{P(x) \\equiv \\mathbb{Pr}\\big(\\{X \\leq x\\}\\big)} \\ .\n\\] That is, the CDF is the probability that the random variable \\(X \\leq x\\), where \\(x\\) is just some real number. To obey the laws of probability, the CDF must satisfy the following properties:\n\nIt’s an increasing function of \\(x\\). That is, if \\(x_1 \\leq x_2\\) then \\(P(x_1) \\leq P(x_2)\\).\nIt has probability zero at \\(x=-\\infty\\). That is, \\(\\lim_{x \\rightarrow -\\infty} P(x) = 0\\).\nIt has probability one at \\(x=\\infty\\). That is, \\(\\lim_{x \\rightarrow \\infty} P(x) = 1\\).\n\nIf the set of all values \\(X\\) can take on are discrete, we say \\(X\\) is a discrete random variable. In this case, we can define a probability mass function or PMF as the function \\[\n\\boxed{p(x) \\equiv \\mathbb{Pr}(X = n)} \\ .\n\\] By the laws of probability the PMF must satisfy the following properties:\n\nIt’s between zero and one: \\(0 \\leq p(n) \\leq 1\\).\nIt sums to one over all values, i.e. \\(\\sum_{n \\in \\mathcal{S}} \\ p(n) = 1\\).\nIt’s related to the CDF by \\(P(x) = \\sum_{n \\leq x} \\ p(n)\\).\n\nIf the set of all values it can take on are continuous, we say \\(X\\) is a continuous random variable. In this case, we can define a probability density function or PDF by the function \\[\n\\boxed{p(x) = \\mathbb{Pr}(x \\leq X \\leq x + dx)} \\ .\n\\] By the laws of probability, the PDF must satisfy the following properties:\n\nIt’s a positive function \\(p(x) \\geq 0\\).\nIt integrates to one over all values, \\(\\int_\\mathcal{S} p(x) dx = 1\\).\nIt’s related to the CDF by differentiation, \\(p(x) = \\frac{d}{dx} P(x)\\).\n\nNote that in physics the PDF has units. If \\(x\\) has units of \\([x]\\), then evidently \\(p(x)\\) must have units of \\(\\frac{1}{[x]}\\). This is why we think of the PDF as a density. It’s a probability per unit \\(x\\).\nBy convention, if \\(S \\subset \\mathbb{R}\\) we’ll assume \\(p(x) = 0\\) on values of \\(x\\) outside of \\(S\\). This means we can treat the PMF as a PDF by using delta functions to indicate where each discrete value of \\(x\\) has non-zero \\(p(x)\\). That is, \\[\np(k) = p(x) \\delta (x - k).\n\\] For this reason, we’ll generally state results in the form of a continuous random variable.\nWhere there’s no risk of confusion, we’ll frequently abuse notation by using the lower case letter \\(x\\) for both the random variable as well as the value it can take on.\n\n\nMoments and Cumulants\nFor both discrete and continuous random variables we can define the expected value of a random function \\(F(x)\\) by summing or integrating the function, weighted by the PMF or PDF. In the continuous case, we’d define the expected value \\(\\langle F(x) \\rangle\\) by \\[\n\\boxed{\\langle F(x) \\rangle \\equiv \\int_{\\mathbb{R}} dx \\ F(x) p(x)} \\ .\n\\] Some of the functions \\(F(x)\\) have special names:\n\nWe call \\(\\mu \\equiv \\langle x \\rangle\\) the mean of \\(x\\).\nWe call \\(\\mu_n \\equiv \\langle x^n \\rangle\\) the nth moment of \\(x\\).\nWe call \\(\\langle e^{-ikx} \\rangle\\) the characteristic function or CF of \\(x\\).\n\nNote the characteristic function is just the Fourier transform of the PDF since \\[\n\\langle e^{-ikx} \\rangle = \\tilde p(k) = \\int_{\\mathbb{R}} dx \\ e^{-ikx} p(x).\n\\] This means we can always go from the CF back to the PDF by taking the inverse Fourier transform, \\[\np(x) = \\int_{\\mathbb{R}} \\frac{dx}{2\\pi} \\ e^{ikx} \\tilde p(k).\n\\] If we Taylor expand the CF, we can also evidently write \\[\n\\langle e^{-ikx} \\rangle = \\bigg\\langle \\sum_{n=0}^\\infty \\frac{(-ik)^n}{n!} x^n \\bigg\\rangle = \\sum_{n=0}^\\infty \\frac{(-ik)^n}{n!} \\mu_n.\n\\] This means that the CF can be used to generate moments for a given distribution. Once we have a closed form for the CF, just expand it into a series and pick off each \\(\\mu_n = \\langle x^n \\rangle\\) term by term.\nWe can translate the CF to any other point \\(x_0\\) by observing that \\[\n\\langle e^{-ik(x-x_0)} \\rangle = \\int_{\\mathbb{R}} dx \\ e^{-ik(x-x_0)} p(x) = e^{ikx_0} \\tilde p(k).\n\\] More useful to us in practice is not the characteristic function, but its logarithm, called the cumulant function. We’ll assume we can expand \\(\\log \\tilde p(k)\\) as a Taylor Series about \\(k=0\\) weighted by some coefficients \\(\\kappa_n\\). By expanding out the MGF inside the log, we can evidently then write \\[\n\\log \\tilde p(k) = \\sum_{n=1}^\\infty \\frac{(-ik)^n}{n!} \\kappa_n = \\log\\bigg(1 + \\sum_{n=1}^\\infty \\frac{(-ik)^n}{n!} \\mu_n \\bigg).\n\\] The sum inside the log is of the form \\(1+\\varepsilon\\). We can thus expand the log in powers of \\(\\varepsilon\\) to get \\[\n\\log\\big(1 + \\varepsilon \\big) = 1 + \\varepsilon - \\frac{1}{2} \\varepsilon^2 + \\frac{1}{3} \\varepsilon^3 - \\frac{1}{4} \\varepsilon^4 + \\cdots\n\\] Using this expansion and matching term-by-term to the original expansion of \\(\\log \\tilde p(k)\\) we can find expressions for the coefficients \\(\\kappa_n\\) in terms of the moments \\(\\mu_n\\). These coefficients are called the nth cumulants of \\(x\\). The first cumulant turns out to be the mean of \\(x\\), \\[\n\\kappa_1 = \\langle x \\rangle.\n\\] Intuitively, the mean \\(\\mu\\) of a distribution represents its center of mass or average value. To see why, suppose \\(x\\) is a discrete random variable taking on values \\(1, 2, \\cdots, n\\) each with probability \\(p(x) = \\frac{1}{n}\\). Then we’d have \\[\n\\mu = \\sum_{x=1}^n x p(x) = \\frac{1}{n} \\sum_{x=1}^n x = \\overline x.\n\\] That is, the mean is just the unweighted average \\(\\overline x\\) from elementary math. In general each \\(x\\) will be weighted by its probability \\(p(x)\\) giving a weighted average.\nThe second cumulant is evidently given by \\[\n\\kappa_2 = \\langle x^2 \\rangle - \\langle x \\rangle^2.\n\\] This is called the variance of \\(x\\), usually denoted \\(\\sigma^2\\). By rearranging the right-hand side a little bit we can also write the variance in the form \\[\n\\boxed{\\sigma^2 \\equiv \\langle x^2 \\rangle - \\langle x \\rangle^2 = \\langle (x-\\mu) \\rangle^2} \\ .\n\\] This gives an intuitive interpretation of the variance. It’s the mean squared difference from the mean. It’s a squared measure of the spread of the distribution. For this reason we often prefer to take its square root to get a measure of the spread in units of \\(x\\) itself. This is called the standard deviation, \\(\\sigma \\equiv \\sqrt{\\sigma^2}\\).\nThe third cumulant is evidently given by \\[\n\\kappa_3 = \\langle x^3 \\rangle - 3\\langle x^2 \\rangle\\langle x \\rangle + 2 \\langle x \\rangle^3.\n\\] It’s not obvious what this represents, but it turns out to represent the skewness of \\(x\\). That is, the tendency for the distribution to skew left or right by some amount. A distribution symmetric about its mean will have zero skew since all of the odd moments will vanish, hence \\(\\kappa_3 = 0\\). Strictly speaking, the skewness is often normalized by dividing by \\(\\sigma^3\\).\nThere’s a useful graphical trick that can be used to quickly find the relationship between cumulants and moments. The idea is to represent the nth cumulant \\(\\kappa_n\\) is a bag of \\(n\\) points. Then we can get the nth moment by summing over all possible ways of distributing \\(n\\) points among all possible bags \\(1, 2, \\cdots, n\\). It’s easiest to show this by example. Here’s how to get the first few moments from the first few cumulants:\n\n\n\n\n\n\n\nChange of Variables\nOccasionally we’ll want to make a change of variables from one random variable to another. To do that we need to figure out how the probabilities change under the change of variables. Suppose \\(F=F(X)\\) is a random function of a random variable \\(X\\). If \\(f = F(x)\\), then probability that \\(X \\in [x, x+dx]\\) must be the same as the probability that \\(F \\in [f, f+df]\\). Provided \\(F(x)\\) is single-valued, that means we’d have \\[\np_F(f) df = p_X(x) dx.\n\\] Dividing both sides by \\(df\\) and noting that probabilities have to be positive, we have \\[\np_F(f) = p_X(x) \\bigg|\\frac{dx}{df}\\bigg|.\n\\] In general \\(F(x)\\) need not be single-valued. This means we have to sum over all possible values \\(x_i\\) such that \\(f=F(x_i)\\). In this case, we’d instead have \\[\n\\boxed{p_F(f) = \\sum p_X(x_i) \\bigg|\\bigg(\\frac{dx}{df}\\bigg)_{x=x_i}\\bigg|} \\ .\n\\]\n\n\n\n\n\n\nExample: The Laplace Distribution\nSuppose \\(p(x) \\propto e^{-\\lambda |x|}\\) where \\(\\lambda &gt; 0\\) is some scale parameter.\n\nFind the normalization constant \\(\\mathcal{N}\\) such that \\(p(x) = \\mathcal{N} e^{-\\lambda |x|}\\).\nThe PDF must integrate to one from \\(-\\infty\\) to \\(\\infty\\). We have \\[\n1 = \\int_{-\\infty}^\\infty dx \\ p(x) = \\int_{-\\infty}^\\infty dx \\  \\mathcal{N} e^{-\\lambda |x|} = \\frac{2\\mathcal{N}}{\\lambda}.\n\\] Thus, \\(\\mathcal{N} = \\frac{\\lambda}{2}\\), so we finally just have \\(p(x) = \\frac{\\lambda}{2} e^{-\\lambda x}\\). This is called the Laplace distribution.\nSuppose \\(f = x^2\\). Find the new PDF \\(p_F(f)\\) using a change of variables.\nThis transformation is multi-valued, with \\(x = \\pm \\sqrt{f}\\). Using the change of variables, we have \\[\n\\begin{align*}\np_F(f) &= p(\\sqrt{f}) \\bigg|\\frac{d}{df} \\sqrt{f}\\bigg| + p(-\\sqrt{f}) \\bigg|-\\frac{d}{df} \\sqrt{f}\\bigg| \\\\\n&= \\frac{\\lambda}{2} e^{-\\lambda \\sqrt{f}} \\bigg(\\frac{1}{2\\sqrt{f}} +  \\frac{1}{2\\sqrt{f}} \\bigg) \\\\\n&= \\frac{\\lambda}{2\\sqrt{f}} e^{-\\lambda \\sqrt{f}}. \\\\\n\\end{align*}\n\\] Note that this new PDF is only defined when \\(f \\geq 0\\) due to the square root.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/probability.html#probability-distributions",
    "href": "statistical-mechanics/probability.html#probability-distributions",
    "title": "Probability",
    "section": "Probability Distributions",
    "text": "Probability Distributions\nSo far I’ve used the term distribution rather loosely. More formally, given a random variable \\(x\\), a probability distribution is a specific functional form for \\(p(x)\\). We’d write \\(x \\sim p(x)\\) to indicate that \\(x\\) is distributed as \\(p(x)\\). Usually \\(p(x)\\) will be parametric, meaning it will have external parameters that tune the shape of the distribution. Here are some common univariate distributions we’ll see in statistical mechanics:\n\nUniform Distribution\nThe uniform distribution is perhaps the simplest distribution of all, with \\(p(x) = const\\) on some set \\(x \\in \\mathcal{S}\\). As a shorthand we might write \\(x \\sim U(\\mathcal{S})\\) to say \\(x\\) is uniform on the set \\(\\mathcal{S}\\). In the discrete case, \\(x\\) takes on some number of values \\(N\\) each with equal probability, for example if \\(\\mathcal{S} = \\{1, 2, \\cdots, n\\}\\) we have \\[\n\\boxed{p(x) = \\frac{1}{N}} \\ .\n\\] We can easily calculate the moments of a uniform random variable directly. In the discrete case, we’d have \\[\n\\langle x^n \\rangle = \\sum_{x=1}^N \\ x^n \\ p(x) = \\frac{1}{N} (1^n + 2^n + \\cdots + N^n).\n\\] This is just an arithmetic sum in powers of \\(n\\). For example, the first two moments are \\[\n\\begin{align*}\n\\langle x \\rangle &= \\frac{(N+1)}{2}, \\\\\n\\langle x^2 \\rangle &= \\frac{(N+1)(2N+1)}{6}. \\\\\n\\end{align*}\n\\] Using these we can directly calculate the mean and variance, which are \\[\n\\begin{align*}\n\\mu &= \\langle x \\rangle = \\frac{(N+1)}{2}, \\\\\n\\sigma^2 &= \\langle x^2 \\rangle - \\langle x \\rangle^2 = \\frac{N^2-1}{12}. \\\\\n\\end{align*}\n\\] The characteristic function is just given by a geometric series in powers of \\(e^{-ik}\\), \\[\n\\tilde p(k) = \\sum_{x=1}^N p(x) e^{-ikx} = \\sum_{x=1}^N \\frac{1}{N} \\big(e^{-ik}\\big)^n = \\frac{e^{-ik}-e^{-ik(N+1)}}{1-e^{-ik}}.\n\\] We could in principle calculate the cumulant function \\(\\log \\tilde p(k)\\) as well, though it’s clearly not going to be as useful for finding the cumulants here. We’ll see later that the uniform distribution is the maximum entropy distribution when the only known constraints are that \\(x\\) lies in some set \\(S\\).\n\n\nGaussian Distribution\nThe Gaussian distribution is one of the most fundamental distributions in physics. In statistical mechanics, for example, it describes the velocity of gases in a box. Suppose \\(x\\) is a continuous random variable defined on the whole real line. We say it’s Gaussian distributed if its PDF is given by \\[\n\\boxed{p(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\bigg(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\bigg)} \\ .\n\\] The Gaussian distribution has two parameters, a real number \\(\\mu\\) and a positive number \\(\\sigma^2\\). As a shorthand we’ll sometimes say \\(x\\) is Gaussian distributed by writing \\(x \\sim \\mathcal{N}(\\mu, \\sigma^2)\\). The PDF’s curve is the distinctive bell-shaped curve that falls off exponentially fast symmetrically around \\(\\mu\\). For practical purposes, almost all of the probability mass lies in the range \\(-3\\sigma \\leq x \\leq 3\\sigma\\).\nWe can calculate the characteristic function by taking the Fourier transform of \\(p(x)\\). By using a couple of changes of variables and completing the square inside the exponent, we have, \\[\n\\begin{align*}\n\\tilde p(k) &= \\int_\\mathbb{R} dx \\ p(x) e^{-ikx} \\\\\n&= \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\int_\\mathbb{R} dx \\ e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}-ikx} \\\\\n&= \\frac{e^{-ik\\mu}}{\\sqrt{2\\pi\\sigma^2}} \\int_\\mathbb{R} dy \\ e^{-\\frac{y^2}{2\\sigma^2}-ikx} \\quad &y \\equiv& \\ x - \\mu \\\\\n&= e^{-ik\\mu-\\frac{1}{2}k^2 \\sigma^2} \\int_\\mathbb{R} \\frac{dz}{\\sqrt{2\\pi\\sigma^2}} \\ e^{-\\frac{z^2}{2\\sigma^2}} \\quad &z \\equiv& \\ y + ik\\sigma^2 \\\\\n&= e^{-ik\\mu-\\frac{1}{2}k^2 \\sigma^2}. \\\\\n\\end{align*}\n\\] Notice the characteristic function is also itself a Gaussian, just with an imaginary shift. Taking the log immediately gives the cumulant function, which is just the exponent terms, \\[\n\\log \\tilde p(k) = -ik\\mu-\\frac{1}{2}k^2 \\sigma^2.\n\\] Notice only the first two powers of \\(k\\) appear in the cumulant. This means \\(\\kappa_1 = \\mu\\), \\(\\kappa_2 = \\sigma^2\\), and all higher cumulants are zero. Evidently, the parameter \\(\\mu\\) is just the mean and the parameter \\(\\sigma^2\\) is just the variance.\nIf we like, we can use the graphical trick to read off the moments as well. In this case, there can’t be any bags with more than two points, which greatly simplifies terms. The first few moments are, \\[\n\\begin{align*}\n\\langle x \\rangle &= \\kappa_1 = \\mu, \\\\\n\\langle x^2 \\rangle &= \\kappa_2 + \\kappa_1^2 = \\sigma^2 + \\mu^2, \\\\\n\\langle x^3 \\rangle &= 3 \\kappa_2 \\kappa_1 + \\kappa_1^3 = 3\\sigma^2 \\mu + \\mu^3, \\\\\n\\langle x^4 \\rangle &= 3 \\kappa_2^2 + 6 \\kappa_2 \\kappa_1^2 + \\kappa_1^4 = 3\\sigma^4 + 6 \\sigma^2 \\mu^2 + \\mu^4.\n\\end{align*}\n\\] ### Binomial Distribution\nSuppose we have a binary random variable \\(x = 0, 1\\) that takes on the value one with a fixed probability \\(p\\). We can express its PMF simply as \\[\np(x) = p^x (1-p)^{1-x}.\n\\] We’d call such an \\(x\\) a Bernoulli random variable. A common example would be flipping a coin, where heads occurs with a fixed probability \\(p=0.5\\). Now suppose we allow the binary outcome to repeat \\(n\\) times independently. It turns out that the sum of those \\(n\\) outcomes is distributed in a similar way, except now \\(x\\) can take on any value in the range \\(x = 0, 1, \\cdots, n\\). Accounting for normalization, we have \\[\n\\boxed{p(x) = \\binom{n}{x} p^x (1-p)^{n-x}} \\ .\n\\] We’d say \\(x\\) is binomially distributed with parameters \\(p\\) and \\(n\\), sometimes written as \\(x \\sim \\text{Bin}(n,p)\\). The normalization constant is the binomial coefficient, \\[\n\\binom{n}{x} \\equiv \\frac{n!}{x!(n-x)!}.\n\\] The binomial coefficient represents the number of ways to choose \\(x\\) points from a total of \\(n\\) points, assuming the order the points are chosen is irrelevant.\nThe characteristic function of the binomial distribution can be found using the binomial theorem, \\[\n\\begin{align*}\n\\tilde p(k) &= \\sum_{x=0}^n \\binom{n}{x} p^x (1-p)^{n-x} e^{-ikx} \\\\\n&= \\sum_{x=0}^n \\binom{n}{x} \\big(p e^{-ik}\\big)^x (1-p)^{n-x} \\\\\n&= \\big(pe^{-ik} + (1-p) \\big)^n.\n\\end{align*}\n\\] Notice the parameter \\(n\\) appears only in the exponent. This means the cumulant function is just \\(n\\) times the cumulant function for the Bernoulli distribution, \\[\n\\log \\tilde p_n(k) = n \\log \\tilde p_1(k).\n\\] In particular, the cumulants are all proportional to \\(n\\) times the Bernoulli cumulants. Expanding out \\(\\log \\tilde p_1(k)\\), we have \\[\n\\begin{align*}\n\\log \\tilde p_1(k) &= \\log\\big(pe^{-ik} + (1-p)\\big) \\\\\n&= \\log\\big(1 + p(e^{-ik}-1)\\big) \\\\\n&= p(e^{-ik}-1) - \\frac{1}{2} p^2(e^{-ik}-1)^2 + \\cdots \\\\\n&= p\\bigg(-ik + \\frac{(-ik)^2}{2} + \\cdots\\bigg) - \\frac{1}{2} p^2 \\bigg(-ik + \\frac{(-ik)^2}{2} + \\cdots\\bigg)^2 + \\cdots \\\\\n&= -ik p + \\frac{(-ik)^2}{2} p(1-p) + \\cdots\n\\end{align*}\n\\] Thus, the mean and variance of the binomial distribution are just \\[\n\\mu = np, \\quad \\sigma^2 = np(1-p).\n\\] These distributions can be straight-forwardly generalized to situations with more than binomial outcomes. The Bernoulli distribution generalizes to the categorical distribution, where \\(x\\) is allowed to be one of \\(k\\) categories, each with a fixed probability \\(p_j\\). Clearly those probabilities must sum to one. If the categories are \\(x = 1, 2, \\cdots, k\\) the PMF would be given by \\[\np(x) = p_1^{\\delta_{1x}} p_2^{\\delta_{2x}} \\cdots p_k^{\\delta_{kx}}, \\quad x = 1, 2, \\cdots, k.\n\\] The binomial distribution generalizes to the multinomial distribution, where \\(x\\) is now a vector whose jth component is the number of times category \\(j\\) occurred in \\(n\\) total trials. Each \\(x_j = 0, 1, \\cdots, n_j\\) is essentially its own binomial distribution, except we require \\(n = n_1 + n_2 + \\cdots n_k\\). The PMF is given by \\[\np(x) = \\frac{n!}{n_1!n_2!\\cdots n_k!} p_1^{n_1} p_2^{n_2} \\cdots p_2^{n_2}.\n\\] The coefficient \\(\\frac{n!}{n_1!n_2!\\cdots n_k!}\\) is called a multinomial coefficient. It’s a count of the number of ways to distribute \\(n\\) points into \\(k\\) bins such that each bin \\(j\\) contains exactly \\(n_j\\) points. We might say \\(x\\) is multinomially distributed by writing \\(x \\sim \\text{Multinomial}(n_1,n_2,\\cdots,n_k; p_1, p_2, \\cdots, p_k)\\).\n\n\nPoisson Distribution\nSuppose we’re interested in answering the following question: What is the probability that \\(x\\) events occur inside a time interval \\([0,T]\\) provided each event is independent of the others, and that the probability of any one event occurring in an infinitesimal interval \\([0,dt]\\) is a constant \\(\\alpha dt\\). To figure out what \\(p(x)\\) is, let’s imagine subdividing \\([0,T]\\) up into \\(N = \\frac{T}{dt}\\) subintervals. In each subinterval, any single event is a Bernoulli random variable that either occurs with probability \\(\\alpha dt\\) or doesn’t occur with probability \\((1-\\alpha)dt\\). If we assume each subinterval is independent of the others, the characteristic function of \\(p(x)\\) is just \\[\n\\begin{align*}\n\\tilde p(k) &= (\\tilde p_1(k))^N \\\\\n&= \\big(\\alpha e^{-ik}dt + (1-\\alpha)dt\\big)^N \\\\\n&= \\big(1 + \\alpha dt(e^{-ik}-1)\\big)^{T/dt} \\\\\n&\\approx e^{\\alpha T(e^{-ik} - 1)}. \\\\\n\\end{align*}\n\\] The last equality becomes exact when \\(dt\\) is infinitesimal. Let’s define \\(\\lambda \\equiv \\alpha T\\) as a dimensionless rate parameter. Then we can write the characteristic function as \\[\n\\tilde p(k) = e^{\\lambda(e^{-ik} - 1)}.\n\\] To get the sought after PDF \\(p(x)\\) we just need to take the inverse Fourier transform of \\(\\tilde p(k)\\). We have \\[\n\\begin{align*}\np(x) &= \\int_{\\mathbb{R}} \\frac{dk}{2\\pi} \\ \\tilde p(k) e^{ikx} \\\\\n&= \\int_{\\mathbb{R}} \\frac{dk}{2\\pi} \\ e^{\\lambda (e^{-ik}-1)}e^{ikx} \\\\\n&= e^{-\\lambda} \\int_{\\mathbb{R}} \\frac{dk}{2\\pi} \\  e^{ikx} \\sum_{n=0}^\\infty \\frac{(\\lambda e^{-ik})^n}{n!} \\\\\n&= e^{-\\lambda} \\sum_{n=0}^\\infty \\frac{\\lambda^n}{n!} \\int_{\\mathbb{R}} \\frac{dk}{2\\pi} e^{-ik(x-n)} \\\\\n&= e^{-\\lambda} \\sum_{n=0}^\\infty \\frac{\\lambda^n}{n!} \\delta(x-n). \\\\\n\\end{align*}\n\\] The delta function forces \\(x\\) to be a positive integer for \\(p(x)\\) to be non-zero. That is, \\(p(x)\\) is actually a PMF \\[\n\\boxed{p(x) = e^{-\\lambda} \\frac{\\lambda^x}{x!}} \\ .\n\\] This is called the Poisson distribution. The Poisson distribution is used to model counts of events, where each event is allowed to occur independently with some fixed rate \\(\\lambda = \\alpha T\\). We can denote that \\(x\\) is Poisson distributed by writing \\(x \\sim \\text{Poisson}(\\lambda)\\).\nThis distribution has the unusual property that all its cumulants are equal. Indeed, observe we have \\[\n\\log \\tilde p(k) = \\lambda (e^{-ik} - 1) = \\sum_{n=1}^\\infty \\frac{(-ik)^n}{n!} \\lambda.\n\\] That is, all the cumulants are just \\(\\lambda\\). In particular, \\(\\mu = \\sigma^2 = \\lambda\\).",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/probability.html#multivariate-probability",
    "href": "statistical-mechanics/probability.html#multivariate-probability",
    "title": "Probability",
    "section": "Multivariate Probability",
    "text": "Multivariate Probability\n\nRandom Vectors\nLet’s now look at the situation where we have \\(N\\) random variables \\(X_1, X_2, \\cdots, X_N\\). The vector of all such random variables is called a random vector, i.e. a vector \\(\\mathbf{X} = (X_1, X_2, \\cdots, X_N)\\). To each random vector we can assign a joint CDF of the form \\[\nP(\\mathbf{x}) \\equiv \\mathbb{Pr}(\\{\\mathbf{X} \\leq \\mathbf{x}\\}) = \\mathbb{Pr}(\\{X_1 \\leq x_1, X_2 \\leq x_2, \\cdots, X_N \\leq x_N\\}).\n\\] The CDF must be an increasing function in each \\(x_i\\), go to \\(0\\) as all \\(x_i \\rightarrow -\\infty\\), and go to \\(1\\) as all the \\(x_i \\rightarrow \\infty\\).\nIf \\(\\mathbf{X}\\) is discrete, we can assign a joint PMF to each value in the support \\(S \\in \\mathbb{R}^N\\) by defining \\[\n\\boxed{p(\\mathbf{x}) \\equiv \\mathbb{Pr}(\\{\\mathbf{X} = \\mathbf{x}\\})} \\ .\n\\] The joint PMF is a valid probability, meaning it must satisfy \\(0 \\leq p(\\mathbf{n}) \\leq 1\\) and \\(\\sum_{\\mathbf{n} \\in S} p(\\mathbf{n}) = 1\\).\nSimilarly, if \\(\\mathbf{X}\\) is continuous, we can assign a joint PDF to each value in \\(S \\in \\mathbb{R}^N\\) by defining \\[\np(\\mathbf{x}) d^Nx \\equiv \\mathbb{Pr}(\\{x_1 \\leq X_1 \\leq x_1 + dx_1, x_2 \\leq X_2 \\leq x_2 + dx_2, \\cdots, x_N \\leq X_N \\leq x_N + dx_N\\}),\n\\] where \\(d^N x = dx_1dx_2\\cdots dx_N\\) is the \\(N\\)-dimensional volume element. The joint PMF must satisfy both \\(p(\\mathbf{x}) \\geq 0\\), and \\(\\int_S d^N x \\ p(\\mathbf{x}) = 1\\). Clearly the joint PMF is just a special case of the joint PDF, since we can always just use delta functions to express a PMF as a PDF.\nAs with ordinary random variables, we’ll frequently abuse notation by using \\(\\mathbf{x}\\) for both the random vector itself as well as its value where there’s no risk of confusion.\n\n\nJoint Moments and Cumulants\nFor any function \\(F(\\mathbf{x})\\) of a random vector \\(\\mathbf{x}\\) we can define its expectation value as \\[\n\\boxed{\\langle \\mathbf{x} \\rangle \\equiv \\int_S d^N x \\ F(\\mathbf{x}) p(\\mathbf{x})} \\ .\n\\] For both discrete and continuous random vectors we can define the joint characteristic function \\[\n\\boxed{\\tilde p(\\mathbf{k}) \\equiv \\langle e^{-i\\mathbf{k} \\cdot \\mathbf{x}} \\rangle \\equiv \\int_{\\mathbb{R}^N} d^Nx \\ p(\\mathbf{x}) e^{-i\\mathbf{k} \\cdot \\mathbf{x}}} \\ .\n\\] By taking the logarithm of the joint CF, we can also define the joint cumulant function \\(\\log \\tilde p(\\mathbf{k})\\). From these two functions we can extract the joint moments and cumulants. The \\(n_1, n_2, \\cdots, n_N\\) joint moment \\(\\mu_{n_1,n_2,\\cdots,n_N} \\equiv \\langle x_1^{n_1} x_2^{n_2} \\cdots x_N^{n_N} \\rangle\\) of \\(\\mathbf{X}\\) is given by taking partial derivatives of the joint characteristic function, \\[\n\\langle x_1^{n_1} x_2^{n_2} \\cdots x_N^{n_N} \\rangle \\equiv \\frac{\\partial^{n_1}}{\\partial (-i k_1)^{n_1}} \\frac{\\partial^{n_2}}{\\partial (-i k_2)^{n_2}} \\cdots \\frac{\\partial^{n_N}}{\\partial (-i k_N)^{n_N}} \\tilde p(k_1, k_2, \\cdots, k_N) \\bigg |_{k_1=k_2=\\cdots=k_N=0}.\n\\] Similarly, the \\(n_1, n_2, \\cdots, n_N\\) joint cumulant \\(\\kappa_{n_1,n_2,\\cdots,n_N}\\) is given by taking partial derivatives of the joint cumulant function, \\[\n\\kappa_{n_1,n_2,\\cdots,n_N} \\equiv \\frac{\\partial^{n_1}}{\\partial (-i k_1)^{n_1}} \\frac{\\partial^{n_2}}{\\partial (-i k_2)^{n_2}} \\cdots \\frac{\\partial^{n_N}}{\\partial (-i k_N)^{n_N}} \\log \\tilde p(k_1, k_2, \\cdots, k_N) \\bigg |_{k_1=k_2=\\cdots=k_N=0}.\n\\] The sum \\(n \\equiv n_1 + n_2 + \\cdots n_N\\) determines the order of the moment or cumulant. Of particular interest are the first and second cumulants. The first cumulants are the means \\(\\mu_i \\equiv \\langle x_i \\rangle\\). We can think of these together by putting them all into a mean vector \\(\\boldsymbol{\\mu} \\equiv \\langle \\mathbf{x} \\rangle \\equiv \\big(\\mu_1, \\mu_2, \\cdots, \\mu_N\\big)\\). The second cumulants are the covariances, \\(\\sigma_{ij} \\equiv \\kappa_{ij}\\). We can put all these into an \\(N \\times N\\) matrix to get the covariance matrix \\(\\mathbf{\\Sigma} \\equiv \\big(\\sigma_{ij}\\big)_{i,j=1,\\cdots,N}\\). The diagonal entries of the covariance matrix correspond to the usual variances \\(\\sigma_i^2 = \\sigma_{ii}\\). The off diagonal terms are the covariances, capturing the dependence or correlation between \\(x_i\\) and \\(x_j\\).\nWe can use the same graphical trick to express joint cumulants in terms of joint moments. The only difference is we need to label each point by its index and bag them appropriately. We can use this to show that the covariance \\(\\sigma_{ij} \\equiv \\kappa_{ij}\\) can be written as \\[\n\\sigma_{ij} = \\langle x_i x_j \\rangle - \\langle x_i \\rangle \\langle x_j \\rangle = \\langle (x_i - \\mu_i)(x_j - \\mu_j) \\rangle.\n\\] In matrix notation, the entire covariance matrix can be expressed using moments as \\[\n\\boxed{\\mathbf{\\Sigma} = \\langle \\mathbf{x}\\mathbf{x}^\\top \\rangle - \\langle \\mathbf{x} \\rangle \\langle \\mathbf{x} \\rangle^\\top = \\langle (\\mathbf{x}-\\boldsymbol{\\mu})(\\mathbf{x}-\\boldsymbol{\\mu})^\\top \\rangle} \\ .\n\\] This implies the covariance matrix must in fact be a positive semi-definite matrix. That is, \\[\n\\mathbf{\\Sigma} = \\mathbf{\\Sigma}^\\top, \\quad \\mathbf{v}^\\top\\mathbf{\\Sigma}\\mathbf{v} \\geq 0 \\quad \\forall \\mathbf{v} \\neq \\mathbf{0}.\n\\]\n\n\nConditional and Marginal Probability\nWe can get smaller joint probabilities by “summing out” the random variables we don’t need. These are called marginal probabilities or unconditional probabilities. For example, if we have two random variables \\(x\\) and \\(y\\), the marginal PDF \\(p(y)\\) is given by integrating \\(x\\) out of the joint PDF \\(p(x,y)\\), \\[\n\\boxed{p(y) \\equiv \\int_\\mathbb{R} dx \\ p(x,y)} \\ .\n\\] If we have \\(N\\) random variables \\(x_1,x_2,\\cdots, x_s, x_{s+1},\\cdots,x_N\\) and integrate out the last \\(N-s\\) variables \\(x_s, x_{s+1},\\cdots,x_N\\), then we get the marginal PDF \\(p(x_1,x_2,\\cdots, x_s)\\), \\[\np(x_1,x_2,\\cdots, x_s) \\equiv \\int_{\\mathbb{R}^{N-s}} dx_s, dx_{s+1},dx_N \\ p(x_1,x_2,\\cdots, x_s, x_s, x_{s+1},\\cdots,x_N).\n\\] Similarly, we can define the conditional probabilities, which allow for random variables to depend on the outcome of other random variables directly. For example, for two random variables \\(x\\) and \\(y\\) with joint PDF \\(p(x,y)\\), we can define the conditional probability of \\(y\\) given \\(x\\) as \\[\n\\boxed{p(y|x) \\equiv \\frac{p(x,y)}{p(x)}} \\ .\n\\] We can think of \\(p(x,y)\\) as a kind of prior distribution and \\(p(x)\\) as a kind of normalization constant. Notice we can similarly write \\(p(x,y) = p(x|y) p(y)\\). If we plug this into the formula for \\(p(y|x)\\) we get the well-known Bayes’ Rule, which says that \\[\np(y|x) = \\frac{p(x|y)p(y)}{p(x)}.\n\\] If we have \\(N\\) random variables \\(x_1,x_2,\\cdots, x_s, x_{s+1},\\cdots,x_N\\) and want to condition the first \\(s\\) variables on the last \\(N-s\\) variables, we’d similarly write \\[\np(x_1,x_2,\\cdots, x_s) \\equiv \\frac{p(x_1,x_2,\\cdots, x_s, x_{s+1},\\cdots,x_N)}{p(x_{s+1},\\cdots,x_N)}.\n\\] We haven’t proven it, but it’s not hard to show that the marginal and conditional probabilities are indeed valid probabilities and PDFs.\nWhen conditioning a random variable \\(y\\) on another random variable \\(x\\) gives no information about \\(y\\), we say that \\(x\\) and \\(y\\) are independent, sometimes written \\(x \\perp y\\). If \\(x\\) gives no information about \\(y\\), that means we must have \\(p(y|x) = p(y)\\), which is equivalent to saying the joint PDF factors, \\(p(x,y) = p(x) p(y)\\). Clearly, if \\(x\\) gives no information about \\(y\\), then \\(y\\) gives no information about \\(x\\) either. Independence is symmetric.\nMore generally, we say \\(N\\) random variables \\(x_1,x_2,\\cdots,x_N\\) are mutually independent provided \\[\n\\boxed{p(x_1,x_2,\\cdots,x_N) = p_1(x_1) p_2(x_2) \\cdots p_N(x_N)} \\ .\n\\] In the special case where all \\(N\\) variables also happen to come from the same distribution \\(p(x)\\) we say they’re independent identically distributed or IID. In this simple case we just have \\[\np(x_1,x_2,\\cdots,x_N) = \\big(p(x)\\big)^N.\n\\] Independent random variables have the property that their mixed cumulants will always be zero. This is equivalent to saying that the joint expectation of any product of random variables value factors, \\[\n\\langle F_1(x_1) F_2(x_2) \\cdots F_N(x_N) \\rangle = \\langle F_1(x_1) \\rangle \\langle F_2(x_2) \\rangle \\cdots \\langle F_N(x_N) \\rangle.\n\\]\n\n\nThe Multivariate Gaussian Distribution\nWhile there are many joint probability distributions, the most important one to be aware of is the multivariate Gaussian distribution. Suppose \\(\\mathbf{x} = (x_1, x_2, \\cdots, x_N)\\) are independent, with each \\(x_i\\) Gaussian distributed with mean \\(\\mu_i\\) and variance \\(\\sigma_i^2\\). Then it’s easy to show their joint PDF is given by \\[\np(x_1, x_2, \\cdots, x_N) = \\bigg(\\frac{1}{(2\\pi)^N\\sigma_1^2\\sigma_2^2\\cdots\\sigma_N^2}\\bigg)^{1/2} \\exp\\bigg(-\\frac{1}{2} \\sum_{i=1}^N \\frac{(x_i-\\mu_i)^2}{\\sigma_i^2} \\bigg).\n\\] But what if \\(\\mathbf{x}\\) is not independent? All we have to do in that case is make a change of basis. Notice that joint PDF above is just the diagonalized form for the following joint PDF in vector form, \\[\n\\boxed{p(\\mathbf{x}) = \\bigg(\\frac{1}{(2\\pi)^N \\det(\\mathbf{\\Sigma})}\\bigg)^{1/2} \\exp\\bigg(-\\frac{1}{2} (\\mathbf{x} - \\boldsymbol{\\mu})^\\top \\mathbf{\\Sigma}^{-1}(\\mathbf{x} - \\boldsymbol{\\mu}) \\bigg)} \\ .\n\\] By making a change of basis or rotating \\(\\mathbf{\\Sigma}\\), this vectorized PDF gives the most general form of the Gaussian distribution for \\(N\\) variables. This is the multivariate Gaussian distribution, denoted \\(\\mathbf{x} \\sim \\mathcal{N}(\\boldsymbol{\\mu},\\mathbf{\\Sigma})\\).\nUsing the same diagonalization trick, it’s just as easy to show that the joint characteristic function is \\[\n\\boxed{\\tilde p(\\mathbf{k}) = \\exp(-i\\mathbf{k} \\cdot \\boldsymbol{\\mu} - \\frac{1}{2} \\mathbf{k}^\\top \\mathbf{\\Sigma} \\mathbf{k})} \\ ,\n\\] and the joint cumulant is just \\(\\log \\tilde p(\\mathbf{k}) = -i\\mathbf{k} \\cdot \\boldsymbol{\\mu} - \\frac{1}{2} \\mathbf{k}^\\top \\mathbf{\\Sigma} \\mathbf{k}\\). This again implies that only the first and second joint cumulants are non-zero for the multivariate Gaussian. All higher-order terms vanish. For this reason, multivariate Gaussian random variables satisfy a special condition known as Wick’s Theorem.\nWick’s Theorem: Suppose \\(\\mathbf{x} = (x_1, x_2, \\cdots, x_N)\\) is a Gaussian random vector with mean \\(\\boldsymbol{\\mu} = \\mathbf{0}\\). Then the \\(n\\)th joint moments are given by \\[\n\\boxed{\n\\langle x_1^{n_1} x_2^{n_2} \\cdots x_N^{n_N} \\rangle =\n\\begin{cases}\n0 & n = \\text{odd} \\\\\n\\text{sum of all pairwise contractions} & n = \\text{even} \\\\\n\\end{cases}\n} \\ .\n\\] For example, suppose we wanted to calculate \\(\\langle x_1^2 x_2 x_3 \\rangle\\). In this case, the possible pairwise contractions are\n\n\\(x_1 x_1\\) and \\(x_2 x_3\\) , which gives a term \\(\\sigma_{11} \\sigma_{23}\\),\n\\(x_1 x_2\\) and \\(x_1 x_3\\) , which gives a term \\(\\sigma_{12} \\sigma_{13}\\),\n\\(x_1 x_3\\) and \\(x_1 x_2\\) , which gives a term \\(\\sigma_{13} \\sigma_{12}\\).\n\nSumming each of these pairwise contractions together, we just have \\[\n\\langle x_1^2 x_2 x_3 \\rangle = \\sigma_{11} \\sigma_{23} + 2 \\sigma_{12} \\sigma_{13}.\n\\]",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/probability.html#asymptotic-analysis",
    "href": "statistical-mechanics/probability.html#asymptotic-analysis",
    "title": "Probability",
    "section": "Asymptotic Analysis",
    "text": "Asymptotic Analysis\nIn this section we’ll focus on important results that apply for large numbers of random variables \\(N \\gg 1\\).\n\nThe Central Limit Theorem\nIt turns out that the sum of random variables will often by approximately Gaussian distributed provided some minor regularity assumptions are met. This important result is called the central limit theorem.\nCentral Limit Theorem: Suppose \\(x = \\sum_{i=1}^N x_i\\) is a sum of \\(N\\) IID random variables with finite mean \\(\\mu\\) and variance \\(\\sigma^2\\). Then when \\(N \\gg 1\\) the probability density satisfies \\[\n\\boxed{p\\bigg(\\frac{x-N\\mu}{\\sqrt{N\\sigma^2}}\\bigg) \\approx \\frac{1}{\\sqrt{2 \\pi}} \\exp\\bigg(-\\frac{1}{2}\\bigg(\\frac{x-N\\mu}{\\sqrt{N\\sigma^2}}\\bigg)^2\\bigg)} \\ .\n\\] Proof: Suppose each \\(x_i\\) is IID with distribution \\(p_1(x_1)\\). The characteristic function for \\(p(x)\\) must then be \\[\n\\tilde p(k) = \\langle e^{-i kx} \\rangle = \\langle e^{-i k\\sum_{i=1}^N x_i} \\rangle = \\prod_{i=1}^N \\langle e^{-i k x_i} \\rangle = \\tilde p(k_1, k_2, \\cdots, k_N) \\bigg |_{k_1=k_2=\\cdots=k_N=k}.\n\\] If we take the cumulant function \\(\\log \\tilde p(k)\\) and expand it out directly, we have \\[\n\\log \\tilde p(k) = \\sum_{n=1}^\\infty \\frac{(-ik)^n}{n!} \\kappa_n(x) = -ik \\kappa_1(x) + \\frac{(-ik)^2}{2} \\kappa_2(x) + \\cdots\n\\] Expanding out the cumulant function \\(\\log \\tilde p(k_1, k_2, \\cdots, k_N)\\) and setting all \\(k_i=k\\), we have \\[\n\\begin{align*}\n\\log \\tilde p(k_1, k_2, \\cdots, k_N) &= \\sum_{n=0}^\\infty \\sum_{\\sum n_j=n} \\frac{(-ik_1)^{n_1} (-ik_2)^{n_2} \\cdots (-ik_N)^{n_N}}{n!} \\kappa_{n_1 n_2 \\cdots n_N} \\bigg |_{k_1=k_2=\\cdots=k_N=k} \\\\\n&= \\sum_{n=0}^\\infty \\sum_{\\sum n_j=n} \\frac{(-ik)^n}{n!} \\kappa_{n_1 n_2 \\cdots n_N} \\\\\n&= (-ik) \\sum_{\\sum n_j=1} \\kappa_{n_1 n_2 \\cdots n_N} + \\frac{(-ik)^2}{2} \\sum_{\\sum n_j=2} \\kappa_{n_1 n_2 \\cdots n_N} + \\cdots\n\\end{align*}\n\\] Equating the two equations, we thus have \\[\n\\kappa_n(x) = \\sum_{\\sum n_j=n} \\kappa_{n_1 n_2 \\cdots n_N}.\n\\] That is, the \\(n\\)th cumulant of the sum is the sum of all the joint \\(n\\)th cumulants. Now, suppose all the \\(x_i\\) are independent. Then their joint PDF must factor as \\[\np(x_1,x_2,\\cdots,x_N) = p_1(x_1) p_2(x_2) \\cdots p_N(x_N).\n\\] Moreover, since their mixed cumulants must be zero, the cumulants of the sum further reduce to \\[\n\\kappa_n(x) = \\sum_{i=1}^N \\kappa_n(x_i),\n\\] Now suppose all the \\(x_i\\) are identically distributed with the same PDF \\(p_1(x_i)\\). Then we further have just \\[\n\\kappa_n = N \\kappa_{n,i}.\n\\] Define another random variable \\(y\\) by re-centering and rescaling \\(x\\) as \\[\nz \\equiv \\frac{x - N\\mu}{\\sqrt{N\\sigma^2}}.\n\\] Then the cumulants of \\(z\\) are given by \\[\n\\begin{align*}\n\\kappa_1(z) &= 0, \\\\\n\\kappa_2(z) &= 1, \\\\\n\\kappa_n(z) &= \\frac{N\\kappa_n(x_1)}{(N\\sigma^2)^{n/2}} = O\\big(N^{1-n/2}\\big). \\\\\n\\end{align*}\n\\] The higher order cumulants of \\(z\\) evidently go to zero when \\(N \\gg 1\\). But we already know the only distribution whose higher moments are zero is the Gaussian distribution. Thus, we’ve shown \\[\np(z) \\approx \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{z^2}{2}}. \\qquad \\text{Q.E.D.}\n\\] Note the central limit theorem is also true for non-IID random variables, provided the higher cumulants decay as \\(\\kappa_n(x) = O(N^{n/2})\\).\nIn the proof of the CLT we implicitly assumed that the cumulants were all finite. What if that weren’t the case? This will happen if the PDF of each \\(x_i\\) is heavy-tailed. Heavy-tailed distributions are commonly used to model rare events. It turns out then that the sum won’t in general converge to a Gaussian. In fact, if it does converge, it’ll converge to a Levy distribution, a general class of heavy-tailed distributions.\n\n\nThe Saddlepoint Approximation\nIn the section on thermodynamics, we saw both intensive variables and extensive variables. The intensive variables are ones that don’t depend on particle number at all, i.e. they’re \\(O(1)\\) functions of \\(N\\). The extensive variables are linear in particle number, i.e. they’re \\(O(N)\\). In principle we could imagine other functional dependences on \\(N\\) as well. For example, a variable could be polynomial in \\(N\\), i.e. \\(O(N^p)\\) for some \\(p\\). More importantly, a variable can be exponential in \\(N\\), i.e. \\(O(e^{N\\phi})\\) for some \\(\\phi\\). For example, the volume of a gas would be a variable that can scale exponentially with \\(N\\), since it often goes like \\(V^N\\).\nWhen \\(N \\gg 1\\), the sum of many exponential variables can be well approximated by the maximum term. Suppose we have \\(n\\) non-negative variables \\(x_1,x_2,\\cdots,x_n\\) of the form \\(x_i \\sim e^{N\\phi_i}\\) as \\(N \\rightarrow \\infty\\). Then their sum \\(S = \\sum x_i\\) satisfies \\[\nS \\sim x_{max} = \\max_{i=1,\\cdots,n} x_i, \\quad \\text{when} \\quad N \\rightarrow \\infty.\n\\] When each \\(x_i = A_i e^{N\\phi_i}\\), this just says \\(S \\approx A_{max} e^{N\\phi_{max}}\\) when \\(N \\gg 1\\). To see why this fact is true, note that since each \\(x_i \\geq 0\\), we must have \\(x_{max} \\leq S \\leq nx_{max}\\). Since the logarithm is monotonic, if we take the log of each term and divide by \\(N\\), we have \\[\n\\frac{\\log x_{max}}{N} \\leq \\frac{\\log S}{N} \\leq \\frac{\\log x_{max}}{N} + \\frac{\\log n}{N}.\n\\] If we take \\(N \\rightarrow \\infty\\) while holding \\(n\\) fixed, then the term \\(\\frac{\\log n}{N} \\rightarrow 0\\), which gives \\[\n\\frac{\\log S}{N} \\sim \\frac{\\log x_{max}}{N} = \\phi_i.\n\\]\nMore useful for our purposes will be the continuous analog of this result, the saddlepoint approximation.\nSaddlepoint Approximation: Suppose we have a function of the form \\(f(x) = e^{N\\phi(x)}\\) where \\(\\phi(x)\\) grows polynomially. Then we have \\[\n\\boxed{S = \\int_\\mathbb{R} dx \\ e^{N\\phi(x)} \\sim \\sqrt{\\frac{2\\pi}{N|\\phi''(x_{max})|}} e^{N\\phi_{max}}} \\ , \\quad \\text{as} \\ \\ N \\rightarrow \\infty.\n\\] Proof: To see why this is true let’s first Taylor expand \\(\\phi(x)\\) around its global maximum \\(x_{max}\\). Since \\(\\phi'(x_{max}) = 0\\) and \\(\\phi''(x_{max}) \\leq 0\\), we have \\[\n\\phi(x) = \\phi(x_{max}) - \\frac{1}{2} |\\phi''(x_{max})| (x-x_{max})^2 + O\\big((x-x_{max})^3\\big).\n\\] Plugging this into the integral and simplifying then gives \\[\n\\begin{align*}\nS &= \\int_\\mathbb{R} dx \\ \\exp\\bigg(N\\phi_{max} - \\frac{N}{2} |\\phi''(x_{max})| (x-x_{max})^2 + \\frac{N}{6} |\\phi'''(x_{max})| (x-x_{max})^3 + \\cdots\\bigg) \\\\\n&= \\int_\\mathbb{R} dx \\ \\exp\\bigg(N\\phi_{max} - \\frac{N}{2} |\\phi''(x_{max})| (x-x_{max})^2\\bigg) \\exp\\bigg(\\frac{N}{6} |\\phi'''(x_{max})| (x-x_{max})^3 + \\cdots\\bigg) \\\\\n&= e^{N\\phi_{max}} \\int_\\mathbb{R} dx \\ \\exp\\bigg(- \\frac{N}{2} |\\phi''(x_{max})| (x-x_{max})^2\\bigg) \\bigg(1 + \\frac{N}{6}|\\phi'''(x_{max})|(x-x_{max})^3 + \\cdots\\bigg) \\\\\n&= e^{N\\phi_{max}} \\sqrt{\\frac{2\\pi}{N|\\phi''(x_{max})|}} \\bigg(1 + O\\bigg(\\frac{1}{N}\\bigg)\\bigg).\n\\end{align*}\n\\] The last line follows from the fact that the integral with \\((x-x_{max})^3\\) vanishes since it’s an odd function, which means the next term \\((x-x_{max})^4\\) has to be considered, which integrates to order \\(O\\big(N^{-3/2}\\big)\\).\nNow, let’s again look at \\(\\frac{\\log S}{N}\\) as \\(N \\rightarrow \\infty\\). We have \\[\n\\frac{\\log S}{N} = \\phi_{max} - \\frac{1}{2N} \\log \\frac{N|\\phi''(x_{max})|}{2\\pi} + O\\bigg(\\frac{1}{N^2}\\bigg).\n\\] We can see that as \\(N \\rightarrow \\infty\\), \\(\\frac{\\log S}{N} \\rightarrow \\phi_{max}\\) with a correction of order \\(O\\big(\\frac{\\log N}{N}\\big)\\). \\(\\text{Q.E.D.}\\)\nIt’s interesting to observe that only the global maximum appears in this approximation. What if \\(\\phi(x)\\) had some other local maximum \\(\\phi(x_{max}')\\)? Strictly speaking we’d have to do the same approximation scheme about each of the maxima one-by-one. However, due to the presence of the exponential, if \\(\\phi(x_{max}') &lt; \\phi(x_{max})\\), then for large \\(N\\) we’d have \\[\ne^{N\\phi(x_{max}')} \\ll e^{N\\phi(x_{max})}.\n\\] In the limit where \\(N \\rightarrow \\infty\\), the correction term \\(e^{-N\\big(\\phi(x_{max})-\\phi(x_{max}')\\big)} \\rightarrow 0\\). In this sense, we can indeed neglect the other local maxima as long as they’re less than \\(\\phi(x_{max})\\) and \\(N \\gg 1\\).\n\n\n\n\n\nBy far the most useful corollary to this result for our purposes is the Stirling Approximation.\nStirling Approximation: As \\(N \\rightarrow \\infty\\), we have \\[\n\\boxed{N! \\sim N^N e^{-N} \\sqrt{2\\pi N}} \\ .\n\\] Proof: Observe by induction that we can write \\(N!\\) as the following integral, \\[\nN! = \\int_0^\\infty dx \\ x^N e^{-x} = \\int_0^\\infty dx \\ \\exp\\bigg(N\\bigg(\\log x - \\frac{x}{N}\\bigg)\\bigg).\n\\] Take \\(\\phi(x) = \\log x - \\frac{x}{N}\\). This function is maximized when \\(x_{max} = N\\), where \\(\\phi_{max} = \\log N - 1\\). At this point we have \\(\\phi''(x_{max}) = - \\frac{1}{N^2}\\). Plugging all this into the saddlepoint approximation, we have \\[\n\\begin{align*}\nN! &= e^{N(\\log N - 1)} \\sqrt{\\frac{2\\pi}{N|-N^{-2}|}} \\bigg(1 + O\\bigg(\\frac{1}{N}\\bigg)\\bigg) \\\\\n&= N^N e^{-N} \\sqrt{2\\pi N} \\bigg(1 + O\\bigg(\\frac{1}{N}\\bigg)\\bigg). \\quad \\text{Q.E.D.}\n\\end{align*}\n\\] Usually we’ll be more interested in \\(\\log N!\\) rather than \\(N!\\) itself. In that case we just have \\[\n\\log N! = N \\log N - N + \\frac{1}{2} \\log 2\\pi N + O\\bigg(\\frac{1}{N}\\bigg).\n\\] We’ll typically imagine \\(N\\) to be really big, like \\(N \\sim 10^{23}\\). In that case we can generally neglect the sublinear terms and write \\[\n\\boxed{\\log N! \\approx N\\log N - N} \\ .\n\\] This will usually be the form of Stirling’s approximation that we use in statistical mechanics. We’ll often write Stirling’s approximation in exponentiated form like this as well, where it’s understood what we really mean is the two sides equal only logarithmically as above, \\[\nN! \\sim N^N e^{-N}.\n\\]",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/probability.html#information-theory",
    "href": "statistical-mechanics/probability.html#information-theory",
    "title": "Probability",
    "section": "Information Theory",
    "text": "Information Theory\n\nInformation and Entropy\nWe can think about probabilities in a completely different sense by thinking about the information content contained in a system and how uncertain we are about what that information content is. Suppose we wanted to transmit a message containing \\(N\\) characters, where each character is sampled from some alphabet \\(\\Sigma\\) containing \\(M\\) total characters. We’d like to ask the following question: How many bits of information does a typical message of \\(N\\) characters from this alphabet contain?\nSuppose we had no information at all about how often any one particular character \\(x_m \\in \\Sigma\\) occurs in a message. In this case, we’d have to assume that all messages of length \\(N\\) are typical. Since there are \\(M^N\\) possible messages of length \\(N\\), we’d say there are \\(g = M^N\\) typical messages. Since \\(g\\) contains \\(\\log_2 g\\) bits of information, this means a typical message would contain \\(\\log g = N \\log_2 M\\) bits of information.\nSuppose now that we had an estimate of the frequency \\(p_m\\) that each character \\(x_m \\in \\Sigma\\) occurs in a message. That is, in a message of length \\(N\\), we expect each character \\(x_m\\) to occur \\(N_m \\approx Np_m\\) total times, or to be more precise \\(N_m = Np_m + O\\big(\\sqrt{N}\\big)\\) since each character is a Bernoulli random variable, hence a message of length \\(N\\) is a binomial random variable. In this case, the number of typical messages is just the number of ways of placing \\(N\\) random characters into \\(M\\) bins of sizes \\(N_1, N_2, \\cdots, N_M\\), which is \\[\ng = \\frac{N!}{\\prod_{m=1}^M N_m!}.\n\\] The total number of bits contained in a typical message would then be \\(\\log_2 g\\). If we assume the message length \\(N\\) is large compared to the alphabet size \\(M\\), then we can apply the Stirling approximation to each term containing a factorial. Using the fact \\(N_m = Np_m\\) and \\(\\sum N_m = N\\), we have \\[\n\\begin{align*}\n\\log_2 g &= \\log_2 N! - \\sum_{m=1}^M \\log_2 N_m! \\\\\n&\\approx \\big(N\\log_2 N - N\\big) - \\sum_{m=1}^M \\big(N_m \\log_2 N_m - N_m \\big) \\\\\n&\\approx N \\log_2 N - \\sum N_m \\log_2 N_m \\\\\n&\\approx - N \\sum_{m=1}^M p_m \\log_2 p_m.\n\\end{align*}\n\\] The term \\(-\\sum p_m \\log_2 p_m\\) is just a function of the underlying probability distribution of characters, not of the message length \\(N\\) itself. It captures our uncertainty or surprise in what message we’d receive. We call this term the information entropy or Shannon entropy. Since the choice of base for the logarithm merely adds a constant to this sum, in physics we more typically use the natural logarithm instead of the base-2 logarithm, which expresses entropy in nats instead of bits. In this form, the information entropy can be defined as \\[\n\\boxed{S \\equiv -\\sum_{m=1}^M p_m \\log p_m} \\ .\n\\] We’ve thus answered the question sought: a typical message of length \\(N\\) contains about \\(\\log_2 g \\approx NS\\) bits of information, up to an additive constant that depends on the base of logarithm. Notice that if we knew exactly which message to expect, that would mean \\(g = 1\\), which means \\(S = 0\\). Since we already know the most number of messages possible is \\(g=M^N\\), the information entropy must evidently satisfy \\[\n0 \\leq S \\leq N \\log M.\n\\] In thermodynamics, the information entropy corresponds to the mixing entropy up to a factor of Boltzmann’s constant \\(k_B\\). One implication of this is that while information entropy is dimensionless, thermodynamic entropy has units, namely units of \\(k_B\\), which is energy per degree.\nThe terms \\(I_m \\equiv -\\log p_m\\) capture the information content contained in any one particular character \\(x_m\\). If \\(p_m \\approx 0\\) then \\(I_m \\approx \\infty\\), meaning \\(x_m\\) contains an infinite number of bits of new information relative to what we already know. If \\(p_m \\approx 1\\) then \\(I_m \\approx 0\\), meaning \\(x_m\\) contains no new bits of information. We can thus also think of the entropy as the expected information content of a message, since \\[\nS = -\\sum_{m=1}^M p_m \\log p_m = -\\langle \\log p \\rangle = \\langle I \\rangle.\n\\] While information theory was built around the idea of transmitting messages, there’s nothing inherently limiting these ideas to messages alone. We can apply the concept of entropy as defined to any discrete probability distribution, where each \\(x_m\\) corresponds to some value taken on by a random variable.\nWhat about continuous distributions though? We can try to extend entropy to these as well, but we have to be careful. Since density functions needn’t be positive, the entropy will no longer in general be positive either, meaning it doesn’t make sense to think about it as a direct measure of information content. Nevertheless, we could define the information entropy of a continuous distribution as \\[\n\\boxed{S \\equiv -\\int_{\\mathbb{R}} dx \\ p(x) \\log p(x)} \\ .\n\\] From a physical perspective, a more troublesome problem with this definition is that in general \\(dx\\) will have units, which means \\(p(x)\\) will have units as well. But we can’t have a function with units inside a logarithm. The right way to deal with this will be to convert \\(dx\\) to some kind of dimensionless measure so that \\(p(x)\\) will also be dimensionless. For example, in statistical mechanics we’ll usually be looking at distributions over phase space, where the integration measure is \\(d\\Gamma \\propto d^3 x d^3 p\\). In this case, we’d need to divide by a constant that has units of \\([xp]\\). We’ll see from quantum mechanics that the correct constant is in fact Planck’s constant \\(h\\). That is, the right integration measure is \\[\nd\\Gamma = \\frac{d^3 x d^3 p}{h^3}.\n\\] ### The Principle of Maximum Entropy\nWe can use the idea of information entropy to finally answer the question regarding what the correct way is to define probabilities subjectively or theoretically. The idea is to use the principle of maximum entropy.\nPrinciple of Maximum Entropy: The unbiased assignment of probability is the one that maximizes the information entropy subject to known constraints. More formally, assign a probability distribution \\(p(x)\\) that maximizes the constrained problem \\[\n\\boxed{\n\\begin{align*}\n&\\max_{p(x)} S[p(x)] =  \\max_{p(x)} \\bigg(- \\sum_{x \\in \\mathcal{S}} p(x) \\log p(x) \\bigg) \\\\\n&\\text{subject to} \\ \\sum_{x \\in \\mathcal{S}} p(x) = 1 \\ \\text{and} \\ g(x) = 0 \\\\\n\\end{align*}\n} \\ .\n\\] where \\(g(x) = 0\\) is any set of known constraints on the probability distribution. The first constraint that probabilities sum to one will always be there so that \\(p(x)\\) yields a valid probability function.\nThis is in essence just a generalization of the principle of indifference. If we don’t have any information to go on, we should assume all outcomes have equal probability. The principle of maximum entropy extends this idea to general distributions where we might know some information, like what its mean or variance is, or what range it’s bounded to.\nUsing Lagrange multipliers, the principle of maximum entropy is equivalent to maximizing the Lagrange multiplier function \\[\nL(p(x),\\lambda) \\equiv - \\sum_{x \\in \\mathcal{S}} p(x) \\log p(x) - \\alpha \\bigg(\\sum_{x \\in \\mathcal{S}} p(x) - 1\\bigg) - \\beta \\cdot g(x).\n\\] subject to \\(p(x)\\) and \\(\\alpha\\) and \\(\\beta\\).\nExample: Let’s formally prove the principle of indifference using the principle of maximum entropy. That is, in the absence of no known information, the unbiased probabilities to assign are the ones where each outcome has an equal probability to occur. Suppose the random variable is discrete with \\(n\\) outcomes of probabilities \\(p_1, p_2, \\cdots, p_n\\). In this case, the problem to solve is \\[\n\\begin{align*}\n&\\max_{p} \\bigg(- \\sum_{i=1}^n p_i \\log p_i \\bigg) \\\\\n&\\text{subject to} \\ \\sum_{i=1}^n p_i = 1.\n\\end{align*}\n\\] This is equivalent to maximizing the Lagrange multiplier function \\[\nL(p,\\alpha) \\equiv - \\sum_{i=1}^n p_i \\log p_i - \\alpha \\bigg(\\sum_{i=1}^n p_i - 1\\bigg).\n\\] Differentiating with respect to each \\(p_j\\) and \\(\\alpha\\) and setting the derivatives to zero, we have \\[\n\\begin{align*}\n\\frac{\\partial L}{\\partial p_j} &= -\\log p_j - 1 - \\alpha \\equiv 0\\\\\n\\frac{\\partial L}{\\partial \\alpha} &= \\sum_{i=1}^n p_i - 1 \\equiv 0\\\\\n\\end{align*}\n\\] Solving this system of equations implies that \\[\n\\sum_{j=1}^n p_j = \\sum_{j=1}^n e^{-(1+\\alpha)} = 1 \\quad \\Longrightarrow \\quad e^{1+\\alpha} = n.\n\\] Thus, the maximum entropy probabilities are just \\(p_j = \\frac{1}{n}\\) for all \\(j\\), as expected.\nThe same method can be used in the continuous case as well by replacing the sums \\(\\sum_{i=1}^n p_i\\) by integrals \\(\\int_a^b dx \\ p(x)\\). The main subtlety to be aware of in the continuous case is that we’re no longer maximizing a function of \\(n\\) probabilities, but a functional of the form \\(S[p(x)]\\) over all possible functions \\(p(x)\\). These can be solved for \\(p(x)\\) by finding the choice of \\(p(x)\\) that extremizes the functional \\(S[p(x)]\\). In that case, the maximum entropy probabilities will turn out to be \\(p(x) = \\frac{1}{b-a}\\) as expected.\nExample: Here’s an interesting example involving continuous distributions. Suppose we knew that a random variable \\(x\\) on the real line had a given mean \\(\\mu\\) and variance \\(\\sigma^2\\). What is the maximum entropy distribution \\(p(x)\\) such that these two cumulants are known? The problem to solve is now \\[\n\\begin{align*}\n&\\max_{p(x)} \\bigg(- \\int_\\mathbb{R} dx \\ p(x) \\log p(x) \\bigg) \\\\\n&\\text{subject to} \\ \\int_\\mathbb{R} dx \\ p(x) = 1, \\\\\n&\\text{and} \\int_\\mathbb{R} dx \\ x p(x) = \\mu, \\ \\ \\int_\\mathbb{R} dx \\ x^2 p(x) - \\mu^2 = \\sigma^2. \\\\\n\\end{align*}\n\\] The Lagrange multiplier function is then \\[\n\\begin{align*}\nL(p(x),\\alpha,\\beta,\\gamma) = -&\\bigg(\\int_\\mathbb{R} dx \\ p(x) \\log p(x) \\bigg) - \\alpha\\bigg(\\int_\\mathbb{R} dx \\ p(x) - 1\\bigg) \\\\\n- \\beta&\\bigg(\\int_\\mathbb{R} dx \\ x p(x) - \\mu\\bigg) - \\gamma \\bigg(\\int_\\mathbb{R} dx \\ x^2 p(x) - \\mu^2 - \\sigma^2\\bigg).\n\\end{align*}\n\\] To maximize this function, consider a functional perturbation \\(p + \\delta p\\). Notice every term is linear in \\(p\\) except the first term, which is \\(p \\log p\\). In that term, we have \\[\n\\begin{align*}\n(p + \\delta p) \\log (p + \\delta p) &= (p + \\delta p) \\log(1 + \\frac{\\delta p}{p}) \\log p \\\\\n&= (p + \\delta p) \\bigg(1 + \\frac{\\delta p}{p}\\bigg) \\log p \\\\\n&= p \\log p + \\delta p (\\log p + 1) + O(\\delta p^2).\n\\end{align*}\n\\] If we ignore terms of order higher than \\(\\delta p\\), then solving for \\(\\delta L\\) and setting it to zero gives \\[\n\\begin{align*}\n\\delta L &= L(p + \\delta p,\\alpha,\\beta,\\gamma) - L(p,\\alpha,\\beta,\\gamma) \\\\\n&= -\\int_\\mathbb{R} dx \\delta p \\ \\bigg[\\log p + 1 + \\alpha + \\beta x + \\gamma(x^2 - 2\\mu x) \\bigg] \\equiv 0.\n\\end{align*}\n\\] Since this must be true for any perturbation \\(\\delta p\\), the integrand must be zero, \\[\n\\log p + 1 + \\alpha + \\beta x + \\gamma(x^2 - 2\\mu x) = 0.\n\\] Solving then for \\(p(x)\\) we have \\[\np(x) = \\exp\\big(-1 - \\alpha - \\beta x - \\gamma(x^2 - 2\\mu x)\\big).\n\\] The exponent is just a quadratic function of \\(x\\), hence we can rewrite \\(p(x)\\) in terms of new constants as \\[\np(x) = \\mathcal{N} \\exp\\bigg(-\\frac{(x-a\\mu)^2}{2b\\sigma^2}\\bigg).\n\\] Since this has the form of a Gaussian, integrating over the real line gives a normalization constant of the form \\(\\mathcal{N} = (2\\pi b \\sigma^2)^{-1/2}\\). Similarly, by shift invariance, integrating the mean function requires that \\(a=1\\). Last, the variance constraint requires that \\(b=1\\). We’ve thus shown that the continuous probability distribution whose mean and variance are known must be a Gaussian distribution.\nExample: Let’s do one more example that’s very relevant to statistical mechanics. Suppose we have a discrete random variable \\(x\\) that can take on a possibly countably infinite number of values. Suppose we know that some positive function \\(E(x) \\geq 0\\) of \\(x\\) has expectation \\(\\langle E(x) \\rangle = E\\). Then the problem to solve is \\[\n\\begin{align*}\n&\\max_p \\bigg(- \\sum_{i=0}^\\infty p_i \\log p_i \\bigg) \\\\\n&\\text{subject to} \\ \\sum_{i=0}^\\infty p_i = 1, \\ \\text{and} \\ \\sum_{i=0}^\\infty p_i E_i = E. \\\\\n\\end{align*}\n\\] The Lagrange multiplier function is then given by \\[\nL(p,\\alpha) \\equiv - \\sum_{i=0}^\\infty p_i \\log p_i - \\alpha \\bigg(\\sum_{i=0}^\\infty p_i - 1\\bigg) - \\beta \\bigg(\\sum_{i=0}^\\infty p_i E_i - E\\bigg).\n\\] Differentiating with respect to each \\(p_j\\), \\(\\alpha\\), and \\(\\beta\\) and setting all the derivatives to zero, we have \\[\n\\begin{align*}\n\\frac{\\partial L}{\\partial p_j} &= -\\log p_j - 1 - \\alpha - \\beta E_i \\equiv 0, \\\\\n\\frac{\\partial L}{\\partial \\alpha} &= \\sum_{i=0}^\\infty p_i - 1 \\equiv 0, \\\\\n\\frac{\\partial L}{\\partial \\alpha} &= \\sum_{i=0}^\\infty p_i E_i - E \\equiv 0. \\\\\n\\end{align*}\n\\] Together, these imply that the probabilities must have the form \\[\np_j = e^{-(1+\\alpha)} e^{-\\beta E_j}.\n\\] Again, the factor \\(e^{-(1+\\alpha)}\\) is just a normalization constant. If we redefine it to be \\(\\frac{1}{Z}\\), then we finally have \\[\np_j = \\frac{1}{Z} e^{-\\beta E_j},\n\\] where by normalization \\(Z\\) must satisfy the relation \\[\nZ = \\sum_{i=0}^\\infty e^{-\\beta E_i}.\n\\] More generally, we could imagine \\(\\mathbf{E}(x)\\) being a vector-valued function, in which case the same results apply just be replacing the scalars \\(\\beta E_i\\) with vectors \\(\\boldsymbol{\\beta} \\cdot \\mathbf{E}_i\\). We’ll see later that the normalization constant \\(Z\\) is very important to statistical mechanics. It’s called the partition function. In that case, \\(E_j\\) represents the energy of the system in the \\(j\\)th state and \\(E\\) represents the average internal energy of the system, i.e. the energy that satisfies the first law of thermodynamics.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/kinetic-theory.html",
    "href": "statistical-mechanics/kinetic-theory.html",
    "title": "Kinetic Theory",
    "section": "",
    "text": "Hamiltonian Mechanics\nTo start, we’ll review the classical mechanics of particles via the Hamiltonian formulation.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Kinetic Theory</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/kinetic-theory.html#hamiltonian-mechanics",
    "href": "statistical-mechanics/kinetic-theory.html#hamiltonian-mechanics",
    "title": "Kinetic Theory",
    "section": "",
    "text": "Hamilton’s Equations\nConsider a system with \\(3N\\) degrees of freedom. For simplicity, we’ll assume the generalized coordinates are just the ordinary position vectors \\(\\mathbf{x}_i\\) and ordinary momentum vectors \\(\\mathbf{p}_i\\) for a given particle \\(i\\). In that case, \\(N\\) represents the number of particles in the system. Let \\(\\mathbf{x} \\equiv (\\mathbf{x}_1,\\mathbf{x}_2,\\cdots,\\mathbf{x}_N)\\) and \\(\\mathbf{p} \\equiv (\\mathbf{p}_1,\\mathbf{p}_2,\\cdots,\\mathbf{p}_N)\\). The \\(6N\\)-dimensional vector \\((\\mathbf{x}, \\mathbf{p})\\) characterizes the state of the system. The state is also a point in an abstract \\(6N\\)-dimensional space, called the phase space of the system.\nAssuming the system is conservative, the dynamics of the system are completely determined by the joint Hamiltonian \\(H = H(\\mathbf{x}, \\mathbf{p})\\). We can then in principle solve for the microscopic equations of motion \\(\\big(\\mathbf{x}(t), \\mathbf{p}(t)\\big)\\) by solving Hamilton’s equations, a system of \\(6N\\) differential equations given by \\[\n\\boxed{\\mathbf{\\dot x} = \\frac{\\partial H}{\\partial \\mathbf{p}}, \\quad \\mathbf{\\dot p} = -\\frac{\\partial H}{\\partial \\mathbf{x}}} \\ .\n\\] Said differently, the Hamiltonian induces a flow on the phase space, with the flow described by Hamilton’s equations. Each flow represents the time evolution of a particular state, determined by the initial conditions.\nIt’s important to note that the microscopic equations of motion are time reversal invariant. That is, if the momenta are reversed, \\(\\mathbf{p} \\rightarrow -\\mathbf{p}\\), then the trajectories also reverse, \\(\\mathbf{x}(t) \\rightarrow \\mathbf{x}(-t)\\). This is because the Hamiltonian \\(H(\\mathbf{x},\\mathbf{p})\\) is invariant to time reversal transformations \\((\\mathbf{x}, \\mathbf{p}) \\rightarrow (\\mathbf{x}, -\\mathbf{p})\\). Why is this important to note? Because thermodynamics is not time reversal invariant. Once an isolated system is in equilibrium it will stay in equilibrium. We thus need to figure out how this time reversal invariance property gets lost in the thermodynamic limit.\n\n\nPoisson Brackets\nFor two functions \\(F(\\mathbf{x}, \\mathbf{p})\\) and \\(G(\\mathbf{x}, \\mathbf{p})\\) defined on phase space, define their Poisson bracket by \\[\n\\boxed{\\{F, G\\} \\equiv \\frac{\\partial F}{\\partial \\mathbf{x}} \\cdot \\frac{\\partial G}{\\partial \\mathbf{p}} - \\frac{\\partial G}{\\partial \\mathbf{x}} \\cdot \\frac{\\partial F}{\\partial \\mathbf{p}}} \\ .\n\\] It’s easy to show that the Poisson bracket is anti-symmetric, i.e. \\(\\{F,G\\} = -\\{G,F\\}\\). It’s also bilinear, \\[\n\\begin{align*}\n\\{aF+bG,J\\} &= a\\{F,J\\} + b\\{G,J\\}, \\\\\n\\{F, aG + bJ\\} &= a\\{F,G\\} + b\\{F,J\\}. \\\\\n\\end{align*}\n\\] The Poisson bracket also satisfies the product rule, \\[\n\\frac{d}{dt} \\{F,G\\} = \\bigg\\{\\frac{dF}{dt}, G\\bigg\\} + \\bigg\\{F, \\frac{dG}{dt}\\bigg\\}.\n\\] The total time derivative of any function \\(F(\\mathbf{x}, \\mathbf{p})\\) is given by its Poisson bracket with the Hamiltonian, \\[\n\\frac{dF}{dt} = \\{F, H\\}.\n\\] Evidently, if \\(F\\) is a conserved quantity, its Poisson bracket with \\(H\\) must vanish, i.e. \\(\\{F,H\\} = 0\\). By Taylor expanding, it’s also possible to show that the Poisson bracket of any function of \\(F\\) with \\(H\\) must vanish, i.e. that \\(\\{f(F), H\\} = 0\\) for any analytic function \\(f(F)\\).\nOne result that we’ll frequently use is that the integral of a Poisson bracket \\(\\{F,H\\}\\) vanishes when integrated over an unbounded region of phase space (which is almost always the case). Denote the \\(3N\\)-dimensional phase space volume element by \\(d\\Gamma \\equiv d^{3N} \\mathbf{x} \\ d^{3N} \\mathbf{p}\\). Then we have \\[\n\\int d\\Gamma \\ \\{F,H\\} = 0.\n\\] To see why this is true we just use the definition of the Poisson bracket and integration by parts, \\[\n\\begin{align*}\n\\int d\\Gamma \\ \\{F,H\\} &= \\int d\\Gamma \\ \\bigg(\\frac{\\partial F}{\\partial \\mathbf{x}} \\cdot \\frac{\\partial H}{\\partial \\mathbf{p}} - \\frac{\\partial H}{\\partial \\mathbf{x}} \\cdot \\frac{\\partial F}{\\partial \\mathbf{p}}\\bigg) \\\\\n&= \\int d\\Gamma \\ \\frac{\\partial H}{\\partial \\mathbf{p}} \\cdot \\frac{\\partial F}{\\partial \\mathbf{x}} - \\int d\\Gamma \\ \\frac{\\partial H}{\\partial \\mathbf{x}} \\cdot \\frac{\\partial F}{\\partial \\mathbf{p}} \\\\\n&= -\\int d\\Gamma \\ \\frac{\\partial^2 H}{\\partial \\mathbf{x}\\partial \\mathbf{p}} F + \\int d\\Gamma \\ \\frac{\\partial^2 H}{\\partial \\mathbf{p}\\partial \\mathbf{x}} F + (\\text{boundary terms}). \\\\\n\\end{align*}\n\\] Since second partials commute, the two integrals cancel each other. Since \\(H\\) is a Hamiltonian describing a physical system, it must go to zero as \\(\\mathbf{p}\\) or \\(\\mathbf{x}\\) go to infinity, which means the boundary terms must also vanish as well. Note that for this to be true it’s also important that both \\(F\\) and \\(H\\) depend on all of the integration variables. If not then some of the terms can’t be exchanged. For example, if \\(F\\) is constant, we can pull the entire integral inside the Poisson bracket to get \\[\n\\int d\\Gamma \\ \\{F,H\\} = \\bigg\\{F, \\int d\\Gamma \\ H\\bigg\\} \\neq 0.\n\\]",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Kinetic Theory</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/kinetic-theory.html#liouvilles-equation",
    "href": "statistical-mechanics/kinetic-theory.html#liouvilles-equation",
    "title": "Kinetic Theory",
    "section": "Liouville’s Equation",
    "text": "Liouville’s Equation\nThe Hamiltonian formulation of classical mechanics implies an important result called Liouville’s theorem, a statement about how phase space densities evolve in time. From this theorem we can derived Liouville’s equation, our starting point for kinetic theory.\n\nLiouville’s Theorem\nSuppose a system of \\(N\\) particles has some given thermodynamic macrostate \\(M\\), which will in general be a function of the thermodynamic variables \\(T, V, N\\), etc. The system will also have some microstate \\(\\mu\\) that’s a function of all the positions \\(\\mathbf{x}\\) and momenta \\(\\mathbf{p}\\). In general, there will be many possible microstates \\(\\mu\\) for any given macrostate \\(M\\). Each microstate corresponds to some point in the phase space, which evolves in time. Define a Gibbs ensemble as the set of all possible microstates \\(\\mu\\) that correspond to a given macrostate \\(M\\). An ensemble represents a cloud of points in phase space, with the cloud of points each evolving in time. Suppose there are \\(\\mathcal{N}\\) points in the ensemble. For a given infinitesimal phase space volume element \\(d\\Gamma\\), we can define an ensemble density \\(\\rho\\) as the limiting ratio of ensemble points inside of a cube \\(d\\Gamma\\) with the total number of ensemble points \\(\\mathcal{N}\\), \\[\n\\boxed{\\rho(\\mathbf{x}, \\mathbf{p}, t) d\\Gamma \\equiv \\lim_{\\mathcal{N} \\rightarrow \\infty} \\frac{d\\mathcal{N}}{\\mathcal{N}}} \\ .\n\\] The phase space density defines a proper probability density on the phase space since \\(\\rho \\geq 0\\) and \\[\n\\int d\\Gamma \\ \\rho = \\int \\frac{d\\mathcal{N}}{\\mathcal{N}} = \\frac{\\mathcal{N}}{\\mathcal{N}} = 1.\n\\] We can define an ensemble average for any function \\(F(\\mathbf{x}, \\mathbf{p},t)\\) on the phase space, \\[\n\\boxed{\\langle F(\\mathbf{x}, \\mathbf{p},t) \\rangle \\equiv \\int d\\Gamma \\ \\rho(\\mathbf{x}, \\mathbf{p},t) F(\\mathbf{x}, \\mathbf{p},t)} \\ .\n\\] Liouville’s Theorem: Phase space volumes are preserved under time evolution. That is, for any two times \\(t\\) and \\(t'\\), the differential volume element \\(d\\Gamma\\) must be the same, \\[\nd\\Gamma(\\mathbf{x}', \\mathbf{p}',t') = d\\Gamma(\\mathbf{x}, \\mathbf{p},t).\n\\] Proof: Let \\(d\\Gamma \\equiv d\\Gamma(\\mathbf{x}, \\mathbf{p},t)\\) and \\(d\\Gamma' \\equiv d\\Gamma(\\mathbf{x}', \\mathbf{p}',t+dt)\\), where \\(dt\\) is infinitesimal. Then we must have \\[\n\\begin{align*}\n\\mathbf{x}' &= \\mathbf{x} + \\mathbf{\\dot x} dt, \\\\\n\\mathbf{p}' &= \\mathbf{p} + \\mathbf{\\dot p} dt. \\\\\n\\end{align*}\n\\] The goal is to show that \\(d\\Gamma = d^{3N} \\mathbf{x} \\ d^{3N} \\mathbf{p}\\) is the same as \\(d\\Gamma' = d^{3N} \\mathbf{x}' \\ d^{3N} \\mathbf{p}'\\). Let’s focus on a particular component \\(\\alpha\\) and show \\(dx_\\alpha dp_\\alpha = dx'_{\\alpha} dp'_{\\alpha}\\). Taking the differentials of \\(x'_\\alpha\\) and \\(p'_\\alpha\\), we have \\[\n\\begin{align*}\ndx'_\\alpha &= dx_\\alpha + \\frac{\\partial \\dot x_\\alpha}{\\partial x_\\alpha} dt, \\\\\ndp'_\\alpha &= dp_\\alpha + \\frac{\\partial \\dot p_\\alpha}{\\partial p_\\alpha} dt. \\\\\n\\end{align*}\n\\] Then evidently \\[\ndx'_\\alpha dp'_\\alpha = dx_\\alpha dp_\\alpha \\bigg[1 + \\bigg(\\frac{\\partial \\dot x_\\alpha}{\\partial x_\\alpha} + \\frac{\\partial \\dot p_\\alpha}{\\partial p_\\alpha} \\bigg)  \\bigg].\n\\] Using Hamilton’s equations, however, we have that \\[\n\\frac{\\partial \\dot x_\\alpha}{\\partial x_\\alpha} + \\frac{\\partial \\dot p_\\alpha}{\\partial p_\\alpha} = \\frac{\\partial}{\\partial x_\\alpha} \\frac{\\partial H}{\\partial p_\\alpha} - \\frac{\\partial}{\\partial p_\\alpha} \\frac{\\partial H}{\\partial x_\\alpha} = 0.\n\\] Thus, to first order we have \\(dx_\\alpha dp_\\alpha = dx'_{\\alpha} dp'_{\\alpha}\\) for each \\(\\alpha\\). Multiplying them all together, we finally have \\(d\\Gamma' = d\\Gamma\\), as desired. \\(\\text{Q.E.D.}\\)\n\n\nDerivation\nLiouville’s theorem as stated is equivalent to saying that the phase space density is an incompressible fluid. That is, the flow velocity on phase space has zero divergence. Indeed, we have \\[\n\\nabla_{\\mathbf{x}, \\mathbf{p}} \\cdot (\\mathbf{\\dot x}, \\mathbf{\\dot p}) = \\frac{\\partial \\mathbf{\\dot x}}{\\partial \\mathbf{x}} + \\frac{\\partial \\mathbf{\\dot p}}{\\partial \\mathbf{p}} = \\frac{\\partial}{\\partial \\mathbf{x}} \\frac{\\partial H}{\\partial \\mathbf{p}} - \\frac{\\partial}{\\partial \\mathbf{p}} \\frac{\\partial H}{\\partial \\mathbf{x}} = 0.\n\\] Define the stream derivative or the material derivative of a function \\(f(\\mathbf{x}, \\mathbf{p},t)\\) as the total time derivative, \\[\n\\boxed{\\frac{Df}{Dt} \\equiv \\frac{df}{dt}} \\ .\n\\] The stream derivative represents how any given flow of \\(f\\) changes in time. If you follow any given set of points in time, they’ll evolve according to the stream derivative. This contrasts with the point derivative \\(\\frac{\\partial f}{\\partial t}\\), which represents how \\(f\\) changes at a fixed point \\(\\mathbf{x},\\mathbf{p}\\) in time.\nThe stream derivative of the phase space density can evidently be related to the point derivative by \\[\n\\begin{align*}\n\\frac{D\\rho}{Dt} &= (\\mathbf{\\dot x}, \\mathbf{\\dot p}) \\cdot \\nabla_{\\mathbf{x}, \\mathbf{p}} \\ \\rho \\ + \\frac{\\partial \\rho}{\\partial t} \\\\\n&= \\mathbf{\\dot x} \\cdot \\frac{\\partial \\rho}{\\partial \\mathbf{x}} + \\mathbf{\\dot p} \\cdot\\frac{\\partial \\rho}{\\partial \\mathbf{p}} + \\frac{\\partial \\rho}{\\partial t} \\\\\n&= \\frac{\\partial \\rho}{\\partial \\mathbf{x}} \\cdot \\frac{\\partial H}{\\partial \\mathbf{p}} - \\frac{\\partial \\rho}{\\partial \\mathbf{p}} \\cdot \\frac{\\partial H}{\\partial \\mathbf{x}} \\\\\n&= \\{\\rho, H\\} + \\frac{\\partial \\rho}{\\partial t}.\n\\end{align*}\n\\] Liouville’s theorem implies that the stream derivative of \\(\\rho\\) must vanish. Since \\(d\\Gamma' = d\\Gamma\\), we must have \\(\\rho' d\\Gamma' = \\rho d\\Gamma\\), or \\((\\rho'-\\rho) d\\Gamma = 0\\), which implies \\(\\rho'=\\rho\\). We’ve thus derived Liouville’s equation, which says how the density at any given point in phase space evolves in time, \\[\n\\boxed{\\frac{\\partial \\rho}{\\partial t} = -\\{\\rho, H\\} = \\{H,\\rho\\}} \\ .\n\\] For convenience, it’s also common to define a Liouville operator \\(\\mathcal{L}\\) by \\[\n\\boxed{\\mathcal{L}[\\rho] \\equiv \\{\\rho, H\\} + \\frac{\\partial \\rho}{\\partial t}} \\ .\n\\] In this language, Liouville’s equation can also be written as \\(\\mathcal{L}[\\rho] = 0\\).\nWe can use Liouville’s equation to find the time derivative of an ensemble average. If \\(F(\\mathbf{x},\\mathbf{p})\\) is some time-independent function on phase space. Using integration by parts, we have \\[\n\\frac{d}{dt} \\langle F \\rangle = \\int d\\Gamma \\ F \\frac{\\partial \\rho}{\\partial t} = -\\int d\\Gamma \\ F \\ \\{\\rho, H\\} = \\int d\\Gamma \\ \\rho \\ \\{F, H\\} = \\bigg\\langle \\frac{dF}{dt} \\bigg\\rangle.\n\\] That is, the time derivative of an ensemble average is the ensemble average of the time derivative.\n\n\nEquilibrium Conditions\nWhile all this is nice, our entire purpose is to figure out what happens at or near equilibrium. At equilibrium, the density can’t depend explicitly on time, i.e. \\(\\rho_{eq} = \\rho(\\mathbf{x}, \\mathbf{p})\\). This evidently implies \\[\n\\frac{\\partial \\rho_{eq}}{\\partial t} = -\\{\\rho_{eq}, H\\} = 0.\n\\] A sufficient condition for \\(\\{\\rho_{eq}, H\\}\\) to vanish is that \\(\\rho_{eq}\\) only be an explicit function of the conserved quantities in the system, since conserved quantities all have vanishing Poisson bracket with \\(H\\). This is called the basic assumption of statistical mechanics. If only energy is conserved, which is the typical case, we’d have \\[\n\\rho_{eq} = \\rho(H(\\mathbf{x}, \\mathbf{p})).\n\\] Recall that this requires the Poisson bracket to vanish since we can expand \\(\\rho\\) in powers of \\(H\\). The two most important equilibrium densities we’ll see in statistical mechanics are the microcanonical ensemble \\(\\rho_{eq} = \\delta(H(\\mathbf{x}, \\mathbf{p})-E)\\), and the canonical ensemble \\(\\rho_{eq} \\propto e^{-\\beta H(\\mathbf{x}, \\mathbf{p})}\\).\nNote that we still haven’t shown that it’s even possible that \\(\\rho \\rightarrow \\rho_{eq}\\) as \\(t \\rightarrow \\infty\\). This must happen for the basic assumption of statistical mechanics to be true. However, convergence to a stationary distribution contradicts time reversal symmetry, which \\(\\rho\\) itself must in principle satisfy. In fact, \\(\\rho \\nrightarrow \\rho_{eq}\\) exactly since such a process is irreversible. In principle, if we could follow every point in the ensemble exactly, we could trace the density both forward and backward in time. In practice, however, we can’t do this, meaning we lose information over time. Only in a coarse-grained sense will it be true \\(\\rho \\rightarrow \\rho_{eq}\\).\nTALK ABOUT ERGODICITY HERE",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Kinetic Theory</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/kinetic-theory.html#the-bbgky-hierarchy",
    "href": "statistical-mechanics/kinetic-theory.html#the-bbgky-hierarchy",
    "title": "Kinetic Theory",
    "section": "The BBGKY Hierarchy",
    "text": "The BBGKY Hierarchy\nThe full phase space density of all \\(N\\) particles contains far more information than we need for thermodynamic purposes. In fact, we can often get away with looking at densities of a small number of particles in the background of all the other particles. We can derive a recursive expression for these densities that will be useful for making the approximations that will lead us into thermodynamics.\n\nParticle Densities\nDefine the (un-normalized) density of a single particle as the expected number of particles \\(f_1\\) that occur at some \\(\\mathbf{x},\\mathbf{p},t\\), i.e. \\[\nf_1(\\mathbf{x}, \\mathbf{p},t) \\equiv \\bigg\\langle \\sum_{i=1}^N \\delta^3(\\mathbf{x}_i-\\mathbf{x}) \\delta^3(\\mathbf{p}_i-\\mathbf{p}) \\bigg\\rangle.\n\\] Assuming each particle is identical, we can simplify the right-hand side by noting that the expected value of \\(N\\) identical particles is just \\(N\\) times the expectation of a single particle, \\[\n\\begin{align*}\nf_1(\\mathbf{x}, \\mathbf{p},t) &= N \\big\\langle \\delta^3(\\mathbf{x}_1-\\mathbf{x}) \\delta^3(\\mathbf{p}_1-\\mathbf{p}) \\big\\rangle \\\\\n&= N \\int d^3 \\mathbf{x}_1 d^3 \\mathbf{p}_1 \\ \\rho(\\mathbf{x}_1=\\mathbf{x}, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N, \\mathbf{p}_1=\\mathbf{p}, \\mathbf{p}_2, \\cdots, \\mathbf{p}_N,t) \\\\\n&= N \\rho_1(\\mathbf{x}, \\mathbf{p}, t),\n\\end{align*}\n\\] where \\(\\rho_1(\\mathbf{x}, \\mathbf{p}, t)\\) is just the one-particle marginal PDF of the full density \\(\\rho\\). As expected, the expected number of particles at a point is just \\(N\\) times the normalized one-particle density. We can similarly ask about the expected number of tuples of particles. The density \\(f_s\\) of \\(s\\) particles occurring at some given set of \\(s\\) phase space points at some time \\(t\\) is given by \\[\n\\boxed{f_s(\\mathbf{x}_1, \\cdots, \\mathbf{x}_s,\\mathbf{p}_1, \\cdots, \\mathbf{p}_s,t) \\equiv \\frac{N!}{(N-s)!} \\rho_s(\\mathbf{x}_1, \\cdots, \\mathbf{x}_s,\\mathbf{p}_1, \\cdots, \\mathbf{p}_s,t)} \\ .\n\\] Clearly, \\(f_N\\) is just the un-normalized full density of finding all \\(N\\) particles at their given points, which is \\[\nf_N(\\mathbf{x}_1, \\cdots, \\mathbf{x}_N,\\mathbf{p}_1, \\cdots, \\mathbf{p}_N,t) = N! \\ \\rho(\\mathbf{x}_1, \\cdots, \\mathbf{x}_N,\\mathbf{p}_1, \\cdots, \\mathbf{p}_N,t).\n\\]\n\n\nDerivation\nWhat we’d like to try to do is to find a way of expressing \\(f_N\\) as a hierarchy of lower-particle densities. If we can get that then we can start approximating the full density using the much simpler one or two particle densities. This hierarchy of densities is called the BBGKY Hierarchy, which we’ll now derive.\nTo do that we need to make an assumption about the functional form of the full Hamiltonian \\(H\\). We’ll assume that it’s composed of the kinetic energy for each particle, where each particle has the same mass \\(m\\), some external potential energy \\(V\\) acting on each particle (e.g. the force resulting from the walls of the box of a container), and some interaction potential energy \\(\\nu\\) between particles, which we’ll approximate as being some central potential between all pairs of distinct particles (an adequate approximate for a weakly interacting gas). All together, we thus have \\[\nH = \\sum_{i=1}^N \\bigg(\\frac{\\mathbf{p}_i^2}{2m} + V(\\mathbf{x}_i)  + \\sum_{j &lt; i} \\nu\\big(|\\mathbf{x}_i-\\mathbf{x}_j|\\big)\\bigg).\n\\] We need to figure out the time evolution of each \\(s\\)-particle density \\(f_s\\). To do that it’s convenient to split the full Hamiltonian up into three pieces: One piece \\(H_s\\) that only involves interactions between the \\(s\\) particles themselves. One piece \\(H_{N-s}\\) that only involves interactions between the remaining \\(N-s\\) particles. And finally one piece \\(H'\\) that completely specifies the interactions between the \\(s\\) particles with the other \\(N-s\\) particles. We can then write \\[\nH = H_s + H_{N-s} + H'.\n\\] The first two terms are just the full Hamiltonian, but with \\(i\\) running from \\(1\\) to \\(s\\) or \\(s+1\\) to \\(N\\) respectively. The interaction term only involves the interaction potential energies between the two sets, \\[\nH' = \\sum_{i=1}^s \\sum_{j=s+1}^N \\nu\\big(|\\mathbf{x}_i-\\mathbf{x}_j|\\big).\n\\] By Liouville’s equation, we have \\(\\frac{\\partial \\rho}{\\partial t} = -\\{\\rho, H\\}\\). But this is only true for the full density. Let’s try to see what Liouville’s equation for the marginal density \\(\\rho_s\\) might look like. Then we have \\[\n\\begin{align*}\n\\frac{\\partial \\rho_s}{\\partial t} &= \\int \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\frac{\\partial \\rho}{\\partial t} \\\\\n&= -\\int \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\ \\{\\rho, H\\} \\\\\n&= -\\int \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\ \\bigg(\\{\\rho, H_s\\} + \\{\\rho, H_{N-s}\\} + \\{\\rho, H'\\} \\bigg). \\\\\n\\end{align*}\n\\] Starting with the first term, the Hamiltonian \\(H_s\\) is constant with respect to the integration variables, so we just have \\[\n\\int \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\{\\rho, H_s\\} = \\bigg\\{ \\int \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\rho \\ , \\ H_s \\bigg\\} = \\{\\rho_s, H_s\\}.\n\\] That is, the first term is just Liouville’s equation for the first \\(s\\) particles. This makes sense, since we’re ignoring the presence of the other \\(N-s\\) particles in the dynamics of \\(\\rho_s\\) via \\(H_s\\). The second term is an integral over two functions that depend on the integration variables, which means it vanishes as usual, \\[\n\\int \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\{\\rho, H_{N-s}\\} = 0.\n\\] Finally we have the integral of the interaction terms. If we split the Poisson bracket \\(\\{\\rho, H'\\}\\) into a sum of two terms, one over the \\(s\\) variables and the other over the \\(N-s\\) variables, we have \\[\n\\{\\rho, H'\\} = \\{\\rho, H'\\}_s + \\{\\rho, H'\\}_{N-s.}\n\\] Integrating the second Poisson bracket again gives zero since it’s a bracket of the integration variables. The first bracket is more interesting. Noting that \\(H'\\) depends only on the positions, we have \\[\n\\begin{align*}\n\\int \\ \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\{\\rho, H'\\}_s &= \\int \\ \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\sum_{j=1}^s \\bigg(\\frac{\\partial \\rho}{\\partial \\mathbf{x}_j} \\cdot \\frac{\\partial H'}{\\partial \\mathbf{p}_j} - \\frac{\\partial H'}{\\partial \\mathbf{x}_j} \\cdot \\frac{\\partial \\rho}{\\partial \\mathbf{p}_j}\\bigg) \\\\\n&= - \\sum_{j=1}^s \\int \\ \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\frac{\\partial H'}{\\partial \\mathbf{x}_j} \\cdot \\frac{\\partial \\rho}{\\partial \\mathbf{p}_j} \\\\\n&= - \\sum_{j=1}^s \\int \\ \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\bigg(\\sum_{k=s+1}^N \\frac{\\partial \\nu}{\\partial \\mathbf{x}_j} \\bigg) \\cdot \\frac{\\partial \\rho}{\\partial \\mathbf{p}_j} \\\\\n&= (N-s) \\sum_{j=1}^s \\int \\ d^3 \\mathbf{x}_{s+1} d^3 \\mathbf{p}_{s+1} \\ \\mathbf{F}_{j,s+1} \\cdot \\frac{\\partial}{\\partial \\mathbf{p}_j} \\bigg(\\int \\ \\prod_{k=s+2}^N d^3 \\mathbf{x}_k d^3 \\mathbf{p}_k \\ \\rho \\bigg) \\\\\n&= (N-s) \\sum_{j=1}^s \\int \\ d^3 \\mathbf{x}_{s+1} d^3 \\mathbf{p}_{s+1} \\ \\mathbf{F}_{j,s+1} \\cdot \\frac{\\partial \\rho_{s+1}}{\\partial \\mathbf{p}_j}. \\\\\n\\end{align*}\n\\] The last equalities follow from the fact that the integral over the third line is just \\(N-s\\) copies of the same integral over particle \\(s+1\\), except we have to be careful to still integrate \\(\\rho\\) over the remaining terms from \\(s+2\\) to \\(N\\), which give the \\(s+1\\) particle density \\(\\rho_{s+1}\\). Since the negative gradient of a potential energy is a force, each term \\(\\mathbf{F}_{j,i} = -\\nabla_j \\nu(\\mathbf{x}_j-\\mathbf{x}_i)\\) represents the force on particle \\(j\\) due to its interaction with particle \\(s+1\\), which by Newton’s Third Law is of course the negative of the opposite force \\(\\mathbf{F}_{i,j}\\).\nWe thus finally have a modified form of Liouville’s equation for \\(\\rho_s\\), which adds a new term representing the collisions of the \\(s\\) particles with the other \\(N-s\\) particles. We have \\[\n\\frac{\\partial \\rho_s}{\\partial t} + \\{\\rho_s, H_s\\} = (N-s) \\sum_{j=1}^s \\int \\ d^3 \\mathbf{x}_{s+1} d^3 \\mathbf{p}_{s+1} \\ \\mathbf{F}_{s+1,j} \\cdot \\frac{\\partial \\rho_{s+1}}{\\partial \\mathbf{p}_j}.\n\\] It’s more common to express things in terms of the un-normalized densities \\(f_s\\) instead. Doing this eliminates the \\(N-s\\) factor in front of the collision term and replaces each \\(\\rho_s\\) with \\(f_s\\). We’ve thus finally arrived at the BBGKY Hierarchy we sought after, \\[\n\\boxed{\\frac{\\partial f_s}{\\partial t} + \\{f_s, H_s\\} = \\sum_{j=1}^s \\int \\ d^3 \\mathbf{x}_{s+1} d^3 \\mathbf{p}_{s+1} \\ \\mathbf{F}_{s+1,j} \\cdot \\frac{\\partial f_{s+1}}{\\partial \\mathbf{p}_j}} \\ .\n\\] We can think of this as a kind of ladder of densities. The one-particle density \\(f_1\\) depends via the collision integral on the two-particle density \\(f_2\\), which itself depends on \\(f_3\\), and so on until we get to the full density \\(f_N\\). It’s worth noting that the BBGKY Hierarchy is completely equivalent to Liouville’s equation for a box of \\(N\\) particles obeying the Hamiltonian specified above.\nOf most use to use will be the equations for \\(f_1\\) and \\(f_2\\). If we expand the Poisson brackets, they become \\[\n\\begin{align*}\n\\frac{\\partial f_1}{\\partial t} + &\\frac{\\mathbf{p}_1}{m} \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{x}_1} + \\mathbf{F}_1 \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{p}_1} = \\int d^3 \\mathbf{x}_2 d^3 \\mathbf{p}_2 \\ \\mathbf{F}_{2,1} \\cdot \\frac{\\partial f_2}{\\partial \\mathbf{p}_1}, \\\\\n\\frac{\\partial f_2}{\\partial t} + \\frac{\\mathbf{p}_1}{m} \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{x}_1} + &\\mathbf{F}_1 \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{p}_1} + \\frac{\\mathbf{p}_2}{m} \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{x}_2} + \\mathbf{F}_2 \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{p}_2} +\\mathbf{F}_{1,2} \\cdot \\bigg(\\frac{\\partial f_1}{\\partial \\mathbf{p}_1} - \\frac{\\partial f_1}{\\partial \\mathbf{p}_2}\\bigg) = \\\\ &\\int d^3 \\mathbf{x}_3 d^3 \\mathbf{p}_3 \\ \\bigg(\\mathbf{F}_{3,1} \\cdot \\frac{\\partial f_3}{\\partial \\mathbf{p}_1} + \\mathbf{F}_{3,2} \\cdot \\frac{\\partial f_3}{\\partial \\mathbf{p}_2}\\bigg). \\\\\n\\end{align*}\n\\]\nHere \\(\\mathbf{F}_i = -\\nabla V(\\mathbf{x}_i)\\) represents the force on particle \\(i\\) due to the external potential energy \\(V\\). The combination of derivatives in the \\(\\mathbf{F}_{1,2}\\) term is done by using Newton’s third law to get \\(\\mathbf{F}_{2,1} = -\\mathbf{F}_{1,2}\\). This is equivalent to assume that the interaction potential \\(\\nu\\) is symmetric in \\(i\\) and \\(j\\), which is true of central forces.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Kinetic Theory</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/kinetic-theory.html#the-boltzmann-equation",
    "href": "statistical-mechanics/kinetic-theory.html#the-boltzmann-equation",
    "title": "Kinetic Theory",
    "section": "The Boltzmann Equation",
    "text": "The Boltzmann Equation\nThus far we really haven’t made much progress in studying the approach to equilibrium. Both Liouville’s equation and the BBGKY hierarchy are fully reversible, describing the microscopic behavior of the system. To study equilibrium we need to coarse grain things more, giving up the ability to track the exact dynamics of any given particle. We’ll start by looking at the time scales involved in the BBGKY hierarchy to get an idea of which terms in the equations are most important.\n\nCoarse-Graining\nSuppose the system involved is a box of gas whose sides are each of length of order \\(L\\). Suppose the particles in the box move with some average speed \\(v\\). Evidently then, it takes a given particle an average time \\(\\tau_{ext} \\equiv \\frac{L}{v}\\) to traverse the length of the box. This defines a time-scale for the external force terms, \\[\n\\mathbf{F}_i \\cdot \\frac{\\partial}{\\partial \\mathbf{p}_i} \\sim \\frac{v}{L} = \\frac{1}{\\tau_{ext}}.\n\\] In the box particles will collide with a certain frequency. Suppose interaction forces are felt when particles are within some distance \\(d \\ll L\\) of each other. The time that particles spend interacting in an interaction is then evidently on the order of \\(\\tau_{int} \\equiv \\frac{d}{v}\\). This defines another time-scale for the interaction force terms, \\[\n\\mathbf{F}_{i,j} \\cdot \\frac{\\partial}{\\partial \\mathbf{p}_i} \\sim \\frac{v}{d} = \\frac{1}{\\tau_{int}}.\n\\] Since \\(d \\ll L\\), we typically have \\(\\tau_{int} \\ll \\tau_{ext}\\), which means the interaction terms should typically dominate the external force terms on the left-hand side of the equations. For example, for a gas we might have \\(L \\sim 1 \\ \\text{m}\\) while \\(d \\sim 10^{-10} \\ \\text{m}\\), with \\(v \\sim 10^2 \\ \\text{m/s}\\) at room temperature. This gives time scales on the order of \\(\\tau_{ext} \\sim 10^{-3} \\ \\text{s}\\) and \\(\\tau_{int} \\sim 10^{-12} \\ \\text{s}\\).\nOn the right-hand side of these equations we have another set of time scales that say something about how long we have to wait for \\(s+1\\) particles to all come together and collide with each other. Call that time scale \\(\\tau_X\\). If we look at the ratio of \\(\\frac{f_{s+1}}{f_s}\\) as a ratio of densities, it goes roughly like the number density \\(n \\equiv \\frac{N}{d^3}\\) of particles inside a unit volume \\(d^3\\). Since the collisions only happen inside a volume \\(d^3\\), essentially the entire integral falls off to zero outside this region. Thus, we’d have \\[\n\\int \\ d^3 \\mathbf{x}_{s+1} \\ d^3 \\mathbf{p}_{s+1} \\ \\mathbf{F}_{s+1,j} \\cdot \\frac{\\partial }{\\partial \\mathbf{p}_j} \\frac{f_{s+1}}{f_s} \\sim \\frac{nd^3}{\\tau_{int}} \\equiv \\frac{1}{\\tau_X}.\n\\] This new time scale \\(\\tau_X = \\frac{1}{nvd^2}\\) is called the mean free time. It represents the typical time a particle will spend between collisions. Its relative size with respect to \\(\\tau_{col}\\) depends on \\(nd^3\\). This reflects the fact we have to wait for \\(s+1 \\sim N\\) particles to all come together and collide. The range of interactions between particles determines two limiting regions of consideration. When interactions short-range, we’d say we’re in the dilute limit where \\(nd^3 \\ll 1\\). This is the typical setting for gases, where we might have \\(nd^3 \\sim 10^{-4}\\), and so \\(\\tau_X \\sim 10^4 \\ \\tau_{int}\\). Conversely, when interactions are long-range, we’d say we’re in the dense limit where \\(nd^3 \\gg 1\\). This limit is the setting for studying plasmas, where \\(\\tau_X \\ll \\tau_{int}\\). We’ll see that the dilute limit leads us to the Boltzmann equation, and hence to thermodynamics, while the dense limit leads us to the Vlasov equation, and hence to plasma physics.\nAll the equations in the BBGKY hierarchy appear to look something like \\[\n\\text{(external interactions)} + \\text{(internal interactions)} = \\text{(collision terms)}.\n\\] In this situation the time scale comparisons look something like \\[\n\\frac{1}{\\tau_{ext}} + \\frac{1}{\\tau_{int}} = \\frac{nd^3}{\\tau_{int}}.\n\\] In the dilute limit the right-hand side is much smaller than the left-hand side, so we can evidently ignore the collision terms at least to zeroth order. This appears to be a problem though, since it says that we shouldn’t look at the background interactions at all and just treat each \\(f_s\\) as its own Liouvillian system. Fortunately, the equation for \\(f_1\\) does not look like this. In that case there are no internal interaction terms on the left-hand side, which means we can’t say much about how the left and right-hand sides compare. We have to keep both terms, which preserves the dependence of \\(f_1\\) on \\(f_2\\). But, we can treat \\(f_2\\) as having a right-hand side of zero, so we can ignore the dependence on \\(f_3\\) and higher terms and only focus on the relationship between \\(f_1\\) and \\(f_2\\).\n\n\nDerivation\nLet’s try to find a way under this approximation to combine the equations for \\(f_1\\) and \\(f_2\\) into a single equation. To do that we need to figure out how to substitute the \\(f_2\\) equation into the \\(f_1\\) equation. If we assume the collision term for \\(f_2\\) is zero, we have \\[\n\\begin{align*}\n\\frac{\\partial f_1}{\\partial t} + &\\frac{\\mathbf{p}_1}{m} \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{x}_1} + \\mathbf{F}_1 \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{p}_1} = \\int d^3 \\mathbf{x}_2 \\ d^3 \\mathbf{p}_2 \\ \\mathbf{F}_{2,1} \\cdot \\frac{\\partial f_2}{\\partial \\mathbf{p}_1}, \\\\\n\\frac{\\partial f_2}{\\partial t} + \\frac{\\mathbf{p}_1}{m} \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{x}_1} + &\\mathbf{F}_1 \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{p}_1} + \\frac{\\mathbf{p}_2}{m} \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{x}_2} + \\mathbf{F}_2 \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{p}_2} +\\mathbf{F}_{1,2} \\cdot \\bigg(\\frac{\\partial f_1}{\\partial \\mathbf{p}_1} - \\frac{\\partial f_1}{\\partial \\mathbf{p}_2}\\bigg) = 0. \\\\\n\\end{align*}\n\\] The second equation involves a density of two interaction particles. It’s convenient thus to express things in terms of center of mass and relative coordinates. Let \\(\\boldsymbol{\\mathcal{x}} \\equiv \\mathbf{x}_2 - \\mathbf{x}_1\\) represent coordinates between the two particles and \\(\\mathbf{X} \\equiv \\mathbf{x}_2 + \\mathbf{x}_1\\) represent the center of mass coordinates. Typically the center of mass coordinates will vary much slower than the relative coordinates, making the center of mass frame a good approximation of the lab frame dynamics as well. In this situation, we’d have \\(\\boldsymbol{\\mathcal{x}} = -\\mathbf{x}_1 = \\mathbf{x}_2\\). Near equilibrium we’d expect \\(\\frac{\\partial f_2}{\\partial t} \\approx 0\\). Changing variables in and writing \\(\\mathbf{F}_{2,1} = -\\mathbf{F}_{1,2}\\), the second equation becomes \\[\n\\frac{\\mathbf{p}}{m} \\cdot \\frac{\\partial f_2}{\\partial \\boldsymbol{\\mathcal{x}}} - \\mathbf{F}_{2,1} \\cdot  \\bigg(\\frac{\\partial f_2}{\\partial \\mathbf{p}_1} - \\frac{\\partial f_2}{\\partial \\mathbf{p}_2}\\bigg) \\approx 0.\n\\] Now, in the first equation, the right-hand side contains an integral over \\(d^3 \\mathbf{x}_2\\). We can evidently add any total derivative that depends on \\(\\mathbf{x}_2\\) to the integrand since its integral will vanish. Let’s thus re-write \\[\n\\int d^3 \\mathbf{x}_2 d^3 \\mathbf{p}_2 \\ \\mathbf{F}_{2,1} \\cdot \\frac{\\partial f_2}{\\partial \\mathbf{p}_1} = \\int d^3 \\mathbf{x}_2 \\ d^3 \\mathbf{p}_2 \\ \\mathbf{F}_{2,1} \\cdot \\bigg(\\frac{\\partial f_2}{\\partial \\mathbf{p}_1} - \\frac{\\partial f_2}{\\partial \\mathbf{p}_2}\\bigg).\n\\] Since \\(\\boldsymbol{\\mathcal{x}} = \\mathbf{x}_2\\) we also must have \\(d^3 \\boldsymbol{\\mathcal{x}} = d^3 \\mathbf{x}_2\\). We can now see how to substitute in the second equation into the first. We have \\[\n\\frac{\\partial f_1}{\\partial t} + \\frac{\\mathbf{p}_1}{m} \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{x}_1} + \\mathbf{F}_1 \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{p}_1} = \\int d^3 \\boldsymbol{\\mathcal{x}} \\ d^3 \\mathbf{p}_2 \\ \\frac{\\mathbf{p}_2 - \\mathbf{p}_1}{m} \\cdot \\frac{\\partial f_2}{\\partial \\boldsymbol{\\mathcal{x}}}.\n\\] Note this equation is only true when we’re near equilibrium since we neglected the time derivative \\(\\frac{\\partial f_2}{\\partial t}\\). More correctly, this equation is valid when \\(t\\) is much larger than the interaction time \\(\\tau_{int}\\).\nAt this point it’s helpful to re-express the integral in terms of collision coordinates. The collision forces are felt inside some sphere of interaction radius \\(d\\). In the center of mass frame, two particles collide along the same line. If two particles with momenta \\(\\mathbf{p}_1\\) and \\(\\mathbf{p}_2\\) come in and collide along some line, they’ll exit the collision with some new momenta \\(\\mathbf{p}'_1\\) and \\(\\mathbf{p}'_2\\) along some other line. In an elastic collision both kinetic energy and momentum must be conserved. Define a parameter \\(a \\equiv \\frac{1}{m} |\\mathbf{p}_2 - \\mathbf{p}_1|\\) to represent the relative velocity between the two particles. Perpendicular to the \\(a\\) is a plane that can be specified by another vector \\(\\mathbf{b} \\equiv (b,\\vartheta)\\). This vector has a magnitude \\(b\\), called the impact parameter, equal to the perpendicular distance between the incoming trajectories in the center of mass frame. It also has an angle \\(\\vartheta\\) representing how the incoming momenta get rotated to the outgoing momenta in the collision.\n\n\n\n\n\nNow, in collision coordinates we can write \\(d^3 \\boldsymbol{\\mathcal{x}} = d^2 \\mathbf{b} \\ da\\). It turns out that if momentum is conserved, the collision itself doesn’t depend on \\(a\\), only \\(\\mathbf{b}\\). This means the integral \\(\\int da\\) just gives \\(a\\). If we further assume the collision happens almost at a single point, we can think of the gradient of \\(f_2\\) as the instantaneous change if \\(f_2\\) before and after the collision, i.e. \\[\n\\Delta f_2 \\equiv f_2(\\mathbf{x}'_1, \\mathbf{x}'_2, \\mathbf{p}'_1, \\mathbf{p}'_2,t) - f_2(\\mathbf{x}_1, \\mathbf{x}_2, \\mathbf{p}_1, \\mathbf{p}_2,t).\n\\] Plugging all this in, we thus have \\[\n\\frac{\\partial f_1}{\\partial t} + \\frac{\\mathbf{p}_1}{m} \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{x}_1} + \\mathbf{F}_1 \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{p}_1} = \\int d^3 \\mathbf{p}_2 \\ d^2 \\mathbf{b} \\ \\frac{|\\mathbf{p}_2 - \\mathbf{p}_1|}{m} \\cdot \\Delta f_2.\n\\] The last assumption we’ll make is perhaps the most important, since it’s the coarse-graining that leads to the second law of thermodynamics: the assumption of molecular chaos. For short-range interactions the density \\(f_2\\) mixes coordinates only inside the interaction radius \\(d\\). For distances much greater than \\(d\\) it’s a good assumption to say that \\(f_2\\) is a product of two one-particle densities, i.e. that the two particles’ states are statistically independent of each other. The assumption of molecular chaos says we send \\(d \\rightarrow 0\\), meaning we lose information about the nature of collisions and just assume particles collide at a single point. In this setting, we can globally assume that \\(f_2\\) factors into a product of one-particle densities \\[\nf_2(\\mathbf{x}_1, \\mathbf{x}_2, \\mathbf{p}_1, \\mathbf{p}_2,t) = f_1(\\mathbf{x}_1, \\mathbf{p}_1, t) f_1(\\mathbf{x}_2, \\mathbf{p}_2, t).\n\\] This means we can factor \\(\\Delta f_2\\) as well to get \\[\n\\Delta f_2 = f_1(\\mathbf{x}_1, \\mathbf{p}'_1, t) f_1(\\mathbf{x}_2, \\mathbf{p}'_2, t) - f_1(\\mathbf{x}_1, \\mathbf{p}_1, t) f_1(\\mathbf{x}_2, \\mathbf{p}_2, t).\n\\] Notice how the coordinates after collision are now assumed to be the same as the coordinates before collision. This is another consequence of course-graining away \\(d \\rightarrow 0\\). Plugging this result into the previous equation for \\(f_1\\) finally gives us the Boltzmann Equation, \\[\n\\begin{align*}\n&\\frac{\\partial f_1}{\\partial t} + \\frac{\\mathbf{p}_1}{m} \\cdot \\frac{\\partial f}{\\partial \\mathbf{x}_1} + \\mathbf{F}_1 \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{p}_1} = \\\\\n\\int d^3 \\mathbf{p}_2 \\ d^2 \\mathbf{b} \\ \\frac{|\\mathbf{p}_2 - \\mathbf{p}_1|}{m} &\\big[f_1(\\mathbf{x}_1, \\mathbf{p}'_1, t) f_1(\\mathbf{x}_2, \\mathbf{p}'_2, t) - f_1(\\mathbf{x}_1, \\mathbf{p}_1, t) f_1(\\mathbf{x}_2, \\mathbf{p}_2, t)\\big].\n\\end{align*}\n\\] Since we no longer need the higher particle densities we’ll from now on just write \\(f \\equiv f_1\\) and assume we’re working with one particle at a time. In this simplified notation we’ll write \\[\n\\boxed{\\frac{\\partial f}{\\partial t} + \\frac{\\mathbf{p}}{m} \\cdot \\frac{\\partial f}{\\partial \\mathbf{x}} + \\mathbf{F} \\cdot \\frac{\\partial f}{\\partial \\mathbf{p}} = \\frac{\\partial f}{\\partial t} \\bigg|_{\\text{col}}} \\ .\n\\] We can write the Boltzmann Equation even more succinctly by noting that the left-hand side is just a Liouville operator \\(L[f]\\) and defining a collision operator \\(C[f]\\) to represent the right-hand side. We then have \\[\n\\boxed{L[f] = C[f]} \\ .\n\\] Evidently, the Boltzmann equation looks like a modified Liouville equation with a non-zero right-hand side arising from a background of particles to collide with. The term \\(L[f]\\) characterizes the dynamics of particles with respect to the external forces alone, while \\(C[f]\\) characterizes the dynamics of particles due to their interactions with other particles.\n\n\nH-Theorem\nSince we’re neglecting dynamics on the scale of the interaction radius we’re losing information on the system’s microscopic dynamics. This means the Boltzmann equation also comes with a notion of increasing entropy. This result is called the H-Theorem (pronounced “Eta Theorem”).\nH-Theorem: Suppose \\(f(\\mathbf{x}, \\mathbf{p}, t)\\) satisfies the Boltzmann equation \\(L[f] = C[f]\\). Then there exists a quantity \\(\\mathrm{H}(t)\\) defined by \\[\n\\boxed{\\mathrm{H}(t) \\equiv \\int d^3 \\mathbf{x} \\ d^3 \\mathbf{p} \\ f(\\mathbf{x}, \\mathbf{p}, t) \\log f(\\mathbf{x}, \\mathbf{p}, t)}\n\\] such that \\(\\mathrm{H}(t)\\) is a decreasing function of time. That is, \\(\\frac{d\\mathrm{H}}{dt} \\leq 0\\).\nProof: We need to do is take the time derivative of \\(\\mathrm{H}(t)\\) and show its time derivative is negative. Differentiating both sides, we have \\[\n\\begin{align*}\n\\frac{d\\mathrm{H}}{dt} &= \\int d^3 \\mathbf{x} \\ d^3 \\mathbf{p} \\ \\frac{\\partial}{\\partial t}(f \\log f) \\\\\n&= \\int d^3 \\mathbf{x} \\ d^3 \\mathbf{p} \\ \\big(1 + \\log f \\big) \\frac{\\partial f}{\\partial t} \\\\\n&= \\int d^3 \\mathbf{x} \\ d^3 \\mathbf{p} \\ \\big(1 + \\log f \\big) \\big(C[f]-\\{f,H\\}\\big).\n\\end{align*}\n\\] The term involving \\(\\frac{\\partial}{\\partial t}(f \\log f)\\) just integrate to \\(N\\), a constant, and hence vanishes. Both integrals involving \\(\\{f,H\\}\\) vanish by the usual integration by parts argument. We’re thus left to calculate one term, \\[\n\\begin{align*}\n\\frac{d\\mathrm{H}}{dt} &= \\int d^3 \\mathbf{x} \\ d^3 \\mathbf{p} \\ \\log f \\ C[f] \\\\\n&= \\int d^3 \\mathbf{x}_1 \\ d^3 \\mathbf{p}_1 \\ d^3 \\mathbf{p}_2 d^2 \\mathbf{b} \\ \\frac{|\\mathbf{p}_2 - \\mathbf{p}_1|}{m} \\big[f(\\mathbf{p}'_1) f(\\mathbf{p}'_2) - f(\\mathbf{p}_1) f(\\mathbf{p}_2)\\big] \\log f(\\mathbf{p}_1).\n\\end{align*}\n\\] Here the dependence of \\(f\\) on position and time are suppressed for convenience. Now we’re going to make use of a trick. Notice the integral is symmetric in the momenta of particles \\(1\\) and \\(2\\). This means we can permute the indices and get the same answer. It also means we can average the two permutations. Though much less obvious, we can permute the primed and unprimed momenta as well since their Jacobian is \\(1\\). We can thus take the average of the primed and unprimed momenta as well. Using these facts, we have \\[\n\\begin{align*}\n\\frac{d\\Eta}{dt} &= \\int d^3 \\mathbf{x}_1 \\ d^3 \\mathbf{p}_1 d^3 \\mathbf{p}_2 d^2 \\mathbf{b} \\ \\frac{|\\mathbf{p}_2 - \\mathbf{p}_1|}{m} \\big[f(\\mathbf{p}'_1) f(\\mathbf{p}'_2) - f(\\mathbf{p}_1) f(\\mathbf{p}_2)\\big] \\log f(\\mathbf{p}_1) \\\\\n&= \\frac{1}{2}  \\int d^3 \\mathbf{x}_1 \\ d^3 \\mathbf{p}_1 d^3 \\mathbf{p}_2 d^2 \\mathbf{b} \\ \\frac{|\\mathbf{p}_2 - \\mathbf{p}_1|}{m} \\big[f(\\mathbf{p}'_1) f(\\mathbf{p}'_2) - f(\\mathbf{p}_1) f(\\mathbf{p}_2)\\big] \\log \\big(f(\\mathbf{p}_1) f(\\mathbf{p}_2)\\big) \\\\\n&= \\frac{1}{4} \\int d^3 \\mathbf{x}_1 \\ d^3 \\mathbf{p}_1 d^3 \\mathbf{p}_2 d^2 \\mathbf{b} \\ \\frac{|\\mathbf{p}_2 - \\mathbf{p}_1|}{m} \\big[f(\\mathbf{p}'_1) f(\\mathbf{p}'_2) - f(\\mathbf{p}_1) f(\\mathbf{p}_2)\\big] \\log \\bigg(\\frac{f(\\mathbf{p}_1)f(\\mathbf{p}_2)}{f(\\mathbf{p}'_1)f(\\mathbf{p}'_2)}\\bigg). \\\\\n\\end{align*}\n\\] Evidently, the integrand is proportional to a function of the form \\[\n-(f'_1 f'_2 - f_1 f_2) \\log \\bigg(\\frac{f'_1 f'_2}{f_1 f_2}\\bigg),\n\\] which is negative since the log is an increasing function of its arguments. This of course means the integral must be negative as well, i.e. \\(\\frac{d\\mathrm{H}}{dt} \\leq 0\\). \\(\\text{Q.E.D.}\\)\nThe quantity \\(\\mathrm{H}(t)\\) looks similar to the differential entropy of a continuous density function. It’s actually just a negative affine shift of the entropy of the one-particle density \\(f\\). In fact, for an \\(N\\)-particle system, we can relate the thermodynamic entropy of the system to \\(\\mathrm{H}\\) via \\(S \\equiv -k_B \\mathrm{H}\\). Thus, if \\(\\mathrm{H}\\) is a decreasing function, then \\(S\\) must be an increasing function, and vice versa.\n\n\nAside: Vlasov Equation\nWhat happens in the dense limit where \\(nd^3 \\gg 1\\)? In that case we can only say \\(\\tau_{\\text{int}} \\gg \\tau_X\\), which means we can drop the collision terms from the left-hand side of each BBGKY hierarchy. If we again assume each density \\(f_s\\) factors into a product of one-particle densities then it’ll turn out all the equations for \\(f_s\\) are equivalent, leaving a single equation to be satisfied, \\[\n\\boxed{\\frac{\\partial f}{\\partial t} + \\frac{\\mathbf{p}}{m} \\cdot \\frac{\\partial f}{\\partial \\mathbf{x}} + \\mathbf{F}_{\\text{eff}} \\cdot \\frac{\\partial f}{\\partial \\mathbf{p}} = 0} \\ ,\n\\] where \\(\\mathbf{F}_{\\text{eff}}\\) represents a kind of averaged background force on \\(f\\) given by \\[\n\\mathbf{F}_{\\text{eff}} \\equiv - \\frac{d}{d\\mathbf{x}} \\bigg(V(\\mathbf{x}) + \\int d^3\\mathbf{x}' d^3\\mathbf{p} \\ \\nu(\\mathbf{x}-\\mathbf{x}') f(\\mathbf{x}', \\mathbf{p}, t)\\bigg).\n\\] This is the Vlasov Equation. We can write the equation more succinctly by assuming an affective Hamiltonian \\(H_{\\text{eff}}\\) gives rise to the above dynamics. Then we’re back to Liouville’s equation, \\[\n\\frac{\\partial f}{\\partial t} + \\{f, H_{\\text{eff}}\\} = 0.\n\\] In this setting there’s in general no relaxation towards equilibrium. In fact, any function \\(f(\\mathbf{x},\\mathbf{p}) = g(\\mathbf{p})\\) is a valid steady state solution to the Vlasov equation. The Vlasov equation is used to characterize the behavior of plasmas. Typically when studying plasmas, one assumes the background forces are electromagnetic fields, in which case \\(\\mathbf{F}_{\\text{eff}}\\) just becomes the Lorentz force on each charged particle, \\[\n\\mathbf{F}_{\\text{eff}} = e\\mathbf{E} +  e\\frac{\\mathbf{v}}{c} \\times \\mathbf{B}.\n\\]",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Kinetic Theory</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/kinetic-theory.html#equilibrium",
    "href": "statistical-mechanics/kinetic-theory.html#equilibrium",
    "title": "Kinetic Theory",
    "section": "Equilibrium",
    "text": "Equilibrium\nWe’re now in a position to find what the density \\(f\\) has to be at equilibrium. Recall that the equilibrium distribution \\(f_{eq}\\) must satisfy the property that \\[\n\\frac{\\partial}{\\partial t} f_{eq}(\\mathbf{x}, \\mathbf{p}) = 0.\n\\] Using the Boltzmann equation and the H-theorem we can figure out what \\(f_{eq}\\) must be.\n\nEquilibrium Distributions\nSuppose \\(f\\) satisfies the Boltzmann equation. Let’s see if we can try to figure out what distribution \\(f\\) must have at equilibrium. At equilibrium we said we must have \\(\\frac{\\partial f}{\\partial t} = 0\\). As we saw, this is equivalent to requiring \\(\\frac{d\\mathrm{H}}{dt} = 0\\). For that to be true over any region of phase space as \\(t \\rightarrow \\infty\\), we must have the steady state requirement that \\[\n\\log \\bigg(\\frac{f(\\mathbf{x},\\mathbf{p}_1)f(\\mathbf{x},\\mathbf{p}_2)}{f(\\mathbf{x},\\mathbf{p}'_1)f(\\mathbf{x},\\mathbf{p}'_2)}\\bigg) = 0.\n\\] That is, for any position \\(\\mathbf{x}\\), \\[\n\\log f(\\mathbf{x}, \\mathbf{p}_1) + \\log f(\\mathbf{x},\\mathbf{p}_2) = \\log f(\\mathbf{x},\\mathbf{p}'_1) + \\log f(\\mathbf{x},\\mathbf{p}'_2).\n\\] This is a law of detailed balance, in that it states that some quantity before a collision must equal the same quantity after collision. Detailed balance evidently implies that the sum \\(\\log f(\\mathbf{x}, \\mathbf{p}_1) + \\log f(\\mathbf{x},\\mathbf{p}_2)\\) must be conserved during collisions. In an elastic collision we require that particle number, momentum and kinetic energy be conserved, \\[\n\\begin{align*}\n1 + 1 &= 1' + 1',\\\\\n\\mathbf{p}_1 + \\mathbf{p}_2 &= \\mathbf{p}'_1 + \\mathbf{p}'_2, \\\\ \\frac{\\mathbf{p}^2_1}{2m} + \\frac{\\mathbf{p}^2_2}{2m} &= \\frac{\\mathbf{p}'^{2}_1}{2m} + \\frac{\\mathbf{p}'^{2}_2}{2m}.\n\\end{align*}\n\\] It thus makes sense to suppose that in equilibrium each \\(\\log f(\\mathbf{x}, \\mathbf{p},t)\\) is only a quadratic function in \\(\\mathbf{p}\\). Suppose then that \\[\n\\log f(\\mathbf{x},\\mathbf{p}) \\equiv \\nu(\\mathbf{x}) + \\boldsymbol{\\alpha}(\\mathbf{x}) \\cdot \\mathbf{p} - \\beta(\\mathbf{x}) \\frac{\\mathbf{p}^2}{2m}.\n\\] By completing the square and exponentiating, we can write the density in the form \\[\nf(\\mathbf{x}, \\mathbf{p}) = \\mathcal{N}(\\mathbf{x}) \\exp\\bigg(-\\frac{\\beta(\\mathbf{x})}{2m}(\\mathbf{p}-\\boldsymbol{\\pi}(\\mathbf{x}))^2\\bigg).\n\\] However, this equation doesn’t solve the entire Boltzmann equation. It only solves the equation \\(C[f] = 0\\). We still need to impose that \\(L[f] = 0\\) as well. If we like, we can add to the kinetic energy an external potential energy \\(V(\\mathbf{x})\\) that represents, for example, the walls of a box of fixed volume. Then \\[\nH(\\mathbf{x},\\mathbf{p}) = \\frac{\\mathbf{p}^2}{2m} + V(\\mathbf{x}).\n\\] To satisfy \\(L[f] = 0\\), we saw that \\(f\\) must be conserved under \\(H\\), i.e. \\(\\{f, H\\} = 0\\). This also must be true for any other quantity conserved under \\(H\\), in this case the momentum vector \\(\\mathbf{p}\\) and particle number \\(1\\). Enforcing that all these Poisson brackets vanish then forces \\(\\mathcal{N}\\), \\(\\beta\\), and \\(\\boldsymbol{\\pi}\\) to all be constant. The final equilibrium one-particle density for a gas is thus just a Gaussian in the momentum \\(\\mathbf{p}\\), \\[\n\\boxed{f_{eq}(\\mathbf{x}, \\mathbf{p}) = n(\\mathbf{x}, t) \\bigg(\\frac{\\beta}{2\\pi m}\\bigg)^{3/2} \\exp\\bigg(-\\frac{\\beta}{2m}(\\mathbf{p}-\\boldsymbol{\\pi})^2\\bigg)} \\ .\n\\] Here \\(n\\) is just the number density \\(n(\\mathbf{x}, t)\\), representing the fact that \\(f\\) isn’t normalized over the volume of the box. This can also be written in the form \\[\nf_{eq}(\\mathbf{x}, \\mathbf{p}) \\propto e^{-\\beta H(\\mathbf{x},\\mathbf{p})}.\n\\] This is called the Boltzmann Distribution. We’ll see it derived again when we get to statistical mechanics. This distribution describes how the energy of a closed system is distributed in equilibrium.\n\n\nIdeal Gas\nSuppose we’re dealing with a stationary gas of free particles, so \\(\\boldsymbol{\\pi} = \\mathbf{0}\\) and \\(V(\\mathbf{x}) = 0\\) inside the box. Then \\[\n\\rho_{eq}(\\mathbf{p}) = \\bigg(\\frac{\\beta}{2\\pi m}\\bigg)^{3/2} \\exp\\bigg(-\\frac{\\beta}{2m}\\mathbf{p}^2\\bigg).\n\\] Since this is an uncorrelated Gaussian, we can read off that each component of \\(\\mathbf{p}\\) has variance \\(\\langle p_i^2 \\rangle = \\frac{m}{\\beta}\\). The variance of \\(\\mathbf{p}\\) is thus evidently just \\[\n\\langle \\mathbf{\\mathbf{p}}^2 \\rangle = \\langle p_x^2 \\rangle + \\langle p_y^2 \\rangle + \\langle p_z^2 \\rangle = \\frac{3m}{\\beta}.\n\\] Plugging this into the Hamiltonian we can find an expression for the average internal kinetic energy of a free gas at equilibrium. We have \\[\nE \\equiv \\langle H \\rangle = \\frac{\\langle \\mathbf{p}^2 \\rangle}{2m} = \\frac{3}{2\\beta} = \\frac{3}{2} k_B T.\n\\] Evidently, a gas of free particles in a box is just the ideal gas, with \\(\\beta = \\frac{1}{k_B T}\\).\nIf we like we can also find the equation of state by calculating the force exerted on the walls of the box. To do that, let’s look at the force exerted on one of the walls of the box, say the wall on the positive x-axis. Evidently the number of particles \\(\\delta N_x\\) with momentum \\(p_x = mv_x\\) that collide with the wall in a time \\(\\delta t\\) is given by density times volume, i.e. \\[\n\\delta N_x = d^3 \\mathbf{p} \\ f(\\mathbf{p}) \\ A v_x \\delta t.\n\\] Assuming each collision is elastic, the momentum change in colliding with the wall is \\(\\Delta p_x = 2p_x\\). Then the force \\(F\\) exerted on the wall is \\[\nF = \\frac{1}{2\\delta t} \\int \\delta N_x \\ \\Delta p_x = \\int d^3 \\mathbf{p} \\ f(\\mathbf{p}) \\ A \\frac{p_x^2}{m}.\n\\] Using this force on the wall we can calculate the pressure of the gas by dividing by the wall area \\(A\\). Plugging in the distribution for momenta, we have \\[\nP = \\int d^3 \\mathbf{p} \\ f(\\mathbf{p}) \\ \\frac{p_x^2}{m} = \\int d^3 \\mathbf{p} \\ \\frac{p_x^2}{m} n\\bigg(\\frac{\\beta}{2\\pi m}\\bigg)^{3/2} \\exp\\bigg(-\\frac{\\beta}{2m}\\mathbf{p}^2\\bigg) = \\frac{n}{\\beta}.\n\\] Using the fact that \\(n = \\frac{N}{V}\\) and \\(\\beta = \\frac{1}{k_B T}\\), we’ve evidently derived the ideal gas law, \\[\nPV = N k_B T.\n\\] Insisting a free gas reduce to an ideal gas at equilibrium again supports that \\(\\beta = \\frac{1}{k_B T}\\).\nIf desired, one can calculate the entropy too by using \\(S \\equiv -k_B \\mathrm{H}\\) and doing the integral for \\(\\mathrm{H}\\). The result will be (up to an additive constant) the entropy for a monoatomic ideal gas. ### Maxwell-Boltzmann Distribution\nWe can also ask about the distribution for the speed \\(v\\) of an ideal gas at equilibrium. Using the relation \\(\\mathbf{p} = m \\mathbf{v}\\), we then have \\[\n\\rho_{eq}(\\mathbf{v}) = \\bigg(\\frac{m}{2\\pi k_B T}\\bigg)^{3/2} \\exp\\bigg(-\\frac{m\\mathbf{v}^2}{2k_B T}\\bigg).\n\\] This is the distribution for the velocity of a gas in the rest frame, not the speed. It’s evidently a mean-zero Gaussian distribution with variance \\(\\frac{k_B T}{m}\\). The ratio \\(v_{th}^2 \\equiv \\frac{k_B T}{m}\\) has dimensions of velocity squared. That velocity \\(v_{th}\\) is amply referred to as the root mean square (RMS) velocity. We’ve actually seen it already. It’s the velocity one gets from setting the kinetic energy equal to the mean thermal energy \\(k_B T\\). Practically all velocities of interest in thermodynamics are on the order of the RMS velocity.\nAnyway, notice the distribution depends only on the speed since \\(v^2 = \\mathbf{v}^2\\). It may seem like the distribution for \\(v\\) should be a Gaussian, but it’s not. The reason is we have to integrate over the volume element, \\[\n1 = \\int d^3 \\mathbf{v} \\ \\rho_{eq}(\\mathbf{v}) = \\int v^2 dv d\\Omega \\ \\rho_{eq}(|\\mathbf{v}|) = \\int dv \\ 4\\pi v^2\\rho_{eq}(|\\mathbf{v}|) \\equiv \\int dv \\ \\rho_{eq}(v).\n\\] This distribution for the particle speeds at equilibrium is called the Maxwell-Boltzmann Distribution, \\[\n\\boxed{\\rho_{eq}(v) = \\bigg(\\frac{m}{2\\pi k_B T}\\bigg)^{3/2} 4\\pi v^2 \\exp\\bigg(-\\frac{mv^2}{2k_B T}\\bigg)} \\ .\n\\] Since speeds are non-negative this is a rightward-skewed distribution. This means its mean won’t be zero like with the vector velocities. This makes sense, as a mean zero speed would imply the particles aren’t moving at all. In fact, the mean speed is proportional to the RMS velocity, \\[\n\\langle v \\rangle = 2\\sqrt{\\frac{2}{\\pi}} \\sqrt{\\frac{k_B T}{m}} \\approx 1.6 \\ v_{th}.\n\\]",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Kinetic Theory</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/kinetic-theory.html#conservation-laws",
    "href": "statistical-mechanics/kinetic-theory.html#conservation-laws",
    "title": "Kinetic Theory",
    "section": "Conservation Laws",
    "text": "Conservation Laws\nSo far all we’ve done is derived the equilibrium distribution for a gas at equilibrium. But we don’t need kinetic theory to do this. As we’ll see, we can do that much more easily using statistical mechanics. What kinetic theory is really useful for is describing how the system approaches equilibrium. Specifically, what we really want to know is how the usual conserved quantities like particle number, energy, and momentum approach equilibrium. To do that we need to figure out what the dynamics are of conserved quantities.\n\nCollision-Conserved Quantities\nWe’ll specifically want to focus on collision conserved quantities. The ones that satisfy detailed balance conditions. We say \\(\\chi\\) is a collision conserved quantity if for any two colliding particles we have \\[\n\\chi_1 + \\chi_2 = \\chi'_1 + \\chi'_2.\n\\] A collision conserved quantity satisfies the useful property that the quantity \\(J(\\mathbf{x},t)\\) defined by \\[\nJ(\\mathbf{x},t) \\equiv \\int d^3 \\mathbf{p} \\ \\chi(\\mathbf{x}, \\mathbf{p},t) C[f]\n\\] vanishes. To see why, just substitute in the integral for \\(C[f]\\) and perform the same steps used in the proof of the H-theorem. Doing those manipulations with \\(\\log f\\) replaced by \\(\\chi\\) will give an integral of the form \\[\nJ(\\mathbf{x},t) = \\frac{1}{4} \\int d^3 \\mathbf{p}_1 \\ d^3 \\mathbf{p}_2 \\ \\frac{|\\mathbf{p}_2 - \\mathbf{p}_1|}{m} \\big[f(\\mathbf{p}_1)f(\\mathbf{p}_2)-f(\\mathbf{p}'_1)f(\\mathbf{p}'_2)\\big] \\big[\\chi(\\mathbf{p}_1) + \\chi(\\mathbf{p}_2) - \\chi(\\mathbf{p}'_1) - \\chi(\\mathbf{p}'_2)\\big].\n\\]\nProvided \\(\\chi\\) is a collision-conserved quantity the last term is zero, hence we get \\(J(\\mathbf{x},t) = 0\\).\nNow, notice if the system satisfies the Boltzmann equation we can replace \\(C[f]\\) with \\(L[f]\\) in the integral, \\[\n0 = \\int d^3 \\mathbf{p} \\ \\chi \\ L[f] = \\int d^3 \\mathbf{p} \\ \\chi \\ \\bigg(\\frac{\\partial}{\\partial t} + \\frac{\\mathbf{p}}{m} \\cdot \\frac{\\partial }{\\partial \\mathbf{x}} + \\mathbf{F} \\cdot \\frac{\\partial}{\\partial \\mathbf{p}} \\bigg) f.\n\\] We can manipulate this expression to get a useful differential equation for the field \\(\\chi(\\mathbf{x},t)\\). Since \\(L\\) is an operator of first derivatives we can apply the product rule to write \\[\n\\chi \\cdot L[f] = L[f \\cdot \\chi] - f \\cdot L[\\chi].\n\\] Plugging this in, we get \\[\n0 = \\int d^3 \\mathbf{p} \\ \\bigg[\\bigg(\\frac{\\partial (f \\cdot \\chi)}{\\partial t} + \\frac{\\mathbf{p}}{m} \\cdot \\frac{\\partial (f \\cdot \\chi)}{\\partial \\mathbf{x}} + \\mathbf{F} \\cdot \\frac{\\partial (f \\cdot \\chi)}{\\partial \\mathbf{p}} \\bigg) - \\bigg(\\frac{\\partial \\chi}{\\partial t} + \\frac{\\mathbf{p}}{m} \\cdot \\frac{\\partial \\chi}{\\partial \\mathbf{x}} + \\mathbf{F} \\cdot \\frac{\\partial \\chi}{\\partial \\mathbf{p}} \\bigg) f \\bigg].\n\\] At this point it’s useful to define a collision average. Notice the number density can be given by marginalizing out the momentum, \\[\nn(\\mathbf{x}, t) = \\int d^3 \\mathbf{p} \\ f(\\mathbf{x}, \\mathbf{p}, t).\n\\] Using this fact, we can define a collision average on any phase space function \\(\\chi\\) by \\[\n\\boxed{\\big\\langle \\chi(\\mathbf{x},t) \\big\\rangle_{c} \\equiv \\frac{1}{n(\\mathbf{x}, t)} \\int d^3 \\mathbf{p} \\ f(\\mathbf{x}, \\mathbf{p}, t) \\ \\chi(\\mathbf{x}, \\mathbf{p}, t)} \\ .\n\\] Going back to our expression for \\(J(\\mathbf{x},t)\\), notice we can pull any terms and derivatives that doesn’t depend on \\(\\mathbf{p}\\) out of the integral. The terms remaining under the integral can then be written as collision averages, \\[\n\\boxed{\\frac{\\partial}{\\partial t} n\\big\\langle \\chi \\big\\rangle_{c} + \\frac{\\partial}{\\partial \\mathbf{x}} \\cdot n\\bigg\\langle \\frac{\\mathbf{p}}{m} \\chi \\bigg\\rangle_{c} - \\ n \\bigg\\langle \\frac{\\partial \\chi}{\\partial t} \\bigg\\rangle_{c} - \\ n \\bigg\\langle \\frac{\\mathbf{p}}{m} \\cdot\\frac{\\partial \\chi}{\\partial \\mathbf{x}}\\bigg\\rangle_{c} - n \\mathbf{F} \\cdot \\bigg\\langle \\frac{\\partial \\chi}{\\partial \\mathbf{p}}\\bigg\\rangle_{c} = 0 } \\ .\n\\] Note the integral over \\(\\mathbf{F} \\cdot \\frac{\\partial (f \\cdot \\chi)}{\\partial \\mathbf{p}}\\) vanishes since it’s a total time derivative. The above equation is called the hydrodynamics equation or the conservation law for the field \\(\\chi(\\mathbf{x},t)\\). Unlike typical conservation laws in classical mechanics, these conservation laws are local.\n\n\nParticle Number\nThe particular conservation laws we’ll focus on are the usual ones for a gas: particle number (or mass), momentum, and kinetic energy. To find the conservation law for particle number or mass, take \\(\\chi = 1\\). In that case, all the derivatives of \\(\\chi\\) vanish, so we’re left with \\[\n\\frac{\\partial n}{\\partial t} + \\frac{\\partial}{\\partial \\mathbf{x}} n\\bigg\\langle \\frac{\\mathbf{p}}{m} \\bigg\\rangle_{c} = 0.\n\\] The collision average of \\(\\frac{\\mathbf{p}}{m}\\) gives some kind of velocity field \\(\\mathbf{u}(\\mathbf{x},t)\\). This is the flow velocity of the gas, treated as a kind of continuous fluid. We can thus write \\[\n\\boxed{\\frac{\\partial n}{\\partial t} + \\nabla \\cdot n \\mathbf{u}  = 0} \\ .\n\\] This is the well-known continuity equation, in this case for the particle number.\nThis says that at any region of space, particle number must be conserved. To see why, if we integrate the equation with respect to volume and use the divergence theorem, we have \\[\n\\frac{d}{dt} \\int_\\mathcal{V} d^3 \\mathbf{x} \\ n = \\int_\\mathcal{S} n \\mathbf{u} \\cdot d\\mathbf{a}.\n\\] That is, the only way particle number inside a region \\(\\mathcal{V}\\) can change is by flowing out of its surface \\(\\mathcal{S}\\). Over all space, the right-hand side must vanish for physical reasons, which just says total particle number is conserved, \\[\n\\frac{dN}{dt} = 0.\n\\] The same equation holds for mass density \\(\\rho \\equiv mn\\) by multiplying both sides of the continuity equation by the mass \\(m\\). In that language it expresses the conservation of mass for the gas. It’s sometimes useful to re-write the continuity equation in terms of the material derivative. To do that we need to factor out the \\(\\mathbf{u}\\) from the divergence using the product rule. We then get \\[\n\\boxed{\\frac{Dn}{Dt} = -n \\nabla \\cdot \\mathbf{u}} \\ .\n\\] This form is particularly useful when dealing with an incompressible fluid, since in that case \\(\\nabla \\cdot \\mathbf{u} = 0\\), implying the fluid has uniform density. Incompressible fluids are more characteristic of liquids than gases, however, since we can practically always compress a gas by applying pressure to it.\n\n\nMomentum\nThe next conservation law we’ll derive is conservation of momentum. Rather than take \\(\\chi\\) to be the momentum \\(\\mathbf{p}\\) directly, it’s more useful to take it to be the relative particle velocity \\[\n\\mathbf{c} \\equiv \\frac{\\mathbf{p}}{m} - \\mathbf{u}.\n\\] Let’s apply the conservation law to one of the components of \\(\\mathbf{c}\\) by taking \\(\\chi = c_\\alpha\\). This definition has the advantage that \\(\\langle c_\\alpha \\rangle_{c}\\) vanishes, which simplifies calculations somewhat. Noting that \\(\\frac{\\mathbf{p}}{m} = \\mathbf{c} + \\mathbf{u}\\), and using the summation convention, we have $$ \\[\\begin{align*}\n0 &= \\frac{\\partial}{\\partial x_\\beta} n\\bigg\\langle \\frac{p_\\beta}{m} c_\\alpha \\bigg\\rangle_c - \\ n \\bigg\\langle \\frac{\\partial c_\\alpha}{\\partial t} \\bigg\\rangle_c - \\ n \\bigg\\langle \\frac{p_\\beta}{m} \\frac{\\partial c_\\alpha}{\\partial x_\\beta}\\bigg\\rangle_c - n F_\\beta \\cdot \\bigg\\langle \\frac{\\partial c_\\alpha}{\\partial p_\\beta}\\bigg\\rangle_c \\\\\n\n&= \\frac{\\partial}{\\partial x_\\beta} n\\bigg\\langle (c_\\beta+u_\\beta) c_\\alpha \\bigg\\rangle_c - \\ n \\bigg\\langle \\frac{\\partial c_\\alpha}{\\partial t} \\bigg\\rangle_c - \\ n \\bigg\\langle (c_\\beta+u_\\beta) \\frac{\\partial c_\\alpha}{\\partial x_\\beta}\\bigg\\rangle_c - n F_\\beta \\cdot \\bigg\\langle \\frac{\\partial c_\\alpha}{\\partial p_\\beta}\\bigg\\rangle_c \\\\\n&= \\frac{\\partial}{\\partial x_\\beta} n \\big\\langle c_\\alpha c_\\beta \\big\\rangle_c + n \\frac{\\partial u_\\alpha}{\\partial t} + n u_\\beta \\frac{\\partial u_\\alpha}{\\partial x_\\beta} - n F_\\beta \\frac{\\delta_{\\alpha\\beta}}{m} \\\\\n&= \\frac{\\partial}{\\partial x_\\beta} nm \\big\\langle c_\\alpha c_\\beta \\big\\rangle_c + nm \\frac{\\partial u_\\alpha}{\\partial t} + nm u_\\beta \\frac{\\partial u_\\alpha}{\\partial x_\\beta} - n F_\\alpha.\n\\end{align*}\\] $$\nWe evidently have a differential equation for the flow velocity \\(\\mathbf{u}\\). The only unfamiliar term is the first one, which is evidently the gradient of a symmetric rank-two tensor. This is the pressure tensor, defined by \\[\nP_{\\alpha\\beta} \\equiv nm \\big\\langle c_\\alpha c_\\beta \\big\\rangle_c \\ , \\quad \\text{or} \\quad \\mathbf{P} \\equiv nm\\langle \\mathbf{c} \\otimes \\mathbf{c} \\rangle_c \\ .\n\\] Plugging the pressure tensor in and re-arranging, we see that each component of the flow velocity satisfies a conservation law of the form \\[\n\\frac{\\partial u_\\alpha}{\\partial t} + u_\\beta \\frac{\\partial u_\\alpha}{\\partial x_\\beta} = \\frac{F_\\alpha}{m} - \\frac{1}{nm} \\frac{\\partial P_{\\alpha\\beta}}{\\partial x_\\beta}.\n\\] If we think of the velocity gradient as being done component-wise and the divergence on the right as a contraction over one of the indices, then we can write this conservation law in vector notation as \\[\n\\boxed{nm \\frac{D \\mathbf{u}}{Dt} = n \\mathbf{F} - \\nabla \\cdot \\mathbf{P}} \\ .\n\\] This is called the Cauchy momentum equation. Notice how this conservation law looks something like Newton’s second law. On the left is a kind of mass times acceleration term, while on the right are the two kinds of forces acting on each gas particle, the external forces and the internal pressure-driven forces.\n\n\nEnergy\nThe final conservation law we’ll consider is the one for kinetic energy. Again, it’s convenient to look instead at the relative kinetic energy \\(\\chi = \\frac{1}{2} m \\mathbf{c}^2\\). Define the energy density or the heat flux \\(\\varepsilon\\) to be the collision average of the relative kinetic energy, \\[\n\\varepsilon \\equiv \\frac{1}{2} m \\big\\langle \\mathbf{c}^2 \\big\\rangle_c.\n\\] It’s also helpful to define a vector \\(\\mathbf{h}\\) called the heat flux given by \\[\n\\mathbf{h} \\equiv \\frac{1}{2} nm \\big\\langle \\mathbf{c}^2 \\mathbf{c} \\big\\rangle_c.\n\\] Last, it’s helpful to define another symmetric rank-two tensor \\(\\mathbf{U}\\) called the rate of strain tensor. Its components are the symmetrized gradients of \\(\\mathbf{c}\\), i.e. \\[\nU_{\\alpha\\beta} \\equiv \\frac{\\partial u_\\alpha}{\\partial x_\\beta} + \\frac{\\partial u_\\beta}{\\partial x_\\alpha}.\n\\] With these definitions, after a lot of tedious work we can express the conservation law for kinetic energy in component form (again using the summation convention) as \\[\n\\frac{\\partial \\varepsilon}{\\partial t} + u_\\alpha \\frac{\\partial \\varepsilon}{\\partial x_\\alpha}  = -\\frac{1}{n}\\frac{\\partial h_\\alpha}{\\partial x_\\alpha} - \\frac{1}{n}P_{\\alpha\\beta} U_{\\alpha\\beta} \\ .\n\\] The first term on the right is the divergence of the heat flux. The second term is the trace over the matrix product of the pressure tensor with the rate of strain. With this in mind, we can express this equation in vector notation as \\[\n\\boxed{n\\frac{D\\varepsilon}{Dt} = -\\nabla \\cdot \\mathbf{h} - \\text{tr}(\\mathbf{P} \\cdot \\mathbf{U})} \\ .\n\\] Roughly speaking, this conservation law expresses the first law of thermodynamics. The left-hand-side is the change in the total energy, while the right-hand side is the change in heat plus the change in work.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Kinetic Theory</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/kinetic-theory.html#approach-to-equilibrium",
    "href": "statistical-mechanics/kinetic-theory.html#approach-to-equilibrium",
    "title": "Kinetic Theory",
    "section": "Approach to Equilibrium",
    "text": "Approach to Equilibrium\nAs was already mentioned, our whole purpose in deriving collision conserved quantities and conservation laws was to study how systems approach equilibrium. To do this we’ll want to study the solutions of the conservation laws as \\(t \\rightarrow \\infty\\). To approach equilibrium, each conserved quantity should approach a constant value, its equilibrium value.\n\nZeroth-Order Solutions\nWhile all these conservation equations are nice, we still don’t know how to solve them. To do that we’d need to know the pressure tensor and the heat flux, both of which require that we already know the density. Usually we don’t know the full density. What we’ll try to do instead is expand the density in terms of the parameter \\(\\frac{\\tau_X}{\\tau_{\\text{ext}}}\\), the characteristic inverse time scale of \\(L[f]\\). In the limit where external forces act on much larger time scales than the collision forces this parameter will be small.\nLet’s start by calculating the zeroth order density \\(f^0\\). In the zeroth order case we’re assuming \\(\\tau_{\\text{ext}} \\rightarrow \\infty\\), hence \\(C[f^0] = 0\\). We already saw using detailed balance that such a distribution is just a Gaussian in terms of the momenta or velocity. If we write \\[\n\\mathbf{c}(\\mathbf{x}, t) = \\mathbf{p} - m\\mathbf{u}(\\mathbf{x}, t) = \\mathbf{p} - \\boldsymbol{\\pi}(\\mathbf{x}, t),\n\\] and choose \\(\\beta = \\frac{1}{k_B T}\\) as before, then the zeroth order distribution can be written as \\[\nf^0(\\mathbf{x}, \\mathbf{p}, t) \\equiv n(\\mathbf{x}, t)\\bigg(\\frac{m}{2\\pi k_B T(\\mathbf{x}, t)}\\bigg)^{3/2} \\exp\\bigg(-\\frac{m\\mathbf{c}^2}{2k_B T(\\mathbf{x}, t)}\\bigg).\n\\] This is a mean-zero Gaussian distribution in \\(\\mathbf{c}\\) with variance \\(\\frac{k_B T}{m}\\). Let’s assume this is the density and see what we can deduce about the conservation laws and how they approach equilibrium.\nSince we’re dealing with a Gaussian, we can use Wick’s theorem to conclude the odd-power moments are zero. This means that the heat flux vanishes, since \\[\n\\mathbf{h} = \\frac{1}{2} nm \\big\\langle \\mathbf{c}^2 \\mathbf{c} \\big\\rangle_c = \\mathbf{0} .\n\\] The pressure tensor, however, is an even moment. Since the covariance of \\(f^0\\) is diagonal, we just have \\[\n\\mathbf{P} = nm \\big\\langle \\mathbf{c} \\otimes \\mathbf{c} \\big\\rangle_c = nm \\frac{k_B T}{m} \\ \\mathbf{1} = nk_B T \\ \\mathbf{1}.\n\\] Last, the energy density is just \\[\n\\varepsilon = \\frac{m}{2} \\big\\langle \\mathbf{c}^2 \\big\\rangle_c = \\frac{m}{2} \\frac{3k_B T}{m} = \\frac{3}{2} k_B T.\n\\]\nTogether, these mean that the three conservation laws can be written as \\[\n\\begin{align*}\n\\frac{Dn}{Dt} &= -n \\nabla \\cdot \\mathbf{u}  \\\\\n\\frac{D\\mathbf{u}}{Dt} &= \\frac{1}{m} \\mathbf{F} -\\frac{k_B}{nm} \\nabla nT  \\\\\n\\frac{DT}{Dt} &= -\\frac{2}{3} T \\ \\nabla \\cdot \\mathbf{u} \\ \\ . \\\\\n\\end{align*}\n\\] Let’s try to combine the first and last equation and see what we get. Notice both terms contain a divergence \\(\\nabla \\cdot \\mathbf{u}\\). If we solve for the divergence in the first equation and plug it into the third, we get \\[\n\\begin{align*}\n&\\frac{DT}{Dt} = -\\frac{2}{3} T \\ \\nabla \\cdot \\mathbf{u} = \\frac{2T}{3n} \\frac{Dn}{Dt} \\\\\n&\\Longrightarrow \\quad \\frac{3}{2} \\frac{D}{Dt} \\log T - \\frac{D}{Dt} \\log n = 0 \\\\\n&\\Longrightarrow \\quad \\frac{D}{Dt} \\log n T^{-3/2} = 0.\n\\end{align*}\n\\] That is, along any given streamline the quantity \\(\\log n T^{-3/2}\\) is constant. This quantity is a kind of local entropy since \\(dS \\sim \\log n T^{-3/2} d^3 \\mathbf{x}\\). We’ve thus shown that the zeroth order solution implies \\(dS=0\\), i.e. the entire process is adiabatic for all time. This in particular means entropy can’t increase to a maximum, which implies that the system will never come to equilibrium unless it starts out in equilibrium. Evidently the zeroth order approximation isn’t enough to get equilibrium. We’ll need to go further.\nLet’s look at this more formally first. For the system to always converge to equilibrium the solutions need to be stable. That is, if any conserved quantity is nudged from equilibrium it should relax back to equilibrium. Suppose the system is initially in equilibrium. Suppose we make the following first-order perturbations, \\[\n\\begin{align*}\nn(\\mathbf{x}, t) &= n_0 + \\nu(\\mathbf{x}, t) \\\\\nT(\\mathbf{x}, t) &= T_0 + \\theta(\\mathbf{x}, t) \\ . \\\\\n\\end{align*}\n\\] For simplicity, assume no external forces act inside the box and at equilibrium the box is at rest. In that case, to first order \\(\\frac{D}{Dt} \\approx \\frac{\\partial}{\\partial t}\\). Plugging these into the conservation laws and keeping only terms to first order, we get \\[\n\\begin{align*}\n\\frac{\\partial\\nu}{\\partial t} &\\approx -n_0 \\nabla \\cdot \\mathbf{u}  \\\\\n\\frac{\\partial\\mathbf{u}}{\\partial t} &\\approx -\\frac{k_B T_0}{mn_0} \\nabla \\nu - \\frac{k_B}{m} \\nabla \\theta \\\\\n\\frac{\\partial\\theta}{\\partial t} &\\approx -\\frac{2}{3} T_0 \\ \\nabla \\cdot \\mathbf{u} \\ \\ . \\\\\n\\end{align*}\n\\]\nNow let’s Fourier transform these first order quantities and look at their normal modes. The natural frequencies \\(\\omega(\\mathbf{k})\\) and the normal modes are the solutions to the following eigenvalue equation, \\[\n\\begin{pmatrix}\n0 & n_0 \\mathbf{k} & 0 \\\\\n\\frac{k_B T_0}{mn_0} \\mathbf{k} & 0 & \\frac{k_B}{m} \\mathbf{k}  \\\\\n0 & \\frac{2}{3} T_0 \\mathbf{k} & 0 \\\\\n\\end{pmatrix}\n\\begin{pmatrix}\n\\tilde \\nu \\\\\n\\mathbf{\\tilde u} \\\\\n\\tilde \\theta \\\\\n\\end{pmatrix} =\n\\omega\n\\begin{pmatrix}\n\\tilde \\nu \\\\\n\\mathbf{\\tilde u} \\\\\n\\tilde \\theta \\\\\n\\end{pmatrix}.\n\\] Note the block notation being used. This is really a \\(5 \\times 5\\) matrix multiplying a size \\(5\\) vector. There are thus \\(5\\) distinct normal modes that satisfy this equation. To get the modes we need to solve the characteristic equation, which turns out to be \\[\n\\text{det}(\\mathbf{A} - \\omega \\mathbf{I}) = \\omega^3\\bigg(\\omega^2 - \\frac{5k_B T_0}{3m} \\bigg) = 0.\n\\]\n\nThe first mode is a stationary mode, one of the zero modes with \\(\\omega = 0\\). The modes themselves are \\[\n\\tilde\\nu = \\text{const}, \\quad \\mathbf{\\tilde u} = \\mathbf{0}, \\quad \\tilde \\theta = \\text{const},\n\\] meaning that the fluid is essentially stationary for all frequencies. This implies the fluid maintains uniform pressure \\(P = n k_B T_0\\), which ensures that the fluid can’t start moving due to pressure variations since \\(\\Delta S \\sim nT_0\\) is constant.\nThe next two modes are sound modes, where \\(\\omega = \\pm v_s |\\mathbf{k}|\\). Here \\(v_s\\) is the speed of sound of the fluid, given by \\[\nv_s \\equiv \\sqrt{\\frac{\\gamma k_B T_0}{m}}, \\quad \\text{where} \\quad \\gamma = \\frac{5}{3}\n\\] is the adiabatic constant for a monoatomic ideal gas. Sound modes represent pressure waves propagating outward forever without damping. All of the conserved quantities propagate as longitudinal waves along the \\(\\mathbf{k}\\) direction, since \\[\n\\tilde\\nu = n_0 |\\mathbf{k}|, \\quad \\mathbf{\\tilde u} = \\pm v_s \\mathbf{k}, \\quad \\tilde\\theta = \\frac{2}{3} T_0 |\\mathbf{k}|.\n\\]\nThe last two modes are shearing modes. These are also zero modes with \\(\\omega = 0\\), but they correspond to motion in the transverse directions orthogonal to \\(\\mathbf{k}\\). This means we’d have \\[\n\\tilde \\nu = \\text{const}, \\quad \\mathbf{\\tilde u} \\cdot \\mathbf{k} = 0, \\quad \\tilde \\theta = \\text{const}.\n\\] Transverse motions in a fluid create a shearing effect. Since \\(\\mathbf{\\tilde u}\\) stays constant for shearing modes, each quantity will just continue forever without damping.\n\nWe thus find that none of the conserved quantities relax to equilibrium to zeroth-order. Shear flow and entropy modes persist forever, while the two sound modes have undamped oscillations. Since none of the normal modes in general relax to equilibrium, neither will any general solutions, which are themselves just superpositions of normal modes.\n\n\nFirst-Order Solutions\nWe thus have to move onto first order solutions. Instead of assuming an infinite \\(\\tau_{\\text{ext}}\\), we’ll assume it’s small to first order compared to \\(\\tau_X\\). This brings the left-hand side \\(L[f]\\) of Boltzmann’s equation back into the game. We’ll assume a first-order density of the form \\[\nf^1(\\mathbf{x}, \\mathbf{p}, t) = f^0(\\mathbf{x}, \\mathbf{p}, t) \\big(1 + g(\\mathbf{x}, \\mathbf{p}, t)\\big),\n\\] where \\(g(\\mathbf{x}, \\mathbf{p}, t)\\) is assumed to be related to the inverse time scale \\(\\frac{\\tau_X}{\\tau_{\\text{ext}}} \\ll 1\\). To evaluate \\(C[f^1]\\) we have to linearize the integral. To do so we’ll employ the single collision time approximation, which says that \\[\nC[f^1] \\approx -f^0 \\frac{g}{\\tau_X}.\n\\] If we assume \\(g\\) is in some sense small, then \\(L[f^1] = L[f^0]+L[f^0g]] \\approx L[f^0]\\). We thus have that \\[\nL[f^0] \\approx -f^0 \\frac{g}{\\tau_X},\n\\] Using the expression for \\(f^0\\) found already, this means \\[\ng = - \\tau_X L[\\log f^0] = - \\tau_X L\\bigg[\\log \\bigg(n\\bigg(\\frac{m}{2\\pi k_B T}\\bigg)^{3/2} \\exp\\bigg(-\\frac{m\\mathbf{c}^2}{2k_B T}\\bigg)\\bigg)\\bigg].\n\\] Now, observe we can re-write the Liouville operator in a more useful way in terms of \\(\\mathbf{u}\\) instead of \\(\\mathbf{p}\\) as \\[\nL[f] = \\frac{Df}{Dt} + \\mathbf{c} \\cdot \\frac{\\partial f}{\\partial \\mathbf{x}} + \\mathbf{F} \\cdot \\frac{\\partial f}{\\partial \\mathbf{p}}.\n\\] Combining all of these facts together and using the zeroth-order conservation laws we already derived, we finally get \\[\n\\begin{align*}\ng &= -\\tau_X \\ L[\\log f^0] \\\\\n&= -\\tau_X \\ L\\bigg[\\log n - \\frac{3}{2} \\log \\frac{2\\pi k_B T}{m} - \\frac{mc^2}{2 k_B T} \\bigg] \\\\\n&= -\\tau_X \\ \\bigg(\\frac{D}{Dt} + \\mathbf{c} \\cdot \\frac{\\partial}{\\partial \\mathbf{x}} + \\mathbf{F} \\cdot \\frac{\\partial}{\\partial \\mathbf{p}}\\bigg)\\bigg[\\log n - \\frac{3}{2} \\log \\frac{2\\pi k_B T}{m} - \\frac{mc^2}{2 k_B T} \\bigg] \\\\\n&= -\\tau_X \\bigg[\\frac{m}{k_B T} U_{ij} \\bigg(c_i c_j - \\frac{c^2}{3} \\delta_{ij}\\bigg) + \\bigg(\\frac{m c^2}{2k_B T} - \\frac{5}{2} \\bigg) \\frac{c_i}{T} \\frac{\\partial T}{\\partial x_i}\\bigg]. \\\\\n\\end{align*}\n\\] This means the first-order density in full is given in vector notation as \\[\n\\begin{align*}\nf^1(\\mathbf{x}, \\mathbf{p},t) = \\ &n\\bigg(\\frac{m}{2\\pi k_B T}\\bigg)^{3/2} \\exp\\bigg(-\\frac{m\\mathbf{c}^2}{2k_B T}\\bigg) \\ \\times \\\\\n&\\bigg\\{1 -\\tau_X \\bigg[\\frac{m}{k_B T}\\text{tr}\\bigg( \\mathbf{U} \\cdot \\bigg(\\mathbf{c} \\otimes \\mathbf{c} - \\frac{c^2}{3} \\mathbf{I}\\bigg)\\bigg) + \\bigg(\\frac{m c^2}{2k_B T} - \\frac{5}{2} \\bigg) \\mathbf{c} \\cdot \\frac{\\nabla T}{T} \\bigg]\\bigg\\}.\n\\end{align*}\n\\] The term involving the trace of velocities represents the correlation of particle velocity with the rate of strain tensor. It describes how velocities vary due to fluid strain. The term involving the temperature gradient says something about how velocities depend on temperature gradients across the fluid. Together, these effects give the density an anisotropic, multimodal behavior.\nAfter some work, it turns out that integrating \\(f^1\\) again gives the particle density, \\[\nn(\\mathbf{x},t) = \\int d^3 \\mathbf{p} \\ f^1(\\mathbf{x}, \\mathbf{p}, t).\n\\] We can more quickly calculate the first-order collision averages in terms of the zeroth-order averages as \\[\n\\langle \\chi(\\mathbf{x},t) \\rangle_c^1 = \\frac{1}{n(\\mathbf{x},t)} \\int d^3 \\mathbf{p} \\ \\chi(\\mathbf{x},t) f^0(\\mathbf{x}, \\mathbf{p}, t)\\big(1+g(\\mathbf{x}, \\mathbf{p}, t)\\big) = \\big\\langle \\chi(\\mathbf{x},t) \\big\\rangle_c^0 + \\big\\langle g(\\mathbf{x}, t) \\chi(\\mathbf{x},t) \\big\\rangle_c^0 \\ .\n\\] All quantities of interest involve calculating moments of \\(\\mathbf{c}\\). Notice that the first-order correction now contains terms proportional to both \\(c\\) and \\(c^3\\), which means the first and third moments no longer vanish. Together, these will imply the existence of a non-zero heat flux vector and a non-diagonal pressure tensor. We can use Wick’s theorem to calculate these values to eventually get \\[\n\\begin{align*}\n\\mathbf{P} &= nm \\langle \\mathbf{c}\\otimes\\mathbf{c} \\rangle_c^1 = nk_B T \\bigg[\\mathbf{1} - 2 \\tau_X \\bigg(\\mathbf{U} - \\frac{u^2}{3} \\mathbf{1}\\bigg)\\bigg], \\\\\n\\varepsilon &= \\frac{1}{2} m \\langle c^2 \\rangle_c^1 = \\frac{3}{2} k_B T, \\\\\n\\mathbf{h} &= \\frac{1}{2} mn \\langle c^2 \\mathbf{c} \\rangle_c^1 = -\\frac{5 \\tau_X nk_B^2 T}{2m} \\nabla T.\n\\end{align*}\n\\] The coefficient \\(\\mu \\equiv nk_B T \\tau_X\\) in the off diagonals of the pressure tensor is the viscosity coefficient. The off-diagonals cause the fluid to shear against opposing viscous forces that go like \\(\\mu \\nabla^2 \\mathbf{u}\\). Similarly, the coefficient \\(K \\equiv \\frac{5 \\tau_X nk_B^2 T}{2m}\\) is the thermal conductivity coefficient of the gas. In particular, when the gas is at rest and the pressure is uniform, we get \\[\n\\frac{\\partial T}{\\partial t} = \\alpha \\nabla^2 T,\n\\] which is a classic diffusion equation for the temperature, called the Fourier equation. Recall that solutions to diffusion equations will always settle down into an equilibrium state as \\(t \\rightarrow \\infty\\). The diffusion coefficient \\[\n\\alpha(T) \\equiv \\frac{2K}{3nk_B} = \\frac{5\\tau_X k_B T}{3m}\n\\] characterizes the inverse time scale over which the temperature relaxes to its equilibrium temperature. For variations on distance scales of \\(\\lambda\\), the heat equation relaxes on a time scale of \\[\n\\tau_{\\text{diff}} \\sim \\frac{\\lambda^2}{\\alpha}.\n\\] The fluid velocity relaxes according to a similar diffusion equation brought on by the shearing in the pressure tensor.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Kinetic Theory</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/classical-stat-mech.html",
    "href": "statistical-mechanics/classical-stat-mech.html",
    "title": "Classical Statistical Mechanics",
    "section": "",
    "text": "Formal Definition\nSuppose we have a system of \\(N\\) particles in equilibrium whose phase space configuration is described by a microstate \\(\\boldsymbol{\\mu} \\equiv \\{\\mathbf{x}_i, \\mathbf{p}_i\\}\\) . Suppose we’re interested in studying some set of macroscopic equilibrium properties described by a macrostate \\(M=(E,X,N)\\). For a given macrostate \\(M\\), suppose the equilibrium phase space density for the system to be in some microstate \\(\\boldsymbol{\\mu}\\) is given by a probability distribution \\(p_M(\\boldsymbol{\\mu})\\). Let’s define statistical mechanics as the probabilistic study of the equilibrium macrostates \\(M\\) of a system with a large number of degrees of freedom \\(N \\gg 1\\) using the equilibrium probability distribution \\(p_M(\\boldsymbol{\\mu})\\).\nRecall that to be in equilibrium the phase space density should be time independent. By Liouville’s equation, this means \\[\n\\frac{\\partial}{\\partial t} p_M(\\boldsymbol{\\mu}) = -\\{p_M(\\boldsymbol{\\mu}), H\\} = 0.\n\\] In general this will be true so long as \\(p_M(\\boldsymbol{\\mu})\\) is an explicit function only of the Hamiltonian \\(H(\\boldsymbol{\\mu})\\) and possibly any other conserved quantities. If there are no other conserved quantities then the equilibrium distribution should be an explicit function of \\(H(\\boldsymbol{\\mu})\\) alone, i.e. \\[\np_M(\\boldsymbol{\\mu}) \\equiv p_M(H(\\boldsymbol{\\mu})).\n\\] In statistical mechanics we’re primarily interested in probability distributions corresponding to specific classes of system constraints, or ensembles. We’ll focus on the following ensembles, each of which corresponds to a conserved free energy.\nAll of these distributions arise from the principle of maximum entropy given certain known constraints, particularly the assumption that the expected values of zero or more quantities are given. We’ll study the implications of each ensemble one at a time and discuss when to use which for a given problem.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Classical Statistical Mechanics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/classical-stat-mech.html#formal-definition",
    "href": "statistical-mechanics/classical-stat-mech.html#formal-definition",
    "title": "Classical Statistical Mechanics",
    "section": "",
    "text": "The microcanonical ensemble: \\(p_M(\\boldsymbol{\\mu}) \\propto \\delta(H(\\boldsymbol{\\mu}) - E)\\). This corresponds to the energy \\(E\\) being conserved.\nThe canonical ensemble: \\(p_M(\\boldsymbol{\\mu}) \\propto e^{-\\beta H(\\boldsymbol{\\mu})}\\). This corresponds to the Hemlholtz free energy \\(F\\) being conserved.\nThe Gibbs canonical ensemble: \\(p_M(\\boldsymbol{\\mu}) \\propto e^{-\\beta (H(\\boldsymbol{\\mu}) - J \\cdot X)}\\). This corresponds to the Gibbs free energy \\(G\\) being conserved.\nThe grand canonical ensemble: \\(p_M(\\boldsymbol{\\mu}) \\propto e^{-\\beta (H(\\boldsymbol{\\mu}) - \\mu \\cdot N)}\\). This corresponds to the grand potential \\(\\mathcal{G}\\) being conserved.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Classical Statistical Mechanics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/classical-stat-mech.html#microcanonical-ensemble",
    "href": "statistical-mechanics/classical-stat-mech.html#microcanonical-ensemble",
    "title": "Classical Statistical Mechanics",
    "section": "Microcanonical Ensemble",
    "text": "Microcanonical Ensemble\nSuppose we have an isolated system, where the macrostate \\(M=(E,X,N)\\) is assumed to be constant. This is called the microcanonical ensemble. The corresponding probability distribution is given by the assumption of a-priori probability. We assume all microstates are equally likely so long as \\(M\\) stays fixed. More specifically, the probability distribution is assumed to be uniform on phase space manifolds of constant energy, \\[\n\\boxed{\np(\\boldsymbol{\\mu}) = \\frac{1}{\\Omega(M)} \\delta\\big(H(\\boldsymbol{\\mu}) - E\\big)\n} \\ ,\n\\] The variable \\(\\Omega(M)\\) is some normalization constant ensuring the probability integrates to one. In fact, it’s just a count of the total number of microstates corresponding to the macrostate \\(M\\). We’ll call it the multiplicity. The multiplicity also corresponds to the surface area of the phase space manifold of constant energy \\(E\\), \\[\n\\boxed{\\Omega(M) = \\int_{H(\\boldsymbol{\\mu})=E} d \\boldsymbol{\\mu}} \\ .\n\\] Given the probability distribution, we can calculate the thermodynamic entropy using the formula \\(S = -k_B \\langle \\log p \\rangle\\), \\[\n\\begin{align*}\nS(M) &= -k_B \\int d \\boldsymbol{\\mu} \\ p(\\boldsymbol{\\mu}) \\log p(\\boldsymbol{\\mu}) \\\\\n&= k_B \\int_{H(\\mathbf{x},\\mathbf{p})=E} d \\boldsymbol{\\mu} \\ \\frac{\\log \\Omega(M)}{\\Omega(M)} \\\\\n&= k_B \\log \\Omega(M). \\\\\n\\end{align*}\n\\] That is, the entropy is simply proportional to the logarithm of the number of microstates, \\[\n\\boxed{\nS = k_B \\log \\Omega\n} \\ .\n\\]\n\nLaws of Thermodynamics\nWith a probability distribution and a definition of entropy in hand, we can proceed to derive almost all of the laws of thermodynamics from the assumption of a microcanonical ensemble. Let’s start with the zeroth law.\nZeroth Law: Suppose two otherwise isolated systems \\(A\\) and \\(B\\) are in thermal contact with each other and allowed to exchange energy. When they both reach equilibrium, there will be some temperature function such that \\(T = T_A = T_B\\).\nProof: Suppose system \\(A\\) has energy \\(E_A\\) and system \\(B\\) has energy \\(E_B\\). The entire system \\(A+B\\) is isolated, which means it has some constant energy that must be given by \\(E = E_A + E_B\\). The multiplicity of the full system is just the product of multiplicities of each subsystem, integrated over all energies that sum up to \\(E\\). That is, \\[\n\\Omega(E) = \\int_{E=E_A+E_B} dE \\ \\Omega(E_A) \\Omega(E_B) = \\int dE_A \\ \\Omega(E_A) \\Omega(E-E_A).\n\\] We can write this in terms of entropies as well. We have \\[\n\\Omega(E) = \\int dE_A \\ e^{\\frac{1}{k_B} S_A} e^{\\frac{1}{k_B} S-S_A} = \\int dE_A \\ e^{\\frac{1}{k_B}(S_A+S_B)}\n\\] Now, entropy is an extensive quantity, meaning \\(S \\propto N\\). Since \\(N\\) is large we can employ the saddlepoint approximation, evaluating the integrand at the energies \\(E_A^*\\) and \\(E_B^*\\) that maximize the total entropy to get \\[\n\\Omega(E) \\approx e^{\\frac{1}{k_B} \\big(S(E_A^*) + S(E_B^*)\\big)}.\n\\] This maximum must occur when the partial derivatives at the maximum energies vanish, i.e. \\[\n\\frac{\\partial }{\\partial E_A} S(E_A^*) \\bigg|_{X,N} - \\frac{\\partial }{\\partial E_B} S(E_B^*) \\bigg|_{X,N} = 0.\n\\] When \\(A\\) and \\(B\\) are in equilibrium, the total entropy \\(S\\) must be maximized, meaning the partial derivatives must be equal. This condition defines a function whose values must equal at equilibrium, which by convention is the inverse temperature, \\[\n\\frac{1}{T} \\equiv \\frac{\\partial S}{\\partial E_A} \\bigg|_{X,N} = \\frac{\\partial S}{\\partial E_B} \\bigg|_{X,N}. \\quad \\text{Q.E.D.}\n\\] Notice in the above proof that we paid no attention to how the system reached equilibrium, only that it did eventually reached equilibrium, meaning that it satisfies the microcanonical probability distribution. Let’s look now at the first law.\nFirst Law: Consider a system having some form of mechanical work done on it by a force \\(J\\). It’s also allowed to exchange particles with the environment via a chemical potential \\(\\mu\\). If the force causes a differential displacement \\(dX\\) and \\(dN\\) particles are exchanged, then the total change in energy is given in differential form by \\[\ndE = TdS + J \\cdot dX + \\mu \\cdot dN.\n\\] Proof: Let’s calculate the change in the system’s entropy when a differential amount of work is done on the system. The amount of work done on a system in response to a displacement \\(\\delta X\\) and particle exchange \\(\\delta N\\) is given by \\[\n\\delta E = J \\cdot \\delta X + \\mu \\cdot \\delta N.\n\\] Suppose the system is initially at a constant energy \\(E\\) and increased by \\(\\delta E\\). Then to first order we have \\[\n\\begin{align*}\n\\delta S &= S(E+\\delta E, X+\\delta X, N+\\delta N) - S(E,X,N) \\\\\n&= \\frac{\\partial S}{\\partial E} \\bigg|_{X,N} (J \\cdot \\delta X + \\mu \\cdot \\delta N) + \\frac{\\partial S}{\\partial X} \\bigg|_{E,N} \\delta X + \\frac{\\partial S}{\\partial N} \\bigg|_{E,X} \\delta N \\\\\n&= \\bigg(\\frac{J}{T} - \\frac{\\partial S}{\\partial X} \\bigg|_{E,N}\\bigg)\\delta X + \\bigg(\\frac{N}{T} - \\frac{\\partial S}{\\partial N} \\bigg|_{E,X}\\bigg)\\delta N. \\\\\n\\end{align*}\n\\] Now, at equilibrium we must have \\(\\delta S = 0\\) for any \\(\\delta X\\) and \\(\\delta N\\). This means each term must vanish, giving \\[\n\\delta S = \\frac{1}{T} \\delta E - \\frac{J}{T} \\delta X - \\frac{\\mu}{T} \\delta N. \\quad \\text{Q.E.D.}\n\\] Using the first law, we can now find any other thermodynamic quantity of interest once we have the entropy. We have \\[\n\\begin{align*}\n\\frac{1}{T} &= \\frac{\\partial S}{\\partial E} \\bigg |_{X,N} \\ , \\\\\n-\\frac{J}{T} &= \\frac{\\partial S}{\\partial X} \\bigg |_{E,N} \\ , \\\\\n-\\frac{\\mu}{T} &= \\frac{\\partial S}{\\partial N} \\bigg |_{E,X} \\ . \\\\\n\\end{align*}\n\\] This gives us a sort of recipe we can use to calculate equations of state for systems in the microcanonical ensemble:\n\nCalculate \\(\\Omega(E,X,N)\\) and use that to get the entropy via \\(S = k_B \\log \\Omega\\).\nUse the first law to get other thermodynamic variables of interest via \\[\ndS =  \\frac{1}{T} dE -  \\frac{J}{T} \\cdot dX - \\frac{\\mu}{T} \\cdot dN.\n\\]\n\nThe second law is trivial. We’ve essentially already proved it.\nSecond Law: The entropy of a system is non-decreasing over time.\nProof: We’ve already shown this. For any two subsystems \\(A\\) and \\(B\\), suppose they start with energies \\(E_A^0\\) and \\(E_B^0\\). Over time the system will move to equilibrium to reach a maximum entropy, with energies of \\(E_A^*\\) and \\(E_B^*\\). It must be the case then that \\[\nS(E_A) + S(E_B) \\leq S(E_A^*) + S(E_B^*). \\quad \\text{Q.E.D.}\n\\]\nIt turns out that we can’t derive the third law from classical statistical mechanics alone. For that we’ll need quantum statistical mechanics, a topic we’ll get to later. Let’s go ahead and also check the stability conditions though while we’re here. For entropy to be maximized at equilibrium, we require the entropy near equilibrium to be concave, i.e. \\[\n\\frac{\\partial^2}{\\partial E_A^2} S(E_A^*) \\bigg|_{X,N} - \\frac{\\partial^2}{\\partial E_B^2} S(E_B^*) \\bigg|_{X,N} \\leq 0.\n\\] Using the same logic as we did in the thermodynamics lesson, we can then show this implies the heat capacity of the system be non-negative. Moreover, the requirement that any second-order perturbations be non-positive requires \\(\\frac{\\partial^2 S}{\\partial X_i \\partial X_j}\\) to be positive-definite at any constant energy \\(E\\).\n\n\nExample: Two-State Systems\nLet’s consider a simple example of a system we can actually solve in the microcanonical ensemble, indeed one of the few we can solve. Suppose we have a collection of particles that can take on only one of two states. We can imagine only caring about the spin of an electron, for example, in which case the two states would be spin-up and spin-down for each electron. Since there are only two states we can’t really think in terms of phase space in this case, so we have to cheat a bit. We’ll just sum over all states instead of integrating over phase space.\nSuppose each particle can take on an energy of the form \\(\\varepsilon n_i\\) where \\(n_i=0,1\\). That is, the particle has no energy if the state is down and a constant \\(\\varepsilon\\) energy if the spin is up. Then for \\(N\\) particles the Hamiltonian will just be the sum of all these energies, \\[\nH = \\sum_{i=0}^N \\varepsilon n_i \\equiv \\varepsilon N_1.\n\\] On the right we just defined \\(N_1\\) to be the total number of all states that are up. In the microcanonical we assert that \\(H\\) is held to a constant energy \\(E\\). This means we can also write \\(N_1 = \\frac{E}{\\varepsilon}\\).\nNow, to find \\(\\Omega(E,N)\\) observe the following fact: The number of total states with energy \\(E\\) is equivalent to the number of ways of choosing exactly \\(N_1\\) particles with state up out of a total of \\(N\\) particles. Assuming both \\(N\\) and \\(N_1\\) are large, we have \\[\n\\Omega(E,N) = \\binom{N}{N_1} = \\frac{N_1!}{N_1!(N-N_1)!} \\approx \\frac{N^N}{N_1^{N_1}(N-N_1)^{N-N_1}} \\ .\n\\] The entropy of such a system is thus \\[\n\\begin{align*}\nS &= k_B \\log \\Omega(E) \\\\\n&= k_B \\bigg[\\log N - \\frac{N_1}{N}\\log N_1 - \\frac{N-N_1}{N}\\log (N-N_1) \\bigg] \\\\\n&= -Nk_B \\bigg[\\frac{E}{N\\varepsilon}\\log\\frac{E}{N\\varepsilon} + \\bigg(1-\\frac{E}{N\\varepsilon}\\bigg) \\log \\bigg(1-\\frac{E}{N\\varepsilon}\\bigg) \\bigg].\n\\end{align*}\n\\] From this we can get the temperature in terms of the energy, \\[\n\\frac{1}{T} = \\frac{\\partial S}{\\partial E} \\bigg |_N = \\frac{k_B}{\\varepsilon} \\log \\frac{E}{N\\varepsilon-E}.\n\\] If we like, we can then solve for the energy in terms of the temperature to get \\[\nE(T) = \\frac{N\\varepsilon}{1 + e^{\\frac{\\varepsilon}{k_B T}}}.\n\\] One interesting property of the two-state system is that it can in principle take on negative temperatures. This comes from the fact that the energy \\(E\\) can take on any value between \\(0\\) (all states down) and \\(N\\varepsilon\\) (all states up). Having \\(E \\leq \\frac{1}{2} N\\varepsilon\\) corresponds to positive temperatures, while having \\(E \\geq \\frac{1}{2} N\\varepsilon\\) corresponds to negative temperatures. Negative temperatures are counter-intuitive since they implies that entropy increases when energy is taken out of the system, not put in. In practice this isn’t an issue, since the system must always be in thermal contact with a heat bath, which forces it to have positive temperature.\nIf we like we can use \\(E(T)\\) to calculate the heat capacity by differentiating with respect to \\(T\\), \\[\nC(T) = \\frac{\\partial E}{\\partial T} \\bigg |_{N} = Nk_B \\bigg(\\frac{\\varepsilon}{k_B T}\\bigg)^2 \\frac{e^{\\frac{\\varepsilon}{k_B T}}}{\\big(1 + e^{\\frac{\\varepsilon}{k_B T}}\\big)^2}.\n\\] By looking at the limited cases where \\(\\varepsilon \\ll k_B T\\) and \\(\\varepsilon \\gg k_B T\\), it’s easy to see that \\(C(T) \\rightarrow 0\\) both as \\(T \\rightarrow 0\\) and as \\(T \\rightarrow \\infty\\). Vanishing at low temperatures has to do with the discrete energy gap for each particle, while vanishing at high temperatures has to do with energy saturation due to the finite number of states allowed.\nNotice that if we divide \\(E\\) by \\(\\varepsilon\\) what’s left is dimensionless. In fact, it’s just the mean number of particles with state up, i.e. \\[\n\\langle n \\rangle = \\frac{N}{1 + e^{\\frac{\\varepsilon}{k_B T}}}.\n\\] It’s also worth asking what \\(p(n)\\) is, the probability for a given particle to be up or down. Evidently that probability should be \\(p(0) = \\frac{N-N_1}{N}\\) and \\(p(1) = \\frac{N_1}{N}\\). Plugging in \\(N_1 = \\frac{E(T)}{\\varepsilon}\\), we can write the expression as \\[\np(n) = \\delta(n) \\frac{1}{1 + e^{-\\frac{\\varepsilon}{k_B T}}} + \\delta(n-1) \\frac{e^{-\\frac{\\varepsilon}{k_B T}}}{1 + e^{-\\frac{\\varepsilon}{k_B T}}}.\n\\] The shape of this curve depends on the temperature. At low temperatures \\(p(0) \\approx 1\\). At high temperatures \\(p(1) \\approx 1\\). And when \\(\\varepsilon \\approx k_B T\\) we get \\(p(0) \\approx p(1) \\approx \\frac{1}{2}\\).",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Classical Statistical Mechanics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/classical-stat-mech.html#distinguishability",
    "href": "statistical-mechanics/classical-stat-mech.html#distinguishability",
    "title": "Classical Statistical Mechanics",
    "section": "Distinguishability",
    "text": "Distinguishability\nWe’d like to use the microcanonical ensemble to work out the relations for a more interesting system, like an ideal gas. It turns out however that there’s some subtly involved that we need to address in applying statistical mechanics to realistic systems.\n\nExample: Ideal Gas\nLet’s start by trying to derive the ideal gas expressions using only what we’ve covered so far and seeing where things go wrong. Suppose an isolated system of gas particles has the non-interacting Hamiltonian for an ideal gas, namely \\[\nH(\\mathbf{x}_1,\\cdots,\\mathbf{x}_N,\\mathbf{p}_1,\\cdots,\\mathbf{p}_N) = \\sum_{i=1}^N \\frac{\\mathbf{p}_i^2}{2m} + V(\\mathbf{x}_1,\\cdots,\\mathbf{x}_N),\n\\] where the potential energy \\(V(\\mathbf{x}_1,\\cdots,\\mathbf{x}_N)\\) is zero inside a container of volume \\(V\\) and infinite otherwise. To calculate the equations of state we first need to find \\(\\Omega(E,V,N)\\). Integrating over the volume of the box and all valid momenta, we get \\[\n\\Omega(E,V,N) = \\int_{\\frac{\\mathbf{p}^2}{2m} = E} d^{3N} \\mathbf{x} \\ d^{3N} \\mathbf{p} = V^N  \\int_{|\\mathbf{p}| = \\sqrt{2mE}} d^{3N} \\mathbf{p} \\equiv V^N \\Sigma_{3N}.\n\\] The integral \\(\\Sigma_{3N}\\) is the surface area of a \\(3N\\)-dimensional hypersphere in momentum space of radius \\(R=\\sqrt{2mE}\\).\nTo make anymore progress we need to figure out what the surface area of a \\(d\\)-dimensional hypersphere is. Now, notice we can write the \\(d\\)-dimensional volume element as \\(d^d \\mathbf{x} = R^{d-1} dR \\ d\\Omega_{d-1}\\), where \\(d\\Omega_{d-1}\\) is the \\(d-1\\) dimensional solid angle. For a hypersphere we can factor the integral. If \\(S_d \\equiv \\int d\\Omega_{d-1}\\), then we have \\(\\Sigma_{d} = S_d R^{d-1}\\). Here \\(S_d\\) is a constant that depends only on the dimension \\(d\\). To find \\(S_d\\), the trick is to use the fact that the integral of a \\(d\\)-dimensional Gaussian is just \\[\nI_d \\equiv \\int d^d \\mathbf{x} \\ e^{-\\mathbf{x}^2} = \\bigg(\\int dx \\ e^{-x^2}\\bigg)^d = \\pi^{d/2}.\n\\] By changing variables to spherical coordinates, it’s easy to show \\[\nI_d = \\int R^{d-1} dR \\ d\\Omega_{d-1} \\ e^{-R^2} = \\frac{1}{2} \\bigg(\\frac{d}{2}-1\\bigg)! \\ S_d.\n\\] Equating the two expressions, we can solve for \\(S_d\\) and finally get the surface area of a \\(d\\)-dimensional hypersphere, \\[\n\\Sigma_d = \\frac{2\\pi^{d/2}}{\\big(\\frac{d}{2}-1\\big)!} R^{d-1}.\n\\] Back to the problem at hand. Plugging all this in, we finally get a multiplicity of \\[\n\\Omega(E,V,N) = \\frac{2\\pi^{\\frac{3N}{2}}}{\\big(\\frac{3N}{2}-1\\big)!} V^N (2mE)^{\\frac{3N-1}{2}} \\approx 2 V^N \\bigg(\\frac{4\\pi m E}{3N}\\bigg)^{3N/2}.\n\\] The right–hand side is simplified using Stirling’s approximation \\(N! \\sim N^N e{-N}\\). The entropy is then \\(S = k_B \\log \\Omega\\). If we ignore terms of order less than \\(O(N)\\), up to an added constant we get the same result we found using kinetic theory, namely \\[\nS = Nk_B \\log V\\bigg(\\frac{4\\pi emE}{3N}\\bigg)^{3/2}.\n\\] Aside: Suppose we didn’t know the energy \\(E\\) exactly, but only within some range \\(E \\pm \\delta E\\). In that case, the hypersphere radius would have an uncertainty \\(\\delta R = \\sqrt{\\frac{m}{2E}} \\delta E\\). The effect of this is that \\(\\Omega\\) now gains a multiplicative factor of \\(\\delta R\\). This causes the entropy to then gain an additive factor of \\(k_B \\log \\delta R \\propto \\log \\frac{\\delta E}{\\sqrt{E}}\\). Since energy is extensive, this new added factor will be \\(O(\\log N)\\), which is small compared to the original terms of \\(O(N)\\), and can hence be neglected. The net effect of all this is that none of the thermodynamic variables get materially affected by the uncertainty. For this reason we’ll ignore it from now on.\nUsing the entropy we can now proceed to calculate the temperature, pressure, and chemical potential. The equation for temperature gives the usual energy relation for a monoatomic ideal gas, \\[\n\\frac{1}{T} = \\frac{\\partial S}{\\partial E} \\bigg |_{X,N} = \\frac{3Nk_B}{2E} \\quad \\Longrightarrow \\quad E = \\frac{3}{2} Nk_B T.\n\\] The equation for the pressure gives the usual ideal gas law, \\[\nP = T \\frac{\\partial S}{\\partial V} \\bigg |_{E,N} = \\frac{Nk_B T}{V} \\quad \\Longrightarrow \\quad PV = Nk_B T.\n\\] Both of these seem perfectly fine. The problem, however, comes when we try to evaluate the chemical potential. We’d get \\[\n\\mu = -T \\frac{\\partial S}{\\partial N} \\bigg |_{E,V} = - k_B T \\bigg[\\log V\\bigg(\\frac{4\\pi mE}{3N}\\bigg)^{3/2} - \\frac{3}{2} \\bigg].\n\\] Now, the problem here is that the chemical potential should be intensive, but it’s not. It’s proportional to \\(\\log V\\). The same problem showed up in the entropy as well. The entropy should be extensive, yet it’s proportional to \\(V\\log N\\). It seems like we should have to divide by something else extensive inside the logarithm to cancel the effect of the \\(V\\).\n\n\nGibbs’ Paradox\nTo resolve this issue let’s look at another toy problem. Consider the mixing entropy of a container containing two distinct ideal gases of different types. Suppose the container initially split into two components, the first a gas with configuration \\((S_1,N_1,V_1)\\) and the second a gas with configuration \\((S_2,N_2,V_2)\\). Assume the system is at equilibrium, so both systems have the same temperature \\(T\\). An adiabatic wall is then removed, so the two gases are allowed to mix and come to a new equilibrium of the same temperature. The initial total entropy \\(S_i\\) in the container is evidently given by \\(S_i = S_1 + S_2\\), i.e. \\[\nS_i = k_B \\bigg( N_1 \\log V_1 + \\frac{3}{2} N_1 \\log 2\\pi e m_1 k_B T\\bigg) + k_B \\bigg(N_2 \\log V_2 + \\frac{3}{2} N_2 \\log 2\\pi e m_2 k_B T\\bigg),\n\\] where we’ve used the fact that \\(E = \\frac{3}{2} N k_B T\\). To find the final total entropy \\(S_f\\), observe that at the new equilibrium both gases should fill up the entire box uniformly, meaning \\(V_1 = V_2 = V\\), hence \\[\nS_f = k_B \\bigg( N_1 \\log V + \\frac{3}{2} N_1 \\log 2\\pi e m_1 k_B T\\bigg) + k_B \\bigg(N_2 \\log V + \\frac{3}{2} N_2 \\log 2\\pi e m_2 k_B T\\bigg).\n\\] All together, this means the change in total entropy is given by \\[\n\\Delta S = S_f - S_i = k_B \\bigg(N_1 \\log \\frac{V}{V_1} + N_2 \\log \\frac{V}{V_2}\\bigg).\n\\] So what’s the problem here? Well, suppose the two gases were the same, and we opened the adiabatic wall and allowed them to mix? What should happen physically? Nothing. They’re the same gas, at the same temperature. The thermodynamic variables shouldn’t change at all, meaning we should have \\(\\Delta S = 0\\). On the other hand, if the two gases were distinct, we should expect the total entropy of the system to increase like shown. This conundrum is known as the Gibbs Paradox.\nThe solution to this paradox is to notice that we have to treat identical systems separately from distinguishable systems. If a system is distinguishable we’re fine as is. But if a system is identical we have to account for the fact that we’re overcounting \\(\\Omega\\) any time we count two identical systems as distinct. The way to fix this is pretty easy. Just divide \\(\\Omega\\) by the number of ways to permute the particles in each identical system.\nTo resolve the above paradox and the issue with extensively, notice that if we have an ideal gas of \\(N\\) particles then we’re overcounting \\(\\Omega\\) by a factor of \\(N!\\), the number of ways to permute a set of \\(N\\) identical particles. Then \\(\\Omega\\) for an ideal gas becomes \\[\n\\Omega(E,V,N) = \\frac{V^N}{N!}\\frac{2\\pi^{\\frac{3N}{2}}}{\\big(\\frac{3N}{2}-1\\big)!} (2mE)^{\\frac{3N-1}{2}} \\approx 2\\bigg(\\frac{Ve}{N}\\bigg)^N \\bigg(\\frac{4\\pi m E}{3N}\\bigg)^{3N/2}.\n\\] This means the entropy \\(S\\) then becomes \\[\nS = Nk_B \\bigg[\\log \\frac{V}{N}\\bigg(\\frac{4\\pi mE}{3N}\\bigg)^{3/2} + \\frac{5}{2}\\bigg],\n\\] and hence that the chemical potential \\(\\mu\\) becomes \\[\n\\mu = - k_B T \\log \\frac{V}{N}\\bigg(\\frac{4\\pi mE}{3N}\\bigg)^{3/2}.\n\\] Now it appears that we’re dividing \\(V\\) by \\(\\frac{N}{e}\\) inside the logarithm, which makes \\(S\\) is properly extensive and \\(\\mu\\) properly intensive.\nTo resolve the Gibbs paradox, notice that if the two gases are distinct, we have to divide \\(\\Omega\\) by \\(N_1!N_2!\\). This ultimately gives \\[\n\\Delta S = k_B \\bigg(N_1 \\log \\frac{V}{V_1} + N_2 \\log \\frac{V}{V_2}\\bigg),\n\\] which is of course what we had before. If the two gases are identical, we instead have to divide \\(\\Omega\\) by \\(N!\\). This ultimately gives \\[\n\\Delta S = k_B \\bigg[(N_1+N_2) \\log \\frac{V}{N_1+N_2} - N_1 \\log \\frac{V_1}{N_1} - N_2 \\log \\frac{V_2}{N_2}\\bigg] = 0\n\\] since at equilibrium (both initially and finally) we must have \\(\\frac{V}{N}=\\frac{V_1}{N_1}=\\frac{V_2}{N_2}\\). The paradox is thus resolved.\nThis resolves one of the problems we had with the expressions for an ideal gas, but there’s one more. If we look careful, we can see that the expression inside the logarithm isn’t dimensionless, as it should be. In fact, it has units of action to some power. Recall that action has units of position times momentum, or energy times time. The dimensionality issue ultimately arises from the fact that we’re working with a continuous system and integrating over phase space. But phase space has units. To fix this problem, all we have to do is divide the phase space measure \\(d \\mathbf{x} d\\mathbf{p}\\) by some constant with units of action cubed. We’ll call this constant \\(h\\). Its value turns out to be largely immaterial for classical purposes. We’ll see what it is when we get to quantum statistical mechanics. At any rate, to fix the measure we just need to make the substitution \\[\nd^3 \\mathbf{x} d^3 \\mathbf{p} \\rightarrow \\frac{d^3 \\mathbf{x} d^3 \\mathbf{p}}{h^3}.\n\\] These two facts together resolve our problems. For \\(N\\) particles all of the same type, we substitute the following measures \\[\nd^{3N} \\mathbf{x} \\ d^{3N} \\mathbf{p} \\rightarrow\n\\begin{cases}\n\\frac{d^{3N} \\mathbf{x} \\ d^{3N} \\mathbf{p}}{h^{3N}} & N \\ \\text{distinguishable particles}, \\\\\n\\frac{d^{3N} \\mathbf{x} \\ d^{3N} \\mathbf{p}}{N! \\ h^{3N}} & N \\ \\text{identical particles}. \\\\\n\\end{cases}\n\\]\nFor an ideal gas, the right measure to use is the second one. Plugging this in, we finally get an entropy of \\[\nS = Nk_B \\bigg[\\log \\frac{V}{N}\\bigg(\\frac{4\\pi mE}{3Nh^2}\\bigg)^{3/2} + \\frac{5}{2}\\bigg].\n\\] This result, the correct entropy of a classical ideal gas, is known as the Sakur-Tetrode equation. The chemical potential is then \\[\n\\mu = - k_B T \\log \\frac{V}{N}\\bigg(\\frac{4\\pi mE}{3Nh^2}\\bigg)^{3/2}.\n\\] To finish up this section, it’s worth mentioning that statistical mechanics gives us even more information than thermodynamics gives us. Not only does it tell us what the variables are, but it can also tell us how variables are distributed. For example, we can derive the distribution for the momentum of a single ideal gas particle. We have \\[\n\\begin{align*}\np(\\mathbf{p}) &= \\frac{V^N}{\\Omega(E,V,N)} \\int_{|\\mathbf{p}| = \\sqrt{2mE}} d^{3N-1} \\mathbf{p} \\\\\n&= V\\frac{\\Omega\\big(E-\\frac{\\mathbf{p}^2}{2m},V,N-1\\big)}{\\Omega(E,V,N)} \\\\\n&= \\bigg(1 - \\frac{\\mathbf{p}^2}{2mE}\\bigg)^{3N/2-2} \\frac{1}{(2\\pi m E)^{3/2}} \\frac{(\\frac{3N}{2}-1)!}{(\\frac{3(N-1)}{2}-1)!} \\\\\n&\\approx \\bigg(\\frac{3N}{4\\pi m E}\\bigg)^{3/2} \\exp\\bigg(-\\frac{3N\\mathbf{p}^2}{4mE}\\bigg). \\\\\n\\end{align*}\n\\] The last line follows from the fact that \\(E\\) is extensive and \\(N \\gg 1\\), hence we can use the identity \\(e^x \\approx \\big(1+\\frac{x}{N}\\big)^{N}\\). Using the relation \\(E = \\frac{3}{2} N k_B T\\) then gives the usual form of this distribution, known as the Maxwell-Boltzmann distribution.\n\n\nExample: Ultrarelativistic Ideal Gas\nA similar example is the ultrarelativistic ideal gas. Recall from special relativity that the kinetic energy of a particle is given by the relativistic energy formula \\[\nE^2 = m^2c^4 + \\mathbf{p}^2 c^2.\n\\] In the limit where \\(|\\mathbf{p}| \\ll mc\\) we recover the classical kinetic energy \\(E=\\frac{\\mathbf{p}^2}{2m}\\). We can also ask about the limit where \\(|\\mathbf{p}| \\gg mc\\). This is called the ultrarelativistic limit. This limit includes massless particles like photons or neutrinos that move at or near the speed of light. In this limit the kinetic energy is just \\(E=|\\mathbf{p}| c\\).\nLet’s again suppose we have a gas of \\(N\\) non-interacting particles, but that they’re ultrarelativistic. In that case, the Hamiltonian is \\[\nH(\\mathbf{x}_1,\\cdots,\\mathbf{x}_N,\\mathbf{p}_1,\\cdots,\\mathbf{p}_N) = \\sum_{i=1}^N |\\mathbf{p}_i| c + V(\\mathbf{x}_1,\\cdots,\\mathbf{x}_N).\n\\] We’ll again assume the potential is zero inside a container of volume \\(V\\) and infinite otherwise. We proceed as usual by trying to find \\(\\Omega(E,V,N)\\). Supposing we’re dealing with a gas of \\(N\\) identical particles, we have \\[\n\\Omega(E,V,N) = \\frac{1}{N!h^{3N}} \\int_{E=|\\mathbf{p}| c} d^{3N} \\mathbf{x} \\ d^{3N} \\mathbf{p} = \\frac{V^N}{N!h^{3N}} \\int_{E=|\\mathbf{p}| c} d^{3N} \\mathbf{p}.\n\\] Again note that the momentum space integral is over a \\(3N\\)-dimensional hypersphere, this time of radius \\(R=\\frac{E}{c}\\). Thus, \\[\n\\Omega(E,V,N) = \\frac{V^N}{N!h^{3N}} \\Sigma_{3N} \\approx 2 \\bigg[\\frac{eV}{N} \\bigg(\\frac{2\\pi e E^2}{3h^2c^2 N}\\bigg)^{3/2}\\bigg]^N.\n\\] Again keeping terms only to \\(O(N)\\), the entropy is thus given by \\[\nS = N k_B \\bigg[\\log \\frac{V}{N} \\bigg(\\frac{2\\pi E^2}{3h^2c^2 N}\\bigg)^{3/2} + \\frac{5}{2}\\bigg].\n\\] It’s worth noting that the entropy in this case is no longer properly extensive, as it contains a term of order \\(O(N \\log N)\\) due to the presence of the \\(E^2\\) in the logarithm. There’s no obvious way to fix this problem. In fact, an ultrarelativistic gas is super-extensive. It’s in a class of systems with so-called anonomous scaling behaviors. In practice this isn’t a huge deal.\nWe can calculate the temperature the usual way. We have \\[\n\\frac{1}{T} = \\frac{\\partial S}{\\partial E} \\bigg |_{V,N} = \\frac{3Nk_B}{E} \\quad \\Longrightarrow \\quad E = 3Nk_B T.\n\\] Notice the entropy depends on volume in the same way as it does for the classical ideal gas. Indeed, we have \\[\n\\frac{P}{T} = \\frac{\\partial S}{\\partial V} \\bigg |_{E,N} = \\frac{Nk_B}{V} \\quad \\Longrightarrow \\quad PV = Nk_B T.\n\\] The chemical potential follows similarly. Following the same kind of calculation as before, we get \\[\n\\mu = - k_B T \\log \\frac{V}{N}\\bigg(\\frac{2\\pi E^2}{3c^2h^2N}\\bigg)^{3/2}.\n\\] Since the entropy isn’t properly extensive, the chemical potential evidently isn’t properly intensive as we’d expect. It’s not hard to show that the distribution of momenta is now longer a Gaussian either. It’s in fact a Laplace distribution, with \\[\np(\\mathbf{p}) = \\frac{3Nc}{2E} \\exp\\bigg(-\\frac{3N|\\mathbf{p}|c}{E}\\bigg) = \\frac{c}{2k_B T} \\exp\\bigg(-\\frac{|\\mathbf{p}| c}{k_B T}\\bigg).\n\\]\n\n\nExample: Hard Sphere Gas\nLet’s look at another problem similar to the ideal gas. Suppose that we have a gas of \\(N\\) non-interacting solid spheres each of volume \\(\\omega \\ll V\\), where \\(V\\) is again the volume of the container. The Hamiltonian otherwise remains the same as for the ordinary ideal gas. If we assume the spheres are identical, following the same logic as for the ordinary ideal gas we can write the multiplicity as \\[\n\\Omega(E,V,N) = \\frac{1}{N!}\\frac{2\\pi^{\\frac{3N}{2}}}{\\big(\\frac{3N}{2}-1\\big)!} (2mE)^{\\frac{3N-1}{2}} \\mathcal{V}_{N}.\n\\] Here \\(\\mathcal{V}_{N}\\) represents the volume integral over all \\(N\\) particles. For the ordinary ideal gas we just had \\(\\mathcal{V}_{N} = V^N\\). Now, imagine putting the spheres into the container one at a time. The first one could occupy the volume \\(V\\). The second would be the full volume minus the volume of the first sphere, so \\(V-\\omega\\). The third would be the full volume minus the volumes of the first two spheres, so \\(V-2\\omega\\). And so on until the last sphere, which would have an available volume of \\(V-(N-1)\\omega\\). Assuming \\(\\omega \\ll V\\), we can approximate \\(\\mathcal{V}_N\\) as \\[\n\\begin{align*}\n\\mathcal{V}_N &= V\\big(V-\\omega\\big)\\big(V-2\\omega\\big)\\cdots\\big(V-(N-1)\\omega\\big) \\\\\n&= V^N \\prod_{j=1}^{N-1}\\bigg(1-j\\frac{\\omega}{V}\\bigg) \\\\\n&\\approx V^N \\bigg(1-\\frac{N(N-1)}{2}\\frac{\\omega}{V}\\bigg) \\\\\n&\\approx V^N \\bigg(1-\\frac{N^2}{2}\\frac{\\omega}{V}\\bigg) \\\\\n&\\approx \\bigg(V-\\frac{N\\omega}{2}\\bigg)^N. \\\\\n\\end{align*}\n\\] Effectively, this says the total available volume for each particle in the container to explore gets reduced from \\(V\\) to \\(V-\\frac{N\\omega}{2}\\). The term \\(\\frac{N\\omega}{2}\\) is called the excluded volume. The multiplicity is evidently then \\[\n\\Omega(E,V,N) = \\frac{\\big(V-\\frac{N\\omega}{2}\\big)}{N!}\\frac{2\\pi^{\\frac{3N}{2}}}{\\big(\\frac{3N}{2}-1\\big)!} (2mE)^{\\frac{3N-1}{2}} \\approx 2\\bigg(\\frac{\\big(V-\\frac{N\\omega}{2}\\big)e}{N}\\bigg)^N \\bigg(\\frac{4\\pi m E}{3N}\\bigg)^{3N/2}.\n\\] This is exactly what we had for the ordinary ideal gas, except with \\(V\\) replaced by \\(V-\\frac{1}{2}N\\omega\\). This means the entropy is just \\[\nS = Nk_B \\bigg[\\log \\frac{V-\\frac{N\\omega}{2}}{N}\\bigg(\\frac{4\\pi mE}{3N}\\bigg)^{3/2} + \\frac{5}{2}\\bigg].\n\\] Clearly the equation for temperature isn’t affected at all. We still have \\(E = \\frac{3}{2} N k_B T\\). The equation for pressure though does change though. Since we’re differentiating \\(S\\) with respect to \\(V\\) and not \\(V-\\frac{1}{2}N\\omega\\), we have \\[\n\\frac{P}{T} = \\frac{\\partial S}{\\partial V} \\bigg |_{E,N} = \\frac{Nk_B}{V-\\frac{N\\omega}{2}} \\quad \\Longrightarrow \\quad P\\bigg(V-\\frac{N\\omega}{2}\\bigg) = Nk_B T.\n\\] The ideal gas law is thus slightly modified by reducing the volume from \\(V\\) to the available volume \\(V-\\frac{N\\omega}{2}\\).\nIncidentally, the hard sphere gas is almost a good model of a real interacting gas away from the dense limit. One change that can make it even more accurate is to reduce not just the volume, but also the pressure, to account for the fact that interactions tend to make particles slightly less likely to be near the walls of the container instead of around the center. This slight generalization will give us the van der Waals equation, which we’ll derive when we get to interacting particles.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Classical Statistical Mechanics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/classical-stat-mech.html#canonical-ensemble",
    "href": "statistical-mechanics/classical-stat-mech.html#canonical-ensemble",
    "title": "Classical Statistical Mechanics",
    "section": "Canonical Ensemble",
    "text": "Canonical Ensemble\nWhile the microcanonical ensemble is easy to understand, it’s usually not the easiest ensemble to work with for most problems. Usually finding the multiplicity \\(\\Omega(M)\\) directly isn’t easy since it involves a high level of combinatorial insight. Another approach we can take is to not take \\(M=(E,X,N)\\), but to instead take \\(M=(T,X,N)\\). That is, we consider a system with a fixed temperature, not a fixed energy. Physically, this means considering not an isolated system, but a closed system. We assume our system of interest is placed in contact with a large environment, or heat bath, and allowed to come to equilibrium. The system inherits its temperature from the heat bath and is allowed to exchange heat with it.\n\nBoltzmann Distribution\nTo derive the probability distribution for a canonical system let’s first consider the combined system of our system of interest plus the heat bath. We’ll suppose the combined system is isolated, meaning it follows the microcanonical ensemble. Denote the system of interest as \\(S\\), the heat bath as \\(R\\), and the combined system as \\(RS\\). The total energy \\(E\\) is just the sum of the Hamiltonians of \\(S\\) and \\(R\\) at a given point in their respective phase spaces, \\[\nE = H_R(\\boldsymbol{\\mu}_R) + H_S(\\boldsymbol{\\mu}_S).\n\\] In the microcanonical ensemble the probability of any given state \\((\\boldsymbol{\\mu}_R,\\boldsymbol{\\mu}_S)\\) is then just \\[\np_{RS}(\\boldsymbol{\\mu}_R,\\boldsymbol{\\mu}_S) = \\frac{1}{\\Omega_{RS}} \\delta\\big(E-H_R(\\boldsymbol{\\mu}_R)-H_S(\\boldsymbol{\\mu}_S)\\big).\n\\] To get the probability we seek, the probability of system states we need to find \\(p_S(\\boldsymbol{\\mu}_S)\\). By marginalizing, we have \\[\n\\begin{align*}\np_S(\\boldsymbol{\\mu}_S) &= \\int d \\boldsymbol{\\mu}_R \\ p_{RS}(\\boldsymbol{\\mu}_R,\\boldsymbol{\\mu}_S) \\\\\n&= \\frac{1}{\\Omega_{RS}} \\Omega_R\\big(E-H_S(\\boldsymbol{\\mu}_S)\\big) \\\\\n&= \\frac{1}{\\Omega_{RS}}\\exp\\bigg(\\frac{1}{k_B}S_R\\big(E-H_S(\\boldsymbol{\\mu}_S)\\big)\\bigg).\n\\end{align*}\n\\] Now, we assume the heat bath is much larger than the system of interest. This means the \\(S_{RS} \\approx S_R\\) and the total energy \\(E \\gg H_S\\). If we Taylor expand \\(S_R\\) about \\(E\\), to first order we thus have \\[\nS_R\\big(E-H_S(\\boldsymbol{\\mu}_S)\\big) \\approx S_{RS}(E) - \\frac{\\partial S_{RS}}{\\partial E} H_S(\\boldsymbol{\\mu}_S).\n\\] Since the heat bath is fixed at a temperature \\(T\\), we can write the partial derivative as \\(\\frac{\\partial S_R}{\\partial E} = \\frac{1}{T}\\). Plugging back in, we have \\[\np_S(\\boldsymbol{\\mu}_S) \\approx \\frac{e^{\\frac{1}{k_B} S_{RS}(E)}}{\\Omega_{RS}}e^{-\\frac{1}{k_B T} H_S(\\boldsymbol{\\mu}_S)}.\n\\] For convenience we’ll define \\(\\beta \\equiv \\frac{1}{k_B T}\\). Notice the first term above is just some normalization constant that we’ll denote as \\(\\frac{1}{Z(\\beta)}\\). Dropping the explicit \\(S\\) subscripts and ignoring the presence of the heat bath we finally have our canonical ensemble probability, called the Boltzmann distribution, \\[\n\\boxed{p(\\boldsymbol{\\mu}) = \\frac{1}{Z(T,X,N)}e^{-\\beta H(\\boldsymbol{\\mu})}} \\ .\n\\]\n\n\nPartition Function\nThe normalization constant \\(Z(T,X,N)\\) is so important it has a special name. It’s called the canonical partition function. We can find an expression for it by asserting that the probability density integrate to one. Evidently, we get \\[\n\\boxed{Z(T,X,N) = \\int d \\boldsymbol{\\mu} \\ e^{-\\beta H(\\boldsymbol{\\mu})}} \\ .\n\\] The partition function turns out to be very important to statistical mechanics, as it essentially encodes all the statistical mechanical information contained in the system. To see why it’s helpful to re-write the partition function as an integral (or sum) over all possible system energies \\(E\\). To do that multiple microstates can have the same energy. That means we need to multiply the integrand by a multiplicity \\(\\Omega(E)\\). We thus have \\[\nZ = \\int dE \\ \\Omega(E) \\ e^{-\\beta E} = \\int dE \\ e^{\\frac{1}{k_B} S} e^{-\\frac{1}{k_B T} E} = \\int dE \\ e^{-\\frac{1}{k_B T}(E-TS)}.\n\\] Recall from thermodynamics though that \\(E-TS\\) is just the Helmholtz free energy \\(F\\). Now, since \\(F\\) is extensive we can again employ the saddlepoint approximation about the maximum energy \\(E^*\\) to get \\[\nZ = \\int dE \\ e^{-\\beta F} \\approx e^{-\\beta F(E^*)} \\sqrt{\\frac{2\\pi}{|F''(E^*)|}}.\n\\] Taking the logarithm of both sides and solving for \\(F\\), we evidently have \\[\nF = -k_B T \\log Z + O\\big(\\log N\\big).\n\\] Since \\(N\\) is large, we can neglect the dependence on \\(\\log N\\). We thus have a nice expression for the free energy as \\[\n\\boxed{F = -k_B T \\log Z} \\ .\n\\] Why is this important? We already know \\(F\\) encodes all of the thermodynamic information in the system because \\[\ndF = -S dT + J \\cdot dX + \\mu \\cdot dN.\n\\] This formula gives a way to find the entropy, force, and chemical potential of the system just from \\(\\log Z\\). For example, \\[\n\\begin{align*}\nJ &= \\frac{\\partial F}{\\partial X} \\bigg |_{T,N} = -\\frac{1}{\\beta} \\frac{\\partial \\log Z}{\\partial X}, \\\\\n\\mu &= \\frac{\\partial F}{\\partial N} \\bigg |_{T,X} = -\\frac{1}{\\beta} \\frac{\\partial \\log Z}{\\partial N}. \\\\\n\\end{align*}\n\\] We can also derive a convenient expression for the energy \\(E\\) by looking at the expected value of the Hamiltonian. We have \\[\n\\langle H \\rangle = \\int d \\boldsymbol{\\mu} \\ H(\\boldsymbol{\\mu}) p(\\boldsymbol{\\mu}) = \\int d \\boldsymbol{\\mu} \\ H(\\boldsymbol{\\mu}) \\frac{e^{-\\beta H(\\boldsymbol{\\mu})}}{Z} = -\\frac{1}{Z} \\frac{\\partial Z}{\\partial \\beta} = - \\frac{\\partial \\log Z}{\\partial \\beta}.\n\\] Assuming we can equate the macrostate energy \\(E\\) with \\(\\langle H \\rangle\\), an issue we’ll discuss in a moment, we can thus write \\[\n\\boxed{E = \\langle H \\rangle = - \\frac{\\partial \\log Z}{\\partial \\beta}} \\ .\n\\] Using the formula \\(F = E - TS\\) we can also get a convenient formula for the entropy. We have \\[\nS = \\frac{E}{T} - \\frac{F}{T} = k_B \\big(\\beta E + \\log Z \\big).\n\\]\nFor systems of \\(N\\) non-interacting particles, it’s generally the case that the partition function can be factored into a product of single-particle partition functions. That is, \\(Z = Z_1^N\\). If the particles are identical we have to be sure to divide by \\(N!\\) as well. This trick will be useful in solving for equations of state in many examples.\n\n\nFluctuations\nBut why can we assert that the thermodynamic energy \\(E\\) is the same thing as the expected value of the Hamiltonian \\(\\langle H \\rangle\\)? The reason for this has to do almost entirely with the fact that \\(N\\) is really large. To see why, let’s ask the following question: How much can we expect the energy to fluctuate about its mean \\(\\langle H \\rangle\\)?\nTo answer this, we just need to find the variance \\(\\sigma_E^2\\). Using the same trick as before, the \\(k\\)th moment of \\(H\\) is given by \\[\n\\langle H^k \\rangle = \\int d \\boldsymbol{\\mu} \\ H^k(\\boldsymbol{\\mu}) p(\\boldsymbol{\\mu}) = \\int d \\boldsymbol{\\mu} \\ H^k(\\boldsymbol{\\mu}) \\frac{e^{-\\beta H(\\boldsymbol{\\mu})}}{Z} = (-1)^k\\frac{1}{Z} \\frac{\\partial^k Z}{\\partial \\beta^k}.\n\\] From this formula, it’s not hard to see the cumulants of \\(H\\) are simply given by \\[\n\\langle H^k \\rangle_c = (-1)^k \\frac{\\partial^k \\log Z}{\\partial \\beta^k}.\n\\] In particular, this means the variance is given by \\[\n\\sigma_E^2 = \\frac{\\partial^2 \\log Z}{\\partial \\beta^2} = - \\frac{\\partial \\langle H \\rangle}{\\partial \\beta} = k_B T^2 \\frac{\\partial \\langle H \\rangle}{\\partial T} \\bigg |_{X,N} \\ .\n\\] To the extent we can write \\(E \\approx \\langle H \\rangle\\), the right-hand derivative is just the heat capacity \\(C_X\\). The variance of \\(H\\) is thus \\[\n\\boxed{\\sigma_E^2 = k_B T^2 C_X} \\ .\n\\] Now, recall the heat capacity is in general extensive. This means the variance (and in fact all cumulants of \\(H\\)) are extensive as well. Thus, roughly speaking, we expect the energy \\(E\\) to fluctuation about the mean by an amount \\[\n\\sigma_E = \\sqrt{k_B T^2 C_X} = O(\\sqrt{N}).\n\\] This means that the energy \\(E\\) will with high probability lie within a few \\(\\sigma_E\\) of the mean, \\[\nE \\approx \\langle H \\rangle \\pm \\sigma_E = \\langle H \\rangle \\pm O(\\sqrt{N}).\n\\] Since \\(\\langle H \\rangle = O(N)\\) and \\(N\\) is large, we can neglect the \\(O(\\sqrt{N})\\) fluctuations in the thermodynamic limit and just write \\[\nE \\approx \\langle H \\rangle.\n\\] Note that the energy distribution can have pretty much any curve we like. All that matters is that it be extensive. It can even have multiple peaks. Due to extensivity, the global maximum \\(E^*\\) will always be exponentially larger than the other maxima. Around that maximum we can fit a Gaussian with mean \\(E^* \\approx \\langle H \\rangle\\) and variance \\(\\sigma_E^2\\). That Gaussian will be sharply peaked about \\(E^*\\) with a negligible fluctuation, meaning we can safely write \\(E \\approx E^* \\approx \\langle H \\rangle\\).\n\n\n\n\n\nThis is in essence the magic of thermodynamics. When \\(N\\) is really really large, at equilibrium we can pretty much ignore the shape of the distribution and just assume \\(E = E^* = \\langle H \\rangle\\). This holds for other extensive variables as well, not just energy. For all practical purposes, thermodynamic variables are deterministic due to the character of the thermodynamic limit.\nAs an example to see that fluctuations don’t really matter, if we looked at one mole of air at STP, we’d expect the energy to be about \\(E \\approx \\frac{5}{2} RT \\approx 6100 \\ \\text{J}\\). On the other hand, the energy is expected to fluctuate as \\(\\sigma_E = \\sqrt{k_B T^2 \\frac{5}{2} R} \\approx 3 \\cdot 10^{-10} \\ \\text{J}\\). That is, the fluctuations \\(\\sigma_E\\) are a full 13 orders of magnitude smaller than \\(E\\), hence completely negligible.\n\n\nExample: Ideal Gas\nFrequently, the canonical ensemble is much easier to work with than the microcanonical ensemble. Perhaps the best example of this is comparing both methods for solving the ideal gas problem. Consider again a gas with Hamiltonian \\[\nH(\\mathbf{x}_1,\\cdots,\\mathbf{x}_N,\\mathbf{p}_1,\\cdots,\\mathbf{p}_N) = \\sum_{i=1}^N \\bigg(\\frac{\\mathbf{p}_i^2}{2m} + V(\\mathbf{x}_i)\\bigg),\n\\] where \\(V(\\mathbf{x}_i)\\) is zero inside a container of volume \\(V\\) and infinite otherwise. Since this Hamiltonian factors into a product of single-particle terms, we can most easily calculate \\(Z\\) by first calculating the single particle partition function \\(Z_1\\). We have \\[\n\\begin{align*}\nZ_1 &= \\frac{1}{h^3} \\int d^{3} \\mathbf{x} \\ d^{3} \\mathbf{p} \\ \\exp\\bigg[-\\beta \\bigg(\\frac{\\mathbf{p}^2}{2m} + V(\\mathbf{x})\\bigg)\\bigg] \\\\\n&= \\frac{V}{h^3} \\int d^3 \\mathbf{p} \\ \\exp\\bigg[-\\beta \\bigg(\\frac{\\mathbf{p}^2}{2m}\\bigg)\\bigg] \\\\\n&= \\frac{V}{h^{3}} \\bigg(\\frac{2\\pi m}{\\beta}\\bigg)^{3/2} \\\\\n&= \\frac{V}{\\lambda_T^3}.\n\\end{align*}\n\\] Here we’ve defined a useful quantity \\(\\lambda_T \\equiv \\frac{h}{\\sqrt{2\\pi m k_B T}}\\) known as the thermal DeBroglie wavelength. For now this is just a convenience, but we’ll see in quantum statistical mechanics that this wavelength has physical meaning. It says something about how tightly packed particles in a gas need to be for quantum effects to become important. In classical statistical mechanics it won’t matter, since temperatures are assumed to be so large that particles are well-approximated as point particles.\nNow that we have \\(Z_1\\), we can find the full partition function by multiplying them together \\(N\\) times and dividing by \\(N!\\), \\[\nZ = \\frac{1}{N!} Z_1^N = \\frac{V^N}{N! \\lambda_T^{3N}} = \\frac{V^N}{N! h^{3N}} \\bigg(\\frac{2\\pi m}{\\beta}\\bigg)^{3N/2} \\ .\n\\] We can now get everything of interest from here by looking at the logarithm of the partition function, \\[\n\\log Z = N \\log \\frac{Ve}{N} \\bigg(\\frac{2\\pi m}{\\beta h^2}\\bigg)^{3/2}.\n\\] For example, the energy is given by \\[\nE = - \\frac{\\partial \\log Z}{\\partial \\beta} = \\frac{3N}{\\beta} = \\frac{3}{2} N k_B T,\n\\] and the pressure is given by \\[\nP = \\frac{1}{\\beta} \\frac{\\partial \\log Z}{\\partial V} = \\frac{N}{\\beta V} = \\frac{Nk_B T}{V}.\n\\] One way to see how useful the canonical ensemble can be is by calculating the distribution of momentum in the gas. The Maxwell-Boltzmann distribution pretty much falls right out of the Boltzmann factor. Indeed, we have \\[\n\\begin{align*}\np(\\mathbf{p}_1) &= \\frac{1}{N! Z} \\frac{1}{h^{3N}} \\int d^{3N} \\mathbf{x} \\ d^{3N-1} \\mathbf{p} \\ p(\\mathbf{x}_1,\\cdots,\\mathbf{x}_N,\\mathbf{p}_1,\\cdots,\\mathbf{p}_N)\n\\\\\n&= \\bigg(\\frac{\\lambda_T^{3}}{V}\\bigg)^N \\bigg(\\frac{V}{\\lambda_T^{3}}\\bigg)^{N-1} \\frac{V}{h} \\exp\\bigg[-\\beta \\bigg(\\frac{\\mathbf{p}_1^2}{2m}\\bigg)\\bigg] \\\\\n&= \\frac{1}{(2\\pi m k_B T)^{3/2}} \\exp\\bigg[-\\frac{1}{2}\\bigg(\\frac{\\mathbf{p}_1^2}{mk_B T}\\bigg) \\bigg].\n\\end{align*}\n\\]\n\n\nEquipartition Theorem\nRecall from thermodynamics that we have a quick rule of thumb for finding the energy of certain gases. Look at the Hamiltonian of the gas and count number of quadratic degrees of freedom (both momenta plus positions). If the gas has \\(d\\) quadratic degrees of freedom, then the energy of the gas is just \\[\nE = \\frac{d}{2} N k_B T.\n\\] For example, a monoatomic ideal gas has just \\(d=3\\) quadratic degrees of freedom per molecule, since each molecule has a total energy proportional to \\(p_x^2 + p_y^2 + p_z^2\\). This means the total energy is \\(E=\\frac{3}{2} Nk_B T\\), as we’ve already derived multiple times. Let’s use the canonical ensemble to quickly prove the most general case of the equipartition theorem.\nSuppose a system of \\(N\\) particles has a joint Hamiltonian \\(H\\) consisting of the sum of single-particle Hamiltonians \\(H_i\\). Each single-particle contains \\(d\\) degrees of freedom \\(\\boldsymbol{\\xi}=(\\xi_1,\\xi_2,\\cdots,\\xi_d)\\). Suppose each single-particle Hamiltonian has the same form \\(H_i = \\sum_{k=1}^d c_k |\\boldsymbol{\\xi}|^s\\) for some positive power \\(s\\). Then the joint Hamiltonian is given by \\[\nH = \\sum_{i=1}^N \\sum_{k=1}^d c_k |\\boldsymbol{\\xi}_{ik}|^s.\n\\] Equipartition Theorem: In equilibrium, the total thermodynamic energy \\(E = \\langle H \\rangle\\) is given by \\[\nE = \\frac{d}{s} N k_B T.\n\\] In particular, when \\(s=2\\) we recover the usual equipartition theorem for quadratic degrees of freedom.\nProof: Without loss of generality, suppose the system has all its degrees of freedom in the momenta, so we can write \\[\nH = \\sum_{i=1}^N \\sum_{k=1}^{d} c_k |\\mathbf{p}_{ik}|^s.\n\\] It’s convenient here to work in the canonical ensemble. Since all we’re interested in is the energy, for simplicity we’ll assume all particles are distinguishable and ignore factors of \\(h\\). The partition function is then \\[\nZ = \\int d^{dN} \\mathbf{x} \\ d^{dN} \\mathbf{p} \\ \\exp\\bigg[-\\beta \\sum_{i=1}^N \\sum_{k=1}^{d} c_k |\\mathbf{p}_{ik}|^s\\bigg].\n\\] Suppose the particles are confined to some \\(d\\)-dimensional hypervolume \\(V_d\\). Factoring the exponentials by particle, we have \\[\nZ = V_d^N \\bigg(\\prod_{k=1}^d \\int d^{d} \\mathbf{p} \\ e^{-\\beta c_k |\\mathbf{p}|^s}\\bigg)^N.\n\\] We can write the \\(d\\)-dimensional volume element \\(d^d \\mathbf{p}\\) as a product of the \\(d\\)-dimensional solid angle \\(d^d\\Omega\\) and a radial term \\(r^{d-1} dr\\), \\[\nd^d \\mathbf{p} = r^{d-1} dr d^d \\Omega.\n\\] Since the integral for \\(Z\\) is spherically symmetric, we can integrate each solid angle to just get the surface area of a \\(d\\)-dimensional hypersphere, which we’ll recall is given by \\(S_d\\). What remains inside the integral is just the factorial function up to a change of variable. We thus have \\[\n\\begin{align*}\nZ &= V_d^N \\bigg(\\prod_{k=1}^d \\int d^d\\Omega \\int_0^{\\infty} dp \\ p^{d-1} e^{-\\beta c_k p^s}\\bigg)^N \\\\\n&= V_d^N \\bigg(\\prod_{k=1}^d S_d \\int_0^{\\infty} dp \\ p^{d-1} e^{-\\beta c_k p^s}\\bigg)^N \\\\\n&= V_d^N \\bigg(\\prod_{k=1}^d\\frac{S_d\\big(\\frac{d}{s}-1\\big)!}{s(\\beta c_k)^{1/s}}\\bigg)^N. \\\\\n\\end{align*}\n\\] In particular, notice that \\(Z\\) is proportional to \\(\\beta^{-Nd/s}\\), which means \\(\\log Z \\sim -\\frac{Nd}{s} \\log \\beta\\). The energy is thus just \\[\nE = -\\frac{\\partial \\log Z}{\\partial \\beta} = \\frac{Nd}{s\\beta} = \\frac{d}{s} N k_B T. \\quad \\text{Q.E.D.}\n\\] The equipartition theorem is a useful shortcut for quickly figuring out how the partition function depends on temperature since we can use it to avoid having to do any integration, provided the degrees of freedom are all of the same power. For example, we saw for an ultrarelativistic ideal gas that \\(H = \\sum_{i=1}^N |\\mathbf{p}_i|c\\). In this case \\(s=1\\) and \\(d=3\\), so \\(E=3Nk_B T\\), which we’ve seen.\n\n\nExample: Diatomic Gas\nLet’s now consider a slightly more interesting variant of the ideal gas, namely one where the particles in question aren’t point particles anymore, but rather diatomic. That is, each particle consists of two masses that strongly interact with each other. Think of these particles as dumbbells with masses at each end. Except when these dumbbells are heated up enough, the bar holding them together becomes a spring that can oscillate at some frequency. While this may seem academic, diatomic molecules are actually very common in nature. Many atoms, like hydrogen, oxygen, nitrogen, etc only exist in nature in diatomic form because they’re more chemically stable. For example, each “particle” of hydrogen gas is actually a pair of interacting hydrogen atoms.\nWe’ll assume each diatomic gas particle does not interact with other particles, so there’s no external potential energy associated with each dumbbell. We’ll assume the two masses inside interact via some radial potential energy \\(u\\) undergoing small oscillations near some minimum energy. We can describe the Hamiltonian for each individual particle by \\[\nH_1 = \\frac{\\mathbf{p}_1^2}{2m_1} + \\frac{\\mathbf{p}_2^2}{2m_2} + u(|\\mathbf{x}_1-\\mathbf{x}_2|).\n\\] As usual when working with pairs of masses, it’s helpful to re-express the Hamiltonian in center of mass and relative coordinates. We’ll also assume the potential is approximately harmonic at some distance \\(d\\), with \\(u(r) \\approx \\frac{1}{2}\\mu\\omega^2 r^2 + u(d)\\) to get \\[\nH_1 = \\frac{\\mathbf{P}^2}{2M} + \\frac{\\mathbf{p}^2}{2\\mu} + \\frac{1}{2}\\mu\\omega^2 r^2 + u(d).\n\\] Now, before turning the crank, it’s worth stopping to take a look at what we’re doing. We’ve assumed that the two masses only undergo oscillations about some equilibrium distance \\(d\\). We’ve also assumed each particle oscillates at the same constant frequency \\(\\omega\\), not a horrible assumption for a large number of particles in equilibrium at sufficiently high temperatures. Since we’re assuming harmonic oscillations around this distance \\(d\\) there will be an added constant \\(u(d)\\) that we can ignore.\nNotice that each term in the Hamiltonian contributes quadratic degrees of freedom. This means we should be able to use the equipartition theorem to predict what the energy should be. Since each particle has \\(3+3+1=7\\) quadratic degrees of freedom, with no work we can predict the energy of this system to be \\(E=\\frac{7}{2} k_B T\\). Now we’ll verify this the hard way.\nAssuming the particles don’t interact, the partition function \\(Z\\) factors into a product of one-particle partition functions \\(Z_1\\). For indistinguishable particles, we’d thus have \\(Z = \\frac{1}{N!} Z_1^N\\). Writing out \\(Z_1\\) and integrating each term, we have \\[\n\\begin{align*}\nZ_1 &= \\frac{1}{h^6} \\int d^3 \\mathbf{X} \\ d^3 \\mathbf{P} \\ d^3 \\mathbf{x} \\ d^3 \\mathbf{p} \\ e^{-\\beta H_1} \\\\\n&= \\frac{1}{h^6} \\int d^3 \\mathbf{X} \\int d^3 \\mathbf{P} \\ e^{-\\beta \\frac{\\mathbf{P}^2}{2M}} \\int 4\\pi r^2 dr \\ e^{-\\frac{\\beta\\mu\\omega^2}{2} r^2} \\int d^3 \\mathbf{p} \\ e^{-\\beta \\frac{\\mathbf{p}^2}{2\\mu}} \\\\\n&= \\frac{4\\pi V}{h^6} \\bigg(\\frac{2\\pi M}{\\beta}\\bigg)^{3/2} \\bigg(\\frac{2\\pi \\mu}{\\beta}\\bigg)^{3/2} \\bigg(\\frac{2\\pi}{\\mu\\omega^2\\beta}\\bigg)^{1/2} \\\\\n&= \\frac{16\\pi^4 M^{3/2}}{h^6} \\frac{V}{\\beta^{7/2}} \\ .\n\\end{align*}\n\\] From this expression we can easily read off the energy and pressure. As predicted by the equipartition theorem, we indeed have \\[\nE=\\frac{7}{2} Nk_B T.\n\\] We can also easily see that the non-interacting diatomic gas has the same ideal gas law \\(PV=Nk_B T\\). If we like, we can also calculate the heat capacity \\(C\\), which turns out to be \\[\nC = \\frac{\\partial E}{\\partial T} \\bigg |_{V,N} = \\frac{7}{2} N k_B \\ .\n\\] This value for heat capacity is a precise prediction of classical statistical mechanics that we can test in the lab for any diatomic gas. In fact, at room temperature the measured heat capacity of most gases tends to be about \\(C = \\frac{5}{2} Nk_B\\). Essentially what’s going on is that at room temperature the vibrational mode gets frozen out, leaving only the translational and rotational modes to contribute to the energy. The reason for this behavior we’ll only be able to answer later with quantum statistical mechanics.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Classical Statistical Mechanics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/classical-stat-mech.html#higher-ensembles",
    "href": "statistical-mechanics/classical-stat-mech.html#higher-ensembles",
    "title": "Classical Statistical Mechanics",
    "section": "Higher Ensembles",
    "text": "Higher Ensembles\nWhile the microcanonical ensemble is perhaps the most intuitive, and the canonical ensemble is perhaps the most useful, there are other ensembles we can imagine as well. In fact, each free energy has its own ensemble. We’ve already seen the ensembles corresponding to the energy \\(E\\) and Helmholtz free energy \\(F\\). We’ll now look at two more ensembles corresponding to the last two free energies, the Gibbs free energy \\(G\\) and the grand potential \\(\\mathcal{G}\\). While all ensembles are in some sense equivalent, each ensemble has its advantages in certain situations. In particular, we’ll see the grand canonical ensemble arise in our treatment of quantum statistical mechanics.\n\nGibbs Canonical Ensemble\nSimilar to the canonical ensemble, the Gibbs canonical ensemble arises from considering a system in equilibrium with a much larger heat bath, except now we also allow for the possibility that work is done on the system as well. That is, we now take \\(M=(T,J,N)\\) and assume the total energy has the form \\(E = H(\\boldsymbol{\\mu}) + J \\cdot X\\). Then the probability of achieving a given microstate \\(\\boldsymbol{\\mu}\\) at a particular displacement \\(X\\) is given by \\[\np(\\boldsymbol{\\mu},X) = \\frac{1}{Z_G(T,J,N)}e^{-\\beta \\big(H(\\boldsymbol{\\mu})-J \\cdot X\\big)},\n\\] where \\(Z_G=Z_G(T,J,N)\\) is again a normalization constant, this time called the Gibbs partition function. It’s given by integrating over all microstates \\(\\boldsymbol{\\mu}\\) and displacements \\(X\\), \\[\nZ_G(T,J,N) \\equiv \\int dX \\ d \\boldsymbol{\\mu} \\ e^{-\\beta \\big(H(\\boldsymbol{\\mu})-J \\cdot X\\big)}.\n\\] By factoring the dependences on \\(\\boldsymbol{\\mu}\\) and \\(X\\) we can write the Gibbs partition function in terms of the canonical partition function \\(Z(T,X,N)\\) as \\[\nZ_G(T,J,N) = \\int dX \\ e^{-\\beta J \\cdot X} \\ Z(T,X,N).\n\\] Since the displacement \\(X\\) is now a random variable, we can ask how it varies about its mean \\(\\langle X \\rangle\\). Following the same logic as we did with the energy, it’s easy to see that \\[\n\\langle X \\rangle = \\frac{\\partial}{\\partial (\\beta J)} \\log Z_G.\n\\] The cumulants of \\(X\\) are similarly given by \\[\n\\langle X^k \\rangle_c = \\frac{\\partial^k \\log Z_G}{\\partial (\\beta J)^k} = \\frac{\\partial^{k-1} \\langle X \\rangle}{\\partial (\\beta J)^{k-1}}.\n\\] In particular, all cumulants of \\(X\\) are extensive. This means the variance is proportional to \\(\\langle X \\rangle\\), which means the fluctuations in \\(X\\) go like \\(\\sigma_X = \\sqrt{\\langle X \\rangle}\\). This means we can again assert that \\(X = X^* = \\langle X \\rangle\\) when \\(N\\) is really large.\nWe can relate the partition function to the Gibbs free energy by observing \\[\nZ_G = \\int dX \\ dE \\ e^{-\\beta(E-J \\cdot X)} \\Omega(E,X) = \\int dX \\ dE \\ e^{-\\beta(E-TS-J \\cdot X)}.\n\\] Here \\(G \\equiv E-TS-\\mu \\cdot N\\) is of course the Gibbs free energy. Using the saddlepoint approximation, in the thermodynamic limit we can write \\[\nZ_G \\approx e^{-\\beta G(E^*, \\ X^*)}.\n\\] Solving for \\(G\\) we have the familiar expression \\[\nG = -k_B T \\log Z_G.\n\\] From here all other thermodynamic variables we seek follow in the usual way using the identity \\[\ndG = -S dT - X \\cdot dJ + \\mu \\cdot dN.\n\\] In this ensemble the canonical energy formula no longer applies. Instead that formula gives the enthalpy \\(H = E - J \\cdot X\\), \\[\nH = -\\frac{\\partial \\log Z_G}{\\partial \\beta}.\n\\]\n\n\nGrand Canonical Ensemble\nThe grand canonical ensemble follows exactly the same logic as the Gibbs ensemble did, except now we imagine the system is in equilibrium with a heat bath and allowed to exchange particles with it via chemical work. That is, \\(M = (T,X,\\mu)\\) and the energy has the form \\(E = H(\\boldsymbol{\\mu}) + \\mu \\cdot N\\). Then the probability of a given microstate \\(\\boldsymbol{\\mu}\\) and a given particle number \\(N\\) is given as \\[\np(\\boldsymbol{\\mu},N) = \\frac{1}{\\mathcal{Z}(T,X,\\mu)}e^{-\\beta \\big(H(\\boldsymbol{\\mu})-\\mu \\cdot N\\big)},\n\\] where \\(\\mathcal{Z}(T,X,\\mu)\\) is another normalization constant gotten by integrating over all possible \\(\\boldsymbol{\\mu}\\) and summing over all possible \\(N\\). This is called the grand canonical partition function, given by \\[\n\\mathcal{Z}(T,X,\\mu) \\equiv \\sum_{N=0}^\\infty \\int d \\boldsymbol{\\mu} \\ e^{-\\beta \\big(H(\\boldsymbol{\\mu})-\\mu \\cdot N\\big)}.\n\\] We can again factor the \\(\\boldsymbol{\\mu}\\) and \\(N\\) dependences apart and write just \\[\n\\mathcal{Z}(T,X,\\mu) = \\sum_{N=0}^\\infty e^{\\beta\\mu \\cdot N} Z(T,X,N).\n\\] The dimensionless variable \\(\\log z \\equiv \\beta\\mu = \\frac{\\mu}{k_B T}\\) is sometimes called the log fugacity, where \\(z \\equiv e^{\\beta\\mu}\\) is the fugacity. The fugacity turns out to be important in quantum statistical mechanics since its size says something about the limiting behaviors of the equations of state at low temperatures.\nWhile not necessarily obvious, more mathematical care is needed to interpret the grand canonical ensemble due to the fact that \\(N\\) is no longer fixed, but allowed to vary. This means we can’t a priori just assume that \\(N\\) is large and the thermodynamic limit applies. Moreover, the phase spaces being integrated over aren’t even of the same dimensions since each \\(d=6N\\).\nInstead of interpreting things in terms of \\(N\\), a random variable, we instead need to interpret things in terms of \\(\\langle N \\rangle\\). Following the same logic as we did with the energy, it’s easy to see that \\[\n\\langle N \\rangle = \\frac{\\partial}{\\partial (\\beta\\mu)} \\log \\mathcal{Z}.\n\\] The cumulants of \\(N\\) are similarly given by \\[\n\\langle N^k \\rangle_c = \\frac{\\partial^k \\log \\mathcal{Z}}{\\partial (\\beta\\mu)^k} = \\frac{\\partial^{k-1} \\langle N \\rangle}{\\partial (\\beta\\mu)^{k-1}}.\n\\] In particular, all cumulants of \\(N\\) are proportional to \\(\\langle N \\rangle\\). In particular, this means the variance is proportional to \\(\\langle N \\rangle\\), which means the fluctuations in \\(N\\) go like \\(\\sigma_N = \\sqrt{\\langle N \\rangle}\\). By the same usual logic, this means we can assert that \\(N = N^* = \\langle N \\rangle\\) provided \\(N^*\\) is very large, which will typically be the case in thermodynamics.\nAgain using the same logic as before, we can relate the partition function to the free energy by observing \\[\n\\mathcal{Z} = \\sum_{N=0}^\\infty \\int dE \\ e^{-\\beta(E-\\mu \\cdot N)} \\Omega(E,N) = \\sum_{N=0}^\\infty \\int dE \\ e^{-\\beta(E-TS-\\mu \\cdot N)}.\n\\] Here \\(\\mathcal{G} \\equiv E-TS-\\mu \\cdot N\\) is of course the grand potential. Using the saddlepoint approximation, in the thermodynamic limit we can write \\[\n\\mathcal{Z} \\approx e^{-\\beta\\mathcal{G}(E^*,N^*)}.\n\\] Solving for \\(\\mathcal{G}\\) we again have the familiar expression \\[\n\\mathcal{G} = -k_B T \\log \\mathcal{Z}.\n\\] From here all other thermodynamic variables we seek follow in the usual way using the identity \\[\nd\\mathcal{G} = -S dT + J \\cdot dX - N \\cdot d\\mu.\n\\]\n\n\nExample: Ideal Gas\nAs an example, we’ll work out the equations of state again for the ideal gas, both in the Gibbs canonical and the grand canonical ensembles. Starting with the Gibbs canonical ensemble, the Gibbs partition function can be calculated by observing that the integral over \\(V\\) is almost a factorial function. We have \\[\n\\begin{align*}\nZ_G &= \\int_0^\\infty dV e^{-\\beta PV} Z \\\\\n&= \\frac{1}{N! h^{3N}} \\bigg(\\frac{2\\pi m}{\\beta}\\bigg)^{3N/2} \\int_0^\\infty dV e^{-\\beta PV} V^N \\\\\n&= \\frac{1}{N! h^{3N}} \\bigg(\\frac{2\\pi m}{\\beta}\\bigg)^{3N/2} \\frac{N!}{(\\beta P)^{N+1}} \\\\\n&= \\bigg(\\frac{2\\pi m}{h^2 \\beta}\\bigg)^{3N/2} (\\beta P)^{-(N+1)}. \\\\\n\\end{align*}\n\\] Taking the logarithm of both sides, we have \\[\n\\log Z_G \\approx \\frac{3N}{2} \\log \\frac{2\\pi m}{h^2 \\beta} - N \\log \\beta P.\n\\] We can get the mean volume \\(V \\approx \\langle V \\rangle\\) by differentiating both sides with respect to \\(-\\beta P\\), \\[\nV \\approx \\frac{\\partial \\log Z_G}{\\partial (-\\beta P)} = \\frac{N}{\\beta P} = \\frac{Nk_B T}{P}.\n\\] This is of course the usual equation of state, with \\(PV = N k_B T\\). We can easily find the enthalpy as well, \\[\nH = -\\frac{\\partial \\log Z_G}{\\partial \\beta} = \\frac{3N}{2\\beta} + \\frac{N}{\\beta} = \\frac{5}{2} N k_B T.\n\\] Since \\(H = E + PV\\), we can immediately read off the usual formula for energy, \\(E = \\frac{3}{2} N k_B T\\).\nMoving onto the grand canonical ensemble, the grand partition function is given by noting that the sum over \\(N\\) is just the Taylor series of an exponential function. We have \\[\n\\begin{align*}\n\\mathcal{Z} &= \\sum_{N=0}^\\infty dV e^{\\beta \\mu N} Z(\\beta) \\\\\n&= \\sum_{N=0}^\\infty e^{\\beta \\mu N} \\frac{V^N}{N! h^{3N}} \\bigg(\\frac{2\\pi m}{\\beta}\\bigg)^{3N/2} \\\\\n&= \\sum_{N=0}^\\infty \\frac{1}{N!} \\bigg[\\frac{Ve^{\\beta\\mu}}{h^3} \\bigg(\\frac{2\\pi m}{\\beta}\\bigg)^{3/2}\\bigg]^N \\\\\n&= \\exp \\bigg[\\frac{Ve^{\\beta\\mu}}{h^3} \\bigg(\\frac{2\\pi m}{\\beta}\\bigg)^{3/2}\\bigg]. \\\\\n\\end{align*}\n\\] This means \\(\\log \\mathcal{Z}\\) is just \\[\n\\log \\mathcal{Z} = \\frac{Ve^{\\beta\\mu}}{h^3} \\bigg(\\frac{2\\pi m}{\\beta}\\bigg)^{3/2}.\n\\] It’s helpful to first find \\(N \\approx \\langle N \\rangle\\). We have \\[\nN \\approx \\frac{\\partial \\log \\mathcal{Z}}{\\partial (\\beta\\mu)} = \\frac{Ve^{\\beta\\mu}}{h^3} \\bigg(\\frac{2\\pi m}{\\beta}\\bigg)^{3/2} = \\log \\mathcal{Z}.\n\\] This means all cumulants of \\(N\\) will be \\(\\log \\mathcal{Z}\\) as well. Recall all cumulants being equal implies that \\(N\\) must be Poisson distributed. The grand potential is evidently just \\(\\mathcal{G} = -N k_B T\\). But by extensivity \\(\\mathcal{G} = -PV\\). We thus get the ideal gas law, \\[\nPV = N k_B T.\n\\] Getting the energy is slightly trickier. It’s not too hard to show that \\[\nE - \\mu N = -\\frac{\\partial \\log \\mathcal{Z}}{\\partial \\beta} = N \\bigg(\\frac{3}{2} k_B T - \\mu\\bigg).\n\\] Cancelling \\(\\mu N\\) from both sides, we again get \\(E = \\frac{3}{2} N k_B T\\). Finally, if we like we can solve for the chemical potential by inverting the formula for \\(N\\). As expected, we have \\[\n\\mu = k_B T \\log \\frac{N}{V} \\bigg(\\frac{2\\pi m k_B T}{h^2}\\bigg)^{3/2}.\n\\]",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Classical Statistical Mechanics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/classical-gases.html",
    "href": "statistical-mechanics/classical-gases.html",
    "title": "Classical Gases",
    "section": "",
    "text": "Cumulant Expansion\nWe’ll start by formulating the partition function for a gas with an arbitrary interaction potential \\(U\\). Consider a gas of \\(N\\) indistinguishable particles in a fixed container \\(\\mathcal{B}\\) of volume \\(V\\). Suppose the gas has a Hamiltonian of the form \\[\nH = \\sum_{i=1}^N \\bigg(\\frac{\\mathbf{p}_i}{2m} + V(\\mathbf{x}_i)\\bigg) + U(\\mathbf{x}_1, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N),\n\\] where \\(V(\\mathbf{x}_i)\\) is the usual potential specifying that particle \\(i\\) must be inside the container, and \\(U(\\mathbf{x}_1, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N)\\) is some general interaction potential between the \\(N\\) particles. Let’s proceed using the canonical ensemble and try to find the partition function \\(Z(T,V,N)\\). Following the same logic as we did with the ideal gas, we have \\[\n\\begin{align*}\nZ &= \\frac{1}{N! h^{3N}} \\int d^{3N} \\mathbf{x} \\ d^{3N} \\mathbf{p} \\ e^{-\\beta H} \\\\\n&= \\frac{1}{N! h^{3N}}\\int_\\mathcal{B} d^{3N} \\mathbf{x} \\ e^{-\\beta U} \\int d^{3N} \\mathbf{p} \\ e^{-\\beta\\sum \\frac{\\mathbf{p}_i}{2m}} \\\\\n&= \\frac{1}{N!} \\bigg(\\frac{V}{\\lambda_T^3}\\bigg)^N \\int_\\mathcal{B} \\frac{d^{3N} \\mathbf{x}}{V^N} \\ e^{-\\beta U},\n\\end{align*}\n\\] where \\(\\lambda_T = \\frac{h}{\\sqrt{2\\pi m k_B T}}\\) is the Thermal DeBroglie wavelength defined previously. In this form, we recognize that the terms outside the integral are just the partition function of the ideal gas, which we’ll denote by \\(Z_0\\). If we think of \\(\\frac{1}{V^N}\\) is some kind of uniform probability density over the container \\(\\mathcal{B}\\) then we can imagine the above integral being some kind of expected value \\(\\langle e^{-\\beta U} \\rangle\\). We can thus write the partition function in the simple form \\[\nZ = Z_0 \\langle e^{-\\beta U} \\rangle.\n\\] Notice the expected value can be thought of as a kind of characteristic function for \\(U\\), except with \\(ik\\) replaced by \\(\\beta\\). If we expand the characteristic function as a series in terms of the moments, we get \\[\nZ = Z_0 \\sum_{k=0}^\\infty \\frac{(-\\beta)^k}{k!} \\langle U^k \\rangle.\n\\] That means if we instead look at \\(\\log Z\\), then the sum over the moments will become a sum over the cumulants, giving \\[\n\\log Z = \\log Z_0 + \\sum_{k=1}^\\infty \\frac{(-\\beta)^k}{k!} \\langle U^k \\rangle_c.\n\\] This is called the cumulant expansion. We’ve created an expansion of the free energy in terms of the cumulants of the interaction potential. Unfortunately though, we still have no systematic way to actually calculate these cumulants.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Classical Gases</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/classical-gases.html#cumulant-expansion",
    "href": "statistical-mechanics/classical-gases.html#cumulant-expansion",
    "title": "Classical Gases",
    "section": "",
    "text": "Pairwise Interactions\nTo make further progress we need to make assumptions about the functional form of the interaction potential. The most obvious first step is to imagine the potential consists only of pairwise interactions. While one could imagine interactions between three particles, four particles, or any higher number of them, it’s the pairwise interactions that encompass the common interactions found in nature for weakly interacting systems. Roughly speaking, provided we aren’t dealing with a dense plasma, pairwise interactions alone yield a sufficient description of the behavior of a gas.\nIn this form, the full potential \\(U\\) breaks up into a sum of potentials \\(u\\) over pairs of particles. We’ll assume the pairwise interactions only interact radially and ignore any self-interactions. We can thus write \\[\nU(\\mathbf{x}_1, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N) = \\sum_{i=1}^N \\sum_{j=i+1}^N u(|\\mathbf{x}_i - \\mathbf{x}_j|) \\equiv \\sum_{i &lt; j} u_{ij} \\ .\n\\]\nWith this functional form we can proceed to simplify the cumulants one by one. Let’s start with the mean. Notice that since all integrals are over the same potential over the same region, we can think of them as a multiple of a single pairwise integral. There are \\(\\binom{N}{2}\\) such integrals. Each integral is only over two coordinates. The rest yield a factor of \\(V^{N-2}\\). We thus have \\[\n\\begin{align*}\n\\langle U \\rangle_c &= \\sum_{i &lt; j} \\int_\\mathcal{B} \\frac{d^{3N} \\mathbf{x}}{V^N} \\ u_{ij} \\\\\n&= \\frac{N(N-1)}{2} \\frac{V^{N-2}}{V^N} \\int_\\mathcal{B} d^3\\mathbf{x}_1 \\ d^3\\mathbf{x}_2 \\ u_{12}.\n\\end{align*}\n\\] Finally, we can change variables and integrate over the center of mass coordinate \\(\\mathbf{X}\\) and relative coordinate \\(\\mathbf{x}\\). This lets us pull out another factor of \\(V\\). If we employ the thermodynamic limit and assume the interaction ranges are much less than the size of the container, we have \\[\n\\langle U \\rangle_c \\approx \\frac{N^2}{2V} \\int d^3\\mathbf{x} \\ u(r).\n\\] Using the same technique we can proceed to find the variance of \\(U\\) as well. Evidently, we have \\[\n\\langle U^2 \\rangle_c = \\sum_{i &lt; j} \\sum_{k &lt; \\ell} \\bigg(\\big\\langle u_{ij} u_{k\\ell} \\big\\rangle - \\big\\langle u_{ij} \\big\\rangle \\big\\langle u_{k\\ell} \\big\\rangle \\bigg).\n\\] We now have to proceed case-by-case. There are three cases to consider.\n\nCase 1 (\\(i \\neq k\\) and \\(j \\neq \\ell\\)): In this case all the position vectors are distinct. Since each position is independent, we can factor the joint moment to get \\(\\big\\langle u_{ij} u_{k\\ell} \\big\\rangle = \\big\\langle u_{ij} \\big\\rangle \\big\\langle u_{k\\ell} \\big\\rangle\\), which of course implies that the contributions of these terms must vanish in the variance calculation.\nCase 2 (\\(i=k\\) and \\(j \\neq \\ell\\)): In this case exactly two position vectors will be equal in each term. However, we can still change variables by defining \\(\\mathbf{x}_{ij} \\equiv \\mathbf{x}_i - \\mathbf{x}_j\\) and \\(\\mathbf{x}_{i\\ell} \\equiv \\mathbf{x}_i - \\mathbf{x}_\\ell\\). These relative position vectors are also independent of each other, which again means we can factor the joint moments to get \\(\\big\\langle u_{ij} u_{i\\ell} \\big\\rangle = \\big\\langle u_{ij} \\big\\rangle \\big\\langle u_{i\\ell} \\big\\rangle\\), which implies that the contributions of these terms must also vanish in the variance calculation.\nCase 3 (\\(i = k\\) and \\(j = \\ell\\)): The last case is when both pairs are the equal. This just implies that \\(\\big\\langle u_{ij} u_{ij} \\big\\rangle = \\big\\langle u_{ij}^2\\big\\rangle\\).\n\nWe finally have then that the variance of \\(U\\) is just \\[\n\\langle U^2 \\rangle_c = \\sum_{i &lt; j} \\bigg(\\big\\langle u_{ij}^2 \\big\\rangle -  \\big\\langle u_{ij}\\big\\rangle^2\\bigg).\n\\] In a way this kind of makes sense. The full variance is just the pairwise sum of the individual pairwise variances. Since each moment is just the same integral over \\(\\binom{N}{2}\\) possible configurations, we can simplify the expression to \\[\n\\langle U^2 \\rangle_c = \\frac{N(N-1)}{2} \\bigg[\\frac{1}{V}\\int_{\\mathcal{B}} d^3\\mathbf{x} \\ u^2(r) - \\frac{1}{V^2}\\bigg(\\int_{\\mathcal{B}} d^3\\mathbf{x} \\ u(r)\\bigg) \\bigg].\n\\] In the limit of large \\(N,V\\) the second term will be much smaller than the first, hence we can write \\[\n\\langle U^2 \\rangle_c \\approx \\frac{N^2}{2V} \\int d^3\\mathbf{x} \\ u^2(r).\n\\] This means to second order in the cumulants we can evidently write \\[\n\\begin{align*}\n\\log Z &\\approx \\log Z_0 - \\beta \\langle U \\rangle_c + \\frac{\\beta^2}{2} \\langle U^2 \\rangle_c - \\cdots \\\\\n&\\approx N \\log \\frac{Ve}{\\lambda^3} + \\frac{N^2}{2V} \\bigg(-\\beta \\int d^3\\mathbf{x} \\ u(r) + \\frac{\\beta^2}{2} \\int d^3\\mathbf{x} \\ u^2(r) - \\cdots\\bigg).\n\\end{align*}\n\\] To see what’s going on here it’s most useful to look at the pressure. Using the formula \\(\\beta P = \\frac{\\partial \\log Z}{\\partial V}\\), we have \\[\n\\beta P = \\frac{N}{V} - \\frac{N^2}{2V^2} \\bigg(-\\beta \\int d^3\\mathbf{x} \\ u(r) + \\frac{\\beta^2}{2} \\int d^3\\mathbf{x} \\ u^2(r) - \\cdots\\bigg).\n\\] It’s pretty clear now what we’ve done. We’ve created a series for the pressure in powers of the density \\(n=\\frac{N}{V}\\). This series is called the virial expansion. Had we kept higher-order interaction terms this series would continue on in higher powers of \\(n\\), \\[\n\\beta P = n - \\frac{n^2}{2} \\bigg(-\\beta\\int d^3\\mathbf{x} \\ u(r) + \\frac{\\beta^2}{2} \\int d^3\\mathbf{x} \\ u^2(r) - \\cdots\\bigg) + O(n^3).\n\\] In the most dilute limit we recover the ordinary ideal gas law. The first correction subtracts a term proportional to \\(n^2\\). And so on.\n\n\nMayer F-Function\nWhile it’s nice to have an expansion in terms of the density, what we have isn’t actually practical to work with. In particular, the second virial coefficient is a series of integrals that are not at all obvious to compute. We can attempt to sum it up though by using the expansion of the exponential function to write write \\[\n\\begin{align*}\n-\\beta \\int d^3\\mathbf{x} \\ u(r) + \\frac{\\beta^2}{2} \\int d^3\\mathbf{x} \\ u^2(r) - \\cdots &= \\int d^3\\mathbf{x} \\ \\sum_{k=1}^\\infty \\frac{(-\\beta)^k}{k!} u^k(r) \\\\\n&= \\int d^3\\mathbf{x} \\ \\bigg[\\exp\\big(-\\beta u(r)\\big) - 1\\bigg] . \\\\\n\\end{align*}\n\\] If we define the integrand to be \\(f(r) \\equiv \\exp\\big(-\\beta u(r)\\big) - 1\\), what we’ve done is found an expansion in terms of various integrals of \\(f(r)\\), called the Mayer f-function. The integral of this function will converge as long as the potential itself decays sufficiently rapidly, e.g. as the van der Waals interaction would. In terms of this function, we can re-write the virial expansion as \\[\n\\beta P = n - \\frac{n^2}{2} \\int d^3\\mathbf{x} \\ f(r) + O(n^3).\n\\] Provided we can integrate the Mayer f-function for some given interaction potential, we can find an expansion for the pressure at least up to second order in the density. It’s worth noting, however, that this is only a good expansion in the dilute limit when densities are small. In the opposite situation we’d have the dense limit, which describes the behavior of plasmas. In that scenario we’d want to use a completely different type of expansion, e.g. ring diagrams.\nOf course, we’d like to be able to look at all the higher virial coefficients as well, not just the second order term. Continuing to do so with cumulants will be cumbersome since we’re always stuck summing these kinds of series. The fact that things come out so cleanly in terms of the Mayer f-function suggests that we should instead consider expanding things in terms of it rather than the cumulants. This leads to the cluster expansion.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Classical Gases</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/classical-gases.html#cluster-expansion",
    "href": "statistical-mechanics/classical-gases.html#cluster-expansion",
    "title": "Classical Gases",
    "section": "Cluster Expansion",
    "text": "Cluster Expansion\nLet’s recall what it is we’re trying to evaluate. We’d like to find an expression for the partition function \\[\nZ = Z_0\\int_\\mathcal{B} \\frac{d^{3N} \\mathbf{x}}{V^N} \\ e^{-\\beta U} = Z_0 \\int_\\mathcal{B} \\frac{d^{3N} \\mathbf{x}}{V^N} \\prod_{i &lt; j} e^{-\\beta u_{ij}} \\ .\n\\] If we use the Mayer function to define \\(f_{ij} \\equiv e^{-\\beta u_{ij}}\\), we can instead write \\[\nZ = \\frac{Z_0}{V^N} \\int_\\mathcal{B} d^{3N} \\mathbf{x} \\prod_{i &lt; j} (1 + f_{ij}) \\equiv \\frac{Z_0}{V^N} Q.\n\\]\n\nCluster Diagrams\nOur challenge is to find a way to evaluate this integral over all possible pairs. If we expand the product \\(\\prod (1+f_{ij})\\) we’d get a series in increasing powers of \\(f\\), where each product appears exactly once, \\[\n\\prod_{i &lt; j} (1 + f_{ij}) = 1 + \\sum_{i &lt; j} f_{ij} \\ + \\sum_{i &lt; j &lt; k &lt; \\ell} f_{ij} f_{k\\ell} + \\cdots \\ .\n\\] It’s helpful to visualize this product in a different way using cluster diagrams. Imagine the \\(N\\) particles as representing \\(N\\) points in a graph. Think of each product of \\(f_{ij}\\) as an edge connecting the two points \\(i\\) and \\(j\\). In the expansion, a \\(1\\) represents no points being connected. A single \\(f_{ij}\\) represents only the points \\(i\\) and \\(j\\) being connected. A double term \\(f_{ij}f_{k\\ell}\\) represents two connections, one between \\(i\\) and \\(j\\), the other between \\(k\\) and \\(\\ell\\). And so on for higher order terms.\nIn this representation, we can schematically represent the general \\(Q\\) function as the sum over all possible graphs over \\(N\\) points, where each sum of \\(\\ell\\) powers of \\(f\\) represents a sum over all graphs with exactly \\(\\ell\\) edges, \\[\n\\begin{align*}\nQ &= \\int_\\mathcal{B} d^{3N} \\mathbf{x} \\prod_{i &lt; j} (1 + f_{ij}) \\\\\n&= \\int_\\mathcal{B} d^{3N} \\mathbf{x} \\bigg[1 + \\sum_{i &lt; j} f_{ij} \\ + \\sum_{i &lt; j &lt; k &lt; \\ell} f_{ij} f_{k\\ell} + \\cdots \\bigg] \\\\\n&= \\int_\\mathcal{B} d^{3N} \\mathbf{x} \\ \\bigg[(\\text{disconnected graph}) + \\sum (\\text{all graphs with one edge}) + \\sum (\\text{all graphs with two edges}) + \\cdots\\bigg] \\ .\n\\end{align*}\n\\] Though not necessarily obvious, we can use a trick from graph theory to reorganize this sum over graphs into something more convenient. For any one graph being summed, we can think of it as itself being a product of its own connected components. For example, suppose we had a particular graph of \\(N=6\\) points in which point \\(1\\) is disconnected, points \\(2\\) and \\(3\\) are connected, and points \\(4\\), \\(5\\), and \\(6\\) are all connected to each other. This would represent the product \\[\n\\int_\\mathcal{B} d^{3} \\mathbf{x}_1 \\int_\\mathcal{B} d^{3} \\mathbf{x}_2 d^{3} \\mathbf{x}_3 \\ f_{23} \\int_\\mathcal{B} d^{3} \\mathbf{x}_4 d^{3} \\mathbf{x}_5 d^{3} \\mathbf{x}_6 \\ f_{45} f_{56}.\n\\] Now, define \\(b_\\ell\\) to be the sum of all connected components connecting exactly \\(\\ell\\) points. That is, \\(b_1\\) is the sum over all completely disconnected clusters, \\(b_2\\) is the sum over all pairs of connected edges, \\(b_3\\) is the sum over all triplets of connected points, and so on. Diagrammatically these might look as follows.\n\n\n\n\n\nNote how the number of terms in the sum blows up with increasing \\(\\ell\\). For example, \\(b_1\\) and \\(b_2\\) each contain one configuration, \\(b_3\\) contains \\(4\\) configurations. It turns out that \\(b_4\\) contains \\(24\\) different terms. That is, there are \\(24\\) ways to connect \\(4\\) points with all possible configurations of edges. Etc.\nNow, for each graph being summed over in the \\(Q\\) function, we expect there to be some number \\(n_\\ell\\) of components in that graph connecting exactly \\(\\ell\\) points. Taking the product over all of these components for each \\(\\ell = 1, \\cdots, N\\) then gives the value of that one graph. In doing this, note that some components may end up being over-counted, so we have to include a multiplicity factor \\(W(\\{n_\\ell\\})\\) in each product to correct the counts. In the end, we’re now representing \\(Q\\) as a sum over all graphs such that each graph contains exactly \\(N\\) points and partitions into exactly \\(n_\\ell\\) clusters for each allowed \\(\\ell\\). As an equation, this means\n\\[\nQ = \\sideset{}{'}\\sum_{\\underset{N=\\sum n_\\ell \\ell}{\\{n_\\ell\\}}} W(\\{n_\\ell\\})\\prod_{\\ell=0}^N b_\\ell^{n_\\ell} \\ .\n\\] Notice the notation used here. This is a constrained sum, a sum over all partitions such that that \\(N=\\sum_\\ell n_\\ell \\ell\\). The multiplicity factor \\(W(\\{n_\\ell\\})\\) turns out to have the explicit form \\[\nW(\\{n_\\ell\\}) = \\frac{N!}{\\prod_\\ell (\\ell!)^{n_\\ell} n_\\ell!}.\n\\] This comes from the fact that for each graph we’re permuting \\(N\\) points. But for each connected component we need to divide out the number of ways of permuting those points. Since there are \\(n_\\ell\\) such components, this means we need to divide by \\((\\ell!)^{n_\\ell}\\) for each \\(\\ell\\). We’re still overcounting though, because exchanging any \\(\\ell\\) cluster with another \\(\\ell\\) cluster shouldn’t change anything, so we also need to divide by \\(n_\\ell!\\). This gives the full multiplicity factor.\nAt any rate, attempting to sum over all graphs to get \\(Q\\) still seems like a daunting task. This is mainly due to the constrained sum, which requires that we sum over all possible partition sizes \\(n_\\ell\\) consistent with the constraint \\(\\sum \\ell n_\\ell = N\\). In general finding constrained sums is hard. But there’s a work around. Namely, we can allow \\(N\\) to vary as well. We can do that by looking not at the canonical partition function \\(Z\\), but instead the grand canonical partition function \\(\\mathcal{Z}\\). Then all we have to do is replace any occurrence of \\(N\\) with \\(\\sum \\ell n_\\ell\\) and sum over all possible partitions \\(\\{n_\\ell\\}\\). Then we’ll have \\[\n\\begin{align*}\n\\mathcal{Z} &= \\sum_{N=0}^\\infty e^{\\beta\\mu N} Z \\\\\n&= \\sum_{N=0}^\\infty e^{\\beta\\mu N} \\sideset{}{'}\\sum_{\\underset{N=\\sum n_\\ell \\ell}{\\{n_\\ell\\}}} \\frac{W(\\{n_\\ell\\})}{N! \\lambda^{3N}}\\prod_{\\ell=0}^N b_\\ell^{n_\\ell} \\\\\n&= \\sum_{\\{n_\\ell\\}} \\bigg(\\frac{e^{\\beta\\mu}}{\\lambda^3}\\bigg)^{\\sum \\ell n_\\ell} \\frac{1}{\\prod_\\ell (\\ell!)^{n_\\ell} n_\\ell!} \\prod_{\\ell=0}^{\\sum \\ell n_\\ell} b_\\ell^{n_\\ell} \\\\\n&= \\prod_{\\ell=1}^\\infty \\sum_{n_\\ell=0}^\\infty \\frac{b_\\ell^{n_\\ell}}{(\\ell!)^{n_\\ell} n_\\ell!} \\bigg(\\frac{e^{\\beta\\mu}}{\\lambda^3}\\bigg)^{\\ell n_\\ell} \\\\\n&= \\prod_{\\ell=1}^\\infty \\exp\\bigg[\\frac{b_\\ell}{\\ell!} \\bigg(\\frac{e^{\\beta\\mu}}{\\lambda^3}\\bigg)^{\\ell}\\bigg] \\ .\n\\end{align*}\n\\] Taking the logarithm then converts the product into the simpler sum \\[\n\\boxed{\n\\log \\mathcal{Z} = \\sum_{\\ell=1}^\\infty \\frac{b_\\ell}{\\ell!} \\bigg(\\frac{e^{\\beta\\mu}}{\\lambda^3}\\bigg)^{\\ell}\n} \\ .\n\\]\n\n\nVirial Expansion\nAs with the cumulant expansion, what we’re mainly interested in here is getting a formula for the pressure. The easiest way to do that here is to use extensivity. Using the fact \\(\\mathcal{G} = -k_B T \\log \\mathcal{Z} = -PV\\) for an extensive system, we can express the pressure as \\[\n\\beta P = \\frac{1}{V} \\log \\mathcal{Z} = \\sum_{\\ell=1}^\\infty \\frac{1}{\\ell!} \\frac{b_\\ell}{V} \\bigg(\\frac{e^{\\beta\\mu}}{\\lambda^3}\\bigg)^{\\ell}.\n\\] Notice that this quantity must be intensive since \\(\\log \\mathcal{Z}\\) must be extensive and we’re dividing by the volume \\(V\\). To make this clear, let’s conveniently define \\(\\textblank_\\ell \\equiv \\frac{b_\\ell}{V}\\). Let’s also define \\(x \\equiv \\frac{e^{\\beta\\mu}}{\\lambda_T^3}\\). Noting that \\(b_1 = V\\) implies \\(\\textblank_1 = 1\\), we can thus write \\[\n\\beta P = \\sum_{\\ell=1}^\\infty \\frac{\\textblank_\\ell}{\\ell!} x^{\\ell} = x + \\frac{\\textblank_2}{2} x^2 + \\frac{\\textblank_3}{6} x^3 + \\cdots \\ .\n\\] We thus have a series for pressure in terms of this scaled fugacity variable \\(x\\). However, what we’d like to get is a virial expansion. That is, we’d like to express the pressure as a series in increasing powers of the density \\(n\\), \\[\n\\beta P = n + B_2 n^2 + B_3 n^3 + \\cdots \\ .\n\\] To do that, recall that we can express \\(N \\approx \\langle N \\rangle\\) in the grand canonical ensemble with the formula \\(N = \\frac{\\partial \\log \\mathcal{Z}}{\\partial (\\beta\\mu)}\\). Dividing both sides by \\(V\\) and again using extensivity, we can then express the number density \\(n\\) as its own series in powers of \\(x\\), \\[\nn = \\frac{1}{V} \\frac{\\partial \\log \\mathcal{Z}}{\\partial (\\beta\\mu)} = \\sum_{\\ell=1}^\\infty \\frac{\\textblank_\\ell}{(\\ell-1)!} x^{\\ell} = x + \\textblank_2 x^2 + \\frac{\\textblank_3}{2} x^3 + \\cdots \\ .\n\\] We’ve managed to express both \\(\\beta P\\) and \\(n\\) each as a series expansion in \\(x\\). To find \\(\\beta P\\) as a function of \\(n\\) we need to eliminate \\(x\\). To do that we need to invert the series \\(n=n(x)\\) to get \\(x=x(n)\\). In general, there’s no way to invert a series like this and get a closed form solution for \\(x=x(n)\\). However, we can get a series for \\(x\\) in powers of \\(n\\). This method will suffice for us, as we’re only interested in the first few terms in the virial expansion anyway.\nTo invert a power series we start by supposing that the inverse \\(x=x(n)\\) itself can be expanded as a power series in \\(n\\) with coefficients that need to be determined, \\[\nx = a_1 n + a_2 n^2 + a_3 n^3 + O(n^4) \\ .\n\\] To find the coefficients we substitute this expression back into the expression for \\(n=n(x)\\) and match terms by powers. We can find \\(a_1\\) immediately be noting that when \\(x\\) is infinitesimal we must have \\(n \\approx x\\), meaning \\(a_1 = 1\\). We’ll then proceed by finding coefficients up to \\(O(n^3)\\). Substituting \\(x\\) back into \\(n(x)\\) and keeping terms only up to \\(O(n^3)\\), we have \\[\n\\begin{align*}\nn &= x + \\textblank_2 x^2 + \\frac{\\textblank_3}{2} x^3 + O(x^4) \\\\\n&= (n + a_2 n^2 + a_3 n^3) + \\textblank_2 (n + a_2 n^2 + a_3 n^3)^2 + \\frac{\\textblank_3}{2} (n + a_2 n^2 + a_3 n^3)^3 + O(n^4) \\\\\n&= (n + a_2 n^2 + a_3 n^3) + \\textblank_2 (n^2 + 2 a_2 n^3) + \\frac{\\textblank_3}{2} n^3 + O(n^4) \\\\\n&= n + \\big(a_2 + \\textblank_2\\big) n^2 + \\bigg(a_3 + 2 \\textblank_2 a_2 + \\frac{\\textblank_3}{2}\\bigg) n^3 + O(n^4) \\ .\n\\end{align*}\n\\] Now, for the left side to equal the right-hand side the coefficients for each higher power of \\(n\\) must be zero. Starting with \\(n^2\\) we have \\(a_2 = -\\textblank_2\\). Plugging this into the coefficient for \\(n^3\\), we then get \\(a_3 = \\big(2\\textblank_2^2 - \\frac{\\textblank_3}{2}\\big)\\). We can continue onto as many powers as we like by working in this way, but we’ll stop here. We’ve evidently found that \\[\nx = n - \\textblank_2 n^2 + \\bigg(2\\textblank_2^2 - \\frac{\\textblank_3}{2}\\bigg) n^3 + O(n^4) \\ .\n\\] Now we can substitute this into \\(\\beta P\\) to get an expansion in powers of the density \\(n\\). We have \\[\n\\begin{align*}\n\\beta P &= x + \\frac{\\textblank_2}{2} x^2 + \\frac{\\textblank_3}{6} x^3 + \\cdots \\\\\n&\\approx \\bigg[n - \\textblank_2 n^2 + \\bigg(2\\textblank_2^2 - \\frac{\\textblank_3}{2}\\bigg)n^3\\bigg] \\\\\n&+ \\frac{\\textblank_2}{2}\\bigg[n - \\textblank_2 n^2 + \\bigg(2\\textblank_2^2 - \\frac{\\textblank_3}{2}\\bigg)n^3\\bigg]^2 \\\\\n&+ \\frac{\\textblank_3}{6}\\bigg[n - \\textblank_2 n^2 + \\bigg(2\\textblank_2^2 - \\frac{\\textblank_3}{2}\\bigg)n^3\\bigg]^3. \\\\\n\\end{align*}\n\\] Rearranging terms in increasing powers of \\(n\\), we finally have a virial expansion up to \\(O(n^4)\\), \\[\n\\beta P = n - \\frac{\\textblank_2}{2} n^2 + \\bigg(\\textblank_2^2-\\frac{\\textblank_3}{3}\\bigg) n^3 + O(n^4).\n\\] We now have a systematic way to get a virial expansion up to any arbitrary power of \\(n\\). After some simplification, the first few virial coefficients turn out to be given by \\[\n\\begin{align*}\nB_1(T) &= 1 \\ , \\\\\nB_2(T) &= -\\frac{\\textblank_2}{2} = -\\frac{1}{2} \\int_{\\mathcal{B}} d^3 \\mathbf{x} \\ f(\\mathbf{x}) \\ , \\\\\nB_3(T) &= \\bigg(\\textblank_2^2-\\frac{\\textblank_3}{3}\\bigg) = -\\frac{1}{3} \\int_{\\mathcal{B}} d^3 \\mathbf{x} \\ d^3 \\mathbf{x}' \\ f(\\mathbf{x}) f(\\mathbf{x}') f(\\mathbf{x}-\\mathbf{x}') \\ . \\\\\n\\end{align*}\n\\] Notice the first two virial coefficients agree with what we calculated from the cumulant expression. The \\(B_3\\) term is new, as we had no easy way to calculate it before. In principle we could keep going to higher order coefficients if we like, but we won’t.\nOf course, we still have no way to actually calculate what the virial coefficients are since we don’t know what the interaction potential \\(u\\) is, hence neither what the Mayer function \\(f\\) is. To proceed further we need to make some assumptions about the interaction potentials involved in a typical gas.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Classical Gases</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/classical-gases.html#van-der-waals-interactions",
    "href": "statistical-mechanics/classical-gases.html#van-der-waals-interactions",
    "title": "Classical Gases",
    "section": "Van der Waals Interactions",
    "text": "Van der Waals Interactions\nThe true interaction forces in real gases can be quite complicated. Typically gases will be electrically neutral, so Coulomb forces don’t tend to play a role. What’s left are much shorter-range forces arising from the permanent or induced dipole interactions between particles. These short-range forces are called van der Waals forces. Typically, such forces fall off very rapidly with the particle separation distance, and rapidly increase as the two particles get too close together. To understand exactly why these forces occur and how they really behave we’d need fairly advanced quantum mechanics. But for our purposes it suffices to adopt a highly simplified crude model, which will lead us to the van der Waals equation of state.\n\nSimple Model\nA very crude model of the van der Waals force is to assume interactions arise from a radially symmetric potential of the form \\[\nu(r) =\n\\begin{cases}\n-u_0 \\big(\\frac{r_0}{r}\\big)^6 & r \\geq r_0 \\ , \\\\\n\\infty & r &lt; r_0 \\ . \\\\\n\\end{cases}\n\\] At close distances we’ll assume the force is infinitely repulsive when \\(r &lt; r_0\\). This hard wall idea approximates the effect that particles will bounce off each other if they get too close, within some distance \\(r_0\\) that’s usually on the order of Angstroms for atoms or molecules. When \\(r \\gg r_0\\) the force becomes weakly attractive, with the potential falling off like \\(r^{-6}\\). The remaining positive constant \\(u_0\\) characterizes the strength of the interaction, usually around room temperature in temperature units.\n\n\n\n\n\nWe can now proceed to calculate the virial coefficients for such an interaction. We already know \\(B_1 = 1\\), so there’s nothing to do there. We’ll recover the ideal gas law at low densities as expected. For \\(B_2\\), we need to find the integral of \\(f(r)\\), which is \\[\n\\begin{align*}\n\\int_{\\mathcal{B}} d^3 \\mathbf{x} \\ f(r) &= \\int_0^\\infty 4\\pi r^2 dr \\ \\big(e^{-\\beta u(r)}-1\\big) \\\\\n&= -\\int_0^{r_0} 4\\pi r^2 dr + \\int_{r_0}^\\infty 4\\pi r^2 dr \\ \\bigg[\\exp\\bigg(\\beta u_0 \\bigg(\\frac{r_0}{r}\\bigg)^6\\bigg)-1\\bigg] \\\\\n&= -\\frac{4\\pi}{3} r_0^3 + \\int_{r_0}^\\infty 4\\pi r^2 dr \\ \\bigg[\\exp\\bigg(\\beta u_0 \\bigg(\\frac{r_0}{r}\\bigg)^6\\bigg)-1\\bigg] . \\\\\n\\end{align*}\n\\] To get at the second term analytically we’ll have to make a further approximation. Suppose \\(\\beta u_0 \\ll 1\\), meaning \\(u_0 \\ll k_B T\\). This is the high temperature regime of classical statistical mechanics. Here we can approximate the integral as \\[\n\\int_{r_0}^\\infty 4\\pi r^2 dr \\ \\bigg[\\exp\\bigg(\\beta u_0 \\bigg(\\frac{r_0}{r}\\bigg)^6\\bigg)-1\\bigg] \\approx \\int_{r_0}^\\infty 4\\pi r^2 dr \\ \\beta u_0\\bigg(\\frac{r_0}{r}\\bigg)^6 = \\frac{4\\pi}{3} r_0^3 \\beta u_0.\n\\] Notice both terms include the term \\(\\omega \\equiv \\frac{4\\pi}{3} r_0^3\\). This is just the volume of a sphere of radius \\(r_0\\), called the excluded volume. It’s the volume of each particle’s electron cloud in a sense. In terms of the excluded volume, we can thus write \\(B_2\\) simply as \\[\nB_2(T) = -\\frac{1}{2} \\int_{\\mathcal{B}} d^3 \\mathbf{x} \\ f(r) = \\frac{\\omega}{2} (1-\\beta u_0).\n\\] In principle, we could also then proceed to calculate the third virial coefficient \\(B_3\\). However, this turns out to be much harder, as now we have to integrate over three-particle interactions. We can eliminate one of the coordinates and write \\[\nB_3(T) = -\\frac{1}{3} \\int_{\\mathcal{B}} d^3 \\mathbf{x} \\ d^3 \\mathbf{x}' \\ f(\\mathbf{x}) f(\\mathbf{x}') f(\\mathbf{x}-\\mathbf{x}'),\n\\] but actually evaluating this integral analytically is an onerous task. Of course, it can often be found numerically. And on the story goes for the higher virial coefficients as well. We’re thus left with the approximation \\[\n\\beta P = n + \\frac{\\omega}{2} (1-\\beta u_0) n^2 + O(n^3) + \\cdots.\n\\] Let’s just focus on the second order part of this equation and see what happens in that case. Whatever it is should at least be more accurate than the ideal gas approximation. If we group the terms involving \\(\\beta\\) on the left-hand side, we have \\[\n\\beta \\bigg(P + \\frac{\\omega u_0}{2} n^2\\bigg) = n + \\frac{\\omega}{2} n^2 + \\cdots \\ .\n\\] Now, for small \\(n\\), the right-hand side looks like the binomial series expansion for \\(\\big(1-\\frac{N\\omega}{2}\\big)^{-1}\\). Let’s conveniently define two constants, \\(a \\equiv \\frac{1}{2} u_0 \\Omega\\) and \\(b \\equiv \\frac{\\omega}{2}\\). If we do that and use the fact that \\(n = \\frac{N}{V}\\), we can write the above equation as \\[\n\\boxed{\n\\bigg(P + a\\frac{N^2}{V^2}\\bigg)(V-Nb) = Nk_B T.\n}\n\\] In this form, the equation of state gives the well-known van der Waals equation of chemistry.\n\n\nValidity of van der Waals\nBefore proceeding, it’s worth stepping back and asking whether the virial expansion we just performed is a good expansion, that it makes sense physically. Let’s try to see what might cause the van der Waals equation to fail:\n\nHigh densities: Clearly if \\(n\\) is large we can’t truncate the virial expansion to second order like we did. We’d need to deal with all the higher order terms as well. Fortunately for a gas this isn’t really an issue. Notice that the series grows like the ratio of the first two terms, which goes like \\[\n\\frac{B_2n^2}{B_1n} = \\frac{\\frac{\\omega}{2} (1-\\beta u_0)n^2}{n} \\sim n\\omega.\n\\] Roughly speaking, \\(n\\omega\\) is the density of the gas divided by its density when liquified. For air at STP, we already saw that ratio of densities is about \\(10^{-3}\\), clearly small enough that we can justify neglecting higher order terms in the expansion. Of course, while this is true for gases, it’s not always true. For example, it’s not true for liquids or plasmas.\nLow temperatures: In deriving the virial coefficient \\(B_2\\) we made the crucial assumption that \\(k_B T \\gg u_0\\). That is, we assumed that temperatures are large compared to the molecular interaction strengths. For gases at room temperatures this is fine, but as temperatures go towards absolute zero things break down and this approximation no longer holds.\nLong-range interactions: Another failure mode we didn’t explicitly mention above is the nature of the interaction potential. We assumed a potential of the form \\(u(r) \\sim r^{-6}\\), which we were able to integrate from \\(r_0\\) to \\(\\infty\\). If we look back at the integral though, we can see that won’t be true for every power of \\(r\\). In particular, such an integral will diverge for powers \\(k &gt; -3\\). This means, for example, that we can’t treat Coulomb interactions this way, where \\(k=-1\\). These divergent integrals arise when interactions are long-range, i.e. when they don’t fall off reasonably fast. For the van der Waals potential we don’t have this problem. But if we’re dealing with, say plasmas, we do have to worry about this issue. In that case we’d need to do a completely different kind of expansion, e.g. using ring diagrams.\n\nThe van der Waals equation was originally derived phenomenologically based on the following two physical arguments:\n\nWe expect the available volume to each particle is reduced by an amount proportional to \\(N\\). Each particle occupies a definite volume, namely the excluded volume \\(\\omega\\). As we saw from the hard sphere gas, this means that the available volume gets reduced by \\(\\frac{N\\omega}{2}\\), not \\(N\\omega\\) as we might expect.\nThe presence of an interaction strength \\(u_0\\) means each particle spends more time away from the walls of the container due to particles in the center attracting it inward. This has the effect of reducing the pressure on the walls of the container by some amount proportional to \\(n^2\\).\n\nIn the lab, \\(a\\) and \\(b\\) are measured experimentally and tabulated for each gas of interest. For most real gases the parameters tend to be quite small at typical densities. For example, for water, tables give the van der Waals constants in chemistry units as \\(a = 5.464 \\ \\frac{\\text{L}^2 \\ \\text{atm}}{\\text{mol}^2}\\) and \\(b = 0.03049 \\ \\frac{\\text{L}}{\\text{mol}}\\). In SI units, these become \\(a = 1.53 \\cdot 10^{-48}\\) and \\(b = 5.06 \\cdot 10^{-29}\\).\nIn typical conditions the pressure correction will often be much larger than the volume correction. With water, the volume correction becomes important when \\(nb \\sim 1\\), or when the mass density gets up to \\(\\rho \\sim 0.6 \\ \\frac{\\text{g}}{\\text{cm}^3}\\). Note the density of liquid water is about \\(\\rho \\sim 1 \\ \\frac{\\text{g}}{\\text{cm}^3}\\), meaning water practically needs to liquify for the volume correction to become important. Compare that with the pressure correction, which becomes important when \\(an^2 \\ll P\\). At atmospheric pressure, this effect would seem to become important when \\(\\rho \\sim 0.008 \\ \\frac{\\text{g}}{\\text{cm}^3}\\), which is much smaller, closer to the density of air in fact.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Classical Gases</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/classical-gases.html#phase-transitions",
    "href": "statistical-mechanics/classical-gases.html#phase-transitions",
    "title": "Classical Gases",
    "section": "Phase Transitions",
    "text": "Phase Transitions\nThe fact that the van der Waals equation only seems to become important as a gas starts to liquify suggests that we should study this transition region from gas to liquid. This is one of many examples of a phase transition, a discontinuous change in the properties of a system as a state variable changes. When dealing with gases, phase transitions often manifest as sharp lines in the phase diagram, i.e. the diagram of pressure vs temperature. Recall such a diagram looks very roughly like the following.\n\n\n\n\n\nPhase diagrams often show similar patterns. At low \\(T\\) and \\(P\\) the gas is in its solid phase. All the particles are aligned in something like a crystal lattice. As \\(T\\) increases the gas moves into its liquid phase. In this phase, the particles are still close together, but they’re no longer locked into a lattice anymore. They’re allowed to move around on top of each other. As \\(T\\) increases further the gas moves into its gas phase. In this phase the particles start to move apart from each other, behaving more like an ideal gas.\nWhat’s more interesting are the sharp lines separating the phases, called coexistence curves. Suppose we fixed \\(T\\) relatively high and started increasing \\(P\\). The gas starts in its gas phase, but at some pressure \\(P=P(T)\\) the gas undergoes a phase transition, turning sharply into a liquid as it crosses the gas-liquid coexistence curve. What’s more interesting though is that this fact is only true for temperatures below some critical temperature \\(T_c\\). If \\(T &gt; T_c\\) no phase transition happens at all. The gas stays in the same phase and just gets continuously more dense. Something strange evidently happens at this critical point.\n\nCritical Points\nTo understand this in more depth let’s consider again the van der Waals interaction \\(PV\\) diagram. As a function of \\(P\\), we have \\[\nP = \\frac{Nk_B T}{V-Nb} - a \\frac{N^2}{V^2}.\n\\] If we plot the isotherms of this equation for different values of \\(T\\), we get something roughly like the following.\n\n\n\n\n\nFirst, notice that all the isotherms asymptotically approach the reduced volume \\(Nb=\\frac{N\\omega}{2}\\) as \\(V \\rightarrow 0\\). This is a consequence of the physical fact that the gas becomes incompressible once it reaches its liquid phase. The isotherms separate into three distinct regimes depending on whether \\(T\\) is greater than some special critical temperature \\(T_c\\),\n\nWhen \\(T \\gg T_c\\) the \\(n^2\\) term is negligible and we essentially recover the hard sphere isotherms with \\(P(V-Nb) \\propto T\\). These are the green curves plotted. As \\(V \\gg Nb\\) these reduce to the ideal gas isotherms with \\(PV \\propto T\\).\nWhen \\(T \\ll T_c\\) we get the curves plotted in red. Unlike the green curves, these have a region with a wiggle. For a given pressure in this region, the curve seems to imply the gas can coexist at three different volumes (and hence three different densities as well). In reality, one of these is disallowed by thermodynamic stability. The dashed part of the curve is unstable since it has negative compressibility. As we’ll see, the black line correctly describes the curve in this region.\nLast, the critical isotherm at \\(T=T_c\\) is plotted in blue. This curve is what separates the first two regimes. Each pressure corresponds to a unique volume, but the curve does have a flat region around some special critical point \\((V_c,P_c)\\).\n\nWe can pretty easily solve for the critical values \\((T_c,V_c,P_c)\\). Since we have three values to solve for, we need to find three independent equations. The first is easy, as \\((T,V,P)\\) must clearly satisfy the van der Waals equation to lie on any of these curves at all. For the other two equations, we impose the condition that we’re on the \\(T=T_c\\) isotherm. A sufficient condition for this to hold is that the first and second derivatives of \\(P(V)\\) must vanish at the critical point. That is, we need to solve the following, \\[\n\\begin{align*}\nP &= \\frac{Nk_B T}{V-Nb} - a \\frac{N^2}{V^2} \\ , \\\\\n\\frac{\\partial P}{\\partial V} \\bigg |_{T,N} &= -\\frac{Nk_B T}{(V-Nb)^2} + 2a \\frac{N^2}{V^3} \\equiv 0 \\ , \\\\\n\\frac{\\partial^2 P}{\\partial V^2} \\bigg |_{T,N} &= 2\\frac{Nk_B T}{(V-Nb)^3} - 6a \\frac{N^2}{V^4} \\equiv 0 \\ . \\\\\n\\end{align*}\n\\] These can be simultaneously solved to give \\[\nT_c = \\frac{8a}{27k_Bb} , \\qquad V_c = 3Nb , \\qquad P_c = \\frac{a}{27b^2} \\ .\n\\] The second equation is more often expressed in terms of a critical density to get rid of the dependence on \\(N\\), defined by \\(\\rho_c \\equiv mn_c \\equiv \\frac{Nm}{V_c}\\). As an example, for water, the critical values would be \\[\nT_c \\approx 650 \\ ^\\circ \\text{K} \\ , \\qquad \\rho_c \\approx 0.19 \\ \\frac{\\text{g}}{\\text{cm}^3} \\ , \\qquad P_c \\approx 218 \\text{ atm} \\ .\n\\] Note that while \\(T_c\\) and \\(P_c\\) agree with experiment, the critical density is slightly off. The measured value is actually \\(\\rho_c \\approx 0.33\\) in the same units. This discrepancy has to do with dipole-dipole interactions among water molecules that we’re not accounting for.\n\n\nStability\nBut what exactly do these critical values represent? Clearly something is going on around the critical temperature that we should investigate. Above \\(T_c\\) everything appears to be what we’d expect. We recover ideal gas like behavior, with some minor corrections as \\(T \\rightarrow T_c\\) from above. Let’s look at the situation where \\(T &lt; T_c\\) and see what might be happening. As mentioned above, the isotherms in this region exhibit non-physical behavior in the regions where the slope of the curve is increasing. Such a phenomenon would imply negative compressibility, since in the positively-sloped region we’d have \\[\n\\kappa = -\\frac{1}{V} \\frac{\\partial V}{\\partial P} \\bigg |_{T,N} &lt; 0.\n\\] Negative compressibility would imply a gas gets bigger as the pressure on it increases. But this is thermodynamically unstable. In fact it even violates the laws of statistical mechanics. To see why, recall by extensivity we have \\(\\log \\mathcal{Z} = \\beta PV\\), which implies \\[\n\\begin{align*}\nN &\\approx \\langle N \\rangle = \\frac{\\partial \\log\\mathcal{Z}}{\\partial (\\beta\\mu)} = V\\frac{\\partial P}{\\partial \\mu} \\bigg |_T \\ , \\\\\n\\sigma_N^2 &= \\frac{\\partial^2 \\log\\mathcal{Z}}{\\partial (\\beta\\mu)^2} = \\frac{\\partial N}{\\partial (\\beta\\mu)} = k_B T \\frac{\\partial N}{\\partial \\mu} \\bigg |_T \\ . \\\\\n\\end{align*}\n\\] Dividing the two expressions and using the chain rule, we have \\[\n\\begin{align*}\n\\frac{\\sigma_N^2}{N} &= \\frac{k_B T \\frac{\\partial N}{\\partial \\mu} \\big |_T}{V\\frac{\\partial P}{\\partial \\mu} \\big |_T} \\\\\n&= \\frac{k_B T}{V} \\frac{\\partial N}{\\partial P} \\bigg |_T \\\\\n&= \\frac{k_B T}{V} \\bigg(-\\frac{\\partial N}{\\partial V} \\bigg |_{T,P} \\ \\frac{\\partial V}{\\partial P} \\bigg |_{T,N}\\bigg) \\\\\n&= -\\frac{k_B T}{V} \\frac{N}{V} \\ \\frac{\\partial V}{\\partial P} \\bigg |_{T,N} \\\\\n&= \\frac{N k_B T}{V} \\bigg(- \\frac{1}{V} \\frac{\\partial V}{\\partial P} \\bigg |_{T,N} \\bigg) \\\\\n&= n k_B T \\ \\kappa_T \\ .\n\\end{align*}\n\\] Now, recall the variance of a random variable must always be non-negative. This implies the above ratio must also be non-negative, which implies the compressibility must be as well. From thermodynamics, we also know that this must also imply thermodynamical stability \\(\\delta P \\delta V \\leq 0\\), which we saw is equivalent to having \\(\\kappa \\geq 0\\). These stability conditions are essentially what determine which states are allowed and which aren’t. Thermodynamically unstable states can’t really happen, at least with any reasonable probability in the thermodynamic limit.\n\n\nMaxwell Construction\nSo what’s going on in the subcritical regime where \\(T &lt; T_c\\)? In fact a phase transition is happening. Imagine varying the pressure on the gas and seeing how the volume (and hence the density) of the gas changes, e.g. by applying a force to a piston.\n\nAt low pressures the allowed states are on the far right of the subcritical isotherms. In this region the ideal gas law more or less holds, perhaps with minor corrections. Any small changes in pressure will cause proportionally small changes in the volume of the gas. That is, the gas behaves like a gas. It’s in its gas phase.\nAt high pressures the allowed states are instead on the far left of the isotherms, asymptotically approaching the barrier at the excluded volume \\(Nb\\). In this region, to get a small change in volume we’d need to apply a huge change in pressure. The gas is almost incompressible. In fact, the gas is in its liquid phase, since \\(V \\approx Nb\\) implies the particles are densely packed together.\nIn between these two regions the gas is in coexistence. At a given pressure \\(P_{co}\\), the curve takes on three distinct volumes (i.e. three densities). Two of these volumes are stable, meaning they can occur. The third is unstable, meaning it can’t occur. This means if we’re exactly at \\(P_{co}\\) the gas seemingly exists in two volumes at once, call them \\(V_{gas}\\) and \\(V_{liq}\\). This region of the \\(PV\\) diagram where two densities can simultaneously coexist is called the coexistence region. Due to the discontinuity, when crossing this region, the volume of the gas will evidently change by some discontinuous amount \\(\\Delta V = V_{gas} - V_{liq}\\) as it apparently undergoes a phase transition from liquid to gas or vice versa.\n\nOf course, the van der Waals equation isn’t right for a real gas at arbitrary densities. It’s only a dilute approximation. It should and indeed does fail for dense gases. That it’s predicting the behavior of a liquid and the phase transition is thus interesting. Maybe we can correct the equation to work even better by fixing what’s going on in the coexistence region.\nConsider again the formula for the particle number along an isotherm, \\[\nN = V\\frac{\\partial P}{\\partial \\mu} \\bigg |_T.\n\\] To get the chemical potential along an isotherm we can rearrange and integrate \\(d\\mu = \\frac{V}{N}dP\\) to get \\[\n\\mu(P) - \\mu(P_0) = \\int_{P_0}^P dP' \\ \\frac{V(P')}{N}.\n\\] Let’s stop and think about what this integration is doing. It’s summing up horizontal slices under the isotherm from \\(P_0\\) to \\(P\\). As long as \\(V(P)\\) is single-valued this is perfectly fine. But inside the coexistence region \\(V(P)\\) is not single-valued, which means the integral will be path-dependent. For example, consider the following situation. Suppose we wanted to find the chemical potential from the point \\(A\\) to the point \\(F\\) along the isotherm shown below.\n\n\n\n\n\nAlong the path \\(ABC\\) the chemical potential \\(\\mu\\) keeps increasing since \\(dP\\) is positive. Along \\(CD\\) though \\(dP\\) is negative, which means \\(\\mu\\) goes back down. Then, along \\(DF\\), \\(dP\\) is positive again, causing \\(\\mu\\) to again start increasing. The trajectory \\(\\mu(P)\\) will cross at the points \\(B\\) and \\(E\\), causing the chemical potential to seemingly be multiple-valued in the region between \\(C\\) and \\(D\\). This crossing point occurs at the coexistence pressure \\(P_{co}=P_E=P_B\\).\nTo fix this problem we can make use of the thermodynamical fact that in equilibrium the gas should seek out the lowest available chemical potential at a given temperature and pressure. This means that in the multiple-valued region the gas should only traverse lower part of the path between \\(C\\) and \\(D\\) i.e. the path \\(ABF\\). For this to be true the closed loop \\(CDE\\) should vanish, \\[\n\\oint_{P_B}^{P_E} dP \\ \\frac{V(P)}{N} = 0 .\n\\] This is equivalent to saying the chemical potentials in the liquid and gas phases should equal in coexistence, i.e. \\(\\mu_{liq}=\\mu_{gas}\\). That is, in coexistence the gas is in chemical equilibrium, with the liquid and gas portions exchanging particles at an equal rate.\nEnforcing chemical equilibrium is equivalent to finding \\(P_{co}\\) by drawing a horizontal line between the points \\(B\\) and \\(E\\) on the isotherm such that the areas in regions \\(BDO\\) and \\(OCB\\) equal and cancel out. This method of graphically finding this pressure is called the Maxwell construction. This sort of thing can be done in the lab by starting with a liquid at pressure \\(P_{liq}\\) and slowly decreasing the pressure at constant temperature until the same value \\(P_{co}\\) occurs twice for two different volumes.\nInterestingly, the Maxwell construction seems to predict that at coexistence a gas can take on any volume between \\(V_{liq}\\) and \\(V_{gas}\\). The construction doesn’t tell us, however, which of these volumes will be taken on for a given gas in coexistence. We simply don’t know. Any mixture of densities in this region is possible.\nAnother relic of the Maxwell construction evidently is that the coexistence line extends beyond the non-physical region. While these added regions indeed have positive compressibility, they’re in fact metastable. It’s possible to show their chemical potential is in fact higher than the chemical equilibrium potential, for a given pressure and temperature. However, if we compress the gas very slowly we can coax the system into a metastable state. These states create what’s known as a super-cooled or super-heated liquid. But in these states any small disturbance will cause some amount of the gas to condense into the liquid, or vice versa.\n\n\nClausius-Clapyron Equation\nWe can also investigate the behavior of the coexistence region in the phase diagram. In the phase diagram, coexistence occurs along the sharp curve separating the gas and liquid phases. Along this curve the gas must again be in chemical equilibrium. We can use this condition to figure out the functional forms of these curves.\nRecall by extensivity the chemical potential is just the Gibbs free energy per particle, i.e. \\(G = \\mu N\\). In each phase we must have \\[\ndG = -SdT + VdP.\n\\] Dividing both sides by \\(N\\) and asserting the chemical equilibrium condition \\(d\\mu_{liq}=d\\mu_{gas}\\), we have \\[\nd\\mu_{liq} = -s_{liq} dT + v_{liq} dP = -s_{gas} dT + v_{gas} dP = d\\mu_{gas},\n\\] where \\(s \\equiv \\frac{S}{N}\\) is the entropy per particle and \\(v \\equiv \\frac{V}{N}\\) is the volume per particle. Rearranging this formula thus says that the slope of the coexistence line in the phase diagram must satisfy \\[\n\\frac{dP}{dT} = \\frac{s_{gas}-s_{liq}}{v_{gas}-v_{liq}} = \\frac{\\Delta s}{\\Delta v}.\n\\] Since the entropy and volume in the gas phase will practically always exceed their values in the liquid phase, we can immediately conclude that the slope of this coexistence curve will generally be positive.\nIt’s more common to write this expression in terms of the specific latent heat, defined by \\(L \\equiv T\\Delta s\\). This is the amount of heat released per particle as the gas passes through the phase transition. In this form the formula for the slope of the coexistence line is called the Clausius-Clapyron equation, \\[\n\\boxed{\n\\frac{dP}{dT} = \\frac{L}{T \\Delta v}\n} \\ .\n\\] In principle this can be a difficult formula to solve since we need to calculate the entropy of both phases. We can often make some simplifying assumptions though. For example, it’s often the case that \\(L\\) is roughly constant and \\(v_{gas} \\gg v_{liq}\\). If we further assume the ideal gas law is approximately valid, we can write \\(v_{gas} \\approx \\frac{k_B T}{P}\\). Together, these imply \\[\n\\frac{dP}{dT} \\approx \\frac{LP}{k_B T^2} \\qquad \\Longrightarrow \\qquad P(T) \\approx P_0 \\exp\\bigg[-\\frac{L}{k_B} \\bigg(\\frac{1}{T}-\\frac{1}{T_0}\\bigg)\\bigg] \\ .\n\\] Such a curve has the interesting behavior of being convex near \\(T \\approx T_0\\) before eventually turning over like \\(P \\sim -\\frac{1}{T}\\). Typically \\(T_0\\) is some reference temperature like the triple point of the gas. Of course, the curve completely stops at the critical temperature \\(T_c\\) anyway, so the high-temperature behavior of the curve is often unimportant.\n\n\n\n\n\nNote that this formula can also be used just as well for gas-solid phase transitions, except with \\(L\\) taking on a different value due to the different type of chemical equilibrium in that case. The solid-liquid transition is a different story. There we can’t use these approximations at all. These coexistence curves can take on very different shapes. For example, the coexistence curve between water and ice is negatively-sloped. This means ice is less dense than water, which is why ice floats on water.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Classical Gases</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/classical-gases.html#mean-field-condensation",
    "href": "statistical-mechanics/classical-gases.html#mean-field-condensation",
    "title": "Classical Gases",
    "section": "Mean Field Condensation",
    "text": "Mean Field Condensation\nWhile the Maxwell construction can be practically useful, from a theoretical perspective we’d like an approach that doesn’t require merely ad hoc fixing van der Waals equation to work in the coexistence region. Let’s step back and see if we can look at subcritical behavior from a more fundamental perspective.\n\nUniform Density Approximation\nConsider again the hard sphere gas of \\(N\\) particles in a container of volume \\(V\\), except we’ll allow for a general potential energy \\(U\\). Recall with the hard sphere gas each particle is allowed to occupy some finite volume \\(\\omega\\) of radius \\(r_0\\). The full Hamiltonian is \\[\nH = \\sum_{i=1}^N \\frac{\\mathbf{p}_i^2}{2m} + U(\\mathbf{x}_1, \\cdots, \\mathbf{x}_N).\n\\] Now, suppose \\(U\\) can be broken up into two components: One component to deal with the hard sphere gas potential, and the other to deal with all possible pairwise interactions \\(u(|\\mathbf{x}_i-\\mathbf{x}_j|)\\). Through some clever notation, we can write \\(U\\) as \\[\nU = \\sum_{i&lt;j} u(|\\mathbf{x}_i-\\mathbf{x}_j|) = \\frac{1}{2} \\int d^3\\mathbf{x} \\ d^3\\mathbf{x}' \\ n(\\mathbf{x}) n(\\mathbf{x}') u(|\\mathbf{x}-\\mathbf{x}'|),\n\\] where each \\(n(\\mathbf{x})\\) is the density of the count of the number of particles \\(N(\\mathbf{x})\\) that appear at the point \\(\\mathbf{x}\\). That is, \\[\nn(\\mathbf{x}) \\equiv \\bigg | \\frac{dN(\\mathbf{x})}{d\\mathbf{x}} \\bigg | = \\sum_{i=1}^N \\delta(\\mathbf{x}-\\mathbf{x}_i) \\ .\n\\] Notice now what we’re doing is looking at the potential not in terms of each particle, but instead in terms of each point in the container. We’re essentially asking, for each point, is there a particle there that contributes to the potential. This different way of viewing the problem will allow us to do the following clever approximation, often called a mean field approximation.\nSuppose that each point in the container contains on average the same density of particles \\(\\overline n\\). That is, the gas uniformly fills the container with constant number density \\(\\overline n = \\frac{N}{V}\\). Using this fact, we can replace each \\(n\\) with \\(\\overline n\\) in the integral. Using this plus the usual trick of expressing pairs of coordinates in center of mass and relative coordinates, we can write \\[\nU = \\frac{\\overline n^2}{2} \\int d^3\\mathbf{x} \\ d^3\\mathbf{x}' \\ u(|\\mathbf{x}-\\mathbf{x}'|) = \\frac{\\overline n^2 V}{2} \\int_{r_0}^\\infty 4\\pi r^2 dr \\ u(r) \\ .\n\\] Notice the integral over \\(r\\) doesn’t depend on which particles we’re talking about. For a short-range potential like the van der Waals interaction, we can assume it converges to some finite positive area \\(-a\\) and just write \\[\nU = -\\frac{\\overline n^2 V a}{2} = -\\frac{\\overline N^2 a}{2V}.\n\\] Let’s now plug all of this into the canonical partition function. Since \\(U\\) is constant, we can pull it outside the integral to get \\[\n\\begin{align*}\nZ &= \\frac{1}{N! h^{3N}} \\int d^{3N} \\mathbf{x} \\ d^{3N} \\mathbf{p} \\ e^{-\\beta H} \\\\\n&= \\frac{1}{N! \\lambda^{3N}} \\int_\\text{Hard Sphere} d^{3N} \\mathbf{x} \\ e^{-\\beta U} \\\\\n&= \\frac{1}{N! \\lambda^{3N}} \\exp\\bigg(-\\frac{\\beta N^2 a}{2V}\\bigg) \\int_\\text{Hard Sphere} d^{3N} \\mathbf{x} \\ .\n\\end{align*}\n\\] Note we can’t just assume the spatial integral integrates to \\(V^N\\) anymore since we’re dealing with a hard sphere gas. Recall for the hard sphere gas that this integral turns out to be not the full volume \\(V^N\\), but the reduced volume \\(\\big(V-\\frac{N\\omega}{2}\\big)^N\\). Defining again the reduced volume per particle to be \\(b \\equiv \\frac{\\omega}{2}\\), we finally have \\[\nZ = \\frac{(V-Nb)^N}{N! \\lambda^{3N}} \\exp\\bigg(-\\frac{\\beta N^2 a}{2V}\\bigg).\n\\] If we take the logarithm of \\(Z\\) we can again find the pressure. We again get the familiar van der Waals equation, except this time without having to do a virial expansion, \\[\n\\bigg(P + a\\frac{N^2}{V^2}\\bigg)(V-Nb) = Nk_B T \\ .\n\\] What’s interesting about this is we’ve made the assumptions needed to derive the van der Waals equation fully transparent. It’s the equation of state arising for a hard sphere gas assuming it uniformly fills its container. The latter assumption explains why the van der Waals equation is problematic for explaining gases in the coexistence region. In coexistence, a gas exists simultaneously in two phases, the gas phase and the liquid phase. This necessarily means the gas can’t be uniformly dense, for if it were it would be all gas or all liquid, not both.\n\n\nIsobaric Perspective\nIf we want to understand the behavior of a gas in coexistence, it’s important that we allow the density to vary. Perhaps the easiest way to do this is to use the same mean field approximation, but to work in a different ensemble. We want to be in an ensemble that allows us to vary the density \\(n\\). One way to do that is to vary the volume while keeping the pressure fixed. The Gibbs or isobaric ensemble is the natural ensemble for this purpose. Recall we can write the Gibbs partition function \\(Z_G\\) as \\[\nZ_G(T,P,N) = \\int_0^\\infty dV \\ e^{-\\beta PV} Z(T,V,N) \\ .\n\\] Physically, working in the isobaric ensemble is equivalent to placing a piston at the top of the container and applying some external \\(P\\). For the pressure to equilibrate, the density must be uniform inside the container. This means such a system cannot tolerate coexistence. It will choose whether to be in the liquid phase or the gas phase depending on \\(P\\).\nTrying to perform the integration for \\(Z_G\\) is pretty hopeless, but fortunately we don’t need to. We’re just trying to understand the behavior of a gas in coexistence. To that end, define \\(\\psi(V)\\) to be the logarithm of the integrand, \\[\n\\psi(V) \\equiv -\\beta PV + \\log Z .\n\\] Since \\(V\\) is extensive, we can employ the saddlepoint approximation and approximate the integral as the integrand around the global maximum volume \\(V^*\\) to get \\(Z_G \\approx e^{-\\psi(V^*)}\\). To find \\(V^*\\) we again imply the usual trick of setting the derivative of \\(\\psi\\) to zero, \\[\n\\frac{d\\psi}{dV} = -\\beta P + \\frac{\\partial \\log Z}{\\partial V} \\bigg |_{V=V^*} = 0 \\ .\n\\] Now, notice that \\(\\frac{\\partial \\log Z}{\\partial V} = \\beta P_{\\text{vdW}}\\), where \\(P_{\\text{vdW}}\\) is the pressure from the van der Waals equation. Evidently then, the integrand is maximized when the pressure on the gas equals its van der Waals pressure at \\(V^*\\), i.e. when \\(P = P_{\\text{vdW}}(V^*)\\).\nSo what is this saying exactly? Remember that the external pressure \\(P\\) is fixed. It’s being applied on the system. This corresponds to picking a horizontal line on the \\(PV\\) diagram, intersecting it with the van der Waals isotherm at temperature \\(T\\), and reading off the volume where the two curves intersect as \\(V=V^*\\). As long as \\(V_{\\text{vdW}}(P)\\) is single-valued this is fine since the curves will intersect at exactly one volume (and hence exactly one density since \\(N\\) is fixed).\nBut inside the coexistence region something different happens. In that case \\(V^* = V_{\\text{vdW}}(P)\\) will be multi-valued. It will in fact return three possible extrema that intersect the line of constant \\(P\\). Of course, one of these extrema will be non-physical as we saw with the Maxwell construction, meaning we’re left with only two possible extrema intersecting the isotherm on the left and right ends. Call the volumes at these extrema \\(V_{liq}\\) and \\(V_{gas}\\). Since \\(N\\) is fixed, these will also correspond to two densities \\(n_{liq}\\) and \\(n_{gas}\\). That is, at such a pressure \\(P\\), we have coexistence of the two phases.\nIt’s helpful to look at the situation graphically. Suppose we plot \\(Z_G \\approx e^{\\psi(V)}\\) as a function of \\(V\\) for a given pressure \\(P\\). Suppose we’re below the critical temperature so phase transitions can occur. If \\(P \\gg P_c\\) then \\(Z_G\\) will peak at a unique volume \\(V^* \\sim Nb\\). That is, we’re uniquely in the liquid phase. If \\(P \\ll P_c\\) then \\(Z_G\\) will peak at a different volume \\(V^* \\gg Nb\\). That is, we’re uniquely in the gas phase. When \\(P \\sim P_c\\) we’re in the multi-valued situation, where \\(Z_G\\) will peak at two extrema according to something like \\[\nZ_G \\sim e^{\\psi(V_{liq})} + e^{\\psi(V_{gas})} \\ .\n\\] Typically one of these peaks will be exponentially larger than the other for a given pressure, but as the pressure changes the two peaks may flip, corresponding to a phase transition. What about the third extremum? In fact it’s a minimum on the \\(Z_G\\) curve, which is why we can think of it as a non-physical (i.e. highly improbable) state.\n\n\n\n\n\nNote that by extensivity we can also write \\(Z_G \\approx e^{-\\beta \\mu N}\\). This means that maximizing \\(Z_G\\) is equivalent to minimizing the chemical potential \\(\\mu\\). This is in a sense the statistical justification behind the Maxwell construction, which we got by picking the part of the integration path of \\(\\mu(P,T)\\) with the lowest chemical potential.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Classical Gases</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/classical-gases.html#ising-model",
    "href": "statistical-mechanics/classical-gases.html#ising-model",
    "title": "Classical Gases",
    "section": "Ising Model",
    "text": "Ising Model\nWe can look at phase transitions yet another way using a very different type of model, the Ising model. Ising models were originally created to understand the phase transitions in ferromagnets, where an external magnetic field can flip the spins of particles inside the magnet, causing it to change its polarization. It turns out, though, that such simplified models can be used to understand many other types of phase transitions as well. We’ll focus on an Ising model for the liquid-gas transition here.\n\nModel\nSuppose we again have \\(N\\) particles that for simplicity are laid out in a \\(d\\)-dimensional grid. Of course, in the real world \\(d=3\\) and particles need not be locked into a grid, but we’ll be general for now. We’ll suppose each particle can only interact with its nearest neighbors. It’s not hard to show by induction that a particle in \\(d\\) dimensions has exactly \\(2d\\) neighbors, assuming diagonals are excluded. We’ll assume a Hamiltonian of the form \\[\nH = -J \\sum_{\\langle i,j \\rangle} \\sigma_i \\sigma_j - h \\sum_{i=1}^N \\sigma_i.\n\\] Here the symbol \\(\\langle i,j \\rangle\\) means to sum over all \\(i,j\\) nearest neighbor pairs. Each \\(\\sigma_i=-1,1\\) is a binary value representing whether particle \\(i\\) is in its gas state (\\(\\sigma_i=1\\)) or liquid state (\\(\\sigma_i=-1\\)). We’ll call these states spins for historical reasons. The parameter \\(J\\) is a measure of the strength of interaction between nearest neighbor pairs. We’ll assume each pair has the same interaction strength. Last, the parameter \\(h\\) is some sort of external field we imagine being allowed to vary. For ferromagnets, \\(h\\) would represent an applied external magnetic field. For gases, \\(h\\) would typically represent the chemical potential of the gas relative to its equilibrium chemical potential.\nGiven this Hamiltonian, we can again find its partition function and study its thermodynamic behavior. Since this is a discrete system the integral over phase space gets replaced by a sum over all possible states, which in this case are all possible configurations of \\(\\sigma_1, \\cdots, \\sigma_N\\). Working in the canonical ensemble and assuming particles are identical, we have \\[\nZ = \\frac{1}{N!} \\sum_{\\{\\sigma_i\\}} \\exp\\bigg[-\\beta\\bigg(-J \\sum_{\\langle i,j \\rangle} \\sigma_i \\sigma_j - h \\sum_{i=1}^N \\sigma_i\\bigg)\\bigg] \\ .\n\\]\n\n\nMean Field Approximation\nTrying to sum over all nearest-neighbor pairs is highly non-trivial. To proceed we’ll again invoke the mean field approximation. Provided \\(d\\) is sufficiently large (more on this soon), it’s reasonable to assume the spin each particle feels from one of its neighbors is roughly the average spin it feels from all its neighbors. We’ll denote the average spin by \\(m \\equiv \\frac{1}{N} \\sum_i \\langle \\sigma \\rangle\\), called the magnetization for historical purposes. Then we can re-write each pair as \\[\n\\sigma_i \\sigma_j = (\\sigma_i-m)(\\sigma_j-m) + m(\\sigma_i + \\sigma_j) - m^2 \\ .\n\\] If we assume each \\(\\sigma_i \\approx m\\) then each \\((\\sigma_i-m)\\) will be small. Since the first term above is second-order small we’ll neglect it, \\[\n\\sigma_i \\sigma_j \\approx m(\\sigma_i + \\sigma_j) - m^2 \\ .\n\\] With this approximation we can replace each \\(\\sum_{\\langle i,j \\rangle}\\) with \\(\\frac{2d}{2} \\sum_i\\) and simplify the Hamiltonian to get \\[\n\\begin{align*}\nH &= -J \\sum_{\\langle i,j \\rangle} \\big(m(\\sigma_i + \\sigma_j) - m^2\\big) - h \\sum_{i=1}^N \\sigma_i \\\\\n&= dJNm^2 - (2dJm + h) \\sum_{i=1}^N \\sigma_i \\ .\n\\end{align*}\n\\] The partition function can then be factored as a product of single-particle partition functions and simplified as \\[\n\\begin{align*}\nZ &= \\frac{1}{N!} \\sum_{\\{\\sigma_i\\}} \\exp\\bigg[-\\beta\\bigg(dJNm^2 - (2dJm + h) \\sum_{i=1}^N \\sigma_i \\bigg)\\bigg] \\\\\n&= \\frac{1}{N!} e^{-\\beta dJNm^2}\\bigg(\\sum_{\\sigma=\\pm 1} e^{\\beta(2dJm + h)\\sigma} \\bigg)^N \\\\\n&= \\frac{1}{N!} e^{-\\beta dJNm^2} \\bigg(e^{\\beta(2dJm + h)} + e^{-\\beta(2dJm + h)} \\bigg)^N \\\\\n&= \\frac{1}{N!} e^{-\\beta dJNm^2} \\cosh^N\\big(2dJm\\beta + h\\beta\\big) \\ .\n\\end{align*}\n\\] Of course, we still don’t know \\(m\\). To get \\(m\\) we need to impose the self consistency constraint that it equals the magnetization, \\[\nm = \\frac{1}{N} \\sum_{i=1}^N \\langle \\sigma \\rangle = \\frac{1}{N\\beta} \\frac{\\partial \\log Z}{\\partial h}.\n\\] Working out the math and simplifying, we get an equation of the form \\[\nm = \\tanh(2dJm\\beta + h\\beta) \\ .\n\\]\n\n\nGraphical Analysis\nThere’s no way to exactly solve this equation, but we don’t need to. We just want to understand the behavior of phase transitions. To do that we’ll resort to graphical methods. Let’s change variables by defining \\(x \\equiv \\frac{k_B T}{2dJ}m\\). Then we get \\[\n\\frac{k_B T}{2dJ} x = \\tanh\\bigg(x + \\frac{h}{k_B T}\\bigg).\n\\] Let’s start with the simplest case where there’s no external field, so \\(h=0\\). In this case we seek the points of intersection between the line \\(y=\\frac{k_B T}{2dJ}x\\) and the curve \\(y=\\tanh(x)\\). The \\(\\tanh\\) function looks like a sigmoid function. Near the origin it’s basically linear, with \\(\\tanh x \\approx x\\). As \\(x\\) gets larger the function turns over and asymptotes to \\(\\tanh x \\approx \\pm 1\\) depending on the sign. This means that the slope of the line determines how many points of intersection there are. How many points there are depend on how \\(T\\) compares to the critical temperature \\(T_c \\equiv \\frac{2dJ}{k_B}\\). As with the van der Waals equation there are three different possibilities:\n\nWhen \\(T &gt; T_c\\) the two curves intersect only at the origin. This corresponds to \\(m=0\\). The temperature is high enough in this case that the magnetization \\(m\\) is completely randomized. The entropy associated with the random temperature fluctuations wins over the energetically preferred state in which the spins align. This is analogous to the supercritical isotherms we saw.\nWhen \\(T &lt; T_c\\) the two curves still intersect at \\(m=0\\), except now they intersect at two other symmetric points \\(m = \\pm m_0\\). The solution at the origin turns out to be unstable, leaving only the two points \\(\\pm m_0\\). Here we see the effects of the interactions between the spins begin to win over temperature. As \\(T \\rightarrow 0\\) it seems \\(m_0 \\approx \\pm 1\\). That is, at zero temperature all the spins are aligned in the same direction, either all up or all down. This is analogous to the subcritical isotherms we saw.\nWhen \\(T = T_c\\) the two curves are basically the exact same line near the origin, but not exactly due to second order error. This means the curves only intersect at \\(m=0\\), but if \\(T\\) decreases any infinitesimal amount the two other solutions will appear. This is analogous to the critical isotherm we saw.\n\n\n\n\n\n\nThe results described above are perhaps rather surprising. Based on the intuition that things in physics always happen smoothly, one might have thought that \\(m\\) would decrease slowly to zero as \\(T \\rightarrow \\infty\\). But that’s not what happens. Instead \\(m\\) turns off abruptly at some finite temperature \\(T_c\\). This is the characteristic behavior of a phase transition. Because it arises from the first derivative of the free energy it’s by convention called a first-order phase transition. This contrasts with higher-order phase transitions, which arise from discontinuities in higher derivatives of the free energy.\nWhat happens now if we turn on an external field, allowing \\(h \\neq 0\\)? If we look at the above equation, we can see that the presence of \\(h\\) seems to shift the zero point of the \\(\\tanh\\) function left or right depending on the sign of \\(h\\). Meanwhile the left-hand line doesn’t shift at all. What does this do to the system? It breaks the symmetry. For any \\(T &lt; \\infty\\) it’s impossible to get \\(m=0\\). Moreover, since the shift \\(\\frac{h}{k_B T} \\rightarrow 0\\) as \\(T \\rightarrow \\infty\\), \\(m\\) will now go smoothly to zero, meaning there is no longer a phase transition. In fact, it’s possible to show that when \\(T &lt; T_c\\) only one of the intersection endpoints will be stable, which means the spins will always prefer one state over the other. This sort of phenomenon is called spontaneous symmetry breaking. Even the slightest stray external field is enough to ruin the ability of a phase transition to occur.\n\n\n\n\n\nIt’s worth mentioning that strictly speaking the mean field approximation only holds as \\(d \\rightarrow \\infty\\) due to the law of large numbers. In fact, the mean field approximation doesn’t work at all when \\(d=1\\). It can even be shown that phase transitions cannot exist in one-dimension. Yet, for \\(d \\geq 2\\) it’s perhaps surprising that the approximation is okay, at least qualitatively. Even by \\(d=2\\) and \\(d=3\\) phase transitions already start to occur in the Ising model. Proving phase transitions indeed occur in these lower dimensions is somewhat more difficult and beyond the scope of this lesson.\n\n\nGases\nWe can use the Ising model to study the liquid-gas phase transitions. In this case case, we just think of spin as representing whether a given spot on the lattice is occupied. A given spot \\(i\\) is occupied if \\(\\sigma_i=1\\) and not occupied if \\(\\sigma_i=-1\\). The external field \\(h\\) corresponds to the chemical potential \\(\\mu\\). In fact it’s the chemical potential relative to chemical equilibrium, i.e. \\(h=\\mu-\\mu_{eq}\\).\nFor gases it’s more insightful to re-write spins in terms of particle densities. We can transform the spins \\(\\sigma\\) to densities \\(n\\) via the formula \\(\\sigma = 2n-1\\). This ensures \\(n=0,1\\) corresponds to \\(\\sigma = -1,+1\\). In terms of densities the Hamiltonian becomes \\[\nH = -4J \\sum_{\\langle i,j \\rangle} n_i n_j - (\\mu-\\mu_{eq}) \\sum_{i=1}^N n_i \\ .\n\\] It’s not hard to show that the density equivalent of magnetization, call it \\(\\nu\\), is related to \\(m\\) by \\(m = 2\\nu - 1\\). This means the qualitative behavior of the liquid-gas phase transition is the same in this model except with the values shifted and rescaled. For example, the \\(\\tanh\\) function becomes instead a sigmoid function scaled between \\(0\\) and \\(1\\). When \\(\\mu=\\mu_{eq}\\) the gas is at chemical equilibrium, which is precisely when phase transitions can occur. As \\(\\mu\\) deviates ever so slightly from \\(\\mu_{eq}\\) the phase transition phenomenon disappears, with the gas staying in either its gas or liquid phase depending on the sign of \\(\\mu-\\mu_{eq}\\).",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Classical Gases</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/classical-gases.html#critical-behavior",
    "href": "statistical-mechanics/classical-gases.html#critical-behavior",
    "title": "Classical Gases",
    "section": "Critical Behavior",
    "text": "Critical Behavior\nWe’ll close this chapter by briefly studying the behavior of systems near the critical point. It turns out that the behavior of gases near the critical point is in some sense universal, in that certain quantities are the same no matter which gas is studied.\n\nCorresponding States\nLet’s go back to the van der Waals equation. Recall the critical points are given by the following equations, \\[\nk_B T_c = \\frac{8a}{27b} , \\qquad v_c = 3b , \\qquad P_c = \\frac{a}{27b^2} \\ .\n\\]\nHere we’ve expressed things in terms of the volume per particle \\(v \\equiv \\frac{V}{N}\\) to keep everything intensive. We’ll re-express the van der Waals equation in dimensionless form by defining \\[\n\\tilde P \\equiv \\frac{P}{P_c}, \\qquad \\tilde T \\equiv \\frac{T}{T_c}, \\qquad \\tilde v \\equiv \\frac{v}{v_c} \\ .\n\\] With these variables we can write the equation in a universal form that doesn’t depend on which gas we’re talking about. It’s sometimes called the law of corresponding states, given by \\[\n\\tilde P = \\frac{8}{3} \\frac{\\tilde T}{\\tilde v - \\frac{1}{3}} - \\frac{3}{\\tilde v^2} \\ .\n\\] First, notice the quantity \\[\n\\frac{P_c v_c}{k_B T_c} = \\frac{8}{3} = 0.375\n\\] doesn’t depend on \\(a\\) or \\(b\\). It seems to be some kind of universal constant for all gases, at least to the extent the above equation is correct. In fact this ratio isn’t right for real gases. It’s slightly too high. Real values tend to be in the range of \\(0.25\\) to \\(0.3\\). Given that the van der Waals equation is only accurate for fairly dilute gases this discrepancy shouldn’t be that surprising.\n\n\nCritical Exponents\nWe’ll look briefly at the behavior of three different quantities to get an idea how a gas behaves near the critical point:\n\nThe behavior of pressure as a function of volume.\nThe behavior of the coexistence volume difference as a function of temperature.\nThe behavior of the compressibility as a function of temperature.\n\nFirst, let’s get an idea how the pressure depends on volume near the critical point. Recall that thermodynamic stability requires that the pressure \\(P(V)\\) along the critical isotherm has no first or second order volume dependence, meaning \\(P(v) = O(v^3)\\). It’s worth asking if pressure in fact has a third order dependence rather than a fifth or odd higher order dependence. At least according to the van der Waals equation there does indeed seems to be a third order dependence. Near the critical point we can Taylor expand the equation and write \\[\nP-P_c \\sim (v-v_c)^3 \\ .\n\\] What’s important here is the prediction that pressure depends on volume to the third power near the critical point. Again, it’s fair to ask if this is exactly true for real gases, and again it turns out the answer is not quite. The true relationship is more like \\(P-P_c \\sim (v-v_c)^{\\delta}\\) where \\(\\delta \\approx 4.8\\). That is, the real critical isotherm is almost a quintic near the critical point, not a cubic.\nSecond, let’s look at how the volume difference \\(\\delta v = v_{gas}-v_{liq}\\) depends on the temperature near the critical point. We expect \\(\\delta v\\) to shrink to zero as \\(T\\) approaches \\(T_c\\), since that must happen for the coexistence behavior to cease. But how fast does it shrink? When \\(T &lt; T_c\\) the van der Waals equation must have two stable solutions to \\(P(v)\\), one with \\(v_{liq}\\) and the other with \\(v_{gas}\\). In dimensionless form, this means \\[\n\\tilde P = \\frac{8}{3} \\frac{\\tilde T}{\\tilde v_{liq} - \\frac{1}{3}} - \\frac{3}{\\tilde v_{liq}^2} = \\frac{8}{3} \\frac{\\tilde T}{\\tilde v_{gas} - \\frac{1}{3}} - \\frac{3}{\\tilde v_{gas}^2} \\ .\n\\] Solving the equation for \\(\\tilde T\\) and Taylor expanding in terms of \\(\\delta v\\), we can then write \\[\n\\tilde T = \\frac{(3v_{liq}-1)(3v_{gas}-1)(v_{liq} + v_{gas})}{8v_{liq}^2 v_{gas}^2} \\approx 1 - \\frac{1}{16} \\delta v^2 + \\cdots \\ .\n\\] Evidently then the temperature near the critical point goes like the velocity difference squared, or inverting, \\[\n\\delta v \\sim (T-T_c)^{1/2} \\ .\n\\] This dependence doesn’t depend on the type of gas under consideration. But is this relationship exact for real gases? Again, not quite. Experimentally, it turns out that \\(\\delta v \\sim (T-T_c)^{\\beta}\\) where \\(\\beta \\approx 0.32\\).\nThird, let’s ask how the compressibility \\(\\kappa\\) depends on the temperature near the critical point. We can express \\(\\kappa\\) as \\[\n\\kappa = -\\frac{1}{v} \\frac{\\partial v}{\\partial P} \\bigg |_T \\ .\n\\] As \\(T \\rightarrow T_c\\) we must have that \\(\\frac{\\partial P}{\\partial v} \\rightarrow 0\\) to be at the critical point. We’d thus expect that the compressibility of a gas diverges at the critical point. Applying the smallest amount of pressure should change the volume a huge amount as the gas undergoes a phase transition. If we expand \\(\\frac{\\partial P}{\\partial v}\\) in powers of \\(T-T_c\\) we expect to get \\[\n\\frac{\\partial P}{\\partial v} = -a(T-T_c) + \\cdots \\ .\n\\] Inverting this equation when \\(T \\approx T_c\\), this then says \\[\n\\kappa \\sim (T-T_c)^{-1} \\ .\n\\] Again, this dependence is apparently independent of the gas. And again, it’s fair to ask if this dependence is truly correct for real gases. As we’d expect by now, it’s not exactly correct. The true relationship is \\(\\kappa \\sim (T-T_c)^{-\\gamma}\\) where \\(\\gamma \\approx 1.2\\).\nThese interesting exponent relationships seem to apply to all gases, at least near the critical point. The exponents themselves are called critical exponents. They’re universal. In fact, they apply to even more than gases. The results obtained even apply to the Ising Model when \\(d=3\\). In that case we’d just replace the volume \\(v\\) with the magnetization \\(m\\), the pressure \\(P\\) with the external field \\(h\\), and the compressibility \\(\\kappa\\) with the susceptibility \\(\\chi \\equiv N\\frac{\\partial m}{\\partial h} \\big |_T\\). All of the previous results can be obtained in an analogous manner to give the critical relations \\[\nh \\sim m^3, \\qquad m_0 \\sim \\pm (T-T_c)^{1/2}, \\qquad \\chi \\sim (T-T_c)^{-1} \\ .\n\\] But why aren’t these results exact? After all the real critical exponents are slightly off in all cases. Fundamentally, the issue is that we’re trying to do an analytic expansion of an equation of state about the critical point. But we can’t really do that since there’s a discontinuity at the critical point, which is why we even get phase transitions at all. To get more accurate estimates of the critical exponents we should approach the problem in a very differently, using more advanced techniques like group renormalization. This gets into the more modern topic of critical phenomena, something we’ll see more in a future lesson.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Classical Gases</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/quantum-stat-mech.html",
    "href": "statistical-mechanics/quantum-stat-mech.html",
    "title": "Quantum Statistical Mechanics",
    "section": "",
    "text": "Quantum Mechanics\nLet’s briefly recall how we initiated the theory of classical statistical mechanics. We started by supposing a system had some huge number of microstates \\(\\mu = \\{\\mathbf{x}_i, \\mathbf{p}_i\\}\\). We then wanted to figure out how many of these microstates corresponded to any one individual macrostate \\(M=(E,X,N)\\). This led us to a definition of the of the equilibrium probability density as the phase space density under the macroscopic constraints. From this we were then able to specify the various statistical ensembles and derive the laws of thermodynamics.\nWe can do something similar in the quantum version, except we need to rethink what exactly it is we mean by a microstate. In classical mechanics we define a state as a point \\((\\mathbf{x},\\mathbf{p})\\) in the phase space. In quantum mechanics, however, we have to contend with the uncertainty principle, which forbids knowing both \\(\\mathbf{x}\\) and \\(\\mathbf{p}\\) simultaneously too precisely. More correctly, for each component we have the uncertainty relation \\[\n\\Delta x_i \\Delta p_j \\geq \\frac{\\hbar}{2} \\delta_{ij} \\ ,\n\\] where \\(\\hbar \\approx 10^{-34} \\text{ J s}\\) is the reduced Planck constant. This really tiny number limits how closely we can resolve points in phase space, since we’re disallowed by the uncertainty principle from localizing points at finer scales than \\(\\hbar\\). We can really only imagine defining smooth functions on phase space at scales much larger than \\(\\hbar\\). Below that we have to transition to quantum mechanics.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Quantum Statistical Mechanics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/quantum-stat-mech.html#quantum-mechanics",
    "href": "statistical-mechanics/quantum-stat-mech.html#quantum-mechanics",
    "title": "Quantum Statistical Mechanics",
    "section": "",
    "text": "Quantum Microstates\nIn quantum mechanics, a microstate \\(\\mu\\) is specified by an abstract ket vector \\(| \\psi\\rangle\\) that lives in a complex Hilbert space which can be of any dimension, finite or infinite. We assume all the rules of the linear algebra for complex vectors applies to Hilbert spaces. For example, we assume we can decompose any ket in the Hilbert space into a linear combination of basis kets, e.g. \\[\n|\\psi\\rangle = \\sum_{n} \\langle n | \\psi\\rangle |n \\rangle \\equiv \\sum_{n} \\psi_n |n \\rangle \\ .\n\\] Here \\(\\psi_n \\equiv \\langle n | \\psi\\rangle\\) is the complex-valued inner product between the kets \\(|n\\rangle\\) and \\(|\\psi \\rangle\\). Notice the ket \\(|n\\rangle\\) gets converted first into a bra vector \\(\\langle n |\\), which can be thought of as the conjugate transpose of the ket \\(|n\\rangle\\). This implies we can write the inner product between any two vectors by applying the bra of one to the ket of the other, \\[\n\\langle \\phi | \\psi \\rangle = \\sum_n \\phi_n^* \\psi_n \\ .\n\\] We typically require that kets in the Hilbert space be normalized, i.e. \\(\\langle \\psi | \\psi \\rangle = 1\\) for any \\(|\\psi \\rangle\\). This means that the length of a vector in quantum mechanics contains no physical information. The reason we normalize them to one is so we can use them to represent probability densities, or amplitudes. This is done using the Born rule, which says that the norm of a vector represents the probability of that state being observed. For example, the inner product \\(|\\psi_n|^2 = \\langle n|\\psi \\rangle^2\\) represents the probability amplitude that \\(|\\psi\\rangle\\) is found exactly in the state \\(|n\\rangle\\). If \\(|n\\rangle\\) represents a state with energy \\(E_n\\), then \\(|\\psi_n|^2\\) represents the probability density of \\(|\\psi\\rangle\\) having energy \\(E_n\\). That is, \\(p_\\psi(E=E_n) = |\\psi_n|^2\\).\nIt’s important to note that this is a fundamentally different kind of probability than that of statistical mechanics. It’s an irreducible probability, not one arising from our ignorance about the system. No matter how much knowledge we have of the system, or how well we can measure it, we still have to contend with these sorts of quantum probabilities.\nIn practice, it’s often useful to think of states using wavefunctions, which are the components \\(\\psi(\\mathbf{x})\\) of kets in the position basis, \\[\n|\\psi \\rangle = \\int d^3 \\mathbf{x} \\ \\langle \\mathbf{x} | \\psi\\rangle |\\mathbf{x} \\rangle \\equiv \\int d^3 \\mathbf{x} \\  \\psi(\\mathbf{x}) |\\mathbf{x} \\rangle \\ .\n\\] By the Born rule, if \\(|\\psi\\rangle\\) represents the state of some particle, we can think of the amplitude \\(|\\psi(\\mathbf{x})|^2\\) as the probability density of observing that particle in space near the point \\(\\mathbf{x}\\). We can imagine wavefunctions in other bases as well. For example, the momentum space wavefunction is defined in a similar way by \\(\\psi(\\mathbf{p}) \\equiv \\langle \\mathbf{p}|\\psi \\rangle\\).\nIn classical mechanics, we can think of observables like energy, momentum, etc. as functions \\(Q(\\mathbf{x},\\mathbf{p})\\) on the phase space. We could then proceed to study the dynamics of those observables by looking at their Poisson bracket with the Hamiltonian, \\[\n\\frac{dQ}{dt} = \\{Q, H\\} \\ .\n\\] By the uncertainty principle this is again disallowed in quantum mechanics. Instead, we think of observables as operators \\(Q\\) that map kets to other kets in the Hilbert space, e.g. \\(Q|\\psi\\rangle = |\\psi\\rangle\\). We also require that observables be Hermitian, meaning \\(Q\\) must equal its conjugate transpose \\(Q^\\dagger\\). This ensures the spectrum of eigenvalues of \\(Q\\) are all real-valued and the eigenvectors are all orthogonal, or can be chosen to be orthogonal.\nIn classical mechanics we can imagine measuring some observable \\(Q\\) to as high a precision as we like by tuning the apparatus to make better and better measurements. In quantum mechanics this is again disallowed by the uncertainty principle. Instead, attempts to measure \\(Q\\) will force it to randomly take on one of a set of fixed values, its spectrum of eigenvalues. Mathematically, if \\(Q\\) is some observable and we attempt to measure it in some state \\(|\\psi\\rangle\\), we imagine measurement as sampling some \\(q\\) from the distribution defined by the density \\(p_\\psi(q)=|\\psi_q|^2\\). This also means we can define an expected value for \\(Q\\) in the usual way, \\[\n\\langle Q \\rangle_\\psi \\equiv \\sum_q q \\ p_\\psi(q) = \\langle \\psi | Q | \\psi \\rangle \\ .\n\\] Notice the probability density and expected value both depend on the state \\(|\\psi\\rangle\\). If the state changes, so will these functions. Again, there is nothing statistical about this probability. Even with a single particle we’d still have to worry about it.\nTo study the dynamics of observables in quantum mechanics we should replace the Poisson bracket with the commutator \\[\n[A,B] \\equiv AB - BA,\n\\] a measure of how much the operators \\(A\\) and \\(B\\) fail to commute with each other. If two observables commute we can in principle measure them simultaneously with no uncertainty. Otherwise they obey an uncertainty principle. For example, we already know the position operator \\(\\mathbf{x}\\) doesn’t commute with the momentum operator \\(\\mathbf{p}\\) since they have an uncertainty principle. In fact, their components satisfy the commutation relation \\[\n[x_i, p_j] = i\\hbar\\delta_{ij} \\ .\n\\] Comparing this with the Poisson bracket relation \\(\\{x_i, p_j\\} = \\delta_{ij}\\) we can establish a crude identification between the two brackets, \\[\n[A,B] \\quad \\longleftrightarrow \\quad -\\frac{i}{\\hbar} \\{A,B\\} \\ .\n\\] This suggests that the time evolution of any observable \\(Q\\) in quantum mechanics is given by \\[\n\\frac{dQ}{dt} = -\\frac{i}{\\hbar} [Q, H] \\ ,\n\\] where the Hamiltonian is now thought of as an operator. This relation is indeed true, at least in the Heisenberg picture of quantum mechanics, where operators are allowed to evolve in time. In the more elementary Schrödinger picture it’s the states that are allowed to evolve, not the operators. In this picture it’s the expectation of the operators that are allowed to time evolve this way. The time evolution of states can be found by using the requirement that the time evolution of kets must be given by a unitary operator \\(U(t) \\equiv e^{-\\frac{i}{\\hbar} Ht}\\), where \\(H\\) is the Hamiltonian, \\[\n|\\psi(t)\\rangle = U(t) |\\psi(0)\\rangle \\ .\n\\] A unitary operator satisfies the condition that \\(U U^\\dagger = 1\\). This implies that unitary operations conserve quantum probabilities, since \\(U|\\psi\\rangle\\) will have the same probability amplitude as \\(|\\psi\\rangle\\). Requiring that time evolution be unitary in this way leads us to the time-dependent Schrödinger equation. If we assume \\(t\\) is infinitesimal we can write \\(U(t) \\approx I - \\frac{i}{\\hbar} Ht\\). Plugging this in and rearranging then gives the more familiar result for the time evolution of states, \\[\nH |\\psi(t)\\rangle = i\\hbar \\frac{\\partial}{\\partial t} |\\psi(t) \\rangle \\ .\n\\] The eigenvalues of the Hamiltonian are the allowed energies the system can take on. If \\(E_n\\) is an eigenvalue of \\(H\\) with eigenvector \\(|n\\rangle\\), we can trivially write \\(H|n\\rangle = E_n |n\\rangle\\). This is often called the time-independent Schrödinger equation.\nAn important set of relationships to be aware of in quantum mechanics is that between position and momentum. We already saw that the position and momentum operators satisfy the commutation relation \\([x_i, p_j] = i\\hbar\\delta_{ij}\\). This means that it’s impossible to simultaneously diagonalize the two operators and get product states like \\(|\\mathbf{x},\\mathbf{p}\\rangle\\). If we could do that we could just use the classical theory of Hamiltonian dynamics. Instead, we have to think about the position basis and momentum basis as being distinct representations. It’s possible to show, however, that the two representations are Fourier transforms of each other, \\[\n|\\mathbf{p} \\rangle = \\int \\frac{d^3 \\mathbf{x}}{(2\\pi\\hbar)^{3/2}} \\ e^{\\frac{i}{\\hbar} \\mathbf{x} \\cdot \\mathbf{p}} |\\mathbf{x}\\rangle \\ .\n\\] This relation essentially encodes the uncertainty principle. For example, if \\(|\\mathbf{x}\\rangle\\) were known exactly in position space, then its wavefunction would be a delta function. But the Fourier transform of a delta function is a constant, which means that in momentum space we’d have to allow for the system to have any possible momentum with equal probability.\nThe Fourier relation above is particularly useful when solving the Schrödinger equation for a free particle. For these kinds of problems it’s more convenient to work rescale units to get rid of factors of \\(\\hbar\\). We can do that by using the DeBroglie relation \\(\\mathbf{p} = \\hbar \\mathbf{k}\\), where \\(\\mathbf{k}\\) is the wavevector defined by \\(|\\mathbf{k}| = \\frac{2\\pi}{\\lambda}\\). Here \\(\\lambda\\) is the wavelength of a wavefunction moving with momentum \\(\\mathbf{p}\\). In this slight rescaling of units the factors of \\(\\hbar\\) disappear and the Fourier transform becomes \\[\n|\\mathbf{k} \\rangle = \\int \\frac{d^3 \\mathbf{x}}{(2\\pi)^{3/2}} \\ e^{i \\mathbf{x} \\cdot \\mathbf{k}} |\\mathbf{x}\\rangle \\ .\n\\] Since we’ll end up using it later, let’s go ahead and work it out the quantum dynamics of the free particle.\n\n\nExample: Free Particle\nConsider a particle moving in free space. We’ve seen many times such a particle has Hamiltonian \\(H = \\frac{\\mathbf{p}^2}{2m}\\), except in this case we should think of \\(H\\) as an operator that depends solely on the momentum operator \\(\\mathbf{p}\\). For convenience we’ll rescale and work in units of the wavevector \\(\\mathbf{k}\\). This means that the eigenvectors of \\(H\\) are also the eigenvectors of \\(\\mathbf{k}\\), hence \\[\nH | \\mathbf{k} \\rangle = E(\\mathbf{k}) | \\mathbf{k} \\rangle = \\frac{\\hbar^2 \\mathbf{k}^2}{2m} |\\mathbf{k} \\rangle \\ .\n\\] We thus have an expression for the energy in terms of the wavevector as \\(E(\\mathbf{k}) = \\frac{\\hbar^2 \\mathbf{k}^2}{2m}\\). Suppose we’re interested in the energy wavefunctions \\(\\psi_\\mathbf{k}(\\mathbf{x}) = \\langle \\mathbf{x} |\\mathbf{k} \\rangle\\) as well. These are just the wavefunctions associated with the Fourier transform for \\(|\\mathbf{k}\\rangle\\), \\[\n\\begin{align*}\n\\psi_\\mathbf{k}(\\mathbf{x}) &= \\langle \\mathbf{x} |\\mathbf{k} \\rangle \\\\\n&= \\int \\frac{d^3 \\mathbf{x}'}{(2\\pi)^{3/2}} \\ e^{i \\mathbf{x}' \\cdot \\mathbf{k}} \\langle \\mathbf{x}|\\mathbf{x}'\\rangle \\\\\n&= \\int \\frac{d^3 \\mathbf{x}'}{(2\\pi)^{3/2}} \\ e^{i \\mathbf{x}' \\cdot \\mathbf{k}} \\delta(\\mathbf{x} - \\mathbf{x}') \\\\\n&= \\frac{1}{(2\\pi)^{3/2}} e^{i \\mathbf{x} \\cdot \\mathbf{k}} \\ .\n\\end{align*}\n\\] Thus, the energy eigenfunctions are just complex plane waves in position space. In fact, they’re plane waves in both position in time, since the time-dependent energy eigenfunctions are just the static wavefunctions multiplied by \\(e^{-i\\omega t}\\) where \\(E=\\hbar \\omega\\), \\[\n\\psi_\\mathbf{k}(\\mathbf{x}, t) = \\frac{1}{(2\\pi)^{3/2}} e^{i (\\mathbf{x} \\cdot \\mathbf{k}-\\omega t)} \\ .\n\\] The true wavefunction \\(\\psi(\\mathbf{x}, t)\\) of the particle can be found by superimposing all the energy eigenfunctions together, \\[\n\\psi(\\mathbf{x},t) = \\langle \\mathbf{x} | \\psi \\rangle\n= \\int d^3 \\mathbf{k} \\langle \\mathbf{x} | \\mathbf{k} \\rangle \\langle \\mathbf{k} | \\psi \\rangle\n= \\int d^3 \\mathbf{k} \\ \\psi_\\mathbf{k}(\\mathbf{x}, t) \\phi(\\mathbf{k}) \\ .\n\\] Here the coefficients \\(\\phi(\\mathbf{k}) = \\langle \\mathbf{k} | \\psi \\rangle\\) are determined by the initial conditions. If the particle is reasonably well localized, \\(\\phi(\\mathbf{k})\\) will tend to have a reasonably narrow peak around some particular \\(\\mathbf{k}\\). This will tend to result in \\(\\psi(\\mathbf{x},t)\\) having a shape where the waves are confined inside of a larger wave packet, whose group velocity is given from the dispersion relation \\(\\omega(\\mathbf{k}) = \\frac{\\hbar \\mathbf{k}^2}{2m}\\) as \\[\n\\mathbf{v}_g \\equiv \\frac{d\\omega}{d\\mathbf{k}} = \\frac{\\hbar \\mathbf{k}}{m} = \\frac{\\mathbf{p}}{m} \\ .\n\\] The group velocity of the wave packet can be thought of as the quantum origin of the velocity of a classical particle, \\(\\mathbf{v} = \\frac{\\mathbf{p}}{m}\\). Note that since \\(\\omega(\\mathbf{k})\\) isn’t linear in \\(\\mathbf{k}\\) the wave will also be dispersive, with a phase velocity \\(v_p \\equiv \\frac{\\omega}{|\\mathbf{k}|}\\) that’s half the group velocity.\n\n\nExample: Particle in a Box\nWhat if now we impose the requirement that the particle be confined to a box of dimensions \\(L_x \\times L_y \\times L_z\\) with volume \\(V\\)? In this case we have to be careful to impose the correct boundary conditions on the wavefunctions. We’ll assume that the wavefunction is periodic at the walls of the box. That is, \\[\n\\begin{align*}\n\\psi(x,y,z,t) &= \\psi(x+L_x,y,z,t), \\\\\n\\quad \\psi(x,y,z,t) &= \\psi(x,y+L_y,z,t), \\\\\n\\quad \\psi(x,y,z,t) &= \\psi(x,y,z+L_z,t) \\ .\n\\end{align*}\n\\] We should expect the energy eigenfunctions to have the same form as for a free particle, with \\(\\psi_\\mathbf{k}(\\mathbf{x}, t) \\propto e^{i (\\mathbf{x} \\cdot \\mathbf{k}-\\omega t)}\\), except that now the boundary conditions will impose constraints on the wavevector \\(\\mathbf{k}\\). Periodicity of the boundary conditions require \\[\nA e^{i (xk_x + yk_y + zk_z-\\omega t)} = A e^{i \\big((x+L_x)k_x + yk_y + zk_z-\\omega t\\big)} \\quad \\Longrightarrow \\quad e^{ik_x L_x} = 1 \\ ,\n\\] and similarly for the \\(y\\) and \\(z\\) components. This condition requires that each component of \\(\\mathbf{k}\\) be discrete, with \\[\nk_x = \\frac{2\\pi n_x}{L_x}, \\quad k_y = \\frac{2\\pi n_y}{L_y}, \\quad k_z = \\frac{2\\pi n_z}{L_z} \\ ,\n\\] where each of \\(n_x, n_y, n_z\\) are independent positive integers. This also forces the energy eigenvalues to be discrete, with \\[\nE_\\mathbf{n} = \\frac{\\hbar^2}{2m} \\bigg(\\frac{n_x^2}{L_x^2} + \\frac{n_y^2}{L_y^2} + \\frac{n_y^2}{L_y^2}\\bigg) \\ .\n\\] That is, \\(H|\\mathbf{n}\\rangle = E_\\mathbf{n} |\\mathbf{n}\\rangle\\). The energy eigenfunctions can be found by plugging in the expressions for \\(\\mathbf{k}_\\mathbf{n}\\) and renormalizing, \\[\n\\psi_\\mathbf{n}(\\mathbf{x}, t) = \\frac{1}{\\sqrt{V}} e^{i \\big(\\mathbf{k}_\\mathbf{n} \\cdot \\mathbf{x} - \\omega_\\mathbf{n} t\\big)} \\ .\n\\] As we might expect, rather than plane waves in space and time, the bounded solutions represent standing waves inside the box, where each \\(\\mathbf{n}\\) represents some specific configuration of harmonics. The full wavefunction \\(\\psi(\\mathbf{x},t)\\) is again given by a superposition of these standing waves, except this time a discrete sum of them, \\[\n\\psi(\\mathbf{x},t) = \\langle \\mathbf{x} | \\psi \\rangle = \\sum_{\\mathbf{n}} \\langle\\mathbf{n} | \\psi \\rangle \\langle \\mathbf{x} | \\mathbf{n} \\rangle = \\sum_{\\mathbf{n}} c_\\mathbf{n}\\psi_\\mathbf{n}(\\mathbf{x}, t) \\ .\n\\] Here, \\(c_\\mathbf{n} = \\langle \\mathbf{n} | \\psi \\rangle\\) are just the usual complex Fourier series coefficients, which are determined by the initial conditions.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Quantum Statistical Mechanics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/quantum-stat-mech.html#density-operator",
    "href": "statistical-mechanics/quantum-stat-mech.html#density-operator",
    "title": "Quantum Statistical Mechanics",
    "section": "Density Operator",
    "text": "Density Operator\nNow that we’ve reviewed the essentials of quantum mechanics we can proceed to setup the apparatus of quantum statistical mechanics. We’ve setup the framework for thinking of the microstates as kets in a Hilbert space, \\(\\mu = \\{|\\psi\\rangle\\}\\). The macrostates remain the same, \\(M = (E,X,N)\\). We now just need to find a way to connect the two via some sort of probability density. It’s not clear though how to think about what a density is in quantum mechanics. We can’t define a density on phase space since we can’t have diagonalizable functions of both position and momentum.\nTo do that we need to think more carefully about what we mean by a quantum mechanical state. Strictly speaking when we say a state is a ket \\(|\\psi\\rangle\\), what we really mean is that \\(|\\psi\\rangle\\) is the state of the system in the idealized situation where we have exact knowledge of the system. These are called pure states. We can think of pure states not only as kets, but as outer products \\[\n\\rho \\equiv |\\psi\\rangle \\langle \\psi| \\ .\n\\] In this form pure states are no longer kets but operators. When operating on their ket equivalent they give back the ket, \\[\n\\rho |\\psi \\rangle = |\\psi\\rangle \\langle \\psi| \\psi \\rangle = |\\psi \\rangle \\ .\n\\] In practice we usually don’t observe exact knowledge of the system. Instead we have to look at the system as an ensemble of states, e.g. by looking at a large number of particles instead of a single particle. In this situation we have to think of a state as a statistical mixture of pure states, \\[\n\\rho \\equiv \\sum_\\alpha p_\\alpha |\\psi_\\alpha\\rangle \\langle \\psi_\\alpha| \\ .\n\\] Here \\(p_\\alpha\\) is a classical probability weight indicating our lack of knowledge about the system. It’s statistical in nature, not quantum mechanical. States like this are called mixed state, because they’re a statistical mixture of pure states. Unlike pure states, we can’t think of mixed states as a ket in Hilbert space. We have to think of them as operators.\nWhat’s most important for our purposes is the nature of this operator \\(\\rho\\), called the density operator. As the notation and name suggests, this is our likely candidate for the quantum mechanical version of the phase space density. To verify this, we first need to show that \\(\\rho\\) represents the operator equivalent of a probability density. It should be:\n\nPositive semi-definite: That is, \\(\\langle \\psi | \\rho | \\psi \\rangle \\geq 0\\) for any ket \\(|\\psi\\rangle\\). To verify this, observe \\[\n\\langle \\psi | \\rho | \\psi \\rangle = \\sum_\\alpha p_\\alpha \\langle \\psi|\\psi_\\alpha\\rangle \\langle \\psi_\\alpha|\\psi\\rangle = \\sum_\\alpha p_\\alpha |\\langle \\psi|\\psi_\\alpha\\rangle|^2 \\geq 0 \\ .\n\\]\nHermitian: The probability density should be observable, which means \\(\\rho = \\rho^\\dagger\\). This is easy to verify, \\[\n\\rho^\\dagger = \\sum_\\alpha p_\\alpha \\bigg(|\\psi_\\alpha\\rangle \\langle \\psi_\\alpha|\\bigg)^\\dagger = \\sum_\\alpha p_\\alpha |\\psi_\\alpha\\rangle \\langle \\psi_\\alpha| = \\rho \\ .\n\\]\nUnit Trace: That is, \\(\\tr \\rho = 1\\). This is the generalization of probabilities summing to one. To verify we’ll pick a basis and sum, \\[\n\\tr \\rho = \\sum_n \\langle n | \\rho | n \\rangle = \\sum_\\alpha p_\\alpha \\sum_n \\langle n | \\psi_\\alpha \\rangle \\langle \\psi_\\alpha | n \\rangle = \\sum_\\alpha p_\\alpha = 1 \\ .\n\\] Here we used the fact that \\(p_\\alpha\\) is a valid classical probability that sums to one, and that each \\(|\\psi_\\alpha\\rangle\\) must be normalized.\n\nWe’ve thus shown that the density operator is a valid operator generalization of the probability density. Given this fact we can also proceed to define what we mean by an expected value in quantum statistical mechanics. Now we’re taking not just an average, but a classical ensemble average of a quantum average. It’s not hard to show that we can indeed naturally define \\[\n\\langle Q \\rangle \\equiv \\sum_\\alpha p_\\alpha \\langle Q \\rangle_{\\psi_\\alpha} = \\tr \\rho Q \\ .\n\\] We still need to show that it has the same dynamical character as the phase space density. Recall the classical density must satisfy Liouville’s equation \\(\\frac{\\partial\\rho}{\\partial t} = -\\{\\rho, H\\}\\). According to the replacement rules between Poisson brackets and commutators, we should expect something similar here. Using the definition of the density operator and the Schrödinger equation, we have \\[\n\\begin{align*}\n\\frac{\\partial\\rho}{\\partial t} &= \\frac{\\partial}{\\partial t} \\sum_\\alpha p_\\alpha |\\psi_\\alpha\\rangle \\langle \\psi_\\alpha| \\\\\n&= \\sum_\\alpha p_\\alpha \\bigg(|\\psi_\\alpha\\rangle\\frac{\\partial \\langle \\psi_\\alpha|}{\\partial t} + \\frac{\\partial|\\psi_\\alpha\\rangle}{\\partial t}\\langle \\psi_\\alpha|\\bigg) \\\\\n&= \\sum_\\alpha p_\\alpha \\bigg(\\frac{i}{\\hbar}|\\psi_\\alpha\\rangle \\langle \\psi_\\alpha| H - \\frac{i}{\\hbar}H|\\psi_\\alpha\\rangle \\langle \\psi_\\alpha|  \\bigg) \\\\\n&= \\frac{i}{\\hbar} \\bigg[\\bigg(\\sum_\\alpha p_\\alpha |\\psi_\\alpha\\rangle \\langle \\psi_\\alpha| \\bigg) H - H \\bigg(\\sum_\\alpha p_\\alpha |\\psi_\\alpha\\rangle \\langle \\psi_\\alpha| \\bigg)\\bigg] \\\\\n&= \\frac{i}{\\hbar} [\\rho, H] \\ .\n\\end{align*}\n\\] We’ve thus proved the quantum mechanical equivalent of Liouville’s equation, known as the von-Neumann equation, \\[\n\\boxed{\n\\frac{\\partial\\rho}{\\partial t} = \\frac{i}{\\hbar} [\\rho, H]\n} \\ .\n\\]\nFor an ensemble in equilibrium, we require the density be time-independent, i.e. \\[\n\\frac{\\partial\\rho}{\\partial t} = \\frac{i}{\\hbar} [\\rho, H] = 0 \\ .\n\\] This means that in equilibrium \\(\\rho\\) must commute with \\(H\\) and any other conserved quantities that also commute with \\(H\\). In the simplest case where only energy is conserved, this means in equilibrium we must again have \\(\\rho = \\rho(H)\\).",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Quantum Statistical Mechanics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/quantum-stat-mech.html#statistical-mechanics",
    "href": "statistical-mechanics/quantum-stat-mech.html#statistical-mechanics",
    "title": "Quantum Statistical Mechanics",
    "section": "Statistical Mechanics",
    "text": "Statistical Mechanics\nWe can now proceed as usual to define all of the statistical ensembles, except with the caveat that we have to think in terms of operators. We typically think of the density operator as a mixture of energy states, \\[\n\\rho = \\sum_n p_n |n\\rangle \\langle n | \\ .\n\\] This choice of states is convenient because we want \\(\\rho\\) to be time-independent at equilibrium, and we know that in the energy basis the pure states will remain time-independent. To get the probability of the system being in a particular energy eigenstate we just need to pick out one of these elements to get \\[\np_n = \\langle n | \\rho | n \\rangle \\ .\n\\] Since it’s easy, we’ll typically work in this energy basis when solving problems in quantum statistical mechanics.\n\nMicrocanonical Ensemble\nWe started the classical theory by looking at the microcanonical ensemble where \\(M = (E,X,N)\\). In that setting we have \\[\n\\rho = \\frac{\\delta(H-E)}{\\Omega} \\ .\n\\] In the energy basis, this says \\[\np_n = \\langle n|\\rho |n \\rangle = \\frac{1}{\\Omega} \\delta(E-E_n) \\ .\n\\] This is a reflection of the usual assumption of equal a priori probabilities, where each microstate with energy \\(E\\) can occur with the same uniform probability \\(p_n = \\frac{1}{\\Omega}\\). It’s also illuminating to look at the off-diagonal elements of the density operator. Observe \\[\n\\langle m | \\rho | n  \\rangle = \\frac{\\delta(E-E_n)}{\\Omega} \\delta_{mn} \\ .\n\\] These terms are non-zero only when both \\(E=E_n\\) and \\(m=n\\). That is, only the diagonal elements are non-zero. The fact that the off-diagonal elements are zero is often called the assumption of random phases. Essentially, it means the system has had time to fully mix with its environment, leading to quantum decoherence. When a quantum system has fully decohered, its wave packets have become very well localized, its density operator is diagonal, and it becomes well approximated by classical dynamics.\nWe can also find an explicit expression for the multiplicity \\(\\Omega\\) by tracing over \\(\\rho\\) and solving to get \\[\n\\Omega = \\text{tr} \\ \\delta(H-E) = \\sum_n \\delta(E-E_n) \\ .\n\\] This factor again represents the number of microstates with energy \\(E\\). From this expression we can again derive the entropy and write it in the familiar form \\[\nS = -\\sum_n p_n \\log p_n = k_B \\log \\Omega \\ .\n\\] With the entropy in hand we can proceed to derive all the thermodynamic variables of interest as usual. For example, we can find the temperature by solving the equation \\[\n\\frac{1}{T} = \\frac{\\partial S}{\\partial E} \\bigg |_{X,N} \\ .\n\\] Just as in the classical theory, the microcanonical is often not the most convenient ensemble to work with, so we should cover the more convenient ones too.\n\n\nCanonical Ensemble\nWe can similarly look at the canonical ensemble where \\(M=(T,X,N)\\). In that setting we have \\[\n\\rho = \\frac{1}{Z} e^{-\\beta H} \\ ,\n\\] where \\(Z\\) is the quantum canonical partition function. In the energy basis this means the probability of any given eigenstate is \\[\np_n = \\frac{1}{Z} e^{-\\beta E_n} \\ .\n\\] By tracing over \\(\\rho\\) we can express \\(Z\\) using the useful formula \\[\n\\boxed{\nZ = \\text{tr} \\ e^{-\\beta H}\n} \\ .\n\\] In terms of the energy basis this just says \\[\nZ = \\sum_n e^{-\\beta E_n} \\ .\n\\] From the partition function we can again proceed to find all thermodynamic variables of interest. For example, the average energy \\(E\\) of the system is given by \\[\nE = \\langle H \\rangle = \\text{tr} \\ \\rho H = -\\frac{\\partial \\log Z}{\\partial \\beta} \\ .\n\\]\n\n\nHigher Ensembles\nIn a similar fashion of course we can also look at the two higher ensembles. In the Gibbs canonical ensemble we take as macrostates \\(M = (T,J,N)\\). The density operator becomes \\[\n\\rho = \\frac{1}{Z_G} e^{-\\beta (H-J \\cdot X)} \\ ,\n\\] where the Gibbs canonical partition function \\(Z_G\\) is given by \\[\nZ_G = \\int dX \\ \\tr e^{-\\beta (H-J \\cdot X)} = \\int dX \\  e^{\\beta J \\cdot X} Z \\ .\n\\] Notice that while \\(H\\) is thought of as an operator, the displacement \\(X\\) and force \\(J\\) are not. They’re just ordinary vectors. We can find the mean displacement \\(\\langle X \\rangle\\) in the usual way by \\[\n\\langle X \\rangle = \\frac{\\partial \\log Z_G}{\\partial (\\beta J)} \\ .\n\\] Similarly, in the grand canonical ensemble we take as macrostates \\(M=(T,X,\\mu)\\) where \\(\\mu\\) is the chemical potential. Then \\[\n\\rho = \\frac{1}{\\mathcal{Z}} e^{-\\beta (H-\\mu \\cdot N)} \\ ,\n\\] where the Grand canonical partition function \\(\\mathcal{Z}\\) can be found by the formula \\[\n\\mathcal{Z} = \\sum_{N=0}^\\infty \\text{tr} \\ e^{-\\beta (H-\\mu \\cdot N)} = \\sum_{N=0}^\\infty  e^{\\beta \\mu \\cdot N} Z \\ .\n\\] Again, here we should think of \\(\\mu\\) and \\(N\\) as ordinary vectors, not operators. We can find the mean particle number \\(\\langle N \\rangle\\) in the usual way as well by \\[\n\\langle N \\rangle = \\frac{\\partial \\log\\mathcal{Z}}{\\partial (\\beta \\mu)} \\ .\n\\] Both formulations reduce to their obvious form when working in the energy basis.\n\n\nClassical Limit\nIt’s worth briefly mentioning here in what sense classical statistical mechanics is a limit of quantum statistical mechanics. Clearly in the classical world of large energies the laws of classical statistical mechanics are perfectly valid, yet we know that quantum statistical mechanics should be the true theory in all cases. To see how the classical limit arises let’s look at the canonical partition function \\(Z\\) and see how we can go from the quantum to the classical version via some kind of limiting procedure.\nLet’s suppose for simplicity we want to find \\(Z\\) for a single particle with a Hamiltonian operator given by \\[\nH = \\frac{\\mathbf{p}^2}{2m} + V(\\mathbf{x}) \\ .\n\\] In the position basis, this means the single-particle partition function can be written \\[\nZ = \\text{tr} \\ e^{-\\beta H} = \\int d^3 \\mathbf{x} \\ \\big\\langle \\mathbf{x} \\big| e^{-\\beta \\big(\\frac{\\mathbf{p}^2}{2m} + V(\\mathbf{x})\\big)} \\big| \\mathbf{x} \\big\\rangle \\ .\n\\] Now, we’d like to factor the exponential, except we have to be careful because the exponents here are operators. For two arbitrary operators \\(A\\) and \\(B\\) we can’t generally say \\(e^{A+B} = e^A e^B\\). This is only true if \\(A\\) and \\(B\\) commute. We already know position and momentum don’t commute. The more general result requires a series in terms of the iterated commutators of \\(A\\) and \\(B\\). To first few terms written out look like \\[\ne^{A} e^{B} = e^{A + B + \\frac{1}{2} [A,B] + \\cdots} \\ .\n\\] Since \\([x_i, p_j] = i\\hbar\\delta_{ij}\\) the first order correction to the classical result is of order \\(\\hbar\\), which means we can rearrange and write \\[\ne^{-\\beta \\big(\\frac{\\mathbf{p}^2}{2m} + V(\\mathbf{x})\\big)} = e^{-\\beta \\frac{\\mathbf{p}^2}{2m}} e^{-\\beta V(\\mathbf{x})}\\big(1 + \\beta O(\\hbar)\\big) \\ .\n\\] In the classical limit we typically imagine sending \\(\\hbar \\rightarrow 0\\), in which case the classical factorization becomes exact.\nLet’s now plug this result into the partition function traced over the position states. We have \\[\n\\begin{align*}\nZ &= \\text{tr} \\ e^{-\\beta H} \\\\\n&\\approx \\int d^3 \\mathbf{x} \\ \\big\\langle \\mathbf{x} \\big| e^{-\\beta \\frac{\\mathbf{p}^2}{2m}} e^{-\\beta V(\\mathbf{x})} \\big| \\mathbf{x} \\big\\rangle \\\\\n&\\approx \\int d^3 \\mathbf{x} \\ d^3 \\mathbf{p} \\ \\big\\langle \\mathbf{x} \\big| e^{-\\beta \\frac{\\mathbf{p}^2}{2m}} \\big| \\mathbf{p} \\big\\rangle \\big\\langle \\mathbf{p} \\big| e^{-\\beta V(\\mathbf{x})} \\big| \\mathbf{x} \\big\\rangle \\\\\n&\\approx \\int d^3 \\mathbf{x} \\ d^3 \\mathbf{p} \\ e^{-\\beta \\big(\\frac{\\mathbf{p}^2}{2m} + V(\\mathbf{x})\\big)} \\big| \\langle \\mathbf{x} | \\mathbf{p} \\rangle \\big|^2 \\\\\n&\\approx \\int \\frac{d^3 \\mathbf{x} \\ d^3 \\mathbf{p}}{(2\\pi\\hbar)^3} \\ e^{-\\beta H(\\mathbf{x},\\mathbf{p})} \\ .\n\\end{align*}\n\\] In the third line we inserted a resolution of the identity over the momentum states. In the fourth line we used the fact that for any operator \\(Q\\) we have \\(f(Q) |q\\rangle = f(q)|q\\rangle\\). This allows us to pull the exponentials out and combine them to get the classical Boltzmann scalar factor \\(e^{-\\beta H(\\mathbf{x},\\mathbf{p})}\\). Last, we used the fact that \\(\\big| \\langle \\mathbf{x} | \\mathbf{p} \\rangle \\big|^2 = (2\\pi\\hbar)^{-3}\\).\nNow, recall that in the classical partition function we had to insert a factor of \\(h\\) that had units of action. We didn’t know what it was, and it turned out not to affect any of the classical results. But now we know exactly what it is. As the notation always suggested, it’s the classical Planck’s constant \\(h = 2\\pi\\hbar\\). Inserting this identity we’ve shown how the classical limit arises.\nNotice our derivation of the classical limit just assumed that we could send \\(\\hbar \\rightarrow 0\\). But \\(\\hbar\\) is constant, so what do we really mean when we say something like this? In the case of statistical mechanics, what we really mean is that we’re in the high temperature limit. As \\(T \\rightarrow \\infty\\), \\(\\beta \\rightarrow 0\\). This means that even ignoring \\(\\hbar\\) we still can factorize \\(e^{-\\beta H}\\) in the high temperature limit as \\[\ne^{-\\beta H} = e^{-\\beta \\frac{\\mathbf{p}^2}{2m}} e^{-\\beta V(\\mathbf{x})}\\big(1 + \\beta O(\\hbar)\\big) \\approx e^{-\\beta \\frac{\\mathbf{p}^2}{2m}} e^{-\\beta V(\\mathbf{x})} \\ .\n\\] We’ll see this tendency towards the classical limit at high temperatures again and again as we work examples.\n\n\nDensity of States\nLet’s go ahead and mention an important concept we’ll need in our study of quantum statistical mechanics, the idea of the density of states. We’ll frequently find that we want to do is replace a discrete sum over states with an integral over some weighted measure \\(g(\\chi)d\\chi\\). The weight \\(g(\\chi)\\) is called a density of states. The density of states is basically a count of the number of states in the range \\(\\chi\\) to \\(\\chi + d\\chi\\). The hardest part is actually calculating what \\(g(\\chi)\\) should be.\nFor most quantities \\(\\chi\\) of interest the density of states will depend on the problem itself. But there’s one that’s pretty general, namely when \\(\\chi = \\mathbf{k}\\). In that case we imagine an enclosed system with periodic boundary conditions, so that we can write \\[\n\\mathbf{k} \\approx \\frac{2\\pi}{V^{1/3}} \\mathbf{n} \\ .\n\\] If we assume the number of states per unit area is extremely dense we can write \\(\\sum_{\\mathbf{n}} \\approx \\int d^3 \\mathbf{n}\\). Then using the multivariate change of variables formula, we have \\[\nd^3 \\mathbf{n} = d \\bigg(\\frac{V^{1/3} k_x}{2\\pi}\\bigg) d \\bigg(\\frac{V^{1/3} k_y}{2\\pi}\\bigg) d \\bigg(\\frac{V^{1/3} k_z}{2\\pi}\\bigg)  = \\frac{V}{(2\\pi)^3} d^3 \\mathbf{k} \\ .\n\\] The function out front of the differential is then the density of states, namely \\(g(\\mathbf{k}) = \\frac{V}{(2\\pi)^3}\\). This relation will be useful all across statistical mechanics, where we assume \\(\\lambda = \\frac{2\\pi}{|\\mathbf{k}|} \\ll V^{1/3}\\), meaning that each \\(d^3 \\mathbf{k}\\) of volume contains a huge number of states.\nTwo other densities of states we’ll be interested in are the ones for energy \\(E\\) and frequency \\(\\omega\\). To calculate these we just need to use whatever dispersion relation \\(\\omega(\\mathbf{k})\\) a given system has to calculate \\(g(\\omega)\\), and then use \\(E=\\hbar\\omega\\) to calculate \\(g(E)\\). Anytime we calculate densities, we need to be careful to do so using the full measures, not just the densities themselves. For example, for the particle in the box we saw that the energy had the form \\(E = \\frac{\\hbar^2 |\\mathbf{k}|^2}{2m}\\), or equivalently that \\(\\omega = \\frac{\\hbar |\\mathbf{k}|^2}{2m}\\). We’d thus have \\[\ng(\\mathbf{k}) d^3 \\mathbf{k} = \\frac{V}{(2\\pi)^3} 4\\pi d\\bigg(\\sqrt{\\frac{2m\\omega}{\\hbar}}\\bigg) = \\frac{V}{4\\pi^2} \\bigg(\\frac{2m}{\\hbar}\\bigg)^{3/2} \\sqrt{\\omega} d\\omega = g(\\omega) d\\omega \\ .\n\\] That is, for the particle in a box, the density of states for frequency is \\(g(\\omega) = \\frac{V}{4\\pi^2} \\big(\\frac{2m}{\\hbar}\\big)^{3/2} \\sqrt{\\omega}\\). The density of states for energy can then be found by using the relation \\(E=\\hbar\\omega\\) in the change of variables formula to get \\[\ng(E) = \\frac{(2m)^{3/2} V}{4\\pi^2\\hbar^3} \\sqrt{E} \\ .\n\\] The energy density of states \\(g(E)\\) also happens to be the Laplace transform of the canonical partition function \\(Z(\\beta)\\), since \\[\nZ(\\beta) = \\int_0^\\infty dE \\ g(E) e^{-\\beta E} \\ .\n\\] It’s also possible to show that \\(g(E)\\) can be related to the multiplicity \\(\\Omega\\) via the relation \\(g(E) = \\frac{1}{V} \\frac{\\partial \\Omega}{\\partial E}\\).\n\n\nExample: Particle in a Box\nLet’s go ahead and calculate the partition function and equation of state for the particle in a box. For now we’ll assume the particles are distinguishable. The reason for this has to do with a subtlety with identical particles in quantum mechanics that we’ll come to later on. We already saw that in the energy basis states are discrete with energy eigenvalues \\[\nE_\\mathbf{n} = \\frac{\\hbar^2}{2m} \\bigg(\\frac{n_x^2}{L_x^2} + \\frac{n_y^2}{L_y^2} + \\frac{n_y^2}{L_y^2}\\bigg) \\ , \\quad n_x, n_y, n_z = 1, 2, \\cdots \\ .\n\\] For convenience we’ll assume \\(L \\equiv L_x = L_y = L_z\\). Defining the energy constant \\(\\varepsilon \\equiv \\frac{\\hbar^2  \\pi^2}{2mL^2}\\), we can then write \\[\nE_{\\mathbf{n}} = \\varepsilon (n_x^2 + n_y^2 + n_z^2) \\ .\n\\] In the energy basis the partition function for a single particle is given by \\[\nZ_1 = \\sum_{n_x,n_y,n_z=1}^\\infty e^{-\\beta \\varepsilon (n_x^2 + n_y^2 + n_z^2)} = \\bigg(\\sum_{n=1}^\\infty e^{-\\beta \\varepsilon n^2} \\bigg)^3 \\ .\n\\] Functions of this form are related to a type of special function known as a theta function. Specifically they’re related to the \\(\\theta_3\\) functions defined by \\[\n\\theta_3(x) \\equiv 1 + 2\\sum_{n=1}^\\infty x^{n^2} = 1 + 2x + 2x^4 + 2x^9 + \\cdots \\ .\n\\] Substituting this in for each component using \\(x=e^{-\\beta\\varepsilon}\\), the exact partition function for a single particle is then \\[\nZ_1 = \\frac{1}{8} \\bigg(\\theta_3\\big(e^{-\\beta\\varepsilon}\\big) - 1\\bigg)^3 \\ .\n\\] As will usually be the case in quantum statistical mechanics, having the exact partition function rarely helps us understand the physics. They’ll often be expressed in terms of arcane special functions like this. Instead, what we’ll usually do in practice is look at two limits: the high temperature limit where we should recover the classical result, and the low temperature limit where we should see the limiting quantum mechanical behavior near absolute zero.\nStarting with the high temperature limit, we’re looking at what happens as \\(\\beta \\rightarrow 0\\). In that case each \\(e^{-\\beta\\varepsilon}\\) is roughly flat and we can replace the sums by integrals. It’s not hard to see that for a flat function, a sum from \\(1\\) to \\(N\\) is approximately the same as its integral from \\(0\\) to \\(N\\). We can thus to high accuracy write \\[\n\\sum_{n=1}^\\infty e^{-\\beta \\varepsilon n^2} \\approx \\int_0^\\infty dn \\ e^{-\\beta \\varepsilon n^2} = \\frac{1}{2} \\sqrt{\\frac{\\pi}{\\beta \\varepsilon}} = \\frac{L}{\\lambda_{T}} \\ ,\n\\] where \\(\\lambda_T = \\frac{h}{\\sqrt{2\\pi m k_B T}}\\) is the thermal DeBroglie wavelength. Plugging these into the partition function gives exactly what we’d expect for a non-interacting classical particle in a container, \\[\nZ_1 \\approx \\frac{L^3}{\\lambda_T^3} = \\frac{V}{\\lambda_T^3} \\ .\n\\] From this we can immediately read off the equations of state as the ones for an ideal gas. Nothing new here though. What about the low temperature limit? In that region we can no longer approximate the sum with an integral since it’s nowhere near flat anymore, but instead rapidly decaying. Instead we can approximate each series with its first few terms, \\[\n\\sum_{n=1}^\\infty e^{-\\beta \\varepsilon n^2} = e^{-\\beta \\varepsilon} + \\big(e^{-\\beta \\varepsilon}\\big)^4 + \\big(e^{-\\beta \\varepsilon}\\big)^9 + \\cdots \\ .\n\\] For temperatures very close to zero it’s easy to see that we can keep only the first term. Then the partition function is just \\[\nZ_1 \\approx e^{-3\\beta\\varepsilon} = \\exp\\bigg[-3\\beta\\frac{\\hbar^2\\pi^2}{2mL^2}\\bigg] \\ .\n\\] Notice this is just the energy we get when \\(n_x=n_y=n_z=1\\). That is, it’s the ground state energy \\(E_0=3\\varepsilon\\). This makes sense. We’d expect that at the lowest temperatures the particle would fall down into its ground state, with mean energy \\(E \\approx E_0\\).\nIf we like we can attempt to fit a curve between the high and low temperature regions by calculating the next correction to the partition function. The partition function with the next term in the series included would be \\[\nZ_1 \\approx \\bigg(e^{-\\beta \\varepsilon} + \\big(e^{-\\beta \\varepsilon}\\big)^4\\bigg)^3 \\approx e^{-\\beta E_0} \\big(1 + 3e^{-\\beta E_0}\\big) \\ .\n\\] Here we used the fact that if \\(\\beta\\) is large then \\(e^{-\\beta E_0}\\) must be small. Using the same fact again we get \\[\n\\log Z_1 = -\\beta E_0 + \\log(1+3e^{-\\beta E_0}) \\approx -\\beta E_0 + 3e^{-\\beta E_0} \\ .\n\\] We can then calculate the energy per particle to this correction as \\[\nE_1 = -\\frac{\\partial \\log Z_1}{\\partial\\beta} \\approx E_0 (1 + e^{-E_0/k_B T}) \\ .\n\\] Typically we’re more interested in the curve of the heat capacity as a function of temperature. To get that we need to calculate the heat capacity \\(C\\) from the energy. We have \\[\nC_1 \\approx \\frac{\\partial E_1}{\\partial T} = k_B \\bigg(\\frac{E_0}{k_B T}\\bigg)^2 e^{-E_0/k_B T} \\ .\n\\] If we join this with the classical heat capacity line \\(C_1 = \\frac{3}{2}\\) at high temperatures we get a plot something like the one below. Notice that \\(C_1 \\rightarrow 0\\) as \\(T \\rightarrow 0\\) in agreement with the third law of thermodynamics. In fact, it goes to zero exponentially. The interpolation region seems to occur around a characteristic temperature \\(\\theta\\) given by \\(k_B \\theta \\equiv E_0\\).\n\n\n\n\n\nWe can also calculate the density operator in some basis. Let’s look at the diagonal and off diagonal elements of \\(\\rho\\) in the position basis. We’ll assume we’re at temperatures \\(T \\gg \\theta\\) so that we can approximate \\(Z_1 \\approx \\frac{V}{\\lambda_T^3}\\). In that case, we have \\[\n\\begin{align*}\n\\langle \\mathbf{x} | \\rho | \\mathbf{x}' \\rangle &= \\frac{1}{Z_1} \\langle \\mathbf{x} | e^{-\\beta H} | \\mathbf{x}' \\rangle \\\\\n&= \\frac{1}{Z_1} \\sum_{\\mathbf{n},\\mathbf{n}'} \\langle \\mathbf{x} | \\mathbf{n} \\rangle \\langle \\mathbf{n} | e^{-\\beta \\frac{\\hbar^2}{2m} \\mathbf{k}^2} | \\mathbf{n}' \\rangle \\langle \\mathbf{n}' | \\mathbf{x}' \\rangle  \\\\\n&= \\frac{1}{Z_1} \\sum_{\\mathbf{n}} e^{-\\beta \\frac{\\hbar^2}{2m} \\mathbf{k}_\\mathbf{n}^2} \\langle \\mathbf{x} | \\mathbf{n} \\rangle \\langle \\mathbf{n} | \\mathbf{x}' \\rangle  \\\\\n&\\approx \\frac{1}{Z_1} \\frac{V}{(2\\pi)^3} \\int \\frac{d^3 \\mathbf{k}}{V} \\ e^{i \\mathbf{k} \\cdot (\\mathbf{x} - \\mathbf{x}')} e^{-\\beta \\frac{\\hbar^2}{2m} \\mathbf{k}^2} \\\\\n&\\approx \\frac{\\lambda_T^3}{V} \\frac{1}{\\lambda_T^3} \\exp\\bigg(-\\frac{(\\mathbf{x}-\\mathbf{x}')^2}{2m/ \\beta\\hbar^2}\\bigg) \\\\\n&\\approx \\frac{1}{V} \\exp\\bigg(-\\frac{(\\mathbf{x}-\\mathbf{x}')^2}{\\lambda_T^2 / \\pi} \\bigg) \\ .\n\\end{align*}\n\\] So what is this saying? First, let’s look at the diagonal elements by setting \\(\\mathbf{x}=\\mathbf{x}'\\). In that case we get \\(p(\\mathbf{x}) = \\frac{1}{V}\\). This just says that the particle is uniformly likely to be anywhere in the box. But what about when \\(\\mathbf{x}\\neq\\mathbf{x}'\\)? In this case, the density operator is telling us how much the presence of a particle at \\(\\mathbf{x}\\) quantum mechanically interferes with the presence of another particle at \\(\\mathbf{x}'\\). The two particle’s wavefunctions would overlap inside a Gaussian envelope with a spread proportional to \\(\\lambda_T\\). At higher temperatures, \\(\\lambda_T\\) will be smaller, meaning it’s less likely two nearby particles interfere with each other. At high temperatures the system has effectively decohered, in which case it’s usually a good approximation to treat the system classically.\nEvidently, it’s when \\(v \\sim \\lambda_T^3\\) that quantum effects start to become important at a given temperature. For most particles at typical temperatures, \\(\\lambda_T\\) will be on the order of a few Angstroms, which is roughly the atomic spacing. This means quantum effects will tend to be far more important for liquids and solids than for dilute gases, except at temperatures very near absolute zero.\n\n\nExample: Harmonic Oscillator\nThe next example we’ll consider is the quantum harmonic oscillator. Suppose we have a one-particle Hamiltonian given by \\[\nH_1 = \\frac{p^2}{2m} + \\frac{1}{2} m \\omega^2 x^2 \\ .\n\\] This represents a particle connected to a one-dimensional spring with spring constant \\(k = m\\omega^2\\). In quantum mechanics we have to treat this as an operator. It turns out we can factor this Hamiltonian in the form \\(H_1 = \\hbar\\omega(N+\\frac{1}{2})\\), where \\(N\\) is a number operator. When acted on the energy eigenstates it gives \\(N|n\\rangle = n|n\\rangle\\). From this, we conclude the energy eigenvalues are \\[\nE_n = \\hbar \\omega \\bigg(n + \\frac{1}{2}\\bigg) \\ , \\quad n = 0,1,\\cdots \\ .\n\\] From here we can calculate the single-particle partition function, and in this case actually get a closed form for it. We have \\[\n\\begin{align*}\nZ_1 &= \\sum_{n=0}^\\infty e^{-\\beta\\hbar\\omega\\big(n+\\frac{1}{2}\\big)} \\\\\n&= e^{-\\frac{\\beta\\hbar\\omega}{2}} \\sum_{n=0}^\\infty \\big(e^{-\\beta\\hbar\\omega}\\big)^n \\\\\n&= \\frac{e^{-\\frac{\\beta\\hbar\\omega}{2}}}{1 - e^{-\\beta\\hbar\\omega}} \\ .\n\\end{align*}\n\\] The logarithm of \\(Z_1\\) is then given by \\[\n\\log Z_1 = -\\frac{\\beta\\hbar\\omega}{2} - \\log\\big(1 - e^{-\\beta\\hbar\\omega}\\big) \\ .\n\\] From here we can calculate the energy per particle to get \\[\nE_1 = \\frac{\\hbar\\omega}{2} + \\frac{\\hbar\\omega}{e^{\\hbar\\omega/k_B T}-1} \\ .\n\\] Again, let’s investigate the behavior of the energy in the high and low temperature limits. In the high temperature limit we can approximate the exponential by \\(e^{\\hbar\\omega/k_B T} \\approx 1 + \\frac{\\hbar\\omega}{k_B T}\\) to get the classical result we’d expect from the equipartition theorem, \\[\nE_1 \\approx \\frac{\\hbar\\omega}{2} + k_B T \\approx k_B T \\ .\n\\] Here we used the fact that at high temperatures \\(k_B T \\gg \\hbar\\omega\\). At zero temperature we can see the energy is just the ground state energy exactly, \\(E_1 = \\frac{1}{2} \\hbar\\omega\\), which is again what we’d expect.\nSince we’ll need it later, let’s go ahead and look at the heat capacity per particle too. We have \\[\nC_1 = k_B \\bigg(\\frac{\\hbar\\omega}{k_B T}\\bigg)^2 \\frac{e^{\\hbar\\omega/k_B T}}{\\big(e^{\\hbar\\omega/k_B T}-1\\big)^2} \\ .\n\\] At high temperatures we again use the Taylor expansion of \\(e^{\\hbar\\omega/k_B T}\\) to get \\[\nC_1 \\approx k_B \\bigg(\\frac{\\hbar\\omega}{k_B T}\\bigg)^2 \\frac{1-\\frac{\\hbar\\omega}{k_B T}}{\\big(\\frac{\\hbar\\omega}{k_B T}\\big)^2} \\approx k_B \\bigg(1-\\frac{\\hbar\\omega}{k_B T}\\bigg) \\ .\n\\] For temperatures where \\(k_B T \\gg \\hbar\\omega\\) we can neglect the last term to get \\(C_1 \\approx k_B\\), which is what we’d expect classically. At low temperatures we can use the fact that \\(e^{\\hbar\\omega/k_B T} \\ll 1\\) along with the binomial expansion \\((1-x)^{-2} \\approx 1+2x\\) to write \\[\nC_1 \\approx k_B \\bigg(\\frac{\\hbar\\omega}{k_B T}\\bigg)^2 \\frac{e^{-\\hbar\\omega/k_B T}}{\\big(1-e^{-\\hbar\\omega/k_B T}\\big)^2} \\approx k_B \\bigg(\\frac{\\hbar\\omega}{k_B T}\\bigg)^2 e^{-\\hbar\\omega/k_B T} \\big(1 + 2e^{-\\hbar\\omega/k_B T}\\big) \\ .\n\\] Again, we can see that the heat capacity goes to zero exponentially in accordance with the third law. Connecting the two limits, we get a similar curve to the particle in the box heat capacity, except with a characteristic temperature given by \\(k_B \\theta = \\hbar\\omega\\).",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Quantum Statistical Mechanics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/quantum-stat-mech.html#three-classic-problems",
    "href": "statistical-mechanics/quantum-stat-mech.html#three-classic-problems",
    "title": "Quantum Statistical Mechanics",
    "section": "Three Classic Problems",
    "text": "Three Classic Problems\nWe’ll now turn our attention to addressing the three problems mentioned at the start of this chapter. Namely the resolution of the heat capacity of diatomic gases, the heat capacity of solids, and blackbody radiation. We’ll show that for each of these problems classical statistical mechanics gave results that disagreed with experiments of the time, and then we’ll show precisely how it is that quantum statistical mechanics was able to resolve all of these problems.\n\nDiatomic Gases\nRecall that a diatomic gas is a gas in which each particle can be thought of as two masses connected to a spring. Such particles are not only allowed to translate in space like point particles. They’re also allowed to rotate and vibrate, essentially giving them new degrees of freedom. We saw previously that the Hamiltonian for a single diatomic particle can be written \\[\n\\begin{align*}\nH_1 &= \\frac{\\mathbf{p}_1^2}{2m} + \\frac{\\mathbf{p}_2^2}{2m} + u(|\\mathbf{x}_1-\\mathbf{x}_2|) \\\\\n&= \\frac{\\mathbf{P}^2}{2M} + \\frac{\\mathbf{p}^2}{2\\mu} + \\frac{1}{2}\\mu\\omega^2r^2 + u(d) \\ ,\n\\end{align*}\n\\] where in the last line we switched to center of mass and relative coordinates and approximated the interaction potential between the two masses by a harmonic oscillator with equilibrium distance \\(d\\), i.e. \\(u(r) \\approx \\frac{1}{2}\\mu\\omega^2r^2 + u(d)\\). By integrating over each coordinate, we were able to show the classical single particle partition function had the form \\[\nZ_1 = \\frac{16\\pi^4 M^{3/2}}{h^6} \\frac{V}{\\beta^{7/2}} \\ .\n\\] From here, we were able to show the diatomic gas had average energy \\(E=\\frac{7}{2} Nk_B T\\) and heat capacity \\(C = \\frac{7}{2}Nk_B\\).\nGreat, so what’s the problem? It turns out that if we were to go out and actually measure the ratio \\(\\frac{C}{k_B}\\) for a gas of some given diatomic molecule, most of the time we won’t get \\(\\frac{7}{2}\\). In fact, around room temperature we’ll usually get something closer to \\(\\frac{5}{2}\\). If we reduce the temperature to around \\(10 \\ ^\\circ \\text{K}\\) and measure again, we instead get something close to \\(\\frac{3}{2}\\). If we increase the temperature to around \\(1000 \\ ^\\circ \\text{K}\\) and measure again, we get the \\(\\frac{7}{2}\\) factor that the classical theory predicts. It’s almost as if degrees of freedom are frozen out at lower temperatures, and only activate one by one as the temperature increases. This gives heat capacity curves that looks something like the following.\n\n\n\n\n\nClearly the classical theory isn’t able to account for such a strange heat capacity curve. It’s not able to predict this freezing out of degrees of freedom. We’ll show that the quantum theory can by looking at each mode one by one. Let’s first rewrite the diatomic gas Hamiltonian in a slightly different form. We’ll ignore the added constant \\(u(d)\\) from now on since it contributes nothing to the dynamics. We can explicitly split off the rotational contribution to the relative coordinates by factoring the \\(\\mathbf{p}^2\\) to get \\[\nH_1 = \\frac{\\mathbf{P}^2}{2M} + \\frac{\\mathbf{L}^2}{2I} + \\frac{p^2}{2\\mu} + \\frac{1}{2}\\mu\\omega^2r^2 \\equiv H_{\\text{trans}} + H_{\\text{rot}} + H_{\\text{vib}} \\ ,\n\\] where \\(\\mathbf{L}\\) is the angular momentum and \\(I=\\mu r^2\\) is the scalar moment of inertia. Note that even though \\(\\mathbf{L}\\) is a vector it only contributes two degrees of freedom. In this form, we can think of the Hamiltonian as composed of three distinct pieces, a translational piece \\(H_{\\text{trans}}\\) depending only on the center of mass coordinates, a rotational piece \\(H_{\\text{rot}}\\) depending only on the angular coordinates, and the vibrational piece \\(H_{\\text{vib}}\\) depending only on the radial coordinates. Let’s look at the heat capacity curves for each of these pieces one-by-one.\nFirst we have the translational piece \\(H_{\\text{trans}} = \\frac{\\mathbf{P}^2}{2M}\\). But this is just the Hamiltonian for the free particle. We already know what its solutions look like. At high temperatures we recover the classical result for the ideal gas, \\(C \\approx \\frac{3}{2} N k_B\\). At low temperatures we get a curve that goes to zero exponentially fast, \\[\nC \\approx Nk_B \\bigg(\\frac{E_0}{k_B T}\\bigg)^2 e^{-E_0/k_B T} \\ .\n\\] The transition region between the low and high temperature regions occurs when \\(k_B T \\approx E_0\\). For a \\(1 \\ \\text{m}^3\\) box of diatomic oxygen, this occurs at a temperature of around \\(\\theta \\approx 10^{-20} \\ ^\\circ\\text{K}\\). In fact this isn’t exactly right due to the fact that we’re not treating identical particles in quantum mechanics correctly yet. But the rough idea is right. The heat capacity goes to zero in accordance with the third law, and translational modes indeed activate very quickly at non-zero temperatures. This resolves the first part of the plot.\nSecond, we have the rotational piece \\(H_{\\text{rot}} = \\frac{\\mathbf{L}^2}{2I}\\). On its face this one looks the same as the translational piece, but there’s an important subtlety here. Angular momentum is also quantized separately from the energy. In quantum mechanics we can think about angular momentum states as two combined states \\(|\\ell m\\rangle\\), one representing the eigenvalues of \\(\\mathbf{L}^2\\) and the other representing the eigenvalues of the \\(z\\)-component \\(\\mathbf{L}_z\\). It turns out that both \\(\\mathbf{L}^2\\) and \\(\\mathbf{L}_z\\) commute, which means they’re simultaneously diagonalizable, and hence their eigenvectors can be chosen to be identical, namely \\(|\\ell m\\rangle\\), where \\[\n\\begin{align*}\n\\mathbf{L}^2 |\\ell m\\rangle &= \\hbar^2 \\ell(\\ell+1)|\\ell m\\rangle \\\\\n\\mathbf{L}_z |\\ell m\\rangle &= \\hbar m|\\ell m\\rangle \\ .\n\\end{align*}\n\\] Here \\(\\ell = 0,1,2, \\cdots\\) and \\(m = -\\ell, \\cdots, \\ell\\) are both integers. Notice that for each given \\(\\ell\\) there are \\(2m+1\\) eigenstates due to degeneracy in \\(\\mathbf{L}_z\\). Using these relations, in the \\(|\\ell m\\rangle\\) basis we can easily see that \\(H_{\\text{rot}}\\) diagonalizes too. Thus, we have \\[\nH_{\\text{rot}} |\\ell m\\rangle = \\frac{\\hbar^2\\ell(\\ell+1)}{2I} |\\ell m\\rangle \\quad \\Longrightarrow \\quad E_\\ell = \\frac{\\hbar^2\\ell(\\ell+1)}{2I} \\ .\n\\] From here we can proceed to calculate the partition function in the \\(|\\ell m \\rangle\\) basis. We have \\[\n\\begin{align*}\nZ_{\\text{rot}} &= \\text{tr} \\ e^{-\\beta H_{\\text{rot}}} \\\\\n&= \\sum_{\\ell=0}^\\infty \\sum_{m=-\\ell}^\\ell \\exp\\bigg(-\\frac{\\beta\\hbar^2\\ell(\\ell+1)}{2I}\\bigg) \\\\\n&= \\sum_{\\ell=0}^\\infty (2\\ell+1) \\exp\\bigg(-\\frac{\\beta\\hbar^2\\ell(\\ell+1)}{2I}\\bigg) \\ .\n\\end{align*}\n\\] As sort of expected, we yet again have a partition function with no obvious closed form solution. Instead we’ll proceed as we have been by looking at things in the high and low temperature limits. In the high temperature limit the states are so close together that we can approximate the sum with an integral. Using the substitution \\(x=\\ell(\\ell+1)\\) we get \\[\n\\begin{align*}\nZ_{\\text{rot}} &\\approx \\int_0^\\infty d\\ell \\ (2\\ell+1) \\exp\\bigg(-\\frac{\\beta\\hbar^2\\ell(\\ell+1)}{2I}\\bigg) \\\\\n&\\approx \\int_0^\\infty dx \\ \\exp\\bigg(-\\frac{\\beta\\hbar^2}{2I}x\\bigg) \\\\\n&\\approx \\frac{2I}{\\hbar^2\\beta} \\ .\n\\end{align*}\n\\] From here we can read off that \\(E_{\\text{rot}} \\approx Nk_B T\\), which means \\(C\\approx Nk_B\\). That is, the rotational modes contribute exactly two degree of freedom, just as we’d expect from the equipartition theorem.\nIn the low temperature limit we’ll instead approximate the partition function with its first two terms as \\[\nZ_{\\text{rot}} \\approx 1 + 3 e^{-\\frac{\\beta\\hbar^2}{I}} \\ .\n\\] From here we can see the energy is given by \\(E_{\\text{rot}} \\approx 6Nk_B \\big(\\frac{\\hbar^2}{2Ik_B}\\big) e^{-\\hbar^2/Ik_BT}\\), and thus \\[\nC \\approx 3Nk_B \\bigg(\\frac{\\hbar^2}{Ik_BT}\\bigg)^2 e^{-\\hbar^2/Ik_BT} \\ .\n\\] Again, we see the heat capacity levels off at temperatures above some temperature \\(\\theta = \\frac{\\hbar^2}{2Ik_B}\\) and goes to zero at temperatures below \\(\\theta\\). For diatomic oxygen this temperature turns out to be about \\(\\theta \\approx 2 \\ ^\\circ \\text{K}\\). This means that for all but temperatures very near zero the rotational modes of oxygen and most substances are also activated. This explains the second part of the plot.\nLast, we have to look at the vibrational modes \\(H_{\\text{vib}} \\equiv \\frac{p^2}{2\\mu} + \\frac{1}{2}\\mu\\omega^2r^2\\). We can quickly recognize this Hamiltonian as the quantum harmonic oscillator, which we already know has discrete energy eigenvalues of the form \\(E_n = \\hbar\\omega \\big(n + \\frac{1}{2}\\big)\\). The partition function for a single particle is given by \\[\nZ_1 = \\frac{e^{-\\frac{\\beta\\hbar\\omega}{2}}}{1 - e^{-\\beta\\hbar\\omega}} \\ .\n\\] From this, we read off the energy as \\(E = \\frac{N\\hbar\\omega}{2} + \\frac{N\\hbar\\omega}{e^{\\hbar\\omega/k_B T}-1}\\), and from there calculate the heat capacity as \\[\nC = Nk_B \\bigg(\\frac{\\hbar\\omega}{k_B T}\\bigg)^2 \\frac{e^{\\hbar\\omega/k_B T}}{\\big(e^{\\hbar\\omega/k_B T}-1\\big)^2} \\ .\n\\] We’ve already seen that this heat capacity also goes to zero exponentially at low temperatures, and levels off to \\(C \\approx Nk_B\\) at high temperatures. The transition region is at a temperature \\(\\theta = \\frac{\\hbar\\omega}{k_B}\\). For diatomic oxygen this is about \\(\\theta \\approx  2256 \\ ^\\circ \\text{K}\\). This covers the last part of the plot. We’ve been able to explain each of the three transition regions by finding the heat capacity for each of the three types of modes and identifying their characteristic temperatures.\n\n\nHeat Capacity of Solids\nWe’ve thus far pretty much completely ignored solids in this course. The main reason for this is that understanding the behavior of solids tends to require a lot more quantum mechanics. Nevertheless, we can at least address one relatively simply but historically important problem dealing with solids, which is the behavior of their heat capacities. Unlike most properties of solids, we can understand their heat capacities by assuming little more than that solids are a set of particles locked in a lattice. We’ll assume in this section that a solid is merely a cubic lattice of \\(N\\) identical particles, each interacting with its nearest neighbors.\nThe first attempt to understand heat capacity of solids is to model the lattice of particles as a coupled spring system. This is known as the Boltzmann model of a solid. We suppose each particle is attached to its nearest neighbors with a spring and allowed to oscillate at the same constant frequency \\(\\omega\\). From classical mechanics, we know we can always diagonalize a system of coupled harmonic oscillators into their fundamental modes and write the Hamiltonian in decoupled form as \\[\nH = \\sum_{i=1}^{3N} \\frac{p_i^2}{2m} + \\frac{1}{2} m\\omega^2 x_i^2 \\ .\n\\] Here strictly speaking, each \\(x_i\\) and \\(p_i\\) should be thought of as generalized coordinates, but for our purposes that won’t matter. Since this Hamiltonian decouples into \\(3N\\) degrees of freedom, we can use the equipartition theorem to state the average energy in the solid is \\(E = 3Nk_B T\\). From this, we can infer the heat capacity of a solid is just \\[\nC = 3Nk_B \\ .\n\\] This is classically known as the law of Dulong-Petit. This law says the heat capacity of a solid should be constant for all \\(T\\). Indeed, it turns out to hold well at high \\(T\\). But, of course, we shouldn’t expect this to really be true at all temperatures, since the third law requires \\(C \\rightarrow 0\\) as \\(T \\rightarrow 0\\). But maybe we can fix this by again trying to quantize the harmonic oscillators.\nWe’ll now model a solid not as \\(3N\\) classical harmonic oscillators, but with \\(3N\\) quantum harmonic oscillators again all oscillating at the same constant frequency \\(\\omega\\). This is known as the Einstein model of a solid. The heat capacity is given by \\[\nC = 3Nk_B \\bigg(\\frac{\\hbar\\omega}{k_B T}\\bigg)^2 \\frac{e^{\\hbar\\omega/k_B T}}{\\big(e^{\\hbar\\omega/k_B T}-1\\big)^2} \\ .\n\\] This is the same heat capacity we saw for the vibrational modes of a diatomic gas, except with \\(3N\\) degrees of freedom instead of \\(N\\) degrees of freedom. This means in the high temperature limit \\(C \\approx 3Nk_B T\\) in accordance with the law of Dulong-Petit, while in the low temperature limit \\(C \\sim e^{-\\hbar\\omega / T}\\). So now \\(C \\rightarrow 0\\) like we’d expect. But is this right? It turns out not. Experimentally it turns out the heat capacity of a solid goes to zero like \\(C \\sim T^3\\), not like an exponential. This is illustrated in the figure below.\n\n\n\n\n\nHow can we change our model of a solid to get this cubic heat capacity behavior? We’re already using quantum mechanics. We need something more. In fact, the main thing we’re missing is that solids have sound modes. When you bang on a solid, each particle in the lattice jiggles in a wave pattern, creating sound waves that propagate through the solid at some speed. This modification of the Einstein model produces what’s known as the Debye model of a solid.\nWe can allow for sound modes by assuming the frequency \\(\\omega\\) is no longer constant, but instead has a linear dispersion relation \\[\n\\omega(\\mathbf{k}) = v |\\mathbf{k}| \\ .\n\\] Here we assume for simplicity all frequencies have the same speed of sound \\(v\\), though each direction along the lattice could have a different speed and the main results of this section won’t really change. If we again model each particle as a quantum harmonic oscillator, at each frequency we have an energy of the form \\[\nE(\\omega) = 3 \\bigg(\\frac{\\hbar\\omega}{2} + \\frac{\\hbar\\omega}{e^{\\hbar\\omega/k_B T}-1}\\bigg) \\ .\n\\] The factor of \\(3\\) can be thought of as belonging here for multiple reasons. One reason is that we’re effectively considering \\(3N\\) decoupled harmonic oscillators. Another reason is that a solid has three polarizations, two for the transverse directions of each wave and one for the longitudinal direction. To get the total energy \\(E\\) over all frequencies we can integrate over all frequencies weighted by the density of states. Rather than rewrite everything in terms of \\(\\mathbf{k}\\) let’s find an expression for \\(g(\\omega)\\). Using the dispersion relation \\(\\omega=vk\\) we can write \\[\ng(\\mathbf{k}) d^3 \\mathbf{k} = \\frac{Vn^3}{4\\pi^2} \\omega^2 d\\omega \\equiv g(\\omega) d\\omega \\ .\n\\] Note we can define a natural frequency from this expression via \\(\\omega_D^3 \\equiv 6\\pi^2 v^3 n\\) and rewrite \\(g(\\omega) = \\frac{3N\\omega^2}{\\omega_D^3}\\). This special frequency \\(\\omega_D\\) is called the Debye frequency. It turns out to be important for reasons we’ll see shortly. The total energy is thus \\[\nE = \\int d\\omega \\ g(\\omega) E(\\omega) = \\frac{9N}{\\omega_D^3} \\int d\\omega \\ \\bigg(\\frac{\\hbar\\omega^3}{2} + \\frac{\\hbar\\omega^3}{e^{\\hbar \\omega/k_B T}-1}\\bigg) \\ .\n\\] There’s still the question of what frequencies we’re allowed to integrate over. For sound waves we could in principle have wavelengths \\(\\lambda\\) as high as we like. But having small wavelengths is limited by the atomic spacing inside the lattice. Suppose each particle in the lattice is a distance \\(a\\) from its nearest neighbors, meaning \\(V=Na^3\\) or \\(na^3=1\\). Then we should expect \\(\\lambda \\sim a\\) to be about the smallest allowed wavelength for sound waves to propagate through the solid. This implies there should be some highest frequency that’s roughly around \\(\\omega^* \\sim \\frac{2\\pi v}{a}\\). In fact \\(\\omega^* = \\omega_D\\) exactly. This gives us a new interpretation of the Debye frequency. It’s the smallest allowed frequency for sound waves to propagate in the Debye model.\nRather than evaluate the above integral exactly, let’s look at the two limits. First, in the high temperature limit, we can again use the Taylor expansion \\(e^{\\hbar\\omega / k_B T} - 1 \\approx \\frac{\\hbar\\omega}{k_B T}\\) to write \\[\nE \\approx \\frac{9N}{\\omega_D^3} \\int_0^{\\omega_D} d\\omega \\ \\bigg(\\frac{\\hbar\\omega^3}{2} + \\frac{\\hbar\\omega^3}{\\hbar \\omega/k_B T}\\bigg) \\approx E_0 + 3 N k_B T \\ .\n\\] The first term \\(E_0 = \\frac{9N}{8} \\hbar\\omega_D\\) is just a constant. For all practical purposes we can ignore it. The second term we recognize. If we differentiate with respect to energy we just get the Dulong-Petit law again as expected, \\(C \\approx 3 N k_B\\).\nWhat about the low temperature limit? After all, that’s the whole reason we’re still here. In this limit we can use the fact that the integrand of the second term is a negative exponential, and hence a rapidly decaying function of \\(\\omega\\). This means for all practical purposes we can allow the upper limit to go to infinity. If we make the substitution \\(x = \\hbar \\omega / k_B T\\), we can write \\[\nE \\approx E_0 + \\frac{9N}{\\omega_D^3} \\bigg(\\frac{k_B T}{\\hbar}\\bigg)^4 \\int_0^\\infty dx \\ \\frac{x^3}{e^{x} - 1} \\ .\n\\] Now we make use of the fact that this integral over \\(x\\) is a well-known integral with value \\(\\pi^4 / 15\\). Plugging this in, we have \\[\nE \\approx E_0 + \\frac{9\\pi^4 N}{15\\omega_D^3} \\bigg(\\frac{k_B T}{\\hbar}\\bigg)^4 \\ .\n\\] What’s important here is that \\(E \\sim T^4\\), meaning when we differentiate we get \\(C \\sim T^3\\). The transition region between high and low temperature behaviors seems to occur when \\(\\hbar \\omega_D \\sim k_B T\\). This defines a characteristic temperature \\(T_D \\equiv \\frac{\\hbar \\omega_D}{k_B}\\) known as the Debye temperature that separates the behavior of the two regimes. We can then write the heat capacity at low temperatures as \\[\nC = N k_B \\frac{12\\pi^4}{5} \\bigg(\\frac{T}{T_D}\\bigg)^3 + O(T^4) \\ .\n\\] As a brief aside, it’s natural to ask if this heat capacity relationship truly holds for all solids. The answer is almost. For insulating materials this law holds just fine, but for metals it turns out the low temperature limit needs to be slightly modified to \\[\nC \\sim \\gamma T + \\alpha T^3 \\ ,\n\\] where \\(\\alpha\\) and \\(\\gamma\\) are constant with temperature. That is, the heat capacity of metals goes to zero linearly, not cubically. The reason for this essentially comes from the fact that in metals the electrons are allowed to move around freely throughout the solid, creating a composite of a solid and a Fermi gas of electrons. We’ll study this more in the next chapter on quantum gases.\n\n\nBlackbody Radiation\nPretty much all of our applications so far have been of matter. We’ve seen applications involving solids, liquids, and gases of particles that have definite mass. We’ve yet to really study the thermodynamics of light, or electromagnetic radiation. We saw that we could model the thermodynamics of light classically as an ultra-relativistic gas. Let’s now study a more interesting and historically important application to light, the problem of blackbody radiation.\nSuppose some amount of light is allowed to be emitted and absorbed inside some cavity. The particles in the walls of the cavity undergo small oscillations in the presence of the light. In equilibrium the oscillation frequencies of these particles are the same as the frequencies of radiation. Said differently, the walls glow at the same color as the light itself, where the color depends on the temperature. Our goal is to understand the behavior of the color spectrum of this light, like which colors are most likely to be emitted or absorbed at a given temperature.\nLet’s first look at the problem classically. We’ll suppose for simplicity that the cavity is a hollow cube with side lengths \\(L\\) and volume \\(V=L^3\\), though it turns out the shape of the cavity doesn’t impact the results. We’ll also assume the interior of the cavity can be treated as a vacuum with periodic boundary conditions, so we can treat the electromagnetic waves as periodic plane waves. This means the wavevector \\(\\mathbf{k}\\) is again periodic with only allowed discrete values \\(\\mathbf{k} = \\frac{2\\pi}{L} \\mathbf{n}\\). Since the particles in the wall undergo small oscillations, we can model them as harmonic oscillators with average energy \\(k_B T\\) per oscillator, and then use the condition that the walls and light are in equilibrium to state the same formulas hold for the light in the cavity as well.\nUsing the fact that each photon has an energy \\(E = \\hbar \\omega\\) we get \\[\ng(E) dE = \\frac{VE^2}{\\pi^2\\hbar^3 c^3} dE =  \\frac{V\\omega^2}{\\pi^2 c^3} d\\omega \\equiv g(\\omega) d\\omega \\ .\n\\] At equilibrium we now use our oscillator assumption to write \\(E(\\omega) d\\omega = k_B T g(\\omega)d\\omega\\). What we’re really interested in though is the energy as a function of wavelength \\(\\lambda\\). To get this, we use the fact that \\(\\lambda = \\frac{2\\pi c}{\\omega}\\) for light to write \\[\nE(\\omega) d\\omega = \\frac{Vk_B T}{\\pi^2 c^3} \\omega^2d\\omega = \\frac{2Vk_B T}{\\pi^2 c^3} \\bigg(\\frac{2\\pi c}{\\lambda}\\bigg)^2 \\bigg |-\\frac{2\\pi cd\\lambda}{\\lambda^2} \\bigg | = E(\\lambda) d\\lambda \\ .\n\\] The spectrum light is typically understood by plotting wavelength against the spectral radiance \\(I(\\lambda)\\), which is defined as the amount of energy flux per unit time per given wavelength. For light, it’s possible to show \\(I(\\lambda) = \\frac{c}{4} \\varepsilon(\\lambda)\\), where \\(\\varepsilon(\\lambda) \\equiv \\frac{E(\\lambda)}{V}\\) is the energy density. We’ve thus derived the classical formula for the radiance of blackbody radiation, called the Rayleigh-Jeans law, \\[\nI(\\lambda) = \\frac{2\\pi c k_B T}{\\lambda^4} \\ .\n\\] Let’s take a look at this expression. Remember, it’s a plot of the color spectrum of light. We should thus expect it to behave kind of like a probability density. The conservation of energy requires there to be a finite area under the curve. But if we attempt to integrate the Rayleigh-Jeans law what do we get for the total radiance? Infinity! The integral diverges as \\(\\lambda \\rightarrow 0\\). Since lower wavelengths fall on the ultraviolet side of visible light, this blowing up of the spectrum is called the ultraviolet catastrophe. Simply put, there’s no physical reason it can happen for a system with finite energy. It was already known in the 19th century via spectral measurements that the actual blackbody spectrum turns over and goes to zero as \\(\\lambda \\rightarrow 0\\) like the solid line in the figure below.\n\n\n\n\n\nIt was Planck who realized originally that we could get the correct blackbody spectrum by making use of the fact that energy be quantized in units of \\(E = \\hbar\\omega\\). As we’ve seen over and over, the way to fix things is to treat the classical harmonic oscillators quantum mechanically. Instead of assuming each particle has an average energy \\(k_B T\\), we assume each has the average energy given by a quantum harmonic oscillator, i.e. \\(\\frac{\\hbar \\omega}{2} + \\frac{\\hbar \\omega}{e^{\\hbar \\omega / k_B T} - 1}\\). Since the first term doesn’t depend on temperature it can be thought of as an added constant to the energy. If we ignore this term and focus only on the temperature dependent part, we can write \\[\nE(\\omega) d\\omega = \\frac{V\\hbar \\omega^3 / \\pi^2 c^3}{e^{\\hbar \\omega / k_B T} - 1} d\\omega = \\frac{V\\hbar / \\pi^2 c^3}{e^{2\\pi\\hbar / k_B T \\lambda} - 1} \\bigg(\\frac{2\\pi c}{\\lambda}\\bigg)^3  \\bigg |-\\frac{2\\pi cd\\lambda}{\\lambda^2} \\bigg | = E(\\lambda) d\\lambda \\ .\n\\] Plugging this expression for \\(E(\\lambda)\\) into the radiance \\(I(\\lambda) = \\frac{c}{4} \\varepsilon(\\lambda)\\) and using the relation \\(h=2\\pi\\hbar\\), we finally have \\[\n\\boxed{\nI(\\lambda) = \\frac{2\\pi hc^2}{\\lambda^5} \\frac{1}{e^{hc/k_B T \\lambda} - 1}\n} \\ .\n\\] It’s easy to see that this spectrum indeed vanishes at both limits. At small wavelengths the spectrum exponentially decays like \\(I(\\lambda) \\sim e^{-hc/k_B T\\lambda}\\), while at large wavelengths the spectrum decays like \\(I(\\lambda) \\sim \\lambda^{-4}\\) in accordance with the Rayleigh-Jeans law.\nThe spectrum evidently seems to peak at a wavelength \\(\\lambda_W\\) satisfying \\(\\frac{dI}{d\\lambda} \\big |_{\\lambda_W} = 0\\). This can be solved to give \\(\\lambda_W = \\frac{b}{T}\\), where \\(b \\approx 3 \\cdot 10^{-3} \\ ^\\circ \\text{K m}\\) in SI units. This relationship between peak wavelength and temperature is known as Wien’s displacement law. It’s this simple law that tells us which color we’re most likely to see a cavity full of radiation glow at at a given temperature.\nIf we like, we can integrate \\(E(\\omega)\\) over all frequencies and find the total energy inside the cavity. Since light can in principle take on all frequencies, we have to integrate to infinity. There is no logical frequency cutoff anymore. Lumping the non-temperature dependent piece into one integral we’ll call \\(E_0\\) and again using the substitution \\(x = \\frac{\\hbar\\omega}{k_B T}\\) and integrating, we have \\[\n\\begin{align*}\nE &= E_0 + \\frac{V\\hbar}{\\pi^2 c^3} \\int_0^\\infty d\\omega \\ \\frac{\\omega^3}{e^{\\hbar \\omega / k_B T} - 1} \\\\\n&= E_0 + \\frac{V\\hbar}{\\pi^2 c^3} \\bigg(\\frac{k_B T}{\\hbar}\\bigg)^4 \\int_0^\\infty dx \\ \\frac{x^3}{e^{x} - 1} \\\\\n&= V\\bigg[\\varepsilon_0 + \\frac{\\hbar \\pi^2}{15 c^3} \\bigg(\\frac{k_B T}{\\hbar}\\bigg)^4\\bigg] \\ .\n\\end{align*}\n\\] Here we pulled out a factor of volume at the end so we can express things in terms of the total energy density \\(\\varepsilon\\), which is more commonly done when dealing with light. It’s worth taking a minute to address the constant term \\(\\varepsilon_0\\). Had we actually done this integral, we’d realize that in fact \\(\\varepsilon_0\\) is infinite. We can hand-wave and argue that since \\(\\varepsilon_0\\) constant, and physics only cares about energy differences, we can ignore \\(\\varepsilon_0\\) and only focus on the temperature dependent part. At a deeper level, it’s fair to speculate whether this infinite energy arises from some deeper physics, e.g. the vacuum energy or cosmological constant, but at present this is a topic of ongoing research.\nIt’s typical to lump most of the constants in the second term of the previous equation into a single constant \\(\\sigma\\). This is known as the Stefan-Boltzmann constant, defined by \\[\n\\boxed{\n\\sigma \\equiv \\frac{\\pi^2 k_B^4}{60c^2 \\hbar^3} \\approx 5.67 \\cdot 10^{-8} \\ \\frac{\\text{W}}{\\text{m}^2 \\ ^\\circ \\text{K}^4}\n} \\ .\n\\] In terms of this new constant \\(\\sigma\\) we can then write \\[\n\\varepsilon = \\varepsilon_0 + \\frac{4 \\sigma}{c} T^4 \\ .\n\\] The most important thing to notice for our purposes though is that the energy density relates to temperature as \\(\\varepsilon \\propto T^4\\). Since energy density and energy flux are proportional, we have \\[\nI = \\sigma T^4 \\ .\n\\] This statement that the total radiance, i.e. the total power radiated by the blackbody, is proportional to \\(T^4\\) is known as the Stefan-Boltzmann law. Last, it’s possible to use the partition function for this system to show that the radiation inside the cavity also creates a pressure. In fact, that radiation pressure is simply given by \\[\nP = P_0 + \\frac{1}{3} \\varepsilon = P_0 + \\frac{4\\sigma}{c} T^4 \\ .\n\\] Here, the pressure \\(P_0\\) arises from the constant energy density \\(\\varepsilon_0\\). This means \\(P_0\\) will also be infinite. However, it turns out \\(P_0\\) does have a potential physical interpretation. It’s believed to result from the Casimir force, which arises when two conducting plates are put very close together, resulting in an attraction due to the pressure differences inside and outside the plates.\nAs academic as the problem of blackbody radiation may sound, these results turn out to be extremely useful in astrophysics. Typically in astronomy we’re very limited in what we can directly measure about a far away star or galaxy. In particular, we’re limited to observing the spectra of light being emitted by those stars. However, to an excellent approximation, it turns out stars can be well modeled as blackbodies. This means we can use measured information about their spectra to deduce other physical facts, like what their energies or pressures are.\nAs a simple example of this, it’s observed that the sun has a spectrum that peaks in the green part of the visible spectrum. Since green light occurs at wavelengths around \\(\\lambda \\approx 5.2 \\ \\mu\\text{m}\\), using Wien’s displacement law we find that the temperature at the surface of the Sun must be about \\(T \\approx 5800 \\ ^\\circ \\text{K}\\). Given the surface temperature, we can immediately find the total energy flux as well, and from that the total power radiated by the sun, which turns out to be about \\(\\mathcal{P} \\approx 3 \\cdot 10^{26} \\ \\text{W}\\). However, the predicted pressure is much lower than the true pressure observed, which is about \\(P \\approx 0.1 \\ \\text{atm}\\). This discrepancy arises from the fact that we’re ignoring other more significant contributions to the pressure, particularly the hydrostatic pressure.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Quantum Statistical Mechanics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/quantum-gases.html",
    "href": "statistical-mechanics/quantum-gases.html",
    "title": "Quantum Gases",
    "section": "",
    "text": "Identical Particles\nRecall the distinction we made in classical statistical mechanics between distinguishable particles and identical particles. A collection of particles was distinguishable if we could label each particle and in principle tell them apart. They were identical if this wasn’t true, if there was no way even in principle to tell apart one particle from another. We found it was very easy to account for this fact in classical statistical mechanics. If \\(N\\) particles were identical, we just needed to be sure to divide the partition function by \\(N!\\) to account for all possible permutations of those particles.\nIn quantum mechanics, the nature of identical particles is baked deep into the theory itself. There’s nothing arbitrary about them, since in quantum mechanics there really is no way even in principle to label a tiny particle without changing its state. Every fundamental particle is identical. From a theoretical perspective, identical particles arise due to the exchange postulate. Consider two particles. Suppose \\(|\\psi \\rangle\\) is the state of particle one, and \\(|\\phi \\rangle\\) is the state of particle two. Then we should expect the joint state where both of these occur is given by the tensor product of the two, namely \\(|\\psi \\rangle |\\phi \\rangle \\equiv |\\psi \\rangle \\otimes |\\phi \\rangle\\). The exchange postulate states that the only tensor product states allowed for real particles are those that are eigenvectors of the exchange operator \\(P_\\sigma\\) defined by the relation \\[\nP_\\sigma |\\psi \\rangle |\\phi \\rangle \\equiv |\\phi \\rangle |\\psi \\rangle \\ .\n\\] Since exchange two particles twice gives the original state back, we must have \\(P_\\sigma^2 = 1\\), meaning its eigenvalues must be \\(\\eta \\equiv \\pm 1\\). Calling these eigenvectors \\(|\\Psi\\rangle_\\eta\\), this means \\[\nP_\\sigma |\\Psi\\rangle_\\eta = \\eta |\\Psi\\rangle_\\eta \\ .\n\\] Any tensor product state of two particles must be one of these two eigenstates. It’s easy to see that these eigenstates are just the symmetric and antisymmetric parts of the tensor product state, \\[\n\\begin{align*}\n|\\Psi\\rangle_{+} &= \\frac{1}{\\sqrt{2}} \\big(|\\psi \\rangle |\\phi \\rangle + |\\phi \\rangle |\\psi \\rangle \\big) \\ , \\\\\n|\\Psi\\rangle_{-} &= \\frac{1}{\\sqrt{2}} \\big(|\\psi \\rangle |\\phi \\rangle - |\\phi \\rangle |\\psi \\rangle \\big) \\ .\n\\end{align*}\n\\] Particles whose exchange eigenstates are \\(|\\Psi\\rangle_{+}\\) are called bosons, while particles whose exchange eigenstates are \\(|\\Psi\\rangle_{-}\\) are called fermions. Notice that fermions satisfy the important condition that both particles can never been in the same state, since then we’d have \\(|\\Psi\\rangle_{-} = 0\\), a non-normalizable state. This is a general reflection of the Pauli exclusion principle, which states that no two fermions can occupy the same state. They must always be distinct. Bosons, however, don’t have to satisfy the exclusion principle. This one distinction makes the behavior of bosons and fermions very different from each other.\nBut how do we know which of the two eigenstates a given pair of particles should have? It turns out this comes down to their spin. If each particle has integer total spin, then that particle is a boson. If each particle instead has half-integer total spin, then that particle is a fermion. This fact is consequence of the spin-statistics theorem, an important theorem of relativistic quantum field theory. We won’t bother to prove it here. Electrons are the canonical example of fermions, with spin \\(1/2\\). Photons are the canonical example of bosons, with spin \\(1\\). There are many more of each of course. In fact all particles in nature can be broken down into these two classes depending on whether they have integer or half-integer total spin.\nThis is all true for two particle systems, but in statistical mechanics we’re interested in \\(N\\)-particle systems, where \\(N\\) is typically a huge number. We’ll just state the result for \\(N\\)-particle systems of bosons or fermions without proving anything.\nLet \\(P_\\sigma\\) be the permutation operator that permutes the indexes \\(1, 2, \\cdots, N\\) to some permutation \\(\\sigma(1), \\sigma(2), \\cdots, \\sigma(N)\\). There will generally be \\(N!\\) such permutations. For a set of \\(N\\) bosons, we have \\[\n|\\Psi\\rangle_{+} = \\frac{1}{\\sqrt{N_{+}}} \\sum_\\sigma P_\\sigma | \\psi_1 \\rangle | \\psi_2 \\rangle \\cdots | \\psi_N \\rangle = \\frac{1}{\\sqrt{N_{+}}} \\sum_\\sigma | \\psi_{\\sigma(1)} \\rangle | \\psi_{\\sigma(2)} \\rangle \\cdots | \\psi_{\\sigma(N)} \\rangle \\ .\n\\] For a set of \\(N\\) fermions, we have \\[\n|\\Psi\\rangle_{-} = \\frac{1}{\\sqrt{N_{-}}} \\sum_\\sigma (-1)^{p(\\sigma)} P_\\sigma | \\psi_1 \\rangle | \\psi_2 \\rangle \\cdots | \\psi_N \\rangle = \\frac{1}{\\sqrt{N_{-}}} \\sum_\\sigma (-1)^{p(\\sigma)} | \\psi_{\\sigma(1)} \\rangle | \\psi_{\\sigma(2)} \\rangle \\cdots | \\psi_{\\sigma(N)} \\rangle \\ .\n\\] Here \\(p(\\sigma)\\) denotes the parity of the permutation \\(\\sigma\\). For even permutations \\(p(\\sigma)\\) is some even number, meaning \\((-1)^{p(\\sigma)} = 1\\). For odd permutations \\(p(\\sigma)\\) is some odd number, meaning \\((-1)^\\sigma = -1\\).\nIt’s easy to see that we can combine both equations into one by using \\(\\eta = \\pm 1\\) to write \\[\n\\boxed{\n|\\Psi\\rangle_\\eta = \\frac{1}{\\sqrt{N_\\eta}} \\sum_\\sigma \\eta^{p(\\sigma)} P_\\sigma | \\psi_1 \\rangle | \\psi_2 \\rangle \\cdots | \\psi_N \\rangle\n} \\ .\n\\] The factors \\(N_\\eta\\) are whatever normalization factors are needed so that \\(\\langle\\Psi|\\Psi\\rangle_\\eta=1\\). Intuitively, we’d expect that \\(N_\\eta = N!\\) given there are \\(N!\\) permutations. This is true for fermions provided we insist all states \\(\\psi_k\\) be unique to satisfy the exclusion principle. That is, \\(N_{-} = N!\\) for fermions, provided the sum is over distinct states only.\nHowever, for bosons taking \\(N_{+} = N!\\) would mean we’re overcounting due to the fact that some of the states in the sum are equivalent. To correct for this, we also have to divide by \\(\\prod_k n_k!\\), where \\(n_k\\) is the number of particles in state \\(\\psi_k\\). To see why this is true, take the case of 3 bosons. Symmetrizing we’d have \\[\n|\\psi_1 \\psi_2 \\psi_3 \\rangle_{+} = \\mathcal{N} \\big(|\\psi_1 \\psi_2 \\psi_3 \\rangle + |\\psi_2 \\psi_3 \\psi_1 \\rangle + |\\psi_1 \\psi_3 \\psi_2 \\rangle + |\\psi_2 \\psi_1 \\psi_3 \\rangle + |\\psi_3 \\psi_2 \\psi_1 \\rangle + |\\psi_3 \\psi_1 \\psi_2 \\rangle\\big) \\ ,\n\\] where \\(\\mathcal{N}\\) is whatever normalization constant is needed so that \\(\\langle \\psi_1 \\psi_2 \\psi_3 | \\psi_1 \\psi_2 \\psi_3 \\rangle_{+} = 1\\). In this case, it’s clear we have \\(\\mathcal{N}=\\frac{1}{\\sqrt{6}}\\). Now suppose two of the states are the same, say \\(\\psi_1=\\psi_2\\). Then the above sum reduces to \\[\n\\begin{align*}\n|\\psi_1 \\psi_1 \\psi_3 \\rangle_{+} &= \\mathcal{N} \\big(|\\psi_1 \\psi_1 \\psi_3 \\rangle + |\\psi_1 \\psi_3 \\psi_1 \\rangle + |\\psi_1 \\psi_3 \\psi_1 \\rangle + |\\psi_1 \\psi_1 \\psi_3 \\rangle + |\\psi_3 \\psi_1 \\psi_1 \\rangle + |\\psi_3 \\psi_1 \\psi_1 \\rangle\\big) \\\\\n&= 2\\mathcal{N} \\big(|\\psi_1 \\psi_1 \\psi_3 \\rangle + |\\psi_1 \\psi_3 \\psi_1 \\rangle + |\\psi_3 \\psi_1 \\psi_1 \\rangle\\big) \\\\\n&= \\frac{1}{\\sqrt{3}} \\big(|\\psi_1 \\psi_1 \\psi_3 \\rangle + |\\psi_1 \\psi_3 \\psi_1 \\rangle + |\\psi_3 \\psi_1 \\psi_1 \\rangle\\big) \\ .\n\\end{align*}\n\\] For this sum to normalize properly, we’d instead need to take \\(\\mathcal{N} = \\frac{1}{\\sqrt{12}} = \\frac{1}{\\sqrt{3!2!1!}}\\), which means \\(N_{+} = N! \\prod n_k!\\). The set \\(\\{n_k\\}\\) of all such \\(n_k\\) are called occupation numbers since they represent the number of particles that occupy a given state.\nFor bosons, each particle can occupy whichever states it likes. All we require is that the total number of bosons stay conserved. This means bosons should satisfy the constraint \\(\\sum_k n_k = N\\). We can think of occupation numbers as applying to fermions too. In that case, the exclusion principle requires each \\(n_k=0,1\\) only. They should still satisfy the constraint \\(\\sum_k n_k = N\\). This means we can streamline notation if we like and express the normalization constant in both cases by \\[\nN_\\eta \\equiv N! \\prod_k n_k! \\ .\n\\] It turns out we can even use occupation numbers to characterize the states of identical particles as well. Instead of representing \\(|\\Psi\\rangle_\\eta\\) as a combination of product states \\(| \\psi_1 \\rangle | \\psi_2 \\rangle \\cdots | \\psi_N \\rangle\\), we could represent the state \\(|\\Psi\\rangle_\\eta\\) by indicating what the occupation numbers are for each state \\(\\psi_k\\). That is, \\(|\\Psi\\rangle_\\eta = \\big|\\{n_k\\} \\big\\rangle\\).\nFor example, if all states are distinct we could represent \\(|\\psi_1 \\psi_2 \\psi_3 \\rangle_{+}\\) by the ket \\(|1,1,1 \\rangle\\). If exactly two of the three states are equal, say \\(\\psi_1=\\psi_2 \\neq \\psi_3\\) then we could represent the state by \\(|\\psi_1 \\psi_2 \\psi_3 \\rangle_{+} \\equiv |2,1 \\rangle\\). In both cases each ket sums to the total particle number. This representation of a joint state is called a Fock space representation. Fock space representations of identical particles are often nice since we avoid the need to explicitly sum over all valid permutations.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Quantum Gases</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/quantum-gases.html#quantum-ideal-gas",
    "href": "statistical-mechanics/quantum-gases.html#quantum-ideal-gas",
    "title": "Quantum Gases",
    "section": "Quantum Ideal Gas",
    "text": "Quantum Ideal Gas\nWith a discussion of identical particles out of the way we can now attempt to give a proper treatment to the quantum ideal gas. Recall in our prior treatment of the quantum ideal gas we had to assume all particles were distinguishable. In quantum mechanics this is generally forbidden, since even in principle we can’t imagine labeling any small particles without violating the uncertainty principle. We’ll now attempt to find the partition function for the quantum mechanical gas of identical particles. Since there is more subtlety involved in the quantum case than in the classical case, we’ll derive the partition function in two different representations, starting with the position representation.\n\nPosition Representation\nRather than calculate the partition function \\(Z\\) directly, we’ll start by finding the density matrix in the position representation. Recall for a single non-interacting particle in a box of volume \\(V \\gg \\lambda_T^3\\) we derived the formula \\[\n\\langle \\mathbf{x} | \\rho_1 | \\mathbf{x}' \\rangle = \\frac{1}{V} \\exp\\bigg(-\\frac{(\\mathbf{x}-\\mathbf{x}')^2}{\\lambda_T^2 / \\pi} \\bigg) \\ .\n\\] We’ll now attempt to derive a formula for the density matrix \\(\\big\\langle \\{\\mathbf{x}\\} | \\rho_1 | \\{\\mathbf{x}'\\} \\big\\rangle_\\eta\\) of \\(N\\) non-interacting particles in a box. The Hamiltonian is then \\(H = \\sum \\frac{\\mathbf{p}_i^2}{2m}\\), which again means the basis of wavevector kets \\(\\big|\\{\\mathbf{k}\\} \\big\\rangle\\) diagonalizes the \\(H\\), with \\[\nH \\big|\\{\\mathbf{k}\\} \\big\\rangle = \\sum_{i=1}^N \\frac{\\hbar^2 \\mathbf{k}_i^2}{2m} \\big|\\{\\mathbf{k}\\} \\big\\rangle \\ .\n\\] Inserting two resolutions of the identity over both \\(\\{\\mathbf{k}\\}\\) and \\(\\{\\mathbf{k}'\\}\\) and simplifying, we have \\[\n\\begin{align*}\n\\big\\langle \\{\\mathbf{x}\\} | \\rho | \\{\\mathbf{x}'\\} \\big\\rangle_\\eta &= \\sideset{}{'}\\sum_{\\{\\mathbf{k}\\}} \\sideset{}{'}\\sum_{\\{\\mathbf{k}'\\}} \\big\\langle \\{\\mathbf{x}\\} | \\{\\mathbf{k}\\} \\big\\rangle_\\eta \\ \\big\\langle\\{\\mathbf{k}\\} |\\rho| \\{\\mathbf{k}'\\} \\big\\rangle \\ \\big\\langle\\{\\mathbf{k}'\\} | \\{\\mathbf{x}'\\} \\big\\rangle_\\eta \\\\\n&= \\frac{1}{Z}\\sideset{}{'}\\sum_{\\{\\mathbf{k}\\}} \\sideset{}{'}\\sum_{\\{\\mathbf{k}'\\}} \\exp\\bigg(-\\frac{\\beta\\hbar^2}{2m} \\sum_{j=1}^N \\mathbf{k}_j^2 \\bigg) \\big\\langle \\{\\mathbf{x}\\} | \\{\\mathbf{k}\\} \\big\\rangle_\\eta \\ \\big\\langle\\{\\mathbf{k}\\} | \\{\\mathbf{k}'\\} \\big\\rangle \\ \\big\\langle\\{\\mathbf{k}'\\} | \\{\\mathbf{x}'\\} \\big\\rangle_\\eta \\\\\n&= \\frac{1}{Z}\\sideset{}{'}\\sum_{\\{\\mathbf{k}\\}} \\exp\\bigg(-\\frac{\\beta\\hbar^2}{2m} \\sum_{j=1}^N \\mathbf{k}_j^2 \\bigg) \\big\\langle \\{\\mathbf{x}\\} | \\{\\mathbf{k}\\} \\big\\rangle_\\eta \\ \\big\\langle\\{\\mathbf{k}\\} | \\{\\mathbf{x}'\\} \\big\\rangle_\\eta  \\ .\\\\\n\\end{align*}\n\\] Note the use of the restricted sum here. We’re constrained by the fact that there must be exactly \\(N\\) particles in the box, whether for fermions or bosons. To get rid of the constraint we just need to figure out how much we’re overcounting by in the sum. It turns out that overcounting factor is just \\(\\prod_{\\mathbf{k}} n_{\\mathbf{k}}! / N!\\), so we can just do the substitution \\[\n\\sideset{}{'}\\sum_{\\{\\mathbf{k}\\}} \\rightarrow \\sum_{\\{\\mathbf{k}\\}} \\frac{\\prod_{\\mathbf{k}} n_{\\mathbf{k}}!}{N!} \\ .\n\\] We also need to make sure to sum over all permutations for each term \\(\\big\\langle \\{\\mathbf{x}\\} | \\{\\mathbf{k}\\} \\big\\rangle_\\eta\\) and \\(\\big\\langle\\{\\mathbf{k}\\} | \\{\\mathbf{x}'\\} \\big\\rangle_\\eta\\). This will give a double sum over permutations with different parities \\(p\\) and \\(p'\\), contributing a normalization factor \\(N_\\eta = N! \\prod_{\\mathbf{k}} n_{\\mathbf{k}}!\\) that fortunately happens to cancel the \\(\\prod_{\\mathbf{k}} n_{\\mathbf{k}}!\\) prefactor from the constrained sum, \\[\n\\begin{align*}\n\\big\\langle \\{\\mathbf{x}\\} | \\rho | \\{\\mathbf{x}'\\} \\big\\rangle_\\eta &= \\frac{1}{Z}\\sum_{\\{\\mathbf{k}\\}} \\frac{\\prod_{\\mathbf{k}} n_{\\mathbf{k}}!}{N!} \\exp\\bigg(-\\frac{\\beta\\hbar^2}{2m} \\sum_{j=1}^N \\mathbf{k}_j^2 \\bigg) \\big\\langle \\{\\mathbf{x}\\} | \\{\\mathbf{k}\\} \\big\\rangle_\\eta \\ \\big\\langle\\{\\mathbf{k}\\} | \\{\\mathbf{x}'\\} \\big\\rangle_\\eta \\\\\n&= \\frac{1}{Z}\\sum_{\\{\\mathbf{k}\\}} \\frac{\\prod_{\\mathbf{k}} n_{\\mathbf{k}}!}{N!} \\exp\\bigg(-\\frac{\\beta\\hbar^2}{2m} \\sum_{j=1}^N \\mathbf{k}_j^2 \\bigg) \\sum_{\\sigma,\\sigma'} \\frac{\\eta^p \\eta^{p'}}{N! \\prod_{\\mathbf{k}} n_{\\mathbf{k}}!} \\big\\langle \\{\\mathbf{x}\\} | P_\\sigma \\{\\mathbf{k}\\} \\big\\rangle \\ \\big\\langle P_{\\sigma'} \\{\\mathbf{k}\\} | \\{\\mathbf{x}'\\} \\big\\rangle \\\\\n&= \\frac{1}{Z(N!)^2} \\sum_{\\sigma,\\sigma'} \\eta^p \\eta^{p'} \\sum_{\\{\\mathbf{k}\\}} \\exp\\bigg(-\\frac{\\beta\\hbar^2}{2m} \\sum_{j=1}^N \\mathbf{k}_j^2 \\bigg) \\big\\langle \\{\\mathbf{x}\\} | P_\\sigma \\{\\mathbf{k}\\} \\big\\rangle \\ \\big\\langle P_{\\sigma'} \\{\\mathbf{k}\\} | \\{\\mathbf{x}'\\} \\big\\rangle \\ .\\\\\n\\end{align*}\n\\] We’ll now use the usual density of states approximation for the sums over all \\(\\{\\mathbf{k}\\}\\). This of course assumes \\(V \\gg \\lambda_T^3\\) so that particle quantum interactions are relatively weak. Replacing the sum by an integral, and using the fact that \\(\\big\\langle \\{\\mathbf{x}\\} | P_\\sigma \\{\\mathbf{k}\\} \\big\\rangle\\) is just the Fourier transform weighting factor in \\(3N\\) dimensions, we have \\[\n\\big\\langle \\{\\mathbf{x}\\} | \\rho | \\{\\mathbf{x}'\\} \\big\\rangle_\\eta\n\\approx \\frac{1}{Z(N!)^2} \\sum_{\\sigma,\\sigma'} \\eta^p \\eta^{p'} \\int \\frac{d^{3N}\\mathbf{k}}{(2\\pi)^{3N}} \\exp\\bigg[\\sum_{j=1}^N \\bigg(-\\frac{\\beta\\hbar^2}{2m}\\mathbf{k}_j^2 + i\\big(\\mathbf{k}_{\\sigma(j)} \\cdot \\mathbf{x}_j - \\mathbf{k}_{\\sigma'(j)} \\cdot \\mathbf{x}'_j\\big) \\bigg)\\bigg] \\ .\n\\] This integral seems like another Gaussian integral, but we have to be careful here since the integration variables are over \\(\\{\\mathbf{k}\\}\\) and not \\(P_\\sigma \\{\\mathbf{k}\\}\\) or \\(P_{\\sigma'} \\{\\mathbf{k}\\}\\). We can move the permutations onto the position vectors instead by simply inverting them to get \\[\n\\begin{align*}\n\\big\\langle \\{\\mathbf{x}\\} | \\rho | \\{\\mathbf{x}'\\} \\big\\rangle_\\eta\n&= \\frac{1}{Z(N!)^2} \\sum_{\\sigma,\\sigma'} \\eta^p \\eta^{p'} \\int \\frac{d^{3N}\\mathbf{k}}{(2\\pi)^{3N}} \\ \\exp\\bigg[\\sum_{j=1}^N \\bigg(-\\frac{\\beta\\hbar^2}{2m}\\mathbf{k}_j^2 + i\\big(\\mathbf{k}_j \\cdot \\mathbf{x}_{\\sigma^{-1}(j)} - \\mathbf{k}_j \\cdot \\mathbf{x}'_{\\sigma'^{-1}(j)}\\big) \\bigg)\\bigg] \\\\\n&= \\frac{1}{Z(N!)^2} \\sum_{\\sigma,\\sigma'} \\eta^p \\eta^{p'} \\prod_{j=1}^N \\int \\frac{d^{3}\\mathbf{k}_j}{(2\\pi)^{3N}} \\ \\exp\\bigg[-\\frac{\\beta\\hbar^2}{2m}\\mathbf{k}_j^2 + i \\mathbf{k}_j \\cdot \\big(\\mathbf{x}_{\\sigma^{-1}(j)} - \\mathbf{x}'_{\\sigma'^{-1}(j)}\\big)\\bigg] \\\\\n&= \\frac{1}{Z(N!)^2} \\sum_{\\sigma,\\sigma'} \\eta^p \\eta^{p'} \\prod_{j=1}^N \\bigg(\\frac{1}{\\lambda_T^3} \\exp\\bigg[-\\frac{(\\mathbf{x}_{\\sigma^{-1}(j)} - \\mathbf{x}'_{\\sigma'^{-1}(j)})^2}{\\lambda_T^2/\\pi}\\bigg] \\bigg) \\ .\n\\end{align*}\n\\] Now, we can use the fact that the two permutations are now redundant by rewriting the double sum as a free sum over all \\(N!\\) permutations plus a sum over the relative permutations \\(Q \\equiv P'^{-1}P\\) to get \\[\n\\big\\langle \\{\\mathbf{x}\\} | \\rho | \\{\\mathbf{x}'\\} \\big\\rangle_\\eta = \\frac{1}{ZN!\\lambda_T^{3N}} \\sum_\\tau \\eta^q \\exp\\bigg[-\\sum_{j=1}^N\\frac{(\\mathbf{x}_j - \\mathbf{x}'_{\\tau(j)})^2}{\\lambda_T^2/\\pi}\\bigg] \\ .\n\\] Finally, to get the partition function, we can use the relation \\(\\text{tr } \\rho = 1\\) and solve for \\(Z\\) by integrating over all \\(\\{\\mathbf{x}\\}\\) to get \\[\n\\boxed{\nZ = \\frac{1}{N!\\lambda_T^{3N}} \\int d^{3N} \\mathbf{x} \\ \\sum_\\tau \\eta^q \\exp\\bigg[-\\sum_{j=1}^N\\frac{(\\mathbf{x}_j - \\mathbf{x}_{\\tau(j)})^2}{\\lambda_T^2/\\pi}\\bigg]\n} \\ .\n\\] It’s hard to parse what this is saying as is. To make it easier to analyze let’s write out the permutations in order of increasing parity. The zero-parity term involves no permutations at all, that is \\(Q=1\\). In that case the exponential vanishes to give \\(V^N\\), which implies \\(Z \\approx \\frac{1}{N!} \\big(\\frac{V}{\\lambda_T^3})^N\\). This is just the partition function for the classical ideal gas. We can also see right off where that \\(N!\\) term for identical particles came from in classical statistical mechanics. It falls right out of the quantum theory.\nThe next permutations involve one-parity terms of pairwise swaps. In this case, all but two of the exponentials vanish, giving a factor of \\(V^{N-2}\\). The remaining two terms we can convert to relative coordinates and integrate out another factor of \\(V\\). Since there are \\(\\binom{N}{2} = \\frac{N(N-1)}{2}\\) such terms, we get \\[\nZ \\approx \\frac{V^N}{N!\\lambda_T^{3N}} \\bigg(1 + \\frac{N^2}{2V} \\int d^3 \\boldsymbol{x} \\ \\eta e^{- 2\\pi r^2 / \\lambda_T^2} \\bigg) \\approx \\frac{V^N}{N!\\lambda_T^{3N}} \\bigg[1 + \\frac{\\eta N^2}{2V} \\bigg(\\frac{\\lambda_T^2}{2}\\bigg)^{3/2} + O\\bigg(\\frac{N^3}{V^2}\\bigg)\\bigg] \\ .\n\\] To see what’s going on let’s calculate the pressure. Letting \\(n=\\frac{N}{V}\\) be the density, the expression for \\(\\beta P\\) is evidently \\[\n\\beta P = \\frac{\\partial \\log Z}{\\partial V} = n - \\frac{\\eta}{2} \\bigg(\\frac{\\lambda_T^2}{2}\\bigg)^{3/2} n^2 + O(n^3) \\ .\n\\] This is clearly a virial expansion in terms of some kind of interaction potential \\(u(r)\\). The second virial coefficient in this case is \\[\nB_2(T) = -\\frac{\\eta}{2} \\bigg(\\frac{\\lambda_T^2}{2}\\bigg)^{3/2} \\ .\n\\] For bosons this coefficient is negative, meaning the pressure is reduced from that of the classical ideal gas due to bosonic attraction. For fermions the opposite is true, meaning the pressure is increased due to fermionic repulsion. As \\(T\\) increases these effects become less and less important since \\(\\lambda_T \\rightarrow 0\\), becoming essentially negligible in the classical limit.\nNow, recall from our discussion of classically interacting gases that virial expansions can be thought of as arising from a cluster expansion in terms of powers of the Mayer f-function \\(f(r) \\equiv e^{-\\beta u(r)}-1\\). This means we can think of the above expansion as arising from the presence of an effective potential \\(u(r) = -k_B T \\log (1 + f(r))\\). In our case we can read off from the expansion for \\(Z\\) that \\(f(r) = e^{-2\\pi r^2 / \\lambda_T^2}\\), hence we have \\[\nu(r) \\approx - k_B T \\log\\big( 1 + \\eta e^{-2\\pi r^2 / \\lambda_T^2}\\big) \\ .\n\\] This effective potential \\(u(r)\\) arises purely from the quantum mechanical behavior of identical particles, even if we assume they’re completely non-interacting as we would for the ideal gas. If we plot \\(u(r)\\) for \\(\\eta = \\pm 1\\) we get two potential curves like the ones shown in the following figure.\n\n\n\n\n\nFor fermions, \\(u(r)\\) goes to zero exponentially fast as \\(r \\rightarrow \\infty\\) and blows up as \\(r \\rightarrow 0\\). This reflects the exclusion principle, which essentially forbids fermions from getting too close to each other. As the particles get farther apart this fermionic repulsion dies off exponentially fast.\nFor bosons, \\(u(r)\\) still dies off exponentially fast as \\(r \\rightarrow \\infty\\), except now from below due to the attractive nature of bosons. Instead of blowing up as \\(r \\rightarrow 0\\) we instead get a finite value of \\(u(0) \\approx -k_B T \\log 2\\). The shape of this curve represents the fact that bosons prefer to be in the same state, yet they only feel this effect when very close to each other.\nOf course, this only a valid potential when the density is sufficiently small. For denser gases we’d need to include higher order corrections arising from multi-body quantum exchange interactions. This further complicates what the potential for identical particles looks like, but the rough idea is basically the same. Qualitatively speaking, bosons attract, while fermions repel.\n\n\nEnergy Representation\nWhile insightful, it’s pretty clear that the position representation is an unnatural way to compute the partition function for an ideal gas. We’ve already seen that the natural basis for this is the basis of wavevector states \\(|\\{\\mathbf{k}\\}\\rangle\\). In this basis, we have\n\\[\nZ = \\text{tr} \\ e^{-\\beta H} = \\sideset{}{'}\\sum_{\\{\\mathbf{k}\\}} \\langle \\{\\mathbf{k}\\} | e^{-\\beta \\sum_{i=1}^N \\varepsilon_{\\mathbf{k}_i}} | \\{\\mathbf{k}\\} \\rangle_\\eta \\ ,\n\\]\nwhere we’ve introduced the shorthand \\(\\varepsilon_\\mathbf{k}\\) to refer to the energy eigenvalue of a given particle with wavevector \\(\\mathbf{k}\\). In the usual case of an ideal non-relativistic particle in a box, we’d have \\(\\varepsilon_\\mathbf{k} = \\frac{\\hbar^2 \\mathbf{k}^2}{2m}\\). But in other cases it may differ. For example, we could also be describing a gas of ultra-relativistic particles in a box, where we’d have \\(\\varepsilon_\\mathbf{k} = \\hbar c |\\mathbf{k}|\\).\nAgain we’re dealing with a constrained sum due to the requirement that \\(N = \\sum n_\\mathbf{k}\\). Rather than write out the permutations explicitly as we did before, let’s instead work in Fock space this time by setting \\(| \\{\\mathbf{k}\\} \\rangle_\\eta = | \\{n_\\mathbf{k}\\} \\rangle\\). We then have \\[\nZ = \\sideset{}{'}\\sum_{\\{n_\\mathbf{k}\\}} \\langle \\{n_\\mathbf{k}\\} | e^{-\\beta \\sum_\\mathbf{k} n_\\mathbf{k} \\varepsilon_\\mathbf{k}} | \\{n_\\mathbf{k}\\} \\rangle = \\sideset{}{'}\\sum_{\\{n_\\mathbf{k}\\}} e^{-\\beta \\sum_\\mathbf{k} n_\\mathbf{k} \\varepsilon_\\mathbf{k}} \\ .\n\\] Of course, we still haven’t removed the constraint. To do that we’ll use a trick we’ve seen before. Namely, we’ll switch to the grand canonical formulation where \\(N\\) is allowed to take on any positive integer. Doing that removes the constraint, giving \\[\n\\mathcal{Z} = \\sum_{N=0}^\\infty e^{\\beta\\mu N} Z = \\sum_{\\{n_\\mathbf{k}\\}} e^{\\beta\\mu \\sum_\\mathbf{k} n_\\mathbf{k}} e^{-\\beta \\sum_\\mathbf{k} n_\\mathbf{k} \\varepsilon_\\mathbf{k}} = \\prod_\\mathbf{k} \\sum_{n_\\mathbf{k}} e^{-\\beta n_\\mathbf{k}\\big(\\varepsilon_\\mathbf{k} - \\mu\\big)} \\ .\n\\] Now, to do the sum over \\(n_\\mathbf{k}\\) we have to distinguish between the case for bosons and fermions. For fermions \\(n_\\mathbf{k}=0,1\\), which means we’re just summing two terms. For bosons \\(n_\\mathbf{k}=0,1,\\cdots\\), which gives a geometric series. We can combine both expressions into one by writing \\[\n\\mathcal{Z}_\\eta = \\prod_\\mathbf{k} \\bigg(1 + \\eta e^{-\\beta \\big(\\varepsilon_\\mathbf{k} - \\mu\\big)}\\bigg)^{-\\eta} \\ .\n\\] This means the log grand partition function is given by \\[\n\\log\\mathcal{Z}_\\eta = -\\eta \\sum_{\\mathbf{k}} \\log \\bigg(1 + \\eta e^{-\\beta \\big(\\varepsilon_\\mathbf{k} - \\mu\\big)}\\bigg) \\ .\n\\]\n\n\nQuantum Distributions\nAs is typical with the grand canonical formulation, one of the first things we want to do is calculate \\(N\\). Since the sum over all occupation numbers must equal \\(N\\), we have \\[\nN = \\frac{\\partial \\log\\mathcal{Z}_\\eta}{\\partial (\\beta\\mu)} = -\\eta \\sum_{\\mathbf{k}} \\frac{\\partial}{\\partial(\\beta\\mu)} \\log \\bigg(1 + \\eta e^{-\\beta \\big(\\varepsilon_\\mathbf{k} - \\mu\\big)}\\bigg)  = \\sum_{\\mathbf{k}} \\frac{1}{e^{\\beta(\\varepsilon_\\mathbf{k}-\\mu)} - \\eta} = \\sum_{\\mathbf{k}} \\langle n_\\mathbf{k} \\rangle \\ .\n\\] Evidently then, the mean occupation numbers are given by the formula \\[\n\\boxed{\n\\langle n_\\mathbf{k} \\rangle = \\frac{1}{e^{\\beta(\\varepsilon_\\mathbf{k}-\\mu)} - \\eta}\n} \\ .\n\\] This formula defines two distributions describing how many particles we can expect to occupy a given state when those particles are identical. For bosons this distribution is called the Bose-Einstein distribution, given by \\[\n\\langle n_\\mathbf{k} \\rangle = \\frac{1}{e^{\\beta(\\varepsilon_\\mathbf{k}-\\mu)} - 1} \\ ,\n\\] while for fermions the distribution is called the Fermi-Dirac distribution, given by \\[\n\\langle n_\\mathbf{k} \\rangle = \\frac{1}{e^{\\beta(\\varepsilon_\\mathbf{k}-\\mu)} + 1} \\ .\n\\] In the dilute limit we expect each \\(\\langle n \\rangle \\ll 1\\), which means \\(e^{\\beta(\\varepsilon_\\mathbf{k}-\\mu)} \\gg 1\\). In that limit, both distributions reduce to the classical distribution we expect for a particle of energy \\(\\varepsilon_\\mathbf{k}\\), namely the Maxwell-Boltzmann distribution given by \\[\n\\langle n_\\mathbf{k} \\rangle = e^{-\\beta(\\varepsilon_\\mathbf{k}-\\mu)} \\ .\n\\] We have seen how the Maxwell-Boltzmann distribution behaves already when we studied classical statistical mechanics. In the next few sections we’ll focus on the study of the Fermi-Dirac and Bose-Einstein distributions and their implications.\n\n\nEquations of State\nNow that we have the partition function we can proceed to calculate the equations of state for the quantum ideal gas. We’ll again assume that \\(V \\gg \\lambda_T^3\\) so that we can use the density of states to rewrite the log partition function as \\[\n\\log\\mathcal{Z}_\\eta \\approx -\\eta\\frac{g V}{(2\\pi)^3} \\int d^3 \\mathbf{k} \\  \\log \\bigg(1 + \\eta e^{-\\beta \\big(\\varepsilon_\\mathbf{k} - \\mu\\big)}\\bigg) \\ .\n\\]\nNotice we’ve now introduced a factor \\(g\\) in the density of state conversion. This constant is there to reflect the fact that at the quantum level particles also contain a spin state \\(s\\), which gives an extra \\(g=s(s+1)\\) degeneracy to each state. For example, for spin-half fermions like electrons we’d have \\(s=\\frac{1}{2}\\) and hence \\(g=2\\).\nFrom here on we’ll again assume the energy states \\(\\varepsilon_\\mathbf{k}\\) are those for the particle in the box, \\(\\varepsilon_\\mathbf{k} = \\frac{\\hbar^2\\mathbf{k}^2}{2m}\\). Let’s first calculate the expected particle number \\(N\\), or more conveniently the number density \\(n \\approx \\frac{N}{V}\\). Plugging in this choice of \\(\\varepsilon_\\mathbf{k}\\) and using the density of states conversion along with the fact that the integral is spherically symmetric, we have \\[\nn = \\frac{1}{V} \\sum_{\\mathbf{k}} \\langle n_\\mathbf{k} \\rangle\n\\approx \\frac{g}{(2\\pi)^3} \\int_0^\\infty 4\\pi k^2 dk \\ \\frac{1}{e^{-\\beta\\mu} e^{\\beta\\frac{\\hbar^2 k^2}{2m}} - \\eta} \\ .\n\\] Here it benefits to perform a change of variables. First we’ll reintroduce the fugacity \\(z \\equiv e^{\\beta\\mu}\\) to provide a more convenient variable to tune than the chemical potential \\(\\mu\\). Next we’ll use thermal deBroglie wavelength \\(\\lambda_T = \\frac{h}{(2\\pi m k_B T)^{1/2}}\\) to rewrite the expression \\(\\frac{\\beta\\hbar^2}{m} = \\frac{\\lambda_T^2}{2\\pi}\\). Last, we’ll define a change of variable from \\(k\\) to a new variable \\(x\\) defined by \\[\nx \\equiv \\frac{\\beta\\hbar^2}{2m} k^2 = \\frac{\\lambda_T^2}{4\\pi} k^2 \\quad \\Longrightarrow \\quad\n\\begin{cases}\nk = \\frac{2\\pi^{1/2}}{\\lambda_T} x^{1/2} \\\\\ndk = \\frac{\\pi^{1/2}}{\\lambda_T} x^{-1/2} dx \\\\\n\\end{cases} \\ .\n\\] Plugging each of these expressions back into the integral and simplifying, we get \\[\nn = \\frac{g}{(2\\pi)^3} \\frac{(2\\pi^{1/2})^5}{2\\lambda_T^3} \\int_0^\\infty dx \\ \\frac{x^{1/2}}{z^{-1} e^{x} - \\eta} = \\frac{g}{\\lambda_T^3} \\frac{1}{(1/2)!} \\int_0^\\infty dx \\ \\frac{x^{1/2}}{z^{-1} e^{x} - \\eta} \\ .\n\\] Here we used the fact that \\((1/2)! = \\sqrt{\\pi}/2\\) for reasons we’ll understand shortly. Let’s now calculate the energy \\(E\\), or more conveniently \\(\\beta\\varepsilon\\), where the energy density \\(\\varepsilon \\equiv \\frac{E}{V}\\), using a similar method. Using the same definitions, we have \\[\n\\begin{align*}\n\\beta\\varepsilon &= \\frac{\\beta}{V} \\sum_{\\mathbf{k}} \\varepsilon_\\mathbf{k} \\langle n_\\mathbf{k} \\rangle \\\\\n&\\approx \\beta\\frac{g}{(2\\pi)^3} \\int_0^\\infty 4\\pi k^2 dk \\ \\frac{\\frac{\\hbar^2 k^2}{2m}}{e^{-\\beta\\mu} e^{\\beta\\frac{\\hbar^2 k^2}{2m}} - \\eta} \\\\\n&= \\frac{g}{(2\\pi)^3} \\frac{(2\\pi^{1/2})^3}{2\\lambda_T^3} \\int_0^\\infty dx \\ \\frac{x^{3/2}}{z^{-1} e^{x} - \\eta} \\\\\n&= \\frac{3}{2} \\frac{g}{\\lambda_T^3} \\frac{1}{(3/2)!} \\int_0^\\infty dx \\ \\frac{x^{3/2}}{z^{-1} e^{x} - \\eta} \\ .\n\\end{align*}\n\\]\nFinally, let’s calculate the pressure, or really \\(\\beta P\\) again for simplicity. Recall by extensivity that we can write \\(\\log \\mathcal{Z} = \\beta P V\\). Thus, \\[\n\\begin{align*}\n\\beta P &= \\frac{1}{V} \\log\\mathcal{Z} \\\\\n&\\approx \\frac{-\\eta g}{(2\\pi)^3} \\int d^3 \\mathbf{k} \\  \\log \\bigg(1 + \\eta e^{-\\beta \\big(\\varepsilon_\\mathbf{k} - \\mu\\big)}\\bigg) \\\\\n&= \\frac{-\\eta g}{(2\\pi)^3} \\int_0^\\infty 4\\pi k^2 dk \\  \\log \\bigg(1 + \\eta z e^{-\\frac{\\beta\\hbar^2 k^2}{2m}}\\bigg) \\\\\n&= \\frac{-\\eta g}{(2\\pi)^3} \\frac{(2\\pi^{1/2})^5}{2\\lambda_T^3} \\int_0^\\infty dx \\ x^{1/2} \\log \\bigg(1 + \\eta z e^{-x}\\bigg) \\\\\n&= \\frac{g}{\\lambda_T^3} \\frac{1}{(3/2)!} \\int_0^\\infty dx \\ \\frac{x^{3/2}}{z^{-1} e^x - \\eta} \\ .\n\\end{align*}\n\\] In the last line we used integration by parts to move the derivative from \\(\\log \\big(1 + \\eta z e^{-x}\\big)\\) to \\(x^{1/2}\\) and made use of the fact that the boundary terms vanish. The reason we did this was to show how all of the above expressions involve an integral that more or less looks alike apart from some parameter. Let’s give this class of integrals a name by defining \\[\n\\boxed{\nf_s^\\eta (z) \\equiv \\frac{1}{(s-1)!} \\int_0^\\infty dx \\ \\frac{x^{s-1}}{z^{-1} e^x - \\eta}\n} \\ .\n\\] We’ll study the properties of these functions in the next section. For now just observe that if we make this substitution, we can simplify the above expressions by writing \\[\n\\boxed{\n\\begin{align*}\nn &= \\frac{g}{\\lambda_T^3} f_{3/2}^\\eta(z) \\\\\n\\beta \\varepsilon &= \\frac{3}{2} \\frac{g}{\\lambda_T^3} f_{5/2}^\\eta(z) \\\\\n\\beta P &= \\frac{g}{\\lambda_T^3} f_{5/2}^\\eta(z) \\\\\n\\end{align*}\n} \\ .\n\\] We can immediately read off the important relation \\(\\varepsilon = \\frac{3}{2} P\\), which just says \\(E = \\frac{3}{2} PV\\). We’ve seen this before for the classical ideal gas. Evidently the relationship holds for the quantum ideal gas as well, both for fermions and bosons. However, the relation between \\(P\\) and \\(n\\) is no longer as straightforward as it was in the classical case. To figure that relationship out we’ll need to get a series expansion for \\(f_s^\\eta(z)\\) so we can express \\(z\\) as a function of \\(n\\) and hence get a virial expansion of \\(P\\) as a function of \\(n\\).\n\n\nSpecial Functions\nGiven these special functions \\(f_s^\\eta(z)\\) seem to occur so frequently in quantum statistics, perhaps we should study their properties a little bit before proceeding to a more detailed study of the quantum ideal gas. These special functions are a well-known class of mathematical functions known as polylogarithms. They’re a generalization of yet another class of special functions called zeta functions. Zeta functions, denoted \\(\\zeta_s\\) are defined by the arithmetic series expression \\[\n\\zeta_s \\equiv \\sum_{n=1}^\\infty \\frac{1}{n^s} = 1 + \\frac{1}{2^s} + \\frac{1}{3^s} + \\cdots \\ .\n\\] For real-valued \\(s\\), zeta functions converge whenever \\(s &gt; 1\\) and diverge otherwise. However, even when these functions do converge we can’t generally find \\(\\zeta_s\\) in closed form for most values of \\(s\\). In fact we only have closed-form expressions for even integer values of \\(s\\). For example, it’s known that \\(\\zeta_2 = \\frac{\\pi^2}{6}\\) and \\(\\zeta_4 = \\frac{\\pi^4}{90}\\). Even \\(\\zeta_3 \\approx 1.202\\) doesn’t have a closed-form expression and has to be found numerically. It’s evidently a new irrational number now known as Apery’s constant.\nPolylogarithms, usually denoted \\(\\text{Li}_s(z)\\), generalize zeta functions by turning them into a power series in some variable \\(z\\), \\[\n\\text{Li}_s(z) \\equiv \\sum_{n=1}^\\infty \\frac{z^n}{n^s} = z + \\frac{z^2}{2^s} + \\frac{z^3}{3^s} + \\cdots \\ .\n\\] Evidently when \\(z=1\\) we just get back the zeta functions, i.e. \\(\\text{Li}_s(1) = \\zeta_s\\). Polylogarithms only converge in general when \\(|z| &lt; 1\\), though they can be analytically continued to cover almost all of real \\(z\\). When \\(z &gt; 0\\) the functions asymptote at \\(z=1\\) when \\(s \\leq 1\\), otherwise they meet the \\(z=1\\) line at some finite value, which is of course \\(\\zeta_s\\). Here’s a plot of the polylogarithms for a few different values of \\(s\\). The curves for \\(s=0,\\frac{1}{2},1\\) go to infinity at \\(z=1\\), while those for \\(s=\\frac{3}{2},2,\\frac{5}{2}\\) are finite-valued at \\(z=1\\).\n\n\n\n\n\nSince there’s no constant term in the series it evidently must be the case that \\(\\text{Li}_s(0)=0\\). Moreover, when \\(z\\) is small we must have \\(\\text{Li}_s(z) \\approx z\\), which as we’ll soon see turns out to be important to us.\nThe name “polylogarithm” comes from the fact that the functions satisfy the differentiation ladder relationship \\[\n\\frac{d}{dz} \\text{Li}_s(z) = \\frac{\\text{Li}_{s-1}(z)}{z} \\ ,\n\\] which combined with the fact that \\(\\text{Li}_1(z) = -\\log (1-z)\\) implies that when \\(s\\) is an integer these functions are just successive derivatives of logarithms. This ladder relation gives us an easy way to find other values of \\(\\text{Li}_s(z)\\) provided we know the functional form for some \\(s\\), though it only works for finding integer steps of \\(s\\).\nPerhaps most importantly for our purposes, polylogarithms can be re-expressed in an integral form that we’ll recognize. Observe that by using the expression for a geometric series plus the integral representation of the factorial function that we can rewrite the polylogarithm as \\[\n\\begin{align*}\n\\text{Li}_s(z) &= \\sum_{n=1}^\\infty \\frac{z^n}{n^s} \\\\\n&= \\sum_{n=1}^\\infty \\frac{z^n}{(s-1)!} \\frac{(s-1)!}{n^s}\\\\\n&= \\sum_{n=1}^\\infty \\frac{z^n}{(s-1)!} \\int_0^{\\infty} dx \\ x^{s-1} e^{-nx} \\\\\n&= \\frac{1}{(s-1)!} \\int_0^{\\infty} dx \\ x^{s-1} \\sum_{n=1}^\\infty \\big(z e^{-x}\\big)^n \\\\\n&= \\frac{1}{(s-1)!} \\int_0^{\\infty} dx \\ \\frac{x^{s-1}}{z^{-1} e^x - 1} \\ .\n\\end{align*}\n\\] Note this also means we instantly have an integral expression for the zeta function as well by setting \\(z=1\\), \\[\n\\zeta_s = \\frac{1}{(s-1)!} \\int_0^{\\infty} dx \\ \\frac{x^{s-1}}{e^x - 1} \\ .\n\\] Evidently the integral form for \\(\\text{Li}_s(z)\\) is just the expression for \\(f_s^\\eta(z)\\) that we saw before when \\(\\eta = 1\\)! That is, \\(f_s^{+}(s) = \\text{Li}_s(z)\\) exactly. What about when \\(\\eta = -1\\) though? We can get a similar relationship by just replacing \\(z\\) with \\(-z\\) in the series to get \\(\\text{Li}_s(z)=-\\text{Li}_s(-z)\\). We can combine the two expressions into one by writing \\[\nf_s^\\eta(z) = \\eta \\text{Li}_s(\\eta z) = \\sum_{n=1}^\\infty \\frac{\\eta^{n+1} z^n}{n^s} = z + \\frac{\\eta z^2}{2^s} + \\frac{z^3}{3^s} + \\frac{\\eta z^4}{4^s} + \\cdots \\ .\n\\] That is, the functions \\(f_s^\\eta(z)\\) we’re seeing fall out of quantum statistics are just polylogarithms, with the caveat that when \\(\\eta=-1\\) the series is alternating on even powers. This alternating behavior for \\(\\eta=-1\\) means that those functions turn out to be defined for all \\(z\\), not just when \\(|z| &lt; 1\\). In fact, we’ll see later that \\(f_s^{-}(z) \\sim \\frac{1}{s!} (\\log z)^s\\) when \\(z\\) is really large.\n\n\n\n\n\nIn either case, we can see that \\(f_s^\\eta(z) \\approx z\\) when \\(z\\) is small. Treating \\(z\\) as the fugacity, \\(z\\) will be small at high temperatures, meaning in the high temperature limit our equation of state becomes \\(\\beta P \\approx n\\). This expression is of course none other the classical ideal gas law \\(PV = N k_B T\\). Evidently the quantum ideal gases reduces to the classical ideal gas in the high temperature limit, as we’d expect, both for fermions as well as bosons. The distinction between the two types of particles washes out in a sense with higher temperatures.\nBut what about at lower temperatures? First let’s define \\(d \\equiv \\frac{n \\lambda_T^3}{g}\\), which we’ll call the degeneracy factor for reasons we’ll see later. If we again want pressure as a function of density we’d need to invert the power series for \\(d = d(z)\\) to find \\(z = z(d)\\). We’ve seen before how to systematically do this. Starting with the power series for \\(d = f_{3/2}^\\eta (z)\\) we have \\[\nd = z + \\frac{\\eta z^2}{2^{3/2}} + \\frac{z^3}{3^{3/2}} + O(z^4) \\ .\n\\] Now suppose \\(z\\) can be expanded in a power series in \\(d\\) as \\[\nz = a_1 d + a_2 d^2 + a_3 d^3 + O(d^4) \\ .\n\\] When \\(z\\) is infinitesimal we see \\(d \\approx z\\), which means \\(a_1 = 1\\). To get the higher order coefficients we’ll substitute this expression into the formula for \\(d=d(z)\\) and match powers. We have \\[\n\\begin{align*}\nd &= \\big(d + a_2 d^2 + a_3 d^3\\big) + \\frac{\\eta}{2^{3/2}} \\big(d + a_2 d^2 + a_3 d^3\\big)^2 + \\frac{1}{3^{3/2}} \\big(d + a_2 d^2 + a_3 d^3\\big)^3 + O(d^4) \\\\\n&= \\big(d + a_2 d^2 + a_3 d^3\\big) + \\frac{\\eta}{2^{3/2}} (d^2 + 2 a_2 d^3) + \\frac{1}{3^{3/2}} d^3 + O(d^4) \\\\\n&= d + \\bigg(a_2 + \\frac{\\eta}{2^{3/2}}\\bigg) d^2 + \\bigg(a_3 + 2 \\frac{\\eta}{2^{3/2}} a_2 + \\frac{1}{3^{3/2}}\\bigg) d^3 + O(d^4) \\ .\n\\end{align*}\n\\] Setting the higher-order coefficients to zero, we get \\(a_2 = - \\frac{\\eta}{2^{3/2}}\\) and \\(a_3 = \\frac{1}{4}  -\\frac{1}{3^{3/2}}\\). Thus, up to \\(O(d^3)\\) we have \\[\nz = d - \\frac{\\eta}{2^{3/2}} d^2 + \\bigg(\\frac{1}{4}  -\\frac{1}{3^{3/2}}\\bigg) d^3 + O(d^4) \\ .\n\\] Plugging this expression back into \\(\\beta P\\) and simplifying, we get \\[\n\\begin{align*}\n\\beta P &= \\frac{g}{\\lambda_T^3} \\bigg(z + \\frac{\\eta}{2^{5/2}} z^2 + \\frac{1}{3^{5/2}} z^3 + O(z^4)\\bigg) \\\\\n&= \\frac{g}{\\lambda_T^3} \\bigg\\{\\bigg[d - \\frac{\\eta}{2^{3/2}} d^2 + \\bigg(\\frac{1}{4}  -\\frac{1}{3^{3/2}}\\bigg) d^3\\bigg] + \\frac{\\eta}{2^{5/2}} \\bigg[d - \\frac{\\eta}{2^{3/2}} d^2 + \\bigg(\\frac{1}{4}  -\\frac{1}{3^{3/2}}\\bigg) d^3\\bigg]^2 \\\\\n&+ \\frac{1}{3^{5/2}} \\bigg[d - \\frac{\\eta}{2^{3/2}} d^2 + \\bigg(\\frac{1}{4}  -\\frac{1}{3^{3/2}}\\bigg) d^3\\bigg]^3 + O(d^4)\\bigg\\} \\\\\n&= \\frac{g}{\\lambda_T^3} \\bigg[d - \\frac{\\eta}{2^{5/2}} d^2 + \\bigg(\\frac{1}{8} - \\frac{2}{3^{5/2}}\\bigg) d^3 + O(d^4) \\bigg] \\ .\n\\end{align*}\n\\] Finally, to get a virial expansion up to \\(O(n^3)\\) we substitute \\(d = \\frac{n \\lambda_T^3}{g}\\) to get \\[\n\\beta P = n - \\frac{\\lambda_T^3}{g} \\frac{\\eta}{2^{5/2}} n^2 + \\frac{\\lambda_T^6}{g^2} \\bigg(\\frac{1}{8} - \\frac{2}{3^{5/2}}\\bigg) n^3 + O(n^4) \\ .\n\\] Notice how even with no interactions present in the quantum ideal gas we still get a virial expansion. In particular, notice the second virial coefficient \\(B_2(T) = -\\frac{\\lambda_T^3}{g} \\frac{\\eta}{2^{5/2}}\\). For bosons \\(B_2\\) is negative, meaning the pressure is reduced from that of the classical ideal gas. On the other hand, for fermions \\(B_2\\) is positive, meaning the pressure is increased from that of the classical ideal gas. It’s as if there are interactions present arising from quantum statistics, which we also saw more explicitly before using the position representation. In either case, since \\(\\lambda_T \\rightarrow 0\\) in the high temperature limit, \\(\\beta P \\rightarrow n\\) as we’d expect.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Quantum Gases</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/quantum-gases.html#degenerate-gases",
    "href": "statistical-mechanics/quantum-gases.html#degenerate-gases",
    "title": "Quantum Gases",
    "section": "Degenerate Gases",
    "text": "Degenerate Gases\nWe’ve largely gone as far as we can by treating bosons and fermions together. We’ve shown that in the classical limit of \\(d=f_{3/2}^\\eta (z) \\ll 1\\) the quantum ideal gas becomes the classical ideal gas, both for fermions and bosons. We’ve also shown how we can add in quantum corrections to the pressure at lower temperatures via a kind of virial expansion.\nBut what about in the other limit, the low temperature limit where \\(d=f_{3/2}^\\eta (z) \\gg 1\\)? In this degenerate limit expansions in powers of \\(z\\) no longer hold and we need to approach things differently. We’ll start by examining the degenerate limit for fermions, the so-called degenerate fermi gas. Afterwards we’ll separately look at the degenerate limit for bosons, the degenerate boson gas.\n\nDegenerate Fermi Gas\nTo understand the behavior of fermions at low temperatures we need a different kind of representation for the polylogarithm, namely an asymptotic series that’s valid when \\(z\\) becomes infinitely large. We’ll need to derive an asymptotic series for \\(f_s^{-}(z)\\). We’ll derive a full expansion later. But for now we’ll focus on the extreme low temperature limit where \\(T \\approx 0\\), meaning \\(\\log z \\gg 1\\). Recall that by definition we have \\[\nf_s^{-}(z) = \\frac{1}{(s-1)!} \\int_0^{\\infty} dx \\ \\frac{x^{s-1}}{z^{-1} e^x + 1} \\ .\n\\] Now, observe that the integrand has the form \\(x^{s-1} \\langle n \\rangle\\) where \\(\\langle n \\rangle = (z^{-1} e^x + 1)^{-1}\\) is the expected occupation number. We know that for fermions the occupation number should change abruptly from one to zero at low temperatures. If we plot \\(\\langle n \\rangle\\)as a function of \\(x\\) we get something like the figure shown below. As \\(z\\) gets larger the curve of \\(\\langle n \\rangle\\) approaches more and more of a step function that goes rapidly to zero around \\(x \\approx \\log z\\).\n\n\n\n\n\nThis means that to a crude approximation we can treat \\(\\langle n \\rangle\\) as a step function that jumps from one to zero at \\(x = \\log z\\), which means near zero temperature we can approximately say \\[\nf_s^{-}(z) = \\frac{1}{(s-1)!} \\int_0^{\\infty} dx \\ \\frac{x^{s-1}}{z^{-1} e^x + 1} \\approx \\frac{1}{(s-1)!} \\int_0^{\\log z} dx \\ x^{s-1} = \\frac{(\\log z)^s}{s!} \\ .\n\\] Using the identity \\(\\log z = \\beta\\mu\\), we then get \\[\n\\begin{align*}\nN &= \\frac{gV}{\\lambda_T^3} \\frac{(\\beta\\mu)^{3/2}}{(3/2)!} \\ , \\\\\nE &= \\frac{3}{2 \\beta} \\frac{gV}{\\lambda_T^3} \\frac{(\\beta\\mu)^{5/2}}{(5/2)!} \\ .\n\\end{align*}\n\\] Note the chemical potential \\(\\mu\\) here should be thought of as a function of temperature \\(T\\). Near \\(T=0\\) the chemical potential should be some constant value. This value \\(\\varepsilon_F \\equiv \\mu_0\\) is a constant with units of energy. It’s called the Fermi energy, which in terms of the density \\(n\\) is apparently given by \\[\n\\varepsilon_F = \\frac{2\\pi\\hbar^2}{m} \\bigg(\\frac{3\\sqrt{\\pi}n}{4g}\\bigg)^{2/3} = \\frac{\\hbar^2}{2m} \\bigg(\\frac{6\\pi^2 n}{g}\\bigg)^{2/3} \\ .\n\\] Physically, we can think of the Fermi energy as the energy of the last occupied state in the Fermi gas. In a Fermi gas, at low temperatures the states will fill up from smallest to largest momentum in successive order. The state occupied by the final particle in the gas will have the highest momentum, which we call the Fermi momentum, given by \\[\n\\varepsilon_F \\equiv \\frac{\\hbar^2}{2m} \\mathbf{k}_F^2 \\ .\n\\] Curiously, we can derive the expression for the Fermi energy directly from its definition as the last occupied state. If this is indeed the highest momentum state, this means in \\(k\\)-space all other particles must lie in or on the sphere whose radius is \\(k_F=|\\mathbf{k}_F|\\). If we assume each particle can take on only their spin degrees of freedom \\(g=2s+1\\), this means we’d have \\[\nN = \\sum_{k \\leq k_F} g \\approx \\frac{gV}{(2\\pi)^3} \\int_0^{k_F} 4\\pi k^2 dk = \\frac{gVk_F^3}{6\\pi^2} \\ .\n\\] Substituting in \\(\\varepsilon_F = \\frac{\\hbar^2}{2m} k_F^2\\) into this formula and solving for \\(\\varepsilon_F\\) in terms of \\(n = \\frac{N}{V}\\) gives the expected result for \\(\\varepsilon_F\\).\nSince it’s useful we’ll go ahead and also define a Fermi temperature \\(T_F\\) using the relation \\(\\varepsilon_F \\equiv k_B T_F\\). If we now take the ratio \\(\\frac{E}{N}\\) to get the energy in terms of particle number like we’re used to, we get \\[\nE = \\frac{3}{5} N \\varepsilon_F = \\frac{3}{5} N k_B T_F \\ .\n\\] Interestingly, it seems the energy of a Fermi gas doesn’t go to zero at zero temperature. It tends to a positive constant. A Fermi gas always has energy due to the exclusion principle preventing the particles from falling into lower energy states. Similarly, a Fermi gas must have non-zero pressure at zero temperature as well since \\(E = \\frac{3}{2} PV\\) implies \\[\nP V = \\frac{2}{5} N \\varepsilon_F = \\frac{2}{5} N k_B T_F \\ .\n\\] This defines a Fermi pressure \\(P_F \\equiv \\frac{2}{5} n \\varepsilon_F\\), usually called degeneracy pressure. It again arises from the exclusion principle due to the fact that we can’t squeeze the fermions arbitrarily close together.\n\nSommerfeld Expansion\nThese expressions tell us what to expect exactly at zero temperature. But what about near zero temperature? How do the equations of state interpolate between these values and the expected classical ones? To investigate this we’ll need to consider more than just the first term in the asymptotic expansion. We need the full asymptotic series now, which we derive below.\nLet’s consider again the integral definition of \\(f_s^{-}(z)\\) and perform integration by parts by moving one of the derivatives from \\(x^{s-1}\\) to \\(\\langle n \\rangle = \\big(z^{-1} e^x + 1\\big)^{-1}\\). Then we have \\[\n\\begin{align*}\nf_s^{-}(z) &= \\frac{1}{(s-1)!} \\int_0^{\\infty} dx \\ \\frac{x^{s-1}}{z^{-1} e^x + 1} \\\\\n&= \\frac{1}{s!} \\int_0^{\\infty} dx \\ x^s \\frac{d}{dx} \\frac{-1}{z^{-1} e^x + 1} \\\\\n&\\approx \\frac{1}{s!} \\int_{-\\infty}^{\\infty} dx \\ x^s \\frac{d}{dx} \\frac{-1}{z^{-1} e^x + 1} \\ .\n\\end{align*}\n\\] The last step requires some justification. Since \\(\\langle n \\rangle\\) is approximately a step function when \\(z \\gg 1\\) its derivative must be approximately a delta function. This means the integrand will be sharply peaked around \\(\\log z\\) and so extending the limits of integration to the whole real line is essentially immaterial, though convenient.\nWe’ll now make a change of variable. Let \\(u = x - \\log z\\), meaning \\(x = \\log z + u\\) and \\(dx = du\\). Substituting, doing a binomial expansion on \\(x^s = (\\log z + u)^s\\), and then reversing the integration by parts, we get \\[\n\\begin{align*}\nf_s^{-}(z) &\\approx \\frac{1}{s!} \\int_{-\\infty}^{\\infty} du \\ (\\log z + u)^s \\frac{d}{du} \\frac{-1}{e^u + 1} \\\\\n&= \\frac{1}{s!} \\int_{-\\infty}^{\\infty} du \\sum_{\\alpha=0}^\\infty \\binom{s}{\\alpha} u^\\alpha (\\log z)^{s-\\alpha} \\frac{d}{du} \\frac{-1}{e^u + 1} \\\\\n&= \\frac{(\\log z)^s}{s!} \\sum_{\\alpha=0}^\\infty \\frac{s!}{\\alpha!(s-\\alpha)!} (\\log z)^{-\\alpha} \\int_{-\\infty}^{\\infty} du \\ u^\\alpha \\frac{d}{du} \\frac{-1}{e^u + 1} \\\\\n&= \\frac{(\\log z)^s}{s!} \\sum_{\\alpha=0}^\\infty \\frac{s!}{\\alpha!(s-\\alpha)!} (\\log z)^{-\\alpha} \\alpha \\int_{-\\infty}^{\\infty} du \\ \\frac{u^{\\alpha-1}}{e^u + 1} \\ .\n\\end{align*}\n\\] Now, the integrand in the last line, call it \\(g(u)\\), is always either an odd or even function depending on \\(\\alpha\\). When \\(\\alpha\\) is odd the integral must be zero, and when \\(\\alpha\\) is even the integral must be twice the positive part, both by symmetry. Moreover, the positive part of the integral is just \\((2\\alpha-1)! f_{2\\alpha}^{-}(1)\\) since \\(u\\) is a dummy variable and \\(z=1\\). This means we have\n\\[\n\\begin{align*}\nf_s^{-}(z) &= \\frac{(\\log z)^s}{s!} \\sum_{\\alpha=0}^\\infty \\frac{s!}{(s-\\alpha)!} (\\log z)^{-\\alpha} \\frac{1}{(\\alpha-1)!} \\int_{-\\infty}^{\\infty} du \\ \\frac{u^{\\alpha-1}}{e^u + 1} \\\\\n&= \\frac{(\\log z)^s}{s!} \\sum_{\\alpha=0}^\\infty \\frac{s!}{(s-2\\alpha)!} (\\log z)^{-2\\alpha} \\frac{2}{(2\\alpha-1)!} \\int_0^{\\infty} du \\ \\frac{u^{2\\alpha-1}}{e^u + 1} \\\\\n&= \\frac{(\\log z)^s}{s!} \\sum_{\\alpha=0}^\\infty \\frac{s!}{(s-2\\alpha)!} (\\log z)^{-2\\alpha} 2f_{2\\alpha}^{-}(1) \\\\\n\\end{align*}\n\\] Now, the terms \\(f_{2\\alpha}^{-}(1)\\) are kind of like zeta functions since \\[\nf_s^{-}(1) = -\\text{Li}_s (-1) = \\sum_{n=1}^\\infty \\frac{(-1)^n}{n^s} = 1 - \\frac{1}{2^s} + \\frac{1}{3^s} - \\cdots \\ .\n\\] These functions are called eta functions, denoted \\(\\eta_s\\), and are related to zeta functions via \\(\\eta_s = \\big(1-2^{1-s}\\big) \\zeta_s\\). This can be seen by separating the odd and even parts of the series and doing some factoring. Using this relationship along with the fact that zeta function values for even integers \\(s=2\\alpha\\) have closed form solutions, we finally have \\[\n\\begin{align*}\nf_s^{-}(z) &= \\frac{(\\log z)^s}{s!} \\sum_{\\alpha=0}^\\infty \\frac{s!}{(s-2\\alpha)!} (\\log z)^{-2\\alpha} 2\\big(1-2^{1-2\\alpha}\\big) \\zeta_{2\\alpha} \\\\\n&= \\frac{(\\log z)^s}{s!} \\bigg[1 + \\zeta_2 \\frac{s(s-1)}{(\\log z)^2} + \\frac{7\\zeta_4}{4}\\frac{s(s-1)(s-2)(s-3)}{(\\log z)^4} + O\\big((\\log z)^{-6}\\big) \\bigg] \\\\\n&= \\frac{(\\log z)^s}{s!} \\bigg[1 + \\frac{\\pi^2}{6} \\frac{s(s-1)}{(\\log z)^2} + \\frac{7\\pi^4}{360}\\frac{s(s-1)(s-2)(s-3)}{(\\log z)^4} + O\\big((\\log z)^{-6}\\big) \\bigg] \\ .\n\\end{align*}\n\\] This final series is known as the Sommerfeld expansion. Notice the leading term in the series is just \\(f_s^{-}(z) \\approx \\frac{(\\log z)^s}{s!}\\), which we already expect. This leads to the Fermi values derived before. The higher order terms in the expansion involve reciprocal powers of \\(\\log z\\), which act to give small corrections to the asymptotic expansion at large \\(z\\).\nWe can now use the Sommerfeld expansion to finally calculate the first few corrections to the equations of state at zero temperature. To do that we need to get the series for \\(s=\\frac{3}{2}\\) and \\(s=\\frac{5}{2}\\). Working only to the first correction, we have \\[\n\\begin{align*}\nf_{3/2}^{-}(z) &= \\frac{(\\log z)^{3/2}}{(3/2)!} \\bigg[1 + \\frac{\\pi^2/8}{(\\log z)^2} + O\\big((\\log z)^{-4}\\big) \\bigg] \\ , \\\\\nf_{5/2}^{-}(z) &= \\frac{(\\log z)^{5/2}}{(5/2)!} \\bigg[1 + \\frac{5\\pi^2/8}{(\\log z)^2} + O\\big((\\log z)^{-4}\\big) \\bigg] \\ .\n\\end{align*}\n\\] Again using the fact that \\(\\log z = \\beta\\mu\\) we can read off the corrections to the equations of state. First, we have \\[\nN = \\frac{gV}{\\lambda_T^3} f_{3/2}^\\eta(z) = \\frac{gV}{\\lambda_T^3} \\frac{(\\beta\\mu)^{3/2}}{(3/2)!} \\bigg[1 + \\frac{\\pi^2}{8} \\bigg(\\frac{k_B T}{\\varepsilon_F}\\bigg)^2 + O(T^4) \\bigg] \\ .\n\\] We can use this formula to solve for the chemical potential \\(\\mu\\) by rearranging terms to get \\[\n\\mu = \\frac{\\hbar^2}{2m} \\bigg(\\frac{6\\pi^2 N}{gV}\\bigg)^{2/3} \\bigg[1 + \\frac{\\pi^2}{8} \\bigg(\\frac{k_B T}{\\varepsilon_F}\\bigg)^2 + O(T^4) \\bigg]^{-2/3} = \\varepsilon_F \\bigg[1 - \\frac{\\pi^2}{12}\\bigg(\\frac{T}{T_F}\\bigg)^2 + O(T^4) \\bigg] \\ .\n\\] This means the chemical potential is evidently a downward-sloping parabola at low temperatures with a vertex at the Fermi energy \\(\\varepsilon_F\\). We also expect classically that \\(\\mu \\sim -T \\log T\\) at high temperatures, so the two curves should smoothly interpolate somehow, as shown in the figure below. The transition regime occurs somewhere around the Fermi temperature \\(T_F\\).\n\n\n\n\n\nNext up, we can find the pressure by using the above expansion for \\(\\mu\\) to get $$ \\[\\begin{align*}\nP &= \\frac{g}{\\beta\\lambda_T^3} f_{5/2}^\\eta(z) \\\\\n&= \\frac{g}{\\beta\\lambda_T^3} \\frac{(\\beta\\mu)^{5/2}}{(5/2)!} \\bigg[1 + \\frac{5\\pi^2}{8} \\bigg(\\frac{k_B T}{\\varepsilon_F}\\bigg)^2 + O(T^4) \\bigg] \\\\\n&= \\frac{g}{\\beta\\lambda_T^3} \\frac{(\\beta\\varepsilon_F)^{5/2}}{(5/2)!} \\bigg[1 - \\frac{\\pi^2}{12}\\bigg(\\frac{T}{T_F}\\bigg)^2 + O(T^4) \\bigg]^{5/2} \\bigg[1 + \\frac{5\\pi^2}{8} \\bigg(\\frac{T}{T_F}\\bigg)^2 + O(T^4) \\bigg] \\\\\n&= P_F \\bigg[1 + \\frac{5\\pi^2}{12}\\bigg(\\frac{T}{T_F}\\bigg)^2 + O(T^4) \\bigg] \\ .\n\n\\end{align*}\\] $$ Evidently the correction to the pressure is also quadratic, but this time the parabola is upward sloping, causing pressure to increase with temperature. In the classical limit of course we expect pressure to become linear \\(P \\sim T\\), with a turning point occurring again around the Fermi temperature \\(T_F\\). This is shown in the figure below.\n\n\n\n\n\nWith the pressure in hand we can now proceed to calculate the average internal energy using the formula \\(E = \\frac{3}{2} PV\\). We get \\[\nE = \\frac{3}{5} N k_B T_F \\bigg[1 + \\frac{5\\pi^2}{12}\\bigg(\\frac{T}{T_F}\\bigg)^2 + O(T^4) \\bigg] \\ .\n\\] Clearly the energy will also be an upward-sloping parabola at low temperatures and have \\(E \\sim T\\) at high temperatures. Having energy as a function of temperature we can proceed to calculate the heat capacity for the Fermi gas at low temperatures. Differentiating with respect to \\(T\\) we get \\[\nC = \\frac{\\partial E}{\\partial T} = N k_B \\frac{\\pi^2}{2} \\bigg(\\frac{T}{T_F}\\bigg) + O(T^3) \\ .\n\\] Importantly, notice that at low temperatures the heat capacity of a Fermi gas is linear with a cubic correction. As \\(T\\) approaches the Fermi temperature \\(T_F\\) the heat capacity turns over and starts to behave classically, as shown in the figure below.\n\n\n\n\n\nPerhaps the most important application of this result is to metals. Metals can be thought of as solids where internal electrons are allowed to move freely as an interacting Fermi gas. We already saw in a previous chapter that typical non-conducting solids are dominated by phonon effects at low temperatures, causing \\(C \\sim T^3\\) when \\(T \\ll T_D\\), where \\(T_D\\) is the solid’s Debeye temperature. Metals slightly modify this result by having \\[\nC \\sim \\gamma T + \\alpha T^3\n\\] at low temperatures. We can imagine the linear term arising from the Fermi gas effects of the free electrons. In fact this isn’t exactly true since electrons do interact with each other via Coulomb forces. They’re not free particles, hence not ideal. Nevertheless, if we imagine the Coulomb interactions as being adiabatic in the sense of being “turned on slowly”, then their energy at low temperatures turns out to be the same as if the gas were ideal. Since the heat capacity of a metal at low temperatures would go something like \\[\nC \\sim N k_B \\bigg[\\frac{\\pi^2}{2} \\bigg(\\frac{T}{T_F}\\bigg) + \\frac{12\\pi^4}{5} \\bigg(\\frac{T}{T_D}\\bigg)^3 \\bigg] \\ ,\n\\] we can see at what temperature the Fermi and phonon effects become comparable by equating terms and solving for \\(T\\) to get \\[\nT \\sim \\sqrt{\\frac{5T_D^3}{24\\pi T_F}} \\ .\n\\] For a typical metal we’d have something like \\(T_D \\sim 10^2 \\ ^\\circ \\text{K}\\) and \\(T_F \\sim 10^4 \\ ^\\circ \\text{K}\\), meaning the linear term would become important only when temperatures get down to around \\(T \\sim 1 \\ ^\\circ \\text{K}\\).\n\n\nExample: Paramagnetism\nAs another interesting application of the theory of Fermi gases, let’s consider the case of paramagnetism. A paramagnet is any material whose electron spins tend to align themselves parallel to an applied external magnetic field. Typically paramagnetic behavior is observed in materials whose atoms have an odd number of electrons so that some of them are left unpaired. Only these unpaired electrons contribute anything significant to the magnetization. Atoms with an even number of electrons experience a different and much weaker effect known as diamagnetism, where the electron spins tend to align themselves antiparallel to the external field. Both effects are significantly weaker than ferromagnetism, often by a factor of \\(10^4\\) or more.\nThe tendency of a material to respond to an external magnetic field \\(\\mathbf{B}\\) is captured via its magnetization vector \\(\\mathbf{M}\\). Its magnitude \\(M\\) is the average magnetic dipole moment per unit volume, which can be more usefully related to the difference between densities of up-spin to down-spin unpaired electrons by \\[\nM \\equiv \\frac{\\langle m \\rangle}{V} = \\mu_B \\frac{N_+ - N_-}{V} \\ ,\n\\] where \\(\\mu_B \\equiv \\frac{e\\hbar}{2m_ec} \\approx 5.8 \\cdot 10^{-9} \\ \\text{eV} \\cdot \\text{G}^{-1}\\) is a constant known as the Bohr magneton. The magnetization depends on the strength of the external field. We can relate the two via a constituency relation whose form depends both on the material as well as the strength of the external field. In the simplest case where the material is isotropic and \\(\\mathbf{B}\\) is sufficiently weak, \\(\\mathbf{M}\\) will be approximately linear in the auxiliary field \\(\\mathbf{H} \\equiv \\mathbf{B} - 4\\pi\\mathbf{M}\\), with \\(\\mathbf{M} \\approx \\chi \\mathbf{H}\\), where \\(\\chi\\) is a proportionality constant known as the magnetic susceptibility. In the limit of a weak field we can approximate \\(\\mathbf{H} \\approx \\mathbf{B}\\) and hence write \\(\\mathbf{M} \\approx \\chi \\mathbf{B}\\). Taking the derivative of the magnitude of both sides and reminding ourselves we’re in the weak field limit of \\(B \\rightarrow 0\\), we evidently thus have \\[\n\\chi = \\frac{\\partial M}{\\partial B} \\bigg |_{B=0} \\ .\n\\] The susceptibility \\(\\chi\\) expresses essentially all of the material-specific properties that contribute to the magnetization. It’s thus useful to study its properties, for instance its dependence on thermodynamic variables like temperature or density.\nFor paramagnetic materials, we can express the Hamiltonian for a single electron to a decent approximation by \\[\nH_1 = \\frac{\\mathbf{p}^2}{2m} + \\mu_B \\boldsymbol{\\sigma} \\cdot \\mathbf{B} \\ ,\n\\] where \\(m=m_e\\) is the mass of the electron and \\(\\boldsymbol{\\sigma}\\) is the Pauli operator. It’s not too hard to see that the eigenstates of the \\(\\boldsymbol{\\sigma} \\cdot \\mathbf{B}\\) operator alone are two states \\(|\\pm\\rangle\\) with energies \\(\\varepsilon_{\\pm} = \\pm B\\). To get the full energy eigenvalues we instead need to use the joint states \\(|\\mathbf{k}, \\pm\\rangle\\). In terms of the joint states, the energy eigenvalues are given by \\[\n\\varepsilon_{\\mathbf{k}, \\pm} = \\frac{\\hbar^2 \\mathbf{k}^2}{2m} \\pm \\mu_B B \\ .\n\\] Since electrons are fermions, if we’re interested in low temperature behaviors we’ll need to treat the problem as a Fermi gas. This means we’ll need to proceed from here by again calculating the grand partition function \\(\\mathcal{Z}\\) and going from there. We have \\[\n\\begin{align*}\n\\mathcal{Z} &= \\sum_{N=0}^\\infty e^{\\beta\\mu N} \\text{ tr } e^{-\\beta H} \\\\\n&= \\prod_\\mathbf{k} \\sum_{n_{\\mathbf{k}, \\pm}} e^{-\\beta n_{\\mathbf{k}, \\pm}\\big(\\varepsilon_{\\mathbf{k}, \\pm} - \\mu\\big)} \\\\\n&= \\prod_\\mathbf{k} \\bigg(1 + e^{-\\beta \\big(\\varepsilon_{\\mathbf{k}} - \\mu + \\mu_B B\\big)}\\bigg) \\bigg(1 + e^{-\\beta \\big(\\varepsilon_{\\mathbf{k}} - \\mu - \\mu_B B\\big)}\\bigg) \\\\\n&= \\prod_\\mathbf{k} \\bigg(1 + e^{-\\beta \\big(\\varepsilon_{\\mathbf{k}} - \\mu_+\\big)}\\bigg) \\bigg(1 + e^{-\\beta \\big(\\varepsilon_{\\mathbf{k}} - \\mu_-\\big)}\\bigg) \\\\\n\\end{align*}\n\\]\nHere we’ve define \\(\\mu_\\pm \\equiv \\mu \\mp \\mu_B B\\) to be effective chemical potentials and \\(z_\\pm \\equiv e^{\\beta\\mu_\\pm}\\) to be the effective fugacities. From here, we can take the logarithm and simplify by again using the density of states and the same substitutions to get \\[\n\\begin{align*}\n\\log \\mathcal{Z} &\\approx \\frac{2V}{(2\\pi)^3} \\int d^3 \\mathbf{k} \\ \\bigg[\\log \\bigg(1 + z e^{-\\frac{\\beta\\hbar^2}{2m} \\mathbf{k}^2} e^{-\\beta \\mu_B B}\\bigg) + \\log \\bigg(1 + z e^{-\\frac{\\beta\\hbar^2}{2m} \\mathbf{k}^2} e^{\\beta \\mu_B B}\\bigg)\\bigg] \\\\\n&= \\frac{2V}{\\lambda_T^3} \\frac{1}{(3/2)!} \\int_0^\\infty dx \\ \\bigg[\\frac{x^{3/2}}{z_{+}^{-1} e^x + 1} + \\frac{x^{3/2}}{z_{-}^{-1} e^x + 1}\\bigg] \\\\\n&= \\frac{2V}{\\lambda_T^3} \\big[f_{5/2}^{-}\\big(z_+\\big) + f_{5/2}^{-}\\big(z_-\\big)\\big] \\ .\n\\end{align*}\n\\] Note we used the fact that the spin degeneracy for an electron is \\(g=2\\). From here we can proceed to calculate the mean up-spin and down-spin densities \\(n_\\pm = \\frac{N_\\pm}{V}\\). Using the differentiation ladder relation for polylogarithms, we just have \\[\nn_\\pm = \\frac{1}{V} \\frac{\\partial \\log\\mathcal{Z}}{\\partial (\\beta\\mu_\\pm)} = \\frac{z_\\pm}{V} \\frac{\\partial \\log\\mathcal{Z}}{\\partial z_\\pm} = \\frac{2}{\\lambda_T^3} f_{3/2}^{-}\\big(z_\\pm\\big) \\ .\n\\] This means the magnetization \\(M\\) is just given by \\[\nM = \\frac{2}{\\lambda_T^3} \\big[f_{3/2}^{-}\\big(z_+\\big) + f_{3/2}^{-}\\big(z_-\\big)\\big] \\ ,\n\\] from which we can conclude the susceptibility \\(\\chi\\) is given by \\[\n\\chi = \\frac{\\partial M}{\\partial B} \\bigg |_{B=0} = \\frac{4\\beta\\mu_B^2}{\\lambda_T^3} f_{1/2}^{-}(z) \\ .\n\\] Since this expression isn’t all that informative as is let’s analyze the behavior of \\(\\chi(T)\\) in the high and low temperature limits. It’ll be useful to write things in terms of \\(N\\), which we can get from the relation \\[\nN = N_+ + N_- = \\frac{2V}{\\lambda_T^3} \\big[f_{3/2}^{-}\\big(z_+\\big) + f_{3/2}^{-}\\big(z_-\\big)\\big] \\ .\n\\] At high temperatures we can use the fact that \\(f_{1/2}^{-}(z) \\approx z\\) to get \\(N \\approx \\frac{4V}{\\lambda_T^3} z\\) and hence \\[\n\\chi(T) \\approx \\frac{n\\mu_B^2}{k_B T} \\equiv \\frac{C}{T} \\ .\n\\] This is a well-known result for paramagnetic materials, known as Curie’s Law. As the temperature of the material increases its susceptibility decreases in constant proportion. Of course, this law fails in the low temperature limit.\nIn the low temperature limit we can use the Sommerfeld expansion in the weak field limit to write \\(f_s^{-}(z_\\pm) \\approx \\frac{\\beta^s\\mu^s}{s!}\\). From here, we can express \\(N \\approx \\frac{4V}{(3/2)!} \\frac{\\beta^{3/2}}{\\lambda_T^3} \\varepsilon_F^{3/2}\\) and plug this back into \\(\\chi\\) to get the following relation in the low temperature limit, \\[\n\\chi(T) \\approx \\frac{3\\mu_B^2 n}{2k_B T_F} \\bigg[1 - \\frac{\\pi^2}{12} \\bigg(\\frac{T}{T_F}\\bigg)^2 + O(T^4) \\bigg] \\ .\n\\] As we’d expect, the susceptibility goes to a positive constant \\(\\chi_F\\) in the low temperature limit. The first quadratic correction is negative, meaning \\(\\chi(T)\\) will decrease and eventually go like \\(\\chi(T) \\sim \\frac{C}{T}\\) in the high temperature limit, as shown below.\n\n\n\n\n\n\n\n\nDegenerate Bose Gas\nWe’ll now consider the case of the degenerate Bose gas at low temperatures. Bosons at low temperatures behave quite differently from fermions. While fermions form a Fermi sphere of states of ever-increasing momentum, bosons instead eventually all pile into their ground state in a phenomenon known as Bose-Einstein Condensation.\nUnlike with the fermi function \\(f_s^{-}(z)\\) which is well-defined for all \\(z\\), the boson function \\(f_s^{+}(z)\\) is only well-defined when \\(|z| \\leq 1\\). To see why this is the case physically and not just mathematically, consider again the Bose-Einstein distribution \\[\n\\langle n_\\mathbf{k} \\rangle = \\frac{1}{e^{\\beta(\\varepsilon_\\mathbf{k}-\\mu)} - 1} \\ .\n\\] Since \\(\\langle n_\\mathbf{k} \\rangle\\) is an occupation number it must be non-negative. This can only happen if \\(\\mu \\leq \\varepsilon_\\mathbf{k}\\) for any value of \\(\\varepsilon_\\mathbf{k}\\). Since \\(\\min \\varepsilon_\\mathbf{k} = 0\\) is the smallest energy possible, this means we must have \\(\\mu \\leq 0\\). Since we expect \\(\\mu\\) to increase as \\(T\\) decreases, it’s reasonable to expect that \\(\\mu \\rightarrow 0\\) as \\(T \\rightarrow 0\\). And since \\(\\mu\\) goes to zero like \\(\\mu \\sim k_B T \\log \\frac{n\\lambda_T^3}{g}\\), this means we must have \\(z \\rightarrow 1\\) as \\(T \\rightarrow 0\\). Thus, studying the low temperature limit for bosons is essentially equivalent to studying the behavior of \\(f_s^{+}(z)\\) as \\(z \\rightarrow 1\\) from below.\nAs we saw before, the polylogarithm increases monotonically with \\(z\\), hitting the finite value of \\(\\zeta_s = f_s^{+}(1)\\) at \\(z=1\\) provided \\(s &gt; 1\\), or blowing up to infinity at \\(z=1\\) otherwise. Together these imply we should have \\[\n\\frac{n\\lambda_T^3}{g} = f_{3/2}^{+}(z) \\leq \\zeta_{3/2} \\approx 2.61 \\ .\n\\] But physically this doesn’t quite make sense at low temperatures. We generally think of \\(n=\\frac{N}{V}\\) as being fixed, reflecting in essence the conservation of mass. But the only way \\(n\\) can stay fixed as \\(T \\rightarrow 0\\) is for \\(f_{3/2}^{+}(z) \\rightarrow \\infty\\) as \\(\\lambda_T \\rightarrow \\infty\\). But this isn’t happening here since \\(f_{3/2}^{+}(z) \\rightarrow \\zeta_{3/2}\\) instead. So what’s going on?\nIf we step back and think about the quantum mechanics of the situation, we should realize that the lowest energy state each particle can occupy is its ground state. It would thus make sense at the lowest temperatures for particles to start to move into their ground states. Though non-obvious, our formulas aren’t keeping track of the particles in the ground state at all due to the subtleties in the density of states approximation, which expressed in terms of the energy is given by \\[\n\\sum_{\\mathbf{k}} \\approx \\frac{(2m)^{3/2} V}{4\\pi^2\\hbar^3} \\int dE \\ \\sqrt{E} \\ .\n\\] Because of the \\(\\sqrt{E}\\) weight inside the integrand, the ground state energy \\(E=0\\) doesn’t contribute at all to the integral. When temperatures are away from zero this isn’t a major issue since comparatively few particles are in their ground states. But very near zero temperature it becomes a much bigger deal.\nWe can attempt to correct for this efficiency by counting the ground state contributions separately from the excited states. For the excited states we’ll continue to use the density of states approximations, which gives the results we saw before. For the ground states, all we have to do is observe that the Bose-Einstein distribution says the expected number of particles in the ground state at a given fugacity \\(z\\) is just \\[\nN_0 \\approx \\langle n_0 \\rangle = \\frac{1}{z^{-1} - 1} = \\frac{z}{1-z} \\ .\n\\] All we have to do is break the density up into two pieces, the ground state density \\(n_0\\) and the excited state density \\(n_&gt;\\), \\[\nN = N_0 + N_&gt; = \\frac{z}{1-z} + \\frac{gV}{\\lambda_T^3} f_{3/2}^{+}(z) \\ .\n\\] We can define a useful critical temperature \\(T_c\\) by seeing at what temperature \\(\\frac{N\\lambda_T^3}{gV} = \\zeta_{3/2}\\), which turns out to be \\[\nT_c \\equiv \\frac{2\\pi\\hbar^2}{mk_B} \\bigg(\\frac{N}{\\zeta_{3/2} gV}\\bigg)^{2/3} \\ .\n\\] The critical temperature evidently tells us something about how many particles occupy the ground state. The fraction of total particles in the ground state or excited states at a given temperature is evidently \\[\n\\frac{N_0}{N} = 1 - \\frac{gV}{N\\lambda_T^3} \\zeta_{3/2} = 1 - \\bigg(\\frac{T}{T_c}\\bigg)^{3/2} \\quad , \\quad \\frac{N_&gt;}{N} = \\frac{gV}{N\\lambda_T^3} \\zeta_{3/2} = \\bigg(\\frac{T}{T_c}\\bigg)^{3/2} \\ .\n\\] Notice \\(N_&gt; \\approx N\\) when \\(T \\geq T_c\\), so we need only worry about the excited states. But when \\(T \\approx 0\\) the opposite is true, with all particles crowding into the ground state to give \\(N \\approx N_0\\). We can see this tradeoff between occupied states in the figure below.\n\n\n\n\n\nThis phenomenon where bosons all pile into their ground state below some temperature is called Bose-Einstein Condensation or BEC. Note that critical temperatures are generally very close to zero, for example water has a critical temperature of about \\(T_c \\approx 0.06 \\ ^\\circ\\text{K}\\). This means for BEC to be seen at all a gas needs to be cooled to almost exactly \\(T=0\\).\nIn a similar vein, we can find formulas for the pressure and energy at low temperatures. In these cases, the contribution from the ground state is negligible in the thermodynamic limit since they’re a factor of \\(N\\) less than the excited state contributions. This means for all \\(T\\) we can safely write \\[\nP = k_B T \\frac{g}{\\lambda_T^3} f_{5/2}^{+}(z) \\quad , \\quad E = \\frac{3}{2} k_B T\\frac{gV}{\\lambda_T^3} f_{5/2}^{+}(z) \\ .\n\\] When \\(T &lt; T_c\\) we just need to replace \\(f_{5/2}^{+}(z)\\) by \\(\\zeta_{5/2} \\approx 1.41\\) to get the correct results near \\(T=0\\), \\[\nP = k_B T \\frac{g}{\\lambda_T^3} \\zeta_{5/2} \\quad , \\quad E = \\frac{3}{2} k_B T \\frac{gV}{\\lambda_T^3} \\zeta_{5/2} \\ .\n\\] In particular, notice that when \\(T &lt; T_c\\) both the pressure and energy go like \\(T^{5/2}\\), while perhaps strangely the pressure doesn’t depend at all on the density \\(n=\\frac{N}{V}\\) anymore since the ground state particles no longer contribute to the pressure. This means even though \\(P = n k_B T\\) in the high temperature limit, at low temperatures it always follows the same curve, as shown below.\n\n\n\n\n\nAs is pretty much custom by now, we’ll differentiate energy with respect to temperature to get the heat capacity. To do this we need to keep the \\(f_{5/2}^{+}(z)\\) in the formula even below \\(T_c\\) since \\(z\\) itself depends implicitly on temperature. One can then show using the relation \\(N = \\frac{gV}{\\lambda_T^3} f_{3/2}^{+}(z)\\) and the ladder relationship \\(\\frac{d}{dz} f_s^{+}(z) = \\frac{1}{z} f_{s-1}^{+}(z)\\) that \\[\n\\begin{align*}\nC = \\frac{\\partial E}{\\partial T} &= \\frac{15}{4} \\frac{gV}{\\lambda_T^3} k_B f_{5/2}^{+}(z) + \\frac{3}{2} \\frac{gV}{\\lambda_T^3} k_B T \\frac{df_{5/2}^{+}(z)}{dz} \\frac{\\partial z}{\\partial T} \\\\\n&= \\frac{3}{2} k_B \\frac{gV}{\\lambda_T^3} \\bigg[\\frac{5}{2} f_{5/2}^{+}(z) - \\frac{3}{2} \\frac{\\big(f_{3/2}^{+}(z)\\big)^2}{f_{1/2}^{+}(z)}\\bigg] \\ .\n\\end{align*}\n\\] When \\(T \\gg T_c\\) we can use the approximation \\(f_s^{+}(z) \\approx z\\) to recover the classical result of \\(C = \\frac{3}{2} N k_B\\). When \\(T &lt; T_c\\) the second term goes to zero since \\(f_{1/2}^{+}(z) \\rightarrow \\infty\\) as \\(z \\rightarrow 1\\). In that limit we evidently have \\[\nC = \\frac{15}{4} k_B \\frac{gV}{\\lambda_T^3} \\zeta_{5/2} = \\frac{15}{4} \\frac{\\zeta_{5/2}}{\\zeta_{3/2}} \\bigg(\\frac{T}{T_c}\\bigg)^{3/2} \\ .\n\\] Evidently near zero temperature the heat capacity of a boson goes like \\(T^{3/2}\\), which is very different from fermions. The way the two limits join in this case though is particularly interesting. It turns out they join at a kink above \\(\\frac{3}{2} Nk_B\\) as shown below.\n\n\n\n\n\nTo see why this is true we need to study the behavior when \\(T &gt; T_c\\) but \\(T \\approx T_c\\). This can be seen by expanding the heat capacity when \\(T &gt; T_c\\) and observing that the corrections increase the heat capacity from \\(\\frac{3}{2} N k_B\\). This expansion turns out to be \\[\nC = \\frac{3}{2} N k_B \\bigg[1 + \\frac{\\lambda_T^3}{2^{7/2}} n + O(n^2) \\bigg] \\ .\n\\] This lack of smoothness in the heat capacity can be thought of as a phase transition at \\(T=T_c\\). Bosons below the critical temperature can be thought of as a distinct state of matter. We can further see this by looking at the compressibility \\(\\kappa_T\\), \\[\n\\kappa_T = \\frac{1}{V} \\frac{\\partial V}{\\partial P} \\bigg |_{T,N} = \\frac{1}{n} \\frac{\\partial n / \\partial z}{\\partial P / \\partial z} \\bigg |_{T,N} = \\frac{1}{nk_BT} \\frac{f_{1/2}^{+}(z)}{f_{3/2}^{+}(z)} \\ .\n\\] Notice as \\(z \\rightarrow 1\\) at the critical temperature that \\(f_{1/2}^{+}(z) \\rightarrow \\infty\\) and so \\(\\kappa_T \\rightarrow \\infty\\) as well. This means the isotherms of the \\(PV\\)-diagram become flat when \\(T&lt;T_c\\) similar to the way they do for the van der Waals interaction, indicating coexistence.\nAnother example of a low-temperature phase transition for bosons is a different phenomenon known as superfluidity. For example, helium is known to come in two common isotopes, helium-3 and helium-4. Helium-3 is a fermion since it contains 2 protons, 2 electrons, and a single neutron. Meanwhile, helium-4 is a boson since it contains 2 protons, 2 electrons, and 2 neutrons. At typical pressures helium never forms a solid at low temperatures. It instead forms a superfluid, which is a liquid with many similar properties to BEC. Superfluids have the interesting property that they have zero viscosity, meaning they can seep through whatever container they’re in when the temperature gets below some critical temperature \\(T_c\\). For helium-4 this temperature is known to be about \\(T_c \\approx 2.2 \\ ^\\circ\\text{K}\\) at standard pressure.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Quantum Gases</span>"
    ]
  }
]