[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Personal Notes",
    "section": "",
    "text": "Preface\nThis page contains notes I’ve taken over time for several different subjects of interest. Currently these subjects include\n\nClassical Mechanics\nElectrodynamics\nCircuit Analysis\nQuantum Mechanics\nStatistical Mechanics\n\nFeel free to use whatever you find helpful.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "classical-mechanics/newtonian-mechanics.html",
    "href": "classical-mechanics/newtonian-mechanics.html",
    "title": "Newtonian Mechanics",
    "section": "",
    "text": "Point Particles\nIn nature, an object is made of matter. It can be composed of many different molecules arranged in intricate and complicated ways. Further, each molecule is itself made of atoms, and each atom is itself made up of subatomic particles. Trying to model the motion of an object would be extremely cumbersome if we insisted on modeling the dynamics of each subatomic particle.\nInstead, it’s convenient to make abstractions. The most convenient abstraction to make is that we can describe the global behavior of an object as if it were a point object with no width. It can’t spin or deform. It’s one indivisible thing. We call these point particles.\nWe’ll think of a point particle as following some trajectory in the 3-dimensional Euclidean space \\(\\mathbb{R}^{3}\\). The trajectory or position is a time-dependent vector\n\\[\n\\mathbf{x}(t) = x(t)\\mathbf{e}_x + y(t)\\mathbf{e}_y + z(t)\\mathbf{e}_z.\n\\] A moving particle also has associated to it a velocity vector given by\n\\[\n\\mathbf{v} = \\mathbf{\\dot x} = \\frac{d\\mathbf{x}}{dt}.\n\\] Perhaps the most fundamental goal of classical mechanics is to find these two vectors as a function of time. In the Newtonian formulation, if we want to find a particle’s trajectory, we start with the particle’s acceleration vector \\[\n\\mathbf{a} = \\mathbf{\\dot v} = \\mathbf{\\ddot x} = \\frac{d^2\\mathbf{x}}{dt^2},\n\\] and match it with the force vector \\(\\mathbf{F}\\) via Newton’s Second Law to get a second-order differential equation for \\(\\mathbf{x}(t)\\).",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Newtonian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/newtonian-mechanics.html#newtons-laws",
    "href": "classical-mechanics/newtonian-mechanics.html#newtons-laws",
    "title": "Newtonian Mechanics",
    "section": "Newton’s Laws",
    "text": "Newton’s Laws\nNewton’s Laws efficiently encapsulate the fundamental physics of classical mechanics. They’re stated below specifically for a point particle, or body, but can be extended to more complex systems as well.\n\nA body remains at rest, or in motion at a constant speed in a straight line, unless acted upon by a force. That is,\n\\[\n\\mathbf{F} = \\mathbf{0} \\Rightarrow \\mathbf{v}=const.\n\\]\nWhen a body is acted upon by a force, the time rate of change of its acceleration is proportional to the force. That is, \\[\n\\mathbf{F} = m \\mathbf{a}.\n\\]\nIf two bodies exert forces on each other, these forces have the same magnitude but opposite directions. That is, \\[\n\\mathbf{F}_{12} = \\mathbf{F}_{21}.\n\\]\n\n\n\n\n\n\nForces are vectors, which means they obey the superposition principle, and can be analyzed in components. Position, velocity, and acceleration are vectors as well. The proportionality constant between \\(\\mathbf{F}\\) and \\(\\mathbf{a}\\) is called the mass \\(m\\). Loosely speaking, the mass of an object is a measure of its inertia or resistance to motion.\nThe functional form of the forces themselves depend on the particular type of forces applied. Some common forces are:\n\nGravitational Force: \\(\\mathbf{F} = -\\frac{GMm}{r^2} \\mathbf{e}_r\\)\nCoulomb Force: \\(\\mathbf{F} = k_e \\frac{Qq}{r^2} \\mathbf{e}_r\\)\nHarmonic Oscillator: \\(\\mathbf{F} = -k\\mathbf{x}\\)\nLorentz Force: \\(\\mathbf{F} = q\\mathbf{E} + \\frac{q}{c}\\mathbf{v} \\times \\mathbf{B}\\)\nThrust: \\(\\mathbf{F} = - |\\mathbf{v}_{ex}| \\dot m \\mathbf{e}_v\\)\n\n\n\n\n\nNormal Forces: \\(\\mathbf{F} = \\mathbf{N}\\)\nTension Forces: \\(\\mathbf{F} = \\mathbf{T}\\)\nFrictional Forces: \\(\\mathbf{F} = -\\mu |\\mathbf{N}| \\mathbf{e}_v\\)\nDrag Forces: \\(\\mathbf{F} = -f(\\mathbf{v}) \\mathbf{e}_v \\approx -a\\mathbf{v} -b|\\mathbf{v}|^2\\mathbf{e}_v\\)\nCentrifugal Forces: \\(\\mathbf{F} = m\\boldsymbol{\\omega} \\times (\\mathbf{x} \\times \\boldsymbol{\\omega})\\)\nCoriolis Forces: \\(\\mathbf{F} = 2m \\mathbf{v} \\times \\boldsymbol{\\omega}\\)\nBuoyant Forces: \\(\\mathbf{F} = - \\rho_{liq} V_{sub} \\mathbf{g}\\)",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Newtonian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/newtonian-mechanics.html#conservation-laws",
    "href": "classical-mechanics/newtonian-mechanics.html#conservation-laws",
    "title": "Newtonian Mechanics",
    "section": "Conservation Laws",
    "text": "Conservation Laws\nA quantity Q is said to be conserved if its time derivative is zero, \\(\\dot Q = 0\\). That is, Q is conserved it it’s constant in time.\n\nMomentum\nFor an object moving at velocity \\(\\mathbf{v}\\), define its linear momentum \\(\\mathbf{p}\\) by\n\\[\n\\mathbf{p} = m \\mathbf{v}.\n\\] If the mass \\(m\\) is constant, we evidently have \\[\n\\mathbf{F} = \\mathbf{\\dot p}.\n\\] If \\(\\mathbf{F} = \\mathbf{0}\\), then \\(\\mathbf{p}=const\\), hence momentum is conserved if there are no forces applied. This is the conservation of momentum.\n\n\nAngular Momentum\nDefine the angular momentum \\(\\mathbf{L}\\) of an object by \\[\n\\mathbf{L} = \\mathbf{x} \\times \\mathbf{p}.\n\\] Similarly, define the torque or moment \\(\\mathbf{N}\\) by \\[\\mathbf{N} = \\mathbf{x} \\times \\mathbf{F}.\\]\nNote both angular momentum and torque depend on the choice of coordinate system used since the position vector \\(\\mathbf{x}\\) depends on choice of origin. Now, observe that \\[\n\\mathbf{\\dot L} = \\mathbf{\\dot x} \\times \\mathbf{p} + \\mathbf{x} \\times \\mathbf{\\dot p} = m \\mathbf{v} \\times \\mathbf{v} + \\mathbf{x} \\times \\mathbf{F} = \\mathbf{N}.\n\\] Thus, \\(\\mathbf{N} = \\mathbf{\\dot L}\\). If \\(\\mathbf{N} = \\mathbf{0}\\), then \\(\\mathbf{L}=const\\), hence angular momentum must be conserved if there are no torques applied. This is the conservation of angular momentum.\n\n\nWork and Energy\nDefine the work done on an object as it moves along a path \\(\\gamma\\) from \\(A\\) to \\(B\\) by\n\\[\nW = \\int_A^B \\mathbf{F} \\cdot d\\mathbf{x}.\n\\]\n\n\n\n\n\nIn general, work depends on the path taken to get from \\(A\\) to \\(B\\), hence it isn’t a unique property of the system.\nObserve that \\[\ndW = \\mathbf{F} \\cdot d\\mathbf{x} = \\mathbf{F} \\cdot \\mathbf{v} dt = d\\bigg(\\frac{1}{2}m\\mathbf{v}^2 \\bigg).\n\\] Define the kinetic energy of the system by \\(T = \\frac{1}{2} m \\mathbf{v}^2\\). Then we evidently have \\(dW=dT\\). That is, the work done on the system to get from \\(A\\) to \\(B\\) via \\(\\gamma\\) is just the change in kinetic energy between \\(A\\) and \\(B\\), \\[\nW = \\Delta T = T_B - T_A.\n\\] When the work done is independent of the path taken it’s a state function of the kinetic energy. In this case, the force \\(\\mathbf{F}\\) is said to be conservative.\nBy the Helmholtz theorem, the following conditions are all equivalent:\n\n\\(\\mathbf{F}\\) is conservative,\n\\(W\\) is path-independent,\n\\(\\nabla \\times \\mathbf{F} = \\mathbf{0}\\),\nThere is a scalar potential \\(V=V(\\mathbf{x})\\) such that \\(\\mathbf{F} = -\\nabla V\\).\n\nThe scalar potential \\(V\\) is called the potential energy of the system. Evidently, if \\(\\mathbf{F}\\) is conservative, we have \\[\nW = \\int_A^B \\mathbf{F} \\cdot d\\mathbf{x} = -\\int_A^B \\nabla V \\cdot d\\mathbf{x} = -\\int_A^B dV = V_A - V_B = -\\Delta V = \\Delta T.\n\\] That is, \\(\\Delta T + \\Delta V = 0\\). Define the total mechanical energy \\(E\\) of the system by \\[\nE = T + V.\n\\] Then \\(\\Delta E = \\Delta (T + V) = 0\\). That is, energy is conserved when the forces on the system are conservative. This is the conservation of energy.\nEnergy isn’t generally conserved if the forces aren’t conservative. Examples of non-conservative forces include any force that’s a function of velocity. These include dissipative forces like friction or drag, as well as magnetic forces.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Newtonian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/newtonian-mechanics.html#using-newtons-laws",
    "href": "classical-mechanics/newtonian-mechanics.html#using-newtons-laws",
    "title": "Newtonian Mechanics",
    "section": "Using Newton’s Laws",
    "text": "Using Newton’s Laws\nThe primary goal of mechanics is to understand how systems evolve with time. To understand a particle’s given trajectory in Newtonian Mechanics, we need to\n\nWrite down all the forces acting on the particle,\nUse \\(\\mathbf{F} = m \\mathbf{a}\\) to set up the equations of motion,\nSolve the equations of motion for the trajectory \\(\\mathbf{x}(t)\\), either analytically or (usually) numerically.\n\nHere are some examples.\n\n\nExample: Projectile motion\nSuppose a cannon is launched from the origin at an angle \\(\\theta\\) above the ground with initial velocity \\(\\mathbf{v}_0\\).\n\n\n\n\n\n\nWrite down the equations of motion. Assume drag is negligible.\nThe forces are \\(\\mathbf{F} = \\mathbf{g} = -g\\mathbf{e}_y\\). Then, \\[\n\\mathbf{a} = \\ddot x\\mathbf{e}_x + \\ddot y\\mathbf{e}_y = -g\\mathbf{e}_y \\quad \\Longrightarrow \\quad   \\ddot x = 0, \\ \\ \\ddot y = -mg.\n\\]\nFind the trajectory \\(\\mathbf{x}(t) = x(t)\\mathbf{e}_x + y(t)\\mathbf{e}_y\\).\nIntegrating each element twice gives \\[\n\\begin{align*}\nx(t) &= x_0 + v_{0x}t = v_0t \\cos \\theta, \\\\\ny(t) &= y_0 + v_{0y}t - \\frac{1}{2} gt^2 = v_{0}t\\sin \\theta - \\frac{1}{2} gt^2.\n\\end{align*}\n\\]\nFind the range, i.e. the value \\(R=x(T)\\) when the cannon hits the ground. Which launch angle maximizes the range?\nFirst, we need to find the time \\(T\\) when \\(y(T) = 0\\). Setting \\[\ny(T) = 0 = v_0 T \\sin \\theta - \\frac{1}{2} gT^2 \\Longrightarrow T = 0, \\frac{2v_0 \\sin \\theta}{g}.\n\\] The \\(T=0\\) case is trivial. Plugging the other one in to \\(x(T)\\) finally gives the range, \\[\nR = x(T) = v_0T \\cos \\theta = \\frac{2v_0^2 \\sin \\theta}{g} \\cos \\theta = \\frac{v_0^2 \\sin 2\\theta}{g}.\n\\] Note that the range is maximized when \\(\\sin 2 \\theta = 1\\), which is when the launch angle is \\(\\theta = 45^\\circ\\).\nFind the shape of the motion \\(y = y(x)\\).\nWe need to eliminate \\(t\\) in both equations and solve for \\(y=y(x(t))\\). Solving \\(x(t)\\) for \\(t\\) gives, \\[\nx = v_0 t\\cos \\theta \\Longrightarrow t = \\frac{x}{v_0 \\cos \\theta}.\n\\] Plugging this into \\(y\\) then gives \\[\ny = v_{0}\\frac{x}{v_0 \\cos \\theta}\\sin \\theta - \\frac{1}{2} g\\bigg(\\frac{x}{v_0 \\cos \\theta}\\bigg)^2 =  \\tan \\theta \\cdot x - \\frac{g}{2v_0^2 \\cos^2 \\theta} x^2.\n\\] This is a downward sloping parabola with vertex at \\(\\big(\\frac{v_0^2 \\sin 2\\theta}{2g}, \\frac{v_0^2 \\sin^2 \\theta}{g}\\big)\\).\nFind any conserved quantities.\n\nMomentum: Since \\(\\mathbf{F} \\neq \\mathbf{0}\\), momentum isn’t conserved. However, \\(p_x\\) is conserved.\nAngular Momentum: Since \\(\\mathbf{N} = \\mathbf{x} \\times \\mathbf{F} = \\mathbf{x} \\times m\\mathbf{g} \\neq 0\\), angular momentum is not conserved.\nEnergy: Since \\(V=mgy\\), the force \\(\\mathbf{F}\\) is conservative, hence energy is conserved.\n\n\n\n\n\nExample: Block sliding on a ramp with friction\nA block of mass \\(m\\) is sliding down a ramp inclined from the horizontal at an angle \\(\\theta\\). Assume the system has a coefficient of friction \\(\\mu\\), and that the block starts from rest at the top of the ramp.\n\n\n\n\n\n\nWrite down the equations of motion.\nChoose a coordinate system such that \\(x\\) is pointing downwards parallel to the ramp and \\(y\\) is pointing outwards perpendicular to the ramp. There are three forces acting, gravity, the normal force, and the frictional force, so \\[\n\\mathbf{F} = \\mathbf{N} + m\\mathbf{g} - \\mu \\mathbf{N} \\mathbf{e}_v = N\\mathbf{e}_y + mg(\\sin\\theta\\mathbf{e}_x - \\cos\\theta\\mathbf{e}_y) - \\mu N \\mathbf{e}_x.\n\\] Resolving into components, we have \\[\n\\begin{align*}\nm \\ddot x &= mg\\sin\\theta - \\mu N, \\\\\nm \\ddot y &= N - mg\\cos\\theta = 0.\n\\end{align*}\n\\] The second equation follows from the assumption that the block is constrained to stay on the ramp.\nFind the trajectory \\(\\mathbf{x}(t) = x(t)\\mathbf{e}_x + y(t)\\mathbf{e}_y\\).\nTo solve, we need to eliminate the normal force \\(N\\). Using the EOM for \\(\\ddot y\\), we get \\(N = mg\\cos\\theta\\). Plugging this into the equation for \\(\\ddot x\\) then gives\n\\[\n\\begin{align*}\n\\ddot x &= g(\\sin\\theta - \\mu\\cos\\theta) = const, \\\\\n\\ddot y &= 0.\n\\end{align*}\n\\] Suppose the block starts at the top of the ramp, which we’ll call the origin. Then integrating, we get,\n\\[\n\\begin{align*}\nx(t) &= v_0 t + \\frac{1}{2}g(\\sin\\theta - \\mu\\cos\\theta)t^2, \\\\\ny(t) &= 0.\n\\end{align*}\n\\] Notice \\(x(t)\\) is just the equation of an object falling under a modified gravity \\[\n\\mathbf{g}'=-g(\\sin\\theta - \\mu\\cos\\theta)\\mathbf{e}_x.\n\\]\nFind the angle \\(\\theta\\) at which the block will start sliding.\nThe block will move if \\(\\ddot x \\geq 0\\), i.e. when \\(\\mu \\leq \\tan\\theta\\). It will start moving at the angle when \\(\\tan\\theta=\\mu\\) exactly, i.e. when \\[\n\\theta = \\arctan\\mu.\n\\]\nFind any conserved quantities.\n\nMomentum: Since \\(\\mathbf{F} \\neq \\mathbf{0}\\), momentum is not conserved. However, \\(p_y\\) is conserved.\nAngular momentum: Since \\(\\mathbf{N} = \\mathbf{x} \\times \\mathbf{F} \\neq \\mathbf{0}\\), angular momentum is not conserved.\nEnergy: Since friction is present, \\(\\mathbf{F}\\) is a dissipative force, hence it’s not conservative, and energy is not conserved.\n\nFind the rate of energy dissipation as the block slides down the ramp.\nFriction dissipates as a heat \\(Q\\). If the block slides a distance \\(L\\), this means \\(E(0) = E(L) + Q\\). Since the block starts from rest, \\(E(0) = 0\\). At \\(x=L\\), the work done is \\[\nW = \\int_0^L F_x dx = \\int_0^L mg(\\sin\\theta - \\mu\\cos\\theta)dx = mgL(\\sin\\theta - \\mu\\cos\\theta) = T(L) - 0 = T(L),\n\\] so the energy when the block gets to the bottom is \\[\nE(L) = T(L) + V(L,0) = mgL(\\sin\\theta - \\mu\\cos\\theta) - mgL\\sin\\theta = -\\mu mgL\\cos\\theta.\n\\] Finally, using this to solve for \\(Q\\), the heat dissipated over the entire trajectory, we get \\[\nQ = E(0) - E(L) = \\mu mgL\\cos\\theta.\n\\] The most important sanity check here is to notice there’s no heat dissipation if there is no friction.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Newtonian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/newtonian-mechanics.html#curvilinear-coordinates",
    "href": "classical-mechanics/newtonian-mechanics.html#curvilinear-coordinates",
    "title": "Newtonian Mechanics",
    "section": "Curvilinear Coordinates",
    "text": "Curvilinear Coordinates\nFor many problems, it’s more convenient to take advantage of the underlying symmetry by using special coordinate systems. Other than rectangular coordinates \\((x,y,z)\\), the most common coordinate systems worth being familiar with are polar coordinates \\((r,\\varphi)\\), cylindrical coordinates \\((\\rho,\\varphi,z)\\), and spherical coordinates \\((r,\\theta,\\varphi)\\).\n\nPolar Coordinates\nFor problems with circular symmetry it’s convenient to use polar coordinates \\((r,\\varphi)\\), defined by\n\\[\n\\begin{align*}\nx &=  r\\cos\\varphi, \\\\\ny &=  r\\sin\\varphi. \\\\\n\\end{align*}\n\\] where \\(r \\geq 0\\) and \\(0 \\leq \\varphi \\leq 2\\pi\\). We can assign basis vectors to polar coordinates \\(\\mathbf{e}_r, \\mathbf{e}_\\varphi\\) to each point as usual.\n\n\n\n\n\nThe thing to keep in mind is that these curvilinear basis vectors are now functions of position,\n\\[\n\\begin{align*}\n\\mathbf{e}_r &= \\mathbf{e}_r(r, \\varphi), \\\\\n\\mathbf{e}_\\varphi &= \\mathbf{e}_\\varphi(r, \\varphi).\n\\end{align*}\n\\] We can figure out how these basis vectors change by taking their differentials, which follow from the figure above,\n\\[\n\\begin{align*}\nd\\mathbf{e}_r &= \\mathbf{e}_\\varphi d\\varphi, \\\\\nd\\mathbf{e}_\\varphi &= -\\mathbf{e}_r d\\varphi.\n\\end{align*}\n\\] Using these differential forms, we can conclude that the motion vectors change as follows,\n\\[\n\\begin{align*}\n\\mathbf{x} &= r\\mathbf{e}_r, \\\\\n\\mathbf{v} &= \\dot r \\mathbf{e}_r + r\\dot \\varphi \\mathbf{e}_\\varphi, \\\\\n\\mathbf{a} &= (\\ddot r - r\\dot \\varphi^2)\\mathbf{e}_r + (2\\dot r \\dot \\varphi + r\\ddot \\varphi)\\mathbf{e}_\\varphi.\n\\end{align*}\n\\]\n\n\nExample: Circular orbits\nSuppose an object moves in a circular orbit of radius \\(r\\) at a constant angular velocity \\(\\omega\\) due to a central force \\(\\mathbf{F} = -F\\mathbf{e}_r\\).\n\n\n\n\n\n\nFind the equations of motion. Since the object moves at constant \\(\\omega\\), we have \\(\\dot \\varphi = \\omega = const\\). Using the polar equations for velocity and acceleration, we have \\[\n\\begin{align*}\n\\mathbf{v} &= \\dot r \\mathbf{e}_r, \\\\\n\\mathbf{a} &= -r\\omega^2\\mathbf{e}_r + r \\dot \\omega\\mathbf{e}_\\varphi = - \\frac{F}{m}\\mathbf{e}_r.\n\\end{align*}\n\\] Note we can re-write these equations to get \\(F = m\\omega^2 r\\).\nFind the period \\(\\tau\\) of the orbit.\nWe want the time it takes for \\(\\Delta \\varphi = 2\\pi\\). Since \\(\\Delta \\varphi = \\omega\\tau\\), solving for \\(\\tau\\) gives \\[\\tau = \\frac{2\\pi}{\\omega}.\\]\nSuppose the central force is the gravitational force, \\(F = \\frac{GMm}{r^2}\\). Find the angular velocity, the period, and the orbital velocity as a function of \\(G, M, r\\).\nWe have \\[\nF = \\frac{GMm}{r^2} = m\\omega^2 r \\ \\Longrightarrow \\ \\omega = \\sqrt{\\frac{GM}{r^3}} \\ \\Longrightarrow \\ \\tau = \\frac{2\\pi}{\\sqrt{GM}} r^{3/2}.\n\\] This is just a special case of Kepler’s third law, \\(\\tau^2 \\propto r^3\\). The orbital velocity is given by \\[\nv = r\\omega = \\sqrt{\\frac{GM}{r}}.\n\\]\n\n\n\n\nExample: Simple pendulum\nConsider the problem of the simple pendulum, where a mass \\(m\\) swings on a massless string of length \\(\\ell\\) under the force of gravity. The string is fixed at one point. Assume no damping is present.\n\n\n\n\n\n\nFind the equations of motion from the forces directly.\nThere are two forces in this problem, gravity and the tension in the string, \\[\n\\mathbf{F} = \\mathbf{T} + m\\mathbf{g} = -T\\mathbf{e}_r + mg(\\cos\\theta \\mathbf{e}_r - \\sin\\theta\\mathbf{e}_\\theta).\n\\] Dividing by \\(m\\) and setting equal to the polar form of \\(\\mathbf{a}\\), we have \\[\n\\mathbf{a} = (-T+mg\\cos\\theta)\\mathbf{e}_r - mg\\sin\\theta\\mathbf{e}_\\theta = -m\\ell^2 \\dot \\theta^2 \\mathbf{e}_r + m\\ell^2 \\ddot \\theta \\mathbf{e}_\\theta.\n\\] This gives two equations of motion, one for the tension and one for the angular acceleration, \\[\n\\begin{align*}\nT &= m\\ell^2 \\dot\\theta^2 + mg\\cos\\theta, \\\\\n\\ddot \\theta &= -\\frac{g}{\\ell} \\sin\\theta. \\\\\n\\end{align*}\n\\]\nFind the equations of motion again, but this time using torques.\nRecall \\(\\mathbf{N} = I \\boldsymbol{\\dot \\omega}\\), where \\(I\\) is the scalar moment of inertia and \\(\\boldsymbol{\\omega}\\) is the angular velocity vector. In this case, \\(I=m\\ell^2\\) and \\(\\boldsymbol{\\dot \\omega} = \\ddot \\theta \\mathbf{e}_z\\). Then we have \\[\nI \\boldsymbol{\\dot \\omega} = m\\ell^2 \\ddot \\theta \\mathbf{e}_z \\equiv \\ell\\mathbf{e}_r \\times m\\mathbf{g} = -mg\\ell\\sin\\theta \\mathbf{e}_z = \\mathbf{N},\n\\] which can be solve to get \\(\\ddot \\theta = -\\frac{g}{\\ell}\\sin\\theta\\). Notice how in this approach we don’t need to worry about the tension at all.\nSuppose \\(\\theta\\) is small. Write down the equations of motion, solve them, and find the period.\nWhen \\(\\theta \\ll 1\\) the small angle approximation applies, \\(\\sin\\theta \\approx \\theta\\). In this case, the equation of motion reduces to \\[\\ddot \\theta = -\\frac{g}{\\ell} \\theta,\\] which is just simple harmonic oscillation with angular frequency \\(\\omega = \\sqrt{\\frac{g}{\\ell}}\\). The solution to SHO is \\[\n\\theta(t) = A\\sin(\\omega t + \\phi),\n\\] where \\(A\\) is some amplitude and \\(\\phi\\) is some phase determined by the initial conditions. Finally, solving for the period, we have \\[\n\\tau = \\frac{2\\pi}{\\omega} = 2\\pi\\sqrt{\\frac{\\ell}{g}}.\n\\]\n\n\n\n\n\nCylindrical Coordinates\nCylindrical coordinates extend polar coodinates by adding in the z-axis from the rectangular system,\n\\[\n\\begin{align*}\nx &=  r\\cos\\varphi, \\\\\ny &=  r\\sin\\varphi, \\\\\nz &= z.\n\\end{align*}\n\\] The basis vectors are \\(\\mathbf{e}_r, \\mathbf{e}_\\varphi, \\mathbf{e}_z\\). Their differential forms are just \\[\n\\begin{align*}\nd\\mathbf{e}_r &= \\mathbf{e}_\\varphi d\\varphi, \\\\\nd\\mathbf{e}_\\varphi &= -\\mathbf{e}_r d\\varphi \\\\\nd\\mathbf{e}_z &= 0.\n\\end{align*}\n\\] The motion vectors in cylindrical coordinates are thus given by, \\[\n\\begin{align*}\n\\mathbf{x} &= r\\mathbf{e}_r, \\\\\n\\mathbf{v} &= \\dot r \\mathbf{e}_r + r\\dot \\varphi \\mathbf{e}_\\varphi + \\dot z \\mathbf{e}_z , \\\\\n\\mathbf{a} &= (\\ddot r - r\\dot \\varphi^2)\\mathbf{e}_r + (2\\dot r \\dot \\varphi + r\\ddot \\varphi)\\mathbf{e}_\\varphi + \\ddot z \\mathbf{e}_z.\n\\end{align*}\n\\]\n\n\nSpherical Coordinates\nSpherical coordinates extend polar coordinates in a slightly different way. The radius \\(r\\) is now 3-dimensional, and there are two angles, a polar angle \\(0 \\leq \\theta \\leq \\pi\\) and an azimuthal angle \\(0 \\leq \\varphi \\leq 2\\pi\\). The conversion to rectangular coordinates is given by, \\[\n\\begin{align*}\nx &=  r\\sin\\theta\\cos\\varphi, \\\\\ny &=  r\\sin\\theta\\sin\\varphi, \\\\\nz &= r\\cos\\theta. \\\\\n\\end{align*}\n\\] The basis vectors are \\(\\mathbf{e}_r, \\mathbf{e}_\\theta, \\mathbf{e}_\\varphi\\). Deriving the differential forms of these is a good bit more complex. Here they are, \\[\n\\begin{aligned}\nd\\mathbf{e}_r &= \\dot\\theta \\sin\\varphi d\\mathbf{e}_\\theta + \\dot\\varphi d\\mathbf{e}_\\varphi, \\\\\nd\\mathbf{e}_\\theta &= - \\dot\\theta \\sin\\varphi d\\mathbf{e}_r - \\dot\\theta \\cos\\varphi d\\mathbf{e}_\\varphi, \\\\\nd\\mathbf{e}_\\varphi &= - \\dot\\varphi \\mathbf{e}_r + \\dot\\theta \\cos\\varphi \\mathbf{e}_\\theta. \\\\\n\\end{aligned}\n\\] These can then be used to get the motion vectors in spherical coordinates, \\[\n\\begin{align*}\n\\mathbf{r} &= r \\mathbf{e}_r, \\\\\n\\mathbf{v} &= \\dot{r} \\mathbf{e}_r + r \\dot\\theta \\sin\\varphi \\mathbf{e}_{\\theta} + r \\dot\\varphi \\mathbf{e}_{\\varphi}, \\\\\n\\mathbf{a} &= (\\ddot{r} - r \\dot{\\theta}^2 \\sin^2\\varphi - r \\dot{\\varphi}^2) \\mathbf{e}_r \\\\\n&\\quad + (r \\ddot\\theta \\sin\\varphi + 2 \\dot{r} \\dot\\theta \\sin\\varphi + 2 r \\dot\\theta \\dot\\varphi \\cos\\varphi) \\mathbf{e}_{\\theta} \\\\\n&\\quad + (r \\ddot\\varphi + 2 \\dot{r} \\dot\\varphi - r \\dot{\\theta}^2 \\sin\\varphi \\cos\\varphi) \\mathbf{e}_{\\varphi}. \\\\\n\\end{align*}\n\\]",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Newtonian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/newtonian-mechanics.html#many-particle-systems",
    "href": "classical-mechanics/newtonian-mechanics.html#many-particle-systems",
    "title": "Newtonian Mechanics",
    "section": "Many-Particle Systems",
    "text": "Many-Particle Systems\nThus far we’ve worked with single-particle systems. Let’s now consider a system of \\(N\\) particles with positions \\(\\mathbf{x}_1, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N\\) respectively. We can use the principle of superposition to extend the laws derived above for single particles.\nFor \\(N\\)-particle systems it’s convenient to characterize the system’s position using the center of mass vector \\(\\mathbf{R}\\), \\[\n\\mathbf{R} \\equiv \\frac{1}{M}\\sum_{i=1}^N m_i \\mathbf{x}_i,\n\\] where \\(M\\) is just the total mass of the system, \\(M \\equiv \\sum m_i\\). The center of mass is just the mass-weighted average of all the particle position vectors.\nSuppose an external force \\(\\mathbf{F}^{ext}\\) is acting on the system, and suppose each particle \\(i\\) imparts a force \\(\\mathbf{F}_{ij}\\) on particle \\(j \\neq i\\). Here’s what this would look like for \\(N=3\\) particles.\n\n\n\n\n\nBy superposition, the total force acting on the entire system is thus, \\[\n\\mathbf{F} = \\mathbf{F}^{ext} + \\sum_{i \\neq j} \\mathbf{F}_{ij} = \\sum m_i \\mathbf{a}_i = M\\mathbf{\\ddot R}.\n\\] Now, by Newton’s third law, \\(\\mathbf{F}_{ij} = -\\mathbf{F}_{ji}\\). This means all the internal forces cancel in pairs, so we have \\[\n\\mathbf{F}^{ext} = M\\mathbf{\\ddot R}.\n\\] That is, the system as a whole moves as if it were a point mass \\(M\\) with an external force \\(\\mathbf{F}^{ext}\\) acting on its center of mass \\(\\mathbf{R}\\).\nIf the total momentum is defined as \\(\\mathbf{P} = M \\mathbf{\\dot R}\\), this expression then says \\(\\mathbf{F}^{ext} = \\mathbf{\\dot P}\\). Thus, if no external forces act on the system, then its total linear momentum \\(\\mathbf{P}\\) is conserved.\nLet’s now consider the total torques on the system. Suppose the system experiences an external torque \\(\\mathbf{N}^{ext}\\), and that each particle \\(i\\) exerts a torque \\(\\mathbf{N}_{ij}\\) on particle \\(j\\). Then by superposition, the total torque on the system is \\[\n\\mathbf{N} = \\mathbf{N}^{ext} + \\sum_{i \\neq j} \\mathbf{N}_{ij} = \\mathbf{N}^{ext} + \\sum_{i \\neq j} \\mathbf{x}_i \\times \\mathbf{F}_{ij},\n\\] Again, we can use the fact that each \\(\\mathbf{F}_{ij} = -\\mathbf{F}_{ji}\\). If we do this, we can re-write the total torque as\n\\[\n\\mathbf{N} = \\mathbf{N}^{ext} + \\sum_{i&lt;j} (\\mathbf{x}_{i}-\\mathbf{x}_{j}) \\times \\mathbf{F}_{ij} = \\mathbf{N}^{ext}.\n\\] Now, if we further assume that each internal force acts centrally, i.e. \\(\\mathbf{F}_{ij} = \\mathbf{F}_{ij}(\\mathbf{x}_{i}-\\mathbf{x}_{j})\\), then the internal cross products all vanish, and we just get \\(\\mathbf{N} = \\mathbf{N}^{ext}\\). That is, if all the internal forces are central, then the total torque on the system is just the external torque.\nIf the total angular momentum on the system is defined as \\(\\mathbf{L} = \\mathbf{R} \\times \\mathbf{P}\\), this expression says \\(\\mathbf{\\dot L} = \\mathbf{N}^{ext}\\). Thus, if no external torques act on the system, then its total angular momentum \\(\\mathbf{L}\\) is conserved.\nIt’s insightful to separate each particle’s motion vectors explicitly into a center of mass component and a relative component,\n\\[\n\\begin{align*}\n\\mathbf{x}_i &= \\mathbf{R} + \\boldsymbol{\\mathscr{r}}_i, \\\\\n\\mathbf{v}_i &= \\mathbf{V} + \\boldsymbol{\\mathscr{v}}_i. \\\\\n\\end{align*}\n\\]\n\n\n\n\n\nLet’s re-write the total angular momentum \\(\\mathbf{L}\\) in terms of these vectors,\n\\[\n\\begin{align*}\n\\mathbf{L} &= \\sum \\mathbf{x}_i \\times \\mathbf{p}_i = \\sum (\\mathbf{R} + \\boldsymbol{\\mathscr{r}}_i) \\times m_i(\\mathbf{V} + \\boldsymbol{\\mathscr{v}}_i) \\\\\n&= M\\mathbf{R} \\times \\mathbf{V} + \\sum m_i \\boldsymbol{\\mathscr{r}}_i \\times \\boldsymbol{\\mathscr{v}}_i + \\mathbf{R} \\times \\bigg(\\sum m_i \\boldsymbol{\\mathscr{v}}_i \\bigg) + \\bigg(\\sum m_i \\boldsymbol{\\mathscr{r}}_i \\bigg)\\times \\mathbf{V} \\\\\n&= \\mathbf{R} \\times \\mathbf{P} + \\sum m_i \\boldsymbol{\\mathscr{r}}_i \\times \\boldsymbol{\\mathscr{v}}_i \\\\\n&\\equiv \\mathbf{L}^{orb} + \\mathbf{L}^{spin}. \\\\\n\\end{align*}\n\\] We’ve thus been able to separate the angular momentum into two components, an orbital angular momentum \\(\\mathbf{L}^{orb} = \\mathbf{R} \\times \\mathbf{P}\\), and a spin angular momentum \\(\\mathbf{L}^{spin} = \\sum m_i \\boldsymbol{\\mathscr{r}}_i \\times \\boldsymbol{\\mathscr{v}}_i\\). The orbital angular momentum describes how the center of mass of the object tends to rotate about some external point. The spin angular momentum describes how the system itself tends to rotate about its center of mass.\n\n\n\n\n\nLast, let’s look at the total energies of the system. For a system with \\(N\\) particles, the potential energy will be a function of all the position vectors, \\(V = V(\\mathbf{x}_1, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N)\\). It won’t generally simplify. But the kinetic energy we can simplify. Writing it in terms of its relative and center of mass velocities, we have\n\\[\n\\begin{align*}\nT &= \\frac{1}{2}\\sum m_i \\mathbf{v}_i^2 = \\sum m_i (\\mathbf{V} + \\boldsymbol{\\mathscr{v}}_i)^2 \\\\\n&= \\frac{1}{2}M\\mathbf{V}^2 + \\frac{1}{2}\\sum m_i\\boldsymbol{\\mathscr{v}}_i^2 + \\mathbf{V} \\cdot \\bigg(\\sum m_i \\boldsymbol{\\mathscr{v}}_i\\bigg) \\\\\n&= \\frac{1}{2}M\\mathbf{V}^2 + \\frac{1}{2}\\sum m_i\\boldsymbol{\\mathscr{v}}_i^2 \\\\\n&= T^{CM} + T^{rel}.\n\\end{align*}\n\\] Thus, the kinetic energy separates into a sum of the kinetic energy on the center of mass \\(T^{CM} = \\frac{1}{2}M\\mathbf{V}^2\\), and the kinetic energy of the relative components \\(T^{rel} = \\frac{1}{2}\\sum m_i\\boldsymbol{\\mathscr{v}}_i^2\\). Evidently, the total energy is \\[\nE = T + V = T^{CM} + T^{rel} + V(\\mathbf{x}_1, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N).\n\\] It’s conserved provided the external force \\(\\mathbf{F}^{ext}\\) is conservative.\n\n\nExample: Rockets\nSuppose a rocket of mass \\(m_0=m(t) + m_{ex}(t)\\) is moving through free space with no external forces acting on it. It’s expelling fuel for trust at some constant speed \\(v_{ex}\\) with respect to the rocket.\n\n\n\n\n\n\nWhat is the force of thrust on the rocket?\nNo external forces are present, so \\(\\mathbf{F}^{ext} = \\mathbf{0}\\). The internal forces are the thrust of the rocket, and the force of the exhaust. In the frame of the rocket they cancel out, \\(\\mathbf{F}_{th} = \\mathbf{F}_{ex}\\), so we have \\[\n\\mathbf{F}_{th} = -\\mathbf{F}_{ex} = -\\mathbf{\\dot p}_{ex} = -\\frac{d}{dt}(m_{ex} \\mathbf{v}_{ex}) = -\\dot m_{ex} \\mathbf{v}_{ex}.\n\\] Now, since \\(m_0 = m + m_{ex}\\), \\(\\dot m = -\\dot m_{ex}\\), and \\(\\mathbf{v}_{ex} = -v_{ex}\\mathbf{e}_v\\), we have \\[\n\\mathbf{F}_{th} = -\\dot m v_{ex} \\mathbf{e}_v.\n\\]\nFind the velocity \\(\\mathbf{v}(t)\\) of the rocket.\nUsing the fact that \\(\\mathbf{F}_{th} = m\\mathbf{a}\\), we have \\(-\\dot m v_{ex} = m \\dot v\\), a first-order differential equation in \\(v(t)\\), \\[\n\\dot v + v_{ex} \\frac{\\dot m}{m} = 0.\n\\] Integrating both sides and solving for \\(v(t)\\), we get \\[\nv(t) = v_0 - v_{ex} \\int_{m_0}^m \\frac{dm}{m} = -v_{ex} \\log \\frac{m(t)}{m_0}.\n\\] Or, expressing in the form of the well-known rocket equation, \\[\n\\Delta v = v_{ex} \\log\\frac{m_0}{m(t)}.\n\\]\nFind the position \\(\\mathbf{x}(t)\\) of the rocket, assuming fuel is expelled form the rocket at a constant rate.\nAssume \\(\\dot m = -k = const\\). Since there are no external forces, the rocket must be traveling along some line. Suppose without loss of generality then that \\(\\mathbf{x}(t) =  z(t)\\mathbf{e}_z\\). Then we have, \\[\n\\begin{align*}\nz(t) &= \\int_0^t v(t) dt = v_{ex} \\int_0^t dt \\log\\frac{m_0}{m_0-kt} \\\\\n&= v_{ex} \\bigg[t - \\bigg(\\frac{m_0-kt}{k} \\bigg) \\log \\bigg(\\frac{m_0}{m_0-kt} \\bigg) \\bigg] \\\\\n&= v_{ex} t - \\frac{v_{ex}}{k}(m_0 - kt)\\log\\bigg(\\frac{m_0}{m_0-kt} \\bigg).\n\\end{align*}\n\\]",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Newtonian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/simple-systems.html",
    "href": "classical-mechanics/simple-systems.html",
    "title": "Simple Systems",
    "section": "",
    "text": "Independent Forces\nThe first and simplest case we’ll consider are forces that don’t depend on position or velocity, \\[\nm \\mathbf{a} = \\mathbf{F}_0(t).\n\\] We can solve these systems directly by integrating both sides, i.e. reducing to quadrature. We have,\n\\[\n\\begin{align*}\n\\mathbf{a}(t) &= \\frac{1}{m}\\mathbf{F}_0(t), \\\\\n\\mathbf{v}(t) &= \\mathbf{v}_0 + \\frac{1}{m}\\int_0^t dt'\\mathbf{F}_0(t'), \\\\\n\\mathbf{x}(t) &= \\mathbf{x}_0 + \\mathbf{v}_0t + \\frac{1}{m}\\int_0^t dt' \\int_0^{t'} dt''\\mathbf{F}_0(t''). \\\\\n\\end{align*}\n\\] The simplest of these cases are when there are no forces at all, and when the forces are constant. If there are no forces at all acting on the system, \\(\\mathbf{F}_0 = \\mathbf{0}\\), in which case the equations of motion reduce to\n\\[\n\\begin{align*}\n\\mathbf{a}(t) &= 0, \\\\\n\\mathbf{v}(t) &= \\mathbf{v}_0, \\\\\n\\mathbf{x}(t) &= \\mathbf{x}_0 + \\mathbf{v}_0t. \\\\\n\\end{align*}\n\\] This is just a statement of Newton’s First Law. If no forces act on a particle, it continues linearly along its path at constant velocity. The next simplest case is when \\(\\mathbf{F}_0=const\\). In this case, the equations of motion become\n\\[\n\\begin{align*}\n\\mathbf{a}(t) &= \\frac{1}{m}\\mathbf{F}_0, \\\\\n\\mathbf{v}(t) &= \\mathbf{v}_0 + \\frac{1}{m}\\mathbf{F}_0 t, \\\\\n\\mathbf{x}(t) &= \\mathbf{x}_0 + \\mathbf{v}_0t + \\frac{1}{2m^2}\\mathbf{F}_0^2. \\\\\n\\end{align*}\n\\] This case includes the gravitional force near the surface of the Earth, in which case \\(\\mathbf{F}_0=m\\mathbf{g}\\). It also includes the problem of an electric charge placed close to a large conducting sheet with a uniform electric field, where \\(\\mathbf{F}_0=q\\mathbf{E}_0\\).\nIn these problems, the motion will always be along a parabolic arc. The parabola will slope toward the force if the force is attractive, and away from the force if it’s repulsive.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Simple Systems</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/simple-systems.html#independent-forces",
    "href": "classical-mechanics/simple-systems.html#independent-forces",
    "title": "Simple Systems",
    "section": "",
    "text": "Example: Free-fall near Earth\nSuppose an object of mass \\(m\\) is falling freely near the Earth’s surface. In this case, \\(\\mathbf{F}_0 = m\\mathbf{g}\\), so\n\\[\n\\begin{align*}\n\\mathbf{a}(t) &= \\mathbf{g}, \\\\\n\\mathbf{v}(t) &= \\mathbf{v}_0 - \\mathbf{g}t, \\\\\n\\mathbf{x}(t) &= \\mathbf{x}_0 + \\mathbf{v}_0t + \\frac{1}{2}\\mathbf{g}t^2.\n\\end{align*}\n\\] The motion in this case will always lie in the plane spanned by \\(\\mathbf{v}_0\\) and \\(\\mathbf{g}\\). This means without loss of generality we can assume motion lies in the xy-plane with \\(\\mathbf{g} = -g\\mathbf{e}_y\\). Then \\(y\\) can be solved as a function of \\(x\\) to give \\[\ny(x) = v_{0}\\frac{x}{v_0 \\cos \\theta}\\sin \\theta - \\frac{1}{2} g\\bigg(\\frac{x}{v_0 \\cos \\theta}\\bigg)^2,\n\\] which is of course a downward-sloping parabola centered at the vertex \\(\\big(\\frac{v_0^2 \\sin 2\\theta}{2g}, \\frac{v_0^2 \\sin^2 \\theta}{g}\\big)\\).",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Simple Systems</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/simple-systems.html#drag-forces",
    "href": "classical-mechanics/simple-systems.html#drag-forces",
    "title": "Simple Systems",
    "section": "Drag Forces",
    "text": "Drag Forces\nThe next type of forces we’ll consider are those which are functions of velocity,\n\\[\nm\\mathbf{a} = \\mathbf{F}(\\mathbf{v}).\n\\] In the 1-dimensional case, this reduces to,\n\\[\nma = F(v).\n\\] Provided \\(v\\) is small, we can approximate \\(F(v)\\) by its first few terms. I’ll write it as,\n\\[\nF(v) \\approx a - bv - cv^2.\n\\] Typically, drag forces shouldn’t apply a force when the particle is at rest, which means \\(a=0\\). The remaining two terms cover two distinct regimes of drag:\n\nLinear or viscous drag: \\(F(v) = -bv\\), where \\(b &gt; 0\\).\nQuadratic or air drag: \\(F(v) = -cv^2\\), where \\(c &gt; 0\\).\n\n\nLinear Drag\nIt’s convenient to analyze these two distinct cases separately. Let’s first look at linear drag. In that case \\(c=0\\), and we end up with the linear differential equation \\[\nm \\ddot x + b \\dot x = 0.\n\\] To solve this equation, re-write it in terms of \\(v = \\dot x\\),\n\\[\n\\frac{dv}{dt} = -\\frac{b}{m} v.\n\\] Integrating both sides, we get\n\\[\nv(t) = v_0 e^{-\\frac{b}{m} t}.\n\\] For \\(x(t)\\) just integrate both sides again to get\n\\[\nx(t) = x_0 + \\int_0^t v_0 e^{-\\frac{b}{m} t'} dt' = x_0 + \\frac{mv_0}{b}\\big(1 - e^{-\\frac{b}{m} t}\\big).\n\\] Evidently, such forces cause a moving particle to slowly come to rest, since \\(v \\rightarrow 0\\) as \\(t \\rightarrow \\infty\\). The position where the particle comes to rest is evidently \\(x_f = x_0 + \\frac{mv_0}{b}\\). The \\(\\frac{1}{e}\\) decay time is \\(\\tau = \\frac{m}{b}\\). This suggests that \\(b\\) functions as a sort of drag coefficient, since a large \\(b\\) causes the system to dissipate faster.\n\n\n\n\n\nLinear drag is frequently used to model objects moving through a viscous medium at low speeds. Suppose a spherical object of radius \\(R\\) is moving slowly in a viscous medium with viscosity \\(\\eta\\). Then the drag force on the object is given by Stokes’ Law,\n\\[\n\\mathbf{F}_d = -6\\pi\\eta R \\mathbf{v}.\n\\] This force is linear in velocity, hence we can write \\(F_d = -6\\pi\\eta R v\\), which says the drag constant \\(b\\) is just\n\\[\nb = 6\\pi\\eta R.\n\\]\n\n\nExample: Dropping a ball in syrup\nSuppose a ball of radius \\(R\\) and mass \\(m\\) is dropped in a viscous syrup from rest at \\(x=0\\). Find the velocity and position of the ball as it moves through the fluid.\n\n\n\n\n\nThis is a 1-dimensional motion problem since the ball is dropped from rest under gravity, with \\(F=F_d + mg\\). Here Stoke’s law applies, so the drag force is \\(F_d = -bv = -b\\dot x\\). Plugging into Newton’s Second Law, we have \\[\nm\\ddot x + b \\dot x = g.\n\\] Re-writing this in terms of \\(v = \\dot x\\), we get \\[\nm \\dot v + bv = g,\n\\] which is a first order linear differential equation for the velocity \\(v(t)\\). Its general solution is given by \\[\nv(t) = v_0 e^{-\\frac{b}{m}t} + \\frac{mg}{b}(1-e^{-\\frac{b}{m}t}).\n\\] Notice that as \\(t \\rightarrow \\infty\\), \\(v(t) \\rightarrow \\frac{mg}{b}\\). That is, \\(v(t)\\) tends toward a terminal velocity \\[\nv_t = \\frac{mg}{b} = \\frac{mg}{6\\pi\\eta R}.\n\\] Since the ball is dropped from rest, \\(v_0=0\\). The velocity of the ball is thus given by \\[\nv(t) = v_t(1-e^{-\\frac{b}{m}t}).\n\\] Using this we can solve for the position to get \\[\nx(t) = v_t\\bigg(t - \\frac{b}{m}(1 - e^{-\\frac{b}{m}t})\\bigg).\n\\] Notice that drag causes the ball to fall much slower than it would in free-fall. Instead of being a quadratic function of time, \\(x(t)\\) is now approximately a linear function of time, with \\(x(t) \\sim v_t t\\) for large \\(t\\).\n\n\n\n\n\n\n\n\n\nQuadratic Drag\nWe’ll now look at quadratic drag, where \\(b=0\\). Then we get the differential equation, \\[\nm\\ddot x + c \\dot x^2 = 0.\n\\] This is no longer a linear differential equation due to the appearance of \\(\\dot x^2\\), but surprisingly we can still solve it using separation of variables. Again, let \\(v = \\dot x\\). Then we get \\[\nm\\dot v + cv^2 = 0.\n\\] Rearranging and solving for \\(v(t)\\), we have \\[\n\\frac{dv}{dt} = -\\frac{c}{m}v^2 \\quad \\Longrightarrow \\quad\n\\int_{v_0}^{v} \\frac{dv}{v^2} = -\\frac{c}{m} t \\quad \\Longrightarrow \\quad\nv(t) = \\frac{1}{\\frac{1}{v_0} + \\frac{c}{m}t}.\n\\] Integrating both sides and solving for the position, we get \\[\nx(t) = x_0 + \\int_0^t \\frac{dt}{\\frac{1}{v_0} + \\frac{c}{m}t} = x_0 + \\frac{m}{c}\\log\\bigg( 1 + \\frac{cv_0}{m}t \\bigg).\n\\] In this case, \\(v \\rightarrow 0\\), but \\(x \\rightarrow \\infty\\) as \\(t \\rightarrow \\infty\\). Evidently, while linear drag is strong enough to slow a moving particle back down to rest, quadratic drag is not.\n\n\n\n\n\nQuadratic drag is often used to model the drag experienced by objects moving through air or other media where pressure is more important than viscosity. For an object moving through air, drag is well-modeled by the drag equation, \\[\n\\mathbf{F}_d = -\\frac{1}{2}C \\rho A v^2 \\mathbf{e}_v,\n\\] where \\(\\rho\\) is the density of air, \\(A\\) is the cross-sectional area of the object in the direction of motion, and \\(C\\) is the drag coefficient. Since this force is proportional to \\(v^2\\), we evidently have \\[\nc = \\frac{1}{2}C \\rho A.\n\\]\n\n\nReynold’s Number\nIn practice, how can we tell if drag is in the linear or quadratic situation? A simple way to do this is by looking at the Reynold’s Number. Let’s go back to the full quadratic equation for drag, with \\(a\\) set to \\(0\\), \\[\nF_d = -bv - cv^2.\n\\] Notice that the ratio \\(\\frac{cv}{b}\\) gives the relative importance of the two drag terms. Using Stoke’s Law and the Drag Equation for the drag constants, we can re-write this expression as \\[\n\\frac{cv}{b} = \\frac{\\frac{1}{2}C \\rho Av}{6\\pi\\eta R} = \\frac{C \\rho Rv}{3\\eta}.\n\\] This ratio is usually rescaled by a factor of \\(\\frac{3}{C}\\) to get the Reynold’s number \\(r\\), \\[\nr = \\frac{\\rho Rv}{\\eta}.\n\\] The Reynold’s number is usually what’s used in practice to decide whether we’re in the linear or quadratic drag regime.\n\nWhen the Reynold’s number is low, \\(r \\ll 1\\), \\(v \\ll \\frac{\\eta}{R\\rho}\\), and we’re in the linear regime.\nWhen the Reynold’s number is high, \\(r \\gg 1\\), \\(v \\gg \\frac{\\eta}{R\\rho}\\), and we’re in the quadratic regime.\nThe edge case is when \\(r \\approx 1\\), or \\(v \\approx \\frac{\\eta}{R\\rho}\\). Then, we have to include both the linear and quadratic drag terms in the equation of motion. In this general case, there’s no analytic solution and we have to solve things numerically.\n\nThe Reynold’s number is usually easy to calculate since we can often at least roughly estimate the object’s velocity and radius, and we can usually look up the medium’s viscosity and density. For example, a baseball thrown in air at 100 mph would have a Reynold’s number of about \\(r \\approx 3 \\cdot 10^5 \\gg 1\\), which is solidly in the quadratic drag regime.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Simple Systems</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/simple-systems.html#harmonic-oscillation",
    "href": "classical-mechanics/simple-systems.html#harmonic-oscillation",
    "title": "Simple Systems",
    "section": "Harmonic Oscillation",
    "text": "Harmonic Oscillation\nThe next case we’ll consider is when the force is linear in position, \\[\n\\mathbf{F} = -k \\mathbf{x}.\n\\] This relationship is called Hooke’s Law. In the 1-dimensional case, it reduces to the equation of motion \\[\nm \\ddot x + kx = 0.\n\\] This is a second-order linear differential equation for \\(x(t)\\). The general solution to this differential equation depends on the sign of \\(k\\). If \\(k &lt; 0\\), we have \\[\nx(t) = c_1 e^{\\frac{k}{m}t} + c_2 e^{-\\frac{k}{m}t}.\n\\] Since \\(x \\rightarrow \\infty\\) pretty quickly as \\(t \\rightarrow \\infty\\), this kind of solution is usually non-physical, except perhaps in situations where \\(x\\) is bounded between some known range.\nThe most important case by far is when \\(k &gt; 0\\). In this setting, it’s typical to define \\(\\omega^2 \\equiv \\frac{k}{m}\\) and re-rewrite the equation as \\[\n\\ddot x + \\omega^2 x = 0.\n\\] This is called the simple harmonic oscillator or SHO. The canonical example of SHO is of course the motion of a mass attached to an ideal spring with spring constant \\(k\\).\nThe general solution to SHO is a linear combination of sine and cosine functions, \\[\nx(t) = c_1 \\cos \\omega t + c_2 \\sin \\omega t.\n\\] This trajectory is oscillatory and stable since it only involves sines and cosines, both of which are bounded periodic functions. It’s custom to re-write this equation in a more useful form using trig identities,\n\n\n\n\n\n\\[\n\\begin{align*}\nx(t) &= c_1 \\cos \\omega t + c_2 \\sin \\omega t \\\\\n&= A\\bigg(\\frac{c_1}{A}\\cos \\omega t + \\frac{c_2}{A}\\sin\\omega t \\bigg) \\\\\n&= A(\\cos\\delta \\cos \\omega t + \\sin\\delta\\sin\\omega t) \\\\\n&= A\\cos(\\omega t - \\delta). \\\\\n\\end{align*}\n\\] In this form, \\(A\\) is the amplitude of oscillation and \\(\\delta\\) is the phase of oscillation. The period of oscillation is given by \\[\n\\tau = \\frac{2\\pi}{\\omega} = 2\\pi\\sqrt{\\frac{m}{k}}.\n\\]\n\n\n\n\n\nIt’s usually convenient when dealing with harmonic oscillators to work in the complex plane. Consider the complex form of SHO, given by the differential equation \\[\n\\ddot z + \\omega^2 z = 0,\n\\] where \\(z = x+iy = |z|e^{i\\theta}\\) is a complex variable. Its general solution is given as a linear combination of complex exponentials, \\[\nz(t) = \\tilde c_1 e^{i\\omega t} + \\tilde c_2 e^{-i\\omega t}.\n\\] If we demand that the real solution we seek be given by \\(x(t) = \\text{Re}(z(t))\\), then\n\\[\n\\begin{align*}\nx(t) &= \\Re(c_1 e^{i \\omega t}) + \\Re(c_2 e^{-i \\omega t}) \\\\\n&= \\frac{1}{2}(c_1 + c_2^*)e^{i \\omega t} + \\frac{1}{2}(c_1^* + c_2)e^{-i \\omega t} \\\\\n&= \\frac{1}{2} C e^{i \\omega t} + \\frac{1}{2} C^* e^{-i \\omega t} \\\\\n&= A \\cdot \\Re(e^{i(\\omega t - \\delta)}) \\\\\n&= A \\cos(\\omega t - \\delta),\n\\end{align*}\n\\] where \\(C \\equiv Ae^{i \\delta}\\) is some complex number whose real and imaginary parts are \\(c_1+c_2^*\\) and \\(c_1^*+c_2\\) respectively. For the full complex solution we can similarly write \\[\nz(t) = A e^{i(\\omega t - \\delta)}\n\\] Evidently then, SHO is just a CCW circular rotation in the complex plane with radius \\(A\\).\n\n\n\n\n\n\n\nExample: Bottle sloshing in a bucket\nSuppose a bottle of mass \\(m\\) floats calmly in a bucket of water of density \\(\\rho\\) at some equilibrium depth of \\(d=d_0\\). Suppose we push down slightly on the bottle, perturbing its depth to \\(d = d_0 + x\\). The bottle will begin to oscillate. Find its period of oscillation \\(\\tau\\).\n\n\n\n\n\nThe forces on the bottle are gravity downward and an opposing buoyant force upward, \\[\nF = mg - \\rho g V_{sub} = mg - \\rho g A(d_0 + x).\n\\] At equilibrium, the forces must balance, so \\(0 = mg - \\rho g A d_0\\), which means \\(d_0 = \\frac{m}{\\rho A}\\) is the equilibrium depth. Simplifying, this says the equation of motion is given by \\[\nm \\ddot x = mg - \\rho g A(d_0 + x) = -\\rho g A x = -\\frac{mg}{d_0} x.\n\\] This is just SHO with spring constant \\(k = \\frac{mg}{d_0}\\), or angular frequency \\(\\omega = \\frac{g}{d}\\). Thus, the period of the bottle’s oscillation when \\(x\\) is small is given by \\[\n\\tau = \\frac{2 \\pi}{\\omega} = 2\\pi\\sqrt{\\frac{d_0}{g}}.\n\\]\n\n\n\nTwo-Dimensional Harmonic Oscillation\nSuppose now we allow a mass to move in two dimensions. Hooke’s Law becomes\n\\[\n\\begin{align*}\nm \\ddot x &= -k_x x, \\\\\nm \\ddot y &= -k_y y.\n\\end{align*}\n\\] Since the equation of motions are uncoupled, the solutions are simply given by\n\\[\n\\begin{align*}\nx(t) &= A_x \\cos(\\omega_x t - \\delta_x), \\\\\ny(t) &= A_y \\cos(\\omega_y t - \\delta_y).\n\\end{align*}\n\\] Despite what intuition might suggest, the motion of the mass is now quite non-trivial. In fact, the behavior of the trajectory depends entirely on the ratio of the frequencies \\(\\frac{\\omega_x}{\\omega_y}\\) and the relative phase between the two oscillations \\(\\delta = \\delta_x - \\delta_y\\).\nThe motion will only be periodic if \\(\\frac{\\omega_x}{\\omega_y}\\) is rational, i.e. if the frequencies are integer multiples of each other. The curves traced out by \\((x(t), y(t))\\) when \\(\\frac{\\omega_x}{\\omega_y}\\) is rational are called Lissajous curves. They can get quite complicated, but they’ll always be periodic. Here’s what a few of them look like for different\\(\\frac{\\omega_x}{\\omega_y}\\) and \\(\\delta\\).\n\n\n\n\n\n\n\nExample: Charged particle in a uniform magnetic field\nSuppose a particle with charge \\(q\\) and mass \\(m\\) is moving in the presence of a constant magnetic field \\(\\mathbf{B}\\). Find its equations of motion, solve for the trajectory, and describe what it looks like.\n\n\n\n\n\nIf \\(\\mathbf{v}\\) is the velocity of the particle, the magnetic force is given by \\(\\mathbf{F} = \\frac{q}{c} \\mathbf{v} \\times \\mathbf{B}\\). Suppose \\(\\mathbf{B} = B \\mathbf{e}_z\\). Then \\[\n\\mathbf{F} = \\frac{q}{c}\\mathbf{v} \\times \\mathbf{B} = \\frac{qB}{c}(\\dot y \\mathbf{e}_x - \\dot x \\mathbf{e}_y),\n\\] The equations of motion are thus\n\\[\n\\begin{align*}\nm \\ddot x &= \\frac{qB}{c} \\dot y , \\\\\nm \\ddot y &= -\\frac{qB}{c} \\dot x , \\\\\nm \\ddot z &=  0. \\\\\n\\end{align*}\n\\] Define \\(\\omega \\equiv \\frac{qB}{c}\\). The first two equations can be decoupled to give two independent SHO equations in the velocities,\n\\[\n\\begin{align*}\n\\ddot v_x &= -\\omega^2 v_x , \\\\\n\\ddot v_y &= -\\omega^2 v_y , \\\\\n\\end{align*}\n\\] with solutions\n\\[\n\\begin{align*}\nv_x(t) &= V_x \\cos(\\omega t - \\delta_x) , \\\\\nv_y(t) &= V_y \\cos(\\omega t - \\delta_y)  , \\\\\n\\end{align*}\n\\] Now, since \\(\\ddot v_x = \\omega \\dot v_y\\), we must have \\(V_x = V_y\\) and \\(\\delta_y = \\delta_x - \\frac{\\pi}{2}\\). Taking \\(\\delta_x=0\\) and \\(V_x = R\\omega\\) for convenience, we get\n\\[\n\\begin{align*}\nv_x(t) &= R\\omega \\cos(\\omega t) , \\\\\nv_y(t) &= -R\\omega \\sin(\\omega t)  , \\\\\n\\end{align*}\n\\] Finally, integrating the velocity equations gives the trajectory,\n\\[\n\\begin{align*}\nx(t) &=  x_0 + R \\sin(\\omega t), \\\\\ny(t) &= (y_0 - R) + R \\cos(\\omega t) , \\\\\nz(t) &=  z_0 + v_{0z} t. \\\\\n\\end{align*}\n\\] This is just a helix of radius \\(R\\) directed along the z-axis. That is, the particle will just spiral around in a helix directed along the line of the magnetic field. The frequency \\(\\omega\\) is called the cyclotron frequency. Since charge can be positive or negative, it carries a sign, which determines which way the particle will spiral. Notice that \\(R\\) is just the radius of orbit. It’s customarily expressed in terms of the tangential velocity \\(v_\\perp = \\sqrt{v_x^2 + v_y^2} = R\\omega\\), \\[\nR = \\frac{mcv_\\perp}{qB}.\n\\]",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Simple Systems</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/simple-systems.html#damped-harmonic-oscillation",
    "href": "classical-mechanics/simple-systems.html#damped-harmonic-oscillation",
    "title": "Simple Systems",
    "section": "Damped Harmonic Oscillation",
    "text": "Damped Harmonic Oscillation\nLet’s now combine the forces of linear drag with the forces of harmonic oscillation. In the 1-dimensional case, this gives the damped harmonic oscillator or DHO, \\[\nm \\ddot x + bx + kx = 0.\n\\] Define \\(\\beta \\equiv \\frac{b}{2m}\\) and \\(\\omega_0 \\equiv \\sqrt{\\frac{k}{m}}\\), called the damping constant and the natural frequency respectively. Then we can write the DHO equation of motion as \\[\n\\ddot x + 2\\beta x + \\omega_0^2 x = 0.\n\\] It’ll be insightful to solve this in its complex form. Consider instead the equation \\[\n\\ddot z + 2\\beta z + \\omega_0^2 z = 0,\n\\] where \\(z\\) is complex-valued. Let’s try and assume a trial solution of the form \\(z = A e^{i\\omega t - \\delta}\\). Plugging this into the differential equation, we get \\[\n(-\\omega^2 + 2\\beta + \\omega_0^2)A e^{i\\omega t - \\delta} = 0.\n\\] In the non-trivial case \\(A \\neq 0\\), this implies \\((-\\omega^2 + 2\\beta + \\omega_0^2) = 0\\), which we can solve for \\(\\omega\\) to get \\[\n\\omega = i\\beta \\pm \\sqrt{\\omega_0^2 - \\beta^2} \\equiv i\\beta \\pm \\omega',\n\\] where \\(\\omega' \\equiv \\sqrt{\\omega_0^2 - \\beta^2}\\). Plugging this into \\(z\\) then gives \\[\nz(t) = e^{-\\beta t}(c_1 e^{i\\omega' t} + c_2 e^{-i\\omega' t}).\n\\] When dealing with damped systems, it’s customary to define a quality factor \\(Q \\equiv \\frac{\\omega_0}{2\\beta}\\), which expresses in relative terms how much the system is being damped. We can re-write \\(\\omega'\\) in terms of the Q-factor as \\[\n\\omega' = \\omega_0 \\sqrt{1 - \\bigg(\\frac{1}{2Q}\\bigg)^2}.\n\\] Evidently, the form of the solutions divide into three cases depending on the sign of \\(\\omega'\\):\n\nUnderdamping (\\(\\omega' &gt; 0\\) or \\(Q &lt; \\frac{1}{2}\\)): In this case, \\(\\omega'\\) is real, which means we have a real solution \\[\nx(t) = A e^{-\\beta t} \\cos(\\omega't - \\delta).\n\\] This is an exponentially damped sinusoidal oscillation, where \\(x \\rightarrow 0\\) with time constant \\(\\tau = \\frac{1}{\\beta}\\). Notice \\(\\omega' &lt; \\omega_0\\), which means the actual frequency of the oscillation is less than the natural frequency. When \\(Q \\gg 1\\) this distinction disappears, since \\(\\omega' \\approx \\omega_0\\). In practice this occurs frequently for underdamped solutions, and \\(Q\\) need not even be large for \\(\\omega' \\approx \\omega_0\\).\n\n\n\n\n\nOverdamping (\\(\\omega' &lt; 0\\) or \\(Q &gt; \\frac{1}{2}\\)): In this case, \\(\\omega'\\) is complex. Define \\(\\kappa \\equiv i\\omega'\\), which is real-valued. Then we have a solution of the form \\[\nx(t) = e^{-\\beta t}(c_1 e^{\\kappa t} + c_2 e^{-\\kappa t}).\n\\] Since \\(\\kappa &lt; \\beta\\), \\(x \\rightarrow 0\\) monotonically, with time constant \\(\\tau = \\frac{1}{\\beta - \\kappa}\\).\n\n\n\n\n\nCritical damping (\\(\\omega' = 0\\) or \\(Q = \\frac{1}{2}\\)): This is the edge case where \\(\\omega_0 = \\beta\\) exactly. Here the solution is degenerate, with \\[\nx(t) = (c_1 + c_2 t) e^{-\\beta t}.\n\\] Again, \\(x \\rightarrow 0\\), but with time constant \\(\\tau = \\frac{1}{\\beta}\\). Evidently, the critically damped solution decays faster than the overdamped solution.\n\n\n\n\n\n\nIn all three cases the system must eventually come to rest due to the presence of damping. Only the “high Q” systems are allowed to oscillate. Note that as \\(\\beta \\rightarrow 0\\), \\(Q \\rightarrow \\infty\\). In this limit the solution turns into regular SHO, with \\(\\omega' \\rightarrow \\omega_0\\).",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Simple Systems</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/simple-systems.html#driven-damped-harmonic-oscillation",
    "href": "classical-mechanics/simple-systems.html#driven-damped-harmonic-oscillation",
    "title": "Simple Systems",
    "section": "Driven Damped Harmonic Oscillation",
    "text": "Driven Damped Harmonic Oscillation\nLet’s now add in the independent force term to the mix. In the 1-dimensional case, we get the equation of motion \\[\nm \\ddot x + b \\dot x + kx = F_0(t).\n\\] This is called the driven damped harmonic oscillator or DDHO. We imagine \\(F_0(t)\\) to be some external driving force acting on the system. It’s again convenient to rewrite things by defining \\(\\beta = \\frac{b}{2m}\\), \\(\\omega_0^2 = \\frac{k}{m}\\), and \\(f(t) = \\frac{F_0(t)}{m}\\). Then we have the linear differential equation \\[\n\\ddot x + 2\\beta\\dot x + \\omega_0^2 x = f(t).\n\\] Recall that the solutions of linear differential equations can be decomposed into two pieces, a homogenous solution and a particular solution. The homogenous solution is the general solution to \\[\n\\ddot x_h + 2\\beta\\dot x_h + \\omega_0^2 x_h = 0.\n\\] But this is just a DHO. We solved that part already. All we need to do now is find any particular solution that will solve \\[\n\\ddot x_p + 2\\beta\\dot x_p + \\omega_0^2 x_p = f(t).\n\\] Provided we do that, the full, general solution will be \\(x(t) = x_h(t) + x_p(t)\\). There are several ways to find a particular solution, including guessing methods and more systematic methods like Green functions and Fourier transforms. We’ll briefly touch on some of these.\n\n\nExample: Underdamped hanging spring\nSuppose a spring is suspended vertically from a ceiling under the presence of gravity. Find the position \\(x=x(t)\\). Also, find the amount that gravity changes the spring’s equilibrium length.\n\n\n\n\n\nThe forces in this problem are gravity, linear drag, and a spring force, so if \\(x\\) points downward, \\[\nF = mg - bv - kx.\n\\] The equation of motion is thus given by \\[\nm \\ddot x + b \\dot x + kx = mg.\n\\] This is just DDHO with \\(f(t) = g\\). We thus seek a particular solution \\(x_p(t)\\) such that \\[\n\\ddot x_p + 2\\beta\\dot x_p + \\omega_0^2 x_p = g.\n\\] Assume a trial solution of the form \\(x_p = c\\). Then, \\[\n\\omega_0^2 c = g \\Longrightarrow c = \\frac{g}{\\omega_0^2} = \\frac{gm}{k}.\n\\] Supposing the spring is underdamped, then \\[\nx(t) = Ae^{-\\beta t} \\cos(\\omega' t - \\delta) + \\frac{gm}{k}.\n\\] The new equilibrium occurs when the object is at rest, i.e. when \\(\\ddot x = \\dot x = 0\\). This occurs at \\(x = \\frac{gm}{k}\\) relative to the free equilibrium \\(x=0\\).\n\n\n\nSinusoidal Driving Forces\nThe most interesting driving forces in practice are ones that are periodic. Periodic driving functions lead to the important concept of resonance, which is a phenomenon that occurs when the driving frequency matches the natural frequency.\nConsider a sinusoidal driving force of the form \\(f(t) = f_0 \\cos\\omega t\\). In complex form, we can then write \\[\n\\ddot z + 2\\beta\\dot z + \\omega_0^2 z = f_0 e^{i \\omega t}.\n\\] Assume a particular solution of the form \\(z(t) = \\tilde A e^{i \\omega t}\\) where \\(\\tilde A = Ae^{-i\\delta}\\). Plugging this in, we have \\[\n(-\\omega^2 + 2\\beta\\omega i + \\omega_0^2)\\tilde A e^{-i\\omega t} = f_0 e^{i\\omega t},\n\\] which we can solve for the complex amplitude \\(\\tilde A\\) to get \\[\n\\tilde A = \\frac{f_0}{(\\omega_0^2-\\omega^2) + 2\\beta\\omega i}.\n\\] With the help of little trig, we can decompose this solution to get the real amplitude and phase,\n\n\n\n\n\n\\[\nA = \\frac{f_0}{\\sqrt{(\\omega_0^2-\\omega^2)^2 + 4\\beta^2\\omega^2}}, \\quad \\delta = \\tan^{-1} \\frac{2\\beta\\omega}{\\omega_0^2-\\omega^2}.\n\\]\nWith these, the real particular solution is given by \\(x_p(t) = A \\cos(\\omega t - \\delta)\\). Since the homogenous solution decays to zero exponentially, \\(x \\rightarrow x_p\\) as \\(t \\rightarrow \\infty\\). That is, \\(x_p(t)\\) describes the steady state solution of the DDHO. In this sense, the system evidently “forgets” its own natural frequency and starts to oscillate at the driving frequency as time goes on and the transient state dies off.\n\n\n\n\n\nInterestingly, the memory of the transient dynamics is preserved in the amplitude and phase. As a rule of thumb, the number of oscillations \\(N\\) until \\(x \\approx x_p\\) is basically just the Q-factor, \\[\nN \\approx \\frac{Q}{\\pi}.\n\\] Let’s now look more deeply at the amplitude and phase. It’s worth asking how they depend on the external driving frequency \\(\\omega\\).\n\nWhen \\(\\omega \\ll \\omega_0\\), \\(A \\approx \\frac{f_0}{\\omega_0^2}\\) and \\(\\delta \\approx 0\\).\nWhen \\(\\omega \\gg \\omega_0\\), \\(A \\approx 0\\) and \\(\\delta \\approx \\pi\\).\nWhen \\(\\omega \\approx \\omega_0\\), \\(A \\approx \\frac{f_0}{2\\beta\\omega_0}\\) and \\(\\delta \\approx \\frac{\\pi}{2}\\).\n\n\n\n\n\n\nEvidently, \\(A\\) is maximized at \\(\\omega_R = \\sqrt{\\omega_0^2-2\\beta^2} = \\omega_0 \\sqrt{1-\\frac{1}{2Q^2}}\\). When \\(Q&gt;1\\), \\(\\omega_R \\approx \\omega_0\\), so this distinction doesn’t really matter. This frequency \\(\\omega_R \\approx \\omega_0\\) is called the resonance frequency of the system. When the driver is operating near the resonance frequency, the system responds extremely well to the driving force. It turns out that when a spectrum of frequencies is dumped on an oscillating system, the system tends to pick out the resonance frequencies and respond to those. This fact makes resonance a very important topic in physics and engineering.\nIn practice, high-Q systems are very common. In those cases, \\(A\\) dies off quickly when the driving frequencies aren’t close to \\(\\omega_0\\). That means practically all the interesting behavior of a high-Q systems is in the band around the resonance frequency. Suppose \\(\\Delta \\equiv \\omega - \\omega_0\\) is small. Then we can write \\[\n(\\omega_0^2-\\omega^2) = (\\omega_0-\\omega)(\\omega_0+\\omega) = -\\Delta(2\\omega_0+\\Delta) \\approx -2\\omega_0 \\Delta.\n\\] That means we can write the complex amplitude \\(\\tilde A\\) as \\[\n\\tilde A = \\frac{f_0}{(\\omega_0^2-\\omega^2) + 2\\beta\\omega i} \\approx -\\frac{\\frac{f_0}{2\\omega_0}}{\\Delta-\\beta i} = \\frac{f_0}{2\\omega_0}\\bigg(-\\frac{\\Delta}{\\Delta^2+\\beta^2} + i\\frac{\\beta}{\\Delta^2+\\beta^2} \\bigg).\n\\] This function on the right is called the Lorentzian. Using this, we can see \\[\nA \\approx \\frac{f_0}{2\\omega_0} \\frac{1}{\\sqrt{\\Delta^2 + \\beta^2}} \\quad \\Longrightarrow \\quad A^2 \\approx \\bigg(\\frac{f_0}{2\\omega_0}\\bigg)^2 \\frac{1}{\\Delta^2 + \\beta^2}.\n\\] Since the energy in a harmonic oscillator is just \\(E = \\frac{1}{2}kA^2 \\propto A^2\\), it’s common to look at plots of \\(A^2\\) when plotting these resonance curves. Evidently, \\(A^2 \\rightarrow 0\\) as \\(\\Delta \\rightarrow \\infty\\), and it’s maximized when \\(\\Delta = 0\\), which is when \\(\\omega = \\omega_0\\) and \\(A_{max}^2 = \\big(\\frac{f_0}{2\\omega_0 \\beta}\\big)^2\\).\nIt’s common to measure the width of the resonance curve by using the full width at half maximum or FWHM. The FWHM is defined as the difference between the left and right points around the maximum whose height is half the maximum, \\[\nFWHM \\equiv \\Delta \\omega \\equiv \\omega_R - \\omega_L, \\quad \\text{where} \\quad A^2(\\omega_L) = A^2(\\omega_R) = \\frac{1}{2}A_{max}.\n\\] Solving for these left and right points gives \\(\\omega_L = \\omega_0 - \\beta\\) and \\(\\omega_R = \\omega_0 + \\beta\\), so \\[\n\\Delta \\omega = (\\omega_0 + \\beta) - (\\omega_0 - \\beta) = 2\\beta.\n\\] The resolving power of the resonance curve is then \\[\n\\frac{\\omega_0}{\\Delta} = \\frac{\\omega_0}{2\\beta} = Q.\n\\] Evidently then, \\(Q\\) represents the resolving power of the resonance curve. The higher the Q-factor is, the more sharply peaked the resonance curve is, and the easier we can pinpoint the resonance frequency exactly. Indeed, this is why \\(Q\\) is called a quality factor.\n\n\n\n\n\nOne very important system where we want a high-Q is a clock. To keep precise time, we need to make sure that it’s oscillating pretty much exactly at its resonance frequencies. This is because we need to keep a regular period, so \\(\\tau = \\frac{2\\pi}{\\omega}\\) can’t be allowed to vary very much from the true period \\(\\tau_0 = \\frac{2\\pi}{\\omega_0}\\). There’s a tradeoff though. Since the decay time of the transient behavior is \\(N\\tau_0 \\equiv \\frac{1}{\\beta}\\), it takes about \\(N=\\frac{Q}{\\pi}\\) cycles of ringing for the system to come to steady state. So the better precision we want, the longer we’ll have to wait for the system to come to steady state.\nNote that \\(Q\\) also affects the phase curve of the system, since \\[\n\\delta = \\tan^{-1} \\frac{2\\beta\\omega}{\\omega_0^2-\\omega^2} \\approx \\tan^{-1} \\frac{2\\omega}{Q\\Delta}.\n\\] Evidently as \\(Q\\) increases, the system becomes more responsive to sudden changes in phase around \\(\\omega_0\\).\n\n\n\n\n\n\n\nArbitrary Driving Forces\nThe situation where resonance occurs in a DDHO system is not just confined to sinusoidal driving forces. Using Fourier analysis, we can decompose more arbitrary driving forces into a sum of sinusoidal driving forces of different frequencies. The simplest of these cases is when the driving force is periodic with some period \\(\\tau\\). Even if the driver isn’t sinusoidal, we can decompose it into a linear combination of cosines of different frequencies, i.e. a Fourier Series, \\[\nf(t) = \\sum_{n=-\\infty}^{\\infty} f_n e^{i \\omega n t},\n\\] where each \\(f_n\\) can be found via the formula \\[\nf_n = \\langle f(t), e^{i \\omega n t} \\rangle = \\frac{\\omega}{\\pi} \\int_0^{\\tau} f(t) e^{i \\omega n t} dt.\n\\] Using the principle of superposition, we could then find the solution for each of the sinusoidal drivers term by term, and then sum them together to get the full solution. Each term will have amplitude and phase \\[\nA_n = \\frac{f_n}{\\sqrt{(\\omega_0^2-\\omega^2 n^2)^2 + (2\\beta\\omega n)^2}}, \\quad \\delta_n = \\tan^{-1} \\frac{2\\beta\\omega n}{\\omega_0^2-\\omega^2n^2}.\n\\] Plugging these in will yield a general solution of the form \\[\nx(t) = x_h(t) + \\sum_{n=1}^{\\infty} A_n \\cos(\\omega n t - \\delta_n).\n\\] Each component will yield its own resonance frequency where \\(\\omega n \\approx -\\omega_0\\). As a function of the main driving frequency, this means there will resonances at each \\(\\omega_n = \\frac{\\omega_0}{n}\\). The resonance curve for \\(A^2\\) can be found via Parseval’s Theorem, which says \\[\nA^2 = \\langle x^2(t) \\rangle = \\frac{1}{2} \\sum_{n=0}^\\infty A_n^2.\n\\] The peaks evidently go to zero as \\(n \\rightarrow \\infty\\) since each \\(A_n^2 \\propto f_n^2\\) and each \\(f_n \\rightarrow 0\\) by the Riemann–Lebesgue lemma.\n\n\n\n\n\nWhat if the driving force isn’t periodic? In this case we have a few options. One would be to decompose it into its Fourier transform, \\[\nf(t) = \\int_{-\\infty}^{\\infty} f(\\omega) e^{i\\omega t} dt.\n\\] Then each term gives a set of complex amplitudes and phases that can be solved for and stitched back together to get \\(x(t)\\). Another solution that’s perhaps more common is to use Green’s functions. Instead of decomposing the driver into a linear combination of periodic functions, we’ll decompose it into a linear combination of impulse responses or delta functions, \\[\nf(t) = \\int_{-\\infty}^{\\infty} f(t') \\delta(t-t') dt'.\n\\] To find the solution \\(x(t)\\), we first need to find the particular solution \\(G(t-t')\\) to the DDHO with an impulse response, \\[\n\\ddot G + 2\\beta\\dot G + \\omega_0^2 G = \\delta(t - t').\n\\] Once this is found, we can stitch together the full solution as \\[\nx(t) = \\int_{-\\infty}^{\\infty} f(t') G(t-t') dt'.\n\\] Note the Green’s function solution already incorporates in the homogeneous solution since \\(G(t-t')\\) must itself satisfy the initial conditions.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Simple Systems</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/reference-frames.html",
    "href": "classical-mechanics/reference-frames.html",
    "title": "Reference Frames",
    "section": "",
    "text": "Orthogonal Transformations\nSuppose \\(\\mathbf{x}\\) is some vector, and \\(\\{\\mathbf{e}_i\\}\\) and \\(\\{\\mathbf{e}_i'\\}\\) are two orthonormal bases for \\(\\mathbb{R}^3\\), then \\[\n\\mathbf{x} = \\sum_{j=1}^3 x_j \\mathbf{e}_j = \\sum_{i'=1}^3 x_{i'} \\mathbf{e}_{i'},\n\\] where \\(x_i = \\mathbf{x} \\cdot \\mathbf{e}_i\\) and \\(x_i' = \\mathbf{x} \\cdot \\mathbf{e}_i'\\).\nNotation: From now on we’ll use the Einstein summation convention. If a repeated index occurs in a sum, we’ll omit the \\(\\sum\\) symbol. For example, we can re-write the above line as the following, where it’s understood we’re summing over \\(j\\) and \\(i'\\) in each case, \\[\n\\mathbf{x} = x_j \\mathbf{e}_j = x_{i'} \\mathbf{e}_{i'}.\n\\] Now, observe we can write one component in terms of the other as \\[\nx_i' = \\mathbf{x} \\cdot \\mathbf{e}_{i'} = (\\mathbf{e}_j \\cdot \\mathbf{e}_{i'}) x_j \\equiv R_{i'j} x_j,\n\\] where \\(R_{i'j} = \\mathbf{e}_j \\cdot \\mathbf{e}_i'\\) defines a matrix \\(\\mathbf{R}\\) called an orthogonal transformation.\nNotice that if we take the inner product of two vectors \\(\\mathbf{x}\\) and \\(\\mathbf{y}\\), we get \\[\n\\mathbf{x} \\cdot \\mathbf{y} = x_{i'} \\delta_{i' j'} x_{j'} = R_{ii'} \\delta_{i'j'} R_{j'j} x_i x_j = \\mathbf{x} \\cdot (\\mathbf{R}^\\top \\mathbf{R}) \\mathbf{y}.\n\\] Thus, an orthogonal transformation \\(\\mathbf{R}\\) satisfies the property that \\[\n\\mathbf{R}^\\top \\mathbf{R} = \\mathbf{I}, \\quad \\text{or} \\quad R_{ij} R_{jk} = \\delta_{ik}.\n\\] Due to the inner product preserving nature of orthogonal transformations, they can in a sense be used to define what we mean by a scalar or vector or tensor in classical mechanics. They’re objects that transform a certain way under an orthogonal transformation:\nNotice since \\(\\mathbf{R}^\\top \\mathbf{R} = \\mathbf{I}\\), we can take the determinant of both sides to get \\(\\det(\\mathbf{R}^\\top \\mathbf{R}) = \\det^2(\\mathbf{R}) = 1\\), which implies that \\(\\det(\\mathbf{R}) = \\pm 1\\). This fact divides orthogonal transformations into two distinct classes:\nMost vector operations are proper, in the sense that they preserve the handedness of the underlying coordinate system. If \\(\\mathbf{v}\\) is a vector, they’ll transform under a reflection to \\(-\\mathbf{v}\\). The one major exception is the cross product, which reverses the handedness. Under a reflection, it keeps its sign, \\[\n\\mathbf{v} \\times \\mathbf{w} \\Rightarrow (-\\mathbf{v}) \\times (-\\mathbf{w}) = \\mathbf{v} \\times \\mathbf{w}.\n\\] For this reason, cross products are sometimes called pseudovectors or axial vectors to distinguish them from ordinary vectors that transform under a reflection as \\(\\mathbf{v} \\Rightarrow -\\mathbf{v}\\).\nAside: It turns out that the set of all orthogonal transformations on \\(\\mathbb{R}^3\\) form a group \\(G\\), in the sense that it satisfies the following special “symmetry” properties:\nThe group of orthogonal transformations under matrix multiplication is called the orthogonal group, denoted \\(O(3)\\). The subset of \\(O(3)\\) where \\(\\det(\\mathbf{R})=1\\) happens to form a subgroup, i.e. a subset of \\(O(3)\\) that’s closed under group operations. It’s called the special orthogonal group, denoted \\(SO(3)\\). This is essentially the group of all rotations in 3 dimensions. The orthogonal groups turn out to be very important in understanding the theory of angular momentum, especially in quantum mechanics.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reference Frames</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/reference-frames.html#orthogonal-transformations",
    "href": "classical-mechanics/reference-frames.html#orthogonal-transformations",
    "title": "Reference Frames",
    "section": "",
    "text": "A scalar is any object \\(\\alpha\\) that is invariant under an orthogonal transformation, \\[\n\\alpha' = \\alpha.\n\\]\nA vector is any object \\(\\mathbf{v}\\) that transforms under an orthogonal transformation as, \\[\nv_{i'} = R_{i'i} v_i.\n\\]\nA tensor of order \\(k\\) is any object \\(\\mathbf{T}\\) that transforms under an orthogonal transformation as, \\[\nT_{i_1' i_2' \\cdots i_k'} = R_{i_1' i_1} R_{i_2' i_2} \\cdots R_{i_k' i_k} T_{i_1 i_2 \\cdots i_k}.\n\\]\n\n\n\nProper Rotations (\\(\\det(\\mathbf{R}) = 1\\)): These correspond to pure rotations in space. They preserve the handedness of the underlying coordinate system.\nImproper Rotations (\\(\\det(\\mathbf{R}) = -1\\)): These correspond to reflections in space, which are transformations \\(\\mathbf{v} \\Rightarrow -\\mathbf{v}\\) combined with a pure rotation. These transformations permute the handedness of the underlying coordinate system.\n\n\n\n\n\n\n\n\n\nClosure: If \\(A, B \\in G\\) , then \\(AB \\in G\\) also.\nAssociativity: For any \\(A,B,C \\in G\\), we have \\((AB)C = A(BC)\\).\nIdentity: There is a unique element \\(I \\in G\\) satisfying \\(IA = AI\\) for any \\(A \\in G\\).\nInvertibility: For any \\(A \\in G\\), there is an inverse element \\(A^{-1}\\) such that \\(A^{-1} A = A A^{-1} = I\\).\n\n\n\nExample: Rotations in two dimensions\nWe can easily figure out what proper rotations look like in 2D space by looking at how to relate one basis with another. Suppose \\(\\{\\mathbf{e}_x, \\mathbf{e}_y \\}\\) is the standard basis for \\(\\mathbb{R}^2\\), and \\(\\{\\mathbf{e}_{x'}, \\mathbf{e}_{y'}\\}\\) is some other orthonormal basis. Suppose \\(\\varphi\\) is the angle between \\(\\mathbf{e}_x\\) and \\(\\mathbf{e}_{x'}\\). Using a little geometry, we have,\n\n\n\n\n\n\\[\n\\begin{align*}\nR_{x'x} &= \\mathbf{e}_{x'} \\cdot \\mathbf{e}_x = \\cos\\varphi,\n&R_{x'y} &= \\mathbf{e}_{x'} \\cdot \\mathbf{e}_y = \\sin\\varphi, \\\\\nR_{y'x} &= \\mathbf{e}_{y'} \\cdot \\mathbf{e}_x = -\\sin\\varphi,\n&R_{y'y} &= \\mathbf{e}_{y'} \\cdot \\mathbf{e}_y = \\cos\\varphi. \\\\\n\\end{align*}\n\\] We can thus express any proper rotation in \\(\\mathbb{R}^2\\) using a \\(2 \\times 2\\) matrix of the form \\[\n\\mathbf{R}(\\varphi) =\n\\begin{pmatrix}\n\\cos\\varphi & \\sin\\varphi \\\\\n-\\sin\\varphi & \\cos\\varphi\n\\end{pmatrix}.\n\\] This is the matrix that rotates the underlying basis \\(\\{\\mathbf{e}_x, \\mathbf{e}_y \\}\\) to the new, rotated basis \\(\\{\\mathbf{e}_{x'}, \\mathbf{e}_{y'} \\}\\).\n\n\nActive vs Passive Transformations\nThe previous example suggests that we can think about a rotation in space two different ways. One way is to rotate the underlying basis and keep the vector \\(\\mathbf{v}\\) fixed. That is, \\(\\mathbf{e}_i \\Rightarrow R_{i'i} \\mathbf{e}_i\\).. This way of looking at a rotation is called a passive transformation. It rotates the coordinate system under \\(\\mathbf{v}\\), not \\(\\mathbf{v}\\) itself.\nAnother way of looking at a rotation is to imagine keeping the coordinate system fixed, but rotating the components of the vector \\(\\mathbf{v}\\) directly. That is, \\(v_i \\Rightarrow R_{i'i}v_i\\). This way of looking at a rotation is called an active transformation. Despite sounding semantically different, these two ways are physically equivalent. Note though that if a vector rotates actively under \\(\\mathbf{R}(-\\varphi)\\), it will rotate passively under \\(\\mathbf{R}(\\varphi)\\).\n\n\n\n\n\nIt’s usually more convenient to assume rotations are active transformations. The major exception is when dealing with rigid bodies, where it’s more convenient to passively transform to body coordinates. Note the same logic applies to 3D transformations. In that case, there are now three angles of rotation to deal with, not just one.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reference Frames</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/reference-frames.html#linearly-accelerating-frames",
    "href": "classical-mechanics/reference-frames.html#linearly-accelerating-frames",
    "title": "Reference Frames",
    "section": "Linearly Accelerating Frames",
    "text": "Linearly Accelerating Frames\nLet’s now examine the motion of systems in non-inertial reference frames. In examining accelerating frames, we’ll treat them as static coordinate systems, completely ignoring the forces that cause the reference frame to accelerate in the first place. We’ll start with linearly accelerating frames.\nSuppose a system is “locked into” a reference frame \\(S_{rel}\\), which is itself moving at a velocity \\(\\mathbf{v}_0\\) with respect to an inertial lab frame \\(S\\). We’ll seek out the equations of motion with respect to the non-inertial frame \\(S_{rel}\\).\n\n\n\n\n\nEvidently, \\(\\mathbf{x} = \\mathbf{x}_{rel} + \\mathbf{v}_0t\\), which means \\(\\mathbf{v} = \\mathbf{v}_{rel} + \\mathbf{v}_0\\), and \\(\\mathbf{a} = \\mathbf{a}_{rel} + \\mathbf{a}_0\\). When \\(\\mathbf{a}_0=\\mathbf{0}\\) we recover the special case of a Galilean transformation. In that case, \\(\\mathbf{F} = m \\mathbf{a} = m \\mathbf{a}_{rel}\\), which means \\(S_{rel}\\) is by definition an inertial frame.\nIf \\(\\mathbf{a}_0 \\neq \\mathbf{0}\\), we get \\(\\mathbf{F} = m(\\mathbf{a}_0 + \\mathbf{a}_{rel})\\), or \\(m\\mathbf{a}_{rel} = \\mathbf{F} - m \\mathbf{a}_0\\). We can think about this in another way, by defining a relative force \\(\\mathbf{F}_{rel} = m\\mathbf{a}_{rel}\\) and thinking of it as being composed of an inertial force \\(\\mathbf{F}\\) along with a fictitious force \\(\\mathbf{F}_{lin} = -m\\mathbf{a}_0\\), \\[\n\\mathbf{F}_{rel} = \\mathbf{F} + \\mathbf{F}_{lin} = \\mathbf{F} - m \\mathbf{a}_0.\n\\] One special case of a linear accelerating frame is an object free-falling under gravity. In that case, \\(\\mathbf{a}_0=-\\mathbf{g}\\) is constant. In some sense, this means we can treat gravity as a kind of generalized coordinate transformation that shifts the acceleration from \\(\\mathbf{a}\\) to \\(\\mathbf{a}_{rel} = \\mathbf{a} + \\mathbf{g}\\). This curious fact arises due to the equivalence principle, which says the gravitational force is proportional to the inertial mass \\(m\\). This curious fact causes the \\(m\\) to cancel from both sides of \\(m\\mathbf{a} = m\\mathbf{g}\\). As far as we know, gravity is the only force in nature with this special property. The equivalence principle is essentially the launch point to Einstein’s general theory of relativity.\n\n\n\n\n\n\n\nExample: Pendulum in an accelerating railcar\nA railcar is moving along the x-axis at a constant acceleration \\(\\mathbf{a}_0\\) with respect to the lab frame. Inside the railcar, a pendulum with mass \\(m\\) and length \\(\\ell\\) is attached to the ceiling and allowed to swing freely. Find the equations of motion for the swinging pendulum. Also, find the equilibrium position of the pendulum.\n\n\n\n\n\nWorking in the frame of the railcar, we have \\(\\mathbf{F}_{rel} = \\mathbf{F} + \\mathbf{F}_{lin}\\). The inertial forces on the pendulum are the string tension \\(\\mathbf{T}\\) and gravity \\(m\\mathbf{g}\\). We thus have \\[\nm\\mathbf{a}_{rel} = \\mathbf{T} + m\\mathbf{g} - m\\mathbf{a}_0 \\equiv \\mathbf{T} + m\\mathbf{g}_{eff},\n\\] where \\(\\mathbf{g}_{eff} \\equiv \\mathbf{g} - \\mathbf{a}_0\\) acts as an effective gravity on the pendulum inside the moving railcar. We can thus use the standard method to solve for the pendulum, but replacing \\(\\mathbf{g}\\) with \\(\\mathbf{g}_{eff}\\), to get \\[\n\\ddot \\theta = -\\omega^2 \\sin \\theta, \\quad \\text{where} \\quad \\omega^2 \\equiv \\frac{|\\mathbf{g}_{eff}|}{\\ell} = \\frac{\\sqrt{g^2 + a_0^2}}{\\ell}.\n\\] The equilibrium position occurs when \\(\\mathbf{F}_{rel}=\\mathbf{0}\\), which is when \\(\\mathbf{T} = -m\\mathbf{g}_{eff}\\). Using a little trig, we can see the equilibrium angle will be shifted to the angle \\(\\theta_{eq}\\) given by\n\n\n\n\n\n\\[\n\\theta_{eq} = \\tan^{-1} \\frac{g}{a_0}.\n\\]\nNotice when \\(a_0\\) we get \\(\\theta_{eq}=0\\), which is what we’d expect if the railcar weren’t accelerating.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reference Frames</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/reference-frames.html#rotating-frames",
    "href": "classical-mechanics/reference-frames.html#rotating-frames",
    "title": "Reference Frames",
    "section": "Rotating Frames",
    "text": "Rotating Frames\nLet’s now look at reference frames that are rotating about some axis. Without loss of generality, we’ll consider a reference frame \\(S_{rot}\\) that’s rotating about the z-axis with respect to the lab frame \\(S\\) at some angular velocity \\(\\boldsymbol{\\omega} = \\dot \\varphi \\mathbf{e}_z\\).\n\n\n\n\n\nLet \\(\\mathbf{A}\\) be some vector in this rotating frame that’s at an angle \\(\\theta\\) with the axis of rotation. The amount that \\(\\mathbf{A}\\) changes due to the frame’s rotation by an amount \\(\\delta\\varphi\\) is given by \\[\n\\delta A = A_\\perp \\delta\\varphi = A\\sin\\theta\\delta\\varphi = |\\mathbf{A} \\times \\delta\\boldsymbol{\\varphi}|,\n\\] so by the right-hand rule we have \\(\\delta\\mathbf{A} = \\delta\\boldsymbol{\\varphi} \\times \\mathbf{A}\\). Dividing both sides by \\(dt\\), we finally have \\[\n\\frac{d\\mathbf{A}}{dt} = \\boldsymbol{\\omega} \\times \\mathbf{A}.\n\\] Remark:  Since velocities add as vectors, so too do angular velocities. This means if \\(S'\\) is a frame rotating relative \\(S\\), and \\(S''\\) is yet another frame that’s rotating to \\(S'\\), then we have \\[\n\\mathbf{v}_S'' = \\mathbf{v}_S' + \\mathbf{v}_{S'}'' \\quad \\Longrightarrow \\quad  \\boldsymbol{\\omega}_S'' \\times \\mathbf{r}_S = \\boldsymbol{\\omega}' \\times \\mathbf{r}_S + \\boldsymbol{\\omega}'' \\times \\mathbf{r}_{S'} \\quad \\Longrightarrow \\quad  \\boldsymbol{\\omega}_S'' = \\boldsymbol{\\omega}_S' + \\boldsymbol{\\omega}_{S'}''.\n\\] This fact allows us to easily solve problems involving complex hierarchies of rotations.\nNow, suppose \\(S_{rot}\\) is rotating with angular velocity \\(\\boldsymbol{\\omega}\\) with respect to the origin of \\(S\\). With respect to an observer in each frame, a vector \\(\\mathbf{A} = A_i \\mathbf{e}_i = A_i^{rot}\\mathbf{e}_i = \\mathbf{A}_{rel}\\) changes as\n\\[\n\\begin{align*}\n\\frac{d\\mathbf{A}}{dt}\\bigg|_{rot} &= \\dot A_i^{rot} \\mathbf{e}_i^{rot}, \\\\\n\\frac{d\\mathbf{A}}{dt}\\bigg|_{lab} &= \\dot A_i^{rot} \\mathbf{e}_i^{rot} + A_i^{rot} \\mathbf{\\dot e}_i^{rot}, \\\\\n\\frac{d\\mathbf{e}_i^{rot}}{dt}\\bigg|_{lab} &= \\boldsymbol{\\omega} \\times \\mathbf{e}_i^{rot}.\n\\end{align*}\n\\] Thus, we have \\[\n\\frac{d\\mathbf{A}}{dt}\\bigg|_{lab} = \\frac{d\\mathbf{A}}{dt}\\bigg|_{rot} + \\boldsymbol{\\omega} \\times \\mathbf{A}_{rot}\n\\] This evidently defines a transport operation between the lab frame and the rotating frame. Namely, time derivatives in the lab frame are related to time derivatives in the rotating frame via \\[\n\\frac{d}{dt}\\bigg|_{lab} = \\frac{d}{dt}\\bigg|_{rot} + \\boldsymbol{\\omega} \\times.\n\\] This result is sometimes called the transport theorem.\nUsing the transport theorem we can now derive what the equations of motion look like inside the rotating frame. Plugging \\(\\mathbf{x}\\) into the transport equation, we get \\[\n\\frac{d\\mathbf{x}}{dt}\\bigg|_{lab} = \\frac{d\\mathbf{x}}{dt}\\bigg|_{rot} + \\boldsymbol{\\omega} \\times \\mathbf{x}_{rot},\n\\] or \\[\n\\mathbf{v} = \\mathbf{v}_{rot} + \\boldsymbol{\\omega} \\times \\mathbf{x}_{rot}.\n\\] To get the acceleration \\(\\mathbf{a}\\), we need to apply the transport equation again to the velocity vector,\n\\[\n\\begin{align*}\n\\frac{d\\mathbf{v}}{dt}\\bigg|_{lab} &= \\bigg(\\frac{d}{dt}\\bigg|_{rot} + \\boldsymbol{\\omega} \\times \\bigg) (\\mathbf{v}_{rot} + \\boldsymbol{\\omega} \\times \\mathbf{x}_{rot}) \\\\\n&= \\mathbf{\\dot v}_{rot} + \\boldsymbol{\\omega} \\times \\mathbf{v}_{rot} + \\boldsymbol{\\dot \\omega} \\times \\mathbf{x}_{rot} + \\boldsymbol{\\omega} \\times \\mathbf{v}_{rot} + \\boldsymbol{\\omega} \\times (\\boldsymbol{\\omega} \\times \\mathbf{x}_{rot}).\n\\end{align*}\n\\] Or after cleaning up a bit, \\[\n\\mathbf{a} = \\mathbf{a}_{rot} + 2 \\boldsymbol{\\omega} \\times \\mathbf{v}_{rot} + \\boldsymbol{\\dot \\omega} \\times \\mathbf{x}_{rot} + \\boldsymbol{\\omega} \\times (\\boldsymbol{\\omega} \\times \\mathbf{x}_{rot}).\n\\]\nSince \\(\\mathbf{F} = m \\mathbf{a}\\) in the lab frame, we can multiply both sides by \\(m\\) and re-arrange terms to get the force vector \\(\\mathbf{F}_{rot}\\), \\[\n\\mathbf{F}_{rot} = \\mathbf{F} + m \\boldsymbol{\\omega} \\times (\\mathbf{x}_{rot} \\times \\boldsymbol{\\omega}) + 2m \\mathbf{v}_{rot} \\times \\boldsymbol{\\omega} + m \\mathbf{x}_{rot} \\times \\boldsymbol{\\dot \\omega}.\n\\] Evidently, there are three distinct fictitious force terms. Naturally, they each have special names:\n\nCentrifugal Force: \\(\\mathbf{F}_{cf} = m \\boldsymbol{\\omega} \\times (\\mathbf{x}_{rot} \\times \\boldsymbol{\\omega}) = m(\\boldsymbol{\\omega} \\cdot \\mathbf{x}_{rot})\\mathbf{x}_{rot} - m\\omega^2 \\mathbf{x}_{rot}\\).\nCoriolis Force: \\(\\mathbf{F}_{cor} = 2m \\mathbf{v}_{rot} \\times \\boldsymbol{\\omega}\\).\nEuler Force: \\(\\mathbf{F}_{eul} = m \\mathbf{x}_{rot} \\times \\boldsymbol{\\dot \\omega}\\).\n\nIn terms of these forces, we can finally write the force experienced in the rotating frame as \\[\n\\mathbf{F}_{rot} = \\mathbf{F} + \\mathbf{F}_{cf} + \\mathbf{F}_{cor} + \\mathbf{F}_{eul}.\n\\] The centrifugal force tends to push a rotating object outward radially from the origin, similar to how a centrifuge works. In the simple case when the position is perpendicular to the axis of rotation, the centrifugal force reduces to the more familiar form from elementary physics, \\[\n\\mathbf{F}_{cf} = - m\\omega^2 \\mathbf{x}_{rot} = -\\frac{mv_{rot}^2}{r_{rot}} \\mathbf{e}_r.\n\\] The Coriolis force tends to deflect a moving object away from its line of motion. It arises due to the fact that as the object moves, the frame under it is rotating underneath, which causes an apparent deflection sideward.\n\n\nExample: Throwing a baseball from the North Pole\nSuppose a baseball is thrown from the North Pole for a distance \\(\\ell\\) and a constant velocity \\(\\mathbf{v}_0\\) with respect to the lab frame. Find the deflection angle \\(\\delta\\theta\\) of the ball caused by the Coriolis force.\n\n\n\n\n\nThe rotating frame in this case is the Earth itself. The Earth rotates counterclockwise about the North Pole with an angular velocity of \\(\\omega_\\oplus = \\frac{2\\pi}{\\text{1 day}} \\approx 7 \\cdot 10^{-5} \\frac{\\text{rad}}{\\text{sec}}\\). Suppose \\(\\mathbf{e}_z\\) is the direction pointing skyward, with the origin at the North Pole. Then \\(\\boldsymbol{\\omega} = \\omega_{\\oplus} \\mathbf{e}_z\\). Suppose the ball is thrown initially along the positive x-axis, so \\(\\mathbf{x} = \\ell \\mathbf{e}_x\\). Since \\(\\mathbf{v} = \\mathbf{v}_{rot} + \\boldsymbol{\\omega} \\times \\mathbf{x}_{rot}\\), we have \\[\n\\mathbf{v}_0 = \\mathbf{v}_{rot} + \\omega_{\\oplus} v_0 t (\\mathbf{e}_z \\times \\mathbf{e}_x) = \\mathbf{v}_{rot} + \\omega_{\\oplus} v_0 t \\mathbf{e}_y.\n\\] On time scales \\(t \\ll \\text{1 day}\\), we can say \\(\\mathbf{v}_{rot} \\approx \\mathbf{v}_0\\) since in that case \\(\\omega_{\\oplus} t\\) becomes small. Then we have \\[\n\\mathbf{F}_{cor} = 2m \\mathbf{v}_{rot} \\times \\boldsymbol{\\omega} \\approx 2m v_0 \\omega_{\\oplus} (\\mathbf{e}_x \\times \\mathbf{e}_z) = -2m v_0 \\omega_{\\oplus} \\mathbf{e}_y,\n\\] Evidently, the Coriolis force in this case is constant, which means the acceleration \\(\\mathbf{a}_{cor}\\) is constant too. We thus get a simple constant equation of motion in \\(y\\), \\[\n\\ddot y = -2v_0 \\omega_{\\oplus}.\n\\] Solving this EOM gives a deflection distance of \\[\nd = |y| = \\frac{1}{2}(2v_0 \\omega_{\\oplus})^2 = v_0 \\omega_{\\oplus} t^2.\n\\] Finally, we can use this to calculate the deflection angle \\(\\delta\\theta\\), \\[\n\\delta\\theta \\approx \\frac{d}{\\ell} = \\frac{\\omega_{\\oplus}v_0 t^2}{v_0 t} = \\omega_{\\oplus} t.\n\\] To plug in some numbers, suppose the ball stays in the air for \\(t = \\text{100 sec}\\). Then we’d get \\(\\delta\\theta \\approx 0.4^\\circ\\), indeed a very small deflection.\n\n\n\nExample: Hurricanes\nIt turns out that hurricanes rotate the direction they do due to the Coriolis force of the Earth. Pressure gradients cause water currents flowing east-west to spiral inward. In the Northern hemisphere, water deflects rightward, causing the gradients (or “hurricanes”) to spiral counterclockwise. Whereas in the Southern hemisphere, water deflects leftward, causing gradients (or “typhoons”) to spiral clockwise.\n\n\n\n\n\n\n\n\nExample: The Foucalt pendulum\nThe Foucalt pendulum is a classic problem that’s often used to demonstrate that the Earth rotates. Suppose a very long pendulum of length \\(l\\) and mass \\(m\\) is fixed near the Earth’s surface at some latitude \\(\\lambda\\) above the equator. Here’s a picture of what’s going on.\n\n\n\n\n\nIt’s reasonable to assume that \\(\\omega_{\\oplus}\\) is constant, so the Euler force is zero. It’s also reasonable to assume the centrifugal force is zero since \\(\\omega_{\\oplus}\\) is small. Thus, in the frame of the rotating Earth, we’re left with the inertial forces on the pendulum and the Coriolis force, \\[\nm\\mathbf{a}_{rot} = m\\mathbf{g} + \\mathbf{T} - 2m\\boldsymbol{\\omega} \\times \\mathbf{v}_{rot}.\n\\] Choose the axes such that the z-axis is pointing outward from the Earth’s surface at the pendulum and the other axes are planar to the surface. Now, we can write \\(\\mathbf{g} = -g \\mathbf{e}_z\\), and using some trig it’s not too hard to show that \\[\n\\mathbf{T} \\approx -\\frac{T}{\\ell} (x \\mathbf{e}_x + y \\mathbf{e}_y + \\ell \\mathbf{z}).\n\\] Using the latitude angle \\(\\lambda\\) we can also express the angular velocity \\(\\boldsymbol{\\omega}\\) as \\[\n\\boldsymbol{\\omega} = -\\omega_{\\oplus}\\cos\\lambda\\mathbf{e}_x + \\omega_{\\oplus}\\sin\\lambda\\mathbf{e}_z.\n\\] Since the pendulum approximately speaking only moves in the xy-plane, we also have \\[\n\\mathbf{v}_{rot} = \\dot x \\mathbf{e}_x + \\dot y \\mathbf{e}_y.\n\\] Together, these together imply \\[\n\\boldsymbol{\\omega} \\times \\mathbf{v}_{rot} \\approx -\\dot y \\omega_{\\oplus} \\sin\\lambda \\mathbf{e}_x + \\dot x \\omega_{\\oplus} \\sin\\lambda \\mathbf{e}_y - \\dot y \\omega_{\\oplus} \\cos\\lambda \\mathbf{e}_z.\n\\] This means \\[\n\\mathbf{a}_{rot} = \\bigg(-\\frac{Tx}{m\\ell} + 2\\dot y \\omega_{\\oplus} \\sin\\lambda \\bigg) \\mathbf{e}_x + \\bigg(-\\frac{Ty}{m\\ell} - 2\\dot x \\omega_{\\oplus} \\sin\\lambda \\bigg) \\mathbf{e}_x,\n\\] which gives equations of motion\n\\[\n\\begin{align*}\n\\ddot x &= -\\frac{T}{m\\ell} \\cdot x + 2\\omega_{\\oplus}\\sin\\lambda \\cdot \\dot y \\\\\n\\ddot y &= -\\frac{T}{m\\ell} \\cdot y - 2\\omega_{\\oplus}\\sin\\lambda \\cdot \\dot x. \\\\\n\\end{align*}\n\\] If we define \\(\\omega_0^2 \\equiv \\frac{T}{m\\ell} = \\frac{g}{\\ell}\\), we can re-arrange and write the equations of motion in the form\n\\[\n\\begin{align*}\n\\ddot x + \\omega_0^2 \\cdot x &= 2\\omega_z \\dot y \\\\\n\\ddot y + \\omega_0^2 \\frac{T}{m\\ell} \\cdot y &= -2\\omega_z \\dot x, \\\\\n\\end{align*}\n\\] where \\(\\omega_z = \\omega_{\\oplus}\\sin\\lambda\\). If we combine these two equations, this is equivalent to a complex DHO problem with imaginary damping, \\[\n\\ddot z + 2i\\omega_z \\dot z + \\omega_0^2 z = 0.\n\\] This means solutions will have the form \\[\nz(t) = e^{-i\\omega_z t}(A e^{i\\omega't} + B e^{-i\\omega't}).\n\\] where \\(\\omega' \\equiv \\sqrt{\\omega_z^2 + \\omega_0^2}\\). If we assume the pendulum swings much faster than the Earth rotates, we have \\(\\omega_0 \\gg \\omega_{\\oplus}\\), which means we can approximate \\(z(t)\\) as \\[\nz(t) \\approx e^{-i\\omega_z t}(A e^{i\\omega_0 t} + B e^{-i\\omega_0 t}).\n\\] If we define \\(z'(t) \\equiv A e^{i\\omega_0 t} + B e^{-i\\omega_0 t}\\), then \\(z(t) = e^{-i\\omega_z t} z'(t)\\), and we can write the real solutions as\n\\[\n\\begin{align*}\nx(t) &= x'(t) \\cos\\omega_z t + y'(t) \\sin\\omega_z t, \\\\\ny(t) &= -x'(t) \\sin\\omega_z t + y'(t) \\cos\\omega_z t. \\\\\n\\end{align*}\n\\] This says that the plane of oscillation itself undergoes a rotation in the xy-plane. That is, the plane of the pendulum’s orbit precesses with a frequency given by \\[\n\\omega_z = \\omega_{\\oplus} \\sin\\lambda = 2\\pi\\frac{\\sin\\lambda}{\\text{1 day}}.\n\\] For example, at a latitude of \\(\\lambda = 34.5^\\circ\\), the pendulum precesses counterclockwise with a frequency of \\(\\omega_z \\approx \\text{3.86 rad/sec}\\), or about \\(8.5^\\circ\\) per hour. It appears precession is non-existent at the equator and highest at the poles, where precession happens exactly with the Earth’s rotation.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reference Frames</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/reference-frames.html#general-non-inertial-frames",
    "href": "classical-mechanics/reference-frames.html#general-non-inertial-frames",
    "title": "Reference Frames",
    "section": "General Non-Inertial Frames",
    "text": "General Non-Inertial Frames\nMore generally, we can combine linearly accelerating and rotating frames by just adding the fictitious forces together. If \\(S_{rel}\\) is both accelerating and rotating about some axis with respect to \\(S\\), we’d have \\[\n\\mathbf{F}_{rel} = \\mathbf{F} + \\mathbf{F}_{lin} + \\mathbf{F}_{cf} + \\mathbf{F}_{cor} + \\mathbf{F}_{eul}.\n\\] This general form for a force in a non-inertial frame can be used to analyze a surprisingly large number of practical problems, where complicated forces can often be decomposed into a sum of linear forces and rotational forces.\nOne fact to be aware of about non-inertial frames is that energy need not be conserved. It’s only true in inertial frames that energy must be conserved. This has to do with the fact that in the relative frame we’re ignoring the forces on the relative frame itself, i.e. the forces that cause the frame to accelerate or rotate. We can generally recover the conservation of energy by transforming back to an inertial frame.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reference Frames</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/lagrangian-mechanics.html",
    "href": "classical-mechanics/lagrangian-mechanics.html",
    "title": "Lagrangian Mechanics",
    "section": "",
    "text": "Configuration Space\nMany forces acting on a system do no work. They serve only to keep particles confined to some surface in space. Such forces are called forces of constraint. Examples of forces of constraint include the tension in a string and the normal force keeping an object on a physical surface.\nSuppose we have a system of \\(N\\) particles with positions \\(\\mathbf{x}_1, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N\\) respectively. Taken together, these positions can be thought of as defining a trajectory in the \\(3N\\)-dimensional space \\(\\mathbb{R}^{3N}\\). A holonomic constraint is a constraint that keeps the \\(N\\) particles confined to some lower-dimensional sub-manifold \\(\\mathcal{Q}\\) of \\(\\mathbb{R}^{3N}\\). Equivalently, it’s a (possibly time-dependent) function of the form \\[\nf(\\mathbf{x}_1, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N, t) = 0.\n\\] The dimension of \\(\\mathcal{Q}\\) is \\(n=3N-C\\), where \\(C\\) is the total number of constraints on the system. These are the number of degrees of freedom of the system. This sub-manifold is called the configuration space of the system. Since \\(\\mathcal{Q}\\) is \\(n\\)-dimensional, we should be able to parametrize it with \\(n\\) coordinates \\(q_1, q_2, \\cdots, q_n\\). We call these generalized coordinates. They’re not ordinary coordinates in real space. They’re a way of describing where in configuration space the system is at a given point in time.\nHolonomicity requires that we be able to find a 1-1 map going back and forth between generalized coordinates and the position vectors, \\[\nq_i = q_i(\\mathbf{x}_1, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N, t), \\quad \\mathbf{x}_\\alpha = \\mathbf{x}_\\alpha(q_1, q_2, \\cdots, q_n, t).\n\\] When the holonomic constraint isn’t time-dependent, they’re called scleronomic constraints. Otherwise they’re called rheonomic constraints. A system that’s not holonomic is called non-holonomic.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lagrangian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/lagrangian-mechanics.html#configuration-space",
    "href": "classical-mechanics/lagrangian-mechanics.html#configuration-space",
    "title": "Lagrangian Mechanics",
    "section": "",
    "text": "Example: Simple Pendulum\nAs an easy example, consider the simple pendulum. Since there’s only one particle, \\(N=1\\). Since the length of the pendulum is fixed, that’s one constraint. Since the motion is confined to a plane, that’s another constraint. We thus have \\(n=3N-C=3-2=1\\) degrees of freedom, which we can of course take to be the angle \\(\\theta\\).\n\n\n\nExample: Rigid Bodies\nA more interesting example is the rigid body. A rigid body is a system of \\(N\\) particles whose particles are always a fixed distance apart, i.e. \\(d_{ij} = |\\mathbf{x}_i - \\mathbf{x}_j|\\) is fixed for all \\(i, j\\). This fixed distance requirement introduces a lot of constraints on the system. To see this, suppose \\(N=4\\). Then there are \\(C=6\\) constraints, since each particle must connect to each other particle. This means there are \\(n=3N-C=6\\) degrees of freedom.\n\n\n\n\n\nIt turns out this fact extends to rigid bodies with arbitrarily many particles as well since adding a new particle gives 3 more coordinates, but also 3 more constraints. A rigid body will always have exactly 6 degrees of freedom, which we usually take to be the 3 center of mass coordinates and the three Euler angles.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lagrangian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/lagrangian-mechanics.html#principle-of-virtual-work",
    "href": "classical-mechanics/lagrangian-mechanics.html#principle-of-virtual-work",
    "title": "Lagrangian Mechanics",
    "section": "Principle of Virtual Work",
    "text": "Principle of Virtual Work\nSuppose we have a system of \\(N\\) particles in mechanical equilibrium, so \\(\\mathbf{F}_i=\\mathbf{0}\\) for all \\(i\\). Let’s imagine we perturb each particle \\(\\mathbf{x}_i\\) by some amount \\(\\delta \\mathbf{x}_i\\), but only in a way that doesn’t change the configuration space. This means each perturbation must be a function of the generalized coordinates, \\(\\delta \\mathbf{x}_i = \\delta \\mathbf{x}_i(q_1, q_2, \\cdots, q_n, t)\\). Define the virtual work done on the system by, \\[\n\\delta W \\equiv \\sum \\mathbf{F}_i \\cdot \\delta\\mathbf{x}_i\n\\] Now, let’s decompose each force \\(\\mathbf{F}_i\\) into a sum of two components, an applied force \\(\\mathbf{F}_i^{app}\\) and a constraint force \\(\\mathbf{F}_i^{con}\\). The applied forces are the ones that do work on each particle, while the constraint forces are the ones that keep them confined to the configuration space. If the system is exactly in equilibrium, then \\(\\mathbf{F}_i = \\mathbf{F}_i^{app} + \\mathbf{F}_i^{con} = \\mathbf{0}\\), which means \\(\\delta W = 0\\) in equilibrium. But since constraint forces do no work, we get \\[\n\\delta W = \\sum \\mathbf{F}_i^{app} \\cdot \\delta\\mathbf{x}_i = 0\n\\] This is called the principle of virtual work.\nNote: Sometimes constraint forces do in fact do work on a system. One major example is a system in rolling motion, e.g. a wheel rolling down a ramp. We’ll mostly ignore these situations in this lesson.\nMore generally, if a system is not in equilibrium, we have \\(\\mathbf{F}_i = m_i \\mathbf{\\dot v}_i\\). If we insist the principle of virtual work must apply to these situations as well, we have \\[\n\\begin{align*}\n0 = \\delta W &= \\sum_i (\\mathbf{F}_i^{app} - m_i \\mathbf{\\dot v}_i) \\cdot \\delta \\mathbf{x}_i \\\\\n&= \\sum_i (\\mathbf{F}_i^{app} - m_i \\mathbf{\\dot v}_i) \\cdot \\sum_j\\frac{\\partial \\mathbf{x}_i}{\\partial q_j} \\delta q_j \\\\\n&= \\sum_j \\bigg(\\sum_i \\mathbf{F}_i^{app} \\cdot \\frac{\\partial \\mathbf{x}_i}{\\partial q_j}  - m_i \\mathbf{\\dot v}_i \\cdot \\frac{\\partial \\mathbf{x}_i}{\\partial q_j} \\bigg) \\delta q_j \\\\\n&= \\sum_j \\bigg[ Q_j - \\bigg(\\frac{d}{dt} \\frac{\\partial T}{\\partial \\dot q_j} - \\frac{\\partial T}{\\partial q_j} \\bigg) \\bigg] \\delta q_j.\n\\end{align*}\n\\] Here I defined \\(Q_j \\equiv \\mathbf{F}_i^{app} \\cdot \\frac{\\partial \\mathbf{x}_i}{\\partial q_j}\\). This term is called the generalized force. It acts as a force, but on the generalized coordinates instead of the position vectors directly. The other thing I did was re-wrote the momentum term by using the total kinetic energy \\(T = \\frac{1}{2} \\sum_i m_i \\mathbf{v}_i^2\\). Now, if we insist that all the \\(q_i\\) are independent of each other, then the terms in the sum must vanish individually, which means for all \\(j=1,\\cdots,n\\) we have \\[\nQ_j = \\frac{d}{dt} \\frac{\\partial T}{\\partial \\dot q_j} - \\frac{\\partial T}{\\partial q_j}.\n\\] In the special case where the forces on the system are conservative, we can use the potential energy \\(V\\) to express the generalized forces as \\(Q_j = -\\frac{\\partial V}{\\partial q_i}\\). Defining a function \\(L \\equiv T - V\\) called the Lagrangian and re-arranging terms, we finally have \\[\n\\frac{\\partial L}{\\partial q_j} - \\frac{d}{dt} \\frac{\\partial L}{\\partial \\dot q_j} = 0.\n\\] This gives a set of \\(n\\) equations for the generalized coordinates, called Lagrange’s equations.\nTo see why Lagrange’s equations are useful, consider the case when \\(T=\\frac{1}{2} \\sum_i m_i \\dot x_i^2\\) and \\(V = V(x_1, x_2, \\cdots, x_n)\\). Then we have a Lagrangian of the form \\[\nL = T - V = \\frac{1}{2} \\sum_i m_i \\dot x_i^2 - V(x_1, x_2, \\cdots, x_n),\n\\] which we can plug into the Euler-Lagrange Equations to get \\[\nm \\ddot x_i = - \\frac{\\partial V}{\\partial x_i} \\quad \\forall i=1,2,\\cdots,n.\n\\] But this is just \\(\\mathbf{F} = m \\mathbf{a}\\)! Evidently we’ve managed to reproduce Newton’s Laws from Lagrange’s equations. This in some sense suggest that Lagrange’s equations might be more general than Newton’s Laws, and in fact they are as we’ll see later.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lagrangian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/lagrangian-mechanics.html#solving-lagranges-equations",
    "href": "classical-mechanics/lagrangian-mechanics.html#solving-lagranges-equations",
    "title": "Lagrangian Mechanics",
    "section": "Solving Lagrange’s Equations",
    "text": "Solving Lagrange’s Equations\nThe Lagrangian formulation is very useful for solving problems that would be very complicated to solve using Newtonian approaches. This is particular true when there are complex constraints present. It’s thus very helpful to see a bunch of examples showing how to solve problems using Lagrangian methods.\nTo solve a problem using Lagrange’s equations we need to do the following steps:\n\nFigure out how many degrees of freedom the system has using \\(n=3N-C\\).\nIdentify the generalized coordinates \\(q_1,q_2,\\cdots,q_n\\).\nExpress the velocity vectors as a function of the generalized coordinates, \\(\\mathbf{v}_i = \\mathbf{v}_i(q_1,q_2,\\cdots,q_n)\\).\nWrite down the kinetic energy \\(T = \\frac{1}{2}\\sum_i m_i \\mathbf{v_i}^2(q_1,q_2,\\cdots,q_n)\\), the potential energy \\(V=V(q_1,q_2,\\cdots,q_n)\\), and finally the Lagrangian \\[\nL = T - V.\n\\]\nUse Lagrange’s equations to derive the equations of motion for the generalized coordinates, \\[\n\\frac{\\partial L}{\\partial q_j} - \\frac{d}{dt} \\frac{\\partial L}{\\partial \\dot q_j} = 0 \\quad \\forall j=1,2\\cdots,n.\n\\]\nIntegrate the equations of motion to get the generalized trajectories \\(q_1(t),q_2(t),\\cdots,q_n(t)\\).\nIf desired, convert back to real space coordinates via \\(\\mathbf{x}_\\alpha = \\mathbf{x}_\\alpha(q_1,q_2,\\cdots,q_n)\\).\n\n\n\nExample: The Simple Spring\nSuppose a mass \\(m\\) is attached to an ideal spring with spring constant \\(k\\).\n\n\n\n\n\nIn this case, \\(N = 1\\), and the spring is constrained to move along, say, the x-axis, so \\(C=2\\), and there’s just \\(n=3N-C=1\\) degree of freedom (as expected). If the generalized coordinate is just \\(q=x\\), we have \\[\nT = \\frac{1}{2} m \\dot q^2, \\quad V = \\frac{1}{2}kq^2,\n\\] which means the Lagrangian is \\[\nL = \\frac{1}{2} m \\dot q^2 - \\frac{1}{2}kq^2.\n\\] Solving Lagrange’s equation in this case gives \\[\n-\\frac{\\partial}{\\partial q} \\frac{k q^2}{2} - \\frac{d}{dt} \\frac{\\partial}{\\partial \\dot q} \\frac{m\\dot q^2}{2} = 0 \\quad \\Rightarrow \\quad m\\ddot q = -k q.\n\\] We’ve already seen the solution to this equation is just the SHO solution \\[\nq(t) = A\\cos(\\omega t - \\delta), \\quad \\omega^2 \\equiv \\frac{k}{m}.\n\\] If desired, in this case we could convert back to real coordinates via \\[\n\\mathbf{x}(t) = q(t) \\mathbf{e}_x = A\\cos(\\omega t - \\delta)\\mathbf{e}_x.\n\\]\n\n\n\nExample: Simple Pendulum\nSuppose a mass \\(m\\) is attached to a massless string of fixed length \\(\\ell\\) and allowed to swing.\n\n\n\n\n\nIn this problem, there’s \\(N=1\\) particle. The string being fixed adds one constraint, and motion being confined to the plane adds another, so we have \\(n=1\\) degrees of freedom here, which we’ll take to be the angle \\(q=\\theta\\). Using polar coordinates, we can write the kinetic and potential energies as \\[\nT = \\frac{1}{2} m\\ell^2 \\dot q^2, \\quad V = -mg\\ell\\cos q,\n\\] which gives a Lagrangian \\[\nL = \\frac{1}{2} m\\ell^2 \\dot q^2 + mg\\ell\\cos q.\n\\] Solving Lagrange’s equation, we get the equation of motion \\[\nm\\ell^2 \\ddot q + mg\\ell\\sin q = 0,\n\\] which is of course the usual equation of motion for the pendulum when \\(q=\\theta\\).\n\n\n\nExample: Central Potential\nSuppose a particle of mass \\(m\\) is in the presence of a central force field \\(V=V(r)\\). There’s one constraint since the problem must be spherically symmetric, which means we have \\(n=2\\) degrees of freedom. Working in spherical coordinates, the kinetic and potential energies are given by \\[\nT = \\frac{1}{2} m (\\dot r^2 + r \\dot \\varphi^2), \\quad V = V(r).\n\\] Plugging these into Lagrange’s equation and solving gives two equations of motion for \\(r\\) and \\(\\varphi\\), \\[\nm \\ddot r = mr \\dot\\varphi^2 - \\frac{dV}{dr}\\\\\n\\frac{d}{dt} mr^2 \\dot\\varphi = 0.\n\\] The second equation is interesting. It says the quantity \\(\\ell = mr^2 \\dot\\varphi\\) must be conserved. But this is just the angular momentum of the system! Evidently, conservation laws somehow fall out of Lagrange’s equations provided the right generalized coordinates are chosen.\n\n\n\nExample: Double Pendulum\nThe examples considered so far are pretty easy to solve using Newtonian methods. Here’s an example where it’s far easier to write down the equations of motion in the Lagrangian formulation. Consider the double pendulum, where a mass is attached to the end of another pendulum and both are allowed to swing. Suppose both masses have mass \\(m\\) and both strings are a fixed length \\(\\ell\\).\n\n\n\n\n\nHere there are \\(N=2\\) particles, each of which has two constraints. That means there are \\(n=2\\) total degrees of freedom in this system. From the above diagram we can see \\[\n\\begin{align*}\n&x_1 = \\ell \\sin\\theta_1, \\quad &&x_2 = \\ell(\\sin\\theta_1 + \\sin\\theta_2), \\\\\n&y_1 = -\\ell \\cos\\theta_1, \\quad &&y_2 = -\\ell(\\cos\\theta_1 + \\cos\\theta_2). \\\\\n\\end{align*}\n\\] We’ll choose the two angles \\(\\theta_1, \\theta_2\\) to be the generalized coordinates. The energies for each mass are given by \\[\n\\begin{align*}\nT_1 &= \\frac{1}{2}m (\\dot x_1^2 + \\dot y_1^2) = \\frac{1}{2}m \\ell^2 \\dot \\theta_1^2, \\quad &&\nT_2 = \\frac{1}{2}m (\\dot x_2^2 + \\dot y_2^2) = \\frac{1}{2}m \\ell^2\\big(\\dot\\theta_1^2 + \\dot\\theta_2^2 + 2\\cos(\\theta_1-\\theta_2)\\dot\\theta_1\\dot\\theta_2\\big), \\\\\nV_1 &= mgy_1 = -mg\\ell\\cos\\theta_1, \\quad && V_2 = mgy_2 = -mg\\ell(\\cos\\theta_1 + \\cos\\theta_2).\\\\\n\\end{align*}\n\\]\nPutting these all into the Lagrangian and simplifying, we evidently get \\[\nL = \\frac{1}{2}m\\ell^2\\big(2\\dot \\theta_1^2 + \\dot \\theta_2^2 + 2\\dot\\theta_1\\dot\\theta_2\\cos(\\theta_1-\\theta_2) \\big) + mg\\ell(2\\cos\\theta_1 + \\cos\\theta_2).\n\\] This then gives the following two equations of motion \\[\n\\begin{align*}\n-m\\ell^2\\dot\\theta_1\\dot\\theta_2\\sin(\\theta_1-\\theta_2) - 2mg\\ell\\sin\\theta_1 &= m\\ell^2 \\frac{d}{dt} \\big(\\dot\\theta_1 + 2\\dot\\theta_2\\cos(\\theta_1-\\theta_2)\\big), \\\\\nm\\ell^2\\dot\\theta_1\\dot\\theta_2\\sin(\\theta_1-\\theta_2) - mg\\ell\\sin\\theta_2 &= m\\ell^2 \\frac{d}{dt} \\big(\\dot\\theta_2 + 2\\dot\\theta_1\\cos(\\theta_1-\\theta_2) \\big). \\\\\n\\end{align*}\n\\]",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lagrangian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/lagrangian-mechanics.html#principle-of-least-action",
    "href": "classical-mechanics/lagrangian-mechanics.html#principle-of-least-action",
    "title": "Lagrangian Mechanics",
    "section": "Principle of Least Action",
    "text": "Principle of Least Action\nA more general, first principles way to derive Lagrange’s equations is via an action principle. Action principles are a very general and powerful tool that applies across pretty much all of modern physics. Suppose we have \\(n\\) generalized coordinates \\(q_1,q_2,\\cdots,q_n\\). For simplicity I’ll write these as a vector, \\[\n\\mathbf{q} = (q_1,q_2,\\cdots,q_n).\n\\] Define the action \\(S\\) as a functional of \\(\\mathbf{q}\\) of the form \\[\nS[\\mathbf{q}] \\equiv \\int_{t_1}^{t_2} L(\\mathbf{q}, \\mathbf{\\dot q}, t) dt.\n\\] We assume the times \\(t_1\\) and \\(t_2\\) are fixed. The integrand function \\(L(\\mathbf{q}, \\mathbf{\\dot q}, t)\\) is called the Lagrangian. Note in general the Lagrangian can depend explicitly on time.\n\n\n\n\n\nSimilar to how it’s useful to analyze a function by looking at its behavior around its minima, we’ll want to analyze the functional \\(S\\) by looking at its behavior around the stationary points of \\(\\mathbf{q}\\). To do so, consider a small perturbation \\(\\delta\\mathbf{q} \\equiv \\varepsilon\\boldsymbol{\\eta}\\) of the coordinates, where \\(\\boldsymbol{\\eta} = \\boldsymbol{\\eta}(t)\\) is a function that vanishes at the endpoints \\(t_1\\) and \\(t_2\\), and \\(\\varepsilon \\ll 1\\). To proceed, we’ll assume the following fundamental principle:\nPrinciple of Least Action:  Physical trajectories evolve in such a way that the action remains stationary, i.e. \\[\n\\delta S[\\mathbf{q}] \\equiv \\frac{\\partial S}{\\partial \\varepsilon} \\bigg|_{\\varepsilon=0} = 0.\n\\] This means if we want to figure out how physical trajectories evolve, we need to find the optimal \\(\\mathbf{q}\\) that make the action \\(S\\) stationary. To do that, let’s set \\(\\delta S[\\mathbf{q}] = 0\\) and solve. We have \\[\n0 = \\delta S[\\mathbf{q}] = \\int_{t_1}^{t_2} \\delta L(\\mathbf{q}, \\mathbf{\\dot q}, t) dt = \\int_{t_1}^{t_2}\\bigg(\\frac{\\partial L}{\\partial\\mathbf{q}} \\cdot \\delta \\mathbf{q} + \\frac{\\partial L}{\\partial\\mathbf{\\dot q}} \\cdot \\delta \\mathbf{\\dot q} \\bigg) \\cdot \\delta\\mathbf{q} dt\n\\] Now, if we perform integration by parts on the second term, we can move the time derivative from \\(\\delta\\mathbf{\\dot q}\\) to the derivative \\(\\frac{\\partial L}{\\partial\\mathbf{\\dot q}}\\) at the cost of a minus sign, so we have \\[\n0 = \\delta S[\\mathbf{q}] = \\int_{t_1}^{t_2}\\bigg(\\frac{\\partial L}{\\partial\\mathbf{q}} - \\frac{d}{dt}\\frac{\\partial L}{\\partial\\mathbf{\\dot q}} \\bigg) \\cdot \\delta \\mathbf{q} dt.\n\\] Note the boundary terms vanish since we require \\(\\boldsymbol{\\eta}\\) to vanish at the endpoints. Assuming each of the coordinates in \\(\\mathbf{q}\\) are functionally independent the integrand must vanish identically, so we have \\[\n\\frac{\\partial L}{\\partial\\mathbf{q}} - \\frac{d}{dt}\\frac{\\partial L}{\\partial\\mathbf{\\dot q}} = \\mathbf{0}.\n\\] Of course, this is just the vector formulation of Lagrange’s equations. We’ve thus fully recovered Lagrange’s equations, and by extension Newton’s Laws for conservative systems, purely from the Principle of Least Action.\nNotice how general this derivation was. We didn’t even assume any specific form of the Lagrangian like \\(L = T-V\\). We only assumed it was a function of the generalized positions, velocities, and time. If we believe the Principle of Least Action, evidently any Lagrangian \\(L(\\mathbf{q}, \\mathbf{\\dot q}, t)\\) will produce equations of motion for some system, not necessarily mechanical, or even classical.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lagrangian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/lagrangian-mechanics.html#symmetries-and-conservation-laws",
    "href": "classical-mechanics/lagrangian-mechanics.html#symmetries-and-conservation-laws",
    "title": "Lagrangian Mechanics",
    "section": "Symmetries and Conservation Laws",
    "text": "Symmetries and Conservation Laws\nIt’s a deep fact of physics that the symmetries of a system are intimately connected with its conservation laws. It’s both practically and theoretically useful to better understand this connection.\n\nCyclic Coordinates\nConsider a general Lagrangian of the form \\(L = L(\\mathbf{q}, \\mathbf{\\dot q}, t)\\). Without loss of generality, suppose the Lagrangian happens to not be a function of the coordinate \\(q_1\\), so \\[\nL = L(q_2,\\cdots,q_n,\\dot q_1,\\dot q_2, \\cdots, \\dot q_n, t).\n\\] Note it can still be a function of the first coordinate’s velocity \\(\\dot q_1\\). In this situation, we’d say the coordinate \\(q_1\\) is a cyclic coordinate or ignorable coordinate. Evidently, it follows that \\[\n\\frac{\\partial L}{\\partial q_1} = 0 \\quad \\Longrightarrow \\quad 0 = \\frac{d}{dt} \\frac{\\partial L}{\\partial \\dot q_1} \\quad \\Longrightarrow \\quad p_1 \\equiv \\frac{\\partial L}{\\partial \\dot q_1} = const.\n\\] We call \\(p_1\\) the conjugate momentum to \\(q_1\\). We’ve thus shown that if \\(q_1\\) is cyclic, then its conjugate momentum \\(p_1\\) is conserved.\n\n\nExample: Free Particle\nFor a free particle, we have \\(L = \\frac{1}{2}m \\dot x^2\\). Since \\(L\\) is not a function of \\(x\\), evidently \\(x\\) is cyclic, which means its conjugate momentum \\(p_x\\) is conserved, \\[\np_x = \\frac{\\partial L}{\\partial \\dot x} = m \\dot x = const.\n\\] Notice in this case the conjugate momentum is the same thing as the ordinary linear momentum. This need not always be true. The conjugate momentum is more general than this.\n\n\n\nExample: Central Force in a Plane\nIn this case the Lagrangian is given by \\[\nL = \\frac{1}{2} m (\\dot r^2 + r^2 \\dot\\varphi^2) - V(r).\n\\] Since \\(\\varphi\\) is cyclic, its conjugate momentum \\(p_\\varphi\\) must evidently be conserved, \\[\np_\\varphi = \\frac{\\partial L}{\\partial \\dot \\varphi} = mr^2\\dot\\varphi = const.\n\\] Notice this is just the \\(z\\)-component of angular momentum \\(L_z = \\ell\\).\n\n\n\n\nNoether’s Theorem\nWe can still have conserved quantities in a given system even if none of its generalized coordinates are explicitly cyclic. This will happen, for example, if we didn’t happen to choose the natural choice of coordinates for some given problem, the ones that take advantage of the system’s symmetries.\nTo find conserved quantities, we need to find the symmetries. Formally, we’ll say a symmetry is any continuous transformation on the generalized coordinates that leaves the Lagrangian invariant. That is, for some parameter \\(s\\), if \\(\\mathbf{q}\\) is continuously transformed to \\(\\mathbf{q}_s\\), then \\(s\\) is a symmetry provided \\[\nL(\\mathbf{q}_s, \\mathbf{\\dot q}_s, t) = L(\\mathbf{q}, \\mathbf{\\dot q}, t).\n\\] Noether’s Theorem: If \\(s\\) is a symmetry of a system, then the quantity given by \\[\nQ \\equiv \\mathbf{p} \\cdot \\frac{\\partial \\mathbf{q}}{\\partial s} = p_i \\frac{\\partial q_i}{\\partial s}\n\\] must be conserved under transformation by \\(s\\). We call \\(Q\\) the Noether charge associated with \\(s\\).\n\nProof: To prove this theorem we need to show that \\(\\dot Q = 0\\). Since \\(s\\) is a symmetry, we must have \\[\n\\frac{\\partial}{\\partial s} L(\\mathbf{q}_s, \\mathbf{\\dot q}_s, t) = \\frac{\\partial}{\\partial s} L(\\mathbf{q}, \\mathbf{\\dot q}, t) = 0.\n\\] Using the chain rule together with Lagrange’s equations on \\(L(\\mathbf{q}_s, \\mathbf{\\dot q}_s, t)\\), we finally get \\[\n\\begin{align*}\n\\mathbf{0} &= \\frac{\\partial}{\\partial s} L(\\mathbf{q}_s, \\mathbf{\\dot q}_s, t) \\\\\n&= \\frac{\\partial L}{\\partial \\mathbf{q}_s} \\cdot \\frac{\\partial \\mathbf{q}_s}{\\partial s} + \\frac{\\partial L}{\\partial \\mathbf{\\dot q}_s} \\cdot \\frac{\\partial \\mathbf{\\dot q}_s}{\\partial s} \\\\\n&= \\frac{d}{dt} \\frac{\\partial L}{\\partial \\mathbf{\\dot q}_s} \\cdot \\frac{\\partial \\mathbf{q}_s}{\\partial s} + \\frac{\\partial L}{\\partial \\mathbf{\\dot q}_s} \\cdot \\frac{d}{dt} \\frac{\\partial \\mathbf{q}_s}{\\partial s} \\\\\n&= \\frac{d}{dt} \\bigg(\\frac{\\partial L}{\\partial \\mathbf{\\dot q}_s} \\cdot \\frac{\\partial \\mathbf{q}_s}{\\partial s}\\bigg) \\\\\n&= \\frac{d}{dt} \\bigg(\\mathbf{p} \\cdot \\frac{\\partial \\mathbf{q}}{\\partial s}\\bigg). \\tag*{$\\square$}\n\\end{align*}\n\\]\n\n\nExample: Conservation of Linear Momentum\nSuppose a single particle is moving through space. Suppose the space is homogeneous, that is, the particle’s Lagrangian is invariant to translations in space, \\[\nL(\\mathbf{x}, \\mathbf{\\dot x}, t) = L(\\mathbf{x} + \\delta\\mathbf{x}, \\mathbf{\\dot x}, t).\n\\] This is equivalent to saying the particle has a symmetry of the form \\(\\mathbf{x}(s) = \\mathbf{x} + s\\boldsymbol{\\varepsilon}\\), where \\(\\boldsymbol{\\varepsilon}\\) is constant. In this case, we’d evidently have \\[\nQ = \\mathbf{p} \\cdot \\frac{\\partial \\mathbf{x}}{\\partial s} = \\mathbf{p} \\cdot \\boldsymbol{\\varepsilon} = const.\n\\] Since \\(\\boldsymbol{\\varepsilon}\\) is an arbitrary constant, we must have \\(\\mathbf{p} = m \\mathbf{\\dot x} = const\\). That is, the linear momentum of the particle is conserved. Equivalently, if space is homogeneous, then the total linear momentum will be conserved.\n\n\n\nExample: Conservation of Angular Momentum\nSuppose again a single particle is moving through space. Suppose this time that space is isotropic, that is, the particle’s Lagrangian is invariant to rotations in space, \\[\nL(\\mathbf{x}, \\mathbf{\\dot x}, t) = L\\big(\\delta\\mathbf{R}\\mathbf{x}, \\mathbf{\\dot x}, t\\big).\n\\] Now, we can always think of a rotation in space as a rotation about some axis. For simplicity we’ll choose that axis to be the \\(z\\)-axis, in which case we can think of \\(\\delta\\mathbf{R}\\) as rotating \\(\\mathbf{x}\\) by some azimuthal angle \\(\\delta\\varphi\\). Take as generalized coordinates the spherical coordinates \\(r, \\theta, \\varphi\\). Then rotational invariance is equivalent to saying the particle has a symmetry of the form \\(\\varphi(s) = \\varphi + s\\). We thus have \\[\nQ = p_r \\frac{\\partial r}{\\partial s} + p_\\theta \\frac{\\partial \\theta}{\\partial s} + p_\\varphi \\frac{\\partial \\varphi}{\\partial s} = p_\\varphi = const.\n\\] That is, the angular momentum \\(L_z = mr^2 \\dot \\varphi = const\\). Since choosing the \\(z\\)-axis as the rotation axis was arbitrary, this says the total angular momentum \\(\\mathbf{L} = const\\). That is, the angular momentum of the particle is conserved. Equivalently, if space is isotropic, then the total angular momentum will be conserved.\n\nWhat about energy though? When is it conserved? It turns out that energy conservation is connected to time translation invariance, which is a little bit more subtle. Suppose a Lagrangian had a time translational symmetry of the form \\(t(s) = t + s\\). Since all of \\(L\\), \\(\\mathbf{q}\\), and \\(\\mathbf{\\dot q}\\) depend explicitly on time, this means we’d have \\[\nL\\big(\\mathbf{q}(t), \\mathbf{\\dot q}(t), t\\big) = L\\big(\\mathbf{q}(t + s), \\mathbf{\\dot q}(t + s), t + s\\big).\n\\] Following along the proof of Noether’s Theorem, we’d have \\[\n0 = \\frac{\\partial L}{\\partial s} = \\frac{\\partial L}{\\partial t} \\frac{\\partial t}{\\partial s} = \\frac{\\partial L}{\\partial t}.\n\\] That is, \\(\\frac{\\partial L}{\\partial t} = 0\\), which means now time is cyclic, and the Lagrangian doesn’t have any explicit time dependence. Now, if we take the total time derivative of the Lagrangian, we get \\[\n\\begin{align*}\n\\frac{dL}{dt} &= \\frac{\\partial L}{\\partial \\mathbf{q}} \\cdot \\mathbf{\\dot q} + \\frac{\\partial L}{\\partial \\mathbf{\\dot q}} \\cdot \\mathbf{\\ddot q} + \\frac{\\partial L}{\\partial t} \\\\\n&= \\frac{d}{dt} \\frac{\\partial L}{\\partial \\mathbf{\\dot q}} \\cdot \\mathbf{\\dot q} + \\frac{\\partial L}{\\partial \\mathbf{\\dot q}} \\cdot \\mathbf{\\ddot q} + \\frac{\\partial L}{\\partial t} \\\\\n&= \\mathbf{\\dot p} \\cdot \\mathbf{\\dot q} + \\mathbf{p} \\cdot \\mathbf{\\ddot q} + \\frac{\\partial L}{\\partial t} \\\\\n&= \\frac{d}{dt} \\mathbf{p} \\cdot \\mathbf{\\dot q} + \\frac{\\partial L}{\\partial t}.\n\\end{align*}\n\\] When time is cyclic, we must have \\[\nH \\equiv \\mathbf{p} \\cdot \\mathbf{\\dot q} - L = const.\n\\] This function is called the Hamiltonian. We’ve just shown that when a system is time translation invariant, its Hamiltonian must be conserved, whatever that is.\nTo see what exactly \\(H\\) is, let’s consider a Lagrangian of the form \\[\nL = T - V = \\frac{1}{2} \\mathbf{\\dot q} \\cdot \\mathbf{T}(\\mathbf{q}) \\cdot \\mathbf{\\dot q} - V(\\mathbf{q}).\n\\] In this case, the Hamiltonian would be \\[\n\\begin{align*}\nH &= \\frac{\\partial L}{\\partial \\mathbf{\\dot q}} \\cdot \\mathbf{\\dot q} - L \\\\\n&= \\mathbf{\\dot q} \\cdot \\mathbf{T}(\\mathbf{q}) \\cdot \\mathbf{\\dot q} - \\frac{1}{2} \\mathbf{\\dot q} \\cdot \\mathbf{T}(\\mathbf{q}) \\cdot \\mathbf{\\dot q} + V(\\mathbf{q}) \\\\\n&= \\frac{1}{2} \\mathbf{\\dot q} \\cdot \\mathbf{T}(\\mathbf{q}) \\cdot \\mathbf{\\dot q} + V(\\mathbf{q}) \\\\\n&= T + V. \\\\\n\\end{align*}\n\\] That is, if \\(L = T-V\\), then \\(H=T+V\\). But \\(T+V\\) is just the total energy \\(E\\). We thus finally have the conservation of energy. If \\(L = T-V\\) and time is homogeneous, then the total energy \\(E\\) is conserved.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lagrangian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/lagrangian-mechanics.html#non-conservative-forces",
    "href": "classical-mechanics/lagrangian-mechanics.html#non-conservative-forces",
    "title": "Lagrangian Mechanics",
    "section": "Non-Conservative Forces",
    "text": "Non-Conservative Forces\nAs we’ve derived them, Lagrange’s equations only hold for systems with conservative forces. In some special cases, we can augment non-conservative forces into Lagrange’s equations as well. Suppose for example we had \\(L = T - U\\), where \\(U = U(\\mathbf{q}, \\mathbf{\\dot q}, t)\\) is some kind of generalized potential energy. Then the generalized forces have the form \\[\n\\mathbf{Q} = - \\frac{\\partial U}{\\partial \\mathbf{q}} + \\frac{d}{dt} \\frac{\\partial U}{\\partial \\mathbf{\\dot q}}.\n\\] In this case, we can solve Lagrange’s equations for \\(L = T-U\\) and everything would work fine even though \\(U\\) is not a proper potential energy anymore.\n\n\nExample: Charged Particle in an Electromagnetic Field\nSuppose a particle of mass \\(m\\) and charge \\(q\\) is moving in the presence of an electromagnetic field. We already know that such a particle obeys the Lorentz force law \\[\n\\mathbf{F} = q \\mathbf{E}(\\mathbf{x},t) + \\frac{q}{c} \\mathbf{v} \\times \\mathbf{B}(\\mathbf{x},t).\n\\] Can we derive this from a Lagrangian? Notice that this force isn’t conservative since it’s a function of the particle’s velocity. However, we can still derive a generalized potential energy \\(U=U(\\mathbf{x},\\mathbf{v},t)\\) as follows. We know from electrodynamics that we can express the electric field \\(\\mathbf{E}\\) and magnetic field \\(\\mathbf{B}\\) as derivatives of a scalar potential \\(\\phi\\) and a vector potential \\(\\mathbf{A}\\), \\[\n\\begin{align*}\n\\mathbf{E}(\\mathbf{x},t) &= - \\nabla \\phi(\\mathbf{x},t) - \\frac{1}{c} \\frac{\\partial}{\\partial t} \\mathbf{A}(\\mathbf{x},t), \\\\\n\\mathbf{B}(\\mathbf{x},t) &= \\nabla \\times \\mathbf{A}(\\mathbf{x},t). \\\\\n\\end{align*}\n\\] Let’s define \\[\nU(\\mathbf{x},\\mathbf{v},t) = q \\phi(\\mathbf{x},t) - \\frac{q}{c} \\mathbf{v} \\cdot \\mathbf{A}(\\mathbf{x},t).\n\\] Then the Lagrangian for this system is then given by \\(L=T-U\\), or \\[\nL = \\frac{1}{2} m \\mathbf{v}^2 - q \\phi + \\frac{q}{c} \\mathbf{v} \\cdot \\mathbf{A}.\n\\] Though a little painful, it’s not hard to show that solving Lagrange’s equations reproduces the above Lorentz force law.\n\nMore generally, we can always just manually add in any non-conservative forces to the equations of motion after Lagrange’s equations have been solved, but they’d need to be converted to generalized forces first. Given some force \\(\\mathbf{F}\\), we can augment Lagrange’s equations by writing \\[\n\\frac{\\partial L}{\\partial\\mathbf{q}} - \\frac{d}{dt}\\frac{\\partial L}{\\partial\\mathbf{\\dot q}} = \\mathbf{Q},\n\\] where \\(\\mathbf{Q} = \\mathbf{F} \\cdot \\frac{\\partial \\mathbf{x}}{\\partial \\mathbf{q}}\\) is the associated generalized force.\nIn the special case that a non-conservative force is linear in the generalized velocities, we can augment the Lagrangian by defining the Rayleigh dissipation function \\(\\mathcal{F}\\) given by \\[\n\\mathcal{F} \\equiv \\frac{1}{2} \\mathbf{\\dot q} \\cdot \\mathbf{B}(\\mathbf{q}) \\cdot \\mathbf{\\dot q} = \\sum_{i,j} b_{ij}(\\mathbf{q}) \\dot q_i \\dot q_j.\n\\] In this case, the generalized forces are just the gradients of \\(\\mathcal{F}\\), \\[\n\\mathbf{Q} = -\\frac{\\partial \\mathcal{F}}{\\partial \\mathbf{q}} = -\\mathbf{B} \\cdot \\mathbf{\\dot q},\n\\] which we can plug into the modified Lagrange’s equations to give \\[\n\\frac{\\partial L}{\\partial\\mathbf{q}} - \\frac{d}{dt}\\frac{\\partial L}{\\partial\\mathbf{\\dot q}} = \\frac{\\partial \\mathcal{F}}{\\partial\\mathbf{\\dot q}}.\n\\]\n\n\n\nExample: Damped Hanging Spring\nSuppose we have a spring with mass \\(m\\) and spring constant \\(k\\) allowed to hang from the top of a closed lid of thick syrup. Assume the viscosity of the syrup is high enough that Stoke’s Law holds.\nIn this case, we simply have \\[\n\\begin{align*}\nT &= \\frac{1}{2} m \\dot x^2, \\\\\nV &= -mgx - \\frac{1}{2} kx^2, \\\\\nL &= \\frac{1}{2} m \\dot x^2 + mgx + \\frac{1}{2} kx^2, \\\\\n\\mathcal{F} &= \\frac{1}{2} b \\dot x^2. \\\\\n\\end{align*}\n\\] Plugging these into the modified Lagrange’s equations finally gives the DDHO equation of motion \\[\nm \\ddot x + b \\dot x + kx = mg.\n\\]",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lagrangian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/lagrangian-mechanics.html#invariant-transformations",
    "href": "classical-mechanics/lagrangian-mechanics.html#invariant-transformations",
    "title": "Lagrangian Mechanics",
    "section": "Invariant Transformations",
    "text": "Invariant Transformations\nIt’s natural to ask what kinds of transformations of a Lagrangian leave it invariant. We already saw that when a system has certain symmetries that the Lagrangian will be invariant under those symmetry transformations. In that case, the Lagrangian itself didn’t change. More general, we could ask what kinds of transformations will leave the equations of motion unchanged, even if the Lagrangian itself did change.\nOne natural question to ask is how the Lagrangian behaves under a coordinate transformation. After all, the choice of coordinates should not affect the physical behavior of the system. Suppose we have two sets of coordinates to describe the system, \\(\\mathbf{q}\\) and \\(\\mathbf{Q}\\). They’re related by a transformation \\(\\mathbf{Q} = \\mathbf{Q}(\\mathbf{q})\\), called a point transformation. The transformed velocities \\(\\mathbf{\\dot Q}\\) are a function of both \\(\\mathbf{q}\\) and \\(\\mathbf{\\dot q}\\), since \\[\n\\mathbf{\\dot Q} = \\mathbf{\\dot Q}(\\mathbf{q}, \\mathbf{\\dot q}) = \\mathbf{\\dot q}\\frac{\\partial \\mathbf{Q}}{\\partial \\mathbf{q}}.\n\\] Suppose the Lagrangian in each coordinate system is given by \\(L_q = L(\\mathbf{q}, \\mathbf{\\dot q}, t)\\) and \\(L_Q = L(\\mathbf{Q}, \\mathbf{\\dot Q}, t)\\) respectively. Assume that \\(L_q\\) satisfies Lagrange’s equations, so \\[\n\\frac{\\partial L_q}{\\partial \\mathbf{q}} + \\frac{d}{dt} \\frac{\\partial L_q}{\\partial \\mathbf{\\dot q}} = \\mathbf{0}.\n\\] What then can we conclude about \\(L_Q\\)? If we express \\(L_Q\\) in terms of \\(\\mathbf{q}\\), we’d have \\[\nL_Q = L\\big(\\mathbf{q}(\\mathbf{Q}), \\mathbf{\\dot q}(\\mathbf{Q}, \\mathbf{\\dot Q}), t\\big).\n\\] Taking derivatives of \\(L_Q\\) with respect to \\(\\mathbf{Q}\\), then \\[\n\\begin{align*}\n\\frac{\\partial L_Q}{\\partial \\mathbf{Q}} &=  \\frac{\\partial \\mathbf{q}}{\\partial \\mathbf{Q}} \\cdot \\frac{\\partial L_q}{\\partial \\mathbf{q}} + \\frac{\\partial \\mathbf{\\dot q}}{\\partial \\mathbf{Q}} \\cdot \\frac{\\partial L_q}{\\partial \\mathbf{\\dot q}} \\\\\n&= \\frac{\\partial \\mathbf{q}}{\\partial \\mathbf{Q}} \\cdot \\frac{d}{dt} \\frac{\\partial L_q}{\\partial \\mathbf{\\dot q}} + \\frac{d}{dt} \\frac{\\partial \\mathbf{q}}{\\partial \\mathbf{Q}} \\cdot \\frac{\\partial L_q}{\\partial \\mathbf{\\dot q}} \\\\\n&= \\frac{d}{dt} \\bigg(\\frac{\\partial \\mathbf{q}}{\\partial \\mathbf{Q}} \\cdot \\frac{\\partial L_q}{\\partial \\mathbf{\\dot q}}\\bigg) \\\\\n&= \\frac{d}{dt} \\bigg(\\frac{\\partial \\mathbf{\\dot q}}{\\partial \\mathbf{\\dot Q}} \\cdot \\frac{\\partial L_q}{\\partial \\mathbf{\\dot q}}\\bigg) \\\\\n&= \\frac{d}{dt} \\frac{\\partial L_Q}{\\partial \\mathbf{\\dot Q}}.\n\\end{align*}\n\\] Thus, if \\(L_q\\) satisfies Lagrange’s equations with respect to \\(\\mathbf{q}\\), then \\(L_Q\\) satisfies Lagrange’s equations with respect to \\(\\mathbf{Q}\\). That is, the equations of motion are invariant to point transformations of the coordinates.\nThis fact means we’re essentially free to write the Lagrangian of a system in whatever set of coordinates we wish. The underlying physics will stay the same. In relativistic language, this result says that the Lagrangian is a proper scalar. It doesn’t transform under coordinate transformations.\nIt’s also natural to ask if we can add functions to a Lagrangian in a way that leave the equations of motion invariant. This leads to the notion of a gauge transformation. To leave the equations of motion invariant, it’s important that any such transformation leave the action stationary.\nSuppose we transformed a valid Lagrangian by adding a total time derivative to it, \\[\n\\tilde L(\\mathbf{q}, \\mathbf{\\dot q}, t) = L(\\mathbf{q}, \\mathbf{\\dot q}, t) + \\frac{d}{dt} F(t).\n\\] If we assume the original equations of motion satisfy the principle of least action, we have \\(\\delta S=0\\), where \\[\nS = \\int_{t_1}^{t_2} L(\\mathbf{q}, \\mathbf{\\dot q}, t) dt.\n\\] Evidently, the modified action \\(\\tilde S\\) has the form \\[\n\\begin{align*}\n\\tilde S &= \\int_{t_1}^{t_2} \\tilde L(\\mathbf{q}, \\mathbf{\\dot q}, t) dt \\\\\n&= \\int_{t_1}^{t_2} \\bigg(L(\\mathbf{q}, \\mathbf{\\dot q}, t) +  \\frac{d}{dt} F(t) \\bigg)dt \\\\\n&= \\int_{t_1}^{t_2} L(\\mathbf{q}, \\mathbf{\\dot q}, t)dt + F(t) \\bigg|_{t_1}^{t_2} \\\\\n&= S + \\Delta F.\n\\end{align*}\n\\] Since \\(\\Delta F\\) is a constant that depends only on the endpoints, we must have \\[\n\\delta S = 0 \\quad \\Longleftrightarrow \\quad \\delta\\tilde S = 0.\n\\] That is, adding a total time derivative to the Lagrangian leaves the equations of motion invariant.\n\n\nExample: Gauge Transformations\nIn electrodynamics, Maxwell’s Equations are known to be invariant under a change of gauge. We can add the derivative of any scalar field \\(\\lambda(\\mathbf{x},t)\\) to the electromagnetic potentials in the following way and leave Maxwell’s Equations invariant, \\[\n\\begin{align*}\n\\phi'(\\mathbf{x},t) &= \\phi(\\mathbf{x},t) - \\frac{1}{c} \\frac{\\partial}{\\partial t} \\lambda(\\mathbf{x},t), \\\\\n\\mathbf{A}'(\\mathbf{x},t) &= \\mathbf{A}(\\mathbf{x},t) + \\nabla \\lambda(\\mathbf{x},t). \\\\\n\\end{align*}\n\\] Suppose we had a particle moving in the presence of an electromagnetic field. We already showed such a Lagrangian would have the form \\[\nL = \\frac{1}{2} m \\mathbf{v}^2 - q \\phi(\\mathbf{x},t) + \\frac{q}{c} \\mathbf{v} \\cdot \\mathbf{A}(\\mathbf{x},t).\n\\] Let’s ask what happens to the Lagrangian if we gauge-transform the potentials. Evidently, \\[\n\\begin{align*}\nL' &= \\frac{1}{2} m \\mathbf{v}^2 - q \\phi' + \\frac{q}{c} \\mathbf{v} \\cdot \\mathbf{A}' \\\\\n&= \\frac{1}{2} m \\mathbf{v}^2 - q \\bigg(\\phi - \\frac{1}{c} \\frac{\\partial \\lambda}{\\partial t} \\bigg) + \\frac{q}{c} \\mathbf{v} \\cdot (\\mathbf{A} + \\nabla \\lambda) \\\\\n&= \\bigg(\\frac{1}{2} m \\mathbf{v}^2 - q\\phi + \\frac{q}{c}\\mathbf{v} \\cdot \\mathbf{A}\\bigg) + \\frac{q}{c} \\bigg(\\mathbf{v} \\cdot \\nabla \\lambda + \\frac{\\partial \\lambda}{\\partial t}\\bigg) \\\\\n&= L + \\frac{q}{c} \\frac{d\\lambda}{dt}.\n\\end{align*}\n\\] Since the gauge-transformed Lagrangian is just the original Lagrangian plus a total time derivative, we can conclude the the Lorentz force law must be gauge invariant as well. Of course, this was already obvious from the fact that \\(\\mathbf{E}\\) and \\(\\mathbf{B}\\) were gauge invariant in Maxwell’s equations.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lagrangian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/lagrangian-mechanics.html#examples",
    "href": "classical-mechanics/lagrangian-mechanics.html#examples",
    "title": "Lagrangian Mechanics",
    "section": "Examples",
    "text": "Examples\nIt’s good to get very comfortable being able to find the equations of motion of systems using Lagrange’s equations. Here are some more complicated examples, many of which would be highly non-trival to solve using Newton’s Laws.\n\n\nExample: Uniform Rod on a Frictionless Table\n\n\n\n\n\n\n\n\nExample: Atwood Machine\n\n\n\n\n\n\n\n\nExample: Particle on a Cylinder\n\n\n\n\n\n\n\n\nExample: Block Sliding on Moving Wedge\n\n\n\n\n\n\n\n\nExample: Bead on a Wire",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lagrangian Mechanics</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/coupled-oscillations.html",
    "href": "classical-mechanics/coupled-oscillations.html",
    "title": "Coupled Oscillations",
    "section": "",
    "text": "One-Dimensional Systems\nConsider a system with one degree of freedom \\(q\\) in the presence of a potential energy \\(V(q)\\). We say such a system has an equilibrium point at \\(q=q_0\\) provided \\[\nF = -\\frac{dV}{dq} \\bigg|_{q=q_0} = 0.\n\\] Equivalently, \\(q_0\\) is an equilibrium point if it’s a stationary point of \\(V(q)\\). We say \\(q_0\\) is stable if it’s a local minimum of \\(V(q)\\), unstable if it’s a local maximum of \\(V(q)\\), and semi-stable if it’s a saddlepoint. In general, a potential energy \\(V(q)\\) may have many different equilibrium points.\nNow, if we expand \\(V(q)\\) in a Taylor Series about \\(q_0\\), we get \\[\nV(q) = V(q_0) + \\frac{dV}{dq}\\bigg|_{q_0} (q - q_0) + \\frac{1}{2} \\frac{d^2 V}{dq^2}\\bigg|_{q_0} (q - q_0)^2 + O\\big((q-q_0)^3\\big).\n\\] Since only differences in potential energy can affect the dynamics of a system, we can suppose without loss of generality that \\(V(q_0) = 0\\). Since \\(q_0\\) is an equilibrium point, we must also have \\(\\frac{dV}{dq}\\big|_{q_0} = 0\\). We’re thus left with \\[\nV(q) = \\frac{1}{2} \\frac{d^2 V}{dq^2}\\bigg|_{q_0} (q - q_0)^2 + O\\big((q-q_0)^3\\big).\n\\] We can always re-center the system so that \\(q_0=0\\). If we define \\(k \\equiv \\frac{d^2 V}{dq^2}\\big|_{q_0}\\), we evidently have \\[\nV(q) = \\frac{1}{2} k q^2.\n\\] But this is just the potential energy for Hooke’s Law, since \\(F = -\\frac{dV}{dq} = -kq\\). We’ve thus evidently defined Hooke’s Law from the assumption that a system is undergoing small motions near an equilibrium point.\nMotions will only be small oscillations if the equilibrium point \\(q_0\\) is stable, which is equivalent to requiring that \\(k &gt; 0\\) since \\(V(q_0)\\) is locally convex. If \\(k &lt; 0\\) the motion will be unstable since \\(V(q_0)\\) is locally concave. If \\(k=0\\) we run into a special case where we have to consider higher orders in the Taylor Series expansion. In this case, motion will be very near constant around \\(q_0\\), but can either grow or decay as \\(q\\) gets farther from \\(q_0\\).\nWe can also plug \\(V(q)\\) into the Lagrangian and get \\[\nL \\approx \\frac{1}{2}m \\dot q^2 - \\frac{1}{2} k q^2,\n\\] which is of course just the Lagrangian for SHO. We’ve thus derived the following important fact: Any 1-dimensional system undergoing small oscillations near a stable equilibrium point can be well-approximated by a simple harmonic oscillator.",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Coupled Oscillations</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/coupled-oscillations.html#one-dimensional-systems",
    "href": "classical-mechanics/coupled-oscillations.html#one-dimensional-systems",
    "title": "Coupled Oscillations",
    "section": "",
    "text": "Example: Kepler Orbits\nRecall for Kepler orbits we have a Lagrangian \\(L = \\frac{1}{2}m\\dot r^2 - V_{eff}(r)\\), where \\[\nV_{eff}(r) = \\frac{\\ell^2}{2mr^2} - \\frac{GMm}{r}.\n\\] This effective potential has a stable equilibrium when the orbits are circular, i.e. \\(r=r_0\\).\nSetting the first derivative of \\(V_{eff}(q)\\) to zero gives \\[\n\\frac{dV_{eff}}{dr}\\bigg|_{r_0} = -\\frac{\\ell^2}{mr_0^3} + \\frac{GMm}{r_0^2} = 0 \\quad \\Longrightarrow \\quad r_0 = \\frac{\\ell^2}{GMm^2}.\n\\] Setting the second derivative to \\(k\\) gives \\[\nk = \\frac{d^2V_{eff}}{dr^2}\\bigg|_{r_0} = 3\\frac{\\ell^2}{mr_0^4} - 2\\frac{GMm}{r_0^3} = \\frac{GMm}{r_0^3} &gt; 0.\n\\] Thus, the Kepler orbit undergoes stable oscillations about the point \\(r=r_0\\), with a force law \\(F(r) \\approx -k(r-r_0)\\). The oscillation frequency and period are given by \\[\n\\omega = \\sqrt{\\frac{k}{m}} = \\sqrt{GM}{r_0^3} \\quad \\Longrightarrow \\quad \\tau = \\frac{2\\pi}{\\sqrt{GM}} r_0^{3/2},\n\\] which is just Kepler’s Third Law for circular orbits.\n\n\n\nExample: Two Coupled Springs\nBefore deriving the general form for the solution of coupled linear systems, let’s try to solve the problem of two springs attached to each other in sequence. Assume both masses have mass \\(m\\). Assume the springs attached to the walls have spring constant \\(k\\), and the coupling spring constant between the two masses is \\(k_{12}\\).\n\n\n\n\n\nDenote the position of mass one relative to its equilibrium as \\(x_1\\), and the position of mass two relative to its equilibrium by \\(x_2\\). Then the Lagrangian is \\[\nL = \\frac{1}{2} m (\\dot x_1^2 + \\dot x_2^2) - \\frac{1}{2}(kx_1^2 + k_{12}(x_2-x_1)^2 + kx_2^2).\n\\] The equations of motion are thus given by \\[\n\\begin{align*}\nm \\ddot x_1 &= -kx_1 + k_{12}(x_2 - x_1), \\\\\nm \\ddot x_2 &= -kx_1 - k_{12}(x_2 - x_1).\n\\end{align*}\n\\] This is a coupled system of two linear differential equations. To solve, let’s suppose that both solutions are sinusoidal with the same frequency \\(\\omega\\), say \\(x_1 = A_1 \\cos\\omega t\\) and \\(x_2 = A_2 \\cos\\omega t\\). Then we have",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Coupled Oscillations</span>"
    ]
  },
  {
    "objectID": "classical-mechanics/coupled-oscillations.html#general-problem",
    "href": "classical-mechanics/coupled-oscillations.html#general-problem",
    "title": "Coupled Oscillations",
    "section": "General Problem",
    "text": "General Problem\nLet’s now consider a system with \\(n\\) degrees of freedom \\(q_1, q_2, \\cdots, q_n\\) given by a Lagrangian \\[\nL = \\frac{1}{2} \\dot q_i T_{ij}(q_1,\\cdots,q_n) \\dot q_j - V(q_1,\\cdots,q_n).\n\\] Let’s re-write this in vector notation by defining \\(\\mathbf{q} \\equiv (q_1,q_2,\\cdots,q_n)\\) and \\(\\mathbf{T} \\equiv (T_{ij})\\). Then we have \\[\nL = \\frac{1}{2}\\mathbf{\\dot q}^\\top \\mathbf{T}(\\mathbf{q}) \\mathbf{\\dot q} - V(\\mathbf{q}).\n\\] Now, suppose \\(\\mathbf{q}_0\\) is an equilibrium point of the system. Since the kinetic energy depends on \\(\\mathbf{q}\\) we’ll have to Taylor expand the entire Lagrangian about \\(\\mathbf{q}_0\\). For \\(V(\\mathbf{q})\\) we have \\[\nV(\\mathbf{q}) = V(\\mathbf{q}_0) + \\nabla V^\\top(\\mathbf{q}_0) (\\mathbf{q}-\\mathbf{q}_0) + \\frac{1}{2} (\\mathbf{q}-\\mathbf{q}_0)^\\top \\mathbf{H}(\\mathbf{q_0}) (\\mathbf{q}-\\mathbf{q}_0) + O\\big(||\\mathbf{q}-\\mathbf{q}_0||^3\\big).\n\\] Again, only differences in potential energy matter, so we can define \\(V(\\mathbf{q}_0) = 0\\). Furthermore, since \\(\\mathbf{q}_0\\) is an equilibrium point, we must have \\(\\nabla V(\\mathbf{q}_0) = \\mathbf{0}\\). Let’s define \\(\\mathbf{K} \\equiv \\mathbf{H}(\\mathbf{q}_0)\\). Then, to second-order in \\(\\mathbf{q}-\\mathbf{q}_0\\) we have \\[\nV(\\mathbf{q}) \\approx \\frac{1}{2} (\\mathbf{q}-\\mathbf{q}_0)^\\top \\mathbf{K} (\\mathbf{q}-\\mathbf{q}_0).\n\\] For the kinetic energy term, expanding \\(\\mathbf{T}(\\mathbf{q})\\) about \\(\\mathbf{q}_0\\) in a similar manner gives \\[\n\\mathbf{T}(\\mathbf{q}) = \\mathbf{T}(\\mathbf{q}_0) + O\\big(||\\mathbf{q}-\\mathbf{q}_0|| \\big).\n\\] Defining \\(\\mathbf{M} \\equiv \\mathbf{T}(\\mathbf{q}_0)\\) and dropping terms of higher order, we have \\(\\mathbf{T}(\\mathbf{q}) \\approx \\mathbf{M}\\). Plugging both of these terms into the Lagrangian and keeping only terms quadratic in \\(\\mathbf{q}\\) and \\(\\mathbf{q}_0\\), we finally have, \\[\nL \\approx \\frac{1}{2} \\mathbf{\\dot q}^\\top \\mathbf{M} \\mathbf{\\dot q} - \\frac{1}{2} (\\mathbf{q}-\\mathbf{q}_0)^\\top \\mathbf{K} (\\mathbf{q}-\\mathbf{q}_0).\n\\] This is the most general form of the Lagrangian for a many-body mechanical system when expanded to quadratic order about an equilibrium point. Most of the time we’ll want to re-center so that \\(\\mathbf{q}_0 = \\mathbf{0}\\). In that case, the Lagrangian reduces to just \\[\nL \\approx \\frac{1}{2} \\mathbf{\\dot q}^\\top \\mathbf{M} \\mathbf{\\dot q} - \\frac{1}{2} \\mathbf{q}^\\top \\mathbf{K} \\mathbf{q}.\n\\] Notice this looks exactly like the scalar Lagrangian for SHO, \\(L = \\frac{1}{2}m \\dot q^2 - \\frac{1}{2} k q^2\\), except everything is in matrix-vector notation now.\nWe can solve Lagrange’s equations in matrix-vector notation now, \\[\n\\frac{dL}{d\\mathbf{q}} + \\frac{d}{dt}\\frac{dL}{d\\mathbf{\\dot q}} = \\mathbf{0}.\n\\] Solving this system simply gives the vector equations of motion \\[\n\\mathbf{M}\\mathbf{\\ddot q} = -\\mathbf{K}\\mathbf{q},\n\\] which is the \\(n\\)-dimensional generalization of Hooke’s Law.\nAssuming \\(\\mathbf{M}\\) is invertible, we can define \\(\\mathbf{\\Omega}^2 \\equiv \\mathbf{M}^{-1} \\mathbf{K}\\), and write \\[\n\\mathbf{\\ddot q} = -\\mathbf{\\Omega}^2 \\mathbf{q}.\n\\] The nature of the solutions will depend on the definiteness of \\(\\mathbf{\\Omega}^2\\). Evidently, if \\(\\mathbf{\\Omega}^2\\) is positive definite, the solutions will be stable. If \\(\\mathbf{\\Omega}^2\\) is negative definite, the solutions will be unstable.\nSkip to the rest of the theory before doing more examples…\nPer ChatGPT: The general solution to the coupled oscillator \\(M \\ddot x = -K x\\) in closed form can be written as \\[\nx(t) = V \\cos(\\Omega t) c + V \\sin(\\Omega t) d,\n\\] where \\(V\\) is the matrix of eigenvectors of \\(\\Omega^2 = M^{-1} K\\), and \\(c, d\\) are initial condition vectors.\nVerify this!!!",
    "crumbs": [
      "Classical Mechanics",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Coupled Oscillations</span>"
    ]
  },
  {
    "objectID": "electrodynamics/preliminaries.html",
    "href": "electrodynamics/preliminaries.html",
    "title": "Preliminaries",
    "section": "",
    "text": "Units\nWe’ll start by saying a word about units. Typically in physics we need not think much about units. Abstractly the formulas look the same, whether the quantities involved are measured in meters, feet, or lightyears. However, electromagnetism has the unusual quirk that different unit systems lead to slightly different looking formulas. The reasons for this are largely historical, and very little if any physics is involved in the way these formulas look in different systems of units. An important implication of this frustrating quirk is that we have to be much more careful at the outset to specify which units we’re using since it will affect the formulas involved in derivations and calculations. To start, we’ll very briefly look at several different systems of units before committing to one for the rest of the course.\nThe foundation of systems of units in electromagnetism are forces on and due to the presence of charges and currents. It was found early on that there are two types of electric charge, positive and negative. Two like charges repel, while two opposite charges attract. The force between those charges also depends on the distance between them in a specific way. Suppose two charges \\(q_1\\) and \\(q_2\\) are separated from each other by a distance \\(r\\). The magnitude of the force felt by the two charges is given by an inverse square law known as Coulomb’s Law, \\[\nF = k_e \\frac{q_1 q_2}{r^2} \\ .\n\\] The proportionality constant \\(k_e\\) is known as the electric constant whose dimension and value depends on choice of units. The quantity \\(k_e q_1 q_2\\) can be measured in the lab by measuring the strength of the force and the distance between the two charges.\nA little while later people figured out how to run moving charges, or currents, through wires. In studying the behavior of current flowing through two nearby parallel wires, it was found that the wires repel each other when the currents move in the same direction, and repel each other when the currents move in the opposite direction. The force also seemed to depend on the distance between the wires. Suppose two parallel wires a distance \\(r\\) apart are carrying currents \\(I_1\\) and \\(I_2\\). Suppose each wire has the same fixed length \\(\\ell\\). Then the force experienced by the two wires due to the currents is given by Ampere’s Force Law,\n\\[\n\\frac{dF}{d\\ell} = 2k_m \\frac{I_1 I_2}{r} \\ .\n\\] The proportionality constant \\(k_m\\) is yet another constant that depends on units. The quantity \\(k_m I_1 I_2\\) can be measured in the lab by measuring the strength of the force per unit length and the distance of separation between the two wires.\nIt was further realized later that these two phenomena can be generalized using the notion of fields. The force felt by a charge due to other charges can also be thought of as a force on a charge felt by an electric field \\(\\mathbf{E}(\\mathbf{x},t)\\) that sums of the effects of all the other background charges. The force felt on a charge \\(q\\) is evidently proportional to this electric field, \\(\\mathbf{F} \\propto q \\mathbf{E}\\). A similar description can be made for the forces felt on a moving charge, i.e. a current, due to the presence of a magnetic field \\(\\mathbf{B}(\\mathbf{x},t)\\) that sums up the effects of all other background currents. This force felt on a moving charge \\(q\\) is proportional to both its velocity \\(\\mathbf{v}\\) and the magnetic field, with \\(\\mathbf{F} \\propto q\\mathbf{v} \\times \\mathbf{B}\\). If we try to sum these two forces together to get the combined force on the moving charge we have to establish how the electric and magnetic fields dimensionally relate to each other. This combined force law is known as the Lorentz Force Law, given generally by \\[\n\\mathbf{F} = q \\bigg(\\mathbf{E} + \\frac{\\mathbf{v}}{\\alpha} \\times \\mathbf{B}\\bigg) \\ .\n\\] Here we introduce a new constant \\(\\alpha\\) to control the dimensional relationship between \\(\\mathbf{E}\\) and \\(\\mathbf{B}\\). Initially this was ignored and \\(\\alpha=1\\) was chosen without people really thinking about it. But later on it was realized that the two fields should actually be thought of as essentially the same object and should thus have the same dimensions. For this to be true, \\(\\alpha\\) must be chosen to be some constant with dimensions of velocity.\nThe three parameters \\(k_e, k_m, \\alpha\\) are not completely independent though. Most importantly, dimensional analysis and experiment force \\(k_e\\) and \\(k_m\\) to be related in a very specific way, namely by \\[\nc^2 = \\frac{k_e}{k_m} \\ ,\n\\] where \\(c\\) is the speed of light in vacuum, a fundamental constant measured to be \\(c \\approx 3 \\cdot 10^{10} \\ \\frac{\\text{cm}}{\\text{s}}\\). Several experiments already concluded that \\(c\\) was indeed a universal constant with no dependence on choice of reference frame. This ratio evidently thus gives us a natural velocity scale, which coincidentally is what we’d need to fix \\(\\alpha\\) to make \\(\\mathbf{E}\\) and \\(\\mathbf{B}\\) to have the same units.\nIn the early days of electromagnetism the centimeter-gram-second or CGS system was already being widely used to measure mechanical quantities like length, mass, time, force, and energy. The unit of force was called the dyne, which comes out to \\(1 \\ \\text{dyne} = 10^{-5} \\ \\text{N}\\), while the unit of energy was called the erg, which comes out to \\(1 \\ \\text{erg} = 10^{-7} \\ \\text{J}\\). When electromagnetism came along it was realized these mechanical units needed to somehow be extended to cover electromagnetic phenomena as well, but that there were different all self consistent ways this could be done based on how \\(k_e, k_m, \\alpha\\) were specified.\nEarly on two unit systems arose to cover electromagnetism, one being used to measure electric quantities, and a completely different one used to measure magnetic quantities. The early system of units for electricity was called electrostatic units or the ESU system. This system defined \\(k_e\\equiv\\alpha\\equiv1\\), which then forced \\(k_m \\equiv \\frac{1}{c^2}\\). This defined a natural unit of charge, later called the electrostatic unit or esu, with \\(1 \\ \\text{esu} \\approx 3.3 \\cdot 10^{-10} \\ \\text{C}\\). An analogous system arose to study magnetism, called electromagnetic units or the EMU system. This system defined \\(k_m \\equiv \\alpha \\equiv 1\\), which then forced \\(k_e = c^2\\). This defined a natural unit of current, later called the absolute amp or abamp, with \\(1 \\ \\text{abamp} = 10 \\ \\text{A}\\) exactly.\nIt was found to be cumbersome to go back and forth between the two subjects since one had to change units to compare results. It was also eventually realized that having the electric and magnetic fields be different dimensions didn’t make sense, as Einstein showed the two fields were really just the same field expressed in different reference frames. The two unit systems were then combined into yet a third system called the Gaussian system. The Gaussian system also uses CGS mechanical units, but takes \\[\nk_e \\equiv 1 \\quad , \\quad k_m \\equiv \\frac{1}{c^2} \\quad , \\quad \\alpha \\equiv c \\ .\n\\] This system had the benefit that the unit of charge was still the esu, but now the electric and magnetic fields have the same units. The unit of current is no longer the abamp, but instead the esu per second. The Gaussian system became popular among physicists, especially among theorists due to the fact that electricity and magnetism were treated on the same footing.\nHowever, things played out differently on the engineering side. While physicists were studying electromagnetism in the lab, engineers were starting to use these ideas to build practical things like wires, motors, transformers, circuits, and radios. Engineers at the time didn’t like the fact that when that CGS units were poorly scaled to measure everyday things like the current through a telegraph wire or the voltage across a resistor. They instead chose to use a different system based on the meter, kilogram, and second, called the MKS system. The abamp was seen as too big for electrical applications of the time, so they defined a smaller unit of current called the amp or Ampere, defined by \\(1 \\ \\text{A} \\equiv 0.1 \\ \\text{abamp}\\).\nLater on, MKS units were extended to the rest of electromagnetism, but in a kind of quirky way. It was decided to define \\[\nk_e \\equiv \\frac{1}{4\\pi\\varepsilon_0} \\quad , \\quad k_m \\equiv \\frac{\\mu_0}{2\\pi} \\quad , \\quad \\alpha \\equiv 1 \\ .\n\\] This odd definition was chosen out of the prevelant belief at the time that electromagnetic phenomena permuated in a fluid known as the ether, which they believed had a natural permittivity and permeability like any other material. This idea was later invalided through experiments, but the notation persists unfortunately. The division by \\(4\\pi\\) was arbitrary, done to rationalize out any factors of \\(\\pi\\) from Maxwell’s equations. As with the ESU and EMU systems, the electric and magnetic fields be of the same units wasn’t seen as an imperative, so no scaling by the speed of light was done either.\nThe constants \\(\\varepsilon_0\\) and \\(\\mu_0\\) were chosen as the more fundamental constants due to a misbelief that the vacuum was made of an electromagnetic fluid known as the ether, which was later falsified by experiment. These constants were tuned in the MKSA system specifically so that unit of current would come out to be exactly a tenth of an abamp. For this to work out consistently, they defined \\[\n\\mu_0 \\equiv 4\\pi \\cdot 10^{-7} \\ \\frac{\\text{N}}{\\text{A}^2} \\quad , \\quad \\varepsilon_0 \\equiv \\frac{10^7}{4\\pi c^2} \\approx 8.84 \\cdot 10^{-14} \\ \\frac{\\text{A}^2 \\ \\text{s}^4}{\\text{kg} \\ \\text{m}^3} \\ .\n\\]\nThis extended MKS system adds a fourth independent unit, the Ampere. All other electromagnetic quantities are then naturally defined in terms of the values of the meter, kilogram, second, and the Ampere. It’s this system, sometimes called the MKSA system, that later become the SI system used widely today in science and engineering.\nOn top of all these systems yet another system of units for electromagnetism was defined that closely relates to the Gaussian system. This system of units is called the Heaviside-Lorentz system. It also uses the CGS system and takes \\(\\alpha=c\\), but it follows the MKSA system in choosing to rationalize out the factors of \\(4\\pi\\) from Maxwell’s equations. It thus chooses \\[\nk_e \\equiv \\frac{1}{4\\pi} \\quad , \\quad k_m \\equiv \\frac{1}{4\\pi c^2} \\quad , \\quad \\alpha \\equiv c \\ .\n\\] As with the Gaussian system, in the Heaviside-Lorentz the electric and magnetic fields again have the same units. The only real difference is that the measured units change by a factor of \\(4\\pi\\), and the factors of \\(4\\pi\\) are removed from Maxwell’s equations.\nNowadays, the ESU and EMU systems are rarely if ever used. The SI system is of course widely used, particularly among experimentalists and engineers, as well as in essentially all modern undergraduate electromagnetism textbooks. The Heaviside-Lorentz system is favored by the particle physics community, perhaps because they often set \\(c=1\\), which makes the formulas look similar to those in the SI system. The Gaussian system remains popular particularly among theoretical physicists due to its symmetric treatment of the electric and magnetic fields and its use of a single constant in formulas, the speed of light \\(c\\).\nWhile each choice of units has its benefits depending on the field of study and the application, in this course we will stick primarily with the Gaussian system of units, which is well-suited to a theoretical study of electromagnetism. To go back and forth between Gaussian and SI units in various formulas, a useful trick that often works (but not always) is to make the identification \\[\n\\varepsilon_0 \\leftrightarrow \\frac{1}{4\\pi} \\quad , \\quad \\mu_0 \\leftrightarrow \\frac{4\\pi}{c} \\ .\n\\]\nBelow is a table of various electromagnetism formulas expressed in the three unit systems still in widespread use today. We’ll define or derive all of these formulas in more details in later lessons.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Preliminaries</span>"
    ]
  },
  {
    "objectID": "electrodynamics/preliminaries.html#units",
    "href": "electrodynamics/preliminaries.html#units",
    "title": "Preliminaries",
    "section": "",
    "text": "Gaussian\nHeaviside-Lorentz\nSI\n\n\n\n\nElectric Field\n\\(\\mathbf{E} = -\\nabla \\Phi + \\frac{1}{c}\\frac{\\partial \\mathbf{A}}{\\partial t}\\)\n\\(\\mathbf{E} = -\\nabla \\Phi + \\frac{1}{c}\\frac{\\partial \\mathbf{A}}{\\partial t}\\)\n\\(\\mathbf{E} = -\\nabla \\Phi + \\frac{\\partial \\mathbf{A}}{\\partial t}\\)\n\n\nMagnetic Field\n\\(\\mathbf{B} = \\nabla \\times \\mathbf{A}\\)\n\\(\\mathbf{B} = \\nabla \\times \\mathbf{A}\\)\n\\(\\mathbf{B} = \\nabla \\times \\mathbf{A}\\)\n\n\nCoulomb’s Law\n\\(\\mathbf{E} = \\frac{q}{r^2} \\mathbf{e}_r\\)\n\\(\\mathbf{E} = \\frac{1}{4\\pi}\\frac{q}{r^2} \\mathbf{e}_r\\)\n\\(\\mathbf{E} = \\frac{1}{4\\pi\\varepsilon_0}\\frac{q}{r^2} \\mathbf{e}_r\\)\n\n\nBiot-Savart Law\n\\(d\\mathbf{B} = \\frac{I}{c} \\frac{d\\boldsymbol{\\ell} \\times \\mathbf{e}_r}{r^2}\\)\n\\(d\\mathbf{B} = \\frac{I}{4\\pi c} \\frac{d\\boldsymbol{\\ell} \\times \\mathbf{e}_r}{r^2}\\)\n\\(d\\mathbf{B} = \\frac{\\mu_0 I}{4\\pi} \\frac{d\\boldsymbol{\\ell} \\times \\mathbf{e}_r}{r^2}\\)\n\n\nLorentz Force Law\n\\(\\mathbf{F} = q\\mathbf{E} + q\\frac{\\mathbf{v}}{c} \\times \\mathbf{B}\\)\n\\(\\mathbf{F} = q\\mathbf{E} + q\\frac{\\mathbf{v}}{c} \\times \\mathbf{B}\\)\n\\(\\mathbf{F} = q\\mathbf{E} + q\\mathbf{v} \\times \\mathbf{B}\\)\n\n\nDisplacement Field\n\\(\\mathbf{D} = \\mathbf{E} + 4\\pi \\mathbf{P}\\)\n\\(\\mathbf{D} = \\mathbf{E} + \\mathbf{P}\\)\n\\(\\mathbf{D} = \\varepsilon_0 \\mathbf{E} + \\mathbf{P}\\)\n\n\nMagnetizing Field\n\\(\\mathbf{H} = \\mathbf{B} - 4\\pi \\mathbf{M}\\)\n\\(\\mathbf{H} = \\mathbf{B} - \\mathbf{M}\\)\n\\(\\mathbf{H} = \\frac{1}{\\mu_0}\\mathbf{B} - \\mathbf{M}\\)\n\n\nGauss’s Law\n\\(\\nabla \\cdot \\mathbf{E} = 4\\pi \\rho\\)\n\\(\\nabla \\cdot \\mathbf{E} = \\rho\\)\n\\(\\nabla \\cdot \\mathbf{E} = \\frac{\\rho}{\\varepsilon_0}\\)\n\n\nFaraday’s Law\n\\(\\nabla \\times \\mathbf{E} = -\\frac{1}{c} \\frac{\\partial \\mathbf{B}}{\\partial t}\\)\n\\(\\nabla \\times \\mathbf{E} = -\\frac{1}{c}\\frac{\\partial \\mathbf{B}}{\\partial t}\\)\n\\(\\nabla \\times \\mathbf{E} = -\\frac{\\partial \\mathbf{B}}{\\partial t}\\)\n\n\nGauss’s Law for Magnetism\n\\(\\nabla \\cdot \\mathbf{B} = 0\\)\n\\(\\nabla \\cdot \\mathbf{B} = 0\\)\n\\(\\nabla \\cdot \\mathbf{B} = 0\\)\n\n\nAmpere-Maxwell Law\n\\(\\nabla \\times \\mathbf{B} = \\frac{4\\pi}{c} \\mathbf{J} + \\frac{1}{c} \\frac{\\partial \\mathbf{E}}{\\partial t}\\)\n\\(\\nabla \\times \\mathbf{B} = \\frac{1}{c} \\mathbf{J} + \\frac{1}{c} \\frac{\\partial \\mathbf{E}}{\\partial t}\\)\n\\(\\nabla \\times \\mathbf{B} = \\mu_0 \\mathbf{J} + \\mu_0 \\varepsilon_0 \\frac{\\partial \\mathbf{E}}{\\partial t}\\)\n\n\nContinuity Equation\n\\(\\nabla \\cdot \\mathbf{J} = -\\frac{\\partial \\rho}{\\partial t}\\)\n\\(\\nabla \\cdot \\mathbf{J} = -\\frac{\\partial \\rho}{\\partial t}\\)\n\\(\\nabla \\cdot \\mathbf{J} = -\\frac{\\partial \\rho}{\\partial t}\\)\n\n\nOhm’s Law\n\\(\\mathbf{J} = \\sigma \\mathbf{E}\\)\n\\(\\mathbf{J} = \\sigma \\mathbf{E}\\)\n\\(\\mathbf{J} = \\sigma \\mathbf{E}\\)\n\n\nEnergy Density\n\\(u = \\frac{1}{8\\pi} (|\\mathbf{E}|^2 + |\\mathbf{B}|^2)\\)\n\\(u = \\frac{1}{2} (|\\mathbf{E}|^2 + |\\mathbf{B}|^2)\\)\n\\(u = \\frac{\\varepsilon_0}{2} |\\mathbf{E}|^2 + \\frac{1}{2\\mu_0} |\\mathbf{B}|^2\\)\n\n\nPoynting Vector\n\\(\\mathbf{S} = \\frac{c}{4\\pi} \\mathbf{E} \\times \\mathbf{B}\\)\n\\(\\mathbf{S} = c \\mathbf{E} \\times \\mathbf{B}\\)\n\\(\\mathbf{S} = \\frac{1}{\\mu_0} \\mathbf{E} \\times \\mathbf{B}\\)",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Preliminaries</span>"
    ]
  },
  {
    "objectID": "electrodynamics/preliminaries.html#vectors",
    "href": "electrodynamics/preliminaries.html#vectors",
    "title": "Preliminaries",
    "section": "Vectors",
    "text": "Vectors\nWe will now give a very brief review of some important mathematical results that will be important in our study of electrodynamics. We will not prove anything here nor provide many if any examples, as this is all assumed to be review.\nAs in mechanics, in electrodynamics we generally assume that physical objects live in a 3-dimensional real space, often denoted by the set \\(\\mathbb{R}^3\\). A vector or 3-vector we’ll define as a 3-component object \\(\\mathbf{v}\\) that lives in \\(\\mathbb{R}^3\\). The 3 components of the vector depend on the choice of coordinate system or basis chosen. In Cartesian coordinates we can expand a vector as a superposition of unit vectors aligned with the coordinate axes, \\[\n\\mathbf{v} = v_x \\mathbf{e}_x + v_y \\mathbf{e}_y + v_z \\mathbf{e}_z = v_1 \\mathbf{e}_1 + v_2 \\mathbf{e}_2 + v_3 \\mathbf{e}_3 \\ .\n\\]\n\n\n\n\n\nThe second representation of using numerical indices to represent the components in order will be useful for us, as we’ll often express superpositions like this using summation notation, or more conveniently using the Einstein summation convention, \\[\n\\mathbf{v} \\equiv v_i \\mathbf{e}_i \\equiv \\sum_{i=1}^3 v_i \\mathbf{e}_i \\ .\n\\] Recall the summation convention says that if a term has a repeated index a summation over all values of that index is implied. In this case, \\(v_i \\mathbf{e}_i\\) has the repeated index \\(i\\), which is assumed to sum from 1 to 3. Any index that does not repeat does not get summed over. We’ll sometimes express a vector only by its components \\(v_i\\), where the basis is left unspecified. This is called index notation. It’s fully equivalent to vector notation but sometimes more convenient when doing complex vector calculations. We’ll go back and forth between these two notations in this course.\nFor a vector to be a valid physical object, we require it transform in a specific way under coordinate transformations. Suppose in one rectangular coordinate system we have coordinates \\(x_i\\) and in another rotated coordinate system we have coordinates \\(x_i'\\). Then for \\(\\mathbf{v}\\) to be a valid vector we require that for any such choice of coordinates we have \\[\n\\mathbf{v} = v_i \\mathbf{e}_i = v_i' \\mathbf{e}_i' \\ .\n\\] We can express this more succinctly by saying that \\[\nv_j' = \\frac{\\partial x_j'}{\\partial x_i} v_i \\ .\n\\] This set of \\(3^2 = 9\\) partial derivatives is called the Jacobian between the coordinates \\(x_i\\) and \\(x_i'\\). Notice the implied summation going on over \\(i\\). This means the right-hand side will contain only 3 elements indexed by \\(j\\). These partial derivatives can be collected into a matrix called the Jacobian matrix, which is often denoted by \\(\\mathbf{J}\\) or \\(\\mathbf{J}(\\mathbf{x},\\mathbf{x}')\\). The Jacobian is a surprisingly important object in vector calculus as we’ll see. Note that by definition, any linear superposition of valid vectors will also be a valid vector.\nWe can thus think of a vector as a one index, or rank-1, object that transforms in the manner specified above. A simpler object with no index, or rank-0, defines a scalar. A scalar is a single number that doesn’t change under coordinate transformations. An important example of a scalar is the dot product or inner product between two vectors, defined in Euclidean space by \\[\n\\mathbf{v} \\cdot \\mathbf{w} \\equiv v_i w_i = v_1 w_1 + v_2 w_2 + v_3 w_3 \\ .\n\\] Recall from elementary physics that we can also express the dot product in terms of the angle \\(\\theta\\) between the two vectors as \\[\n\\mathbf{v} \\cdot \\mathbf{w} = |\\mathbf{v}| |\\mathbf{w}| \\cos\\theta \\ .\n\\] Here \\(|\\mathbf{v}| \\equiv \\sqrt{\\mathbf{v} \\cdot \\mathbf{v}}\\) is the norm or magnitude of \\(\\mathbf{v}\\). This formula says that in some sense the dot product encodes information about both the magnitude of vectors as well as the angles between them. When \\(|\\mathbf{v}|=1\\) we say \\(\\mathbf{v}\\) is a unit vector, which in this course we’ll usually denote by \\(\\mathbf{e}_v\\). Evidently the dot product of two vectors is zero if they’re perpendicular, in which case we call the two vectors orthogonal. When the two vectors are parallel or antiparallel their dot product is \\(\\pm 1\\).\nAs long as coordinate transformations are rotations, the dot product will always be a scalar. As an exercise in using index notation let’s prove this. When working in index notation we need to convert every object we need to an indexed object. Since \\(\\mathbf{v}\\) and \\(\\mathbf{w}\\) are vectors, they both get one index. Since their components get summed over in the dot product, the indices on the two vectors should be the same.\nWe’re now ready to proceed with the proof. We need to show that under a coordinate transformation the dot product stays invariant under rotations. Starting with the dot product in \\(x_i'\\) coordinates, and denoting the partial derivatives in the Jacobian between \\(x_i\\) and \\(x_i'\\) coordinates by \\(J_{ij}\\), we have \\[\nv_i' w_i' = v_i' w_j' = (J_{ij} v_j) (J_{ik} w_k) = J_{ij} J_{ik} v_i w_k  \\ .\n\\] Now, we need the right-hand side to equal \\(v_i w_i\\). The only way this can be true is if \\(J_{ij} J_{ik} = \\delta_{jk}\\). Then we get \\[\nv_i' w_i' = J_{ij} J_{ik} v_i w_k = \\delta_{jk} v_i w_k = v_j w_j  \\ .\n\\] Now, the index being summed over is a dummy index, meaning it doesn’t matter how we label it as long as we’re consistent. We can thus freely relabel \\(j\\) to \\(i\\) and write \\(v_i' w_i' = v_i w_i\\), which is what we wanted to show.\nFor this proof to work, however, we had to impose the fact that \\(J_{ij} J_{ik} = \\delta_{jk}\\). This is just saying that the Jacobian times its transpose should equal the identity, i.e. \\(\\mathbf{J}^\\top \\mathbf{J} = \\mathbf{I}\\). What kinds of transformations satisfy this property? Recall that this is just the definition of an orthogonal transformation. An orthogonal transformation is precisely a transformation that preserves the dot products between vectors. From the elementary definition of the dot product, this also means an orthogonal transformation preserves the angles between vectors. Note that such transformations need not preserve the handedness between the vectors. Since \\(\\det \\mathbf{J} = \\pm 1\\) for orthogonal transformations, there are two cases. It’s the \\(+1\\) case that preserves handedness, while the \\(-1\\) case flips the order between the vectors.\nIt’s fair to ask what happens when the coordinate transformation isn’t orthogonal. In that case, we define \\(\\mathbf{g} \\equiv \\mathbf{J}^\\top \\mathbf{J}\\), in which case we then define \\(\\mathbf{x} \\cdot \\mathbf{y} \\equiv x_i g_{ij} y_j\\). Here \\(\\mathbf{g}\\) is called the metric. It says something about the geometry of the two coordinate transformations. With this generalized form of the dot product it again becomes a proper scalar regardless of what \\(\\mathbf{J}\\) is. We’ll see this more general dot product again when we get to relativistic electrodynamics towards the end of the course. Indeed, the presence of \\(\\mathbf{g}\\) is one of the defining features of relativity, both special and general relativity.\nWe know that vectors in 3 dimensions also have another kind of product that creates vectors from vectors. This other product is called the cross product, which in index notation can be defined by \\[\n(\\mathbf{x} \\times \\mathbf{y}) \\equiv \\varepsilon_{ijk} x_i y_j \\mathbf{e}_k \\ .\n\\] Here \\(\\varepsilon_{ijk}\\) is the Levi-Civita symbol, defined to be \\(+1\\) for even permutations of \\(ijk\\), \\(-1\\) for odd permutations of \\(ijk\\), and \\(0\\) when any of the indices are repeated. Written out in components, it’s not hard to show that \\[\n\\mathbf{v} \\times \\mathbf{w} = (v_y w_z - v_z w_y) \\mathbf{e}_x + (v_z w_x - v_x w_z) \\mathbf{e}_y + (v_x w_y - v_y w_x) \\mathbf{e}_z \\ .\n\\] We know that the cross product between two vectors can also be expressed geometrically, where its magnitude is given by \\[\n|\\mathbf{v} \\times \\mathbf{w}| = |\\mathbf{v}| |\\mathbf{w}| \\sin\\theta \\ ,\n\\] while its direction is given by the right-hand rule. The cross product evidently defines a favored orientation in space. If a plane contains the two vectors \\(\\mathbf{v}\\) and \\(\\mathbf{w}\\), its positive orientation or normal is the direction of \\(\\mathbf{v} \\times \\mathbf{w}\\). Evidently, this version of the cross product says that the cross product of two parallel vectors is \\(\\mathbf{0}\\). Note the cross product is neither commutative nor associative.\nIt’s worth pointing out that despite the hand-waving, the cross product is not really a vector in the sense we’ve defined what a vector really is, an object that transforms a certain way under coordinate transformations. The cross product in general does not transform correctly under coordinate transformations. For example, under an inversion \\(\\mathbf{v} \\rightarrow -\\mathbf{v}, \\mathbf{w} \\rightarrow -\\mathbf{w}\\) their cross product remains \\(\\mathbf{v} \\times \\mathbf{w}\\). It doesn’t become \\(-\\mathbf{v} \\times \\mathbf{w}\\) like we’d require. For this reason the cross product is properly thought of as a pseudovector, in that in a lot of ways it behaves like a vector, but not in all ways. In fact, properly speaking the cross product should be thought of as an antisymmetric tensor. We’ll say more about this below.\nThe Levi-Civita symbol is a useful symbol in its own right, independent of the cross product. We’ll need to understand its algebra a bit better since we’ll use this symbol frequently in this course. One useful fact is that swapping two indices introduces a negative sign. For example, swapping \\(i \\leftrightarrow j\\) gives \\(\\varepsilon_{jik} = -\\varepsilon_{ijk}\\). We can use this fact to show that the cross product is perpendicular to the plane spanned by the two vectors. We can do this by showing \\(\\mathbf{v} \\cdot (\\mathbf{v} \\times \\mathbf{w}) = 0\\). That is, that \\(\\mathbf{v}\\) is orthogonal to \\(\\mathbf{v} \\times \\mathbf{w}\\), which by the geometric version of the dot product means the two are perpendicular. In index notation, we have \\[\n\\mathbf{v} \\cdot (\\mathbf{v} \\times \\mathbf{w}) = \\varepsilon_{ijk} v_j w_k (\\mathbf{v} \\cdot \\mathbf{e}_i) = v_i \\varepsilon_{ijk} v_j w_k = -v_i \\varepsilon_{jik} v_j w_k = -v_j \\varepsilon_{ijk} v_i w_k \\ .\n\\] Notice we have \\(\\varepsilon_{ijk} x_i x_j y_k = -\\varepsilon_{ijk} x_i x_j y_k\\), which can only be true of both are zero, as we wanted to show.\nAnother surprisingly useful identity of the Levi-Civita symbol is gotten by contracting their product to get \\[\n\\boxed{\n\\varepsilon_{ijk} \\varepsilon_{k\\ell m} = \\delta_{i\\ell} \\delta_{jm} - \\delta_{im} \\delta_{j\\ell}\n} \\ .\n\\]\n\nExample: BAC-CAB rule\nAs an application of this identity, we’ll use it to prove the well-known BAC-CAB rule for triple products, \\[\n\\mathbf{a} \\times (\\mathbf{b} \\times \\mathbf{c}) = \\mathbf{b} (\\mathbf{a} \\cdot \\mathbf{c}) - \\mathbf{c} (\\mathbf{a} \\cdot \\mathbf{b}) \\ .\n\\] Let \\(\\mathbf{d} = \\mathbf{a} \\times (\\mathbf{b} \\times \\mathbf{c})\\) for convenience. Writing this out in index notation and applying the previous identity, we have \\[\n\\begin{align*}\nd_i &= [\\mathbf{a} \\times (\\mathbf{b} \\times \\mathbf{c})]_i \\\\\n&= \\varepsilon_{ijk} a_j (\\mathbf{b} \\times \\mathbf{c})_k \\\\\n&= \\varepsilon_{ijk} \\varepsilon_{k\\ell m} a_j b_\\ell c_m \\\\\n&= (\\delta_{i\\ell} \\delta_{jm} - \\delta_{im} \\delta_{j\\ell}) a_j b_\\ell c_m \\\\\n&= \\delta_{i\\ell} \\delta_{jm} a_j b_\\ell c_m - \\delta_{im} \\delta_{j\\ell} a_j b_\\ell c_m \\\\\n&= a_j b_i c_j - a_j b_j c_i \\\\\n&= (\\mathbf{a} \\cdot \\mathbf{c}) b_i - (\\mathbf{a} \\cdot \\mathbf{b}) c_i \\ .\n\\end{align*}\n\\] Written back out in vector notation this gives exactly what we wanted to show.\n\nThe last curious fact of the Levi-Civita symbol that we’ll mention but not really use is that we can use it to write out the determinant of a \\(3 \\times 3\\) matrix. If a matrix \\(\\mathbf{A}\\) has column vectors \\(\\mathbf{a}, \\mathbf{b}, \\mathbf{c}\\), then we have \\[\n\\det \\mathbf{A} = \\varepsilon_{ijk} a_i b_j c_k \\ .\n\\] While cute, this formula only works in 3 dimensions. In other dimensions we’d have to use generalizations of the Levi-Civita symbol to get a formula like this, and even then they’re not actually useful for calculating the determinant.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Preliminaries</span>"
    ]
  },
  {
    "objectID": "electrodynamics/preliminaries.html#vector-calculus",
    "href": "electrodynamics/preliminaries.html#vector-calculus",
    "title": "Preliminaries",
    "section": "Vector Calculus",
    "text": "Vector Calculus\nCalculus extends naturally to higher dimensions, but often in subtle ways. Most importantly, there are different types of derivatives and integrals defined in higher dimensions with different meaning and applications. Due to complications involved in using curvilinear coordinates in vector calculus we’ll state results in Cartesian coordinates and address the others later.\n\nDifferential Vector Calculus\nThe fundamental object of vector calculus is the differential of a field. This says how much the field changes if its inputs are nudged in some direction by an infinitesimal amount. In Cartesian coordinates, it turns out the differential of a scalar field \\(f(\\mathbf{x})\\) is nothing more than a sum of partial differentials along each coordinate. That is, \\[\ndf = \\frac{\\partial f}{\\partial x} dx + \\frac{\\partial f}{\\partial y} dy + \\frac{\\partial f}{\\partial z} dz \\ .\n\\] The right-hand side looks like a sort of dot product between the partial derivatives of \\(f\\) and a differential displacement vector \\(d\\mathbf{x}\\), or vector line element, defined in Cartesian coordinates by \\[\nd\\mathbf{x} \\equiv dx \\mathbf{e}_x + dy \\mathbf{e}_y + dz \\mathbf{e}_z \\ .\n\\] It’s the vector generalization of the differential \\(dx\\) from ordinary calculus. The vector of partial derivatives can be written in a useful way by defining the del operator \\(\\nabla\\) by \\[\n\\nabla \\equiv \\partial_i \\mathbf{e}_i \\equiv \\frac{\\partial}{\\partial x} \\mathbf{e}_x + \\frac{\\partial}{\\partial y} \\mathbf{e}_y + \\frac{\\partial}{\\partial z} \\mathbf{e}_z \\ .\n\\] Here we introduce the convenient shorthand \\(\\partial_i \\equiv \\frac{\\partial}{\\partial x_i}\\) for the partial derivative with respect to component \\(x_i\\). Using the del operator we can define the vector of partial derivatives of a scalar field \\(f\\) by \\[\n\\nabla f \\equiv \\partial_i f \\ \\mathbf{e}_i \\equiv \\frac{\\partial f}{\\partial x} \\mathbf{e}_x + \\frac{\\partial f}{\\partial y} \\mathbf{e}_y + \\frac{\\partial f}{\\partial z} \\mathbf{e}_z \\ .\n\\] This quantity is evidently some kind of vector derivative, called the gradient of the field \\(f\\). Since \\(f\\) is a scalar field, \\(\\nabla f\\) will be a vector field. Its components are the partial derivatives of \\(f\\) in the \\(x_i\\) direction at each \\(\\mathbf{x}\\). The gradient always points perpendicular to the level curves where \\(f=\\text{const}\\). To see why this is the case, we can use the geometric formula for the dot product to express any change in the function along a level curve as \\[\n\\delta f = \\nabla f \\cdot \\delta \\mathbf{x} = |\\nabla f| |\\delta \\mathbf{x}| \\cos\\theta \\ .\n\\] Since \\(\\delta f = 0\\) along the level curve by definition, it must be the case that \\(\\theta = \\pm 90^\\circ\\) along such curves, meaning that the gradient must always be orthogonal to the level curve.\nUsing the gradient, we can finally express the differential \\(df\\) as a dot product of the gradient with the vector line element, \\[\ndf = \\nabla f \\cdot d\\mathbf{x} \\ .\n\\] Unlike in ordinary calculus, however, in vector calculus this isn’t the only kind of derivative we can take. We can see this by looking at the definition of \\(\\nabla\\). We can think of \\(\\nabla f\\) as multiplying a vector by a scalar. But we also know that we can take both the dot product and the cross product of two vectors, which along with \\(\\nabla\\) suggests there are two more derivative operations we can perform on vector fields.\nIf \\(\\mathbf{F}(\\mathbf{x})\\) is a vector field, we can take its dot product of \\(\\nabla\\) with \\(\\mathbf{F}\\) to get a new scalar field known as the divergence, which is evidently defined in Cartesian coordinates by \\[\n\\nabla \\cdot \\mathbf{F} \\equiv \\partial_i F_i \\equiv \\frac{\\partial f}{\\partial x} + \\frac{\\partial f}{\\partial y} + \\frac{\\partial f}{\\partial z} \\ .\n\\] Though not obvious from the definition, the divergence represents the tendency of a vector to flow into or out of a point. A field where \\(\\nabla \\cdot \\mathbf{F} = 0\\) for all points in space has no divergence at all, meaning there are no sources or sinks in the field anywhere. Due to the fact that the magnetic field is the canonical example of a divergence-less vector field, such fields are often called solenoidal.\nWe can also take the cross product of \\(\\nabla\\) with \\(\\mathbf{F}(\\mathbf{x})\\) to get a vector field known as the curl, defined in Cartesian coordinates by \\[\n\\nabla \\times \\mathbf{F} \\equiv \\varepsilon_{ijk} \\partial_i F_j \\mathbf{e}_k \\ .\n\\]\nThough again not obvious from the definition, the curl represents the tendency of a vector to rotate around a point in space. A field where \\(\\nabla \\times \\mathbf{F} = \\mathbf{0}\\) at all points in space is called irrotational since it doesn’t experience any rotational motion at any point. It just flows inward or outward.\nWe can also take vector second derivatives as well. The most useful of these is obtained by taking the divergence of the gradient of a scalar field. This is called the Laplacian, defined in Cartesian coordinates by \\[\n\\nabla^2 f \\equiv \\nabla \\cdot \\nabla f = \\partial_i \\partial_i f = \\frac{\\partial^2 f}{\\partial x^2} + \\frac{\\partial^2 f}{\\partial y^2} + \\frac{\\partial^2 f}{\\partial z^2} \\ .\n\\] The Laplacian has the useful property of being rotationally invariant. That is, if \\(\\nabla\\) represents the del operator in some coordinate system \\(\\mathcal{S}\\) and \\(\\nabla'\\) the same operator in some rotated coordinate system \\(\\mathcal{S}'\\), then \\((\\nabla')^2 = \\nabla^2\\). This follows from the fact that the Laplacian applied to any function gives a scalar, and scalars are by definition invariant under coordinate transformations.\nThere are a few other vector second derivatives as well, some of which turn out to be zero. These are \\[\n\\begin{align*}\n\\nabla \\cdot (\\nabla \\times \\mathbf{F}) &= 0 \\ , \\\\\n\\nabla \\times \\nabla f &= \\mathbf{0} \\ , \\\\\n\\nabla \\times (\\nabla \\times \\mathbf{F}) &= \\nabla (\\nabla \\cdot \\mathbf{F}) - \\nabla^2 \\mathbf{F} \\ .\n\\end{align*}\n\\] The Laplacian in the last expression is understood to be taken component-wise, as a vector with components \\(\\nabla^2 F_i\\). Each of these identities can all be efficiently proven using index notation.\n\n\nIntegral Vector Calculus\nThe gradient, divergence, and curl each has its own corresponding version of the fundamental theorem of calculus. To understand integration in higher dimensions though we first need to define what the differentials are. To integrate over a spatial volume we use the volume element \\(d^3 \\mathbf{x}\\), defined in Cartesian components by \\[\nd^3 \\mathbf{x} \\equiv dx dy dz \\ .\n\\] An important fact about the volume element is that its expression in a given coordinate system depends on the Jacobian. If \\(\\mathbf{u}(\\mathbf{x})\\) is some coordinate transformation with Jacobian \\(\\mathbf{J} \\equiv \\frac{d\\mathbf{u}}{d\\mathbf{x}}\\), then their volume elements are related by \\[\nd^3 \\mathbf{x} = du_1 du_2 du_3 = |\\det \\mathbf{J}| dx_1 dx_2 dx_3 \\ .\n\\] To find the volume integral of a scalar field \\(f\\) over a region of space \\(\\mathcal{V}\\), we can integrate each coordinate iteratively, \\[\n\\int_\\mathcal{V} d^3 \\mathbf{x} \\ f(\\mathbf{x}) = \\iiint_\\mathcal{V} dx dy dz \\ f(x,y,z) \\ .\n\\] We can integrate a vector field over a volume too. In this case the integral is done component-wise, so little new is added.\nSometimes we’ll also need to integrate a field over a surface in space as well. Suppose we wish to integrate over some smooth, orientable surface \\(\\mathcal{S}\\) in space. We can define an area element \\(d\\mathbf{a}\\) on this surface by considering an infinitesimal patch of area \\(da\\) on the surface and attaching an outward unit normal \\(\\mathbf{n}\\) to it to get \\[\nd\\mathbf{a} \\equiv \\mathbf{n} \\ da \\ .\n\\] It’s fair to ask how \\(da\\) itself is determined. When the surface is the \\(xy\\)-plane it’s clear \\(da = dxdy\\). But for more general surfaces we’d need to parametrize \\(\\mathcal{S}\\) with two relative coordinates and express \\(da\\) in terms of those. Evidently the area element \\(d\\mathbf{a}\\) is a kind of vector. We can thus also think of it as the cross product of two infinitesimal vectors on the surface. Importantly, this means \\(d\\mathbf{a}\\) will have both a magnitude and a direction that depend on where we are along the surface. When we require the surface be orientable, we mean that we can always use the right-hand rule to find the direction of \\(\\mathbf{n}\\).\n\n\n\n\n\nTo get the surface integral of a vector field \\(\\mathbf{F}\\) along the surface \\(\\mathcal{S}\\) we’d typically write \\[\n\\int_\\mathcal{S} \\mathbf{F} \\cdot d\\mathbf{a} = \\int_\\mathcal{S} \\mathbf{F} \\cdot \\mathbf{n} \\ da \\ .\n\\] The last form of vector integration we’ll find ourselves using frequently is contour integration, which is the integration of a field along some arbitrary curve in space. We can integrate a vector field \\(\\mathbf{F}\\) along some path or contour \\(\\mathcal{C}\\) in space by defining a line element \\(d\\boldsymbol{\\ell}\\) along the contour, defined in Cartesian coordinates by \\[\nd\\boldsymbol{\\ell} \\equiv d\\mathbf{x} = dx \\mathbf{e}_x + dy \\mathbf{e}_y + dy \\mathbf{e}_y \\ .\n\\] The contour integral is just an infinitesimal sum of the projection of the field along the contour, i.e. \\[\n\\int_\\mathcal{C} \\mathbf{F}(\\mathbf{x}) \\cdot d\\boldsymbol{\\ell} \\ .\n\\] The usual way to evaluate a contour integral is to parametrize the path with some real parameter \\(\\tau\\) from some starting point \\(\\tau=a\\) to some ending point \\(\\tau = b\\). Then we have \\[\n\\int_\\mathcal{C} \\mathbf{F}(\\mathbf{x}) \\cdot d\\boldsymbol{\\ell} \\equiv \\int_a^b d\\tau \\ \\mathbf{F}(\\mathbf{x}(\\tau)) \\cdot \\frac{d\\mathbf{x}}{d\\tau} \\ .\n\\] We can also integrate a scalar field \\(f\\) over the same contour by defining a similar contour integral of the form \\[\n\\int_\\mathcal{C} ds \\ f(\\mathbf{x}) =  \\int_a^b d\\tau \\ f(\\mathbf{x}(\\tau)) \\bigg |\\frac{d\\mathbf{x}}{d\\tau} \\bigg | \\ .\n\\] Here \\(ds\\) is the scalar line element defined in Cartesian coordinates by \\[\nds = |d\\boldsymbol{\\ell}| = \\sqrt{dx^2 + dy^2 + dy^2} \\ .\n\\] Integrating over \\(ds\\) alone gives the arc length of the contour. Interestingly the scalar line element is very important in studying the geometry of a space. In general it depends on the metric \\(\\mathbf{g}\\) by \\[\nds^2 = dx_i g_{ij} dx_j \\ .\n\\] For Euclidean space the metric is always the identity, so we just have \\(ds^2 = dx_i dx_i\\). This is all we’ll need for most of this course, but in relativity (especially general relativity) this line element becomes fundamental.\nUsually a path integral between two endpoints will depend on the exact path of the contour \\(\\mathcal{C}\\). For some special fields though the path integral depends only on the endpoints, not on the path between them. When this is true we say the field is conservative. An implication of this is that if we integrate a conservative field around any closed contour where the path integral vanishes, \\[\n\\oint \\mathbf{F} \\cdot d\\mathbf{x} = 0 \\ .\n\\] It’s easy to see why this must be true. For any closed contour we can break it into two pieces. The line integral of each piece must be path independent, which means their sum, and hence the closed path integral, must vanish for conservative fields.\nIn vector calculus, each version of vector derivative has its own fundamental theorem of calculus that relates it to one or more of the integrals defined above. The fundamental theorem for gradients says the line integral of the gradient of a scalar field depends only on the endpoints, \\[\n\\int_{\\mathbf{x}_1}^{\\mathbf{x}_2} \\nabla f(\\mathbf{x}) \\cdot d\\mathbf{x} = f(\\mathbf{x}_2) - f(\\mathbf{x}_1) \\ .\n\\] This means that the gradient of a scalar field is always conservative. In fact, it turns out any conservative vector field \\(\\mathbf{F}(\\mathbf{x})\\) can be written as the gradient of some scalar field \\(\\phi(\\mathbf{x})\\), \\[\n\\mathbf{F} = -\\nabla \\phi \\ .\n\\] This fact we use extensively in electromagnetism. The minus sign is merely a physics convention. Since the curl of a gradient must vanish, this statement also says \\(\\mathbf{F}\\) must be irrotational, i.e. \\(\\nabla \\times \\mathbf{F} = \\mathbf{0}\\).\nA more general extension of this special case is called the Helmholtz theorem. It says any smooth vector field \\(\\mathbf{F}(\\mathbf{x})\\), conservative or not, can be expressed as the gradient of some scalar field \\(\\phi(\\mathbf{x})\\) plus the curl of some other vector field \\(\\mathbf{A}(\\mathbf{x})\\), i.e. \\[\n\\mathbf{F} = -\\nabla \\phi + \\nabla \\times \\mathbf{A} \\ .\n\\] Though not obvious, this formula in fact can be inverted to find formulas for \\(\\phi\\) and \\(\\mathbf{A}\\) in terms of derivatives of \\(\\mathbf{F}\\), \\[\n\\begin{align*}\n\\phi(\\mathbf{x}) &= \\frac{1}{4\\pi} \\int_{\\mathbb{R}^3} d^3 \\mathbf{x}' \\ \\frac{\\nabla' \\cdot \\mathbf{F}(\\mathbf{x}')}{|\\mathbf{x} - \\mathbf{x}'|} \\ , \\\\\n\\mathbf{A}(\\mathbf{x}) &= \\frac{1}{4\\pi} \\int_{\\mathbb{R}^3} d^3 \\mathbf{x}' \\ \\frac{\\nabla' \\times \\mathbf{F}(\\mathbf{x}')}{|\\mathbf{x} - \\mathbf{x}'|} \\ .\n\\end{align*}\n\\] Here it’s implicitly assumed that \\(\\mathbf{F}\\) vanishes faster than \\(\\frac{1}{r}\\) at infinity. If not we have to include extra boundary terms. The symbol \\(\\nabla'\\) means to differentiate with respect to the integration variable \\(\\mathbf{x}'\\).\nThe fundamental theorem for divergences is called the divergence theorem. It says that the divergence of a vector field is nothing more than the flow or flux of the field through the surface of a closed volume, \\[\n\\int_\\mathcal{V} \\nabla \\cdot \\mathbf{F} \\ d^3\\mathbf{x} = \\int_S \\mathbf{F} \\cdot d\\mathbf{a} \\ .\n\\] The fundamental theorem for curls is called Stokes’ theorem. It says the curl of a vector field is nothing more than the circulation of the field around the boundary of any closed surface, \\[\n\\int_\\mathcal{S} (\\nabla \\times \\mathbf{F}) \\cdot \\ d\\mathbf{a} = \\int_C \\mathbf{F} \\cdot d\\mathbf{x} \\ .\n\\] It’s interesting to note that all of these versions of the fundamental theorem of calculus say essentially the same thing: The integral of the derivative of a field over some space equals the value of that field along the boundary of that space. For gradients, the boundary of a contour is just two endpoints. For divergences, the boundary over a volume is a closed surface. For curls, the boundary of a surface is a closed contour.\nWe can use the divergence theorem to derive two more important integral formulas that we’ll use, the Green’s Identities. What we’ll do is let \\(\\mathbf{F} = \\psi \\nabla \\phi\\), where \\(\\psi\\) and \\(\\phi\\) are two scalar fields that may or may not be different. We want to plug this into the divergence theorem, but first we need to figure out the product rule formula for \\(\\nabla \\cdot (\\psi \\nabla \\phi)\\). This can be done, for example, using index notation. It turns out that \\[\n\\nabla \\cdot (\\psi \\nabla \\phi) = \\nabla \\psi \\cdot \\nabla \\phi + \\psi \\nabla^2 \\phi \\ .\n\\] Plugging this into the divergence theorem formula, we then get Green’s First Identity, which says that \\[\n\\int_\\mathcal{V} d^3 \\mathbf{x} \\ (\\nabla \\psi \\cdot \\nabla \\phi + \\psi \\nabla^2 \\phi) = \\oint_\\mathcal{S} da \\ \\psi \\frac{\\partial \\phi}{\\partial n} \\ .\n\\] Here we’ve defined the normal derivative \\(\\frac{\\partial \\phi}{\\partial n} \\equiv \\nabla \\phi \\cdot \\mathbf{n}\\), which just says how much \\(\\phi\\) changes in the direction normal to the boundary surface \\(\\mathcal{S}\\). If we now swap \\(\\psi\\) and \\(\\phi\\) and difference the two formulas, we get another identity, called Green’s Second Identity, given by \\[\n\\int_\\mathcal{V} d^3 \\mathbf{x} \\ (\\phi \\nabla^2 \\psi - \\psi \\nabla^2 \\phi) = \\oint_\\mathcal{S} da \\ \\bigg[\\phi \\frac{\\partial \\psi}{\\partial n} - \\psi \\frac{\\partial \\phi}{\\partial n} \\bigg] \\ .\n\\] We’ll see frequent use of each of these integral formulas throughout the course.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Preliminaries</span>"
    ]
  },
  {
    "objectID": "electrodynamics/preliminaries.html#tensors",
    "href": "electrodynamics/preliminaries.html#tensors",
    "title": "Preliminaries",
    "section": "Tensors",
    "text": "Tensors\nThus far we’ve seen objects with no indices and objects with one index that transform in a specified way under coordinate transformations. It’s fair to ask whether we can define matrices that transform in a specific way as well, and in fact we can. These two-index objects are called rank-2 tensors. They’re matrices \\(\\mathbf{T}\\) that obey the transformation law \\[\n\\mathbf{T}(\\mathbf{x}') = \\mathbf{J}^\\top \\mathbf{T}(\\mathbf{x}') \\mathbf{J} \\ .\n\\] This is just a direct generalization of the vector transformation law. It’s easier to see this in index notation. Vectors obey the transformation law \\(v_i' = J_{ij} v_j\\), while rank-2 tensors obey the transformation law \\[\nT_{ij}' =  J_{ik} J_{j\\ell} T_{k\\ell} \\ .\n\\] Roughly speaking, this just says each dimension of the tensor transforms itself as a vector would.\nWhile tensors didn’t show up transparently in elementary physics courses, they show up a lot in more advanced physics. A lot of physical quantities are tensors: the metric tensor, the moment of inertia tensor, the strain tensor, and so on. Another example is the cross product. The cross product seems like a vector, but it’s really not. In fact, we can define the cross product in a slightly different way using a rank-2 tensor as \\[\n\\varepsilon_{ijk} (\\mathbf{v} \\times \\mathbf{w})_k = v_i w_j - v_j w_i\n\\] In this variant definition the cross product is no longer a vector, but a rank-2 tensor whose upper diagonal components are the usual components of the cross product in 3 dimensions. Represented as a matrix \\(\\mathbf{A}\\), it looks like \\[\nA_{ij} \\equiv \\varepsilon_{ijk} (\\mathbf{v} \\times \\mathbf{w})_k \\doteq\n\\begin{pmatrix}\n0 & v_1 w_2 - v_2 w_1 & v_1 w_3 - v_3 w_1  \\\\\nv_2 w_1 - v_1 w_2 & 0 & v_2 w_3 - v_3 w_2 \\\\\nv_3 w_1 - v_1 w_3 &  & 0 \\\\\n\\end{pmatrix}\n\\ .\n\\] Here \\(\\mathbf{A}\\) is a rank-2 tensor that evidently satisfies the antisymmetric property \\(A_{ij} = -A_{ji}\\). Unlike with the regular cross product, this generalization of the cross product can be defined for any number of dimensions. To see why we can’t extend the usual cross product this way, notice that the components \\(\\mathbf{v} \\times \\mathbf{w}\\) lie in the upper diagonal of \\(\\mathbf{A}\\). The diagonals are always zero, and the lower diagonal is just minus the upper diagonal, meaning there are only 3 independent components. For a general antisymmetric tensor in \\(d\\) dimensions there will be \\(\\frac{1}{2}d(d-1)\\) such independent components in the upper diagonal. Insisteng that such a tensor be a vector is equivalent to requiring \\(d=\\frac{1}{2}d(d-1)\\), which evidently can only be true when \\(d=3\\). Thus, the cross product can only be a vector in 3 dimensions.\nOne useful operation that we can do with tensors is contraction. Contraction is the tensor generalization of the inner product, obtained by setting two indices in a tensor equal and summing over them. Since rank-2 tensors only have 2 indices, contracting a rank-2 tensor will always give a scalar, which is of course just trace of \\(\\mathbf{T}\\), i.e. \\(T_{ii} = \\text{tr} \\ \\mathbf{T}\\). Just as the dot product of a vector with itself says something about its size (in fact it’s just its squared norm), the trace of a rank-2 tensor says something about its size. Since the trace has no free indices, it must be a rank-0 object, hence a proper scalar like the dot product.\nAnother operation we can do with tensors is take their tensor product. A tensor product is no more than component-wise concatenation. For example, if \\(\\mathbf{x}\\) and \\(\\mathbf{y}\\) are two vectors, we can define their tensor product in index notation by \\[\nT_{ij} \\equiv x_i x_j \\ .\n\\] Evidently the tensor product of two vectors gives a rank-2 tensor. In fact, it’s just the outer product of the two vectors. In this sense the tensor product is a generalization of the outer product, just as contraction is the generalization of the inner product. In more abstract notation we’d write the tensor product as \\[\n\\mathbf{T} = \\mathbf{x} \\otimes \\mathbf{y} \\equiv \\mathbf{x} \\mathbf{y} \\ .\n\\] The last expression \\(\\mathbf{x} \\mathbf{y}\\) for the tensor product is called dyadic notation, where we omit the \\(\\otimes\\) symbol for brevity. It’s tempting to think that all rank-2 tensors can be formed from a tensor product of vectors, but this is false. Only special vectors can, called product tensors. Most rank-2 tensors are mixed tensors, meaning superpositions of vector outer products.\nUsing the tensor product we can define the notion of a basis tensor for a rank-2 tensor as \\[\n\\mathbf{e}_{ij} \\equiv \\mathbf{e}_i \\mathbf{e}_j \\equiv \\mathbf{e}_i \\otimes \\mathbf{e}_j \\ .\n\\] Since this is just the outer products of the two basis vectors, they are 1 when at slot \\((i,j)\\) and 0 otherwise. Using superposition just as we do for vectors, we can use these basis tensors to expand any rank-2 tensor as \\[\n\\mathbf{T} = T_{ij} \\mathbf{e}_i \\mathbf{e}_j \\ .\n\\] We can also take the tensor product of a rank-2 tensor with a vector, which would give a three-index object, or a rank-3 tensor. Taking the tensor product of two rank-2 tensors would give a rank-4 tensor. And so on. In fact we can define a tensor of any rank. A rank-k tensor is an object with \\(k\\) indices that tranforms component-wise according to the law \\[\nT_{i_1' i_2' \\cdots i_k'} = J_{i_1' i_1} J_{i_2' i_2} \\cdots J_{i_2' i_2} T_{i_1 i_2 \\cdots i_k} \\ .\n\\] In this course we won’t generally work much with tensors of higher rank than 2, but they do occasionally show up in electromagnetism, for example in the multipole expansions of the scalar and vector potentials. Tensor contraction can be defined naturally on these higher-rank tensors as well. Contracting two indices in a tensor will always reduce its rank by 2.\nWe can define similar vector calculus operations for tensors as well, not just vectors. For example, if we have a rank-2 tensor \\(\\mathbf{T}\\) we can still imagine taking gradients \\(\\partial_k T_{ij}\\) to get a rank-3 tensor. By contracting the derivative with the tensor we get a different divergence for each index, \\(\\partial_i T_{ij}\\) and \\(\\partial_j T_{ij}\\). Evidently the divergence of a rank-2 tensor gives a vector, not a scalar.\nStrictly speaking we can’t speak of the divergence of a tensor since each index has its own divergence. We can though when the tensor is symmetric. If \\(T_{ij} = T_{ji}\\) we can define a unique divergence operation by \\[\n\\nabla \\cdot \\mathbf{T} \\equiv \\partial_i T_{ij} = \\partial_j T_{ij} \\ .\n\\]\nWe could imagine taking the curl of a tensor as well. From index notation it’s clear that the curl of a rank-2 tensor will give another rank-2 tensor. We can even imagine defining tensor integrals as well in similar ways. In practice though we’ll only care about divergences and gradients of rank-2 tensors in this course, so we won’t go into any detail here.\n\nRewrite this section. It turns out higher-rank tensors do show up in this course, a lot in the multipole expansion especially.\nNeed to define symmetric and antisymmetric tensors for tensors of higher rank.\nNeed to talk about irreducible tensors, i.e. symmetric traceless tensors, and their decomposition in terms of irreducible components. This is essential to deriving the multipole expansion.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Preliminaries</span>"
    ]
  },
  {
    "objectID": "electrodynamics/preliminaries.html#coordinate-systems",
    "href": "electrodynamics/preliminaries.html#coordinate-systems",
    "title": "Preliminaries",
    "section": "Coordinate Systems",
    "text": "Coordinate Systems\nIt will be frequently useful in electrodynamics to work in other coordinate systems. As with other areas of physics, the most important coordinate systems we work with are Cartesian, polar, cylindrical, and spherical coordinates. Cartesian coordinates are rectangular, which means their basis vectors don’t depend on position. They’re always constant. The remaining three coordinate systems, however, are curvilinear, meaning their basis vectors do depend on position. This means going back and forth between these coordinate systems can be cumbersome since additional scale factors get introduced. Below is a table that shows the relationship between these coordinate systems for various vector calculus expressions we’ll frequently use.\n\n\n\n\n\n\n\n\n\n\nCartesian \\((x,y,z)\\)\nCylindrical \\((\\varrho,\\varphi,z)\\)\nSpherical \\((r,\\theta,\\varphi)\\)\n\n\n\n\nCoordinates\n\\(\\begin{align*} x&=x \\\\ y&=y \\\\ z&=z \\end{align*}\\)\n\\(\\begin{align*} x&=\\varrho\\cos\\varphi \\\\ y&=\\varrho\\sin\\varphi \\\\ z&=z \\end{align*}\\)\n\\(\\begin{align*} x&=r\\sin\\theta\\cos\\varphi \\\\ y&=r\\sin\\theta\\sin\\varphi \\\\ z&=r\\cos\\theta \\end{align*}\\)\n\n\nBasis Vectors\n\\(\\begin{align*} \\mathbf{e}_x&=\\mathbf{e}_x \\\\ \\mathbf{e}_y&=\\mathbf{e}_y \\\\ \\mathbf{e}_z&=\\mathbf{e}_z \\end{align*}\\)\n\\(\\begin{align*} \\mathbf{e}_\\varrho &= \\cos\\varphi \\mathbf{e}_x + \\sin\\varphi \\mathbf{e}_y \\\\ \\mathbf{e}_\\varphi &= -\\sin \\varphi \\mathbf{e}_x + \\cos \\varphi \\mathbf{e}_y \\\\ \\mathbf{e}_z&=\\mathbf{e}_z \\end{align*}\\)\n\\(\\begin{align*} \\mathbf{e}_r &= \\sin\\theta \\cos\\varphi \\mathbf{e}_x + \\sin\\theta \\sin\\varphi \\mathbf{e}_y + \\cos\\theta \\mathbf{e}_z \\\\ \\mathbf{e}_\\theta &= \\cos\\theta \\cos\\varphi \\mathbf{e}_x + \\cos\\theta \\sin\\varphi \\mathbf{e}_y - \\sin\\theta \\mathbf{e}_z  \\\\ \\mathbf{e}_\\varphi &= -\\sin\\varphi \\mathbf{e}_x + \\cos\\varphi \\mathbf{e}_y  \\end{align*}\\)\n\n\nDifferential\n\\(d\\mathbf{x} = dx \\mathbf{e}_x + dy \\mathbf{e}_y + dz \\mathbf{e}_z\\)\n\\(d\\mathbf{x} = d\\varrho \\mathbf{e}_\\varrho + \\varrho d\\varphi \\mathbf{e}_\\varphi + dz \\mathbf{e}_z\\)\n\\(d\\mathbf{x} = dr \\mathbf{e}_r + r d\\theta \\mathbf{e}_\\theta + r \\sin \\theta d\\varphi \\mathbf{e}_\\varphi\\)\n\n\nLine Element\n\\(ds^2=dx^2 + dy^2 + dz^2\\)\n\\(ds^2=d\\varrho^2 + \\varrho^2 d\\varphi^2 + dz^2\\)\n\\(ds^2=dr^2 + r^2 d\\theta^2 + r^2 \\sin^2 \\theta d\\varphi^2\\)\n\n\nVolume Element\n\\(d^3 \\mathbf{x} = dx dy dz\\)\n\\(d^3 \\mathbf{x} = \\varrho d\\varrho d\\varphi dz\\)\n\\(d^3 \\mathbf{x} = r^2 \\sin \\theta dr d\\theta d\\varphi\\)\n\n\nGradient\n\\(\\nabla f = \\partial_x f \\mathbf{e}_x + \\partial_y f \\mathbf{e}_y + \\partial_z f \\mathbf{e}_z\\)\n\\(\\nabla f = \\partial_\\varrho f \\mathbf{e}_\\varrho + \\frac{1}{\\varrho} \\partial_\\varphi \\mathbf{e}_\\varphi + \\partial_z f \\mathbf{e}_z\\)\n\\(\\nabla f = \\partial_r f \\mathbf{e}_r + \\frac{1}{r} \\partial_\\theta f \\mathbf{e}_\\theta + \\frac{1}{r \\sin \\theta} \\partial_\\varphi f \\mathbf{e}_\\varphi\\)\n\n\nDivergence\n\\(\\nabla \\cdot \\mathbf{F} = \\partial_x F_x + \\partial_y F_y + \\partial_z F_z\\)\n\\(\\nabla \\cdot \\mathbf{F} = \\frac{1}{\\varrho} \\partial_\\varrho(\\varrho F_\\varrho) + \\frac{1}{\\varrho} \\partial_\\varphi F_\\varphi + \\partial_z F_z\\)\n\\(\\nabla \\cdot \\mathbf{F} = \\frac{1}{r^2} \\partial_r (r^2 F_r) + \\frac{1}{r \\sin \\theta} \\partial_\\theta (F_\\theta \\sin \\theta) + \\frac{1}{r \\sin \\theta} \\partial_\\varphi F_\\varphi\\)\n\n\nCurl\n\\(\\begin{align*}\\nabla \\times \\mathbf{F} &= \\left( \\partial_y F_z - \\partial_z F_y \\right) \\mathbf{e}_x \\\\ &+ \\left( \\partial_z F_x - \\partial_x F_z \\right) \\mathbf{e}_y \\\\ &+ \\left( \\partial_x F_y - \\partial_y F_x \\right) \\mathbf{e}_z \\end{align*}\\)\n\\(\\begin{align*} \\nabla \\times \\mathbf{F} &= \\left( \\frac{1}{\\varrho} \\partial_\\varphi F_z - \\partial_z F_\\varphi \\right) \\mathbf{e}_\\varrho \\\\ &+ \\left( \\partial_z F_\\varrho - \\partial_\\varrho F_z \\right) \\mathbf{e}_\\varphi \\\\ &+ \\frac{1}{\\varrho} \\left( \\partial_\\varrho (\\varrho F_\\varphi) - \\partial_\\varphi F_\\varrho \\right) \\mathbf{e}_z \\end{align*}\\)\n\\(\\begin{align*} \\nabla \\times \\mathbf{F} &= \\frac{1}{r \\sin \\theta} \\left( \\partial_\\theta (F_\\varphi \\sin \\theta) - \\partial_\\varphi F_\\theta \\right) \\mathbf{e}_r \\\\ &+ \\frac{1}{r} \\left( \\frac{1}{\\sin \\theta} \\partial_\\varphi F_r - \\partial_r (r F_\\varphi) \\right) \\mathbf{e}_\\theta \\\\ &+ \\frac{1}{r} \\left( \\partial_r (r F_\\theta) - \\partial_\\theta F_r \\right) \\mathbf{e}_\\varphi \\end{align*}\\)\n\n\nLaplacian\n\\(\\nabla^2 f = \\partial_x^2 f + \\partial_y^2 f + \\partial_z^2 f\\)\n\\(\\nabla^2 f = \\frac{1}{\\varrho} \\partial_\\varrho \\left(\\varrho \\partial_\\varrho f \\right) + \\frac{1}{\\varrho^2} \\partial_\\varphi^2 f + \\partial_z^2 f\\)\n\\(\\nabla^2 f = \\frac{1}{r^2} \\partial_r^2 \\left( r^2 \\partial_r f \\right) + \\frac{1}{r^2 \\sin \\theta} \\partial_\\theta \\left( \\sin \\theta \\partial_\\theta f \\right) + \\frac{1}{r^2 \\sin^2 \\theta} \\partial_\\varphi^2 f\\)\n\n\n\nNote the formulas for these expressions in the the two-dimensional polar coordinate system \\((\\varrho,\\varphi)\\) can be obtained by taking the formulas for cylindrical coordinates and setting all the \\(z\\)-components equal to zero.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Preliminaries</span>"
    ]
  },
  {
    "objectID": "electrodynamics/preliminaries.html#complex-variables",
    "href": "electrodynamics/preliminaries.html#complex-variables",
    "title": "Preliminaries",
    "section": "Complex Variables",
    "text": "Complex Variables\nIn electromagnetism we’ll often find ourselves dealing with not only real variables and real-valued functions, but complex variables and complex-valued functions. Here we’ll briefly touch on the basics of complex variables and functions.\nA complex variable is any variable \\(z\\) of the form \\[\nz = x + iy \\ ,\n\\] where \\(x\\) and \\(y\\) are real numbers and \\(i \\equiv \\sqrt{-1}\\) is the imaginary number. We call \\(x \\equiv \\text{Re} \\ z\\) the real part of \\(z\\) and \\(y \\equiv \\text{Im} \\ z\\) the imaginary part of \\(z\\). Geometrically, we can imagine any complex variable \\(z\\) as a representing a point in a 2-dimensional complex plane, usually denoted by the symbol \\(\\mathbb{C}\\). The \\(x\\)-axis represents the real part of \\(z\\) and the \\(y\\)-axis the imaginary part of \\(z\\).\nEvery complex variable has a dual variable \\(z^*\\) called the complex conjugate, defined by \\[\nz^* \\equiv x - iy \\ .\n\\] By adding and subtracting \\(z\\) and \\(z^*\\) together, we also get the following relations for the real and imaginary parts of \\(z\\), \\[\nx = \\text{Re} \\ z = \\frac{z + z^*}{2} \\quad , \\quad y = \\text{Im} \\ z = \\frac{z - z^*}{2i} \\ .\n\\] Geometrically, the complex conjugate is obtained by flipping \\(z\\) across the real axis in the complex plane. When we say that \\(z^*\\) is dual to \\(z\\), we mean that their product will always be a non-negative real number, with \\(zz^* = x^2 + y^2\\). In the complex plane, this number represents the squared radial distance of \\(z\\) from the origin. We can thus define a modulus or length by \\[\n|z| \\equiv \\sqrt{zz^*} = \\sqrt{x^2 + y^2} \\ .\n\\] Just as we can have real-valued functions of a real variable, we can have complex-valued functions of a real variable, and even complex functions of a complex variable. We’ll talk about these functions more generally in the appendix.\nFor now we only mention the most important complex-valued function in this course, and indeed in all of science, the complex exponential. For a real variable \\(x\\), we define the complex exponential function by \\(f(x) = e^{i x}\\). As written this function seems mysterious and perhaps not that important, but as we’ll see it’s very important.\nObserve that since \\(i^2 = -1\\), then \\(i^3 = -i\\), \\(i^4 = 1\\), etc. In general, \\(i^n = \\pm 1\\) if \\(n\\) is even and \\(i^n = \\pm i\\) if \\(n\\) is odd. This means if we expand the complex exponential as a Taylor series and rearrange terms, we have \\[\n\\begin{align*}\ne^{ix} &= 1 + ix + \\frac{i^2}{2!} x^2 + \\frac{i^3}{3!} x^3 + \\frac{i^4}{4!} x^4 + \\frac{i^5}{5!} x^5 + \\cdots \\\\\n&= 1 + ix - \\frac{x^2}{2!} - \\frac{ix^3}{3!} + \\frac{x^4}{4!} + \\frac{ix^5}{5!} + \\cdots \\\\\n&= \\bigg(1 - \\frac{x^2}{2!} + \\frac{x^4}{4!} + \\cdots\\bigg) + i\\bigg(x - \\frac{x^3}{3!} + \\frac{x^5}{5!} + \\cdots\\bigg) \\\\\n&= \\cos x + i \\sin x \\ .\n\\end{align*}\n\\] In the last step, we recognized the fact that the even powers in the series expansion were just those for \\(\\cos x\\), and the odd terms were just those for \\(i \\sin x\\). This proves the well-known Euler identity, \\[\n\\boxed{\ne^{ix} = \\cos x + i \\sin x\n} \\ .\n\\] Notice that according to this formula, the modulus of \\(e^{ix}\\) is given by \\[\n|e^{ix}| = e^{ix} (e^{ix})^* = \\cos^2 x + \\sin^2 x  = 1 \\ .\n\\] This means that the complex exponential in effect behaves like a rotation in the complex plane. Indeed, the path traversed by \\(e^{ix}\\) as \\(x\\) increases traces a counterclockwise circle of radius one in the complex plane.\nIf we take any complex variable \\(z\\) and multiply it by \\(e^{i\\varphi}\\), then \\(z\\) rotates counter-clockwise by an angle \\(\\varphi\\) in the complex plane. An immediate consequence of this fact is that any complex variable can be represented by the polar formula \\[\nz = r e^{i\\varphi} \\ ,\n\\] where \\(r = |z|\\) represents the distance of \\(z\\) from the origin in the complex plane, while \\(\\varphi\\) represents its angle above the \\(x\\)-axis, called the argument or phase of \\(z\\), often denoted by \\(\\phi \\equiv \\text{Arg} \\ z\\).\nBy writing \\(z = x + iy\\), it’s not hard to see that the phase will depend on the quadrant \\(z\\) is in, with \\[\n\\varphi = \\text{Arg} \\ z = \\begin{cases}\n\\tan^{-1} \\frac{y}{x} & x &gt; 0 \\ , \\\\\n\\pi + \\tan^{-1} \\frac{y}{x} & x &lt; 0 \\ , y &gt; 0 \\ , \\\\\n-\\pi + \\tan^{-1} \\frac{y}{x} & x &lt; 0 \\ , y &lt; 0 \\ .\n\\end{cases}\n\\] One useful fact to remember about phases is that when two complex variables are multiplied together their phases add. To see why this is true, let \\(z_1 = r_1 e^{i \\phi_1}\\) and \\(z_2 = r_2 e^{i \\phi_2}\\). Then the product \\(z_1 z_2\\) can be written as \\[\nz_1 z_2 = r_1 r_2 e^{i (\\varphi_1 + \\varphi_2)} \\ .\n\\] From this, we can see that the modulus of the product is \\(|z_1 z_2| = r_1 r_2\\), and the phase of the product is \\[\n\\text{Arg} \\ z_1 z_2 = \\text{Arg} \\ z_1 + \\text{Arg} \\ z_2 \\ .\n\\] In a similar manner, it’s easy to see that when dividing two complex numbers their phases get subtracted, \\[\n\\text{Arg} \\ \\frac{z_1}{z_2} = \\text{Arg} \\ z_1 - \\text{Arg} \\ z_2 \\ .\n\\] Last, note that if we substitute \\(x=\\pi\\) into the complex exponential function and move everything to one side, we get \\[\ne^{i\\pi} + 1 = 0 \\ .\n\\] This curious identity has sometimes been called the most beautiful in mathematics, since it’s the only valid equation that includes only the fundamental numbers \\(0,1,\\pi,e\\) and \\(i\\), with each number occurring exactly once in the equation.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Preliminaries</span>"
    ]
  },
  {
    "objectID": "electrodynamics/preliminaries.html#delta-function",
    "href": "electrodynamics/preliminaries.html#delta-function",
    "title": "Preliminaries",
    "section": "Delta Function",
    "text": "Delta Function\nA very important mathematical object in electromagnetism and physics more generally is the Dirac delta function \\(\\delta(x-x')\\), defined by the property that for any real-valued function \\(f(x)\\), \\[\n\\boxed{\nf(x) = \\int_{-\\infty}^\\infty dx' \\ f(x') \\delta(x-x')\n} \\ .\n\\] Notice from this definition the delta function must have units to cancel out the units of \\(dx'\\). If \\(dx'\\) has units of length, for example, then evidently \\(\\delta(x-x')\\) must have units of inverse length.\nEvidently, the delta function acts as a sort of sifting function that picks out a point \\(x\\) from an integral and evaluates whatever function is inside the integral at that point. In particular, when \\(x=0\\) we have \\[\nf(0) = \\int_{-\\infty}^\\infty dx \\ f(x) \\delta(x) \\ .\n\\] By taking \\(f(x) = 1\\), we can see that the delta function satisfies \\[\n\\int_{-\\infty}^\\infty dx' \\ \\delta(x-x') = 1 \\ .\n\\] In fact, we don’t even need to integrate over the whole real line. All that’s required is that \\(x\\) is included in the interval. If we consider some small interval \\(x - \\varepsilon \\leq x \\leq x + \\varepsilon\\), we still have \\[\n1 = \\int_{x-\\varepsilon}^{x+\\varepsilon} dx' \\ \\delta(x-x') \\ .\n\\] By letting \\(\\varepsilon \\rightarrow 0\\), we can see that \\(\\delta(x-x') = 0\\) when \\(x' \\neq x\\), but still must integrate to one. This means we can informally think of the delta function as an infinite spike at the point \\(x' = x\\) that instantly dies off to zero away from the point \\(x\\). That is, we can think of the delta function as a sort of density for a single point.\nWe can use this infinite spike idea if we like to “define” a delta function as a limit of Gaussian functions of the form \\[\np(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-(x-x')^2 / 2\\sigma^2} \\ .\n\\] Recall that this function represents the probability density of a Gaussian random variable \\(x\\). In particular, this means this function also integrates to one, is peaked at \\(x' = x\\), and dies off to zero at a rate characterized by the parameter \\(\\sigma\\). The larger \\(\\sigma\\) is the more spread out the Gaussian will be, and vice versa. As we let \\(\\sigma \\to 0\\) the Gaussian becomes infinitely sharp at \\(x'=x\\) and dies off quickly to zero away from this point. This means we can also “define” the delta function as the limit of \\(p(x)\\) as \\(\\sigma \\to 0\\), \\[\n\\delta(x-x') = \\lim_{\\sigma \\rightarrow 0} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-(x-x')^2/2\\sigma^2} \\ .\n\\] We use the term “define” in quotations here because strictly speaking this limit isn’t well-defined at \\(x'=x\\), which means the delta function itself isn’t well-defined. Instead it’s a so-called generalized function or distribution, meaning it’s an object that has meaning only when integrated against some test function \\(f(x)\\). If we like we can formalize the above limit by \\[\n\\int_{-\\infty}^\\infty dx' f(x) \\delta(x-x') = \\lim_{\\sigma \\to \\infty} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\int_{-\\infty}^\\infty dx' f(x') e^{-(x-x')^2/2\\sigma^2} \\ .\n\\] From this formula, it’s clear that the delta function must be an even function, so \\(\\delta(-x) = \\delta(x)\\). In particular, this means that we can always swap \\(x\\) and \\(x'\\) using the relation \\(\\delta(x-x') = \\delta(x'-x)\\).\nAnother useful fact about the delta function relates to how it transforms under a rescaling of coordinates \\(u=ax\\). We have \\[\n\\delta(ax) = \\frac{1}{|a|} \\delta(x) \\ .\n\\] This can easily be proven by integrating against a test function \\(f(x)\\) and changing variables using \\(u=ax\\). The absolute value in the denominator follows from the fact that the delta function must be an even function. This property can be extended to delta functions of the form \\(\\delta(g(x))\\) as well. If \\(g(x)\\) has roots \\(a_n\\) with non-zero derivatives at each \\(a_n\\), we have \\[\n\\delta(g(x)) = \\sum_n \\frac{\\delta(x-a_n)}{\\big|\\frac{d}{dx} g(a_n)\\big|} \\ .\n\\] This can be proven by Taylor expanding \\(g(x)\\) around each root and using the scaling property above on each root.\nWe can define the derivative of a delta function as well by choosing a test function \\(f(x)\\) and integrating by parts to get \\[\n\\int_{-\\infty}^\\infty dx \\ f(x) \\frac{d}{dx} \\delta(x-x') = - \\int_{-\\infty}^\\infty dx \\ \\frac{d}{dx} f(x) \\cdot \\delta(x-x') = -\\frac{d}{dx} f(x') \\ .\n\\] Note for this to be well-defined we require that \\(f(x)\\) vanish as \\(x \\to \\pm \\infty\\).\nWe can also define the delta function in another useful way using the Fourier transform. We won’t go into details on the Fourier transform here. See the appendix for details. In brief, the Fourier transform of a function \\(f(x)\\) can be obtained by multiplying by \\(e^{-ikx}\\) and integrating over the real line to get another function \\(f(k)\\) in terms of this new variable \\(k\\), \\[\nf(k) \\equiv \\int_{-\\infty}^\\infty dx \\ f(x) e^{-ikx} \\ .\n\\] It turns out the Fourier transform is invertible, meaning we can recover \\(f(x)\\) from \\(f(k)\\) by another integral. If we multiply \\(f(k)\\) by \\(\\frac{1}{2\\pi} e^{ikx}\\) and integrate over \\(x\\), we can recover \\(f(x)\\) by the inverse Fourier transform \\[\nf(x) = \\int_{-\\infty}^\\infty \\frac{dk}{2\\pi} \\ f(k) e^{ikx} \\ .\n\\] If we plug the first integral for \\(f(k)\\) into this integral, using \\(x'\\) instead of \\(x\\), we get the completeness relation \\[\nf(x) = \\int_{-\\infty}^\\infty \\frac{dk}{2\\pi} \\bigg(\\int_{-\\infty}^\\infty dx' \\ f(x') e^{-ikx'}\\bigg) e^{ikx} \\ .\n\\] Suppose we interchange the order of integration to integrate first over \\(k\\). Then we get \\[\nf(x) = \\int_{-\\infty}^\\infty dx' f(x') \\int_{-\\infty}^\\infty \\frac{dk}{2\\pi} \\ e^{ik(x-x')} \\ .\n\\] The only way this can be true evidently is if the inner integral is the delta function \\(\\delta(x-x')\\). We thus must have \\[\n\\boxed{\n\\delta(x-x') = \\int_{-\\infty}^\\infty \\frac{dk}{2\\pi} \\ e^{ik(x-x')}\n} \\ .\n\\] Note that this integral isn’t well-defined in the usual sense, since the complex exponentials are oscillating sine and cosine functions, and hence don’t converge at infinity. We think of this integral instead as a formal relation that tells us when we can justify replacing it by a delta function.\nThe delta function extends naturally to higher dimensions. In three dimensions, we can define the delta function \\(\\delta(\\mathbf{x}-\\mathbf{x}')\\) by \\[\nf(\\mathbf{x}) = \\int d^3\\mathbf{x}' \\ f(\\mathbf{x}') \\delta(\\mathbf{x}-\\mathbf{x}') \\ .\n\\] The integral is assumed to be over all space, but it doesn’t matter. So long as \\(\\mathbf{x}\\) is contained inside the integration volume this relation will still hold.\nAgain, if we set \\(f(\\mathbf{x}) = 1\\) we can write \\[\n1 = \\int d^3\\mathbf{x}' \\ \\delta(\\mathbf{x}-\\mathbf{x}') \\ .\n\\] This means we can think of the 3-dimensional delta function as an infinite spike in three dimensions, which can be defined, for instance, by a limit of 3-dimensional Gaussian functions.\nThe specific form of \\(\\delta(\\mathbf{x}-\\mathbf{x}')\\) in terms of coordinates will depend on the coordinate system used. For instance, if working in Cartesian coordinates, we can write \\(d^3\\mathbf{x}' = dx'dy'dz'\\), in which case it’s clear we must have \\[\n\\delta(\\mathbf{x}-\\mathbf{x}') = \\delta(x-x') \\delta(y-y') \\delta(z-z') \\ .\n\\] Since densities transform with volume element and the delta function is a kind of density, when working in other coordinate systems the delta function will depend on the Jacobian. If \\((u,v,w)\\) is some other coordinate system with a volume element of the form \\(d^3\\mathbf{x}' = |\\text{det} \\ \\mathbf{J}| du' dv' dw'\\), then we have \\[\n\\delta(\\mathbf{x}-\\mathbf{x}') = \\frac{1}{|\\text{det} \\ \\mathbf{J}|} \\delta(u-u') \\delta(v-v') \\delta(w-w') \\ .\n\\] For example, in spherical coordinates we have \\(|\\text{det} \\ \\mathbf{J}| = r^2 \\sin\\theta\\), which means the delta function is given by \\[\n\\delta(\\mathbf{x}-\\mathbf{x}') = \\frac{1}{r^2 \\sin\\theta} \\delta(r-r') \\delta(\\theta-\\theta') \\delta(\\varphi-\\varphi') \\ .\n\\] Let’s now work a simple example that puts together some of the topics covered in this chapter.\n\nExample: Divergence of Inverse Square Fields\nSuppose we wanted to calculate the divergence of the following vector field, \\[\n\\mathbf{F}(\\mathbf{x}) = \\frac{\\mathbf{e}_r}{r^2} \\ .\n\\] We could proceed in one of two ways. One way would be to use Cartesian coordinates and index notation to churn it out the hard way. The other way would be to recognize this scalar field is spherically symmetric, so we should work in spherical coordinates more easily. Adopting the second approach, we can write \\[\n\\nabla \\cdot \\mathbf{F} = \\frac{1}{r} \\frac{\\partial}{\\partial r} \\bigg(r^2 \\frac{1}{r^2}\\bigg) \\ .\n\\] It’s tempting to cancel out the factors of \\(r^2\\) and conclude \\(\\nabla \\cdot \\mathbf{F} = 0\\), but we have to be a little more careful than that. To see why, let’s use the divergence theorem to express the same problem as an integral over some closed surface. We can pick any surface we like as long as it includes the origin. Let’s suppose we’re integrating inside a sphere of radius \\(R\\). Then we have \\[\n\\int_S \\mathbf{F} \\cdot d\\mathbf{a} = \\int_\\mathcal{V} \\nabla \\cdot \\mathbf{F} \\ d^3\\mathbf{x} \\ .\n\\] Since \\(\\mathbf{F}\\) is spherically symmetric and we’re integrating over a sphere, we can write \\(\\mathbf{F} \\cdot d\\mathbf{a} = |\\mathbf{F}| da\\) and integrate over the surface area of the sphere to get \\[\n\\int_S \\mathbf{F} \\cdot d\\mathbf{a} = \\int r^2 \\bigg(\\frac{1}{r^2}\\bigg) \\ d\\Omega = 4\\pi \\ .\n\\] Here the notation \\(d\\Omega \\equiv \\sin\\theta d\\theta d\\varphi\\) is called the solid angle, and has units of steradians.\nThe result we just derived true for any surface of arbitrary radius so long as it contains the origin. This means the divergence of \\(\\mathbf{F}\\) can’t be zero, otherwise the surface integral would be zero. Moreover, it means the only contribution from the divergence can come at the point \\(r=0\\) where the function blows up. We thus conclude that there must be a delta function multiplying \\(4\\pi\\) whose value is non-zero only when \\(r=0\\). That is, we have \\[\n\\nabla \\cdot \\bigg(\\frac{\\mathbf{e}_r}{r^2}\\bigg) = 4\\pi \\delta(\\mathbf{x}) \\ .\n\\] It’s not hard to see that if we shift the divergence point from the origin to some other point \\(\\mathbf{x}'\\) and define \\(\\boldsymbol{\\xi} \\equiv \\mathbf{x} - \\mathbf{x}'\\), then the above result doesn’t change except with \\(r\\) replaced by \\(|\\boldsymbol{\\xi}|\\) and the unit vector \\(\\mathbf{e}_r\\) replaced by \\(\\mathbf{e}_\\xi = \\frac{\\boldsymbol{\\xi}}{|\\boldsymbol{\\xi}|}\\). That is, \\[\n\\boxed{\n\\nabla \\cdot \\bigg(\\frac{\\mathbf{x} - \\mathbf{x}'}{|\\mathbf{x} - \\mathbf{x}'|^3}\\bigg) = 4\\pi \\delta(\\mathbf{x} - \\mathbf{x}')\n} \\ .\n\\] Last, notice that \\(\\nabla \\frac{1}{r} = -\\frac{\\mathbf{e}_r}{r^2}\\). This means we’ve also established that \\[\n\\nabla^2 \\bigg(\\frac{1}{r}\\bigg) = -4\\pi \\delta(\\mathbf{x})\n\\] Again shifting by \\(\\mathbf{x}'\\), it’s easy to see this also implies that \\[\n\\boxed{\n\\nabla^2 \\bigg(\\frac{1}{|\\mathbf{x} - \\mathbf{x}'|}\\bigg) = -4\\pi \\delta(\\mathbf{x} - \\mathbf{x}')\n}\\ .\n\\] We will make good use of these formulas in the rest of this course, particularly in electrostatics.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Preliminaries</span>"
    ]
  },
  {
    "objectID": "electrodynamics/preliminaries.html#temporary",
    "href": "electrodynamics/preliminaries.html#temporary",
    "title": "Preliminaries",
    "section": "TEMPORARY",
    "text": "TEMPORARY\nThe coefficient \\(c_{-1}\\) in the Laurent Series is called a residue of the function \\(f(z)\\). In the previous example the function \\(f(z) = e^{1/z}\\) evidently has a residue of \\(c_{-1} = 1\\). These residues that turn out to be very useful for our purposes due to a useful integral theorem we’ll see shortly.\nMany complex functions have residues at different points. Anywhere the function has a pole there will be at least one residue. For example, the function \\[\nf(z) = \\frac{1}{(z-a)(z-b)}\n\\] has two simple poles, one at \\(z=a\\) and another at \\(z=b\\). There’s a trick we can use to quickly figure out the residues in a case like this. Notice if we ignore the \\(z - a\\) term in the denominator what remains is \\(\\frac{1}{z - b}\\). When \\(z=a\\) this remaining term is a residue, with \\[\nc_{-1} = \\frac{1}{a - b} \\ .\n\\] Similarly, if we ignore the \\(z - b\\) term what remains is \\(\\frac{1}{z-a}\\). When \\(z=b\\) this remaining term is another residue, with \\[\nc_{-1} = \\frac{1}{b - a} \\ .\n\\] The two residues associated with this function are thus \\(c_{-1} = \\pm \\frac{1}{b-a}\\). This can also be seen by writing down the full Laurent series at \\(z=a\\) and \\(z=b\\) and picking off the \\(c_{-1}\\) coefficients directly.\nWe can also have complex functions with higher order poles. For example, consider the function \\[\nf(z) = \\frac{1}{(z-a)^2(z-b)} \\ .\n\\] Clearly there are poles at \\(z=a\\) and \\(z=b\\), but the fact that the \\(z-a\\) term is squared in the denominator means there are effectively two poles at \\(z=a\\). We call such a point \\(z=a\\) in this case a pole of order 2. In general, if a function with \\(n\\) poles at a single point \\(z=a\\) we call that point a pole of order \\(n\\). We can find the residues of \\(f(z)\\) for poles of order \\(n\\) using the formula \\[\nc_{-1} = \\frac{1}{(n-1)!} \\frac{d^{n-1}}{d z^{n-1}} \\bigg |_{z=a} (z-a)^n f(z) \\ .\n\\] In the previous example, the pole of order 1 at \\(z=b\\) has a residue of \\(c_{-1} = \\frac{1}{(a-b)^2}\\), while the pole of order 2 at \\(z=a\\) has a residue given by \\[\nc_{-1} = \\frac{d}{dz} (z-a)^2 \\frac{1}{(z-a)^2(z-b)} \\bigg |_{z=a} = -\\frac{1}{(a-b)^2} \\ .\n\\] To understand why residues are important in complex analysis we need to talk a bit about the integration of complex functions. Since complex functions are secretly functions of two real variables, when we integrate a complex function we’re actually integrating over a plane instead of a line. This means complex integrals are always necessarily contour integrals over the complex plane, meaning the result of an integral will always depend on the path chosen.\nWe can define a contour integral in the complex plane just as we would any other contour integral. If \\(f(z)\\) is some function we wish to integrate and \\(\\mathcal{C}\\) is some contour, we parametrize \\(z = z(\\tau)\\) where \\(\\tau\\) is some real parameter traversing the contour from \\(\\tau=a\\) to \\(\\tau=b\\). Then we can define the complex contour integral via \\[\n\\int_\\mathcal{C} dz \\ f(z) \\equiv \\int_a^b d\\tau \\ f(z(\\tau)) \\frac{dz}{d\\tau} \\ .\n\\] It turns out that analytic functions in complex analysis are the analogue of conservative functions in vector calculus, in that their closed loop integrals always vanish. If \\(f(z)\\) is analytic, for any closed loop in the complex plane we have \\[\n\\oint dz \\ f(z) = 0 \\ .\n\\] This result is known as Cauchy’s Theorem in complex analysis. If a function has poles we need to modify this result somewhat. This is what leads us to the Residue Theorem.\nThe residue theorem says that any closed loop integral is proportional to the residues contained inside the closed loop. More formally, suppose \\(f(z)\\) is a complex function with poles at \\(n\\) points \\(z=a_n\\) in the complex plane all contained inside the closed loop. If we denote the residue at \\(z=a_i\\) by \\(R_i\\), the residue theorem says that \\[\n\\oint dz \\ f(z) = 2\\pi i \\sum_{i=1}^n R_i \\ .\n\\] This means that to calculate any closed loop integral of a complex function, we need only find the residues for each pole inside the closed loop and add them together to get the result, up to a factor of \\(2\\pi i\\). Let’s work a couple of examples.\nFirst, consider the simple function \\(f(z) = \\frac{1}{z}\\). This function clearly only has a simple pole at \\(z=0\\) with residue \\(c_{-1} = 1\\). Suppose we wish to integrate this function in a closed loop around the origin. The loop could be anything, a circle, a square, whatever, as long as the origin is inside the closed loop. Then the residue theorem simply says that \\[\n\\oint \\frac{dz}{z} = 2\\pi i \\ .\n\\] What if we chose a closed loop that didn’t contain the origin? In that case the integral would be zero, since there are no poles inside the loop and hence no residues inside.\nAs a slightly more interesting example, consider now the function \\[\nf(z) = \\frac{e^z}{(z-1)(z+1)} \\ .\n\\] This function has two simple poles at \\(z = \\pm 1\\) with residues \\(c_{-1} = \\frac{e}{2}, -\\frac{1}{2e}\\). Suppose we wanted to integrate this function over a closed loop that’s a circle of some radius \\(R &gt; 1\\) centered at \\(z=0\\). Since both residues are contained inside this loop, we have \\[\n\\oint dz \\ \\frac{e^z}{(z-1)(z+1)} = 2\\pi i \\bigg(\\frac{e}{2} - \\frac{1}{2e}\\bigg) \\ .\n\\] The residue theorem turns out to be surprisingly useful, even for calculating integrals of functions of a real variable. This is where we find the most use of residues in electromagnetism. Let’s work an example of such a scenario.\n\nExample: Evaluating a real integral using the residue theorem\nSuppose we have the following real integral we need to evaluate, \\[\n\\int_{-\\infty}^\\infty dx \\ \\frac{\\cos x}{x^2 + 1} \\ .\n\\] This integral turns out to be very difficult to evaluate using traditional means, but we can relatively easily turn it into a complex integral and use the residue theorem to evaluate it. Let’s consider instead the complex integral \\[\n\\oint dz \\ \\frac{e^{iz}}{z^2 + 1} \\ .\n\\] Now let’s look closer at the integrand of this complex integral, \\[\nf(z) = \\frac{e^{iz}}{z^2 + 1} = \\frac{e^{iz}}{(z + i)(z - i)} \\ .\n\\] This function evidently has two poles of order 1 at \\(z = \\pm i\\) with residues \\[\n\\begin{align*}\nc_{-1} &= - \\frac{i}{2e} \\ \\text{when} \\ z = i \\ , \\\\\nc_{-1} &= \\frac{ie}{2} \\ \\text{when} \\ z = -i \\ . \\\\\n\\end{align*}\n\\] Now, we want to relate the complex integral to the real integral we wish to evaluate. To do this, what we can do is choose a closed contour that traverses the real line and then circles back over in a semi-circle to close the path. We’ll thus express the closed contour in two pieces: one piece \\(\\mathcal{R}\\) that runs from \\(-R\\) to \\(R\\) on the real axis, and another piece \\(\\mathcal{S}\\) that connects \\(z=R\\) to \\(z=-R\\) via a semicircular of radius \\(R\\) in the upper half plane. See the figure below to get an idea.\nFIGURE\nThis means the closed loop integral breaks up into two pieces, \\[\n\\oint dz \\ \\frac{e^{iz}}{z^2 + 1} = \\int_{-R}^R dz \\ \\frac{e^{iz}}{z^2 + 1} + \\int_\\mathcal{S} dz \\ \\frac{e^{iz}}{z^2 + 1} \\ .\n\\] Notice now that if we send \\(R \\rightarrow \\infty\\) and take the real part that the first integral on the right-hand side just gives us back the integral we wish to evaluate, which is what we want, \\[\n\\int_{-\\infty}^\\infty dx \\ \\frac{\\cos x}{x^2 + 1} = \\text{Re} \\lim_{R \\rightarrow \\infty} \\int_{-R}^R dz \\ \\frac{e^{iz}}{z^2 + 1} \\ .\n\\] We now need to evaluate the contour integral using the residue theorem. We’ll suppose that \\(R &gt; 1\\) since we’re going to send it to infinity anyway. This means the only residue contained inside the closed loop above is at \\(z=i\\), so we have \\[\n\\oint dz \\ \\frac{e^{iz}}{z^2 + 1} = 2\\pi i \\bigg(- \\frac{i}{2e}\\bigg) = \\frac{\\pi}{e} \\ .\n\\] To deal with the contour integral along the semi-circular arc \\(\\mathcal{S}\\), we can parametrize the arc by letting \\(z = R e^{i\\varphi}\\), where \\(\\varphi\\) is an angle parameter that runs from \\(\\varphi = 0\\) to \\(\\varphi = \\pi\\). We then have \\[\n\\int_\\mathcal{S} dz \\ \\frac{e^{iz}}{z^2 + 1} = \\int_0^\\pi d\\varphi \\ \\frac{e^{i z(\\varphi)}}{z^2(\\varphi) + 1} \\frac{dz}{d\\varphi} =\n\\int_0^\\pi d\\varphi \\ \\frac{\\exp(iRe^{i\\varphi})}{(Re^{i\\varphi})^2 + 1} (i R e^{i\\varphi}) \\ .\n\\] Now, if we let \\(R \\rightarrow \\infty\\) this integral will go to zero, since \\(|e^{iz}| = 1\\) and hence \\[\n\\bigg |\\int_0^\\pi d\\varphi \\ \\frac{\\exp(iRe^{i\\varphi})}{(Re^{i\\varphi})^2 + 1} (i R e^{i\\varphi}) \\bigg | \\sim \\frac{R}{R^2 + 1} \\rightarrow 0 \\ .\n\\] Putting this all together, as \\(R \\rightarrow \\infty\\) we’re left with \\[\n\\int_{-\\infty}^\\infty dz \\ \\frac{e^{iz}}{z^2 + 1} = \\frac{\\pi}{e} \\ .\n\\] Finally, taking the real part of both sides, we have our answer for the original integral we sought to evaluate, \\[\n\\int_{-\\infty}^\\infty dx \\ \\frac{\\cos x}{x^2 + 1} = \\frac{\\pi}{e} \\ .\n\\]",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Preliminaries</span>"
    ]
  },
  {
    "objectID": "electrodynamics/electrostatics.html",
    "href": "electrodynamics/electrostatics.html",
    "title": "Electrostatics",
    "section": "",
    "text": "Coulomb’s Law\nWe can start the subject in any number of ways, for example by just stating Maxwell’s equations and studying their implications. We’ll instead stick to the more usual convention, where we start by assuming the force laws of classical mechanics along with some empirical facts about electric charges and the forces between them.\nWe’ll assume that forces are vectors, meaning they have magnitude and direction. Being vectors, forces obey the principle of superposition, meaning the combined effect of two forces exerted on a body is given by their vector sum.\nIn the 18th century, it was discovered that aside from mass, every physical body has associated to it another scalar quantity called electric charge, which can take on any real value, positive, negative, or zero. From these facts and other experiments, Coulomb discovered that the force between two static, charged bodies satisfies the following properties:",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Electrostatics</span>"
    ]
  },
  {
    "objectID": "electrodynamics/electrostatics.html#coulombs-law",
    "href": "electrodynamics/electrostatics.html#coulombs-law",
    "title": "Electrostatics",
    "section": "",
    "text": "The force between the two charges depends linearly on the magnitude of each charge. The larger the magnitude, the stronger the force between them.\nThe force obeys an inverse square law nature similar to gravity. That is, the strength of the force between the two charges varies with the inverse square of the distance between them.\nAs with gravity, the force is directed along the line of force joining the two charges.\nThe force is attractive if the two bodies have charges of opposite sign, and repulsive if the two bodies have charges of the same sign. If either body has zero charge there is no force between them.\n\n\nCoulomb’s Law\nPutting all of these properties together we get Coulomb’s Law. Suppose we have two point particles with charges \\(q_1\\) and \\(q_2\\) located at positions \\(\\mathbf{x}_1\\) and \\(\\mathbf{x}_2\\) respectively. Then according to Coulomb’s Law, the force charge \\(q_1\\) experiences due to charge \\(q_2\\) is given by \\[\n\\mathbf{F}_{12} = k_e \\frac{q_1 q_2}{|\\mathbf{x}_1 - \\mathbf{x}_2|^2} \\mathbf{e}_{12} \\ .\n\\] Here \\(\\mathbf{e}_{12}\\) is the unit vector pointing from \\(q_2\\) to \\(q_1\\). By Newton’s third law, the force \\(q_2\\) experiences due to \\(q_1\\) is equal and opposite, with \\(\\mathbf{F}_{21} = -\\mathbf{F}_{12}\\). Since this force depends only on the distance between the two point charges it’s a central force, which implies that energy is conserved in electrostatics. We’ll say more about elecrostatic energy later.\nThe proportionality constant \\(k_e\\) has value and dimensions that depend on the choice of units used. In this course we’ll mostly use the Gaussian system of units, where \\(k_e \\equiv 1\\) and the mechanical units are measured in CGS units. This means force is measured in dynes and distance in centimeters. Evidently then, in the Gaussian system of units charge must have units of \\(\\sqrt{\\text{dyne} \\cdot \\text{cm}^2}\\). We give this unit of charge a name, called the electrostatic unit or esu, where \\(1 \\ \\text{esu} \\approx 3.3 \\cdot 10^{-10} \\ \\text{C}\\) in SI units. In Gaussian units, Coulomb’s Law thus simplifies to \\[\n\\mathbf{F}_{12} = \\frac{q_1 q_2}{|\\mathbf{x}_1 - \\mathbf{x}_2|^2} \\mathbf{e}_{12} \\ .\n\\] Note that as defined Coulomb’s Law really only holds for point charges. That is, for point particles where all charge is localized at a single point. This is of course an abstraction. In reality we deal with larger bodies where the charge may be distributed across the body in some way. We’ll see how to modify Coulomb’s Law the work with more arbitrary distributions of charge below.\n\n\nWhat is Charge?\nBefore moving on, it’s worth stopping to ask what exactly it is we mean when we say a body has charge. Mathematically, we can think of charge similar to how we think of mass. It’s a scalar quantity associated with a body, except unlike mass it can take on any real value, positive or negative. More fundamentally though, the charge of a body is really an aggregate of charge due to more atomic particles inside the body like electrons and protons.\nA body is really a collection of atoms held together in some way, each with some number of protons and electrons. What we think of as charge is really how the electrons and protons are distributed inside the body. Electrons and protons carry the same charge but with opposite sign. In practice most bodies are at least approximately charge neutral, meaning it contains the same number of protons and electrons. If there are more electrons than protons the body has negative charge. If there are fewer electrons than protons the body has positive charge.\nIn practice, it’s the movement of electrons that control how a material is charged. In some materials, called conductors these electrons move freely around the material, while for materials, called insulators, these electrons stay locked into their respective atoms and only move inside their confined electron clouds. In either case, if the body is charged it implies some deficit or surplus of electrons.\nOne would think that we should think of charge in terms of electrons and define charge in units of the number of surplus electrons present in the body. However, atomic structure wasn’t known at the time the theory of electromagnetism was first formulated. It was only known that there was a scalar quantity called charge associated to the body, with no understanding of what gives rise to it. It’s for these largely historical reasons that we continue to think of positive charge as moving around inside a body, even though it’s really negatively charged electrons that move around.\n\n\nCoulomb vs Gravity\nGiven that Coulomb’s Law looks so similar to Newton’s law of gravitation, it’s fair to ask how the forces compare to each other. Let’s suppose we have two particles separated by a distance \\(r\\) with masses \\(m_1, m_2\\) and charges \\(q_1, q_2\\) respectively. Since the particles have both mass and charge they’ll feel both a gravitational force \\(\\mathbf{F}_g\\) and a Coulomb force \\(\\mathbf{F}_e\\). We can get an idea of the relative strengths of these two forces by looking at their ratio. In Gaussian units, this is given by \\[\n\\frac{|\\mathbf{F}_e|}{|\\mathbf{F}_g|} = \\frac{q_1 q_2}{r} \\bigg / G \\frac{m_1 m_2}{r} = \\frac{q_1 q_2}{G m_1 m_2} \\ .\n\\] To get a feel for these values let’s pick a representative particle, the electrons. Then we’d have masses \\(m_1 = m_2 = m_e\\) and charges \\(q_1 = q_2 = e\\). In Gaussian units, these values are \\[\n\\ G \\approx 6.7 \\cdot 10^{-8} \\ , \\ m_e \\approx 9 \\cdot 10^{-28} \\ , \\ e \\approx -5 \\cdot 10^{-10} \\ .\n\\] Plugging these numbers in, we get \\[\n\\frac{|\\mathbf{F}_e|}{|\\mathbf{F}_g|} = \\frac{e^2}{G m_e^2} \\approx 4 \\cdot 10^{42} \\ .\n\\] That is, for two electrons the Coulomb force is 42 orders of magnitude stronger than the gravitational force. The difference between the two forces is so stark we can practically speaking neglect the effects of gravity when studying the interactions between electrons, or indeed any small particles. Indeed, this is one reason why in quantum mechanics we rarely consider gravity. On the other hand, larger objects like people, planets, or galaxies tend to be electrically neutral or very close to it. This means in those cases gravity is all there is, and for large masses gravity can obviously be quite substantial.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Electrostatics</span>"
    ]
  },
  {
    "objectID": "electrodynamics/electrostatics.html#electric-fields",
    "href": "electrodynamics/electrostatics.html#electric-fields",
    "title": "Electrostatics",
    "section": "Electric Fields",
    "text": "Electric Fields\nWhile we could proceed to study this force between charges just as we did in with gravity in classical mechanics, we’ll find it’s useful in electromagnetism to make a further abstraction, the field abstraction. The reason for this is that we want to think of all interactions as local. That is, a particle should only feel the presence of things near by, not things far away. If we think in terms of forces we have to give locality up, since two charges will feel a force no matter how far away they are, so-called “action at a distance”.\n\nElectric Field\nInstead what we’ll do is imagine that particles interact due to the presence of background fields, and think of these fields as giving rise to forces. Suppose we have a charge \\(q'\\) sitting in space at some position \\(\\mathbf{x}'\\). Suppose we then place an infinitesimal test charge \\(q\\) at some other position \\(\\mathbf{x}\\). By Coulomb’s Law, the test charge will feel a force \\(\\mathbf{F}\\) due to \\(q'\\). We’ll define a vector-valued function of position known as the electric field by the ratio \\[\n\\mathbf{E}(\\mathbf{x}) \\equiv \\frac{\\mathbf{F}}{q} \\ .\n\\] Empirically this ratio is found to be well-defined and independent of the value of \\(q\\) so long as \\(q\\) is infinitesimal, with \\[\n\\mathbf{E}(\\mathbf{x}) = \\frac{q'}{|\\mathbf{x} - \\mathbf{x}'|^2} \\mathbf{e}_\\xi \\ .\n\\] Here for convenience we define the separation vector \\(\\boldsymbol{\\xi} \\equiv \\mathbf{x} - \\mathbf{x}'\\), so that the field always points from the location \\(\\mathbf{x}'\\) of the source charge \\(q'\\) to the field point \\(\\mathbf{x}\\) where we imagine placing the test charge \\(q\\). The relationship between all these points is shown in the figure below.\n\n\n\n\n\nNotice that the electric field doesn’t depend on \\(q\\) at all. It has a value at every point in space. When a test charge \\(q\\) is brought in and placed at a position \\(\\mathbf{x}\\) it feels a force \\[\n\\boxed{\n\\mathbf{F} = q \\mathbf{E}(\\mathbf{x})\n} \\ .\n\\] Note that the requirement that \\(q\\) be an infinitesimal charge in this definition is important. If test charge is high enough, it will distort the background electric field through its presence, in effect making both charges source charges for the field. Also, note that this doesn’t mean that the charge will move in the direction of the electric field. All that will be true is that its force vector will be tangential to the electric field at that point, pointing in the direction of the field if \\(q\\) is negative, and opposite the field if \\(q\\) is opposite. The path the charge actually follows through the field may be quite complicated.\nWe’ll often find it more useful to express the electric field formula in a slightly different way by getting rid of the unit vector. Using the fact that the separation vector can be written \\(\\boldsymbol{\\xi} = |\\mathbf{x}-\\mathbf{x}'| \\mathbf{e}_\\xi\\) we can write the same electric field in the equivalent form \\[\n\\mathbf{E}(\\mathbf{x}) = q' \\frac{\\mathbf{x}-\\mathbf{x}'}{|\\mathbf{x}-\\mathbf{x}'|^3} \\ .\n\\] This only defines the electric field due to a single point charge \\(q'\\). What if instead we have multiple source charges spread out in space. Suppose we instead have \\(N\\) point source charges \\(q_1, q_2, \\cdots, q_N\\) located at positions \\(\\mathbf{x}_1, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N\\) respectively. Since forces obey the principle of superposition, we know we can add the force due to each source charge to get the total force, \\[\n\\mathbf{F} = \\mathbf{F}_1 + \\mathbf{F}_2 + \\cdots + \\mathbf{F}_N \\ .\n\\] Since the electric field is proportional to the force it must evidently obey the superposition principle as well. Then the combined electric field due to the presence of all of these charges must be given by the sum of each individual field, \\[\n\\mathbf{E}(\\mathbf{x}) = \\sum_{i=1}^N \\mathbf{E}_i(\\mathbf{x}) = \\sum_{i=1}^N q_i \\frac{\\mathbf{x}-\\mathbf{x}_i}{|\\mathbf{x}-\\mathbf{x}_i|^3} \\ .\n\\] Again, the combined electric field does not depend on the test charge, only the source charges. If we imagine placing an infinitesimal test charge \\(q\\) at \\(\\mathbf{x}\\) it will still feel the combined force \\(\\mathbf{F} = q \\mathbf{E}\\).\nThe most typical way to visualize vector fields in electromagnetism is via field lines. We imagine that any positive charge emits from it a bunch of lines, called field lines. These field lines follow the direction of the vector field in space, only terminating at negative charges or at infinity. Field lines should never cross each other. The direction of a field line is always from positive charges to negative charges. The strength of the field is captured by the density of field lines. The more field lines there are surrounding a given point in space, the stronger the field at that point. Indeed, we can informally define a vector field as the flux density of field lines, i.e. the number of field lines per unit volume.\nHere are some examples of electric field line sketches for a few different configurations of point charges. Notice it’s usually fairly easy to sketch field lines for a given charge configuration, even if finding an expression for the actual electric field of that configuration might be difficult. We’ll see field lines sketched in many figures throughout this course.\nFIGURE\nLet’s now work a problem involving finding the electric field for a very simple example, the physical dipole.\n\nExample: Physical dipole\nSuppose we have two like charges of opposite sign separated by a fixed distance along some axis. More formally, suppose we have a positive charge \\(+q\\) located at a point \\(\\mathbf{x}_+ = \\frac{d}{2} \\mathbf{e}_z\\), and a negative charge \\(-q\\) located at the opposite point \\(\\mathbf{x}_- = -\\frac{d}{2} \\mathbf{e}_z\\). Our goal will be to find the electric field for any field point \\(\\mathbf{x}\\) in the \\(xy\\)-plane.\n\n\n\n\n\nBy the superposition principle, the electric field is given by \\[\n\\mathbf{E} = \\mathbf{E}_+ + \\mathbf{E}_- = q\\frac{\\mathbf{x} - \\mathbf{x}_+}{|\\mathbf{x} - \\mathbf{x}_+|^3} - q\\frac{\\mathbf{x} - \\mathbf{x}_-}{|\\mathbf{x} - \\mathbf{x}_-|^3} \\ .\n\\] To proceed further we first need to find the separation vectors for each charge. We have \\[\n\\mathbf{x} - \\mathbf{x}_\\pm = r \\mathbf{e}_r \\mp \\frac{d}{2} \\mathbf{e}_z \\ ,\n\\] Plugging this in and simplifying, we get \\[\n\\begin{align*}\n\\mathbf{E} &= q \\frac{r \\mathbf{e}_r - \\frac{d}{2} \\mathbf{e}_z}{|r \\mathbf{e}_r - \\frac{d}{2} \\mathbf{e}_z|^3} - q \\frac{r \\mathbf{e}_r + \\frac{d}{2} \\mathbf{e}_z}{|r \\mathbf{e}_r + \\frac{d}{2} \\mathbf{e}_z|^3} \\\\\n&= q \\frac{r \\mathbf{e}_r - \\frac{d}{2} \\mathbf{e}_z}{\\bigg[r^2 + \\big(\\frac{d}{2}\\big)^2\\bigg]^{3/2}} - q \\frac{r \\mathbf{e}_r + \\frac{d}{2} \\mathbf{e}_z}{\\bigg[r^2 + \\big(-\\frac{d}{2}\\big)^2\\bigg]^{3/2}} \\\\\n&= \\frac{-qd}{\\bigg[r^2 + \\big(\\frac{d}{2}\\big)^2\\bigg]^{3/2}} \\mathbf{e}_z \\ .\n\\end{align*}\n\\] We can immediately see that the electric field for any point in the \\(xy\\)-plane must point along the negative \\(z\\)-axis. This can be understood intuitively just by vector subtracting the separation vectors in the figure above and noting that the magnitude of the field for each charge must be the same by symmetry.\nThis is as far as we can go as is, but we can make one useful simplification. Let’s suppose \\(r \\gg d\\). This is the far field limit where the field point is far away from both charges. In this limit we can ignore the \\(\\frac{d}{2}\\) term in the denominator and write \\[\n\\mathbf{E} \\approx -\\frac{qd}{r^3} \\mathbf{e}_z \\ .\n\\] This result tells us something interesting. Even far away from the source charges, the dipole doesn’t seem to follow Coulomb’s Law since the field doesn’t fall off as \\(\\mathbf{E} \\sim \\frac{1}{r^2}\\), but rather as \\(\\mathbf{E} \\sim \\frac{1}{r^3}\\). The reason for this is the two charges screen each other, canceling out the monopole field that would usually give rise to a \\(\\frac{1}{r^2}\\) term in the field. This causes the field to be weaker than we’d expect for a point charge in the far field limit.\nThe term \\(qd \\mathbf{e}_z\\) has a name. It’s called the dipole moment, denoted by the vector \\(\\mathbf{p}\\). The dipole moment is a vector of magnitude \\(qd\\) that points from the negative to the positive charge in a dipole. Using the dipole moment it’s possible to show that for a general field point, not just in the \\(xy\\)-plane, we can express the electric field of a dipole in the far field limit as \\[\n\\mathbf{E} = \\frac{3(\\mathbf{p} \\cdot \\mathbf{e}_r) \\mathbf{e}_r}{r^3} - \\frac{\\mathbf{p}}{r^3} \\ .\n\\] Notice the first term is just the projection of the dipole onto the field point direction, which is zero when the two vectors are perpendicular. The dipole turns out to be very important to the theory of electrostatics. We’ll talk about it in more detail in the next chapter when we discuss the multipole expansion.\n\n\n\nContinuous Charge Distributions\nIn classical electromagnetism we rarely find ourselves dealing with point charges. We’re generally dealing with macroscopic materials containing many charged particles packed densely together. In such cases it’s more convenient to treat those charges not as a sum over all the point charges, but instead as a continuous charge distribution.\nA charge distribution can be thought of as a large number of charged point particles packed densely together. Provided the charges are dense enough that we can treat them as continuous, we can define a charge density \\(\\rho(\\mathbf{x}')\\) by \\[\ndq = d^3 \\mathbf{x}' \\ \\rho(\\mathbf{x}') \\ .\n\\] Each \\(dq\\) will give rise to an infinitesimal electric field \\(d\\mathbf{E}\\) defined by Coulomb’s Law. Using the principle of superposition, we can then integrate over all these charges over all space to get the electric field of the distribution, \\[\n\\boxed{\n\\mathbf{E}(\\mathbf{x}) = \\int d^3 \\mathbf{x}' \\ \\rho(\\mathbf{x}') \\frac{\\mathbf{x}-\\mathbf{x}'}{|\\mathbf{x}-\\mathbf{x}'|^3}\n}\\ .\n\\] Strictly speaking we should only integrate over the volume \\(\\mathcal{V}\\) of the distribution, but since we can freely define the density to be zero outside the distribution we’ll usually omit this from the formula and assume we’re integrating over all space.\nThis idea can be seen in the figure below. Here the gray blob is some charge distribution, and \\(dq\\) some infinitesimal element of it. Adding up, or integrating, over all these charges will give the full electric field \\(\\mathbf{E}(\\mathbf{x})\\).\n\n\n\n\n\nThe field lines for the electric fields of continuous distributions work the same way they do for point charges. The main new thing to be aware of is that field lines will always point normal to the surface of the charge distribution. Again, the field lines will point away from positive charge distributions, and toward negative charge distributions or out to infinity, never crossing.\nWe’ll often be interested in charge distributions of lower dimension as well, for example lines of charge and sheets of charge. For this reason it’s useful to define charge densities in these dimensions as well. The simplest case is the point charge, which we can think of as a zero-dimensional density. If \\(q'\\) is some point charge located at \\(\\mathbf{x}'\\), we can use the delta function to write \\[\ndq = d^3 \\mathbf{x} \\ q \\delta(\\mathbf{x} - \\mathbf{x}') \\ .\n\\] Indeed, we get \\[\n\\mathbf{E}(\\mathbf{x}) = \\int d^3 \\mathbf{x}'' \\ q \\delta(\\mathbf{x}'' - \\mathbf{x}') \\frac{\\mathbf{x}-\\mathbf{x}''}{|\\mathbf{x}-\\mathbf{x}''|^3} = q \\frac{\\mathbf{x}-\\mathbf{x}'}{|\\mathbf{x}-\\mathbf{x}'|^3} \\ ,\n\\] which agrees with our original formula for the electric field of a point charge.\nStepping up to one-dimension, we can imagine a line of charge in space, for example a long, thin charged wire. If \\(d\\ell'\\) is an infinitesimal line element of this line of charge, we can define a line charge density \\(\\lambda(\\mathbf{x}')\\) by the formula \\[\ndq = d\\ell' \\ \\lambda(\\mathbf{x}') \\ .\n\\] Then the formula for the electric field becomes \\[\n\\mathbf{E}(\\mathbf{x}) = \\int d\\ell' \\ \\lambda(\\mathbf{x}') \\frac{\\mathbf{x}-\\mathbf{x}'}{|\\mathbf{x}-\\mathbf{x}'|^3} \\ .\n\\] Here it’s again understood that we’re integrating over the line of charge \\(\\mathcal{C}\\), but we’ll again usually omit this dependency.\nLast, we can imagine a two-dimensional surface of charge in space, for example a thin sheet of charge. If \\(da'\\) is the area element along this surface of charge, we can define a surface charge density \\(\\sigma(\\mathbf{x}')\\) by the formula \\[\ndq = d\\mathcal{a}' \\ \\sigma(\\mathbf{x}') \\ .\n\\] Then the formula for the electric field becomes \\[\n\\mathbf{E}(\\mathbf{x}) = \\int da' \\ \\sigma(\\mathbf{x}') \\frac{\\mathbf{x}-\\mathbf{x}'}{|\\mathbf{x}-\\mathbf{x}'|^3} \\ .\n\\] Again, it’s understood we’re integrating over the whole surface of charge \\(\\mathcal{S}\\), which we will usually omit.\nWe could in principle define charge densities in higher dimensions as well, though we won’t since we won’t need them. Each of the cases we discussed can be visualized using the figure below.\n\n\n\n\n\n\nExample: Sphere with uniform charge\nAs a useful example of how to calculate the electric field of a charge distribution, let’s consider the case of a uniformly charged sphere. We’ll first suppose the sphere is hollow with a radius \\(R\\) and a uniform charge \\(Q = 4\\pi R^2 \\sigma\\) where \\(\\sigma\\) is a constant surface density.\nGiven the symmetry of the problem it’s natural to work in spherical coordinates. By symmetry, it’s not hard to see that the electric field for the hollow sphere must always point in the radial direction. To see why, notice that any source point we pick on the sphere will have an opposite point \\(180^\\circ\\) away at the same altitude. Since the charge is uniform both source points will cancel all but the radial component of the field when added together. We thus just need to find the single scalar \\(E(r)\\), where \\[\n\\mathbf{E}(\\mathbf{x}) = E(r) \\mathbf{e}_r \\ .\n\\] To find \\(E(r)\\) we need to take the inner product of \\(\\mathbf{E}\\) with \\(\\mathbf{e}_r\\). In terms of the separation vector \\(\\boldsymbol{\\xi} = \\mathbf{x} - \\mathbf{x}'\\), we have \\[\nE(r) = \\int da' \\ \\frac{\\sigma}{\\xi^3} \\boldsymbol{\\xi} \\cdot \\mathbf{e}_r \\ .\n\\] To make headway we need to find the area element \\(da'\\), the relative distance \\(\\xi = |\\boldsymbol{\\xi}|\\), and the dot product \\(\\boldsymbol{\\xi} \\cdot \\mathbf{e}_r\\). Starting with the area element, for a sphere it’s simply the volume element in spherical coordinates with \\(r=R\\) and without the \\(dr\\) integral, \\[\nda' = R^2 \\sin\\theta' d\\theta' d\\phi' \\ .\n\\] Now we need to find \\(\\xi \\equiv |\\mathbf{x} - \\mathbf{x}'|\\), which is somewhat trickier. Without loss of generality we can assume that the field point lies on the \\(z\\)-axis, so that \\(\\mathbf{x} = r \\mathbf{e}_z\\). Then an arbitrary source point \\(\\mathbf{x}' = R \\mathbf{e}_r\\) on the sphere will subtend a polar angle \\(\\theta'\\) with the \\(z\\)-axis. Using the law of cosines on the triangle shown in the figure below, we can see that \\[\n\\xi^2 = r^2 + R^2 - 2Rr \\cos\\theta' \\ .\n\\]\n\n\n\n\n\nNext we need to calculate the dot product \\(\\boldsymbol{\\xi} \\cdot \\mathbf{e}_r\\). Using the geometric formula for the dot product and the above triangle, we see \\[\n\\boldsymbol{\\xi} \\cdot \\mathbf{e}_r = \\xi \\cos\\alpha = \\frac{r - R\\cos\\theta'}{\\xi} \\ .\n\\] We can now plug all of these values into the electric field integral and just plug away. We’ll integrate over the whole sphere, \\[\n\\begin{align*}\nE(r) &= \\int da' \\ \\frac{\\sigma}{\\xi^3} \\boldsymbol{\\xi} \\cdot \\mathbf{e}_r \\\\\n&= \\int \\sigma R^2 \\sin\\theta' d\\phi' d\\theta' \\frac{r - R\\cos\\theta'}{\\xi^3} \\\\\n&= R^2 \\sigma \\int_0^{2\\pi} \\sin\\theta' d\\phi' \\int_0^{\\pi} d\\theta' \\frac{r - R\\cos\\theta'}{(r^2 + R^2 - 2Rr \\cos\\theta')^{3/2}} \\\\\n&= 2\\pi R^2 \\sigma \\int_0^{\\pi} \\sin\\theta' d\\theta' \\frac{r - R\\cos\\theta'}{(r^2 + R^2 - 2Rr \\cos\\theta')^{3/2}} \\ .\n\\end{align*}\n\\] To evaluate the remaining integral we make use of a very common substitution in electrostatics. Supposing \\(f(\\cos\\theta)\\) is some function we’d like to integrate in spherical coordinates, we can always let \\(\\mu = \\cos\\theta'\\) and \\(d\\mu = -\\sin\\theta' d\\theta'\\). Then we have \\[\n\\int_0^\\pi \\sin\\theta d\\theta \\ f(\\cos\\theta) = \\int_{-1}^1 d\\mu \\ f(\\mu) \\ .\n\\] Using this useful trick, the integral for the field simplifies slightly to \\[\nE(r) = 2\\pi R^2 \\sigma \\int_{-1}^1 d\\mu \\ \\frac{r - R\\mu}{(r^2 + R^2 - 2Rr \\mu)^{3/2}} \\ .\n\\] The remaining integral can be done by breaking up the numerator and doing another substitution. In the end we get $$ \\[\\begin{align*}\nE(r) &= \\frac{2\\pi R^2 \\sigma}{r^2} \\bigg[\\frac{r\\mu - R}{\\sqrt{r^2 + R^2 - 2R\\mu}} \\bigg]_{\\mu=-1}^1 \\\\\n&= \\frac{2\\pi R^2 \\sigma}{r^2} \\bigg[\\frac{r-R}{|r-R|} + 1 \\bigg] \\ .\n\n\\end{align*}\\] $$ Now, notice that the first term in the brackets will always be \\(\\pm 1\\) depending on the sign of \\(r-R\\). When we’re inside the sphere \\(r &lt; R\\), and so this term is \\(-1\\). This means that inside the sphere the electric field must vanish, with \\(E(r) = 0\\).\nOutside the sphere \\(r &gt; R\\), and so the first term is \\(+1\\)​. In this case we have \\[\nE(r) = \\frac{4\\pi R^2 \\sigma}{r^2} = \\frac{Q}{r^2} \\ .\n\\] Notice that this looks identical to Coulomb’s Law for the electric field. Evidently, a hollow sphere behaves as a point charge \\(Q\\)​ for any field points outside the sphere.\nUsing the result we have for the hollow sphere, let’s quickly figure out what the electric field should be for a solid sphere of uniform charge. The only difference now is that the sphere is 3-dimensional. We can work directly from our previous solution. We just have to replace \\(\\sigma\\) with \\(\\rho\\) and \\(R\\) by an integration variable \\(r'\\). However we do have to be slightly careful, since the charge density is only nonzero inside the sphere. This means we integrate up to \\(R\\) for field points outside the sphere, and up to \\(r\\) otherwise. We can take care of both cases by integrating up to \\(r_{\\min} \\equiv \\min(r, R)\\). Then we have \\[\nE(r) = \\frac{4\\pi\\rho}{r^2} \\int_0^{r_{\\min}} dr' \\ r'^2 = \\frac{4\\pi\\rho}{3} \\frac{r_{\\min}^3}{r^2} \\ .\n\\] Now, if \\(r &gt; R\\) we’re outside the sphere, and \\(r_{\\min} = R\\). In that case we have \\[\nE(r) = \\frac{4\\pi R^3 \\rho}{3r^2} = \\frac{Q}{r^2} \\ .\n\\] Here we used the fact that in 3 dimensions the total charge of the sphere becomes \\(Q = \\frac{4\\pi}{3} R^3 \\rho\\)​. Notice that we get the same result we got in the hollow sphere. The electric field is again that of a point charge outside the sphere.\nInside the sphere, however, things change. When \\(r \\leq R\\) we have \\(r_{\\min} = r\\), in which case \\[\nE(r) = \\frac{4\\pi\\rho}{3} r = \\frac{Qr}{R^3} \\ .\n\\] Now the electric field inside the sphere is apparently linear in \\(r\\), not zero. It’s easy to check that the two results match at the boundary of the sphere where \\(r=R\\). Note that in either case the electric field is still just the enclosed charge \\(Q_{\\text{enc}} = \\frac{4\\pi}{3} r_{\\min}^3 \\rho\\) divided by \\(r^2\\). This means any charge outside the enclosed sphere contributes nothing to the field. In the figure below we plot the field strengths \\(E(r)\\) for both the hollow and solid spheres to show the difference between the two.\nFIGURE\nThis was clearly a difficult integration problem. We’ll see a much easier way to find the electric field of a sphere shortly. For now, just be aware that in practice calculating the electric field of a charge distribution straight from the definition is almost always very challenging, and often impossible. Indeed, much of the rest of our study of electrostatics from here on will be about finding simpler ways to calculate the electric field of an arbitrary charge distribution.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Electrostatics</span>"
    ]
  },
  {
    "objectID": "electrodynamics/electrostatics.html#gausss-law",
    "href": "electrodynamics/electrostatics.html#gausss-law",
    "title": "Electrostatics",
    "section": "Gauss’s Law",
    "text": "Gauss’s Law\nWhile Coulomb’s Law is perhaps more directly connected to experiment and the historical progression of electromagnetism, it’s usually not the most illuminating nor useful way to understand and calculate electric fields. Just as in classical mechanics we found it useful to express Newton’s law as an ordinary differential equation for the trajectory of a particle, in electromagnetism we’ll find it more useful to express Coulomb’s Law as a set of partial differential equations for the electric field.\n\nFlux\nWe know from the Helmholtz theorem that any well behaving vector field can be fully characterized by its divergence and its curl. This means if we can find the divergence and curl of the electric field we have an equivalent characterization for the field in terms of two linear partial differential equations. We’ll derive the divergence of the electric field in this section, saving the curl of the electric field for the next section before discovering a neat way to combine them both together.\nTo make a start we need to define the idea of the flux of a vector field. Suppose \\(\\mathcal{S}\\) is some surface of interest we’d like to calculate the flux through. In electromagnetism we call this surface a Gaussian surface. The flux \\(\\Phi\\) through \\(\\mathcal{S}\\) due to the field \\(\\mathbf{E}\\) is defined by the integral \\[\n\\Phi \\equiv \\int_\\mathcal{S} \\mathbf{E} \\cdot d\\mathbf{a} \\ .\n\\] Note when we need to specify which field we’re calculating the flux of, we’ll write \\(\\Phi_\\mathbf{E}\\) to be more specific.\nInformally, we can think of the flux as the total number of signed field lines passing through some specified surface of interest. By signed, we mean that the field lines passing through the positively oriented side of the surface contribute positive flux, while those passing through the negatively oriented side of the surface contribute negative flux. This means that flux itself will be a signed quantity indicating the net tendency of a field to flow into or out of a given surface. In particular, this means if the same field line passes in and out of the same surface it contributes nothing to the flux.\nAs defined, the flux depends entirely on the surface \\(\\mathcal{S}\\) we choose. Different surfaces will have a different flux. However, in practice we’ll usually be interested in closed surfaces. In that case, we’ll show that the flux depends only on the charge distribution enclosed by the surface, not on the geometric properties of the surface itself. To do that we need to find a way to relate the flux of an electric field to the charge distribution in some way.\n\n\nIntegral Form of Gauss’s Law\nLet’s start by trying to find the flux through a sphere of radius \\(r\\) centered on a point charge \\(q\\) located at the origin. Since \\(q\\) is located at the origin we have \\(\\mathbf{x}' = \\mathbf{0}\\), meaning the electric field is simply \\[\n\\mathbf{E}(\\mathbf{x}) = q \\frac{\\mathbf{x}}{|\\mathbf{x}|^3} = \\frac{q}{r^2} \\mathbf{e}_r \\ .\n\\] For a sphere of radius \\(r\\) the area element is given by \\(d\\mathbf{a} = r^2 d\\Omega \\mathbf{e}_r\\). Here \\(d\\Omega\\) is the differential solid angle, which is just a useful shorthand for angular components of the area element, \\(d\\Omega \\equiv \\sin\\theta d\\theta d\\phi\\). To find the flux, we need only now integrate to get \\[\n\\Phi = \\oint_\\mathcal{S} \\mathbf{E} \\cdot d\\mathbf{a} = \\int d\\Omega \\ r^2 \\frac{q}{r^2} \\mathbf{e}_r \\cdot \\mathbf{e}_r = 4\\pi q \\ .\n\\] We’ve thus shown that the flux of a point charge through a sphere is just proportional to the charge. Notice in this result that the radius of the Gaussian surface didn’t enter into the picture at all. No matter what it cancels out. This fact is unique to inverse square fields, like electricity or gravity. Any field of this type will have the property that its flux is proportional to its source “charge”.\nBut thus far we’ve only shown this holds for the flux through a sphere. What about an arbitrary closed surface? In fact the result is the same. To see why, suppose \\(\\mathcal{S}\\) is some arbitrary closed surface containing \\(q\\). Suppose \\(\\alpha\\) is the outward angle between \\(\\mathbf{E}\\) and the surface normal \\(\\mathbf{n}\\). Then we evidently have \\[\n\\mathbf{E} \\cdot d\\mathbf{a} = |\\mathbf{E}| |\\mathbf{n}| \\cos\\alpha da = \\frac{q}{r^2} \\cos\\alpha da \\ .\n\\] It now seems like we should get a different flux. However, we have to look closer at the area element \\(da\\) first. Since the surface is no longer spherical we have to divide by another factor of \\(\\cos\\alpha\\) to account for the fact that we’re only interested in the flux through the outward normal component of the surface, \\[\nda = \\frac{r^2}{\\cos\\alpha} d\\Omega \\ .\n\\] Putting these together we get exactly what we claimed, \\[\n\\oint_\\mathcal{S} \\mathbf{E} \\cdot d\\mathbf{a} = \\int d\\Omega \\ \\frac{r^2}{\\cos\\alpha} \\frac{q}{r^2} \\cos\\alpha = 4\\pi q \\ .\n\\] This is only true though when the charge is contained inside the surface. What if it’s outside the surface? We already said informally the flux in that case should be zero, since any field lines going into the surface also comes out, offsetting the flux. Indeed, if \\(\\mathbf{E} \\cdot d\\mathbf{a}\\) is some contribution to the flux, there will be a corresponding contribution \\(-\\mathbf{E} \\cdot d\\mathbf{a}\\) on some other part of the Gaussian surface that will cancel out the first contribution. This can be seen geometrically in the figure below.\n\n\n\n\n\nPutting these two results together, we’ve shown that if \\(q\\) is a point charge and \\(\\mathcal{S}\\) is some closed surface, then \\[\n\\oint_\\mathcal{S} \\mathbf{E} \\cdot d\\mathbf{a} =\n\\begin{cases}\n4\\pi q, & q \\ \\text{inside} \\ \\mathcal{S} \\\\\n0, & q \\ \\text{outside} \\ \\mathcal{S} \\ .\n\\end{cases}\n\\] By the principle of superposition, this result must also hold for some arbitrary distribution of charge, the flux through a closed surface depends only on the charge \\(Q_{\\text{enc}}\\) enclosed inside the surface, \\[\n\\boxed{\n\\oint_\\mathcal{S} \\mathbf{E} \\cdot d\\mathbf{a} = 4\\pi Q_{\\text{enc}}\n} \\ .\n\\] This important result is called the integral form of Gauss’s Law. It says that the total flux of the electric field through a closed surface is proportional to the enclosed charge inside the surface.\n\n\nDifferential Form of Gauss’s Law\nThe enclosed charge can be found by integrating the charge density over the volume \\(\\mathcal{V}\\) of the closed surface, \\[\nQ_{\\text{enc}} = \\int_\\mathcal{V} d^3\\mathbf{x} \\ \\rho(\\mathbf{x}) \\ .\n\\] Indeed, if we plug this into Gauss’s Law we get \\[\n\\oint_\\mathcal{S} \\mathbf{E} \\cdot d\\mathbf{a} = 4\\pi \\int_\\mathcal{V} d^3\\mathbf{x} \\ \\rho(\\mathbf{x}) \\ .\n\\] Also, notice we can use of the divergence theorem to convert the flux integral into a volume integral, \\[\n\\oint_\\mathcal{S} \\mathbf{E} \\cdot d\\mathbf{a} = \\int_\\mathcal{V} d^3\\mathbf{x} \\ \\nabla \\cdot \\mathbf{E} \\ .\n\\] Putting the two integrals together and moving everything to one side, we have \\[\n\\int_\\mathcal{V} d^3\\mathbf{x} \\ \\big[\\nabla \\cdot \\mathbf{E} - 4\\pi\\rho\\big] = 0 \\ .\n\\] Since this integral must vanish for any valid integrand we must have \\[\n\\boxed{\n\\nabla \\cdot \\mathbf{E} = 4\\pi\\rho\n} \\ .\n\\] This result is known as the differential form of Gauss’s Law. It’s the main thing we sought to derive in this section. It gives us an expression for the divergence of the electric field in terms of the source charge distribution.\n\n\nExamples\nGauss’s Law can sometimes be very convenient to directly find the electric field in situations where the charge distribution has a high level of symmetry. As we’ve shown, as long as two closed surfaces contain the same charge distribution they will also have the same flux. What we can thus do is use this freedom to choose a Gaussian surface that simplifies the problem. The simplest thing we could imagine doing is to choose a Gaussian surface such that \\(|\\mathbf{E}|\\) is constant along the surface. In that case, we’d have \\[\n\\oint_\\mathcal{S} \\mathbf{E} \\cdot d\\mathbf{a} = |\\mathbf{E}| A \\ ,\n\\] where \\(A\\) is the total surface area of \\(\\mathcal{S}\\). Then the integral form of Gauss’s Law simplifies greatly to \\[\n|\\mathbf{E}| = \\frac{4\\pi Q_{\\text{enc}}}{A} \\ .\n\\] For this to work though the charge distribution really needs to have a high level of symmetry. There are essentially three situations where we can do this: for infinite lines of charge, infinite sheets of charged, and charged spheres. Let’s look at each.\n\nExample: Infinite line of Uniform Charge\nConsider a line of charge of infinite length and infinitesimal width, so we can treat the line as one-dimensional. We’ll suppose the line is oriented along the \\(z\\)-axis and carries a constant charge per unit length of \\(\\lambda\\)​. Our goal is to find its electric field. We could do this the hard way as before, but in this case we can do it much more easily using Gauss’s Law, so that’s what we’ll do.\n\n\n\n\n\nBy symmetry, the electric field should depend only on the cylindrical radius \\(\\varrho\\). To see why, pick a random field point in the \\(xy\\)-plane. Now pick a random source point at a height \\(z'\\) along the wire. Then there must also be an opposite source point at a height \\(-z'\\). If we add the two field vectors together, their \\(z\\)-components will cancel, leaving only a contribution in the \\(\\varrho\\)-direction. We thus must conclude that the electric field has the property that \\[\n\\mathbf{E}(\\mathbf{x}) = E(\\varrho) \\mathbf{e}_\\varrho \\ .\n\\] All that remains thus is to find \\(E(\\varrho)\\). Now, the electric field must be constant along cylinders of constant \\(\\varrho\\). This means we have a natural Gaussian surface on which to apply Gauss’s Law. We’ll choose cylinders of radius \\(\\varrho\\) and length \\(z\\) centered on the wire. Since only the sides of the cylinder contribute to the flux, we need only consider the area of the sides of the cylinder, ignoring the two caps. This means the flux of the field is \\[\n\\oint_\\mathcal{S} \\mathbf{E} \\cdot d\\mathbf{a} = |\\mathbf{E}| A = E(\\varrho) \\cdot 2\\pi \\varrho z\n\\] Inside this cylinder, the enclosed charge is \\(Q_{\\text{enc}} = \\lambda z\\). Applying Gauss’s Law, we thus have \\[\nE(r) \\cdot 2\\pi \\varrho z = 4\\pi \\lambda z \\ .\n\\] Solving for \\(E(\\varrho)\\), we finally have \\[\nE(\\varrho) = \\frac{2\\lambda}{\\varrho} \\ .\n\\] Thus, the electric field of an infinitely long wire of uniform charge is inversely proportional to its distance from the wire. Notice that this seems to contradicts Coulomb’s Law, which predicts that far away from the wire the electric field should go like the inverse square of the distance. Why the contradiction? This comes from our assumption that the wire was infinitely long. If the wire had only a finite length, we would indeed recover Coulomb’s Law in the far field limit.\n\n\nExample: Infinite sheet of uniform charge\nWe’ll now consider not an infinite line of uniform charge, but an infinite flat sheet of uniform charge. We’ll suppose this sheet is oriented in the \\(xy\\)-plane and has infinitesimal thickness, so we can treat the sheet as 2-dimensional with a constant surface charge density \\(\\sigma\\)​.\n\n\n\n\n\nBy symmetry, we’ll argue that the electric field must always point away from the sheet in the \\(z\\) direction. To see why, pick a random field point at a height \\(z\\) above (or below) the sheet, centered at the origin. Pick a random source point \\((r',\\varphi')\\) along the sheet. Now, there must be an opposite source point at \\((r',\\varphi'+\\pi)\\) for which the two field vectors will cancel in all but the \\(z\\)-direction. This means \\[\n\\mathbf{E}(\\mathbf{x}) = \\pm E(z) \\mathbf{e}_z \\ .\n\\] All that thus remains is to find \\(E(z)\\). Clearly this field is constant along surfaces of constant \\(z\\). This means that any Gaussian surface with a flat top and bottom will do, since only the field through the top and bottom of the surface contribute anything to the flux. Such a surface is historically called a pillbox. Examples of pillboxes include prisms and cylinders. All that matters is that the top and bottom are flat, and the sides are perpendicular to the sheet. We’ll thus choose any pillbox with equal top and bottom areas \\(A\\) and some arbitrary height, as shown in the figure.\nSince the field is constant on the top and bottom of the Gaussian surface and only points in the \\(z\\)-direction, the flux is given by \\[\n\\oint_\\mathcal{S} \\mathbf{E} \\cdot d\\mathbf{a} = |\\mathbf{E}| \\cdot 2A = E(z) \\cdot 2 A \\ .\n\\] The pillbox encloses a charge given by \\(Q_{\\text{enc}} = \\sigma A\\). Plugging these into Gauss’s Law and solving for \\(E(z)\\), we finally have \\[\nE(z) = 2\\pi\\sigma \\ .\n\\] That is, the electric field strength of an infinite sheet of uniform charge is constant, no matter how far away from the surface we are, with the only difference being the direction (pointing above or below the surface). Yet again this seems to contradict Coulomb’s Law, since the field would still be constant infinitely far from the sheet. This can be rectified, however, by noting that the sheet chosen is infinite in extent. For a finite sheet, Coulomb’s Law would still hold in the far field limit.\n\n\nExample: Sphere with uniform charge\nAs our final example in this section we’ll consider an example we’ve already seen, the uniformly charged sphere. In a previous section we worked out its electric field with great pain. Here we’ll show that Gauss’s Law gives a much simpler way. We’ll again suppose that the charge lies on a hollow sphere of radius \\(R\\)​ centered at the origin.\n\n\n\n\n\nAs argued before, symmetry requires that the electric field point in the radial \\(r\\)-direction, with \\[\n\\mathbf{E}(\\mathbf{x}) = E(r) \\mathbf{e}_r \\ .\n\\] All that thus remains is to find \\(E(r)\\). Since the field is constant along spheres of radius \\(r\\), the natural choice is of Gaussian surface is to choose spheres of radius \\(r\\) centered at the origin. We’ll first suppose \\(r \\geq R\\)​. In that case, the flux is given by \\[\n\\oint_\\mathcal{S} \\mathbf{E} \\cdot d\\mathbf{a} = E(r) \\cdot 4\\pi r^2 \\ .\n\\] The enclosed charge \\(Q_{\\text{enc}}\\) is just the total charge of the sphere, \\(Q = \\frac{4}{3} \\pi R^3 \\sigma\\). Plugging these into Gauss’s Law, we have \\[\nE(r) = \\frac{Q}{r^2} \\ .\n\\] This of course is exactly what we expected. The electric field of a uniformly charged sphere behaves as a point charge outside the sphere. What does Gauss’s Law say when we’re inside the sphere though? In that case there’s no enclosed charge, so \\(Q_{\\text{enc}} = 0\\). This means Gauss’s Law just gives exactly what we’ve already shown, that there’s no electric field inside the sphere, \\[\nE(r) = 0 \\ .\n\\] What if the sphere is now solid instead of hollow, with a constant charge density \\(\\rho\\)? Outside the sphere the result is the same. Inside the sphere though the enclosed charge will be the volume of the Gaussian surface times the charge density, which is just \\(Q(r) = \\frac{4}{3} \\pi r^3 \\rho\\). Plugging this into Gauss’s Law, we have \\[\nE(r) = \\frac{Q(r)}{r^2} = \\frac{4\\pi\\rho}{3} r \\ .\n\\] That is, inside of a uniformly charged solid sphere the electric field is linear in the radius. When \\(r=R\\)​ of course this will equal the equation for the field outside the sphere, where the field will start to decrease as an inverse square law.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Electrostatics</span>"
    ]
  },
  {
    "objectID": "electrodynamics/electrostatics.html#scalar-potential",
    "href": "electrodynamics/electrostatics.html#scalar-potential",
    "title": "Electrostatics",
    "section": "Scalar Potential",
    "text": "Scalar Potential\nRecall that we’re trying to find a way to fully characterize the electric field with a set of field equations. We know it’s sufficient for this purpose to find formulas for the divergence and curl of the field in terms of the source charges. We just found a formula for the divergence, which gave us Gauss’s Law. We’ll now see what the curl of the electric field should be and see what that implies.\n\nCurl of Electric Field\nFrom vector calculus, we know that finding the curl of a vector field is in some sense equivalent to finding the line integral of the field around a closed path. More formally, Stoke’s theorem says that if \\(\\mathcal{C}\\) is some closed loop with interior surface \\(\\mathcal{S}\\), we have \\[\n\\oint_\\mathcal{C} \\mathbf{E} \\cdot d\\boldsymbol{\\ell} =  \\int_\\mathcal{S} (\\nabla \\times \\mathbf{E}) \\cdot d\\mathbf{a} \\ .\n\\] What we’ll thus do is first find the line integral and from that get the curl. As we did with Gauss’s Law, we’ll start with the simplest case of a point charge \\(q\\) centered at the origin. This means we have \\[\n\\mathbf{E} \\cdot d\\boldsymbol{\\ell} = \\frac{q}{r^2} \\mathbf{e}_r \\cdot d\\boldsymbol{\\ell} = \\frac{q}{r^2} dr \\ .\n\\] Here we used the fact that in spherical coordinates the line element is \\(d\\boldsymbol{\\ell} = dr \\mathbf{e}_r + rd\\theta \\mathbf{e}_\\theta + r \\sin\\theta d\\varphi \\mathbf{e}_\\varphi\\). This means that between any two points on the line \\(\\mathbf{a}\\) and \\(\\mathbf{b}\\) we have \\[\n\\int_\\mathbf{a}^\\mathbf{b} \\mathbf{E} \\cdot d\\boldsymbol{\\ell} = \\frac{q}{|\\mathbf{a}|} - \\frac{q}{|\\mathbf{b}|} \\ .\n\\] In particular, if we integrate around a closed loop \\(\\mathcal{C}\\) we must conclude that the line integral vanishes. The line integral over a closed loop is often called the circulation integral. It represents the total contribution of the field in moving around the closed loop, or equivalently the work per unit charge done in moving around the closed loop. Evidently for a point charge this circulation integral must be zero.\nOf course, there is nothing special about a point charge. By the principle of superposition we can consider any arbitrary distribution of charges as well by summing the contribution of each of the point charges inside. We thus conclude that for any distribution of charge giving rise to a total electric field \\(\\mathbf{E}\\) the circulation integral must vanish in electrostatics, \\[\n\\boxed{\n\\oint_\\mathcal{C} \\mathbf{E} \\cdot d\\boldsymbol{\\ell} = 0\n} \\ .\n\\] We can recover the curl of the field by apply Stoke’s theorem, from which we immediately see that the curl vanishes as well, \\[\n\\boxed{\n\\nabla \\times \\mathbf{E} = \\mathbf{0}\n} \\ .\n\\] Note that this was perhaps a long-winded way of saying something that should already be obvious to us: We know from classical mechanics that any conservative force has the property that its curl vanishes. Since the Coulomb force is a central force we know it must be conservative, and hence its curl must vanish, but since the electric field is just force per unit charge, its curl must vanish as well, which is what we just proved.\n\n\nScalar Potential\nFrom vector calculus, we know that any vector field whose curl vanishes must be the gradient of some scalar field. This follows from the fact that the circulation integral vanishes, and hence the line integral between any two points must be path independent and hence a well defined function of the two endpoints. If we call this scalar field \\(\\phi\\), this means we have \\[\n\\boxed{\n\\mathbf{E} = - \\nabla \\phi\n}\\ .\n\\] Note the minus sign is merely a convention. We’ll see why we include this in a moment. In electromagnetism we call \\(\\phi\\) the scalar potential, or more simply the potential depending on the context. The units of scalar potential are evidently energy per unit charge. In SI units the scalar potential has units of volts, or Joules per Coulomb. In Gaussian units the potential has units of ergs per ESU, sometimes called the statvolt, with \\(1 \\ \\frac{\\text{erg}}{\\text{esu}} \\approx 300 \\ \\text{V}\\).\nUsing the fundamental theorem of calculus we can invert the previous formula to get the potential in terms of the field. If \\(\\mathbf{x}\\) is the field point of interest and \\(\\mathbf{g}\\) is some fixed reference point, often called the ground point, we have \\[\n\\phi(\\mathbf{x}) = -\\int_\\mathbf{g}^\\mathbf{x} \\mathbf{E} \\cdot d\\boldsymbol{\\ell} \\ .\n\\] In much of theoretical electromagnetism we choose the ground point to be at infinity, where we insist the scalar potential must vanish for localized charge distributions. In this scenario, we then have \\[\n\\phi(\\mathbf{x}) = \\int_\\mathbf{x}^\\infty \\mathbf{E} \\cdot d\\boldsymbol{\\ell} \\ .\n\\] If \\(\\mathbf{a}\\) and \\(\\mathbf{b}\\) are two points in space, the potential between them, or potential difference, is given by \\[\n\\phi(\\mathbf{b}) - \\phi(\\mathbf{a}) = -\\int_\\mathbf{a}^\\mathbf{b} \\mathbf{E} \\cdot d\\boldsymbol{\\ell} \\ .\n\\] The potential difference is often called the voltage in more applied fields since it’s measured in volts, often denoted by \\(V\\) or \\(\\Delta V\\) when the context is clear. The voltage is what is typically measured in the lab, for example by differencing the potential between the positive and negative terminals of some power source.\nNotice that the integral formula for the scalar potential looks an awful lot like the formula for work in terms of force. Recall that the work done in moving a particle from a point \\(\\mathbf{a}\\) to a point \\(\\mathbf{b}\\) via an exerted force \\(\\mathbf{F}_{\\text{ex}}\\) is given by \\[\nW = \\int_\\mathbf{a}^\\mathbf{b} \\mathbf{F}_{\\text{ex}} \\cdot d\\boldsymbol{\\ell} \\ .\n\\] Since the force one must exert to move against the field is just minus the force generated by the field itself, we must evidently have \\(\\mathbf{F}_{\\text{ex}} = -q\\mathbf{E}\\). Plugging this in and factoring out the charge from both sides, we can see that the work done is proportional to the potential difference between the two points, \\[\nW = -q \\int_\\mathbf{a}^\\mathbf{b} \\mathbf{E} \\cdot d\\boldsymbol{\\ell} = q \\big[\\phi(\\mathbf{b}) - \\phi(\\mathbf{a})\\big] \\ .\n\\] This means we can think of the scalar potential as the work done in moving a unit charge from infinity to its current location in the presence of an external electric field \\(\\mathbf{E}\\). Indeed, this is why we include the minus sign in the definition of the scalar potential as \\(\\mathbf{E} = - \\nabla \\phi\\)​, to ensure that the potential has the same sign as the work done on the charge.\nProvided we set the ground point at infinity, the work done in moving the charge from infinity to some location \\(\\mathbf{x}\\) must evidently be \\(W = q\\phi(\\mathbf{x})\\). This is of course just the potential energy \\(U\\), provided we define \\(U(\\infty)\\equiv 0\\). Thus, for a point charge moving in the presence of an external field, its potential energy is just \\(U = q\\phi\\). For a general charge distribution we need only use the superposition principle to replace the charge \\(q\\) by a volume integral over the charge density \\(\\rho(\\mathbf{x})\\), in which case we have \\[\n\\boxed{\nU = \\int d^3 \\mathbf{x} \\ \\rho(\\mathbf{x}) \\phi(\\mathbf{x})\n} \\ .\n\\] Remember, this is only true for charges moving in the presence of an external electric field. This is not true for the charges used to assemble the distribution giving rise to the field itself. We’ll see what that potential energy must be momentarily.\n\nExample: Hollow sphere with uniform charge\nLet’s now try to calculate the scalar potential for the uniformly charged hollow sphere. Since we already know what the electric field should be, all we need to do is calculate the line integral. Recall the electric field for a uniformly charged hollow sphere of radius \\(R\\) and charge \\(Q\\) centered at the origin is given by \\[\n\\mathbf{E}(\\mathbf{x}) =\n\\begin{cases}\n\\mathbf{0} \\ , & r &lt; R \\ , \\\\\n\\frac{Q}{r^2} \\mathbf{e}_r \\ , & r \\geq R \\ . \\\\\n\\end{cases}\n\\] To find the potential at a given field point \\(\\mathbf{x}\\) we need to integrate from \\(\\mathbf{x}\\) to infinity. Since the field is radially symmetric, we can write \\(\\mathbf{E} \\cdot d\\boldsymbol{\\ell} = E(r) dr\\). When the field point lies outside the sphere \\(r \\geq R\\), and we get \\[\n\\begin{align*}\n\\phi(\\mathbf{x}) &= \\int_\\mathbf{x}^\\infty \\mathbf{E} \\cdot d\\boldsymbol{\\ell} \\\\\n&= Q \\int_r^\\infty \\frac{dr}{r^2} \\\\\n&= \\frac{Q}{r} \\ .\n\\end{align*}\n\\] For field points inside the sphere we have to integrate the field inside the sphere as well. When \\(r &gt; R\\) we get \\[\n\\begin{align*}\n\\phi(\\mathbf{x}) &= \\int_\\mathbf{x}^\\infty \\mathbf{E} \\cdot d\\boldsymbol{\\ell} \\\\\n&= \\int_r^R dr \\ 0 + Q \\int_R^\\infty \\frac{dr}{r^2} \\\\\n&= \\frac{Q}{R} \\ .\n\\end{align*}\n\\] Thus, the potential for a solid sphere is evidently given by \\[\n\\phi(\\mathbf{x}) =\n\\begin{cases}\n\\frac{Q}{R} \\ , & r &lt; R \\ , \\\\\n\\frac{Q}{r} \\ , & r \\geq R \\ . \\\\\n\\end{cases}\n\\] We can verify we got the correct answer if we wish by taking the gradient to recover the field. For example, outside the sphere we have \\[\n\\mathbf{E}(\\mathbf{x}) = -\\nabla \\phi(\\mathbf{x}) = - \\frac{d}{dr} \\frac{Q}{r} \\mathbf{e}_r = \\frac{Q}{r^2} \\mathbf{e}_r \\ .\n\\] Notice that while the electric field is zero inside the sphere, the potential is not. It’s a constant value throughout. Also notice that the two sides match at \\(r=R\\), meaning the potential is continuous even though the field is not at \\(r=R\\).\n\n\nExample: Solid sphere with uniform charge\nWe can also calculate the potential of the solid sphere if we wish. Outside the sphere the result is the same. Inside the sphere we have to use the fact that the field is no longer zero, but linear in \\(r\\), with \\(\\mathbf{E}(\\mathbf{x}) = \\frac{Qr}{R^3} \\mathbf{e}_r\\). When \\(r &lt; R\\) we thus have \\[\n\\begin{align*}\n\\phi(\\mathbf{x}) &= \\int_\\mathbf{x}^\\infty \\mathbf{E} \\cdot d\\boldsymbol{\\ell} \\\\\n&= \\frac{Q}{R^3} \\int_r^R dr \\ r + Q \\int_R^\\infty \\frac{dr}{r^2} \\\\\n&=  \\frac{Q}{R^3} \\bigg(\\frac{R^2}{2} - \\frac{r^2}{2}\\bigg) + \\frac{Q}{R} \\\\\n&= \\frac{Q}{2R} \\bigg(3 - \\frac{r^2}{R^2}\\bigg) \\ .\n\\end{align*}\n\\] Thus, for a solid sphere the potential is evidently given by \\[\n\\phi(\\mathbf{x}) =\n\\begin{cases}\n\\frac{Q}{2R}\\bigg(3 - \\frac{r^2}{R^2}\\bigg) \\ &, & r &lt; R \\ , \\\\\n\\frac{Q}{r} \\ &, & r \\geq R \\ . \\\\\n\\end{cases}\n\\] Again, the potential is continuous at \\(r=R\\). In fact so is its gradient since the field is also continuous at \\(r=R\\).\n\n\nExample: Infinite sheet with uniform charge\nLet’s briefly work an example involving an infinite charge distribution. We’ll choose the uniformly charged infinite sheet. In this case we can no longer take infinity as the ground point. Instead we’ll choose \\(\\mathbf{g} = \\mathbf{0}\\) as the ground point. Recall for the infinite sheet the electric field for \\(z \\geq 0\\) is given by \\(\\mathbf{E}(\\mathbf{x}) = 2\\pi\\sigma \\mathbf{e}_z\\). This means \\(\\mathbf{E} \\cdot d\\boldsymbol{\\ell} = E(z) dz\\), and so we have \\[\n\\phi(\\mathbf{x}) = -\\int_\\mathbf{0}^\\mathbf{x} \\mathbf{E} \\cdot d\\boldsymbol{\\ell} = -2\\pi\\sigma \\int_0^z dz = -2\\pi\\sigma z \\\n\\] One can quickly check that we’d get the same result when \\(z &lt; 0\\). Thus, the potential for the infinite sheet is just \\[\n\\phi(\\mathbf{x}) = -2\\pi\\sigma z \\ ,\n\\] which is what we’d expect since its gradient must be constant.\n\n\n\nIntegral Formula\nWe’ll now see what Coulomb’s Law looks like in terms of the scalar potential. In the previous chapter we proved the identity \\[\n\\nabla \\frac{1}{|\\mathbf{x} - \\mathbf{x}'|} = -\\frac{\\mathbf{x} - \\mathbf{x}'}{|\\mathbf{x} - \\mathbf{x}'|^3} \\ .\n\\] Multiplying both sides by the charge density \\(-\\rho(\\mathbf{x}')\\) and integrating over \\(\\mathbf{x}'\\), we have \\[\n-\\nabla \\int d^3 \\mathbf{x}' \\ \\frac{\\rho(\\mathbf{x}')}{|\\mathbf{x} - \\mathbf{x}'|} = \\int d^3 \\mathbf{x}' \\ \\rho(\\mathbf{x}') \\frac{\\mathbf{x} - \\mathbf{x}'}{|\\mathbf{x} - \\mathbf{x}'|^3} \\ .\n\\] Recognizing that the righthand side is just the electric field and matching with the formula \\(\\mathbf{E} = - \\nabla \\phi\\), we thus have \\[\n\\boxed{\n\\phi(\\mathbf{x}) = \\int d^3 \\mathbf{x}' \\ \\frac{\\rho(\\mathbf{x}')}{|\\mathbf{x}-\\mathbf{x}'|}\n}\\ .\n\\] This is the generalized form of Coulomb’s Law expressed for the scalar potential. Note by replacing \\(d^3 \\mathbf{x}' \\ \\rho(\\mathbf{x}')\\) with \\(da \\ \\sigma(\\mathbf{x}')\\) or \\(d\\ell \\ \\lambda(\\mathbf{x}')\\) we can get the equivalent integrals for the potential of surface or line charge distributions. Do be advised, however, that these formulas only hold for localized charge distributions. For charge distributions that extend to infinity we may need to modify these equations, for example by choosing a different ground point than infinity for our calculations.\nWe can use this formula to calculate the potential directly from the charge density itself rather than having to first calculate the electric field. Indeed this is extremely useful. Recall for the electric field we needed to calculate three integrals, one for each component. Since the potential is a scalar we only need to calculate a single integral without needing to worry about the vector \\(\\mathbf{x} - \\mathbf{x}'\\) at all. Once we have the potential, we can easily calculate the electric field.\nBefore working a few examples, let’s try to get a visual understanding of what the potential of a charge distribution looks like. We already have an idea how to visualize the electric field of a distribution using field lines. Since the field is just the gradient of the potential, we know from vector calculus that the field must always point perpendicular to surfaces of constant potential. These constant potential surfaces are called equipotentials. Indeed, it’s just as easy to draw equipotentials as it is to draw field lines. For example, the equipotential surfaces of a point charge are shown in the figure below.\nFIGURE\nLet’s now work some examples to show how much nicer this integral formula is to use than the one for the electric field.\n\nExample: Finite wire with uniform charge\nLet’s find the potential of a uniformly charged wire of finite length. Suppose a wire of length \\(L\\) has a uniform charge \\(Q = \\lambda L\\). We’ll assume that it is oriented along the \\(z\\)-axis with its center at the origin.\n\n\n\n\n\nAssuming the wire has negligible thickness we can use the \\(1\\)-dimensional version of the integral formula for the potential, \\[\n\\phi(\\mathbf{x}) = \\int d\\ell' \\ \\frac{\\lambda(\\mathbf{x}')}{|\\mathbf{x} - \\mathbf{x}'|} \\ .\n\\] Since \\(\\lambda\\) is constant along the wire and the wire is centered on the \\(z\\)-axis we can set \\(d\\ell' = dz'\\) and write the integral as \\[\n\\phi(\\mathbf{x}) = \\lambda \\int_{-L/2}^{L/2} \\frac{dz'}{|\\mathbf{x} - \\mathbf{x}'|} \\ .\n\\] All that remains now is to find \\(\\xi = |\\mathbf{x} - \\mathbf{x}'|\\). We’ll work in cylindrical coordinates. Since each source point is along the \\(z\\)-axis we can write \\(\\mathbf{x}' = z' \\mathbf{e}_z\\). For the field point we’ll write \\(\\mathbf{x} = \\varrho \\mathbf{e}_\\varrho + z \\mathbf{e}_z\\), where \\(r\\) is the radial cylindrical coordinate. This means we have \\[\n\\xi^2 = \\varrho^2 + (z - z')^2 \\ .\n\\] Plugging this into the integral for the potential, we’re left to evaluate the following integral, \\[\n\\phi(\\mathbf{x}) = \\lambda \\int_{-L/2}^{L/2} \\frac{dz}{\\sqrt{\\varrho^2 + (z - z')^2}} \\ .\n\\] We can evaluate this integral by making the substitution \\(x = \\frac{z - z'}{\\varrho}\\) and \\(dx = -\\frac{z'}{\\varrho}\\) to get \\[\n\\phi(\\mathbf{x}) = -\\lambda \\int_{\\frac{z+L/2}{\\varrho}}^{\\frac{z-L/2}{\\varrho}} \\frac{dx}{\\sqrt{1 + x^2}} = -\\lambda \\log(\\sqrt{1 + x^2} + x) \\bigg |_{x=\\frac{z+L/2}{\\varrho}}^{\\frac{z-L/2}{\\varrho}} \\ .\n\\] Evaluating the endpoints and simplifying a bit, we get \\[\n\\phi(\\mathbf{x}) = \\lambda \\log\\bigg[\\frac{\\sqrt{\\varrho^2 + (z + L/2)^2} - (z - L/2)}{\\sqrt{\\varrho^2 + (z - L/2)^2} - (z + L/2)}\\bigg] \\ .\n\\] This is the full potential in terms of a general field point \\(\\mathbf{x}\\) in cylindrical coordinates. We still don’t easily have an idea what this potential looks like. Let’s try to find its equipotentials. To do that we’ll need to introduce elliptical coordinates. Define \\[\n\\begin{align*}\nu &= \\frac{1}{2} \\bigg( \\sqrt{\\varrho^2 + (z + L/2)^2} + \\sqrt{\\varrho^2 + (z - L/2)^2}\\bigg)  \\ , \\\\\nv &= \\frac{1}{2} \\bigg( \\sqrt{\\varrho^2 + (z + L/2)^2} - \\sqrt{\\varrho^2 + (z - L/2)^2}\\bigg) \\ .\\\\\n\\end{align*}\n\\] If we plug these new coordinates into the potential and simplify, a little tedious algebra will show that the potential is given by \\[\n\\phi(\\mathbf{x}) = \\lambda \\log\\bigg[\\frac{u + L/2}{u - L/2}\\bigg] \\ .\n\\] Now, we can immediately see from this result that the equipotentials will be the curves such that \\(u\\) is constant. Though perhaps not obvious, the constant surfaces of \\(u\\) are ellipsoids of revolution about the \\(z\\)-axis. This means that the equipotentials are just ellipsoids. This should be intuitively obvious. Since the wire has a uniform charge, its equipotentials should be surfaces of constant distance from the wire, which would be ellipsoids. These equipotentials are shown in the figure below.\nFIGURE\nWe can further verify the correctness of this result by considering two limits: the infinite wire limit where \\(|\\mathbf{x}| \\ll L\\), and the far field limit where \\(|\\mathbf{x}| \\gg L\\). In the infinite wire limit we have \\(\\varrho, z \\ll L\\). In that limit we can neglect \\(z\\) and use the binomial approximation then to write \\[\n\\phi(\\mathbf{x}) \\approx \\lambda \\log\\bigg[\\frac{\\sqrt{\\varrho^2 + (L/2)^2} + L/2}{\\sqrt{\\varrho^2 + (L/2)^2} - L/2}\\bigg] \\approx \\lambda \\log\\bigg[\\frac{L/2 + L/2}{L/2 - L/2 + 2\\varrho^2/L}\\bigg] \\approx \\lambda \\log \\frac{L^2}{2\\varrho^2} \\ .\n\\] Simplifying this expression a bit, we get \\[\n\\phi(\\mathbf{x}) \\approx -2\\lambda \\log \\frac{\\varrho}{L} - \\lambda \\log 2 \\ .\n\\] To verify whether this is correct we can take its gradient to recover the electric field, in which case we get \\[\n\\mathbf{E}(\\mathbf{x}) \\approx - \\frac{\\partial \\phi}{\\partial \\varrho} \\mathbf{e}_r \\approx \\frac{2\\lambda}{\\varrho} \\mathbf{e}_\\varrho \\ .\n\\] This is of course exactly what we should expect for an infinite wire of uniform charge, as we’ve derived before.\nIn the far field limit we have \\(r, z \\gg L\\). For convenience let’s suppose \\(z=0\\). In that case, we can neglect the \\(L/2\\) terms inside the roots and use the Taylor series approximation \\(\\log(1+x) \\approx x\\) when \\(x\\) is small to write \\[\n\\phi(\\mathbf{x}) \\approx \\lambda \\log\\bigg[\\frac{\\sqrt{\\varrho^2 + (L/2)^2} + L/2}{\\sqrt{\\varrho^2 + (L/2)^2} - L/2}\\bigg] \\approx \\lambda \\log\\bigg[\\frac{\\varrho + L/2}{\\varrho - L/2}\\bigg] \\approx \\lambda \\log\\bigg[1 + \\frac{L}{\\varrho}\\bigg] \\approx \\frac{\\lambda L}{r} \\ .\n\\] Since \\(Q = \\lambda L\\) is just the total charge of the wire, we get the Coulomb potential \\(\\phi(\\mathbf{x}) = \\frac{Q}{r}\\) in the far field limit, as we’d expect.\n\n\n\nPoisson’s Equation\nWe’ve now found the following two field equations for the electric field of electrostatics, \\[\n\\begin{align*}\n\\nabla \\cdot \\mathbf{E} &= 4\\pi\\rho \\ , \\\\\n\\nabla \\times \\mathbf{E} &= \\mathbf{0} \\ .\n\\end{align*}\n\\] We can use the scalar potential to combine these two first-order field equations into a single second-order equation for the scalar potential. We’ve already shown the curl equation is equivalent to the formula \\(\\mathbf{E} = -\\nabla \\phi\\). Plugging this into Gauss’s Law, we get \\[\n\\nabla \\cdot \\mathbf{E} = \\nabla \\cdot (-\\nabla \\phi) = 4\\pi\\rho \\ .\n\\] Recognizing that this is just the Laplacian of the scalar potential, we thus have \\[\n\\boxed{\n\\nabla^2 \\phi = -4\\pi\\rho\n} \\ .\n\\] This second-order differential equation is called Poisson’s Equation. It’s fully equivalent to the two field equations we derived before. This means that instead of solving two vector first order differential equations to find the electric field, we need only solve Poisson’s equation subject to any boundary conditions and then take the gradient to get the electric field. Indeed, for this reason Poisson’s equation is perhaps the most important equation in electrostatics. It’s the most generally useful way to find the electric field of a charge distribution. We’ll spend considerable time analyzing and solving this equation in the next chapter.\nFor now, just observe that Coulomb’s Law is indeed a solution of Poisson’s equation. If we express Coulomb’s law as \\[\n\\mathbf{E}(\\mathbf{x}) = \\int d^3 \\mathbf{x}' \\ \\rho(\\mathbf{x}') \\frac{\\mathbf{x} - \\mathbf{x}'}{|\\mathbf{x} - \\mathbf{x}'|^3} \\ ,\n\\] then the Laplacian of the potential is given by \\[\n\\begin{align*}\n\\nabla^2 \\phi(\\mathbf{x}) &= -\\nabla \\cdot \\mathbf{E}(\\mathbf{x}) \\\\\n&= -\\nabla \\cdot \\int d^3 \\mathbf{x}' \\ \\rho(\\mathbf{x}') \\frac{\\mathbf{x} - \\mathbf{x}'}{|\\mathbf{x} - \\mathbf{x}'|^3} \\\\\n&= -\\int d^3 \\mathbf{x}' \\ \\rho(\\mathbf{x}') \\nabla \\cdot \\frac{\\mathbf{x} - \\mathbf{x}'}{|\\mathbf{x} - \\mathbf{x}'|^3} \\\\\n&= -\\int d^3 \\mathbf{x}' \\ \\rho(\\mathbf{x}') 4\\pi \\delta(\\mathbf{x} - \\mathbf{x}') \\\\\n&= -4\\pi \\rho(\\mathbf{x}) \\ .\n\\end{align*}\n\\] We’ve thus shown that Coulomb’s law satisfies Poisson’s equation, as we’d expect. In fact, if the charge distribution is localized and there are no boundary conditions present, like say a set of background conductors, then Coulomb’s law is the only valid solution. If boundary conditions are present we have to modify things slightly. We’ll see more on this in the next few chapters.\n\n\nSurfaces of Charge\nRecall from our discussion of Gauss’s Law that we saw something seemingly peculiar: The electric field of an infinite sheet of uniform charge is discontinuous at the surface. Below the surface the field is \\(\\mathbf{E} = -2\\pi\\sigma \\mathbf{e}_z\\), while above the surface the field is \\(\\mathbf{E} = +2\\pi\\sigma \\mathbf{e}_z\\). Evidently, crossing the surface causes the field to change discontinuously by an amount \\(\\Delta |\\mathbf{E}| = 4\\pi\\sigma\\).\nIn fact this is generally true for surfaces of charge. To see why, suppose \\(\\mathcal{S}\\) is some smooth surface of arbitrary shape carrying a surface charge density \\(\\sigma\\). Pick a point \\(\\mathbf{x}\\) on this surface. Since the field for a general surface can point in any direction, what we can do is decompose it into two components, one perpendicular to \\(\\mathcal{S}\\) and one parallel to \\(\\mathcal{S}\\)​, \\[\n\\mathbf{E} = \\mathbf{E}^\\perp + \\mathbf{E}^\\parallel \\ .\n\\] To deal with the perpendicular component, what we can do is apply Gauss’s Law just like we did with the infinite sheet. We’ll choose an infinitesimally high and very thin pillbox with top and bottom areas \\(\\delta A\\) as the Gaussian surface, where \\(\\delta A\\) is so small that any deviations in the curvature of the surface \\(\\mathcal{S}\\) are negligible inside the Gaussian surface. If \\(E_+\\) is the value of the field above the surface and \\(E_-\\) is the value of the field below the surface, by Gauss’s Law we must have \\[\n4\\pi\\sigma \\delta A = \\int \\mathbf{E} \\cdot d\\mathbf{a} \\approx (E_+^\\perp - E_-^\\perp) \\delta A \\ .\n\\] That is, the perpendicular component of the field again undergoes a discontinuous change of \\(4\\pi\\sigma\\) crossing the surface, \\[\nE_+^\\perp - E_-^\\perp = 4\\pi\\sigma \\ .\n\\] What about the parallel component? Suppose \\(\\mathcal{C}\\) is some small closed loop around the point \\(\\mathbf{x}\\) on the surface, so small the curvature of \\(\\mathcal{S}\\) is negligible. We’ve already seen that the circulation integral must be vanish. This means we have \\[\n0 = \\oint_\\mathcal{C} \\mathbf{E} \\cdot d\\boldsymbol{\\ell} \\approx (E_+^\\parallel - E_-^\\parallel) \\ell \\ .\n\\] From this we must conclude that the parallel component is indeed continuous on the surface, with \\(\\mathbf{E}_+^\\parallel = \\mathbf{E}_-^\\parallel\\). We can put these two results together by using the normal vector \\(\\mathbf{n}\\)​ to write \\[\n\\mathbf{E}_+ - \\mathbf{E}_- = 4\\pi\\sigma \\mathbf{n} \\ .\n\\] What about the scalar potential? In fact the potential is continuous across the surface of charge. To see why, suppose \\(\\mathbf{x}_-\\) is some point infinitesimally below the surface and \\(\\mathbf{x}_+\\) some other point infinitesimally above the surface. If the two points are separated by a distance \\(\\delta\\ell\\), the potential difference between these two points must be given by \\[\n\\phi_+ - \\phi_- = -\\int_{\\mathbf{x}_-}^{\\mathbf{x}_+} \\mathbf{E} \\cdot d\\boldsymbol{\\ell} \\approx -(E_+  + E_-) \\delta\\ell \\ .\n\\] Since the right-hand side is infinitesimal, we can conclude that the potential difference crossing the surface must be zero, \\[\n\\phi_+ = \\phi_- \\ .\n\\] Since we’ll be solving Poisson’s equation in the next few chapters, let’s go ahead and formulate these conditions as a set of boundary conditions for the potential and its gradient. For that purpose it’ll be convenient to express the condition for the electric field as a normal derivative of the potential. If we define the normal derivative by \\[\n\\frac{\\partial \\phi}{\\partial n} \\equiv \\nabla \\phi \\cdot \\mathbf{n} \\ ,\n\\] we can write the two boundary conditions for the potential across a surface of charge as \\[\n\\begin{align*}\n\\phi_+ - \\phi_- &= 0 \\ , \\\\\n\\frac{\\partial \\phi_+}{\\partial n} - \\frac{\\partial \\phi_-}{\\partial n} &= -4\\pi\\sigma \\ .\n\\end{align*}\n\\] Here it’s of course understood that \\(\\phi_+\\) and \\(\\phi_-\\) refer to points infinitesimally above and below the surface, respectively.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Electrostatics</span>"
    ]
  },
  {
    "objectID": "electrodynamics/electrostatics.html#field-energy",
    "href": "electrodynamics/electrostatics.html#field-energy",
    "title": "Electrostatics",
    "section": "Field Energy",
    "text": "Field Energy\nWe’ve already discussed the idea of potential energy in electrostatics. In particular, for a point charge \\(q\\) moving in the presence of an external electric field \\(\\mathbf{E}\\) that’s generated by some charge distribution \\(\\rho\\), its potential energy \\(U\\) is given by \\[\nU = \\int d^3 \\mathbf{x} \\ \\rho(\\mathbf{x}) \\phi(\\mathbf{x}) \\ .\n\\] This is not the only form of potential energy we can ask about however when it comes to a field. We can also ask a slightly different question: What is the work done required to assemble the source charge distribution to begin with, or equivalently, what is the potential energy stored in the source charge distribution?\nTo make a start at answering this question we’ll suppose the charge distribution is discrete, so that the total charge \\(Q\\) is just a sum of \\(N\\)​ point charges, \\[\nQ = \\int d^3 \\mathbf{x} \\ \\rho(\\mathbf{x}) \\approx q_1 + q_2 + \\cdots + q_N \\ .\n\\] We’ll suppose that initially all point charges are at infinity, separated from each other by an infinite distance. This means that initially there is no potential present in space. What we’ll now do is bring the point charges in from infinity one at a time and place them at their respective locations in space and calculate the work done, hence the potential energy, to assemble each charge in the presence of the charges already in place.\nFirst, suppose we bring in charge \\(q_1\\) from infinity and place it at its source point \\(\\mathbf{x}_1\\). Since there is no potential present initially, the work done to move this charge to \\(\\mathbf{x}_1\\) must evidently be zero. The work done is evidently thus \\(U_1 = 0\\).\nNow, with \\(q_1\\) in position we’ll bring in \\(q_2\\). Suppose we bring in \\(q_2\\) from infinity and place it at \\(\\mathbf{x}_2\\). This time, however, there is a potential generated by the presence of \\(q_1\\), \\[\n\\phi_1(\\mathbf{x}_2) = \\frac{q_1}{|\\mathbf{x}_2 - \\mathbf{x}_1|} \\ .\n\\] This means the work done to bring in charge \\(q_2\\) in the presence of \\(q_1\\) is \\[\nU_2 = q_2 \\phi_1(\\mathbf{x}_2) = q_2 \\frac{q_1}{|\\mathbf{x}_2 - \\mathbf{x}_1|} \\ .\n\\] With \\(q_1\\) and \\(q_2\\) in place we’ll now bring in \\(q_3\\) and place it at \\(\\mathbf{x}_3\\). This time there are now two potentials we need to deal with, the potentials of both \\(q_1\\) and \\(q_2\\). By superposition, the work done to bring in charge \\(q_3\\) must be \\[\nU_3 = q_3 \\phi_1(\\mathbf{x}_3) + q_3 \\phi_2(\\mathbf{x}_3) = q_3 \\bigg(\\frac{q_1}{|\\mathbf{x}_3 - \\mathbf{x}_1|} + \\frac{q_2}{|\\mathbf{x}_3 - \\mathbf{x}_1|}\\bigg) \\ .\n\\] Hopefully by now we can spot the pattern. If the first \\(i-1\\) charges \\(q_1, q_2, \\cdots, q_{i-1}\\) are already in place and we then bring in charge \\(q_i\\) from infinity and place it at position \\(\\mathbf{x}_i\\), the work done must be \\[\nU_i = q_i \\sum_{j&lt;i} \\phi_j(\\mathbf{x}_i) = q_i \\sum_{j=1}^{i-1} \\frac{q_j}{|\\mathbf{x}_i - \\mathbf{x}_j|} \\ .\n\\] Here the sum over \\(j &lt; i\\) means to sum from \\(j=1\\) to \\(j=i-1\\). This is to make sure we only sum over the point charges already in place, not the ones we haven’t brought in yet.\nNow, the total potential energy \\(\\mathcal{U}\\) to assemble all of these charges into place is just the sum of each of these contributions, \\[\n\\mathcal{U} = \\sum_{i=1}^N U_i = \\sum_{i=1}^N q_i \\sum_{j&lt;i} \\phi_j(\\mathbf{x}_i) \\ .\n\\] It’ll be useful to rewrite the sum over all \\(j &lt; i\\) in a slightly different way by observing that the potential is symmetric in \\(i\\) and \\(j\\), so that \\(\\phi_j(\\mathbf{x}_i) = \\phi_i(\\mathbf{x}_j)\\). This means we can write the same sum by summing over all \\(j \\neq i\\) and dividing by two to avoid double counting, \\[\n\\mathcal{U} = \\frac{1}{2} \\sum_{i=1}^N q_i \\bigg(\\sum_{\\substack{j=1 \\\\ j \\neq i}}^{N} \\phi_j(\\mathbf{x}_i)\\bigg) \\ .\n\\] Observe next that the interior sum is just the total potential exerted on charge \\(q_i\\) due to all other charges \\(q_j\\). Call this potential \\(\\phi(\\mathbf{x}_i)\\). We can now transition back to the continuum by making the replacement \\(\\sum q_i \\rightarrow \\int d^3 \\mathbf{x} \\ \\rho(\\mathbf{x})\\)​ to get \\[\n\\boxed{\n\\mathcal{U} = \\frac{1}{2} \\int d^3 \\mathbf{x} \\ \\rho(\\mathbf{x}) \\phi(\\mathbf{x})\n}\\ .\n\\] This is the potential energy stored in the entire charge distribution. Notice how similar it looks to the potential energy we derived before for a charge distribution in the presence of an external electric field, \\(U = \\int d^3 \\mathbf{x} \\ \\rho(\\mathbf{x}) \\phi(\\mathbf{x})\\). On the surface, the only difference between the two evidently is the factor of \\(\\frac{1}{2}\\). However, we must keep in mind that the \\(\\rho\\) used to find \\(\\mathcal{U}\\) is the source charge distribution, not an external charge distribution like the one used to find \\(U\\)​.\nWe can think of \\(\\mathcal{U}\\) as the potential energy stored in the source charge distribution, but we can also think of it equivalently as the potential energy stored in the electric field itself. To see why it’s helpful to rewrite the integral in a slightly different way. From Gauss’s Law, we know that \\(\\nabla \\cdot \\mathbf{E} = 4\\pi \\rho\\). Plugging this into the formula for \\(\\mathcal{U}\\) we have \\[\n\\mathcal{U} = \\frac{1}{8\\pi} \\int d^3\\mathbf{x} \\ \\phi \\nabla \\cdot \\mathbf{E} \\ .\n\\] As a brief aside, let’s recall the following vector calculus identity between a scalar field \\(f\\) and a vector field \\(\\mathbf{F}\\), \\[\n\\nabla (f \\mathbf{F}) = \\nabla f \\cdot \\mathbf{F} + f \\nabla \\cdot \\mathbf{F} \\ .\n\\] Rearranging terms and integrating over some volume \\(\\mathcal{V}\\), we have \\[\n\\begin{align*}\n\\int_\\mathcal{V} d^3\\mathbf{x} \\ f \\nabla \\cdot \\mathbf{F} &= \\int_\\mathcal{V} d^3\\mathbf{x} \\ \\nabla (f \\mathbf{F}) - \\int_\\mathcal{V} d^3\\mathbf{x} \\ \\nabla f \\cdot \\mathbf{F} \\\\\n&= \\oint_\\mathcal{S} f \\mathbf{F} \\cdot d\\mathbf{a} - \\int_\\mathcal{V} d^3\\mathbf{x} \\ \\nabla f \\cdot \\mathbf{F} \\ .\n\\end{align*}\n\\] In the last line we used the fundamental theorem of vector calculus to rewrite the volume integral over \\(\\nabla (f \\mathbf{F})\\) as an integral over \\(f \\mathbf{F}\\) evaluated at the volume’s surface \\(\\mathcal{S}\\). Now, if we send the volume to infinity, we can neglect the surface term so long as \\(f\\mathbf{F}\\) vanishes at infinity faster than \\(\\frac{1}{r^2}\\). This means if integrating over all space we’d simply have \\[\n\\int d^3\\mathbf{x} \\ f \\nabla \\cdot \\mathbf{F} = - \\int d^3\\mathbf{x} \\ \\nabla f \\cdot \\mathbf{F} \\ .\n\\] Let’s now apply this result to our integral expression for the field potential energy \\(\\mathcal{U}\\). Since \\(\\mathbf{E} = -\\nabla\\phi\\), we have \\[\n\\mathcal{U} = - \\frac{1}{8\\pi} \\int d^3\\mathbf{x} \\ \\nabla \\phi \\cdot \\mathbf{E} = \\frac{1}{8\\pi} \\int d^3\\mathbf{x} \\ \\mathbf{E} \\cdot \\mathbf{E} \\ .\n\\] Note that this will only be true if the boundary term vanishes. We can be sure this is true so long as the charge distribution is localized, since in that case we expect \\(\\phi \\mathbf{E} \\sim \\frac{1}{r^3}\\). It may not be true, however, for charge distributions that extend to infinity, in which case we’d have to be more careful with ignoring boundary term. Of course, such cases aren’t really physical anyway.\nAt any rate, we’ve derived the following interesting result, which says the potential energy stored in the source charge distribution depends only on the square of the electric field, \\[\n\\boxed{\n\\mathcal{U} = \\frac{1}{8\\pi} \\int d^3\\mathbf{x} \\ |\\mathbf{E}|^2\n}\\ .\n\\] This is why we can think of the potential energy \\(\\mathcal{U}\\) as the energy stored in the field. That’s all it depends on. It’ll be useful to give the integrand a name. It’s called the energy density \\(u(\\mathbf{x})\\). It’s the potential energy per unit volume stored in the electric field, \\[\nu(\\mathbf{x}) \\equiv \\frac{1}{8\\pi} |\\mathbf{E}(\\mathbf{x})|^2 \\ .\n\\] We’ll find the idea of energy density perhaps most useful in electrodynamics, where we’ll need to modify the above result to also account for magnetic field effects as well.\nNote that neither the field energy nor the energy density satisfy the principle of superposition since they’re quadratic in the field, not linear. For example, the energy density due to two fields \\(\\mathbf{E}\\) and \\(\\mathbf{E}'\\) would be given by \\[\nu = \\frac{1}{8\\pi} |\\mathbf{E} + \\mathbf{E}'|^2 = \\frac{1}{8\\pi}|\\mathbf{E}|^2 + \\frac{1}{8\\pi}|\\mathbf{E}'|^2 + \\frac{1}{8\\pi}\\mathbf{E} \\cdot \\mathbf{E}' \\ .\n\\] Last, it’s worth pointing out a very important but subtle issue that arises in going from \\[\n\\mathcal{U} = \\frac{1}{2} \\int d^3 \\mathbf{x} \\ \\rho(\\mathbf{x}) \\phi(\\mathbf{x}) \\ \\rightarrow \\ \\frac{1}{8\\pi} \\int d^3\\mathbf{x} \\ |\\mathbf{E}|^2 \\ .\n\\] The problem is that of self energy. According to Coulomb’s Law, a charge does not exert a force on itself. It only exerts a force on other charges. However, the second formula includes forces that a charge exerts on itself. To see why, consider the example of a point charge \\(q\\) centered at the origin. According to the second formula, we have \\[\n\\mathcal{U} = \\int d^3\\mathbf{x} \\ \\frac{1}{8\\pi} |\\mathbf{E}(\\mathbf{x})|^2 = \\int_0^\\infty 4\\pi r^2 dr \\ \\frac{1}{8\\pi} \\bigg(\\frac{q}{r^2}\\bigg)^2 = \\infty \\ .\n\\] However, if we use the first formula we get \\[\n\\mathcal{U} = \\frac{1}{2} \\int d^3\\mathbf{x} \\ \\rho(\\mathbf{x}) \\phi(\\mathbf{x}) = \\frac{1}{2} \\int_0^\\infty 4\\pi r^2 dr \\ q \\delta(\\mathbf{x}) \\frac{q}{r} = 0 \\ .\n\\] As we’ve defined the potential energy it’s the latter that should be correct. There’s no potential energy stored in a single point charge since no work was required to bring it in from infinity and place it at the origin. So what’s going on?\nWe made a subtle error of sorts when we transitioned from a sum over discrete charges to an integral over a charge distribution. Recall that in the sum version we used \\(j \\neq i\\) to enforce the requirement that a charge couldn’t affect itself. When we moved to the integral form though this distinction got lost. It turns out that this issue only affects the second formula though. In fact, it only affects distributions of point charges. For continuous distributions the formulas will generally agree.\nThis doesn’t necessarily mean, however, that the second formula is not correct. It’s just counting something that the first formula isn’t. Namely, it’s also counting the energy required to create the charges, not just assemble them in place. The first formula only counts the energy to assemble the charges, not create them. In this sense they’re both correct, they just mean slightly different things. Indeed, the second formula ties in with the question of whether empty space has energy, the so-called vacuum energy. This topic is a major issue in quantum electrodynamics. In classical dynamics we ignore this distinction, but we do occasionally have to be careful when subtleties like this arise.\n\nExample: Field energy of a hollow sphere\nRecall that the uniformly charged hollow sphere with radius \\(R\\) has an electric field given by \\[\n\\mathbf{E}(\\mathbf{x}) = \\frac{Q}{r^2} \\ \\mathbf{e}_r \\ ,\n\\] where \\(Q = 4\\pi R^2 \\sigma\\) when \\(r \\geq R\\) and zero otherwise. Thus, according to the second formula for the field energy we have \\[\n\\mathcal{U} = \\frac{1}{8\\pi}\\int d^3\\mathbf{x} \\ |\\mathbf{E}(\\mathbf{x})|^2 = \\frac{1}{8\\pi}\\int_R^\\infty 4\\pi r^2 dr \\ \\bigg(\\frac{Q}{r^2}\\bigg)^2 = \\frac{Q^2}{2R} \\ .\n\\] Since this isn’t a point charge, we should expect to get the same result with the first formula as well. Since this is a 2-dimensional distribution we need to replace \\(\\int d^3\\mathbf{x} \\ \\rho(\\mathbf{x})\\) with \\(\\int \\sigma(\\mathbf{x}) \\ da\\). At the surface of the sphere we have \\[\n\\phi(\\mathbf{x}) = \\frac{Q}{R} \\ .\n\\] Thus, integrating over the surface of the sphere we have \\[\n\\mathcal{U} = \\frac{1}{2} \\int \\sigma(\\mathbf{x}) \\phi(\\mathbf{x}) \\ da = \\frac{1}{2} \\int \\sigma \\frac{Q}{R} \\ da = \\frac{Q}{2R} 4\\pi R^2 \\sigma = \\frac{Q^2}{2R} \\ .\n\\] As we can see, the two results agree as expected.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Electrostatics</span>"
    ]
  },
  {
    "objectID": "electrodynamics/electrostatics.html#conductors-and-capacitance",
    "href": "electrodynamics/electrostatics.html#conductors-and-capacitance",
    "title": "Electrostatics",
    "section": "Conductors and Capacitance",
    "text": "Conductors and Capacitance\nElectromagnetic materials can often be thought of one of two types: conductors and insulators. Both are just materials composed of almost all neutral atoms, and hence charge neutral. They differ in one subtle way. Unlike insulators, conductors have a small fraction of unbound electrons that are unbound to their nuclei and free to move around the material, causing the material to conduct in the presence of an external field by moving its unbound electrons around. Insulators don’t have these unbound electrons. The only way an insulator can respond to an external field is by distorting its electron clouds. We’ll talk more about insulators in a future chapter. For now we’ll just focus on conductors, which are a bit easier to understand macroscopically.\n\nConductors\nSuppose we have a conductor with some given charge distribution. We place that conductor in the presence of an external electric field and wait for the system to come to electrostatic equilibrium. Once this happens, the electric field becomes time independent, and hence electrostatic. When this happens, the unbound electrons will move in the direction of the external field, creating an internal field inside the conductor of the same strength as the external field, but in opposite direction. The net result is that once the conductor is in electrostatic equilibrium, the net electric field will vanish. Thus, conductors will have the property that the electric field is zero inside the conductor.\nIn fact, if there is no electric field inside the conductor it must be the case that all the unbound electrons will reside on the surface of the conductor. Indeed, this follows immediately from Gauss’s Law. If there is no internal electric field in the conductor, then any Gaussian surface chosen inside the conductor must have \\(\\rho = 0\\)​. Thus, the only place left for the charge to go is on the surface, where it will distribute itself such that the internal field vanishes.\nThis also implies that the surface of a conductor must be an equipotential surface. Since the internal field is zero, we must have \\[\n\\phi(\\mathbf{b}) - \\phi(\\mathbf{a}) = -\\int_\\mathbf{a}^\\mathbf{b} \\mathbf{E} \\cdot d\\boldsymbol{\\ell} = 0\n\\] for any two points \\(\\mathbf{a}\\) and \\(\\mathbf{b}\\) on the surface of the conductor, meaning \\(\\phi(\\mathbf{a}) = \\phi(\\mathbf{b})\\) is constant on the surface. Since the surface of the conductor is an equipotential, this also means that the field lines at the surface must be perpendicular to the surface, since \\(\\mathbf{E} = -\\nabla \\phi\\)​ and we know that gradients are perpendicular to their equipotential surfaces.\n\n\n\n\n\nWe’ll find it convenient to express these results as a set of boundary conditions for conductors. Surface boundary conditions require that \\(\\mathbf{E}_+ - \\mathbf{E}_- = 4\\pi\\sigma \\mathbf{n}\\). Since the field inside the conductor is zero, \\(\\mathbf{E}_- = \\mathbf{0}\\). Thus, just outside the surface we must have \\[\n\\mathbf{E}_+ = 4\\pi\\sigma \\mathbf{n} \\ ,\n\\] or, in terms of the normal derivative of the potential, we must have \\[\n\\frac{\\partial\\phi}{\\partial n} = -4\\pi\\sigma \\ .\n\\] This gives us a way to find the surface charge on a conductor if we know the potential, something we’ll find useful later on.\n\n\nCapacitance\nWhen discussing conductors it’s typical to also discuss their capacitance, or ability to store charge. A conductor with this property is often called a capacitor. Suppose we have some conductor with charge \\(Q\\) and potential \\(V\\) relative to some ground point. Since its electric field must be proportional to \\(Q\\), so must the potential. This means we can write \\[\n\\boxed{\nQ = CV\n} \\ ,\n\\] where \\(C\\) is some proportionality constant, called the capacitance or self capacitance. This means we can also think of the capacitance as the amount of charge stored in a conductor held at unit potential.\nThe capacitance incapsulates all the geometric information encoded in the conductor needed to relate its charge to its potential. In Gaussian units this is obvious, since by dimensional analysis the capacitance must evidently carry units of length, or centimeters. In SI units, capacitance has units of Volts per Coulomb, called the Farad, with \\(1 \\ \\text{F} \\approx 9 \\cdot 10^{11} \\ \\text{cm}\\). An implication of this is that a Farad is a very large unit of capacitance. In laboratory settings, most capacitors have capacitances in the range of \\(10^{-12}\\) to \\(10^{-6}\\) Farads.\nAs a quick example, let’s consider a conducting sphere of radius \\(R\\) and total charge \\(Q\\). Since the potential inside the sphere is \\(\\frac{Q}{R}\\), we can easily see that \\(C = R\\), meaning the capacitance of a conducting sphere is just its radius.\nIn practice, it’s more common to talk about the capacitance between multiple conductors, usually two conductors. The combined set of conductors becomes the capacitor in this case. Suppose we have two conductors of opposite charge \\(Q\\) and \\(-Q\\) with a potential difference \\(V\\) between them. We again define the capacitance, or mutual capacitance, by the formula \\(Q = CV\\).\nThe classic example of a capacitor involving two conductors is two parallel conducting plates with area \\(A\\) and opposite charges \\(Q\\) and \\(-Q\\) separated by a distance \\(d\\). If we neglect the boundary of the plates by assuming \\(A \\gg d^2\\), their electric field strengths are approximately \\(|\\mathbf{E}| \\approx 2\\pi\\sigma\\). By superposition, the combined field will have a strength of \\(|\\mathbf{E}| = 4\\pi\\sigma\\) between the plates and zero outside the plates. This means the potential difference between the plates must be \\(V = 4\\pi\\sigma d\\).\nFIGURE\nSince the charges themselves must relate to \\(\\sigma\\) via the formula \\(Q = \\sigma A\\), we must have \\[\nQ = \\sigma A = 4\\pi\\sigma d C = CV \\ ,\n\\] which means the capacitance between the two plates is given by \\[\nC = \\frac{A}{4\\pi d} \\ .\n\\] Notice how the capacitance again captures the geometric properties of the conductors, namely the area of the sheets and the distance between them.\nCapacitors like the previous example are popular ways to store charge inside of electric circuits. The higher the capacitance, the more charge we say a capacitor can store at a given voltage. The capacitors used in practice usually aren’t parallel plates, but more complex designs like overlapping cylinders, but the same idea holds.\nWe can also derive a formula for the energy stored in a capacitor. We’ll focus on a single conductor, though the same results easily carry over to multiple conductors as well. Consider again a single conductor with total charge \\(Q\\) and potential \\(V\\). We’ve already shown that the energy stored in this conductor must be \\(\\mathcal{U} = \\frac{1}{2} QV\\). Using the fact that \\(Q = CV\\), we get \\[\n\\boxed{\n\\mathcal{U} = \\frac{1}{2} C V^2\n}\\ .\n\\] Thus, the energy stored in a capacitor is proportional to the capacitance and the square of the potential. A capacitor that can store more charge also stores more energy. Unlike, say batteries, however, capacitors can only store energy while they’re actively charged. If the capacitor discharges, for example by turning off its voltage source, it almost instantly dissipates all its energy.\n\nExample: Capacitance between two charged cylinders\nSuppose we have oppositely charged cylinders, one inside the other. The inner cylinder has a radius \\(a\\) and a charge \\(-Q\\), while the outer cylinder has a radius \\(b\\) and a charge \\(Q\\).\n\nFinish this example. See Griffiths or Greiner.\n\n\n\n\nMutual Capacitance\nThough less common, we can define the mutual capacitance between any number of conductors, not just two. Suppose we have \\(n\\) conductors with charges \\(Q_i\\) and potentials \\(V_i\\) relative to some ground. We can then write \\[\nQ_i = \\sum_{i=1}^n C_{i j} V_j \\ .\n\\] Here each coefficient \\(C_{ij}\\) is called the mutual capacitance between conductor \\(i\\) and conductor \\(j\\).\nWe can relate the mutual capacitance between two oppositely charged conductors with the previous definition of capacitance by setting \\(Q_1 = Q\\), \\(Q_2 = -Q\\), and \\(V = V_2 - V_1\\). It’s not hard to see that we get \\[\nC = \\frac{C_{11} V_1 + C_{12} V_2}{V_2 - V_1} = -\\frac{C_{12} V_1 + C_{22} V_2}{V_2 - V_1} \\ .\n\\] We don’t tend to use mutual capacitance as much in practice, nor will we see it again in this course.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Electrostatics</span>"
    ]
  },
  {
    "objectID": "electrodynamics/bvps-1.html",
    "href": "electrodynamics/bvps-1.html",
    "title": "Boundary Value Problems I",
    "section": "",
    "text": "Poisson’s Equation\nWe saw in the previous chapter that we can in principle calculate the scalar potential \\(\\phi\\) due to the presence of a localized charge distribution \\(\\rho\\) by evaluating the following integral, \\[\n\\phi(\\mathbf{x}) = \\int d^3 \\mathbf{x}' \\ \\frac{\\rho(\\mathbf{x}')}{|\\mathbf{x} - \\mathbf{x}'|} \\ .\n\\] In principle, this integral formula will work as long as the charge distribution is localized, there are no other sources of charge, and we’ve already specified in advance what the charge density \\(\\rho(\\mathbf{x}')\\) actually is. Unfortunately, in practice there are often other sources of charge present, and we often don’t know what the charge density is for those. For example, there may be background conductors or other charged materials present that are too difficult to model, but we know the potential on those surfaces. We can model situations like this by incorporating them into the problem as boundary conditions.\nRecall from the previous chapter that we can express the solution for the potential in an equivalent way to the integral given above via a partial differential equation (PDE) known as Poisson’s Equation, \\[\n\\nabla^2 \\phi = -4\\pi\\rho \\ .\n\\] As we can clearly see, Poisson’s equation is a linear, second-order PDE that depends only on spatial coordinates. Note that in the absence of source charges, Poisson’s equation reduces to another important equation we’ll study known as Laplace’s Equation, \\[\n\\nabla^2 \\phi = 0 \\ .\n\\] To solve Poisson’s equation, it’s sufficient to specify some set of boundary conditions, or conditions that the solution must satisfy on some given boundary surface \\(\\mathcal{S}\\). We imagine the charge distribution \\(\\rho\\) lies inside the surface \\(\\mathcal{S}\\), which may or may not be closed. On the surface, we know before-hand that some condition is satisfied, for example the value of the potential or the electric field on \\(\\mathcal{S}\\).\nA problem of this kind is known as a boundary value problem or BVP. The entire goal of this chapter and the next will be devoted to solving BVPs of this type in various ways. The first way we will do so is via Green’s function methods.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Boundary Value Problems I</span>"
    ]
  },
  {
    "objectID": "electrodynamics/bvps-1.html#greens-functions",
    "href": "electrodynamics/bvps-1.html#greens-functions",
    "title": "Boundary Value Problems I",
    "section": "Green’s Functions",
    "text": "Green’s Functions\nWe will now introduce the idea of a Green’s Function, which is a very useful and important concept in electromagnetism and many other field theories, as well as the theory of partial differential equations. We’ll see that the Green’s function provides a general method for solving Poisson’s equation, and indeed for solving any linear differential equation.\nWe already know that for a localized charge distribution in the absense of boundary conditions that the potential can be found by \\[\n\\phi(\\mathbf{x}) = \\int d^3 \\mathbf{x}' \\ \\frac{\\rho(\\mathbf{x}')}{|\\mathbf{x} - \\mathbf{x}'|} \\ .\n\\] If we look at this integral more closely we can see that it’s really just a convolution of two functions, \\(\\rho(\\mathbf{x}')\\) and another function \\[\n\\boxed{\nG(\\mathbf{x} - \\mathbf{x}') \\equiv \\frac{1}{|\\mathbf{x} - \\mathbf{x}'|}\n}\\ .\n\\] This function \\(G(\\mathbf{x} - \\mathbf{x}')\\) is called a Green’s Function. This function is evidently a property of the PDE itself, and doesn’t depend on any charge distributions or boundary conditions. So where does this function come from?\nSuppose we wanted to solve Poisson’s equation for a single unit point charge located at a source point \\(\\mathbf{x}'\\). Since \\(q=1\\) this means that \\(\\rho(\\mathbf{x}) = \\delta(\\mathbf{x} - \\mathbf{x}')\\). The potential \\(G(\\mathbf{x} - \\mathbf{x}')\\) that solves this Poisson’s equation in the absence of any boundary conditions is known as a Green’s function, \\[\n\\nabla^2 G(\\mathbf{x} - \\mathbf{x}') = -4\\pi \\delta(\\mathbf{x} - \\mathbf{x}') \\ .\n\\] Now, suppose as suggested above that we could recover the potential \\(\\phi\\) from the Green’s function by convolution with the charge density \\(\\rho\\), \\[\n\\phi(\\mathbf{x}) = \\int d^3 \\mathbf{x}' \\ \\rho(\\mathbf{x}') G(\\mathbf{x} - \\mathbf{x}') \\ .\n\\] If we take the Laplacian of \\(\\phi(\\mathbf{x})\\), we then have \\[\n\\begin{align*}\n\\nabla^2 \\phi(\\mathbf{x}) &= \\nabla^2 \\int d^3 \\mathbf{x}' \\ \\rho(\\mathbf{x}') G(\\mathbf{x} - \\mathbf{x}') \\\\\n&= \\int d^3 \\mathbf{x}' \\ \\rho(\\mathbf{x}') \\nabla^2 G(\\mathbf{x} - \\mathbf{x}') \\\\\n&= -4\\pi \\int d^3 \\mathbf{x}' \\ \\rho(\\mathbf{x}') \\delta(\\mathbf{x} - \\mathbf{x}') \\\\\n&= -4\\pi \\rho(\\mathbf{x}) \\ .\n\\end{align*}\n\\] This proves that given the Green’s function, we can use it to find the potential for any given charge distribution by convolution.\n\nGreen’s Function Solution via the Fourier Transform\nSince we already know that the Green’s function for Poisson’s equation must be given by \\[\nG(\\mathbf{x} - \\mathbf{x}') = \\frac{1}{|\\mathbf{x} - \\mathbf{x}'|} \\ ,\n\\] we could just skip ahead to the next section. However, we want to derive the Green’s function yet another way that’s more broadly applicable, namely via the Fourier transform. We cover the mathematical details of the Fourier transform in the appendix, so feel free to stop and read over that first before proceeding.\nLet’s suppose that we wished to solve Poisson’s equation for a unit point charge placed at the origin, \\[\n\\nabla^2 G(\\mathbf{x}) = -4\\pi \\delta(\\mathbf{x}) \\ ,\n\\] We’ll assume that both \\(G(\\mathbf{x})\\) and its normal derivative go to zero as \\(|\\mathbf{x}| \\rightarrow \\infty\\), a physically realistic assumption.\nNow, we take the Fourier transform of both sides to get the Green’s function as a function of the wavevector \\(\\mathbf{k}\\). That is, we multiply both sides by \\(e^{-i \\mathbf{k} \\cdot \\mathbf{x}}\\) and integrate with respect to \\(\\mathbf{x}\\) over all space, \\[\n\\int d^3\\mathbf{x} \\ \\nabla^2 G(\\mathbf{x}) e^{-i \\mathbf{k} \\cdot \\mathbf{x}} = -4\\pi \\int d^3\\mathbf{x} \\ \\delta(\\mathbf{x}) e^{-i \\mathbf{k} \\cdot \\mathbf{x}} \\ .\n\\] Now, the right-hand side is easy to work out. By definition of the delta function we get \\(-4\\pi e^{-i \\mathbf{k} \\cdot \\mathbf{0}} = -4\\pi\\). The left-hand side is more interesting. Those familiar with the Fourier transform will immediately see it must be \\(-|\\mathbf{k}|^2 G(\\mathbf{k})\\), where \\(G(\\mathbf{k})\\) is the Fourier transform of \\(G(\\mathbf{x})\\) defined by \\[\nG(\\mathbf{k}) = \\int d^3\\mathbf{x} \\ G(\\mathbf{x}) e^{-i \\mathbf{k} \\cdot \\mathbf{x}} \\ .\n\\] Let’s prove this real quick. If we apply Green’s second identity to the left-hand side above and require that \\(G(\\mathbf{x})\\) go to zero as \\(|\\mathbf{x}| \\rightarrow \\pm \\infty\\), then the boundary terms vanish, leaving us with \\[\n\\begin{align*}\n\\int d^3\\mathbf{x} \\ \\nabla^2 G(\\mathbf{x}) e^{-i \\mathbf{k} \\cdot \\mathbf{x}} &=\n\\int d^3\\mathbf{x} \\ G(\\mathbf{x}) \\nabla^2 e^{-i \\mathbf{k} \\cdot \\mathbf{x}} +\n\\oint_\\mathcal{S} da \\ \\bigg[e^{-i \\mathbf{k} \\cdot \\mathbf{x}} \\frac{\\partial G}{\\partial n} - G \\frac{\\partial}{\\partial n} e^{-i \\mathbf{k} \\cdot \\mathbf{x}} \\bigg] \\\\\n&= -|\\mathbf{k}|^2 \\int d^3\\mathbf{x} \\ G(\\mathbf{x}) e^{-i \\mathbf{k} \\cdot \\mathbf{x}} \\\\\n&= -|\\mathbf{k}|^2 G(\\mathbf{k}) \\ .\n\\end{align*}\n\\] Putting both sides together, we end up with an algebraic equation in \\(k\\)-space that’s easily solved for \\(G(\\mathbf{k})\\),\n\\[\n-|\\mathbf{k}|^2 G(\\mathbf{k}) = -4\\pi \\quad \\Longrightarrow \\quad G(\\mathbf{k}) = \\frac{4\\pi}{|\\mathbf{k}|^2} \\ .\n\\] Now, we want the Green’s function in terms of \\(\\mathbf{x}\\), not in terms of \\(\\mathbf{k}\\). We can get that by now taking the inverse Fourier transform. That is, we multiply \\(G(\\mathbf{k})\\) by \\(\\frac{1}{(2\\pi)^3} e^{i \\mathbf{k} \\cdot \\mathbf{x}}\\) and integrate with respect to \\(\\mathbf{k}\\) over all \\(k\\)-space to get \\[\nG(\\mathbf{x}) = \\int \\frac{d^3\\mathbf{k}}{(2\\pi)^3} \\ G(\\mathbf{k}) e^{-i \\mathbf{k} \\cdot \\mathbf{x}}\n= 4\\pi \\int \\frac{d^3\\mathbf{k}}{(2\\pi)^3} \\ \\frac{e^{-i \\mathbf{k} \\cdot \\mathbf{x}}}{|\\mathbf{k}|^2} \\ .\n\\] We’re now left with an integral to evaluate that’s quite non-trivial. First, we observe that the integrand depends on two things, the squared norm \\(|\\mathbf{k}|^2\\) and the dot product \\(\\mathbf{k} \\cdot \\mathbf{x}\\). Now, we’re free to orient \\(\\mathbf{x}\\) along any direction of \\(k\\)-space we like. Without loss of generality then, let’s suppose \\(\\mathbf{x}\\) is oriented along the \\(k_z\\)-axis, so that \\(\\mathbf{x} = r \\mathbf{e}_{k_z}\\). Then \\(\\mathbf{k} \\cdot \\mathbf{x} = kr\\cos\\theta_k\\), where \\(k = |\\mathbf{k}|\\) and \\(\\theta_k\\) is the usual polar angle of spherical coordinates in \\(k\\)-space. This strongly suggests we should do the integration in \\(k\\)-space spherical coordinates \\((k, \\theta_k, \\varphi_k)\\). This means the volume element \\(d^3\\mathbf{k}\\) becomes \\[\nd^3 \\mathbf{k} = k^2 \\sin\\theta_k dk d\\theta_k d\\phi_k \\ .\n\\] Plugging this all into the integral and evaluating the trivial integral over \\(\\varphi_k\\), we thus have \\[\nG(\\mathbf{x}) = 4\\pi \\int_0^\\infty dk \\int_0^\\pi d\\theta_k \\int_0^{2\\pi} d\\varphi_k \\ \\frac{k^2 \\sin\\theta_k}{(2\\pi)^3} \\frac{e^{-i kr \\cos\\theta_k}}{k^2} = \\frac{1}{\\pi} \\int_0^\\infty dk \\int_0^\\pi d\\theta_k \\ \\sin\\theta_k \\ e^{-i kr \\cos\\theta_k} \\ .\n\\] Next, we need to evaluate the integral over \\(\\theta_k\\). This is most easily done by making the useful substitution \\(\\mu = \\cos\\theta_k\\) to get \\[\nG(\\mathbf{x}) = \\frac{1}{\\pi} \\int_0^\\infty dk \\int_{-1}^1 d\\mu \\ e^{-i kr \\mu} = \\frac{1}{\\pi} \\int_0^\\infty dk \\ \\frac{e^{-ikr} - e^{ikr}}{-ikr} = \\frac{2}{\\pi} \\int_0^\\infty dk \\ \\frac{\\sin kr}{kr} \\ .\n\\] All that remains now is the integral over \\(k\\). We’ll simplify this remaining integral slightly by substituting \\(u=kr\\) to write \\[\nG(\\mathbf{x}) = \\frac{2}{\\pi r} \\int_0^\\infty du \\ \\frac{\\sin u}{u} \\ .\n\\] The remaining integral in \\(u\\) is a well-known integral, known as a Dirichlet integral. Dirichlet integrals can be evaluated any number of ways. In the appendix we showed that we can evaluate this integral using the residue theorem to get \\[\n\\int_0^\\infty du \\ \\frac{\\sin u}{u} = \\frac{\\pi}{2} \\ .\n\\] Plugging this back into the Green’s function, we finally get \\[\nG(\\mathbf{x}) = \\frac{2}{\\pi r} \\cdot \\frac{\\pi}{2} = \\frac{1}{r} = \\frac{1}{|\\mathbf{x}|} \\ .\n\\] This is the Green’s function that solves the equation posed above. Finally, if we shift the source point from the origin to some other source point \\(\\mathbf{x}'\\) we recover the general Green’s function derived above, \\[\nG(\\mathbf{x} - \\mathbf{x}') = \\frac{1}{|\\mathbf{x} - \\mathbf{x}'|} \\ .\n\\]\nThis perhaps seemed like a pointless exercise, but we’ll see later that this method for solving PDEs is broadly useful. For example, in a later chapter we’ll need to find the Green’s function for the Helmholtz equation, and for that we’ll need this method.\n\n\nFormal Solution to Poisson’s Equation\nWe’ll now derive a formal solution to Poisson’s equation in the presence of boundary conditions. To do so we’ll again make use of Green’s second identity. Recall that Green’s second identity says that for two scalar fields \\(\\psi(\\mathbf{x}')\\) and \\(\\phi(\\mathbf{x}')\\), we have\n\\[\n\\int_\\mathcal{V} d^3 \\mathbf{x}' \\ (\\phi \\nabla'^2 \\psi - \\psi \\nabla'^2 \\phi) = \\oint_\\mathcal{S} da' \\ \\bigg[\\phi \\frac{\\partial \\psi}{\\partial n'} - \\psi \\frac{\\partial \\phi}{\\partial n'} \\bigg] \\ .\n\\] Here \\(\\mathcal{S}\\) is some closed surface enclosing a volume \\(\\mathcal{V}\\), and \\(\\frac{\\partial \\phi}{\\partial n'} = \\nabla' \\phi \\cdot \\mathbf{n}'\\) is the normal derivative of \\(\\phi\\) across the surface. We write the identity in terms of the source point \\(\\mathbf{x}'\\) since that’s what will be useful for us here.\nNow, what we’ll do is set \\(\\psi(\\mathbf{x}') = G(\\mathbf{x} - \\mathbf{x}')\\) and \\(\\phi(\\mathbf{x}')\\) equal to the potential to get \\[\n\\int_\\mathcal{V} d^3 \\mathbf{x}' \\ (\\phi \\nabla'^2 G - G \\nabla'^2 \\phi) = \\oint_\\mathcal{S} da' \\ \\bigg[\\phi \\frac{\\partial G}{\\partial n'} - G \\frac{\\partial \\phi}{\\partial n'} \\bigg] \\ .\n\\] Next, we’ll simplify the left-hand side by using Poisson’s equation to write \\(\\nabla'^2 \\phi = -4\\pi\\rho\\) and the property of the Green’s function derived above to write \\(\\nabla'^2 G = -4\\pi\\delta(\\mathbf{x}-\\mathbf{x}')\\). Plugging these in and rearranging terms, we have \\[\n\\int_\\mathcal{V} d^3 \\mathbf{x}' \\ \\phi(\\mathbf{x}') \\delta(\\mathbf{x}-\\mathbf{x}') = \\int_\\mathcal{V} d^3 \\mathbf{x}' \\ \\rho(\\mathbf{x}') G(\\mathbf{x} - \\mathbf{x}') + \\frac{1}{4\\pi} \\oint_\\mathcal{S} da' \\ \\bigg[G \\frac{\\partial \\phi}{\\partial n'} - \\phi \\frac{\\partial G}{\\partial n'} \\bigg] \\ .\n\\] Now, we can evaluate the left-hand side of this integral. If \\(\\mathbf{x}\\) is outside the surface the left-hand side is zero and we get nowhere. However, if \\(\\mathbf{x}\\) is inside the surface we can use the definition of the delta function to write \\[\n\\boxed{\n\\phi(\\mathbf{x}) = \\int_\\mathcal{V} d^3 \\mathbf{x}' \\ \\rho(\\mathbf{x}') G(\\mathbf{x} - \\mathbf{x}') + \\frac{1}{4\\pi} \\oint_\\mathcal{S} da' \\ \\bigg[G \\frac{\\partial \\phi}{\\partial n'} - \\phi \\frac{\\partial G}{\\partial n'} \\bigg]\n}\\ .\n\\] Provided we interpret \\(\\mathcal{S}\\) as the boundary surface we have exactly what we seek, a formal solution for the potential in the presence of boundary conditions acting along the boundary surface. The surface integral term encodes all the information contained in the boundary conditions. Indeed, if we send the boundary surface to infinity the surface integral goes to zero like \\(r'^{-3}\\), and we recover our original integral formula for the potential.\nSo what exactly is the surface integral encoding? Notice that it contains two terms, one proportional to the value of the potential along the boundary surface, and another proportional to the normal derivative of the potential along the boundary surface. Since we can write the normal derivative in terms of the electric field via \\[\n\\frac{\\partial \\phi}{\\partial n'} = \\nabla' \\phi \\cdot \\mathbf{n}' = -\\mathbf{E} \\cdot \\mathbf{n}' \\ ,\n\\] the normal derivative term is just encoding information about the value of the electric field along the boundary surface.\nWe can also see that if there are no source charges present inside the boundary surface we can still find an expression for the potential. It’s just the surface integral term. This means we need not have a source charge distribution present at all. We can just specify everything in terms of boundary conditions if we like. If there are no source charges present, Poisson’s equation reduces to a simpler PDE known as Laplace’s Equation, \\[\n\\nabla^2 \\phi = 0 \\ .\n\\] We can solve many electrostatics problems just by solving Laplace’s equation subject to boundary conditions, allowing us to avoid having to specify ahead what the charge distributions are. We’ll return to this idea later.\n\n\nUniqueness Theorem\nIn fact, the formal solution we derived above is redundant. We don’t need all of the information encoded in the surface integral to solve Poisson’s equation. It turns out we only need one of the two terms, either the value term or the normal derivative term. In fact, including both terms as boundary conditions can result in the problem having no solution at all.\nWhen we solve Poisson’s equation with only the value of the potential specified on the boundary surface, we say we are using Dirichlet boundary conditions. In a Dirichlet problem, we seek to solve the boundary value problem (BVP) \\[\n\\begin{align*}\n\\begin{cases}\n\\nabla^2 \\phi = -4\\pi\\rho \\ , \\\\\n\\text{where} \\ \\phi = \\phi_0 \\ \\text{on} \\ \\mathcal{S} \\ .\n\\end{cases}\n\\end{align*}\n\\] On the other hand, when we solve Poisson’s equation with only the normal derivative specified on the boundary surface, we say we are using Neumann boundary conditions. In a Neumann problem, we seek to solve the BVP \\[\n\\begin{align*}\n\\begin{cases}\n\\nabla^2 \\phi = -4\\pi\\rho \\ , \\\\\n\\text{where} \\ \\frac{\\partial \\phi}{\\partial n'} = -E_0 \\ \\text{on} \\ \\mathcal{S} \\ .\n\\end{cases}\n\\end{align*}\n\\] Here \\(E_0\\) is used to denote the value of the electric field normal to the boundary surface, i.e. \\(E_0 = \\mathbf{E} \\cdot \\mathbf{n}'\\).\nWe will now show that provided either Cauchy or Neumann boundary conditions are used, the Poisson equation with boundary conditions will yield a unique solution for the potential. Suppose we have two solutions \\(\\phi_1\\) and \\(\\phi_2\\) to Poisson’s equation subject to either Cauchy or Neumann boundary conditions, but not both. That is, we have \\[\n\\begin{align*}\n\\begin{cases}\n\\nabla^2 \\phi_1 = \\nabla^2 \\phi_2 = -4\\pi\\rho \\ , \\\\\n\\text{where} \\ \\phi_1 = \\phi_2 = \\phi_0 \\ \\text{on} \\ \\mathcal{S} \\ , \\\\\n\\text{or} \\ \\frac{\\partial \\phi_1}{\\partial n'} = \\frac{\\partial \\phi_1}{\\partial n'} = -E_0 \\ \\text{on} \\ \\mathcal{S} \\ .\n\\end{cases}\n\\end{align*}\n\\] Now, let \\(u = \\phi_2 - \\phi_1\\). Then \\(\\nabla^2 u = 0\\) by linearity and either \\(u\\) or \\(\\frac{\\partial u}{\\partial n'}\\) equal zero along the boundary surface, so we have \\[\n\\begin{align*}\n\\begin{cases}\n\\nabla^2 u = 0 \\ , \\\\\n\\text{where} \\ u = 0 \\ \\text{on} \\ \\mathcal{S} \\ , \\\\\n\\text{or} \\ \\frac{\\partial u}{\\partial n'} = 0 \\ \\text{on} \\ \\mathcal{S} \\ .\n\\end{cases}\n\\end{align*}\n\\] This means the BVP for \\(u\\) involves only solving Laplace’s equation subject to the condition that either \\(u\\) vanishes along the boundary or its normal derivative does.\nNext we’ll employ Green’s first identity. Recall from the first chapter that this identity says \\[\n\\int_\\mathcal{V} d^3 \\mathbf{x}' \\ (\\nabla' \\psi \\cdot \\nabla' \\phi + \\psi \\nabla'^2 \\phi) = \\oint_\\mathcal{S} da' \\ \\psi \\frac{\\partial \\phi}{\\partial n'} \\ .\n\\] Again we interpret this identity as \\(\\mathcal{S}\\) being a closed boundary surface enclosing a volume \\(\\mathcal{V}\\), and each scalar field being a function of the source position \\(\\mathbf{x}'\\). What we’ll do this time is let \\(u = \\psi = \\phi\\) in this equation to get \\[\n\\int_\\mathcal{V} d^3 \\mathbf{x}' \\ \\big((\\nabla' u)^2 + u \\nabla'^2 u\\big) = \\oint_\\mathcal{S} da' \\ u \\frac{\\partial u}{\\partial n'} \\ .\n\\] Now, according to Laplace’s equation \\(\\nabla'^2 u = 0\\). Also, according to the boundary conditions, either \\(u\\) or \\(\\frac{\\partial u}{\\partial n'}\\) must vanish on the boundary surface, which means the surface integral on the right-hand side must also vanish. We’re thus left with \\[\n\\int_\\mathcal{V} d^3 \\mathbf{x}' \\ |\\nabla' u|^2 = 0 \\ .\n\\] Finally, since \\(|\\nabla' u|^2\\) is strictly non-negative, the integral can only vanish if its integrand does. This means we must have \\[\n\\nabla' u = 0 \\ .\n\\] The only way the gradient can vanish is if \\(u\\) is constant, meaning \\(u = \\phi_2 - \\phi_1 + \\text{const}\\). Under Dirichlet boundary conditions, this additive constant must in fact be zero since if \\(\\nabla' u = 0\\) and \\(u = 0\\) on the boundary, then \\(u=0\\) everywhere. Under Neumann boundary conditions, however, this additive constant can be anything.\nIn either case it’s physically immaterial what the additive constant is. Since the physical quantity of interest is the electric field, the additions of an additive constant to the potential doesn’t physically matter. All together, this means that the solution to Poisson’s equation subject to either Cauchy or Neumann boundary conditions must be unique up to an unimportant constant, which is what we wanted to show.\nNote that the same proof holds if the problem has mixed boundary conditions, where on some parts of the boundary surface the potential is specified, and on other parts the normal derivative is specified. In this case, we only need to break the boundary up into these two pieces and argue the proof for each part.\n\n\nGreen’s Function with Boundary Conditions\nWe derived the Green’s function above under the assumption that no boundary conditions were present, and then later imposed boundary conditions when deriving the formal solution. But we can also define the Green’s function so that the boundary conditions are already backed in. The idea is to generalize the definition of the Green’s function somewhat by supposing \\[\nG(\\mathbf{x} - \\mathbf{x}') = \\frac{1}{|\\mathbf{x} - \\mathbf{x}'|} + F(\\mathbf{x} - \\mathbf{x}') \\ ,\n\\] where \\(F(\\mathbf{x} - \\mathbf{x}')\\) is some function that satisfies Laplace’s equation subject to the boundary conditions, \\[\n\\begin{align*}\n\\begin{cases}\n\\nabla^2 F(\\mathbf{x} - \\mathbf{x}') = 0 \\ , \\\\\n\\text{where} \\ F(\\mathbf{x} - \\mathbf{x}') = 0 \\ \\text{on} \\ \\mathcal{S} \\ , \\\\\n\\text{or} \\ \\frac{\\partial F}{\\partial n'} = 0 \\ \\text{on} \\ \\mathcal{S} \\ .\n\\end{cases}\n\\end{align*}\n\\] We’ll call \\(F(\\mathbf{x} - \\mathbf{x}')\\) the homogeneous part of the Green’s function. Intuitively, we can think of the homogeneous part as the potential of any charge distributions lying beyond the boundary surface. Our goal in this section however isn’t to find \\(F(\\mathbf{x} - \\mathbf{x}')\\), but to formally show that this generalization of the Green’s function gives formal solutions that aren’t overdetermined.\nConsider first the case of a Poisson BVP with Dirichlet boundary conditions. We’ll suppose there exists a Green’s function \\(G_D(\\mathbf{x} - \\mathbf{x}')\\) that satisfies the BVP \\[\n\\begin{align*}\n\\begin{cases}\n\\nabla^2 G_D(\\mathbf{x} - \\mathbf{x}') = -4\\pi\\delta(\\mathbf{x} - \\mathbf{x}') \\ , \\\\\n\\text{where} \\ G_D(\\mathbf{x} - \\mathbf{x}') = 0 \\ \\text{on} \\ \\mathcal{S} \\ .\n\\end{cases}\n\\end{align*}\n\\] Now, if we plug this Green’s function into the formal solution for the potential, we get \\[\n\\phi(\\mathbf{x}) = \\int_\\mathcal{V} d^3 \\mathbf{x}' \\ \\rho(\\mathbf{x}') G_D(\\mathbf{x} - \\mathbf{x}') + \\frac{1}{4\\pi} \\oint_\\mathcal{S} da' \\ \\bigg[G_D \\frac{\\partial \\phi}{\\partial n'} - \\phi \\frac{\\partial G_D}{\\partial n'} \\bigg] \\ .\n\\] Since \\(G_D(\\mathbf{x} - \\mathbf{x}')\\) will vanish on the surface \\(\\mathcal{S}\\) by assumption, the first term in the surface integral vanishes and we’re left with \\[\n\\boxed{\n\\phi(\\mathbf{x}) = \\int_\\mathcal{V} d^3 \\mathbf{x}' \\ \\rho(\\mathbf{x}') G_D(\\mathbf{x} - \\mathbf{x}') - \\frac{1}{4\\pi} \\oint_\\mathcal{S} da' \\ \\phi \\frac{\\partial G_D}{\\partial n'}\n}\\ .\n\\] We’ve thus used this generalized Green’s function to eliminate the boundary term we don’t care about from the formal solution. What remains is the formal solution for a potential under Dirichlet boundary conditions.\nWe can do something similar for a Poisson BVP with Neumann boundary conditions, except we have to be slightly more careful. Suppose there exists a Green’s function \\(G_N\\) that satisfies the BVP \\[\n\\begin{align*}\n\\begin{cases}\n\\nabla^2 G_N(\\mathbf{x} - \\mathbf{x}') = -4\\pi\\delta(\\mathbf{x} - \\mathbf{x}') \\ , \\\\\n\\text{where} \\ \\frac{\\partial G_N}{\\partial n'} = C \\ \\text{on} \\ \\mathcal{S} \\ .\n\\end{cases}\n\\end{align*}\n\\] Notice that we let \\(\\frac{\\partial G_N}{\\partial n'}\\) equal some arbitrary constant \\(C\\) along the boundary instead of setting it to zero. To understand why we did this, recall that the normal derivative of a potential \\(\\phi\\) is proportional to the component of the electric field normal to the surface, with \\(\\frac{\\partial \\phi}{\\partial n'} = -\\mathbf{E} \\cdot \\mathbf{n}'\\). Since the electric field must satisfy Gauss’s Law, this means if we integrate over \\(\\mathcal{S}\\) we must have \\[\n\\oint_\\mathcal{S} da' \\ \\frac{\\partial \\phi}{\\partial n'} = -\\oint_\\mathcal{S} \\mathbf{E} \\cdot \\mathbf{n}' \\ da' = -4\\pi Q_{\\text{enc}} \\ .\n\\] Now, we can think of the Green’s function as the potential of a unit point charge. This means if we substitute \\(\\phi\\) for \\(G_N\\) and set \\(Q_{\\text{enc}} = 1\\), we’re left with \\[\n\\oint_\\mathcal{S} da' \\ \\frac{\\partial G_N}{\\partial n'} = -4\\pi \\ .\n\\] This implies that whatever the normal derivative is doing along the boundary surface, it must have the form \\[\n\\frac{\\partial G_N}{\\partial n'} = -\\frac{4\\pi}{S} \\ \\text{on} \\ \\mathcal{S} \\ .\n\\] We’ll thus choose this as our boundary condition for the Neumann BVP, setting the constant \\(C = -\\frac{4\\pi}{S}\\).\nPlugging this form of \\(G_N\\) into the formal solution and substituting in the above boundary condition, we have \\[\n\\begin{align*}\n\\phi(\\mathbf{x}) &= \\int_\\mathcal{V} d^3 \\mathbf{x}' \\ \\rho(\\mathbf{x}') G_N(\\mathbf{x} - \\mathbf{x}') + \\frac{1}{4\\pi} \\oint_\\mathcal{S} da' \\ \\bigg[G_N \\frac{\\partial \\phi}{\\partial n'} - \\phi \\frac{\\partial G_N}{\\partial n'} \\bigg] \\\\\n&= \\int_\\mathcal{V} d^3 \\mathbf{x}' \\ \\rho(\\mathbf{x}') G_N(\\mathbf{x} - \\mathbf{x}') + \\frac{1}{4\\pi} \\oint_\\mathcal{S} da' \\ G_N \\frac{\\partial \\phi}{\\partial n'} + \\frac{1}{S} \\oint_\\mathcal{S} da' \\phi \\ .\n\\end{align*}\n\\] Notice the last term is just the average value of the potential along the boundary surface, a constant. We’ll let \\[\n\\langle \\phi \\rangle_\\mathcal{S} \\equiv \\frac{1}{S} \\oint_\\mathcal{S} da' \\phi\n\\] denote this constant term. Like all additive constants, this term is irrelevant to the physics and can be absorbed into the potential if we like. We thus finally have the correct formal solution for a potential under Neumann boundary conditions, \\[\n\\boxed{\n\\phi(\\mathbf{x}) = \\langle \\phi \\rangle_\\mathcal{S} + \\int_\\mathcal{V} d^3 \\mathbf{x}' \\ \\rho(\\mathbf{x}') G_N(\\mathbf{x} - \\mathbf{x}') + \\frac{1}{4\\pi} \\oint_\\mathcal{S} da' \\ G_N \\frac{\\partial \\phi}{\\partial n'}\n} \\ .\n\\] Of course, while having these formal solutions is nice, we still haven’t shown how to find these generalized Green’s functions. In fact, it usually isn’t that helpful to find the generalized Green’s function directly when solving a given problem. Its primary use is theoretical, to show that a formal solution for the potential will always exist under certain types of boundary conditions.\n\n\nGreen’s Functions in Other Dimensions\nFor the special case of the Laplacian operator, there’s an easier way to find the (unbounded) Green’s function that also happens to work just as easily for any number of dimensions. Let’s again consider Poisson’s equation for the Green’s function free from boundary conditions, but this time we’ll assume \\(\\mathbf{x}\\) and \\(\\mathbf{x}'\\) are vectors in some arbitrary \\(n\\)-dimensional space. If we ignore the factor of \\(4\\pi\\) from before, we can write \\[\n\\nabla^2 G(|\\mathbf{x} - \\mathbf{x}'|) = -\\delta(\\mathbf{x} - \\mathbf{x}') \\ .\n\\] Here the Laplacian operator is assumed to be defined in \\(n\\) dimensions as well, i.e. \\(\\nabla^2 = \\partial_i \\partial_i\\) in summation notation.\nLet’s now recall the divergence theorem in 3-dimensions, which says for any vector field \\(\\mathbf{F}(\\mathbf{x})\\) we have \\[\n\\int_\\mathcal{V} d^3 \\mathbf{x} \\ \\nabla \\cdot \\mathbf{F} = \\oint_\\mathcal{S} da \\ \\mathbf{F} \\cdot \\mathbf{n} \\ .\n\\] This theorem can be written in any number of dimensions if we think of \\(\\mathcal{V}_n\\) as an \\(n\\)-dimensional volume and \\(\\mathcal{S}_{n-1}\\) as the closed boundary containing that volume in \\(n\\)-dimensional space. Then we have \\[\n\\int_{\\mathcal{V}_n} d^n \\mathbf{x} \\ \\nabla \\cdot \\mathbf{F} = \\oint_{\\mathcal{S}_{n-1}} da^{n-1} \\ \\mathbf{F} \\cdot \\mathbf{n} \\ .\n\\] Now, let \\(\\mathbf{F} = \\nabla G(|\\mathbf{x} - \\mathbf{x}'|)\\). If we plug this in and integrate with respect to the field point \\(\\mathbf{x}\\). If we do that, the left-hand side becomes an \\(n\\)-dimensional Laplacian \\(\\nabla^2 G\\), while the right-hand side becomes the normal derivative \\(\\frac{\\partial G}{\\partial n}\\) through the \\((n-1)\\)-dimensional surface \\(\\mathcal{S}_{n-1}\\), \\[\n\\int_{\\mathcal{V}_n} d^n \\mathbf{x} \\ \\nabla^2 G = \\oint_{\\mathcal{S}_{n-1}} da^{n-1} \\ \\frac{\\partial G}{\\partial n} \\ .\n\\] Now we’ll apply this divergence theorem to the Poisson’s equation above. If we suppose \\(\\mathcal{V}_n\\) is a volume centered at \\(\\mathbf{x}'\\) and use the divergence theorem to replace the volume integral with a surface integral, we have \\[\n\\oint_{\\mathcal{S}_{n-1}} da^{n-1} \\ \\frac{\\partial G}{\\partial n} = -1 \\ .\n\\] Now, we can pick any Gaussian surface we like so long as its volume includes \\(\\mathbf{x}'\\). Let’s suppose \\(\\mathcal{S}_{n-1}\\) is an \\((n-1)\\)-dimensional sphere centered at \\(\\mathbf{x}'\\). If this sphere has a radius \\(r\\), we can write the area element as \\[\nda^{n-1} = r^{n-1} d\\Omega^{n-1} \\ ,\n\\] where \\(d\\Omega^{n-1}\\) is the \\((n-1)\\)-dimensional solid angle. Since \\(G(|\\mathbf{x}|)\\) is radial by assumption, its normal derivative with the sphere will just be its derivative with respect to \\(r\\) and we can pull it out of the integral to write \\[\n\\oint_{\\mathcal{S}_{n-1}} da^{n-1}  \\ \\frac{\\partial G}{\\partial n} = r^{n-1}  \\frac{\\partial G}{\\partial r}\\oint_{\\mathcal{S}_{n-1}} d\\Omega^{n-1} = r^{n-1} \\frac{\\partial G}{\\partial r} \\Omega_{n-1} \\ ,\n\\] where \\(\\Omega_{n-1}\\) is the area of an \\((n-1)\\)-dimensional unit sphere. Putting this all together, we have \\[\n\\frac{\\partial G}{\\partial r} = -\\frac{1}{\\Omega_{n-1} r^{n-1}} \\ .\n\\] This can then be integrated to find the \\(n\\)-dimensional Green’s function \\(G_n(|\\mathbf{x} - \\mathbf{x}'|) = G(r)\\). For \\(n \\geq 3\\) we have \\[\nG_n(|\\mathbf{x} - \\mathbf{x}'|) = \\frac{(-1)^{n+1}}{(n-2) \\Omega_{n-1}} \\frac{1}{|\\mathbf{x} - \\mathbf{x}'|^{n-2}} \\ .\n\\] It’s easy to see that when \\(n=3\\) we get exactly what we’d derived before aside from the factor of \\(4\\pi\\). Indeed, since \\(\\Omega_2 = 4\\pi\\) is the surface area of a unit sphere, we get \\[\nG_3(|\\mathbf{x} - \\mathbf{x}'|) = \\frac{1}{4\\pi} \\frac{1}{|\\mathbf{x} - \\mathbf{x}'|} \\ .\n\\] When \\(n=2\\) we do get a proper function, but it looks different than the rest. In this case \\(\\Omega_1 = 2\\pi\\) is the circumference of a unit sphere, so we get \\[\nG_2(|\\mathbf{x} - \\mathbf{x}'|) = -\\frac{1}{2\\pi} \\log |\\mathbf{x} - \\mathbf{x}'| \\ .\n\\] Finally, when \\(n=1\\), \\(\\Omega_0\\) is just the size of a point, which is zero. This means that \\(G_1(|\\mathbf{x} - \\mathbf{x}'|) = \\infty\\), hence the Green’s function isn’t well-defined in 1-dimension.\nIn practice, aside from the 3-dimensional Green’s function we already studied in depth, it’s the 2-dimensional Green’s function that’s likely to be of most use to use in electromagnetism. It can be useful, for instance, in solving electrostatics problems where we’re only interested in the fields and potentials along some flat 2-dimensional surface.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Boundary Value Problems I</span>"
    ]
  },
  {
    "objectID": "electrodynamics/bvps-1.html#method-of-images",
    "href": "electrodynamics/bvps-1.html#method-of-images",
    "title": "Boundary Value Problems I",
    "section": "Method of Images",
    "text": "Method of Images\nThus far, we’ve yet to show any practical ways to find the potential in a given boundary value problem. In this section we’ll introduce the first method, the powerful method of images. This method exploits the uniqueness theorem and the geometry of a problem to quickly find the potential. It doesn’t always work, but when it does it can be quite useful.\nFrom the previous section, we know we can express the Green’s function satisfying the boundary conditions by letting \\[\nG(\\mathbf{x} - \\mathbf{x}') = \\frac{1}{|\\mathbf{x} - \\mathbf{x}'|} + F(\\mathbf{x} - \\mathbf{x}') \\ ,\n\\] where the homogeneous part \\(F(\\mathbf{x} - \\mathbf{x}')\\) is any function that satisfies Laplace’s equation subject to the boundary conditions. By the uniqueness theorem, we know that if we can find such a function \\(F(\\mathbf{x} - \\mathbf{x}')\\), it will be unique up to an unimportant additive constant to the potential, provided Dirichlet or Neumann (or mixed) boundary conditions are used.\nThe method of images exploits this property of uniqueness by converting the original boundary value problem into an equivalent unbounded problem that still just happens to satisfy the same boundary conditions. Suppose we have one or more point charges in the presence of some set of boundary conditions, for example a set of conductors held at some fixed potentials. In many cases, we can exploit the geometry of the problem to convert this problem into an equivalent unbounded problem by introducing pseudo-charges outside the boundary surface, called image charges, such that when added to the problem the combination of original and image charges together happens to satisfy the original boundary conditions. By the uniqueness theorem, we know that if we find such a solution, it must be the unique solution, even for the original BVP.\n\nExamples\nFor example, suppose we wanted to find the potential for a point charge \\(q\\) located at a distance \\(z=d\\) above an infinite grounded sheet, meaning \\(\\phi = 0\\) at \\(z=0\\). What we can do is pretend the grounded sheet wasn’t there, and instead introduce an image charge \\(-q\\) below the sheet at \\(z = -d\\), which is outside the boundary surface. The potential of this new image problem is just \\[\n\\phi(\\mathbf{x}) = \\frac{q}{|\\mathbf{x} - d \\mathbf{e}_z|} - \\frac{q}{|\\mathbf{x} + d \\mathbf{e}_z|} = \\frac{q}{\\sqrt{x^2 + y^2 + (z-d)^2}} - \\frac{q}{\\sqrt{x^2 + y^2 + (z+d)^2}} \\ .\n\\] The potential of this image problem just happens to solve the original boundary conditions, since \\(\\phi(x,y,0) = 0\\). By the uniqueness theorem, then, this same potential must also be the solution to the original BVP. See the figure below.\n\n\n\n\n\nFrom this potential we can also easily find the Green’s function satisfying the boundary conditions. For a point charge \\(q\\) located at a position \\(\\mathbf{x}_0\\), we have \\(\\rho(\\mathbf{x}') = q \\delta(\\mathbf{x}' - \\mathbf{x}_0)\\), meaning \\[\n\\begin{align*}\n\\phi(\\mathbf{x}) &= \\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') G(\\mathbf{x} - \\mathbf{x}') \\\\\n&= \\int d^3\\mathbf{x}' \\ q \\delta(\\mathbf{x}' - \\mathbf{x}_0) G(\\mathbf{x} - \\mathbf{x}') \\\\\n&= q G(\\mathbf{x} - \\mathbf{x}_0) \\ .\n\\end{align*}\n\\] This means that to get the Green’s function all we need to do is divide the potential by \\(q\\) to get \\[\nG_D(\\mathbf{x} - d\\mathbf{e}_z) = \\frac{q}{\\sqrt{x^2 + y^2 + (z-d)^2}} - \\frac{q}{\\sqrt{x^2 + y^2 + (z+d)^2}} \\ .\n\\] Notice that the first term is just the unbounded Green’s function. The second term is the homogeneous part \\[\nF(\\mathbf{x} - d \\mathbf{e}_z) = -\\frac{q}{\\sqrt{x^2 + y^2 + (z+d)^2}} \\ .\n\\] It’s important to note that the potential and Green’s function we found is only valid above the sheet, where \\(z &gt; 0\\). Below the sheet these formulas will not hold. The method of images only guarantees a solution inside the boundary surface. If we wanted to know what the potential was beyond the boundary surface as well we’d need to use some other approach.\nThis in a nutshell is how we use the method of images. Given some problem involving a set of point charges subject to some set of boundary conditions, we convert the problem into an unbounded problem by introducing image charges, find the image charges needed to satisfy the boundary conditions, write down the potential for this image problem and if desired the Green’s function. Note that for the method of images to work, it’s important that the images charges be outside the boundary surface. If we can’t find image charges outside the surface that satisfy the boundary conditions, we can’t proceed.\nBefore moving on, it’s insightful to calculate the total induced charge on the boundary surface, in this case on the sheet. Using the relation between the surface charge density \\(\\sigma\\) and the normal derivative of \\(\\phi\\) from the previous chapter, we can find the total charge induced on the sheet due to the presence of the point charge \\(q\\). Recall that near the surface the normal derivative must satisfy the condition \\[\n\\frac{\\partial \\phi}{\\partial n} = -4\\pi\\sigma \\ .\n\\] Since the normal vector for the sheet is \\(\\mathbf{n} = z \\mathbf{e}_z\\), the induced surface charge density is given by \\[\n\\begin{align*}\n\\sigma &= -\\frac{1}{4\\pi} \\frac{\\partial \\phi}{\\partial z} \\\\\n&= -\\frac{1}{4\\pi} \\frac{\\partial}{\\partial z} \\bigg(\\frac{q}{\\sqrt{x^2 + y^2 + (z-d)^2}} - \\frac{q}{\\sqrt{x^2 + y^2 + (z+d)^2}}\\bigg) \\\\\n&= -\\frac{1}{4\\pi} \\bigg(\\frac{q(z-d)}{(x^2 + y^2 + (z-d)^2)^{3/2}} - \\frac{q(z+d)}{(x^2 + y^2 + (z+d)^2)^{3/2}}\\bigg) \\\\\n&= -\\frac{qd}{2\\pi}\\frac{1}{(x^2 + y^2 + d^2)^{3/2}} \\ .\n\\end{align*}\n\\] Using this information we can then find the total induced charge \\(Q\\) on the sheet by integrating \\(\\sigma\\) along the surface of the sheet. Since the surface is just the entire \\(xy\\)-plane. We’ll use polar coordinates for the integration since it’s slightly easier. Writing \\(da = r dr d\\varphi\\) and \\(r^2 = x^2 + y^2\\), we have \\[\n\\begin{align*}\nQ &= \\oint_\\mathcal{S} da \\ \\sigma \\\\\n&= -\\frac{qd}{2\\pi} \\int_0^{2\\pi} d\\varphi \\int_0^\\infty r dr \\ \\frac{1}{(r^2 + d^2)^{3/2}} \\\\\n&= \\frac{qd}{\\sqrt{r^2 + d^2}} \\bigg |_{r=0}^\\infty \\\\\n&= -q \\ .\n\\end{align*}\n\\] Notice that the induced charge on the surface is just the image charge, with \\(Q = -q\\). This will be generally true in method of images problems. In fact it must be this way, since the image charges are just a reformulation of the boundary conditions. The net charge in the original BVP should be the same as the net charge in the corresponding image problem.\nWe’ll now work through a few more complicated examples to help solidify these ideas.\n\nExample: Point charge near a grounded conducting sphere\nSuppose we have a point charge \\(q\\) located at some distance \\(d\\) outside a grounded conducting sphere of radius \\(R\\). This means that the boundary surface is just the surface of the sphere, where we must have \\(\\phi = 0\\). To find the potential of this BVP, we’ll suppose there is a single image charge \\(q'\\) located inside the sphere at some distance \\(d' \\leq R\\) from the center.\n\n\n\n\n\nIf we ignore the presence of the sphere and focus on these two charges alone, the potential will be \\[\n\\phi(\\mathbf{x}) = \\frac{q}{|\\mathbf{x} - \\mathbf{d}|} + \\frac{q'}{|\\mathbf{x} - \\mathbf{d}'|} \\ ,\n\\] where \\(\\mathbf{d} = d\\mathbf{n}\\) is the distance vector of \\(q\\) and \\(\\mathbf{d}' = d'\\mathbf{n}'\\) is the distance vector of \\(q'\\), with \\(\\mathbf{n}\\) and \\(\\mathbf{n}'\\) their respective normal vectors relative to the surface of the sphere. To satisfy the boundary conditions, we require that \\(\\phi(R\\mathbf{e}_r) = 0\\). This means we need to find a \\(q'\\) and \\(d'\\) for the image charge that satisfies the condition \\[\n0 = \\frac{q}{|R\\mathbf{e}_r - d \\mathbf{n}|} + \\frac{q'}{|R\\mathbf{e}_r - d' \\mathbf{n}'|} =\n\\frac{q/R}{|\\mathbf{e}_r - \\frac{d}{R}\\mathbf{n}|} + \\frac{q'/d'}{|\\frac{R}{d'}\\mathbf{e}_r - \\mathbf{n}'|} \\ .\n\\] The only way this equation can evidently be satisfied with a nontrivial solution is if \\[\n\\frac{q}{R} = -\\frac{q'}{d'} \\quad , \\quad \\frac{d}{R} = \\frac{R}{d'} \\ .\n\\] This means we means for the image problem to satisfy the boundary conditions, the image charge must satisfy \\[\nq' = -\\frac{R}{d} q \\quad , \\quad \\mathbf{d}' = \\frac{R^2}{d} \\mathbf{n} \\ .\n\\] Plugging these expressions back into the potential, we thus have \\[\n\\phi(\\mathbf{x}) = \\frac{q}{|\\mathbf{x} - d \\mathbf{n}|} - \\frac{\\frac{R}{d} q}{|\\mathbf{x} - \\frac{R^2}{d} \\mathbf{n}|} \\ .\n\\] We can rewrite this expression in a somewhat more useful form by using the law of cosines. If we let \\(\\alpha\\) denote the angle between \\(\\mathbf{x}\\) and \\(\\mathbf{d}\\), we can write \\[\n\\phi(\\mathbf{x}) = \\frac{q}{\\sqrt{r^2 + d^2 - 2rd\\cos\\alpha}} - \\frac{\\frac{R}{d} q}{\\sqrt{R^2 + \\frac{r^2 d^2}{R^2} - 2rd\\cos\\alpha}} \\ .\n\\] By the uniqueness theorem, this must be the solution to the original BVP as well. Let’s check that the limits make sense. As \\(d \\rightarrow \\infty\\), we have \\(d' \\rightarrow 0\\), meaning the image charge moves closer towards the origin as the main charge moves farther away. Moreover, the image charge itself goes to zero, since \\(q' \\rightarrow 0\\). On the other hand, as \\(d \\rightarrow R\\), we have \\(d' \\rightarrow R\\) as well, meaning the image charge moves toward the surface as the main charge does. The image charge itself goes to \\(q' \\rightarrow q\\) in this limit. This also makes sense, since near the surface we expect the problem to approximate that of the charge above an infinite sheet.\nIf we like we can also write down the Green’s function by again dividing both sides of the potential by \\(q\\) to get \\[\nG_D(\\mathbf{x} - \\mathbf{d}) = \\frac{1}{\\sqrt{r^2 + d^2 - 2rd\\cos\\alpha}} - \\frac{\\frac{R}{d}}{\\sqrt{R^2 + \\frac{r^2 d^2}{R^2} - 2rd\\cos\\alpha}} \\ .\n\\] Again, the first term is just the unbounded Green’s function. The second term is the homogeneous part \\[\nF(\\mathbf{x} - \\mathbf{d}) = -\\frac{\\frac{R}{d}}{\\sqrt{R^2 + \\frac{r^2 d^2}{R^2} - 2rd\\cos\\alpha}} \\ .\n\\] One can check that \\(F\\) also satisfies Laplace’s equation subject to the boundary condition \\(F(R\\mathbf{e}_r - \\mathbf{d}) = 0\\).\nAgain, it’s important to note that the potential and Green’s function we found is only valid outside the sphere. These formulas do not hold inside the sphere, which is outside the boundary surface.\nWe can find the charge induced on the surface of the conductor as well. Letting \\(\\mathbf{n} = r \\mathbf{e}_r\\), the surface charge density \\(\\sigma\\) turns out to be given by \\[\n\\sigma = -\\frac{1}{4\\pi} \\frac{\\partial \\phi}{\\partial r} = -\\frac{1}{4\\pi R^2} \\frac{R}{d} \\frac{1-\\frac{R^2}{d^2}}{\\big(1 + \\frac{R^2}{d^2} - 2 \\frac{R}{d} \\cos\\alpha \\big)^{3/2}} \\ .\n\\] Notice that \\(\\sigma\\) now depends on the location of the field point as well due to the presence of the \\(\\cos\\alpha\\) term. The density is evidently highest when \\(\\alpha = 0\\), which is the area on the sphere closest to the point charge, and lowest when \\(\\alpha = \\pi\\), which is the area on the sphere farthest from the point charge. As the point charge moves farther away the density decreases.\nBy evaluating the surface integral, one can again show that the induced charge is given by the induced charge, with \\[\nQ = \\oint_{\\mathcal{S}} da \\ \\sigma = q' = -\\frac{R}{d} q \\ .\n\\] We can also calculate the force between the point charge and the conducting sphere if we like. Since the image charge problem is equivalent, we can just use Coulomb’s Law between the charge \\(q\\) and its image charge \\(q'\\) to get \\[\n\\mathbf{F} = \\frac{qq'}{|\\mathbf{d} - \\mathbf{d}'|^2} \\mathbf{e}_r = -\\frac{q^2 R}{d^3\\big(1 - \\frac{R^2}{d^2}\\big)^2} \\mathbf{e}_r \\ .\n\\] Evidently the force between the conductor and the point charge is always attractive. When the charge is near the conductor, the force goes like \\(F \\sim (d-R)^{-2}\\) similar to a monopole field, but as the charge moves farther away the force goes like \\(F \\sim d^{-3}\\), more similar to a dipole field.\n\n\nExample: Point charge near an ungrounded conducting sphere\nIn the previous example we considered the problem of a point charge in the presence of a grounded conducting sphere. In fact, there’s no necessary reason that the conductor to be grounded. We can hold it at any fixed potential we like, but to do so we need to modify the potential somewhat to account for this.\nSuppose the sphere is held at a constant potential \\(\\phi=V\\). We’ll again place an image charge \\(q' = -\\frac{R}{d} q\\) at a distance \\(d' = \\frac{R^2}{d}\\). However, we need to cancel the potential on the surface of the sphere as well. To address this, we can place another image charge at the origin with charge \\(q'' = VR\\), to ensure that when \\(|\\mathbf{x}| = R\\) we have \\(\\phi = V\\) as expected.\nFIGURE\nThen we have \\[\n\\phi(\\mathbf{x}) = \\frac{q}{|\\mathbf{x} - d\\mathbf{n}|} - \\frac{\\frac{R}{d}q}{|\\mathbf{x} - \\frac{R^2}{d^2}\\mathbf{n}|} + \\frac{VR}{|\\mathbf{x}|} \\ .\n\\] We can use this to get the Green’s function in the usual way by dividing by \\(q\\). In this case, the function \\[\nF(\\mathbf{x} - \\mathbf{d}) = -\\frac{\\frac{R}{d}q}{|\\mathbf{x} - \\frac{R^2}{d^2}\\mathbf{n}|} + \\frac{VR}{|\\mathbf{x}|}\n\\] will satisfy Laplace’s equation. In fact, each term satisfies Laplace’s equation separately, as one can check.\nOne can check that the charge \\(Q\\) on the surface of the sphere is given by \\(Q = q' + q'' = VR - \\frac{R}{d} q\\). The force between the ungrounded sphere and the point charge is evidently given by \\[\n\\mathbf{F} = q\\bigg(\\frac{q'}{|\\mathbf{d} - \\mathbf{d}'|^2} + \\frac{VR}{|\\mathbf{d}|^2}\\bigg)\\mathbf{e}_r = \\frac{q}{d^2} \\bigg(VR - \\frac{qRd^3}{\\big(d^2 - R^2\\big)^2}\\bigg) \\mathbf{e}_r \\ .\n\\] Now, the force includes both the dipole contribution from before, as well as a new monopole contribution due to the presence of the fixed potential \\(V\\). This means in the far field limit \\(d \\gg R\\) the force reduces to Coulomb’s Law between point charges \\(Q\\) and \\(q\\).\nIn the opposite limit where \\(d \\approx R\\) things are somewhat more interesting. Suppose that \\(d = R + \\delta\\), where \\(\\delta \\ll r\\). After working out the math, we find that very close to the surface \\(\\mathbf{F} \\sim -\\frac{q^2}{4\\delta^2} \\mathbf{e}_r\\). That is, no matter what the force becomes infinitely attractive near the surface, even if \\(q\\) and \\(Q\\) have the same sign.\nThe point where this attraction happens is usually very close to the sphere. One can show that when \\(Q \\approx VR \\gg q\\), the force has an unstable equilibrium at \\(d \\approx R\\big(1 + \\frac{1}{2}\\sqrt{\\frac{q}{VR}}\\big)\\). For example, an electron near the surface of a conductor with radius \\(R = 30 \\ \\text{cm}\\) and \\(V = 1 \\ \\text{V}\\) will experience this attraction only when \\(d-R \\lesssim 10 \\ \\mu\\text{m}\\).\nWe can use this fact to interpret why charges almost never leave the surface of a conductor in the presence of an external field. If they tried to, they’d always be pulled back to the surface by this very powerful attractive force.\n\n\nExample: Point charge near two grounded conducting perpendicular sheets\nSuppose we have a point charge \\(q\\) located at point \\(\\mathbf{d} = (a,b)\\) above two perpendicular grounded conducting sheets in the \\(xy\\)-plane. It’s not too hard to see that using a single image charge for this problem won’t work, no matter what its charge or position is. We’ll need multiple. But how many? It turns out we’ll need 3 image charges.\nConsider an equivalent problem where we have 3 image charges \\(q',q'',q'''\\) located at positions \\(\\mathbf{d}'\\), \\(\\mathbf{d}''\\), and \\(\\mathbf{d}'''\\) respectively. The potential of this configuration is evidently given by \\[\n\\phi(\\mathbf{x}) = \\frac{q}{|\\mathbf{x}-\\mathbf{d}|} + \\frac{q'}{|\\mathbf{x}-\\mathbf{d}'|} + \\frac{q''}{|\\mathbf{x}-\\mathbf{d}''|} + \\frac{q'''}{|\\mathbf{x}-\\mathbf{d}'''|} \\ .\n\\] To arrange these image charges in a way that satisfies the boundary condition \\(\\phi(0,y)=\\phi(x,0)=0\\), we’ll choose \\[\n\\begin{align*}\nq' = -q \\quad &, \\quad \\mathbf{d}' = (-a,b) \\ , \\\\\nq'' = -q \\quad &, \\quad \\mathbf{d}'' = (a,-b) \\ , \\\\\nq''' = q \\quad &, \\quad \\mathbf{d}''' = (-a,-b) \\ . \\\\\n\\end{align*}\n\\] This configuration of charges is called the simple quadrupole, a concept we’ll return to in more generality later.\n\n\n\n\n\nNow, observe if we plug these values back into the potential we get \\[\n\\phi(\\mathbf{x}) = \\frac{q}{\\sqrt{(x-a)^2+(y-b)^2}} - \\frac{q}{\\sqrt{(x+a)^2+(y-b)^2}} - \\frac{q}{\\sqrt{(x-a)^2+(y+b)^2}} + \\frac{q}{\\sqrt{(x+a)^2+(y+b)^2}} \\ .\n\\] Observe now that if we set \\(\\mathbf{x}=(x,0)\\) or \\(\\mathbf{x}=(0,y)\\) the potential vanishes, meaning this potential satisfies the boundary conditions, and hence by uniqueness must also be the correct potential for the original BVP. Dividing by \\(q\\) will again give us the Green’s function as usual.\nThe force between the point charge and the two sheets is given in the usual way. We end up with \\[\n\\mathbf{F} = q^2 \\bigg(\\frac{a}{(a^2+b^2)^{3/2}} - \\frac{1}{a^2}\\bigg)\\mathbf{e}_x + q^2 \\bigg(\\frac{b}{(a^2+b^2)^{3/2}} - \\frac{1}{b^2}\\bigg)\\mathbf{e}_y \\ .\n\\] Interestingly, this exact same problem can attempt to be carried out for two conducting sheets separated by an angle \\(\\theta\\). One can be convinced that in this general case, the method of images will only work for angles \\(\\theta = \\frac{\\pi}{4}, \\frac{\\pi}{3}, \\frac{\\pi}{2}, \\pi\\). The lower the angle, the more image charges will be needed to match the problem configuration. If any other angles are tried, one is forced to place image charges inside the boundary surface, which of course is not allowed for the method of images are work.\n\n\nExample: Conducting sphere in a uniform electric field\nWe’ll consider now a problem that involves no point charges at all. Suppose a uniform conducting sphere of radius \\(R\\) lies in the presence of a uniform electric field \\(\\mathbf{E}_0\\). Though not at all obvious, we can solve this problem using the method of images as well.\nWe’ll suppose the sphere is centered at the origin, and that \\(\\mathbf{E}_0 = E_0 \\mathbf{e}_z\\) points along the \\(z\\)-axis of the sphere. To turn this into an image problem, we can think of the electric field as being generated by two opposite charges \\(q_\\pm = \\pm q\\) each located a distance \\(d \\gg R\\) from the origin with positions \\(\\mathbf{d}_\\pm = \\pm R\\mathbf{e}_z\\). Then the electric field will be approximately constant near the sphere, with \\[\nE_0 \\approx \\frac{2q}{d^2} \\ .\n\\] If we send \\(q, d\\) to infinity in a way such that this ratio stays constant, \\(E_0\\) will become exactly uniform at every point.\nFIGURE\nNow, we know how to solve the problem of point charges in the presence of a conducting sphere. Each charge \\(q_+\\) and \\(q_-\\) will have associated image charges inside the sphere with charges and positions given by \\[\nq_\\pm' = \\mp q \\frac{R}{d} \\quad , \\quad \\mathbf{d}_\\pm' = \\frac{R^2}{d} \\mathbf{e}_z \\ .\n\\] Then the potential near the \\(\\phi(\\mathbf{x})\\) near the sphere will be given by \\[\n\\begin{align*}\n\\phi(\\mathbf{x}) &= \\frac{q_+}{|\\mathbf{x} - \\mathbf{d}_+|} + \\frac{q_-}{|\\mathbf{x} - \\mathbf{d}_-|} + \\frac{q_+'}{|\\mathbf{x} - \\mathbf{d}_+'|} + \\frac{q_-'}{|\\mathbf{x} - \\mathbf{d}_-'|} \\\\\n&= q \\bigg[\\frac{1}{\\sqrt{r^2 + d^2 + 2rd\\cos\\theta}} - \\frac{1}{\\sqrt{r^2 + d^2 - 2rd\\cos\\theta}} - \\frac{R/d}{\\sqrt{r^2 + (R^2/d)^2 + 2r(R^2/d)\\cos\\theta}} \\\\\n&\\quad + \\frac{R/d}{\\sqrt{r^2 + (R^2/d)^2 - 2r(R^2/d)\\cos\\theta}}\\bigg] \\ .\n\\end{align*}\n\\] Again, the term in brackets is the Green’s function under Dirichlet boundary conditions.\nNow, to make this exact for a uniform field we need to send \\(d \\rightarrow \\infty\\). In this limit, we can assume that \\(r \\ll d\\), meaning we can factor out \\(d^2\\) from the roots and use the binomial approximation on each term to write \\[\n\\phi(\\mathbf{x}) = -\\frac{2q}{d^2} r \\cos\\theta + \\frac{2q}{d^2} \\frac{R^3}{r^2} \\cos\\theta + O\\bigg(\\frac{r}{d}\\bigg) \\ .\n\\] The higher-order terms will vanish as \\(d \\rightarrow \\infty\\). What remains are terms proportional to the uniform electric field \\(E_0 = \\frac{2q}{d^2}\\), \\[\n\\phi(\\mathbf{x}) = -E_0\\bigg(r - \\frac{R^3}{r^2}\\bigg) \\cos\\theta \\ .\n\\] Notice the first term is just \\(-E_0 z = -E_0 r\\cos\\theta\\), which is what we’d expect for the potential of a uniform electric field in the absence of any conductors. The second term then is evidently the potential of the induced charge density on the sphere, which is equivalent of course to the potential of the image charges. The induced charge density is given in the usual way, \\[\n\\sigma = -\\frac{1}{4\\pi} \\frac{\\partial \\phi}{\\partial r} \\bigg|_{r=R} = \\frac{3}{4\\pi} E_0 \\cos\\theta \\ .\n\\] Evidently, the surface integral of \\(\\sigma\\) in this case will vanish, meaning no net induced charge will accumulate on the sphere, \\[\nQ = \\oint_\\mathcal{S} da \\ \\sigma = \\frac{3}{2} E_0 R^2 \\int_0^\\pi d\\theta \\sin\\theta \\cos\\theta = 0 \\ .\n\\] This can also be seen, of course, by noticing that the image charges \\(q'_+\\) and \\(q_-'\\) are equal and opposite, so their sum will vanish. This doesn’t mean, of course, that there’s no charge on the sphere. Indeed, we’d expect that in the direction of the field, positive charges will concentrate at one pole and negative charges on the other. What this result says is the net charge will be zero.\n\n\n\nGreen’s Function for a Sphere\nLet’s consider again the example of a point charge \\(q\\) in the presence of a grounded conducting sphere of radius \\(R\\). If we let \\(r'\\) denote the distance of the point charge from the origin, we saw that we could write the Green’s function for this problem by \\[\nG_D(\\mathbf{x} - \\mathbf{x}') = \\frac{1}{\\sqrt{r^2 + r'^2 - 2rr'\\cos\\alpha}} - \\frac{R/r'}{\\sqrt{R^2 + \\frac{r^2 r'^2}{R^2} - 2rr'\\cos\\alpha}} \\ ,\n\\] where \\(\\alpha\\) is the angle between the field point \\(\\mathbf{x}\\) and the source point \\(\\mathbf{x}'\\).\nWe can use this Green’s function as a building block to find solutions to any problem whose potential is specified on the surface of a sphere. Recall from a few sections back that we saw we could express the potential in the presence of Dirichlet boundary conditions by the formal solution \\[\n\\phi(\\mathbf{x}) = \\int_\\mathcal{V} d^3 \\mathbf{x}' \\ \\rho(\\mathbf{x}') G_D(\\mathbf{x} - \\mathbf{x}') - \\frac{1}{4\\pi} \\oint_\\mathcal{S} da' \\ \\phi \\frac{\\partial G_D}{\\partial n'} \\ .\n\\] Provided we can find the Green’s function and we know the value of the potential on some given boundary surface, we have a unique solution of this form for the potential everywhere in space.\nNow, suppose we have some charge distribution \\(\\rho(\\mathbf{x})\\) located some distance away from a sphere of radius \\(R\\) whose surface is held at some known potential \\(\\phi_0 = \\phi(R,\\theta',\\varphi')\\). Since \\(\\mathcal{S}\\) is a sphere and the charge distribution lies outside the sphere, its surface normal \\(\\mathbf{n}'\\) will point inward toward the sphere with \\(\\mathbf{n}' = -\\mathbf{e}_{r'}\\). This means the normal derivative of \\(G_D\\) at the surface of the sphere will be \\[\n\\frac{\\partial G_D}{\\partial n'} = -\\frac{\\partial G_D}{\\partial r'} \\bigg|_{r'=R} = -\\frac{(r^2 - R^2)/R}{(r^2 + R^2 - 2Rr \\cos\\alpha)^{3/2}} \\ .\n\\] Plugging this in and using the fact that the area element is \\(da' = R^2 d\\Omega'\\) on the surface of the sphere, we can express the potential for any charge distribution \\(\\rho(\\mathbf{x})\\) outside a sphere of known potential by the integral \\[\n\\begin{align*}\n\\phi(\\mathbf{x}) = &\\int_\\mathcal{V} d^3 \\mathbf{x}' \\ \\rho(\\mathbf{x}') \\bigg[\\frac{1}{\\sqrt{r^2 + r'^2 - 2rr'\\cos\\alpha}} - \\frac{R/r'}{\\sqrt{R^2 + \\frac{r^2 r'^2}{R^2} - 2rr'\\cos\\alpha}}\\bigg] \\\\\n&+ \\frac{1}{4\\pi} \\oint_\\mathcal{S} d\\Omega' \\ \\phi(R,\\theta',\\varphi') \\frac{R(r^2 - R^2)}{(r^2 + R^2 - 2Rr \\cos\\alpha)^{3/2}} \\ ,\n\\end{align*}\n\\] where \\(\\cos\\alpha\\) can be expressed in terms of the trig relation \\[\n\\cos\\alpha = \\cos\\theta \\cos\\theta' + \\sin\\theta \\sin\\theta' \\cos(\\varphi-\\varphi') \\ .\n\\] This is an imposing set of integrals to solve though, so it’s perhaps worth looking at a simplifying scenario. Suppose there are no other charges present other than the sphere. Then we can neglect the volume integral and express the potential by \\[\n\\phi(\\mathbf{x}) = \\frac{1}{4\\pi} \\oint_\\mathcal{S} d\\Omega' \\ \\phi(R,\\theta',\\varphi') \\frac{R(r^2 - R^2)}{(r^2 + R^2 - 2Rr \\cos\\alpha)^{3/2}} \\ .\n\\] Note that we can easily write down the potential inside the sphere as well. All we need to do is flip the sign on the normal derivative, which is equivalent to replacing \\(r^2 - R^2 \\rightarrow R^2 - r^2\\) in the integral above. Everything else is the same.\n\nExample: Conducting sphere with hemispheres of opposite potentials\nSuppose we have a hollow sphere of radius \\(R\\) consisting of two hemispheres held at opposite fixed potentials \\(\\pm V\\) that are separated by a thin insulating ring at the equator. We want to find the potential that matches these boundary conditions on the surface of the sphere.\nFIGURE\nSince there are no other source charges present, we can express the potential in terms of the integral given above, \\[\n\\phi(\\mathbf{x}) = \\frac{1}{4\\pi} \\oint_\\mathcal{S} d\\Omega' \\ \\phi(R,\\theta',\\varphi') \\frac{R(r^2 - R^2)}{(r^2 + R^2 - 2Rr \\cos\\alpha)^{3/2}} \\ .\n\\] We require that \\(\\phi(R,\\theta',\\varphi') = +V\\) when \\(0 \\leq \\theta' &lt; \\frac{\\pi}{2}\\) and \\(\\phi(R,\\theta',\\varphi') = -V\\) when \\(\\frac{\\pi}{2} &lt; \\theta' \\leq \\pi\\). Plugging this in, we get \\[\n\\phi(\\mathbf{x}) = \\frac{VR(r^2 - R^2)}{4\\pi} \\int_0^{2\\pi} d\\varphi' \\bigg[\\int_0^{\\pi/2} \\sin\\theta' d\\theta' - \\int_{\\pi/2}^\\pi \\sin\\theta' d\\theta'\\bigg] \\frac{1}{(r^2 + R^2 - 2Rr \\cos\\alpha)^{3/2}} \\ .\n\\] We can simplify this expression somewhat by making the change of variables \\(\\theta' \\rightarrow \\pi - \\theta', \\varphi' \\rightarrow \\pi + \\varphi'\\) on the second \\(\\theta'\\) integral, combining terms, and making a change of variable \\(\\mu' = \\cos\\theta'\\) to write \\[\n\\phi(\\mathbf{x}) = \\frac{VR(r^2 - R^2)}{4\\pi} \\int_0^{2\\pi} d\\varphi' \\int_0^1 d\\mu' \\bigg[\\frac{1}{(r^2 + R^2 - 2Rr \\cos\\alpha)^{3/2}} - \\frac{1}{(r^2 + R^2 + 2Rr \\cos\\alpha)^{3/2}}\\bigg] \\ .\n\\] Unfortunately though, the presence of the term \\(\\cos\\alpha = \\cos\\theta \\cos\\theta' + \\sin\\theta \\sin\\theta' \\cos(\\varphi-\\varphi')\\) still makes this integral impossible to easily solve. But we can solve it in one simplifying case, when the field point is located on the positive \\(z\\)-axis, so \\(r=z\\). In that case, we can simply write \\(\\cos\\alpha = \\cos\\theta' = \\mu'\\). Then the \\(\\varphi'\\) integral becomes trivial, and we have \\[\n\\phi(z\\mathbf{e}_z) = \\frac{VR(z^2 - R^2)}{2} \\int_0^1 d\\mu' \\bigg[\\frac{1}{(z^2 + R^2 - 2Rz \\mu')^{3/2}} - \\frac{1}{(z^2 + R^2 + 2Rz \\mu')^{3/2}}\\bigg] \\ .\n\\] Both integrals can be easily solved using substitutions of the form \\(u = r^2 + R^2 \\mp 2Rr \\mu'\\). We finally get \\[\n\\phi(z\\mathbf{e}_z) = V \\bigg[1 - \\frac{(z^2 - R^2)/z}{\\sqrt{z^2 + R^2}}\\bigg] \\ .\n\\] Let’s check that this solution makes sense. When \\(z=R\\) we get \\(\\phi = V\\), which is what we expect when \\(z &gt; 0\\), which we assumed. When \\(z \\gg R\\) we get \\(\\phi \\sim \\frac{3VR^2}{2z^2}\\), which means the potential falls off faster than it would for a point charge. In fact, it falls off like a dipole. This should make sense, given that we have two identical hemispheres held at opposite potentials, which means they have a net charge of zero and effectively act as a sort of dipole.\nWhile we can’t evaluate the general integral for this potential for arbitrary \\(\\mathbf{x}\\), we can at least get a series solution. The idea here is to suppose we’re far away from the sphere, so that \\(r \\gg R\\), and define \\(\\varepsilon \\equiv (R/r)^2\\). If we expand the integrand in powers of \\(\\varepsilon\\) and integrate term by term, it’s possible to show that the potential we end up with has the form \\[\n\\phi(\\mathbf{x}) = \\frac{3VR^2}{2r^2} \\bigg(P_1(\\cos\\theta) - \\frac{7R^2}{12r^2} P_3(\\cos\\theta) + \\cdots\\bigg) \\ .\n\\] Here each term \\(P_\\ell(\\cos\\theta)\\) is the Legendre polynomial of degree \\(\\ell\\). Details on the Legendre polynomials can be found in the appendix. Evidently, the potential given only includes the odd degree polynomials. The even degree terms vanish due to the polar symmetry in the problem. The first two odd Legendre polynomials are given by \\[\nP_1(\\cos\\theta) = \\cos\\theta \\quad , \\quad P_3(\\cos\\theta) = \\frac{1}{2} (5\\cos^3\\theta - 3\\cos\\theta) \\ .\n\\] The further we are from the sphere, the better we can approximate this series solution by keeping only the first few terms. In fact, this is the entire idea behind the multipole expansion, something we’ll cover in great detail in a future chapter.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Boundary Value Problems I</span>"
    ]
  },
  {
    "objectID": "electrodynamics/bvps-2.html",
    "href": "electrodynamics/bvps-2.html",
    "title": "Boundary Value Problems II",
    "section": "",
    "text": "Linear Partial Differential Equations\nIn the previous chapter we showed that, at least formally, we can solve Poisson’s equation subject to some given set of boundary conditions by the integral \\[\n\\phi(\\mathbf{x}) = \\int_\\mathcal{V} d^3 \\mathbf{x}' \\ \\rho(\\mathbf{x}') G(\\mathbf{x} - \\mathbf{x}') + \\frac{1}{4\\pi} \\oint_\\mathcal{S} da' \\ \\bigg[G \\frac{\\partial \\phi}{\\partial n'} - \\phi \\frac{\\partial G}{\\partial n'} \\bigg] \\ ,\n\\] where \\(G(\\mathbf{x} - \\mathbf{x}')\\) is the Green’s function. This isn’t, however, the only way to solve Poisson’s equation, nor is it always the most useful. For all but the simplest problems this integral can be very difficult to solve in practice.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Boundary Value Problems II</span>"
    ]
  },
  {
    "objectID": "electrodynamics/bvps-2.html#linear-partial-differential-equations",
    "href": "electrodynamics/bvps-2.html#linear-partial-differential-equations",
    "title": "Boundary Value Problems II",
    "section": "",
    "text": "General Problem\nAnother way we can proceed is to solve Poisson’s equation directly using standard PDE methods. Suppose we have a linear PDE of the form \\[\n\\mathcal{L} \\phi(\\mathbf{x}) = f(\\mathbf{x}) \\ ,\n\\] where \\(\\mathcal{L}\\) is a linear partial differential operator and \\(f(\\mathbf{x})\\) is some source term, e.g. the charge density \\(\\rho(\\mathbf{x})\\). We assume that some set of boundary conditions may be given implicitly.\nWhen we say \\(\\mathcal{L}\\) is a linear operator, we mean that for any two functions \\(\\phi_1(\\mathbf{x})\\) and \\(\\phi_2(\\mathbf{x})\\) and constants \\(\\alpha\\) and \\(\\beta\\), we have \\[\n\\mathcal{L} \\big(\\alpha\\phi_1(\\mathbf{x}) + \\beta\\phi_2(\\mathbf{x})\\big) = \\alpha\\mathcal{L} \\phi_1(\\mathbf{x}) + \\beta\\mathcal{L} \\phi_2(\\mathbf{x}) \\ .\n\\] Linearity means we can compose solutions to a linear PDE using the principle of superposition. In fact we can say more than this. The theory of linear PDEs guarantees that we can solve any linear PDE by finding two solutions of a particular kind and summing them together:\n\nA general homogeneous solution \\(\\phi_h(\\mathbf{x})\\) that solves the homogeneous PDE \\(\\mathcal{L} \\phi_h(\\mathbf{x}) = 0\\) subject to the boundary conditions.\nA particular solution \\(\\phi_p(\\mathbf{x})\\) that solves the inhomogeneous PDE \\(\\mathcal{L} \\phi_p(\\mathbf{x}) = f(\\mathbf{x})\\) in the absence of boundary conditions.\n\nProvided we can find these two solutions, the most general solution to \\(\\mathcal{L} \\phi(\\mathbf{x}) = f(\\mathbf{x})\\) can be written in the form \\[\n\\phi(\\mathbf{x}) = \\phi_h(\\mathbf{x}) + \\phi_p(\\mathbf{x}) \\ .\n\\] All of the PDEs we’ll see in electromagnetism, and indeed in most of physics, turn out to be linear second-order PDEs. The most general spatial second-order linear partial differential operator we can write down is a linear superposition of first and second partial derivatives, plus an ordinary function. We can write this with summation notation in the form \\[\n\\mathcal{L} = a_{ij}(\\mathbf{x}) \\frac{\\partial^2}{\\partial x_i \\partial x_j} + b_i(\\mathbf{x}) \\frac{\\partial}{\\partial x_i} + c(\\mathbf{x}) \\ .\n\\] In particular, we can see that the Laplacian \\(\\nabla^2\\) is a linear operator if we take \\(a_{ij} = \\delta_{ij}\\) and \\(b_i = c = 0\\). This means we can solve Poisson’s equation in the way specified before, by finding a homogeneous solution that solves Laplace’s equation subject to the boundary conditions, and a particular solution that solves Poisson’s equation with a given charge density \\(\\rho(\\mathbf{x})\\).\nFor a localized charge distribution, we already know how to find the particular solution via the integral \\[\n\\phi_p(\\mathbf{x}) = \\int d^3 \\mathbf{x}' \\ \\frac{\\rho(\\mathbf{x}')}{|\\mathbf{x} - \\mathbf{x}'|} \\ .\n\\] This means to solve the general PDE we only need to find the homogeneous solution \\(\\phi_h(\\mathbf{x})\\) that solves Laplace’s equation \\(\\nabla^2 \\phi_h = 0\\) subject to the given boundary conditions, and we’ll have a general solution to Poisson’s equation subject to those boundary conditions.\nNotice how similar this looks to the formal solution approach we took before using Green’s functions. In fact the two approaches are completely equivalent, as they should be. Recall the formal solution could be written \\[\n\\phi(\\mathbf{x}) = \\int_\\mathcal{V} d^3 \\mathbf{x}' \\ \\rho(\\mathbf{x}') G(\\mathbf{x} - \\mathbf{x}') + \\frac{1}{4\\pi} \\oint_\\mathcal{S} da' \\ \\bigg[G \\frac{\\partial \\phi}{\\partial n'} - \\phi \\frac{\\partial G}{\\partial n'} \\bigg] \\ ,\n\\] where the Green’s function is given by \\[\nG(\\mathbf{x} - \\mathbf{x}') = \\frac{1}{|\\mathbf{x} - \\mathbf{x}'|} + F(\\mathbf{x} - \\mathbf{x}') \\ .\n\\] The first integral is just the particular solution \\(\\phi_p(\\mathbf{x})\\). The second integral is in fact the homogeneous solution \\(\\phi_h(\\mathbf{x})\\), which is evidently closely related to the homogeneous part of the Green’s function, \\(F(\\mathbf{x} - \\mathbf{x}')\\).\nSince we know how to find the particular solution, what remains is finding the homogeneous solution. This involves solving Laplace’s equation subject to the given boundary conditions. This is what the rest of this chapter will focus on.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Boundary Value Problems II</span>"
    ]
  },
  {
    "objectID": "electrodynamics/bvps-2.html#separation-of-variables",
    "href": "electrodynamics/bvps-2.html#separation-of-variables",
    "title": "Boundary Value Problems II",
    "section": "Separation of Variables",
    "text": "Separation of Variables\nThe most popular technique for solving linear PDEs analytically is the separation of variables method. Suppose we have an arbitrary homogeneous linear PDE of the form \\[\n\\mathcal{L} \\phi(\\mathbf{x}) = 0 \\ .\n\\] The separation of variables of variable method works exactly as the name suggests. We first assume that in some coordinate system \\((u,v,w)\\) that \\(\\phi(\\mathbf{x})\\) can be written as a trial solution that’s a product of univariate functions of only those coordinates, \\[\n\\phi(\\mathbf{x}) = U(u) V(v) W(w) \\ .\n\\] Provided the linear operator \\(\\mathcal{L}\\) in this coordinate system can be separated into linear operators acting only on these variables alone, i.e. \\(\\mathcal{L} = \\mathcal{L}_u + \\mathcal{L}_v + \\mathcal{L}_w \\ \\), we can plug this trial solution in and divide by \\(UVW\\) and write \\[\n\\frac{1}{U(u)}\\mathcal{L}_u U(u) + \\frac{1}{V(v)}\\mathcal{L}_v V(v) + \\frac{1}{W(w)}\\mathcal{L}_v W(w) = 0 \\ .\n\\] Now, notice we have an equation of the form \\[\nf(u) + g(v) + h(w) = 0 \\ .\n\\] Since each of these functions is an independent function of its own coordinate, the only way their sum can be zero for all possible \\(u,v,w\\) is if each of these functions is constant and those constants all sum to zero, i.e. \\[\nf(u) = \\alpha \\ , \\ g(v) = \\beta \\ , \\ h(w) = \\gamma \\ , \\ \\alpha + \\beta + \\gamma = 0 \\ .\n\\] That is, we must have three coupled ordinary differential equations of the form \\[\n\\begin{align*}\n&\\mathcal{L}_u U(u) = \\alpha U(u) \\ , \\\\\n&\\mathcal{L}_v V(v) = \\beta V(v) \\ , \\\\\n&\\mathcal{L}_w W(w) = \\gamma W(w) \\ , \\\\\n&\\alpha + \\beta + \\gamma = 0 \\ .\n\\end{align*}\n\\] All that remains now is to solve each of these ODEs and impose the boundary conditions. Provided we can find a set of three functions \\(U,V,W\\) that solve these ODEs as well as the boundary conditions, we can reassemble them to get the full solution.\nThose that have read the appendix will notice that each of these differential equations is an eigenvalue problem with eigenvalues \\(\\alpha\\), \\(\\beta\\), and \\(\\gamma\\) respectively. Typically one or more of the separation constants will end up being quantized in terms of an integer whose eigenfunctions form a complete orthonormal set inside the boundary region. For example, we may end up with a set of three quantized differential equations of the form \\[\n\\begin{align*}\n&\\mathcal{L}_u U_n(u) = \\alpha_n U_n(u) \\ , \\\\\n&\\mathcal{L}_v V_m(v) = \\beta_m V_m(v) \\ , \\\\\n&\\mathcal{L}_w W_k(w) = \\gamma_k W_k(w) \\ , \\\\\n&\\alpha_n + \\beta_m + \\gamma_k = 0 \\ ,\n\\end{align*}\n\\] where \\(n,m,k\\) are integers. The product of \\(U_n, V_m, W_k\\) will then give rise to a basis solution of the form \\[\n\\phi_{nmk}(u,v,w) = U_n(u) V_m(v) W_k(w) \\ .\n\\] Since \\(U_n(u)\\), \\(V_m(v)\\), and \\(W_k(w)\\) are each complete sets of orthogonal functions on their own intervals, \\(\\phi_{nmk}\\) will also form a complete set of orthogonal functions in 3-dimensional space. To get the most general solution that solves the boundary value problem, we can use the principle of superposition to sum over a weighted combination of these basis functions to get \\[\n\\phi(\\mathbf{x}) = \\sum_{n,m,k} c_{nmk} \\phi_{nmk}(u,v,w) \\ .\n\\] At this point there will be one more boundary condition left that we still need to satisfy, usually that the potential needs to equal some known function \\(f\\) on one of the boundaries. We can use this last boundary condition along with the orthogonality of the basis functions to determine the coefficients \\(c_{nmk}\\). Once we find these coefficients we’ll have the general solution to the boundary value problem.\nIn this chapter we’ll only be concerned with solving Laplace’s equation, where \\(\\mathcal{L} = \\nabla^2\\). In this case, we can guarantee by the uniqueness theorem that once we find the general solution that fits the boundary conditions that it will be unique, provided the boundary conditions are Dirichlet, Neumann, or mixed, which in practice they always will be.\nThis process will be much easier to illustrate by looking at specific problems. We’ll do that first by considering Laplace’s equation in Cartesian coordinates, before looking at Laplace’s equation in spherical and cylindrical coordinates as well. By the end, the process of how to use separation of variables to find the general solution should hopefully be quite clear.\n\nLaplace’s Equation in Cartesian Coordinates\nWe’ll now turn our focus to solving Laplace’s equation \\(\\nabla^2 \\phi(\\mathbf{x}) = 0\\) using separation of variables, subject to either Dirichlet, Neumann, or mixed boundary conditions. Since the Laplacian looks different in different coordinate systems, we’ll need separate variables and solve this PDE in different coordinate systems of interest, i.e. Cartesian, spherical, and cylindrical coordinates.\nWe start with the simplest case of solving Laplace’s equation in Cartesian coordinates \\((x,y,z)\\). In this coordinate system the Laplacian has an especially simple form, with \\[\n\\nabla^2 \\phi = \\frac{\\partial^2 \\phi}{\\partial x^2} + \\frac{\\partial^2 \\phi}{\\partial y^2} + \\frac{\\partial^2 \\phi}{\\partial z^2} \\ .\n\\] To match with the general setup from before, we can take \\(\\mathcal{L} = \\nabla^2\\), \\(\\mathcal{L}_x = \\partial_x^2\\), \\(\\mathcal{L}_y = \\partial_y^2\\), and \\(\\mathcal{L}_z = \\partial_z^2\\).\nWe now apply the separation of variables by supposing a trial solution exists of the form \\[\n\\phi(\\mathbf{x}) = X(x) Y(y) Z(z) \\ .\n\\] Plugging this into Laplace’s equation and dividing by \\(\\phi = XYZ\\), we get \\[\n0 = \\frac{1}{X} \\frac{d^2 X}{dx^2} + \\frac{1}{Y} \\frac{d^2 Y}{dy^2} + \\frac{1}{Z} \\frac{d^2 Z}{dz^2} \\ .\n\\] Again, since each term is a function of its own variable, the only way this equation can be satisfied for all coordinate values is if each term is constant, and those constants sum to zero. This gives us three coupled ordinary differential equations of the form \\[\n\\begin{align*}\n&\\frac{d^2 X}{dx^2} = \\alpha_x X \\ , \\\\\n&\\frac{d^2 Y}{dy^2} = \\alpha_y Y \\ , \\\\\n&\\frac{d^2 Z}{dz^2} = \\alpha_z Z \\ , \\\\\n&\\alpha_x + \\alpha_y + \\alpha_z = 0 \\ .\n\\end{align*}\n\\] Notice that we now have three uncoupled linear ordinary second differential equations to solve, which can be easily done once we know the boundary conditions. Once we’ve solved these equations, we can stitch them back together to get the general solution for the potential \\(\\phi(\\mathbf{x})\\).\nAt this point it will be easiest to proceed by illustrating this technique with a simple example, since to go any further we need to impose some boundary conditions. We’ll consider a simple 2-dimensional problem involving only \\(x\\) and \\(y\\). Suppose we have two grounded parallel conducting sheets separated by a distance \\(L\\). On one end, the two sheets are separated with insulating material from a perpendicular third conducting sheet held at a constant potential \\(V\\), while on the other end the two parallel sheets extend infinitely far.\nFIGURE\nWe’ll assume the sheets are oriented parallel to the \\(xz\\)-plane and separated along the \\(y\\)-axis from \\(y=0\\) to \\(y=L\\). This means the sheet is held at constant potential \\(\\phi = V\\) at \\(x=0\\), and at \\(\\phi = 0\\) when \\(y=0\\) or \\(y=L\\). We will require that the potential not blow up at infinity as well. Assuming there are no other source charges present, this means we have the following boundary value problem to solve, \\[\n\\begin{align*}\n\\begin{cases}\n\\nabla^2 \\phi = 0 \\ , \\\\\n\\text{where} \\ \\phi(0,y) = V \\ , \\\\\n\\phi(x,0) = \\phi(x,L) = 0 \\ , \\\\\n|\\phi| &lt; \\infty \\ \\text{for all} \\ 0 \\leq x \\leq \\infty \\ .\n\\end{cases}\n\\end{align*}\n\\] Now we can employ separation of variables. Suppose a trial solution of the form\n\\[\n\\phi(x,y) = X(x) Y(y) Z(z) \\ .\n\\] We neglect the \\(z\\) coordinate since it isn’t contributing anything to the problem, so we can just set \\(Z(z) = 1\\) and focus on the remaining functions \\(X(x)\\) and \\(Y(y)\\).\nNow, if we plug this trial solution into Laplace’s equation, we find the problem reduces to solving two coupled ODEs, \\[\n\\frac{1}{X} \\frac{d^2 X}{dx^2} = \\alpha \\quad , \\quad \\frac{1}{Y} \\frac{d^2 Y}{dy^2} = \\beta \\quad , \\quad \\alpha + \\beta = 0 \\ .\n\\] Now, since we only have two separation constants \\(\\alpha\\) and \\(\\beta\\), and those constants must add to zero, we immediately have that \\(\\beta = -\\alpha\\). This means we can work in terms of a single separation constant \\(\\alpha\\). We’ll suppose that \\(\\alpha = k^2\\) for some \\(k &gt; 0\\). This then gives us the following two ODEs to solve subject to the boundary conditions,\n\\[\n\\frac{d^2 X}{dx^2} = k^2 X \\quad , \\quad \\frac{d^2 Y}{dy^2} = -k^2 Y \\ .\n\\] The first equation must satisfy the boundary conditions that \\(X(x)\\) is finite at infinity, and \\(X(0) = V\\). The second equation must satisfy the boundary conditions \\(Y(0) = Y(L) = 0\\).\nThe general solution for the first equation is given by \\[\nX(x) = A e^{kx} + B e^{-kx} \\ .\n\\] If we impose the condition that \\(X(x)\\) not blow up at infinity, then we must choose \\(A=0\\) so that the first term vanishes. Then \\[\nX(x) = B e^{-kx} \\ .\n\\] We still need to impose the boundary condition \\(X(0) = V\\). We’ll come back to this at the end.\nFor the second equation, we know we can express its general solution in the form \\[\nY(y) = C \\cos ky + D \\sin ky \\ .\n\\] This solution has to satisfy the boundary conditions \\(Y(0) = Y(L) = 0\\). Plugging in the first condition requires \\(C=0\\). Plugging in the second condition, we’re left with \\[\nY(y) = D \\sin kL = 0 \\ .\n\\] The only way this can be true is if either \\(D=0\\) or \\(kL\\) is an integer multiple of \\(\\pi\\). If \\(D=0\\) we get nowhere, since that would give the trivial solution \\(Y(y) = 0\\). We’re thus left to impose the second condition. Suppose \\(kL = \\pi n\\) for some positive integer \\(n\\). This implies that \\(k\\) must be quantized as a function of \\(n\\), with \\[\nk_n = \\frac{n\\pi}{L} \\quad , \\quad n=1,2,3,\\cdots \\ .\n\\] Now, each choice of \\(k_n\\) will give rise to its own solution \\(Y_n(y) = D_n \\sin k_n y\\) that solves the differential equation \\[\n\\frac{d^2 Y_n}{dy^2} = -k_n^2 Y_n\n\\] So which \\(Y_n(y)\\) do we choose? In fact we’ll want to keep all of them, since any choice of these functions will satisfy Laplace’s equation, albeit with different separation constants. We don’t care about the separation constants. We care about the general solution to Laplace’s equation. To get the general solution, we use the fact that each \\(Y_n(y)\\) are just the Fourier sine functions. This means they will be orthogonal, and we can represent any general solution \\(Y(y)\\) as a linear superposition of \\(Y_n(y)\\). This means the general solution \\(Y(y)\\) will be a real Fourier series.\nInstead of applying superposition now though, we typically want to do it to the full potential. Notice that if we quantize \\(k\\) that \\(X(x)\\) now also becomes an infinitely family of solutions as well, with \\(X_n(x) = B_n e^{-k_n x}\\). If we now multiply \\(X_n(x)\\) and \\(Y_n(y)\\) back together, we get a basis solution \\(\\phi_n(x,y,z)\\) that solves Laplace’s equation subject to these boundary conditions. We’ll ignore the integration constants, which we’ll put back in a moment, and define the basis functions by \\[\n\\phi_n(x,y,z) \\equiv e^{-k_n x} \\sin k_n y \\ .\n\\] By construction \\(\\phi_n(x,y,z)\\) will solve Laplace’s equation subject to all boundary conditions except one, that \\(\\phi_n(0,y,z) = V\\). The only way we can also satisfy this boundary condition is to use the principle of superposition to take a weighted sum over all of these basis functions to get the most general possible expression for the potential, \\[\n\\phi(x,y,z) = \\sum_{n=1}^\\infty b_n \\phi_n(x,y,z) \\ .\n\\] Now, at this point we have one boundary condition to satisfy, and an infinite set of coefficients \\(b_n\\) to determine. Here we appeal to the property of orthogonality. Observe that when \\(x=0\\) we must have \\[\nV = \\phi(0,y,z) = \\sum_{n=1}^\\infty b_n \\sin k_n y \\ .\n\\] We know from the appendix that the functions \\(\\sin k_n y\\) will be orthogonal on the interval \\(0 \\leq y \\leq L\\). That is, we know that when \\(m \\neq n\\) we must have \\[\n\\langle \\sin k_m y | \\sin k_n y \\rangle = \\int_0^L dy \\ \\sin k_m y \\sin k_n y = 0 \\ .\n\\] This is called an inner product. Similar to how we can define a dot product between two vectors, we can define an inner product between two functions. We say two functions \\(f\\) and \\(g\\) are orthogonal provided \\(\\langle f | g \\rangle = 0\\).\nTo see what this implies, let’s multiply both expressions for \\(\\phi(0,y,z)\\) by \\(\\sin k_m y\\) and integrate from \\(y=0\\) to \\(y=L\\). That is, we want to take the inner product of both sides and solve \\(\\langle \\sin k_m y | V \\rangle = \\langle \\sin k_m | \\sin k_n y \\rangle\\). Plugging in \\(k_m = \\frac{2\\pi}{L}\\), we see that \\[\n\\langle \\sin k_m y | V \\rangle = \\int_0^L dy \\ V \\sin \\frac{m\\pi y}{L} = \\frac{VL}{m\\pi}(1-\\cos m\\pi) \\ .\n\\] Evaluating the second inner product, we get \\[\n\\begin{align*}\n\\bigg\\langle \\sin k_m \\bigg| \\sum_{n=1}^\\infty b_n \\sin k_n y \\bigg\\rangle &= \\sum_{n=1}^\\infty b_n \\int_0^L dy \\ \\sin\\frac{m\\pi y}{L} \\sin\\frac{n\\pi y}{L} \\\\\n&= \\sum_{n=1}^\\infty b_n \\frac{L}{2} \\delta_{nm} \\\\\n&= \\frac{L}{2} b_m \\ .\n\\end{align*}\n\\] Notice that we in fact didn’t need to take \\(m\\) different from \\(n\\) in these inner products. We already knew the sine functions would be orthogonal. We could have just taken the inner products with \\(\\sin k_n y\\) directly. In fact, we could’ve calculate the coefficients \\(b_n\\) directly by using the formula \\[\nb_n = \\frac{\\langle \\sin k_n y | V \\rangle}{\\langle \\sin k_n y | \\sin k_n y \\rangle} \\ .\n\\] At any rate, these two inner product expressions together give us an equation for each \\(b_n\\). We evidently have\n\\[\nb_n = \\frac{2V}{n\\pi} (1 - \\cos n\\pi) \\ .\n\\] Before plugging this back into the general solution we can simplify it a little bit. Notice that \\(\\cos n\\pi\\) will be \\(+1\\) when \\(n\\) is an even number, and \\(-1\\) when \\(n\\) is an odd number. In the even case we get \\(b_n = 0\\) since each term cancels, while in the odd case we get \\[\nb_n = \\frac{4V}{n\\pi} \\quad , \\quad n=1,3,5,\\cdots \\ .\n\\] This means the series expansion for the potential will contain only odd terms, with \\[\n\\phi(\\mathbf{x}) = \\frac{4V}{\\pi} \\sum_{n=1,3,5,\\cdots}^\\infty \\frac{1}{n} e^{-k_n x} \\sin k_n y \\ .\n\\] This expression is the most general form we can write down to the potential for this boundary value problem. By construction it satisfies all of the boundary conditions, which means by the uniqueness theorem it will be the only such solution that does.\nIf we like, we can further simplify this expression further by noting that the sum on the right-hand side has a closed form given by \\[\n\\phi(\\mathbf{x}) = \\frac{2V}{\\pi} \\tan^{-1} \\bigg(\\frac{\\sin k_n y}{\\sinh k_n x}\\bigg) \\ .\n\\] Since this potential is only a function of two variables, we can plot its equipotentials with a contour plot in the \\(xy\\)-plane. In the \\(x\\)-direction, the potential is highest at \\(x=0\\), where \\(\\phi(0,y)=V\\) before dying off exponentially as \\(x \\rightarrow \\infty\\). In the \\(y\\)-direction, the potential goes to zero at the endpoints \\(y=0\\) and \\(y=L\\), and hits its maximum at the midpoint \\(y=\\frac{L}{2}\\).\nFIGURE\nThis in essence is how separation of variables works in Cartesian coordinates. We will always end up with a potential that’s a linear superposition of exponentials and sinusoid functions, where the expansion coefficients are determined by imposing a final boundary condition of some type. Let’s work a few more complex examples to solidify the idea.\n\nExample: Infinite conducting rectangular pipe held at a given potential on one end\nLet’s now consider a slight generalization of the previous problem. Suppose we have a rectangular infinitely long conducting pipe. One end of the pipe is held at some potential \\(V(y,z)\\), while the other end extends infinitely far. Suppose the pipe has a finite width \\(a\\) and a finite depth \\(b\\), and the sides of the pipe are grounded. We want to find the potential inside the pipe.\nWe’ll orient the pipe exactly like we did in the previous problem, with the length along the \\(x\\)-axis, and the width and depth along the \\(y\\) and \\(z\\) axes. At \\(x=0\\) the potential is held constant, with \\(\\phi(0,y,z)=V(y,z)\\). At \\(y=0\\) and \\(y=a\\), and at \\(z=0\\) and \\(z=b\\), the pipe is grounded, with \\(\\phi(x,0,z) = \\phi(x,b,z) = \\phi(x,y,0) = \\phi(x,y,b) = 0\\). We’ll also require that \\(\\phi\\) not blow up at infinity.\nFIGURE\nThis means we end up with a boundary value problem to solve of the form \\[\n\\begin{align*}\n\\begin{cases}\n\\nabla^2 \\phi = 0 \\ , \\\\\n\\text{where} \\ \\phi(0,y,z) = V(y,z) \\ , \\\\\n\\phi(x,0,z) = \\phi(x,a,z) = 0 \\ , \\\\\n\\phi(x,y,0) = \\phi(x,y,b) = 0 \\ , \\\\\n|\\phi| &lt; \\infty \\ \\text{for all} \\ 0 \\leq x \\leq \\infty \\ .\n\\end{cases}\n\\end{align*}\n\\] We again employ separation of variables by assuming a trial solution of the form\n\\[\n\\phi(x,y,z) = X(x) Y(y) Z(z) \\ .\n\\] This time we can’t set \\(Z(z) = 1\\), meaning we’ll end up with three ODEs to solve instead of two. We end up with \\[\n\\frac{1}{X} \\frac{d^2 X}{dx^2} = \\alpha \\quad , \\quad \\frac{1}{Y} \\frac{d^2 Y}{dy^2} = \\beta \\quad , \\quad \\quad \\frac{1}{Y} \\frac{d^2 Z}{dz^2} = \\gamma \\quad , \\quad \\alpha + \\beta + \\gamma = 0 \\ .\n\\] At this point it’s not obvious what signs to choose for these constants. As a general rule of thumb though, if there’s an unbounded coordinate in the problem (in this case \\(x\\)) we want that coordinate to have a positive constant. Any coordinates that have fixed boundary conditions on both ends (in this case \\(y\\) and \\(z\\)) we’ll want to have negative constants. To that end, we’ll assume that \\(\\beta = -k^2\\) and \\(\\gamma = -\\ell^2\\) are both negative, which luckily forces \\(\\alpha = \\sqrt{k^2 + \\ell^2}\\) to be positive.\nThis then leaves us with three differential equations to solve of the form \\[\n\\frac{d^2 X}{dx^2} = (k^2+\\ell^2) X \\quad , \\quad \\frac{d^2 Y}{dy^2} = -k^2 Y \\quad , \\quad \\frac{d^2 Z}{dz^2} = -\\ell^2 Z \\ .\n\\] The equation for \\(X(x)\\) must satisfy the boundary conditions that \\(X(x)\\) is finite at infinity, and \\(X(0) = V(y,z)\\). The first condition will force \\(X(x)\\) be given by a negative exponential, and the second condition we’ll have to come back to at the end. We have \\[\nX(x) = C e^{-\\sqrt{k^2+\\ell^2}x} \\ .\n\\] The equations for \\(Y(y)\\) and \\(Z(z)\\) are identical apart for their separation constants and their endpoints. Requiring that \\(Y(y)\\) vanish at \\(y=0\\) and \\(y=a\\) forces \\(k\\) to be quantized in terms of an integer \\(n\\), with \\(k_n = \\frac{n\\pi}{a}\\). Similarly, requiring that \\(Z(z)\\) vanish at \\(z=0\\) and \\(z=b\\) forces \\(\\ell\\) to be quantized in terms of another integer \\(m\\), with \\(\\ell_m = \\frac{m\\pi}{b}\\). In each case, we’ll have a basis of sinusoid solutions of the form \\[\nY_n(y) = A_n \\sin k_n y \\quad , \\quad Z_m(z) = B_n \\sin \\ell_m z \\ .\n\\] As in the previous example, each of these functions forms a set of complete orthogonal functions on their respective intervals. Now, since \\(X(x)\\) depends on both \\(k\\) and \\(\\ell\\), its set of solutions will now depend on both \\(n\\) and \\(m\\), with \\[\nX_{nm}(x) = C e^{-\\sqrt{k_n^2+\\ell_m^2}x} \\ .\n\\] This means we can construct the general solution for the potential by multiplying each of these solutions together to get a basis function for the potential, which we can superpose with each other to get the general solution. Again ignoring the integration constants, which we’ll put back in soon, we define basis functions of the form \\[\n\\phi_{nm}(x,y,z) \\equiv e^{-\\sqrt{k_n^2+\\ell_m^2}x} \\sin k_n y \\sin \\ell_m z \\ .\n\\] Now, none of these solutions satisfies the final boundary condition that \\(\\phi(0,y,z) = V(y,z)\\). This means we need to consider a more general class of solutions. We again do that by appealing to the principle of superposition. This time though we need to sum over both \\(n\\) and \\(m\\) to get the most general possible solution, \\[\n\\phi(x,y,z) = \\sum_{n=1}^\\infty \\sum_{m=1}^\\infty b_{nm} \\phi_{nm}(x,y,z) \\ .\n\\] We’ll now impose the final boundary condition and use that to find the expansion coefficients \\(b_{nm}\\). Plugging in the final condition \\(V(y,z) = \\phi(0,y,z)\\) to the general solution evaluated at \\(x=0\\), we get \\[\nV(y,z) = \\phi(0,y,z) = \\sum_{n=1}^\\infty \\sum_{m=1}^\\infty b_{nm} \\sin k_n y \\sin \\ell_m z \\ .\n\\] To find the coefficients, we now appeal to the fact that the set of functions \\(\\sin k_n y\\) and \\(\\sin \\ell_m z\\) are each orthogonal on their respective intervals. This means we can multiply both sides of this equation by \\(\\sin k_{n'} y \\ \\sin \\ell_{m'} z\\) and integrate over both \\(y\\) and \\(z\\) to get \\[\n\\int_0^a dy \\int_0^b dz \\ V(y,z) \\sin k_{n'} y \\ \\sin \\ell_{m'} z = \\sum_{n=1}^\\infty \\sum_{m=1}^\\infty b_{nm} \\int_0^a dy \\int_0^b dz \\ \\sin k_n y \\sin \\ell_m z \\sin k_{n'} y \\ \\sin \\ell_{m'} z \\ .\n\\] On the right-hand side, we see that the integrals separate into a product of two univariate integrals, giving \\[\n\\begin{align*}\n\\sum_{n,m} b_{nm} \\int_0^a dy \\int_0^b dz \\ \\sin k_n y \\sin \\ell_m z \\sin k_{n'} z \\ \\sin \\ell_{m'} y\n&= \\sum_{n,m} b_{nm} \\bigg(\\int_0^a dy \\ \\sin k_{n'} y \\ \\sin k_n y\\bigg) \\bigg(\\int_0^b dz \\ \\sin \\ell_m z \\ \\sin \\ell_{m'} z\\bigg) \\\\\n&= \\frac{a}{2} \\frac{b}{2} \\sum_{n,m} b_{nm} \\delta_{nn'} \\delta_{mm'} \\\\\n&= \\frac{ab}{4} b_{n'm'} \\ .\n\\end{align*}\n\\] For the left-hand side, we can’t proceed any further without a specific form for \\(V(y,z)\\). For the sake of argument we’ll suppose that \\(V(y,z) = V\\) is constant. In that case, the left-hand side evaluates to \\[\n\\begin{align*}\n\\int_0^a dy \\int_0^b dz \\ V(y,z) \\sin k_{n'} y \\ \\sin \\ell_{m'} z\n&= V \\int_0^a dy \\ \\sin k_{n'} y \\int_0^b dz \\ \\sin \\ell_{m'} z \\\\\n&= V \\frac{a}{n'\\pi}(1-\\cos n'\\pi) \\frac{b}{m'\\pi}(1-\\cos m'\\pi) \\\\\n&= \\frac{Vab}{n'm' \\pi^2} (1-\\cos n'\\pi) (1-\\cos m'\\pi) \\ .\n\\end{align*}\n\\] Putting these together, the coefficients \\(b_{nm}\\) are evidently given by \\[\nb_{nm} = \\frac{4V}{nm\\pi^2} (1-\\cos n\\pi) (1-\\cos m\\pi) \\ .\n\\] As with the previous example, \\(\\cos n\\pi\\) will equal \\(+1\\) when \\(n\\) is even and \\(-1\\) when \\(n\\) is odd, and similarly for \\(\\cos m\\pi\\). This means the coefficients will vanish if either \\(n\\) or \\(m\\) is even. The only terms that survive are when both are odd, with \\[\nb_{nm} = \\frac{16V}{nm\\pi^2} \\quad , \\quad n,m = 1,3,5,\\cdots \\ .\n\\] We’ve thus satisfied all the boundary conditions in the problem. According to the uniqueness theorem, plugging \\(b_{nm}\\) back into the general solution will give the unique solution that solves this boundary value problem, with \\[\n\\phi(\\mathbf{x}) = \\frac{16V}{\\pi^2} \\sum_{n,m=1,3,5,\\cdots} \\frac{1}{nm} e^{-\\sqrt{k_n^2+\\ell_m^2}x} \\sin k_n y \\sin \\ell_m z  \\ .\n\\] In this case there’s no closed-form solution, so we’re left with this series. Notice, though, that each term falls off quadratically. This means if we like we can get a reasonable approximation to this potential by keeping only the first few terms. Visualizing the equipotentials for this problem is more challenging since now we’re faced with a 4-dimensional plotting situation, but we can still describe qualitatively what these equipotentials will look like. We expect that the potential will be highest at \\(x=0\\) before falling off exponentially in that direction. On the other edges of the pipe the potential will vanish on both sides due to grounding, and will peak along the center-line of the pipe.\n\n\nExample: Conducting rectangular box held at given potential on one end\nLet’s now consider a slight variation to the previous problem. Suppose we have a rectangular conducting box of finite extent in all directions. One of the sides of the box is held at some varying potential \\(V(y,z)\\), while the other five sides of the box are grounded. Suppose the box has a width \\(a\\) in the direction where the potential is ungrounded, a depth \\(b\\), and a height \\(c\\).\nWe’ll orient the box exactly like we did in the previous problem, with the length along the \\(x\\)-axis, and the width and depth along the \\(y\\) and \\(z\\) axes. We’ll assume the box is is ungrounded at \\(x=a\\) with \\(\\phi(a,x,y) = V(y,z)\\), while the other sides are grounded.\nFIGURE\nThis gives us a BVP to solve of the form \\[\n\\begin{align*}\n\\begin{cases}\n\\nabla^2 \\phi = 0 \\ , \\\\\n\\text{where} \\ \\phi(a,y,z) = V(y,z) \\ , \\\\\n\\phi(0,y,z) = 0 \\ , \\\\\n\\phi(x,0,z) = \\phi(x,a,z) = 0 \\ , \\\\\n\\phi(x,y,0) = \\phi(x,y,b) = 0 \\ , \\\\\n|\\phi| &lt; \\infty \\ \\text{for all} \\ x,y,z \\ .\n\\end{cases}\n\\end{align*}\n\\] Since we confine ourselves to the inside of the box, we don’t need to require that \\(\\phi \\rightarrow \\infty\\) as \\(|\\mathbf{x}| \\rightarrow \\infty\\).\nIf we apply separation of variables to this problem, we end up with three differential equations to solve of the form \\[\n\\frac{d^2 X}{dx^2} = (k^2+\\ell^2) X \\quad , \\quad \\frac{d^2 Y}{dy^2} = -k^2 Y \\quad , \\quad \\frac{d^2 Z}{dz^2} = -\\ell^2 Z \\ .\n\\] Notice that we skipped the step where we chose the signs of the separation constants. To give a brief justification for the above choice, notice that all coordinates are bounded in this problem. Two of the coordinates (\\(y\\) and \\(z\\)) have vanishing potentials at both boundaries. For those it makes sense to choose negative constants so that we again get sinusoidal solutions, and can expand the general solution in terms of Fourier bases again. The final coordinate \\(x\\) is then forced to have a positive separation constant. This will turn out to be a reasonable choice, as we’ll see.\nNow, the equations for \\(Y(y)\\) and \\(Z(z)\\) are exactly the same as they were in the previous problem. The boundary conditions force the constants \\(k\\) and \\(\\ell\\) to be quantized in terms of integers \\(n\\) and \\(m\\), with \\(k_n = \\frac{n\\pi}{b}\\) and \\(\\ell_m = \\frac{m\\pi}{c}\\). This means we end up with two infinite sets of basis functions of the form \\(Y_n(y) = \\sin k_n y\\) and \\(Z_m(z) = \\sin \\ell_m z\\). Both sets of functions will be complete and orthogonal on their given intervals.\nThe equation for \\(X(x)\\) again gives a general solution in terms of real exponentials, but this time we can’t throw away one of them since \\(x\\) is bounded as well in this problem. For each \\(n\\) and \\(m\\), we’ll have a general solution of the form \\[\nX_{nm}(x) = A_{nm} e^{\\sqrt{k_n^2 + \\ell_m^2} x} + B_{nm} e^{-\\sqrt{k_n^2 + \\ell_m^2} x} \\ .\n\\] Each of these functions must satisfy the boundary condition that \\(X_{nm}(0) = 0\\). Plugging this in forces \\(B_{nm} = -A_{nm}\\), giving \\[\nX_{nm}(x) = A_{nm} \\big(e^{\\sqrt{k_n^2 + \\ell_m^2} x} - e^{-\\sqrt{k_n^2 + \\ell_m^2} x}\\big) = 2 A_{nm} \\sinh \\sqrt{k_n^2 + \\ell_m^2} x \\ .\n\\] We can then combine each of these solutions together to get a basis of solutions for the potential, which we’ll define by \\[\n\\phi_{nm}(x,y,z) \\equiv \\sinh \\sqrt{k_n^2 + \\ell_m^2} x \\ \\sin k_n y \\ \\sin \\ell_m z \\ .\n\\] Now, we still have to fit the boundary condition that \\(\\phi(a,y,z) = V(y,z)\\). None of these basis functions solve this condition. This means we need to consider a more general solution by appealing to the principle of superposition to write \\[\n\\phi(x,y,z) = \\sum_{n=1}^\\infty \\sum_{m=1}^\\infty b_{nm} \\phi_{nm}(x,y,z) \\ .\n\\] Fitting the final boundary condition will determine the expansion coefficients \\(b_{nm}\\). Setting \\(x=a\\) in the above solution, we get \\[\nV(y,z) = \\phi(a,y,z) = \\sum_{n=1}^\\infty \\sum_{m=1}^\\infty b_{nm} \\sinh \\sqrt{k_n^2 + \\ell_m^2} a \\ \\sin k_n y \\ \\sin \\ell_m z \\ .\n\\] We now again appeal to the fact that \\(\\sin k_n y\\) and \\(\\sin \\ell_m z\\) each form an orthogonal set of functions, which means we can determine the expansion coefficients by taking inner products. Equivalently, we can determine \\(b_{nm}\\) by multiplying both sides of the above equation by \\(\\sin k_{n'} y \\ \\sin \\ell_{m'} z\\) and integrating over both \\(y\\) and \\(z\\) on their respective intervals. Using the previous example as a guide, it’s not hard to see that the right-hand side will give \\[\n\\sum_{n,m} b_{nm} \\sinh \\sqrt{k_n^2 + \\ell_m^2} a \\int_0^b dy \\int_0^c dz \\ \\sin k_n y \\sin \\ell_m z \\sin k_{n'} z \\ \\sin \\ell_{m'} y = \\frac{bc}{4} \\sinh \\sqrt{k_{n'}^2 + \\ell_{m'}^2} a \\ b_{n'm'} \\ .\n\\] To evaluate the left-hand side we need a specific functional form for \\(V(y,z)\\). Even so, we can formally express \\(b_{nm}\\) in terms of an integral by using the previous expression to write \\[\nb_{nm} = \\frac{4}{bc} \\frac{1}{\\sinh \\sqrt{k_n^2 + \\ell_m^2} a} \\int_0^b dy \\int_0^c dz \\ V(y,z) \\sin k_n y \\ \\sin \\ell_m z \\ .\n\\] Notice if we set \\(V(y,z)\\) to a constant and integrate, we get a solution that looks identical to the solution in the previous problem, except with an extra hyperbolic sine factor included. In that simple case, we get \\[\n\\phi(\\mathbf{x}) = \\frac{16V}{\\pi^2} \\sum_{n,m=1,3,5,\\cdots} \\frac{1}{nm} \\frac{\\sinh \\sqrt{k_n^2 + \\ell_m^2} x}{\\sinh \\sqrt{k_n^2 + \\ell_m^2} a} \\sin k_n y \\sin \\ell_m z  \\ .\n\\] Again, the uniqueness theorem will guarantee that once we’ve found this solution, it will be unique.\n\n\n\nLaplace’s Equation in Spherical Coordinates\nApplying separation of variables in Cartesian coordinates is pretty easy due to the fact that the Laplacian takes such a simple form. In curvilinear coordinates though it’s not quite as easy, but it’s still very useful to solve many interesting problems.\nSuppose we now choose to work in spherical coordinates \\((r,\\theta,\\varphi)\\). In this coordinate system, the Laplacian is given by \\[\n\\nabla^2 \\phi = \\frac{1}{r^2} \\frac{\\partial}{\\partial r} \\bigg(r^2 \\frac{\\partial \\phi}{\\partial r}\\bigg) + \\frac{1}{r^2 \\sin\\theta} \\frac{\\partial}{\\partial \\theta} \\bigg(\\sin\\theta \\frac{\\partial \\phi}{\\partial \\theta}\\bigg) + \\frac{1}{r^2 \\sin^2 \\theta} \\frac{\\partial^2 \\phi}{\\partial \\varphi^2} \\ .\n\\]\nTo solve Laplace’s equation we require that \\(\\nabla^2 \\phi = 0\\). If we multiply both sides by \\(r^2\\) we end up with \\[\n\\frac{\\partial}{\\partial r} \\bigg(r^2 \\frac{\\partial \\phi}{\\partial r}\\bigg) + \\frac{1}{ \\sin\\theta} \\frac{\\partial}{\\partial \\theta} \\bigg(\\sin\\theta \\frac{\\partial \\phi}{\\partial \\theta}\\bigg) + \\frac{1}{\\sin^2 \\theta} \\frac{\\partial^2 \\phi}{\\partial \\varphi^2} = 0 \\ .\n\\] Notice this equation isn’t completely separated yet since the last term still depends on \\(\\theta\\). As is convention, we’ll handle the special situation of azimuthal symmetry before proceeding to study the general case.\n\nAzimuthally Symmetric Potentials\nFor problems with azimuthal symmetry the potential depends only on \\(r\\) and \\(\\theta\\), not on \\(\\varphi\\). An example of this type of situation might be a conducting sphere held at a fixed potential, or a potential with only a polar dependence, say \\(\\phi = V(\\theta)\\) on the surface. For problems like this we can ignore the \\(\\varphi\\) derivatives in Laplace’s equation and write \\[\n\\frac{\\partial}{\\partial r} \\bigg(r^2 \\frac{\\partial \\phi}{\\partial r}\\bigg) + \\frac{1}{ \\sin\\theta} \\frac{\\partial}{\\partial \\theta} \\bigg(\\sin\\theta \\frac{\\partial \\phi}{\\partial \\theta}\\bigg) = 0 \\ .\n\\] This equation is clearly separable in \\(r\\) and \\(\\theta\\), so we can proceed as usual. Assume a trial solution of the form \\[\n\\phi(\\mathbf{x}) = R(r) \\Theta(\\theta) \\ .\n\\] Plugging this into the previous equation and dividing by \\(R\\Theta\\), we get \\[\n0 = \\frac{1}{R} \\frac{d}{dr} \\bigg(r^2 \\frac{dR}{dr}\\bigg) + \\frac{1}{\\Theta} \\frac{1}{\\sin\\theta} \\frac{d}{d\\theta} \\bigg(\\sin\\theta \\frac{dY}{d\\theta}\\bigg) \\ .\n\\] Since each term is an independent function in its own variable, the only way their sum can vanish for all \\(r,\\theta\\) is the two terms are equal to a constant if opposite sign. We’ll denote this separation constant by \\(\\ell(\\ell+1)\\) for reasons that will become clear in a moment. Then we have \\[\n\\begin{align*}\n\\frac{d}{dr} \\bigg(r^2 \\frac{dR}{dr}\\bigg) &= \\ell (\\ell+1) R(r) \\ , \\\\\n\\frac{1}{\\sin\\theta}\\frac{d}{d\\theta} \\bigg(\\sin\\theta \\frac{d\\Theta}{d\\theta}\\bigg) &= -\\ell (\\ell+1) \\Theta(\\theta) \\ .\n\\end{align*}\n\\] The first equation, called the radial equation can be solved by changing variables to \\(U(r) = r R(r)\\). Then \\(\\frac{dR}{dr} = \\frac{U}{r} - \\frac{dU}{dr}\\), and so after simplifying a bit we end up with an ODE for \\(U(r)\\) of the form \\[\n\\frac{d^2 U}{dr^2} = \\frac{\\ell (\\ell+1)}{r^2} U \\ .\n\\] To solve this ODE we assume a trial solution of the form \\(U(r) = r^\\lambda\\) for some parameter \\(\\lambda\\) we need to determine. Plugging this solution into the ODE evidently forces \\(\\lambda = -\\ell, \\ell+1\\), which means the general solution is given by the superposition \\[\nU(r) = a r^{-\\ell} + b r^{\\ell+1} \\ .\n\\] Finally, dividing by \\(r\\) gives us the general solution to the original radial equation, \\[\nR(r) = a r^{-\\ell-1} + b r^{\\ell} \\ .\n\\] We now need to deal with the other ODE, called the angular equation, \\[\n\\frac{1}{\\sin\\theta} \\frac{d}{d\\theta} \\bigg(\\sin\\theta \\frac{d\\Theta}{d\\theta}\\bigg) = -\\ell (\\ell+1) \\Theta(\\theta) \\ .\n\\] If we change variables by letting \\(x = \\cos\\theta\\), then \\(\\frac{d\\Theta}{d\\theta} = -\\sin\\theta \\frac{d\\Theta}{dx}\\), and so we end up with the following ODE for \\(\\Theta(x)\\), \\[\n-\\frac{d}{dx} \\bigg((1-x^2)\\frac{d\\Theta}{dx}\\bigg) = \\ell(\\ell+1) \\Theta(x) \\ .\n\\] Those who have read the appendix will know that this ODE has a name. It’s the Legendre equation. Its only bounded solution is the Legendre polynomial \\(P_\\ell(x) = P_\\ell(\\cos\\theta)\\), where \\(\\ell = 0,1,2,\\cdots\\) must be a positive integer. Since this is a second order equation, there is also a second solution, but this solution is known to be unbounded for all \\(\\ell\\), and hence non-physical.\nWe can define the Legendre polynomials most simply using the Rodrigues’ formula as \\[\nP_\\ell(x) \\equiv \\frac{1}{2^\\ell \\ell!} \\frac{d^\\ell}{dx^\\ell} (x^2 - 1)^\\ell \\ .\n\\] For example, the first three Legendre polynomials are given by \\[\nP_0(x) = 1 \\quad , \\quad P_1(x) = x = \\cos\\theta \\quad , \\quad P_2(x) = \\frac{1}{2} (3x^2 - 1) = \\frac{1}{2} (3\\cos^2 \\theta - 1) \\ .\n\\] The Legendre polynomials form a complete orthogonal set on the interval \\(-1 \\leq x \\leq 1\\). This means we can express the general solution \\(\\Theta(\\theta)\\) as a linear superposition of \\(P_\\ell(\\cos\\theta)\\), with \\[\n\\Theta(\\theta) = \\sum_{\\ell=0}^\\infty c_\\ell P_\\ell(\\cos\\theta) \\ .\n\\] Combining this angular solution with the radial solution and absorbing constants together, we can write the general solution for an azimuthally symmetric potential \\(\\phi(\\mathbf{x})\\) in the form \\[\n\\boxed{\n\\phi(\\mathbf{x}) = \\sum_{\\ell=0}^\\infty \\big(a_\\ell r^\\ell + b_\\ell r^{-(\\ell+1)}\\big) P_\\ell(\\cos\\theta)\n} \\ .\n\\] The coefficients \\(a_\\ell\\) and \\(b_\\ell\\) can then be found by imposing the remaining boundary condition. Once these are found, we’ve found the unique general solution for the potential in spherical coordinates that satisfy all the boundary conditions.\nNotice that as written, this solution will always blow up at either the origin or infinity unless we force one of these sets of constants to be zero. In practice, when faced with a spherical boundary value problem, what we’ll do is write down the solution separately inside and outside the surface and match them together along the boundary. Inside the surface we’ll want to set \\(b_\\ell = 0\\) to prevent the potential from blowing up at \\(r=0\\), while outside the surface we’ll often want to set \\(a_\\ell = 0\\) to prevent the potential from blowing up at infinity.\nTo see that this solution makes sense, let’s consider the special case where the potential is spherically symmetric, with \\(\\phi = \\phi(r)\\). Then all but the \\(\\ell=0\\) terms vanish, and since \\(P_0(\\cos\\theta) = 1\\) by definition, we end up with \\[\n\\phi(r) = a_0 + \\frac{b_0}{r} \\ .\n\\] We immediately recognize this as the potential of a uniformly charged sphere, with \\(b_0 = Q\\) and \\(a_0 = \\phi(0)\\) a chosen ground point potential that we can ignore. Let’s now consider some more interesting examples.\n\nExample: Potential inside a hollow sphere held at a given potential\nSuppose we have a hollow sphere of radius \\(R\\) with a fixed potential \\(V(\\theta)\\) on its surface. We want to find the potential inside of the sphere.\nFIGURE\nThe boundary value problem we seek to solve is evidently \\[\n\\begin{align*}\n\\begin{cases}\n\\nabla^2 \\phi(r,\\theta,\\varphi) = 0 \\ , \\\\\n\\text{where} \\ \\phi(R,\\theta,\\varphi) = V(\\theta) \\ , \\\\\n|\\phi| &lt; \\infty \\ \\text{for all} \\ 0 \\leq r \\leq R \\ .\n\\end{cases}\n\\end{align*}\n\\] Since this is clearly an azimuthally symmetric problem, \\(\\phi = \\phi(r,\\theta)\\), which means the general solution must have the form \\[\n\\phi(r,\\theta) = \\sum_{\\ell=0}^\\infty \\big(a_\\ell r^\\ell + b_\\ell r^{-(\\ell+1)}\\big) P_\\ell(\\cos\\theta) \\ .\n\\] Since we’re inside the sphere, we require that all \\(b_\\ell = 0\\) to prevent the potential from blowing up at the origin. This leaves \\[\n\\phi(r,\\theta) = \\sum_{\\ell=0}^\\infty a_\\ell r^\\ell P_\\ell(\\cos\\theta) \\ .\n\\] We’re now left to find the coefficients \\(b_\\ell\\) by imposing the boundary condition at \\(\\phi(R,\\theta)\\), which we can write as \\[\nV(\\theta) = \\phi(R,\\theta) = \\sum_{\\ell=0}^\\infty a_\\ell R^\\ell P_\\ell(\\cos\\theta) \\ .\n\\] Now, recall from the appendix that the Legendre polynomials satisfy the orthogonality relation \\[\n\\langle P_\\ell(x) | P_{\\ell'}(x) \\rangle = \\int_{-1}^1 dx P_\\ell(x) P_{\\ell'}(x) = \\frac{2}{2\\ell+1} \\delta_{\\ell\\ell'} \\ .\n\\] Using the relation \\(x=\\cos\\theta\\) we can re-express this integral in terms of \\(\\theta\\) as well, \\[\n\\langle P_\\ell(\\cos\\theta) | P_{\\ell'}(\\cos\\theta) \\rangle = \\int_0^\\pi d\\theta \\ P_\\ell(\\cos\\theta) P_{\\ell'}(\\cos\\theta) \\sin\\theta = \\frac{2}{2\\ell+1} \\delta_{\\ell\\ell'} \\ .\n\\] We can now use this orthogonality condition to determine the coefficients \\(a_\\ell\\). To do that we proceed as usual. We multiply both sides of the equation for \\(\\phi(R,\\theta)\\) by \\(P_{\\ell'}(\\cos\\theta)\\) and integrate from \\(\\theta=0\\) to \\(\\theta=\\pi\\). Doing the right-hand side, first, we have \\[\n\\sum_{\\ell=0}^\\infty a_\\ell R^\\ell \\int_0^\\pi d\\theta \\ P_{\\ell'}(\\cos\\theta) P_\\ell(\\cos\\theta) = \\sum_{\\ell=0}^\\infty a_\\ell R^\\ell \\frac{2}{2\\ell+1} \\delta_{\\ell\\ell'} = \\frac{2}{2\\ell'+1} a_{\\ell'} R^{\\ell'} \\ .\n\\] To evaluate the left-hand side we need a specific form for \\(V(\\theta)\\). Nevertheless, we can use the previous expression to solve for \\(a_\\ell\\) in terms of this integral to get \\[\na_\\ell = \\frac{2\\ell+1}{2R^\\ell} \\int_0^\\pi d\\theta \\ V(\\theta) P_\\ell(\\cos\\theta) \\ .\n\\] As an example, let’s suppose \\(V(\\theta)\\) takes the specific form \\[\nV(\\theta) = k \\sin^2 \\frac{\\theta}{2} \\ .\n\\] Using the half-angle formula and the value of the first two Legendre polynomials, we can write this in the form \\[\nV(\\theta) = \\frac{k}{2} (1-\\cos\\theta) = \\frac{k}{2} \\big(P_0(\\cos\\theta) - P_1(\\cos\\theta)\\big) \\ .\n\\] If we then plug this into the previous integral and use the definition of the inner product above, we get \\[\n\\begin{align*}\na_\\ell &= \\frac{k}{2}\\frac{2\\ell+1}{2R^\\ell} \\int_0^\\pi d\\theta \\  \\big[P_0(\\cos\\theta) - P_1(\\cos\\theta)\\big]P_\\ell(\\cos\\theta) \\sin\\theta \\\\\n&= \\frac{k}{2}\\frac{2\\ell+1}{2R^\\ell} \\big[\\langle P_0 | P_\\ell \\rangle - \\langle P_1 | P_\\ell \\rangle\\big] \\ .\n\\end{align*}\n\\] Now, by the orthogonality relation, only the \\(\\ell=0,1\\) terms will contribute anything while the rest vanish, with \\[\n\\begin{align*}\na_0 &= \\frac{k}{2} \\frac{1}{2} \\langle P_0 | P_0 \\rangle = \\frac{k}{2} \\ , \\\\\na_1 &= -\\frac{k}{2} \\frac{3}{2R} \\langle P_1 | P_1 \\rangle = -\\frac{k}{2R} \\ .\n\\end{align*}\n\\] For this choice of \\(V(\\theta)\\) we thus have our general solution for the potential that solves this BVP, given by \\[\n\\phi(\\mathbf{x}) = a_0 P_0(\\cos\\theta) + a_1 r P_1(\\cos\\theta) = \\frac{k}{2} \\bigg(1 - \\frac{r}{R} \\cos\\theta\\bigg) \\ .\n\\] By the uniqueness theorem, we can guarantee this will be the unique general solution to the given BVP.\n\n\nExample: Potential outside a hollow sphere held at a given potential\nLet’s now consider again the previous problem, but suppose we’re not interested in the potential outside the hollow sphere. We now require that the potential not blow up at infinity, giving a BVP of the form \\[\n\\begin{align*}\n\\begin{cases}\n\\nabla^2 \\phi(r,\\theta,\\varphi) = 0 \\ , \\\\\n\\text{where} \\ \\phi(R,\\theta,\\varphi) = V(\\theta) \\\\\n|\\phi| &lt; \\infty \\ \\text{for all} \\ R \\leq r \\leq \\infty \\ .\n\\end{cases}\n\\end{align*}\n\\] Clearly this problem also has an azimuthally symmetric potential \\(\\phi = \\phi(r,\\theta)\\), and hence we can still write \\[\n\\phi(r,\\theta) = \\sum_{\\ell=0}^\\infty \\big(a_\\ell r^\\ell + b_\\ell r^{-(\\ell+1)}\\big) P_\\ell(\\cos\\theta) \\ .\n\\] But now we need the potential outside the sphere, not inside. The requirement that \\(\\phi\\) not blow up at infinity now forces \\(a_\\ell=0\\) instead, leaving \\[\n\\phi(r,\\theta) = \\sum_{\\ell=0}^\\infty b_\\ell r^{-(\\ell+1)} P_\\ell(\\cos\\theta) \\ .\n\\] To find \\(b_\\ell\\) we proceed the same way as before, relying on the orthogonality of Legendre polynomials. Multiplying both sides by \\(P_{\\ell'}(\\cos\\theta)\\) and integrating, we end up with the expression \\[\nb_\\ell = \\frac{(2\\ell+1)R^{\\ell+1}}{2} \\int_0^\\pi d\\theta \\ V(\\theta) P_\\ell(\\cos\\theta) \\sin\\theta \\ .\n\\] To proceed further we’d need to know the specific form of the boundary potential \\(V(\\theta)\\). For example, if we again assume the same boundary potential given in the previous problem, we can write \\[\nV(\\theta) = k \\sin^2 \\theta = \\frac{k}{2} \\big[P_0(\\cos\\theta) - P_1(\\cos\\theta)\\big] \\ .\n\\] As in that problem, plugging this into the integral for \\(b_\\ell\\) forces only the \\(\\ell=0,1\\) terms to survive, with coefficients \\[\n\\begin{align*}\nb_0 &= \\frac{k}{2} \\frac{R}{2} \\langle P_0 | P_0 \\rangle = \\frac{kR}{2} \\ , \\\\\nb_1 &= -\\frac{k}{2} \\frac{3R^2}{2} \\langle P_1 | P_1 \\rangle = -\\frac{kR^2}{2} \\ .\n\\end{align*}\n\\] With these, we can write the general solution for the potential outside the sphere as \\[\n\\phi(\\mathbf{x}) = \\frac{b_0}{r} P_0(\\cos\\theta) + \\frac{b_1}{r^2} P_1(\\cos\\theta) = \\frac{kR}{2r} \\bigg(1 - \\frac{R}{r} \\cos\\theta\\bigg) \\ .\n\\] Notice that this behaves exactly how we expect, with \\(\\phi \\rightarrow 0\\) at infinity. It’s also easy to see that this solution agrees with the one inside the sphere at the boundary surface where \\(r=R\\). Indeed, these two solutions together give us the unique potential in all space that satisfies the boundary condition \\(\\phi(R,\\theta,\\varphi) = V(\\theta)\\) on the surface of the sphere.\nIn general, if we have a problem where a boundary value is specified on the surface of a sphere and we’re interested in the potential inside and outside the sphere, we only need to find one of the solutions, and we automatically know the other. For example, suppose we’ve found the potential \\(\\phi\\) inside the sphere. All we need to do to get the potential outside the sphere is make the substitution \\(\\big(\\frac{r}{R})^\\ell \\rightarrow \\big(\\frac{R}{r}\\big)^{\\ell+1}\\) and we automatically have that solution as well.\n\n\nExample: Conducting hemispheres at opposite constant potential\nLet’s now consider a slightly more interesting example that we calculated in the last chapter using Green’s functions, namely the problem of two conducting hemispheres held at equal and opposite constant potentials \\(\\pm V\\).\nFIGURE\nWe showed before with great effort that we could represent the potential as a series of odd-degree Legendre polynomials. Now we’ll provide a much easier way to arrive at the same result using separation of variables.\nWe can also solve this problem using separation of variables. We formulate this setup as a boundary value problem as follows. \\[\n\\begin{align*}\n\\begin{cases}\n\\nabla^2 \\phi(r,\\theta,\\varphi) = 0 \\ , \\\\\n\\text{where} \\ \\phi(R,\\theta,\\varphi) = V \\ \\text{when} \\ 0 \\leq \\theta &lt; \\frac{\\pi}{2} \\ , \\\\\n\\phi(R,\\theta,\\varphi) = -V \\ \\text{when} \\ \\frac{\\pi}{2} &lt; \\theta \\leq \\pi \\ , \\\\\n|\\phi| &lt; \\infty \\ \\text{for all} \\ 0 \\leq r \\leq \\infty \\ .\n\\end{cases}\n\\end{align*}\n\\] Again, this problem is clearly azimuthally symmetric. Since one is as easy as the other, we’ll show how to find the potential inside the sphere, and then use that formula to get the potential outside as well using the trick described in the previous example.\nInside the sphere we require that \\(b_\\ell = 0\\), which gives an expansion of the form \\[\n\\phi(r,\\theta,\\varphi) = \\sum_{\\ell=0}^\\infty a_\\ell r^{\\ell} P_\\ell(\\cos\\theta) \\ .\n\\] Notice this looks exactly like the previous examples if we take \\(V(\\theta) = \\pm V\\). We can solve for the coefficients \\(a_\\ell\\) in the usual way, in which case we end up with the integral \\[\na_\\ell = \\frac{2\\ell+1}{2R^\\ell} \\int_0^\\pi d\\theta \\ V(\\theta) P_\\ell(\\cos\\theta) \\sin\\theta \\ .\n\\] Plugging in \\(V(\\theta) = \\pm V\\), this becomes \\[\na_\\ell =  \\frac{2\\ell+1}{2R^\\ell} V \\bigg[\\int_0^{\\pi/2} d\\theta \\ P_\\ell(\\cos\\theta) \\sin\\theta - \\int_{\\pi/2}^\\pi d\\theta \\ P_\\ell(\\cos\\theta) \\sin\\theta\\bigg] \\ .\n\\] Since \\(P_\\ell(\\cos\\theta)\\) is odd when \\(\\ell\\) is odd and even when \\(\\ell\\) is even, we can see that the even coefficients must cancel out, while for odd terms we can write \\[\na_\\ell = \\frac{2\\ell+1}{R^\\ell} V \\int_0^{\\pi/2} d\\theta \\ P_\\ell(\\cos\\theta) \\sin\\theta \\ .\n\\] Now, by changing variables with \\(x=\\cos\\theta\\) we see that the above integral can be written in the simpler form \\[\n\\int_0^{\\pi/2} d\\theta \\ P_\\ell(\\cos\\theta) \\sin\\theta = \\int_0^1 dx \\ P_\\ell(x) \\ .\n\\] This integral is just the interval of \\(P_\\ell(x)\\) over the right-half interval \\(0 \\leq x \\leq 1\\). Its expression can be calculated for odd \\(\\ell\\) (see the appendix for an example) to give \\[\n\\int_0^1 dx \\ P_\\ell(x) = \\frac{(-1)^{\\frac{\\ell-1}{2}}}{2^\\ell \\big(\\frac{\\ell+1}{2}\\big)} \\frac{(\\ell-1)!}{\\big(\\frac{\\ell-1}{2}!\\big)^2} \\ .\n\\] Plugging this in and simplifying, the coefficients we seek are given by \\[\na_\\ell = \\bigg(\\frac{-1}{2}\\bigg)^{\\frac{\\ell-1}{2}} \\frac{(2\\ell+1)(\\ell-2)!!}{2\\big(\\frac{\\ell+1}{2}!\\big)^2} \\frac{V}{R^\\ell} \\quad , \\quad \\ell=1,3,5,\\cdots \\ .\n\\] This means the potential inside the sphere must be given by \\[\n\\begin{align*}\n\\phi(r,\\theta,\\varphi) &= V\\sum_{\\ell=0}^\\infty \\bigg(\\frac{-1}{2}\\bigg)^{\\frac{\\ell-1}{2}} \\frac{(2\\ell+1)(\\ell-2)!!}{2\\big(\\frac{\\ell+1}{2}!\\big)^2} \\bigg(\\frac{r}{R}\\bigg)^\\ell P_\\ell(\\cos\\theta) \\\\\n&= V \\bigg[\\frac{3}{2}\\bigg(\\frac{r}{R}\\bigg)P_1(\\cos\\theta) - \\frac{7}{8}\\bigg(\\frac{r}{R}\\bigg)^3P_3(\\cos\\theta) + \\frac{11}{16}\\bigg(\\frac{r}{R}\\bigg)^5P_5(\\cos\\theta) - \\cdots\\bigg] \\ , \\quad r \\leq R \\ .\n\\end{align*}\n\\] To get the potential outside the sphere we need only substitute \\(\\big(\\frac{r}{R})^\\ell \\rightarrow \\big(\\frac{R}{r}\\big)^{\\ell+1}\\) to get \\[\n\\begin{align*}\n\\phi(r,\\theta,\\varphi) &= V\\sum_{\\ell=0}^\\infty \\bigg(\\frac{-1}{2}\\bigg)^{\\frac{\\ell-1}{2}} \\frac{(2\\ell+1)(\\ell-2)!!}{2\\big(\\frac{\\ell+1}{2}!\\big)^2} \\bigg(\\frac{R}{r}\\bigg)^{\\ell+1} P_\\ell(\\cos\\theta) \\\\\n&= V \\bigg[\\frac{3}{2}\\bigg(\\frac{R}{r}\\bigg)^2P_1(\\cos\\theta) - \\frac{7}{8}\\bigg(\\frac{R}{r}\\bigg)^4P_3(\\cos\\theta) + \\frac{11}{16}\\bigg(\\frac{R}{r}\\bigg)^6P_5(\\cos\\theta) - \\cdots\\bigg] \\ , \\quad r \\geq R \\ .\n\\end{align*}\n\\] As expected, the potential outside the sphere goes to zero at infinity, satisfying the final boundary condition. It also appears that the potential vanishes at the origin, and indeed in the whole equatorial plane. Indeed, the potential seems to behave as a dipole, with the electric field falling off like \\(r^{-3}\\) far away from the sphere. This should hopefully make sense. Far away from the sphere we could imagine modeling the two hemispheres as opposite point charges very close together.\n\n\nExample: Potential of a hollow sphere with an azimuthally symmetric surface charge distribution\nSince we’ve neglected Neumann boundary value problems in this chapter, let’s consider an example where the potential on the surface of a sphere isn’t known, but instead its surface charge density is known. Suppose we have a hollow sphere of radius \\(R\\), and on this sphere we have a surface charge density of the form \\(\\sigma' = k \\cos\\theta\\), where \\(k\\) is some constant.\nWe’d like to find the potential due to this charged sphere both inside and outside the sphere. We can use the fact that the normal derivative is \\(\\partial \\phi / \\partial n' = -4\\pi \\sigma'\\) on the surface of the sphere to express this as a BVP of the form \\[\n\\begin{align*}\n\\begin{cases}\n\\nabla^2 \\phi(r,\\theta,\\varphi) = 0 \\ , \\\\\n\\text{where} \\ \\partial \\phi / \\partial r' \\big|_{r'=R} = -4\\pi k\\cos\\theta \\ , \\\\\n|\\phi| &lt; \\infty \\ \\text{for all} \\ r \\geq 0 \\ .\n\\end{cases}\n\\end{align*}\n\\] We’ll denote the potential inside the sphere by \\(\\phi_-(r,\\theta,\\varphi)\\), and the potential outside the sphere by \\(\\phi_+(r,\\theta,\\varphi)\\). By requiring that the potential be continuous at the surface of the sphere, we require that \\(\\phi_-(R,\\theta,\\varphi) = \\phi_+(R,\\theta,\\varphi)\\).\nWhen outside the sphere the coefficients \\(a_\\ell\\) must all vanish for the potential to not blow up at infinity. We thus have \\[\n\\phi_+(r,\\theta,\\varphi) = \\sum_{\\ell=0}^\\infty b_\\ell r^{-\\ell(\\ell+1)} P_\\ell(\\cos\\theta) \\ .\n\\] Inside the sphere we require the opposite, that each \\(b_\\ell\\) vanish, giving \\[\n\\phi_-(r,\\theta,\\varphi) = \\sum_{\\ell=0}^\\infty a_\\ell r^\\ell P_\\ell(\\cos\\theta) \\ .\n\\] Requiring that the potential be continuous at the surface of the sphere means each term in these series must match at \\(r=R\\). This means for each \\(\\ell\\) we must have the condition \\[\nb_\\ell R^{-\\ell(\\ell+1)} - a_\\ell R^\\ell = 0 \\quad \\Longrightarrow \\quad b_\\ell = a_\\ell R^{2\\ell+1} \\ .\n\\] Since the sphere is hollow, we know that there’s a discontinuity in the electric field across the surface at \\(r=R\\) that’s proportional to \\(4\\pi\\sigma'\\). The difference between the normal derivatives across the surface the sphere must then satisfy \\[\n\\frac{\\partial \\phi_+}{\\partial r'} \\bigg|_{r'=R} - \\frac{\\partial \\phi_-}{\\partial r'} \\bigg|_{r'=R} = -4\\pi k\\cos\\theta \\ .\n\\] Plugging in the series expansions for each term and differentiating, we then have \\[\n\\sum_{\\ell=0}^\\infty \\bigg[b_\\ell (\\ell+1)R^{-(\\ell+2)} + a_\\ell \\ell R^{\\ell-1} \\bigg] P_\\ell(\\cos\\theta) = 4\\pi k\\cos\\theta \\ .\n\\] Since only \\(P_1(\\cos\\theta) = \\cos\\theta\\), each \\(\\ell \\neq 1\\) term on the left must vanish, which means we have \\[\nb_\\ell (\\ell+1)R^{-(\\ell+2)} + a_\\ell \\ell R^{\\ell-1} = 0 \\quad \\Longrightarrow b_\\ell = a_\\ell R^{2\\ell+1} = 0 \\ .\n\\] When \\(\\ell = 1\\) we must have \\[\n2b_1 R^{-3} + a_1 = 4\\pi k \\quad \\Longrightarrow \\quad b_1 = a_1 R^3 = \\frac{4\\pi}{3} kR^3 \\ .\n\\] Thus, to satisfy the boundary conditions the full potential must be \\[\n\\phi(r,\\theta,\\varphi) = \\frac{4\\pi}{3} kR \\cos\\theta \\bigg(\\frac{R}{r}\\bigg)^2 \\ .\n\\] By the uniqueness theorem, this is the only potential that satisfies the boundary condition \\(\\partial \\phi / \\partial n' = -4\\pi \\sigma'\\), which means it’s the only valid potential that solves this BVP both inside and outside the sphere. Notice that this potential falls off like \\(1/r^2\\). That is, this problem is an example of a dipole. We’ll discuss this more in the next chapter.\n\n\nExample: Conducting sphere in the presence of an external electric field\nLet’s revisit another problem we solved previously with the method of images, that of a solid conducting sphere of radius \\(R\\) in the presence of a constant external electric field \\(\\mathbf{E}_0\\). Recall that we solved this problem previously by modeling the external field with two opposite point charges located far away from the sphere, and placed two image charges inside the sphere that fit the boundary conditions on the sphere. We’ll now show that we can solve this same problem using separation of variables as well.\nModeling this as a boundary value problem with \\(\\mathbf{E}_0 = E_0 \\mathbf{e}_z\\) oriented along the \\(z\\)-axis, we write \\[\n\\begin{align*}\n\\begin{cases}\n\\nabla^2 \\phi(r,\\theta,\\varphi) = 0 \\ , \\\\\n\\text{where} \\ \\phi(R,\\theta,\\varphi) = 0 \\ , \\\\\n\\phi(r,\\theta,\\varphi) \\rightarrow -E_0 r\\cos\\theta \\ \\text{as} \\ r \\rightarrow \\infty \\ .\n\\end{cases}\n\\end{align*}\n\\] Note the last boundary condition was chosen to ensure \\(\\phi\\) becomes the potential for \\(E_0\\) at \\(z=\\infty\\), i.e. \\(\\phi = -E_0z\\). This problem is clearly azimuthally symmetric as well. However, since the potential in this case doesn’t vanish at infinity we can’t set \\(a_\\ell=0\\) anymore. We have to include both terms. Suppose then that \\[\n\\phi(r,\\theta,\\varphi) = \\sum_{\\ell=0}^\\infty \\big(a_\\ell r^\\ell + b_\\ell r^{-\\ell(\\ell+1)}\\big) P_\\ell(\\cos\\theta) \\ .\n\\] At the surface of the sphere we must have \\(\\phi(R,\\theta,\\varphi) = 0\\), which means each term in the sum must vanish, with \\[\n\\big(a_\\ell R^\\ell + b_\\ell R^{-\\ell(\\ell+1)}\\big) P_\\ell(\\cos\\theta) = 0 \\ .\n\\] Since \\(P_\\ell(\\cos\\theta)\\) doesn’t depend on \\(r\\), the only way each term can vanish is if the terms in parentheses do. This happens when \\[\nb_\\ell = -a_\\ell R^{2\\ell+1} \\ .\n\\] Let’s now look at the limiting behavior as \\(r \\rightarrow \\infty\\). When \\(r \\gg R\\) we can neglect the second term and write \\[\n\\phi(r,\\theta,\\varphi) \\approx \\sum_{\\ell=0}^\\infty a_\\ell r^\\ell P_\\ell(\\cos\\theta) \\ .\n\\] To satisfy the boundary condition at infinity we require that \\(\\phi(r,\\theta,\\varphi) \\approx -E_0 r \\cos\\theta\\). Matching this condition with the series evidently forces \\(\\ell = 1\\) while the other terms must vanish. Since \\(P_1(\\cos\\theta) = \\cos\\theta\\), we then get \\[\n-E_0 r \\cos\\theta = a_1 r \\cos\\theta \\quad \\Longrightarrow \\quad a_1 = -E_0 \\ .\n\\] Plugging this in, we get a final expression for the potential satisfying these boundary conditions, with \\[\n\\phi(\\mathbf{x}) = -E_0 r \\bigg(1 - \\frac{R^3}{r^3}\\bigg) \\cos\\theta \\ .\n\\] This of course is exactly what we found before using the method of images. It’s useful to look at the induced surface charge on the sphere to see how the charges on the surface are distributing in response to the external field. We do that by calculating \\[\n\\sigma = -\\frac{1}{4\\pi} \\frac{\\partial \\phi}{\\partial r} \\bigg|_{r=R} = \\frac{E_0}{\\pi} \\cos\\theta \\ .\n\\] Notice that charge density is evidently the most positive near \\(\\theta = 0\\) and the most negative near \\(\\theta = \\pi\\). This indicates that positive charge is building up in the direction of the external field, while negative charge is building up opposite to the direction of the field, which is of course what we’d expect physically in this situation.\n\n\n\nGeneral Potentials\nNow that we’ve studied the special case of azimuthally symmetric potentials we’ll return to the general case where the potential can depend on the angle \\(\\varphi\\) as well. Recall we had the following form for Laplace’s equation in spherical coordinates, \\[\n\\frac{\\partial}{\\partial r} \\bigg(r^2 \\frac{\\partial \\phi}{\\partial r}\\bigg) + \\frac{1}{ \\sin\\theta} \\frac{\\partial}{\\partial \\theta} \\bigg(\\sin\\theta \\frac{\\partial \\phi}{\\partial \\theta}\\bigg) + \\frac{1}{\\sin^2 \\theta} \\frac{\\partial^2 \\phi}{\\partial \\varphi^2} = 0 \\ .\n\\] Now we’ll keep the last term involving the \\(\\varphi\\) derivatives in. However, since the two angular terms depend on each other, we can only separate the radial and angular components, but not all three. Suppose then a trial solution of the form \\[\n\\phi(\\mathbf{x}) = R(r) Y(\\theta,\\varphi) \\ .\n\\] Plugging this trial solution into the above equation and dividing by \\(\\phi = RY\\), we get \\[\n0 = \\frac{1}{R} \\frac{d}{dr} \\bigg(r^2 \\frac{dR}{dr}\\bigg) + \\frac{1}{Y}\\bigg[\\frac{1}{\\sin\\theta} \\frac{\\partial}{\\partial\\theta} \\bigg(\\sin\\theta \\frac{\\partial Y}{\\partial\\theta}\\bigg) + \\frac{1}{\\sin^2 \\theta} \\frac{\\partial^2 Y}{\\partial\\varphi^2}\\bigg] \\ .\n\\] Since these two terms are independent of the other, the only way they can sum to zero is they both equal the same constant but with opposite sign. Again, we’ll denote the separation constant by \\(\\ell(\\ell+1)\\) and write \\[\n\\begin{align*}\n\\frac{d}{dr} \\bigg(r^2 \\frac{dR}{dr}\\bigg) &= \\ell (\\ell+1) R(r) \\\\\n\\frac{\\partial}{\\partial\\theta} \\bigg(\\sin\\theta \\frac{\\partial Y}{\\partial\\theta}\\bigg) + \\frac{\\partial^2 Y}{\\partial\\varphi^2} &= -\\ell (\\ell+1) \\sin^2 \\theta \\ Y(\\theta,\\varphi) \\ .\n\\end{align*}\n\\] The first equation we recognize from before. It’s the radial equation. Its general solution is given by \\[\nR(r) = a r^\\ell + b r^{-(\\ell+1)} \\ .\n\\] The second equation is evidently a more general form of the angular equation. We can again separate variables for the angular equation by supposing a second trial solution of the form \\[\nY(\\theta,\\varphi) = \\Theta(\\theta) \\Phi(\\varphi) \\ .\n\\] If we plug this into the angular equation and divide by \\(\\Theta\\Phi \\ \\), we get \\[\n\\bigg[\\frac{1}{\\Theta} \\frac{d}{d\\theta} \\bigg(\\sin\\theta \\frac{d\\Theta}{d\\theta}\\bigg) - \\ell (\\ell+1) \\sin^2 \\theta\\bigg] + \\frac{1}{\\Phi} \\frac{d^2 \\Phi}{d\\varphi^2} = 0\n\\] Again, each term is an independent function of its own variable, so the only way their sum can vanish is if they’re both constants of equal and opposite sign. For reasons we’ll see in a moment, we’ll denote the separation constant by \\(m^2\\) and write \\[\n\\begin{align*}\n&\\frac{d}{d\\theta} \\bigg(\\sin\\theta \\frac{d\\Theta}{d\\theta}\\bigg) - \\ell (\\ell+1)\\Theta(\\theta) = m^2 \\Theta(\\theta) \\ , \\\\\n&\\frac{d^2\\Phi}{d\\varphi^2} = -m^2 \\Phi(\\varphi) \\ .\n\\end{align*}\n\\] The second equation is easy to solve. It’s just a sum of complex exponentials \\(e^{\\pm im\\varphi}\\). Since we’re dealing with an angle, we require that any solution \\(\\Phi(\\varphi)\\) be periodic, meaning \\(\\Phi(\\varphi) = \\Phi(\\varphi + 2\\pi)\\). It’s easy to see that this requirement forces \\(m\\) to be an integer. By convention, we’ll allow \\(m\\) to run both positive and negative, and write \\(\\Phi(\\varphi)\\) in the form \\[\n\\Phi(\\varphi) = c e^{im\\varphi} \\ .\n\\] We’re now left with the other differential equation to deal with, which we’ll write as \\[\n\\frac{d}{d\\theta} \\bigg(\\sin\\theta \\frac{d\\Theta}{d\\theta}\\bigg) - \\big[\\ell (\\ell+1) \\sin^2 \\theta - m^2\\big] \\Theta(\\theta) = 0 \\ .\n\\] Notice that this equation looks very similar to the Legendre equation except there’s an extra term of the form \\(m^2 \\Theta(\\theta)\\) present. From the appendix, we know that the solutions to this equation are the associated Legendre functions \\(P_\\ell^m(\\cos\\theta)\\), where \\(\\ell\\) again must be a non-negative integer, and \\(m\\) must be an integer that runs from \\(-\\ell\\) to \\(\\ell\\). By again defining \\(x = \\cos\\theta\\) we can again define these functions in terms of a Rodrigues’ equation, with \\[\nP_\\ell^m(x) = \\frac{1}{2^\\ell \\ell!} (1-x^2)^{m/2} \\frac{d^{\\ell+m}}{dx^{\\ell+m}} (x^2 - 1)^\\ell \\ .\n\\] These also form a complete set of orthogonal functions on the interval \\(-1 \\leq x \\leq 1\\), which means we can use superposition to write the general solution \\(\\Theta(\\theta)\\) in the form \\[\n\\Theta(\\theta) = \\sum_{\\ell=0}^\\infty \\sum_{m=-\\ell}^\\ell c_{\\ell m} P_\\ell^m(\\cos\\theta) \\ .\n\\] If we combine \\(\\Theta(\\theta)\\) and \\(\\Phi(\\varphi)\\) back together, we get an angular solution \\(Y(\\theta,\\varphi)\\) of the form \\[\nY(\\theta,\\varphi) = \\sum_{\\ell=0}^\\infty \\sum_{m=-\\ell}^\\ell c_{\\ell m} P_\\ell^m(\\cos\\theta) e^{im\\varphi} \\ .\n\\] Note that we absorbed the integration constant for \\(\\Phi(\\varphi)\\) into the ones for \\(\\Theta(\\theta)\\).\nNow, recall again from the appendix that functions proportional to \\(P_\\ell^m(\\cos\\theta) e^{im\\varphi}\\) also have a name. They’re called the spherical harmonics, which we by convention normalize and write in the more complicated form \\[\nY_{\\ell m}(\\theta,\\varphi) \\equiv (-1)^m \\sqrt{\\frac{2\\ell+1}{4\\pi} \\frac{(\\ell-m)!}{(\\ell+m)!}} P_\\ell^m(\\cos\\theta) e^{im\\varphi} \\ .\n\\] The spherical harmonics are precisely the eigenfunctions of the Laplacian in spherical coordinates. By construction, they form a complete orthonormal set of functions on the sphere, meaning we can write any \\(Y(\\theta,\\varphi)\\) as a superposition of them, \\[\nY(\\theta,\\varphi) = \\sum_{\\ell=0}^\\infty \\sum_{m=-\\ell}^\\ell c_{\\ell m} Y_\\ell^m(\\theta,\\varphi) \\ .\n\\] Finally, we can combine \\(R(r)\\) and \\(Y(\\theta,\\varphi)\\) back together to get the general solution for the potential \\(\\phi(\\mathbf{x})\\). We’ll again absorb the constants \\(c_{\\ell m}\\) into the constants of \\(R(r)\\) and write \\[\n\\boxed{\n\\phi(\\mathbf{x}) = \\sum_{\\ell=0}^\\infty \\sum_{m=-\\ell}^\\ell \\big(a_{\\ell m} r^\\ell + b_{\\ell m} r^{-(\\ell+1)}\\big) Y_\\ell^m(\\theta,\\varphi)} \\ .\n\\] This equation looks exactly the same as the one for the azimuthally symmetric potential, except we now have to replace the Legendre polynomial \\(P_\\ell(\\cos\\theta)\\) by the more general spherical harmonic \\(Y_\\ell^m(\\theta,\\varphi)\\) and sum over \\(m\\). Indeed, it’s easy to see that the azimuthally symmetric potential is a special case of this general potential. Azimuthal symmetry is evidently equivalent to requiring that \\(m=0\\). If we set \\(m=0\\) in the general potential we recover the previous one, up to a normalization factor.\nThe coefficients \\(a_{\\ell m}\\) and \\(b_{\\ell m}\\) can be found in the usual way, by imposing the final boundary condition and taking an inner product. As before, the requirement that the potential not blow up inside the boundary surface will often force either \\(a_{\\ell m}\\) or \\(b_{\\ell m}\\) to vanish depending on whether we’re inside of or outside of the boundary surface. If we seek a solution both inside and outside the surface we’ll need to match these expressions together at the boundary.\n\n\n\nLaplace’s Equation in Cylindrical Coordinates\nLast, we’ll apply separation of variables to the Laplacian in cylindrical coordinates \\((\\varrho,\\varphi,z)\\). In cylindrical coordinates, the Laplacian can be written in the form \\[\n\\nabla^2 \\phi = \\frac{1}{\\varrho} \\frac{\\partial}{\\partial\\varrho} \\bigg(\\varrho \\frac{\\partial\\phi}{\\partial\\varrho} \\bigg) + \\frac{1}{\\varrho^2} \\frac{\\partial^2 \\phi}{\\partial^2\\varphi} + \\frac{\\partial^2 \\phi}{\\partial z^2} \\ .\n\\] To satisfy Laplace’s equation we again require \\(\\nabla^2 \\phi = 0\\). If we set the above equation equal to zero we get \\[\n0 = \\frac{1}{\\varrho} \\frac{\\partial}{\\partial\\varrho} \\bigg(\\varrho \\frac{\\partial\\phi}{\\partial\\varrho} \\bigg) + \\frac{1}{\\varrho^2} \\frac{\\partial^2 \\phi}{\\partial^2\\varphi} + \\frac{\\partial^2 \\phi}{\\partial z^2} \\ .\n\\] As with spherical coordinates, the terms aren’t completely separable since \\(\\varrho\\) appears in two terms. We’ll first consider the case of cylindrical symmetry, where the potential is independent of \\(z\\), before proceeding to the case of more general potentials.\n\nCylindrically Symmetric Potentials\nFor problems with cylindrically symmetry the potential depends only on \\(r\\) and \\(\\varphi\\), not on \\(z\\). These kinds of problems include the infinitely long wire held at constant potential, or infinitely long wires held at some anisotropic potential \\(V(\\varphi)\\).\nIf we assume the potential is cylindrically symmetric then the \\(z\\) derivatives in Laplace’s equation vanish, and we can multiply through by \\(\\varrho^2\\) and write Laplace’s equation in the form \\[\n0 = \\varrho \\frac{\\partial}{\\partial\\varrho} \\bigg(\\varrho \\frac{\\partial\\phi}{\\partial\\varrho} \\bigg) + \\frac{\\partial^2 \\phi}{\\partial^2\\varphi} \\ .\n\\] Now each term is separable and we can proceed to apply separation of variables. Assume a trial solution of the form \\[\n\\phi(\\mathbf{x}) = R(\\varrho) \\Phi(\\varphi) \\ .\n\\] Plugging this into Laplace’s equation and dividing through by \\(\\phi = RZ\\), we end up with \\[\n0 = \\frac{\\varrho}{R} \\frac{d}{d\\varrho} \\bigg(\\varrho \\frac{dR}{d\\varrho} \\bigg) + \\frac{1}{\\Phi} \\frac{d^2 \\Phi}{d\\varphi^2} \\ .\n\\] The only way this equation can vanish is if both terms equal a constant of opposite sign, which we’ll call \\(n^2\\). Then we have \\[\n\\begin{align*}\n\\varrho \\frac{d}{d\\varrho} \\bigg(\\varrho \\frac{dR}{d\\varrho} \\bigg)&= n^2 R(\\varrho) \\ , \\\\\n\\frac{d^2 \\Phi}{d\\varphi^2} &= -n^2 \\Phi(\\varphi) \\ .\n\\end{align*}\n\\] The second equation is easy enough to solve. In real form its solutions are sines and cosines. Provided the problem allows \\(\\varphi\\) to range over the full circle from \\(0 \\leq \\varphi \\leq 2\\pi\\), then we require that the potential be the same when \\(\\varphi \\rightarrow \\varphi + 2\\pi\\). That is, we require that \\(n\\) be an integer so that \\(\\Phi(\\phi) = \\Phi(\\phi + 2\\pi)\\). This means that for each \\(n\\) we’ll have a solution of the form \\[\n\\Phi_n(\\varphi) = a \\cos n\\varphi + b \\sin n\\varphi \\ .\n\\] Note that if \\(\\varphi\\) is restricted to some range \\(0 \\leq \\varphi \\leq \\beta\\) then we have to modify this result slightly. In that case, \\(n\\) will no longer be an integer, but must instead be an integer multiple of \\(\\frac{\\pi}{\\beta}\\). We’ll see an example of such a case below.\nAnyway, to get the full solution for all integer \\(n\\) we appeal to the principle of superposition. We know that the set of functions \\(\\Phi_n(\\varphi)\\) are just the real Fourier functions on the interval \\(0 \\leq \\varphi \\leq 2\\pi\\), which form a complete set of orthogonal functions on this interval. This means the general solution \\(\\Phi(\\varphi)\\) can be written in terms of a real Fourier series of the form \\[\n\\Phi(\\varphi) = \\frac{a_0}{2} + \\sum_{n=1}^\\infty \\big(a_n \\cos n\\varphi + b_n \\sin n\\varphi\\big) \\ .\n\\] To solve the first equation we’ll assume a trial solution of the form \\(R(\\varrho) = \\varrho^\\lambda\\). Plugging this in forces \\(\\lambda = \\pm n\\), giving \\[\nR_n(\\varrho) = c_1 \\varrho^n + c_2 \\varrho^{-n} \\ .\n\\] However, this is only true when \\(n \\neq 0\\). When \\(n=0\\) we need to solve for \\(R(\\varrho)\\) separately. In that case it’s easy to see that \\[\nR_0(\\varrho) = d_1 + d_2 \\log \\varrho \\ .\n\\] To get the general solution for the potential we then combine these two functions. We’ll absorb the constants together and write \\[\n\\phi(\\mathbf{x}) = a_0 + b_0 \\log\\varrho + \\sum_{n=1}^\\infty \\big[(a_n \\cos n\\varphi + b_n \\sin n\\varphi)\\varrho^n + (c_n \\cos n\\varphi + d_n \\sin n\\varphi)\\varrho^{-n}\\big] \\ .\n\\] Note that the requirement that the potential not blow up inside the boundary surface will generally force some of these constants to vanish depending on whether we’re inside of our outside of the boundary surface. If we’re inside the surface, we require that \\(b_0\\) and the \\(\\varrho^{-n}\\) constants vanish so that the potential doesn’t blow up at the origin. If we’re outside the surface we require that the \\(\\varrho^n\\) constants vanish so that the potential vanishes at infinity.\nTo check that this solution makes sense, let’s consider the case of a potential where \\(\\phi = \\phi(\\varrho)\\) only. In this case only the \\(n=0\\) terms survive, leaving \\[\n\\phi(\\varrho) = a_0 + b_0 \\log\\varrho \\ .\n\\] The associated electric field is then \\(\\mathbf{E}(\\mathbf{x}) = E(\\varrho) \\mathbf{e}_\\varrho\\), where \\[\nE(\\varrho) = -\\frac{d\\phi}{d\\varrho} = -\\frac{b_0}{\\varrho} \\equiv \\frac{2\\lambda}{\\varrho} \\ .\n\\] If we take \\(b_0 = -2\\lambda\\) and \\(a_0 = \\phi(0)\\) as a ground point, this is evidently the potential of a uniform wire with line density \\(\\lambda\\). Let’s now consider a more general example.\n\nExample: Grounded infinite wire perpendicular to a uniform electric field\nLet’s now consider the problem of an infinite, grounded wire of some thickness \\(R\\) that’s placed perpendicular to a uniform external electric field \\(\\mathbf{E}_0\\). We’ll suppose the wire is oriented along the \\(z\\)-axis and the field is oriented in the direction of the positive \\(x\\)-axis, with \\(\\mathbf{E}_0 = E_0 \\mathbf{e}_x\\).\nFIGURE\nWe can thus formulate this problem in terms of the following boundary value problem, \\[\n\\begin{align*}\n\\begin{cases}\n\\nabla^2 \\phi(\\varrho,\\varphi,z) = 0 \\ , \\\\\n\\text{where} \\ \\phi(R,\\varphi,z) = 0 \\ , \\\\\n\\phi(r,\\varphi,z) \\rightarrow -E_0 \\varrho \\cos\\varphi \\ \\text{as} \\ \\varrho \\rightarrow \\infty \\ .\n\\end{cases}\n\\end{align*}\n\\] Again, we see that this problem is clearly cylindrically symmetric since the wire is infinite and perpendicular to the field. This means the general solution for the potential can again be written in the form \\[\n\\phi(\\mathbf{x}) = a_0 + b_0 \\log\\varrho + \\sum_{n=1}^\\infty \\big[(a_n \\cos n\\varphi + b_n \\sin n\\varphi)\\varrho^n + (c_n \\cos n\\varphi + d_n \\sin n\\varphi)\\varrho^{-n}\\big] \\ .\n\\] Requiring that \\(\\phi \\rightarrow -E_0 \\varrho \\cos\\varphi\\) as \\(\\varrho \\rightarrow \\infty\\) forces \\(a_0 = b_0 = 0\\) and \\(b_n = d_n = 0\\) for all \\(n\\), and \\(a_n = c_n = 0\\) when \\(n \\neq 1\\). When \\(n=1\\) we must evidently have \\(a_1 = -E_0\\) as well. This evidently leaves a solution of the form \\[\n\\phi(\\mathbf{x}) = \\bigg(-E_0 \\rho + \\frac{c_1}{\\varrho}\\bigg) \\cos\\varphi \\ .\n\\] Requiring now that the potential vanish on the surface of the wire forces \\(c_1 = E_0 R^2\\). Plugging this back in, we finally have \\[\n\\phi(\\mathbf{x}) = -E_0 \\varrho \\bigg(1 - \\frac{R^2}{\\varrho^2}\\bigg) \\cos\\varphi \\ .\n\\] When dealing with conductors placed in an external field, it’s good to look at the induced charge density \\(\\sigma\\) along the surface of the conductor as well. Since the surface normal is just \\(\\mathbf{n} = \\mathbf{e}_\\varrho\\) in this problem, we have \\[\n\\sigma = -\\frac{1}{4\\pi} \\frac{\\partial \\phi}{\\partial\\varrho} = \\frac{E_0}{2\\pi} \\cos\\varphi \\ .\n\\] As we’d expect, the surface charge polarizes along the direction of the field, with positive charge concentrating in the positive \\(x\\)-direction and the negative charge concentrating in the negative \\(x\\)-direction.\n\n\nExample: Infinite hollow cylinder held at a given surface charge density\nSuppose we have an infinitely long hollow cylinder of radius \\(R\\) whose surface is held at some surface charge density \\(\\sigma(\\varphi)\\). We’re interested in the behavior of the potential inside and outside the cylinder.\nFIGURE\nRecall that we can relate the surface density to the potential via its normal derivative, with \\(\\frac{\\partial \\phi}{\\partial n} = -4\\pi \\sigma\\). Since the surface normal to the cylinder is \\(\\mathbf{n} = \\pm \\mathbf{e}_\\varrho\\) depending on whether we’re outside or inside the surface, we thus require that \\(\\frac{\\partial \\phi}{\\partial \\varrho} \\big|_{\\varrho=R} = \\mp 4\\pi \\sigma(\\varphi)\\). We’ll also require that the potential not blow up at any finite position or at infinity.\nThis means we end up with a mixed boundary value problem to solve of the form \\[\n\\begin{align*}\n\\begin{cases}\n\\nabla^2 \\phi(\\varrho,\\varphi,z) = 0 \\ , \\\\\n\\text{where} \\ \\frac{\\partial \\phi}{\\partial \\varrho} \\big|_{\\varrho=R} = \\mp 4\\pi \\sigma(\\varphi) \\ , \\\\\n|\\phi| &lt; \\infty \\ \\text{for all} \\ 0 \\leq \\varrho \\leq \\infty \\ .\n\\end{cases}\n\\end{align*}\n\\] Since this problem is cylindrically symmetric, we know the general solution can be written in the form \\[\n\\phi(\\mathbf{x}) = a_0 + b_0 \\log\\varrho + \\sum_{n=1}^\\infty \\big[(a_n \\cos n\\varphi + b_n \\sin n\\varphi)\\varrho^n + (c_n \\cos n\\varphi + d_n \\sin n\\varphi)\\varrho^{-n}\\big] \\ .\n\\] Now, outside the cylinder we require the potential not blow up at infinity. This forces \\(b_0 = a_n = b_n = 0\\) outside the wire, giving \\[\n\\phi_+(\\mathbf{x}) = a_0^+ + \\sum_{n=1}^\\infty (c_n^+ \\cos n\\varphi + d_n^+ \\sin n\\varphi)\\varrho^{-n} \\quad , \\quad \\varrho \\geq R \\ .\n\\] Meanwhile, inside the cylinder we require that the potential not blow up when \\(\\varrho \\leq R\\). This forces \\(b_0 = c_n = d_n = 0\\), giving \\[\n\\phi_-(\\mathbf{x}) = a_0^- + \\sum_{n=1}^\\infty (a_n^- \\cos n\\varphi + b_n^- \\sin n\\varphi)\\varrho^n \\quad , \\quad \\varrho \\leq R \\ .\n\\] We now need to match these two solutions together at the boundary surface \\(\\varrho = R\\). Along this surface we require that these two solutions match and that the difference in normal derivatives be proportional to \\(\\sigma(\\varphi)\\). The first condition requires that \\[\n\\begin{align*}\n0 &= \\phi_+(R,\\varphi,z) - \\phi_-(R,\\varphi,z) \\\\\n&= (a_0^+ - a_0^-) + \\sum_{n=1}^\\infty \\bigg[(c_n^+ \\cos n\\varphi + d_n^+ \\sin n\\varphi) R^{-n} - (a_n^- \\cos n\\varphi + b_n^- \\sin n\\varphi) R^n \\bigg] \\\\\n&= (a_0^+ - a_0^-) + \\sum_{n=1}^\\infty R^n \\bigg[(c_n^+ R^{-2n} - a_n^-) \\cos n\\varphi + (d_n^+ R^{-2n} - b_n^-) \\sin n\\varphi \\bigg] \\ .\n\\end{align*}\n\\] The only way this can hold is if each term in parentheses vanishes, with \\(a_0^+ = a_0^-\\), \\(a_n^- = c_n^+ R^{-2n}\\), and \\(b_n^- = d_n^+ R^{-2n}\\).\nThe second condition requires that \\[\n\\begin{align*}\n\\sigma(\\varphi) &= -\\frac{1}{4\\pi} \\bigg[\\frac{\\partial \\phi_+}{\\partial \\varrho} - \\frac{\\partial \\phi_-}{\\partial \\varrho}\\bigg]_{\\varrho=R} \\\\\n&= -\\frac{1}{4\\pi} \\sum_{n=1}^\\infty \\bigg[-n(c_n^+ \\cos n\\varphi + d_n^+ \\sin n\\varphi)R^{-(n+1)} - n(a_n^- \\cos n\\varphi + b_n^- \\sin n\\varphi)R^{n-1} \\bigg] \\\\\n&= \\frac{1}{4\\pi} \\sum_{n=1}^\\infty n R^{n-1} \\bigg[(c_n^+ R^{-2n} + a_n^-) \\cos n\\varphi + (d_n^+ R^{-2n} + b_n^-) \\sin n\\varphi \\bigg] \\ .\n\\end{align*}\n\\] Once we have a specific form for \\(\\sigma(\\varphi)\\) we can proceed to match coefficients on the left and right hand sides and determine the coefficients. As an example, suppose \\(\\sigma(\\varphi) = k \\sin m\\varphi\\) for some integer \\(m\\) and parameter \\(k\\). This means for all \\(n \\neq m\\) each term must vanish, with \\(a_n^- = -c_n^+ R^{-2n}\\) for all \\(n\\), \\(b_n^- = -d_n^+ R^{-2n}\\) for \\(n \\neq m\\), and \\(d_m^+ R^{-2m} + b_m^- = k\\) when \\(n=m\\).\nMatching these two sets of conditions together, we evidently require that \\(a_n^- = b_n^- = c_n^+ = d_n^+ = 0\\) when \\(n \\neq m\\), and \\[\nb_m^- = \\frac{2\\pi k}{m R^{m-1}} \\quad , \\quad d_m^+ = \\frac{2\\pi k}{m} R^{m+1} \\ .\n\\] The coefficients \\(a_0^+ = a_0^-\\) are immaterial to this problem and can freely be set to zero. Plugging these coefficients in then gives the final potential for this particular choice of \\(\\sigma(\\varphi)\\), \\[\n\\phi(\\mathbf{x}) = \\begin{cases}\n\\frac{2\\pi k R}{m} \\big(\\frac{\\varrho}{R}\\big)^m \\sin m\\varphi & \\varrho \\leq R \\ , \\\\\n\\frac{2\\pi k R}{m} \\big(\\frac{R}{\\varrho}\\big)^m \\sin m\\varphi & \\varrho \\geq R \\ .\n\\end{cases} \\ .\n\\] Notice that this potential evidently has a discontinuous first derivative at the surface of the cylinder. This is consistent with our observation that the electric field is discontinuous when crossing a surface of charge.\n\n\nExample: Behavior of electric fields around corners and edges of conductors\nLet’s now consider a problem that will help us understand some physics better. We want to ask ourselves how the potential and electric field behave near sharp corners and edges of conducting objects. We can model this behavior by studying the following relatively simple problem.\nSuppose we have two infinite conducting sheets that intersect at some angle \\(0 \\leq \\beta \\leq 2\\pi\\) in the \\(xy\\)-plane. We’ll suppose that both of the sheets are held at some constant potential \\(V\\) on their surfaces. Since the sheets are infinite along the \\(z\\)-direction, we can treat this as a cylindrically symmetric problem and focus only on the behavior of the potential \\(\\phi(\\varrho,\\varphi)\\) in the \\(xy\\)-plane.\nConsider then the following boundary value problem, \\[\n\\begin{align*}\n\\begin{cases}\n\\nabla^2 \\phi(\\varrho,\\varphi,z) = 0 \\ , \\\\\n\\text{where} \\ \\phi(\\varrho,0,z) = V \\ , \\\\\n\\phi(\\varrho,\\beta,z) = V \\ .\n\\end{cases}\n\\end{align*}\n\\] Note that we require \\(0 \\leq \\varphi \\leq \\beta\\). This means \\(n\\) will no longer be an integer, but instead \\(n = \\frac{k\\pi}{\\beta}\\) for some integer \\(k\\). Replacing \\(n\\) by this expression in the general formula for the potential, we thus have \\[\n\\phi(\\mathbf{x}) = a_0 + b_0 \\log\\varrho + \\sum_{k=1}^\\infty \\bigg[\\bigg(a_k \\cos \\frac{k\\pi\\varphi}{\\beta} + b_k \\sin \\frac{k\\pi\\varphi}{\\beta}\\bigg) \\varrho^{k\\pi / \\beta} + \\bigg(c_k \\cos \\frac{k\\pi\\varphi}{\\beta} + d_k \\sin \\frac{k\\pi\\varphi}{\\beta}\\bigg) \\varrho^{-k\\pi / \\beta}\\bigg] \\ .\n\\] We’re interested in studying the behavior of this potential as \\(\\varrho \\rightarrow 0\\). To keep the potential from blowing up we thus require that \\(b_0 = c_k = d_k = 0\\). Requiring that \\(\\phi = V\\) when \\(\\varphi = 0,\\beta\\) also forces \\(a_0 = V\\) and all \\(b_k = 0\\). We’re thus left with the potential \\[\n\\phi(\\mathbf{x}) = V + \\sum_{k=1}^\\infty b_k \\varrho^{k\\pi / \\beta} \\sin \\frac{k\\pi\\varphi}{\\beta} \\ .\n\\] Now, as \\(\\varrho \\rightarrow 0\\) only the \\(k=1\\) term dominates in the sum, meaning near the corner \\(\\varrho = 0\\) we have \\[\n\\phi(\\mathbf{x}) \\approx V + b_1 \\varrho^{\\pi / \\beta} \\sin \\frac{\\pi\\varphi}{\\beta} \\ .\n\\] This means near the corner the electric field is evidently given by \\[\n\\mathbf{E}(\\mathbf{x}) \\approx -\\frac{\\pi b_1}{\\beta} \\varrho^{\\pi / \\beta-1} \\bigg(\\sin \\frac{\\pi\\varphi}{\\beta}\\mathbf{e}_\\varrho + \\cos \\frac{\\pi\\varphi}{\\beta} \\mathbf{e}_\\varphi\\bigg) \\ .\n\\] The surface charge density near the corner is evidently then proportional to the field strength near the corner, with \\[\n\\sigma \\approx \\frac{|\\mathbf{E}(\\varrho,0)|}{4\\pi} \\approx -\\frac{b_1}{4\\beta} \\varrho^{\\pi / \\beta-1} \\ .\n\\] Evidently, both the field strength and the density near the corner vary as \\(\\varrho^{\\pi / \\beta-1}\\). Evidently, the strength of the field and the charge density near the corner will depend explicitly on the corner’s angle \\(\\beta\\). In the figure below, we show this relation for different values of \\(\\beta\\).\nFIGURE\nNotice when \\(\\beta = \\pi\\) we recover the case of a flat conducting plane, where the electric field is constant and the charge is uniformly distributed along the surface. When \\(\\beta &lt; \\pi\\) the charge density and field go to zero near the corner, but grow rapidly as we move away from the corner. Meanwhile, when \\(\\beta &gt; \\pi\\) the corner becomes an edge, where the charge density and field become infinitely large at the edge before rapidly falling off away from the edge.\nThe same qualitative behaviors turn out to hold true for 3-dimensional surfaces as well. This is the reason why lightening rods work. The high concentration of charges near the edge of the rod creates a large electric field, which will draw lightening from the air when electric breakdown takes place. Electric breakdown typically occurs when clouds create electric field strengths higher than about \\(E \\sim 250 \\ \\frac{\\text{kV}}{\\text{cm}}\\). When this happens, a closed circuit effectively gets created between the charged clouds and the ground, which causes the charge to move from clouds to the ground, where the lightening rod will attract much of the charge.\n\n\n\nGeneral Potentials\nWe’ll now return to the more general case with no symmetry in the potential. Recall we had Laplace’s equation in the form \\[\n0 = \\frac{1}{\\varrho} \\frac{\\partial}{\\partial\\varrho} \\bigg(\\varrho \\frac{\\partial\\phi}{\\partial\\varrho} \\bigg) + \\frac{1}{\\varrho^2} \\frac{\\partial^2 \\phi}{\\partial^2\\varphi} + \\frac{\\partial^2 \\phi}{\\partial z^2} \\ .\n\\] We’ll first apply separation of variables to split off the first two terms from the second. Assume a trial solution of the form \\[\n\\phi(\\mathbf{x}) = F(\\varrho, \\varphi) Z(z) \\ .\n\\] Plugging this in and dividing by \\(JZ\\), we end up with \\[\n0 = \\frac{1}{F\\varrho} \\frac{\\partial}{\\partial\\varrho} \\bigg(\\varrho \\frac{\\partial F}{\\partial\\varrho} \\bigg) + \\frac{1}{F\\varrho^2} \\frac{\\partial^2 F}{\\partial^2\\varphi} + \\frac{1}{Z}\\frac{\\partial^2 Z}{\\partial z^2} \\ .\n\\] The only way this equation can vanish is if the first two terms equal a constant, and the last term is a constant of opposite sign. We’ll call that constant \\(-k^2\\). We then end up with two differential equations of the form \\[\n\\begin{align*}\n\\frac{1}{\\varrho} \\frac{\\partial}{\\partial\\varrho} \\bigg(\\varrho \\frac{\\partial F}{\\partial\\varrho} \\bigg) + \\frac{1}{\\varrho^2} \\frac{\\partial^2 F}{\\partial^2\\varphi} &= -k^2 F(\\varrho,\\varphi) \\ , \\\\\n\\frac{d^2 Z}{dz^2} &= k^2 Z(z) \\ .\n\\end{align*}\n\\] The second equation is easy enough to solve. Its solutions are just exponentials, with \\[\nZ(z) = A e^{kz} + B e^{-kz} \\ .\n\\] To deal with the first equation we separate variables again by assuming a trial solution of the form \\[\nF(\\varrho,\\varphi) = R(\\varrho) \\Phi(\\varphi) \\ .\n\\] Then multiplying both sides of the equation by \\(\\varrho^2\\), dividing by \\(F = R\\Phi\\), and rearranging terms, we get \\[\n\\bigg[\\frac{\\varrho}{R\\varrho} \\frac{d}{d\\varrho} \\bigg(\\varrho \\frac{dR}{d\\varrho} \\bigg) + k^2 \\varrho^2\\bigg] + \\frac{1}{\\Phi} \\frac{d^2 \\Phi}{d^2\\varphi} = 0 \\ .\n\\] Again, the only way these terms can vanish is if they equal the same constant with opposite sign. We’ll call that constant \\(n^2\\), so that we end up with following two differential equations, \\[\n\\begin{align*}\n\\frac{1}{\\varrho} \\frac{d}{d\\varrho} \\bigg(\\varrho \\frac{dR}{d\\varrho} \\bigg) + k^2 \\varrho^2 R(\\varrho)  &= n^2 R(\\varrho) \\ , \\\\\n\\frac{d^2 \\Phi}{d^2\\varphi} &= -n^2 \\Phi(\\varphi) \\ .\n\\end{align*}\n\\] The second equation just gives the same solution found in the cylindrically symmetric case. Requiring that \\(\\Phi(\\varphi)\\) be periodic on the interval \\(0 \\leq \\varphi \\leq 2\\pi\\) forces \\(n\\) be an integer. For each integer \\(n\\) we get a solution in terms of sines and cosines of the form \\[\n\\Phi_n(\\varphi) = a_n \\cos n\\varphi + b_n \\sin n\\varphi \\ .\n\\] Since these Fourier functions form a complete set of orthogonal functions, we can get the general solution \\(\\Phi(\\varphi)\\) by expanding in terms of these basis functions \\(\\Phi_n(\\varphi)\\) to get a Fourier series solution.\nTo deal with the first equation, we’ll expand out the derivative and move everything to one side to write \\[\n\\varrho^2\\frac{d^2R}{d\\varrho^2} + \\varrho \\frac{dR}{d\\varrho} + \\big(k^2 \\varrho^2 - n^2\\big) R(\\varrho) = 0 \\ .\n\\] It’s conventional to write this equation slightly differently by letting \\(x = k\\varrho\\). Plugging this in, we get \\[\nx^2\\frac{d^2R}{dx^2} + x \\frac{dR}{dx} + \\big(x^2 - n^2\\big) R(x) = 0 \\ .\n\\] From the appendix, we recognize this differential equation as Bessel’s equation. Its solutions are given by a superposition of Bessel functions of the first and second kind, denoted \\(J_n(x)\\) and \\(Y_n(x)\\) respectively, \\[\nR_n(x) = c_n J_n(x) + d_n Y_n(x) \\ .\n\\] Recall that Bessel functions can be qualitatively thought of as decaying oscillating functions. This means they’ll both have infinitely many roots, which we’ll call \\(x_{nm}\\), where \\(m\\) is another integer characterizing the \\(m\\)th root of \\(J_n(x)\\). Note that by definition both \\(J_n(x)\\) and \\(Y_n(x)\\) will share the same roots for a given fixed \\(n\\).\nAs written, solutions of this form don’t form a complete set of orthogonal functions, but for each \\(n\\) we can find such a set by letting \\(k\\) be proportional to the roots \\(x_{nm}\\). Indeed, if we let \\(k_{nm} = \\frac{x_{nm}}{a}\\) for some characteristic length \\(a\\), then for each \\(n\\), the set of functions \\(J_n(k_{nm} \\varrho)\\) and \\(Y_n(k_{nm} \\varrho)\\) will form a complete set of orthogonal functions on the interval \\(0 \\leq \\varrho \\leq a\\). We can then express each radial solution \\(R_n(\\varrho)\\) as a superposition of these basis functions \\(R_{nm}(\\varrho)\\) defined by \\[\nR_{nm}(\\varrho) = c_n J_n(k_{nm}\\varrho) + d_n Y_n(k_{nm} \\varrho) \\ .\n\\] To proceed further we need to know the specific boundary conditions for the given problem to stitch together the general solution. Let’s suppose we have a cylinder of radius \\(R\\) and height \\(h\\). Suppose the bottom and side of the cylinder are grounded, and the top of the cylinder is held at some known potential \\(V(\\varrho,\\varphi)\\).\nFIGURE\nThis then gives a boundary value problem of the form \\[\n\\begin{align*}\n\\begin{cases}\n\\nabla^2 \\phi(\\varrho,\\varphi,z) = 0 \\ , \\\\\n\\text{where} \\ \\phi(\\varrho,\\varphi,h) = V(\\varrho,\\varphi) \\ , \\\\\n\\phi(\\varrho,\\varphi,0) = 0 \\ , \\\\\n\\phi(R,\\varphi,z) = 0 \\ , \\\\\n|\\phi(\\mathbf{x})| &lt; \\infty \\ \\text{as} \\ |\\mathbf{x}| \\rightarrow \\infty \\ .\n\\end{cases}\n\\end{align*}\n\\] Suppose first we’re inside the cylinder, so \\(0 \\leq \\varrho \\leq R\\) and \\(0 \\leq z \\leq h\\). We can express the radial solution as a superposition of Bessel functions of the form \\[\nR_{nm}(\\varrho) = c_{nm} J_n(k_{nm}\\varrho) + d_{nm} Y_n(k_{nm} \\varrho) \\ ,\n\\] where requiring \\(k_{nm} = \\frac{x_{nm}}{R}\\) will forces this solution to vanish at the sides of the cylinder where \\(\\varrho = R\\). Since \\(Y_n(k_{nm} \\varrho)\\) blows up at the origin, requiring that the potential not blow up at the origin will force each \\(d_{nm} = 0\\).\nAlong the \\(z\\)-direction, it’s easy to see that imposing the boundary condition \\(Z(0) = 0\\) will yield a family of general solutions parametrized by \\(k_{nm}\\) of the form \\[\nZ_{nm}(z) = \\sinh k_{nm} z \\ .\n\\] The general solution for \\(\\Phi_n(\\varphi)\\) is unaffected by the boundary conditions. Multiplying the three solutions together will then yield an infinite set of basis potentials of the form \\[\n\\phi_{nm}(\\varrho,\\varphi,z) = J_n(k_{nm}\\varrho) \\big[a_{nm} \\cos n\\varphi + b_{nm} \\sin n\\varphi\\big] \\sinh k_{nm} z \\ .\n\\] These basis potentials still don’t satisfy the final boundary condition that \\(\\phi(\\varrho,\\varphi,h) = V(\\varrho,\\varphi)\\). This means we need to use the principle of superposition to consider a more general class of solutions of the form \\[\n\\phi(\\varrho,\\varphi,z) = \\sum_{n=0}^\\infty \\sum_{m=1}^\\infty J_n(k_{nm}\\varrho) \\big[a_{nm} \\cos n\\varphi + b_{nm} \\sin n\\varphi\\big] \\sinh k_{nm} z \\ .\n\\] If we plug the final boundary condition into the previous expression and set \\(z = h\\), we get \\[\nV(\\varrho,\\varphi) = \\phi(\\varrho,\\varphi,h) = \\sum_{n=0}^\\infty \\sum_{m=1}^\\infty J_n(k_{nm}\\varrho) \\big[a_{nm} \\cos n\\varphi + b_{nm} \\sin n\\varphi\\big] \\sinh k_{nm} h \\ .\n\\] To determine the coefficients \\(a_{nm}\\), we multiply both sides by \\(\\varrho J_{n'}(k_{n'm'}\\varrho) \\cos n'\\varphi\\) and integrate over \\(\\varrho\\) and \\(\\varphi\\) inside the cylinder. On the right-hand side, we end up with \\[\n\\sum_{n,m} \\sinh k_{nm} h \\int_0^R d\\varrho \\ \\varrho J_{n'}(k_{n'm'}\\varrho) J_n(k_{nm}\\varrho) \\int_0^{2\\pi} d\\varphi \\ \\cos n'\\varphi \\big[a_{nm} \\cos n\\varphi + b_{nm} \\sin n\\varphi\\big] \\ .\n\\] To deal with the first integral we appeal to the orthogonality condition of Bessel functions, which says that \\[\n\\int_0^R d\\varrho \\ \\varrho J_{n'}(k_{n'm'}\\varrho) J_n(k_{nm}\\varrho) = \\frac{R^2}{2} J_{n'+1}^2(k_{n'm'} \\varrho) \\delta_{mm'} \\ .\n\\] For the second integral, we use the fact that \\(\\cos n'\\varphi\\) will be orthogonal to all \\(\\sin n\\varphi\\), and all \\(\\cos n\\varphi\\) when \\(n \\neq n'\\) to get \\[\n\\int_0^{2\\pi} d\\varphi \\ \\cos n'\\varphi \\big[a_{nm} \\cos n\\varphi + b_{nm} \\sin n\\varphi\\big] = \\pi a_{nm} \\delta_{nn'} \\ .\n\\] Putting these two results together, the left-hand side evidently evaluates to \\[\n\\frac{\\pi R^2}{2} J_{n'+1}^2(k_{n'm'} \\varrho) a_{n'm'} \\sinh k_{n'm'} h \\ .\n\\] For the right-hand side we do the same thing to get an integral of the form \\[\n\\int_0^R d\\varrho \\int_0^{2\\pi} d\\varphi \\ \\varrho V(\\varrho,\\varphi) J_{n'}(k_{n'm'}\\varrho) \\cos n'\\varphi \\ .\n\\] This means the coefficients \\(a_{nm}\\) will be given by the formula \\[\na_{nm} = \\frac{2}{\\pi R^2 J_{n+1}^2(k_{nm} \\varrho)} \\frac{1}{\\sinh k_{nm} h} \\int_0^R d\\varrho \\int_0^{2\\pi} d\\varphi \\ \\varrho V(\\varrho,\\varphi) J_{n}(k_{nm}\\varrho) \\cos n\\varphi \\ .\n\\] Note that this is strictly speaking only true when \\(n \\neq 0\\). When \\(n = 0\\) we need to also divide by \\(2\\), since in that case no cosine terms appear in the \\(\\varphi\\) integral, which will cause it to give \\(2\\pi\\) instead of \\(\\pi\\).\nSimilarly, we can determine the coefficients \\(b_{nm}\\) by multiplying both sides of the equation for \\(\\phi(\\varrho,\\varphi,h)\\) by \\(\\varrho J_{n'}(k_{n'm'}\\varrho) \\sin n'\\varphi\\) and performing the same integrations. We end up with the same formula except with the cosine replaced by a sine, \\[\nb_{nm} = \\frac{2}{\\pi R^2 J_{n+1}^2(k_{nm} \\varrho)} \\frac{1}{\\sinh k_{nm} h} \\int_0^R d\\varrho \\int_0^{2\\pi} d\\varphi \\ \\varrho V(\\varrho,\\varphi) J_{n}(k_{nm}\\varrho) \\sin n\\varphi \\ .\n\\] Once these coefficients are determined we have the general solution for the potential that solves this BVP.\nIn some cases, we might be interested in a problem where there is no cylindrical surface present. In that case we want to send \\(R \\rightarrow \\infty\\) and \\(z \\rightarrow \\infty\\). It turns out in this case that the radial solution \\(R(\\varrho)\\) will now need to be expressed as an integral over all \\(k\\). Such an integral is called a Hankel transform. In that case we’d instead express the general solution for the potential in this problem as a sum over \\(n\\) and an integral over \\(k\\). Sending \\(z \\rightarrow \\infty\\) as well makes the \\(\\sinh\\) function goes away, giving \\[\n\\phi(\\varrho,\\varphi,z) = \\sum_{n=0}^\\infty \\int_0^\\infty dk \\ J_n(k\\varrho) \\big[a_n(k) \\cos n\\varphi + b_n(k) \\sin n\\varphi\\big] \\ .\n\\] The boundary condition relation would then be expressed by the integral \\[\nV(\\varrho,\\varphi) = \\sum_{n=0}^\\infty \\int_0^\\infty dk \\ J_n(k\\varrho) \\big[a_n(k) \\cos n\\varphi + b_n(k) \\sin n\\varphi\\big] \\ .\n\\] Other than that, we’d proceed as the same. The only difference is that we now have a continuum of coefficients to obtain for both \\(a_n(k)\\) and \\(b_n(k)\\). We can use similar techniques as above, except that the orthogonality relation will result in the Kronecker delta \\(\\delta_{mm'}\\) being replaced by a Dirac delta function \\(\\delta(k-k')\\).\n\nFill this in more, since you’ll use it in the next example.\nAdd a section on Hankel transforms to the appendix, and expand on the Fourier transform there (and above perhaps).\n\n\nExample: Conducting plane with a circular hole\n\nSee Jackson.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Boundary Value Problems II</span>"
    ]
  },
  {
    "objectID": "electrodynamics/bvps-3.html",
    "href": "electrodynamics/bvps-3.html",
    "title": "Boundary Value Problems III",
    "section": "",
    "text": "Complex Methods\nIn many cases we find ourselves interested in boundary value problems that can be reduced to two dimensions, that is, problems that can be reduced to two variables. For example, if the symmetry of a problem dictates that the potential cannot depend on the \\(z\\)-coordinate, we can write \\(\\phi(\\mathbf{x}) = \\phi(x,y)\\), which reduces the problem to a two dimensional problem in the \\(xy\\)-plane.\nWhile the techniques we’ve covered so far we’ll often work in this setting, there’s another technique that can be used to solve more difficult problems that employs the tools of complex analysis, particular the theory of analytic functions and conformal mappings. We covered the mathematical background of this subject in the appendix. It’s recommend that the reader read that material before proceeding further with this section.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Boundary Value Problems III</span>"
    ]
  },
  {
    "objectID": "electrodynamics/bvps-3.html#complex-methods",
    "href": "electrodynamics/bvps-3.html#complex-methods",
    "title": "Boundary Value Problems III",
    "section": "",
    "text": "Complex Potential\nSuppose \\(\\phi(\\mathbf{x}) = \\phi(x,y)\\) is the 2-dimensional scalar potential for some boundary value problem free of source charges. Then we know that the potential must satisfy Laplace’s equation \\(\\nabla^2 \\phi = 0\\) inside the boundary region. We know from the appendix that any harmonic function in two dimensions can be thought of as the real part of some analytic function in the complex plane.\nWe can thus use the potential \\(\\phi(x,y)\\) to define a complex-valued analytic function \\(F(z)\\) of the form \\[\nF(z) = \\phi(x,y) + i \\psi(x,y) \\ ,\n\\] where \\(z = x + i y\\) is a complex variable whose real part is \\(x\\) and whose imaginary part is \\(y\\), and \\(\\psi(x,y)\\) is the harmonic conjugate of the potential. We call \\(F(z)\\) the complex potential, and \\(\\psi(x,y)\\) the stream function.\nSince \\(F(z)\\) is analytic inside the boundary region, we know that it must satisfy the Cauchy-Riemann equations in this region, \\[\n\\frac{\\partial \\phi}{\\partial x} = \\frac{\\partial \\psi}{\\partial y} \\quad , \\quad\n\\frac{\\partial \\phi}{\\partial y} = -\\frac{\\partial \\psi}{\\partial x} \\ .\n\\] Moreover, the potential \\(\\phi(x,y)\\) and the stream function \\(\\psi(x,y)\\) must each satisfy Laplace’s equation inside the boundary region, \\[\n\\nabla^2 \\phi(x,y) = 0 \\quad , \\quad \\nabla^2 \\psi(x,y) = 0 \\ .\n\\] Since the stream function is the harmonic conjugate of the potential, we can express it in terms of the potential directly by \\[\n\\psi(x,y) = -\\int dx \\ \\frac{\\partial \\phi}{\\partial y} + \\int dy \\ \\frac{\\partial \\phi}{\\partial x} \\ .\n\\] This means the stream function is completely determined by the potential, up to additive constants.\nWe also know that the level curves of \\(\\phi(x,y)\\), i.e. the equipotentials, must be perpendicular to the level curves of \\(\\psi(x,y)\\) in this region, or equivalently \\(\\nabla \\phi \\cdot \\nabla \\psi = 0\\). This lets us assign meaning to the stream function. The level curves of the stream function represent the direction of flow of electric field lines. To see why this is true, observe we can take the gradient of \\(\\psi(x,y)\\) and express it directly in terms of the electric field \\(\\mathbf{E} = -\\nabla \\phi\\) using the Cauchy-Riemann equations. We have \\[\n\\nabla \\psi = \\frac{\\partial \\psi}{\\partial x} \\mathbf{e}_x + \\frac{\\partial \\psi}{\\partial y} \\mathbf{e}_y = -\\frac{\\partial \\phi}{\\partial y} \\mathbf{e}_x + \\frac{\\partial \\phi}{\\partial x} \\mathbf{e}_y = E_y \\mathbf{e}_x - E_x \\mathbf{e}_y \\ .\n\\] That is, we have \\[\n\\mathbf{E}(x,y) = \\frac{\\partial \\psi}{\\partial y} \\mathbf{e}_x - \\frac{\\partial \\psi}{\\partial x} \\mathbf{e}_y \\ .\n\\] Since \\(\\nabla \\psi\\) is perpendicular to the level curves of \\(\\psi(x,y)\\), and since \\(\\mathbf{E} \\cdot \\nabla \\psi = 0\\), it must be the case that the electric field lines point along the level curves of the stream function.\nWe can also express the electric field directly in terms of a the complex derivative of the complex potential \\(F(z)\\). Using the properties of complex derivatives, we can write \\[\n\\frac{dF}{dz} = \\frac{\\partial \\phi}{\\partial x} - i \\frac{\\partial \\phi}{\\partial y} = -E_x + i E_y \\ .\n\\] Notice if we then take the negative complex conjugate of this derivative, we get a function whose real and imaginary parts are the components of the electric field, \\[\n-\\bigg(\\frac{dF}{dz}\\bigg)^* = E_x + i E_y \\ .\n\\] This is just the complex equivalent of the statement that the electric field is the negative gradient of the potential.\n\n\nConformal Mappings\nNow, recall that we can also think of any complex function as a geometric transformation acting on the complex plane. That is, any complex function \\(w = T(z)\\) can be thought of as mapping points \\(z = x + iy\\) in the \\(z\\)-plane to points \\(w = u+iv\\) in the \\(w\\)-plane. When \\(T(z)\\) is analytic in some region of the \\(z\\)-plane, these transformations are called conformal mappings. Conformal mappings can be shown to preserve the angles between curves under mapping. Moreover, under a conformal mapping the area element \\(da = dxdy\\) merely gets rescaled to a new area element \\(da' = dudv\\) by \\[\ndu dv = \\bigg|\\frac{dw}{dz}\\bigg|^2 dxdy \\ .\n\\] Most importantly for our purposes, conformal mappings preserve harmonic functions. That is, if \\(\\phi(u,v)\\) is some function that satisfies Laplace’s equation in the \\(w\\)-plane, then \\(\\phi(x,y) = \\phi\\big(u(x,y), v(x,y)\\big)\\) satisfies Laplace’s equation in the original \\(z\\)-plane, and the boundary conditions are preserved under the transformation \\(w = T(z)\\).\nLet’s first prove the first part. Suppose \\(\\phi(u,v)\\) is harmonic in some region of the \\(w\\)-plane, meaning inside this region it satisfies Laplace’s equation with respect to \\(u\\) and \\(v\\), \\[\n\\frac{\\partial^2 \\phi}{\\partial u^2} + \\frac{\\partial^2 \\phi}{\\partial v^2} = 0 \\ .\n\\] Since \\(\\phi(u,v)\\) is harmonic, it must be the real part of some analytic function \\(F(w) = \\phi(u,v) + i\\psi(u,v)\\) in the \\(w\\)-plane. And since the composition of analytic functions is also analytic, then the function \\[\nF(T(z)) = \\phi\\big(u(x,y), v(x,y)\\big) + i \\psi\\big(u(x,y), v(x,y)\\big)\n\\] must also be analytic in some region of the \\(z\\)-plane. In particular, this means the function \\(\\phi(x,y) = \\phi\\big(u(x,y), v(x,y)\\big)\\) must also be harmonic in this region of the \\(z\\)-plane, hence satisfying Laplace’s equation with respect to \\(x\\) and \\(y\\), \\[\n\\frac{\\partial^2 \\phi}{\\partial x^2} + \\frac{\\partial^2 \\phi}{\\partial y^2} = 0 \\ .\n\\] We’ll now prove the second part, namely that conformal mappings preserve the boundary conditions. We’ll focus on the usual cases where we have Dirichlet or Neumann boundary conditions. The mixed boundary condition case follows from these.\nSuppose \\(\\mathcal{C}_z\\) is some smooth curve in the \\(z\\)-plane that under the conformal mapping \\(w=T(z)\\) maps to another smooth curve \\(\\mathcal{C}_w\\) in the \\(w\\)-plane. Suppose first that \\(\\phi(u,v) = \\phi_0\\) is constant along the curve \\(\\mathcal{C}_w\\) in the \\(w\\)-plane. Clearly then, we have \\[\n\\phi(x,y) = \\phi\\big(u(x,y), v(x,y)\\big) = \\phi_0 \\ .\n\\] That is, \\(\\phi(x,y)\\) will also be constant along the curve \\(\\mathcal{C}_z\\) in the \\(z\\)-plane. This proves that Dirichlet boundary conditions are preserved under a conformal mapping.\nSuppose next that \\(\\partial \\phi / \\partial n_w = 0\\) along the curve \\(\\mathcal{C}_w\\) in the \\(w\\)-plane, where \\(\\mathbf{n}_w\\) is the normal vector to this curve. Since \\[\n\\frac{\\partial \\phi}{\\partial n_w} = \\nabla \\phi(u,v) \\cdot \\mathbf{n}_w = 0 \\ ,\n\\] this can only be true if the curve \\(\\mathcal{C}_w\\) is perpendicular to the level curves of \\(\\phi(u,v)\\) in the \\(w\\)-plane. However, the level curves of \\(\\phi(u,v)\\) are the same as the level curves of \\(\\phi(x,y) = \\phi\\big(u(x,y), v(x,y)\\big)\\), since constants get mapped to constants under the conformal mapping. This means in the \\(z\\)-plane that the level curves of \\(\\phi(x,y)\\) will again be perpendicular to the curve \\(\\mathcal{C}_z\\). That is, if \\(\\mathbf{n}_z\\) is the normal vector to the curve \\(\\mathcal{C}_z\\) we must have \\[\n\\frac{\\partial \\phi}{\\partial n_z} = \\nabla \\phi\\big(u(x,y), v(x,y)\\big) \\cdot \\mathbf{n}_z = 0 \\ .\n\\] This proves that Neumann boundary conditions are preserved under a conformal mapping. By combining these results together, it’s possible to show that mixed boundary conditions are also preserved under conformal mappings.\n\n\nBoundary Value Problems\nThe results of the previous section mean that, given some conformal mapping, we essentially have a duality between BVPs in the \\(xy\\)-plane and BVPs in the \\(uv\\)-plane. If we can somehow find such a conformal mapping that simplifies the problem so that it’s much easier to solve in the new space using any of the techniques we’ve covered so far, we can map it back to get the potential that solves the original BVP.\nOf course, the challenging part is finding a conformal mapping \\(w = T(z)\\) that simplifies the given problem. There’s an art to this, involving looking at the geometry of the original problem and using that to identify a good transformation that makes the problem easier to solve in a new space. This is best shown by example.\nLet’s start with a BVP we’ve already seen before so we can see that the method of conformal mappings gives the same answer for the potential as other methods do.\n\nExample:",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Boundary Value Problems III</span>"
    ]
  },
  {
    "objectID": "electrodynamics/bvps-3.html#multipole-expansion",
    "href": "electrodynamics/bvps-3.html#multipole-expansion",
    "title": "Boundary Value Problems III",
    "section": "Multipole Expansion",
    "text": "Multipole Expansion\nWe will now turn our attention away from boundary value problems and consider again the problem of a localized charge distribution sitting somewhere in space, free of boundary surfaces like conductors or whatever. We know that in this setting we can formally express the potential as an integral \\[\n\\phi(\\mathbf{x}) = \\int d^3\\mathbf{x}' \\frac{\\rho(\\mathbf{x}')}{|\\mathbf{x} - \\mathbf{x}'|} \\ .\n\\] The hard part is actually solving this integral for a general charge distribution \\(\\rho(\\mathbf{x}')\\). It would be nice then if we could find a systematic way to approximate the potential as a series in inverse powers of the distance of the field point from the charge distribution. Provided we can find such an expansion, we can often find a good approximate solution when we’re far away from the source charges by considering the first few expansion terms. This is called the multipole expansion.\n\nBasic Expansion\nBased on intuition and past examples, we expect that very far away from the charge distribution the potential should be approximately that of a point charge, falling off like \\(1/r\\) when \\(r \\gg r'\\). But we’ve also seen potentials that fall off like \\(1/r^2\\) as well. In fact, we can find charge distributions with potentials that fall off like \\(1/r^n\\) for any positive integer \\(n\\).\nSince only the only part of the integrand that depends on the field point \\(\\mathbf{x}\\) is the Green’s function \\(1/|\\mathbf{x} - \\mathbf{x}'|\\), it suffices to find an expression of the Green’s function in powers of \\(1/r\\). Provided we can do this, we can plug the expansion back into the above integral and get an expansion for the potential in powers of \\(1/r\\).\nSuppose \\(\\alpha\\) is the angle between the vectors \\(\\mathbf{x}\\) and \\(\\mathbf{x}'\\), i.e. \\(\\mathbf{x} \\cdot \\mathbf{x}' = rr' \\cos \\alpha\\). We can then rewrite the Green’s function as \\[\n\\frac{1}{|\\mathbf{x} - \\mathbf{x}'|} = \\frac{1}{\\sqrt{r^2 + r'^2 - 2 rr' \\cos\\alpha}} = \\frac{1}{r} \\frac{1}{\\sqrt{1 + \\varepsilon^2 - 2 \\varepsilon \\cos\\alpha}} \\ .\n\\] Now, let \\(\\varepsilon \\equiv r'/r\\). We expect \\(\\varepsilon\\) to be small in the far field limit \\(r \\gg r'\\), which means it suffices to look at only the first few expansion terms. We can then do a binomial expansion of the Green’s function in powers of \\(\\varepsilon^2 - 2 \\varepsilon \\cos\\alpha\\) to get \\[\n\\frac{1}{|\\mathbf{x} - \\mathbf{x}'|} = \\frac{1}{r} \\bigg[1 - \\frac{1}{2} (\\varepsilon^2 - 2\\varepsilon \\cos\\alpha) + \\frac{3}{8} (\\varepsilon^2 - 2\\varepsilon \\cos\\alpha)^2 - \\frac{5}{16} (\\varepsilon^2 - 2\\varepsilon \\cos\\alpha)^3 + \\cdots \\bigg] \\ .\n\\] Collecting terms in powers of \\(\\varepsilon\\) and substituting back in \\(\\varepsilon = r'/r\\) we then get \\[\n\\frac{1}{|\\mathbf{x} - \\mathbf{x}'|} = \\frac{1}{r} + \\cos\\alpha \\frac{r'}{r^2} + \\frac{1}{2} (3 \\cos^2\\alpha - 1) \\frac{r'^2}{r^3} + \\cdots \\ .\n\\] Finally, plugging this expansion of the Green’s function back into the potential, we get \\[\n\\phi(\\mathbf{x}) = \\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') \\bigg[\\frac{1}{r} + \\cos\\alpha \\frac{r'}{r^2} + \\frac{1}{2} (3 \\cos^2\\alpha - 1) \\frac{r'^2}{r^3} + \\cdots\\bigg] \\ .\n\\] This is the basic multipole expansion of the potential in powers of \\(1/r\\). For reasons we’ll explain below, we define \\[\n\\begin{align*}\nq &\\equiv \\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') \\ , \\\\\n\\mathbf{p} &\\equiv \\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') \\mathbf{x}' \\ , \\\\\n\\mathbf{Q} &= \\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') \\bigg[3 \\mathbf{x}' \\otimes \\mathbf{x}' - r'^2 \\mathbf{1}\\bigg] \\ .\n\\end{align*}\n\\] The first quantity \\(q\\) is clearly a scalar. The second quantity \\(\\mathbf{p}\\) is evidently a vector. The last quantity \\(\\mathbf{Q}\\) is a rank-2 tensor, which we’ll show below. The integrand contains an outer product of \\(\\mathbf{x}'\\) with itself, along with a term proportional to the rank-2 identity tensor \\(\\mathbf{1}\\). Each of these quantities are called multipole moments. We’ll explain each these moments in much more detail below.\nIf we substitute these quantities in and do some algebra, we can rewrite the basic multipole expansion above in the form \\[\n\\phi(\\mathbf{x}) = \\frac{q}{r} + \\frac{\\mathbf{p} \\cdot \\mathbf{e}_r}{r^2} + \\frac{\\mathbf{e}_r \\cdot \\mathbf{Q} \\cdot \\mathbf{e}_r}{2r^3} + \\cdots \\ .\n\\] Or equivalently, by substituting in \\(\\mathbf{e}_r = \\mathbf{x}/r\\) we can write \\[\n\\boxed{\n\\phi(\\mathbf{x}) = \\frac{q}{r} + \\frac{\\mathbf{p} \\cdot \\mathbf{x}}{r^3} + \\frac{\\mathbf{x} \\cdot \\mathbf{Q} \\cdot \\mathbf{x}}{2r^5} + \\cdots\n} \\ .\n\\] Notice that all of the dependence on the source charge distribution is evidently contained in the multipole moments, leaving explicit any terms that depend on the field point. We’ll derive the more general multipole expansion later in this chapter.\n\nMonopole Moment\nSubstituting in the definition for the first multipole moment \\(q\\), we can write the first term in the multipole expansion as \\[\n\\phi_0(\\mathbf{x}) = \\frac{1}{r} \\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') = \\frac{q}{r} \\ .\n\\] We call this first term in the expansion the monopole potential. Clearly it falls off like \\(1/r\\). The multipole moment \\(q\\) is called the monopole moment. By definition, the monopole moment is just the total net charge of the source charge distribution, \\[\nq \\equiv \\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') \\ .\n\\] Thus, the first term in the expansion is just \\(q/r\\). This is exactly what we’d expect. Since the electric field is always given by \\(\\mathbf{E} = -\\nabla \\phi\\), the electric field of the monopole potential will be given by Coulomb’s Law, with \\[\n\\mathbf{E}_0(\\mathbf{x}) = \\frac{q}{r^2} \\mathbf{e}_r \\ .\n\\] The field lines for the monopole look exactly as we’d expect. We show a plot of these field lines below to compare with the field lines of the higher order multipole terms in the next few sections. As usual, the field lines are assume to point outward for a positive point charge, and inward for a negative point charge.\n\n\n\n\n\nSince this is the first term in the multipole expansion, we should expect that very far away from the charge distribution, the potential should approximate the of a point charge with total net charge \\(q\\). Of course, this is only true provided the net charge isn’t zero. If it is, we have to proceed to the next term in the multipole expansion, the dipole term.\nBefore proceeding to the next term, notice something trivial. The monopole moment \\(q\\) does not depend on the choice of coordinate system since it’s a scalar. If we rotate or translate the coordinate system the monopole moment remains the same, and so too does the monopole potential.\n\n\nDipole Moment\nSubstituting in the definition for the second multipole moment \\(\\mathbf{p}\\), we can write the second term in the multipole expansion as \\[\n\\phi_1(\\mathbf{x}) = \\frac{1}{r^2} \\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') \\cos\\alpha r' = \\frac{\\mathbf{p} \\cdot \\mathbf{e}_r}{r^2} = \\frac{\\mathbf{p} \\cdot \\mathbf{x}}{r^3} \\ .\n\\] In making this substitution we just used the fact that \\(\\mathbf{x} \\cdot \\mathbf{x}' = rr' \\cos \\alpha\\) to replace the \\(\\cos\\alpha\\) term in the integrand, which lets us pull out a factor of \\(\\mathbf{x}/r\\) from the integrand since the integral is over \\(\\mathbf{x}'\\).\nWe call this expansion term the dipole potential. This potential clearly falls off like \\(1/r^2\\). What remains is the multipole moment \\(\\mathbf{p}\\), which encapsulates all of the information about the charge distribution. We call this moment the dipole moment, \\[\n\\mathbf{p} \\equiv \\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') \\mathbf{x}' \\ .\n\\] So why do we call this the dipole moment? We’ve seen the dipole before, or more correctly the physical dipole. To recall, suppose we have two opposite point charges \\(q\\) and \\(-q\\) separated from each other by a distance \\(d\\). We’ll suppose the charges lie along the \\(z\\)-axis with \\(q\\) at position \\(\\mathbf{x}_+ = d/2 \\mathbf{e}_z\\) and \\(-q\\) at position \\(\\mathbf{x}_- = -d/2 \\mathbf{e}_z\\).\nWe can then use the superposition principle to express the potential of the physical dipole as \\[\n\\phi(\\mathbf{x}) = \\frac{q}{|\\mathbf{x} - d/2 \\mathbf{e}_z|} - \\frac{q}{|\\mathbf{x} + d/2 \\mathbf{e}_z|} \\ .\n\\] Rewriting the denominators in Cartesian coordinates, we can then write \\[\n\\phi(\\mathbf{x}) = \\frac{q}{\\sqrt{x^2 + y^2 + (z-d/2)^2}} - \\frac{q}{\\sqrt{x^2 + y^2 + (z+d/2)^2}} \\ .\n\\] Here is a plot of what the field lines look like for the physical dipole, with \\(+q\\) shown in red and \\(-q\\) in blue. As always, the field lines go from positive charges to negative charges, and the equipotential curves are tangent to the field lines.\n\n\n\n\n\nThis is the exact expression for the potential of the physical dipole. Clearly it doesn’t look at all like the expression for the dipole potential though. In fact, the dipole potential is just an approximation of the physical dipole potential in the far field limit. To see this, suppose we’re far away from the two charges, so that \\(r \\gg d\\). Then we can do a binomial expansion of the roots to write $$ \\[\\begin{align*}\n\\phi(\\mathbf{x}) &= q \\bigg[\\big(x^2 + y^2 + (z-d/2)^2\\big)^{-1/2} - \\big(x^2 + y^2 + (z+d/2)^2\\big)^{-1/2}\\bigg] \\\\\n&\\approx \\frac{q}{r} \\bigg[\\big(1-dz/r\\big)^{-1/2} - \\big(1+dz/r\\big)^{-1/2}\\bigg] \\\\\n&\\approx \\frac{q}{r} \\big[(1 + dz/2r) - (1 - dz/2r)\\big] \\\\\n&\\approx \\frac{qdz}{r^2} \\ .\n\n\\end{align*}\\] \\[\nWe now have a potential that falls off like $1/r^2$. If we define $\\mathbf{p} = qd \\mathbf{e}_z$, in the far field limit we can express this potential as\n\\] () _1() =  , $$ which is of course the dipole potential. Note it’s conventional to define a vector \\(\\mathbf{d} = d\\mathbf{e}_z\\) and write the dipole moment for the physical dipole as \\(\\mathbf{p} = q \\mathbf{d}\\). With this definition we can orient the charges along any axis \\(\\mathbf{d}\\) we like and the expression for this potential won’t change.\nWe can model the behavior of the physical dipole in the far field limit in a slightly different way by considering an idealized physical dipole where we let \\(d \\to 0\\) while keeping \\(qd\\) finite. This pushes the charges right on top of each other, giving an identical result to the far field dipole potential above. We call this idealized configuration the pure dipole.\nHere is a plot of what the field lines of a pure dipole look like. Since the charges are right on top of each other in this case we show them both in red. Notice that these look just like the field lines of the physical dipole when far away from the charges. However, the field lines do look different near the charges, since all the higher order terms in the physical dipole potential identically vanish for the pure dipole potential.\n\n\n\n\n\nThe physical dipole helps us assign meaning to what exactly the dipole moment and dipole potential represent. We can think of the dipole moment as representing the charge polarization of the source charge distribution \\(\\rho(\\mathbf{x}')\\) along some axis \\(\\mathbf{d}\\). To understand why this is true, suppose \\(\\rho(\\mathbf{x}')\\) consists of \\(N\\) discrete point charges \\(q_i\\) located at positions \\(\\mathbf{x}_i\\). Then \\[\n\\rho(\\mathbf{x}') = \\sum_{i=1}^N q_i \\delta(\\mathbf{x}' - \\mathbf{x}_i) \\ .\n\\] We will now separate this sum into two sums, one for all the positive charges \\(q_i^+\\) and one for all the negative charges \\(-q_i^-\\), \\[\n\\rho(\\mathbf{x}') = \\rho_+(\\mathbf{x}') + \\rho_-(\\mathbf{x}') = \\bigg(\\sum_{i=1}^{N_+} q_i^+ \\delta(\\mathbf{x}' - \\mathbf{x}_i^+)\\bigg) - \\bigg(\\sum_{i=1}^{N_-} q_i^- \\delta(\\mathbf{x}' - \\mathbf{x}_i^-)\\bigg) \\ ,\n\\] where \\(N_+\\) is the number of positive charges and \\(N_-\\) is the number of negative charges, so that \\(N = N_+ + N_-\\).\nNow, each of these two distributions will have its own center of charge \\(\\mathbf{x}_\\pm\\) given by \\[\n\\mathbf{x}_\\pm = \\sum_{i=1}^{N_\\pm} \\frac{-q_i^+}{-q_\\pm} \\mathbf{x}_i^\\pm \\ ,\n\\] where \\(q_\\pm = \\sum q_i^\\pm\\) is the total charge of each distribution. On average then, the total positive and negative charges \\(q_\\pm\\) will be separated by some distance \\(d = |\\mathbf{d}|\\), where \\(\\mathbf{d} = \\mathbf{x}_+ - \\mathbf{x}_-\\). We can model this behavior with a physical dipole with a positive charge \\(q_+\\) and a negative charge \\(-q_-\\) separated by a distance \\(d\\) along the \\(\\mathbf{d}\\)-axis. In the far field limit \\(r \\gg d\\), we get a dipole moment that can be expressed in the form \\[\n\\mathbf{p} = q_+ \\mathbf{x}_+ - q_- \\mathbf{x}_- \\ .\n\\] Notice that in the special case \\(q_+ = q_-\\), we can simplify this further to get \\(\\mathbf{p} = q_+ \\mathbf{d}\\), which is the expression we had above. In this sense then, the dipole moment represents the average charge polarization of charges in a charge distribution.\nFIGURE (sketch the dipole situation for a general charge distribution, showing the polarizations)\nAs we did with the monopole moment, it’s worth asking how the dipole moment behaves under a change of coordinates. Evidently, the dipole moment \\(\\mathbf{p}\\) is a vector, which means under rotations it must transform as a vector does. But what about under translations? Suppose we shifted the origin of the coordinate system by some vector \\(\\mathbf{a}\\). Then under this transformation, the new dipole moment \\(\\mathbf{p}'\\) is evidently related to the original dipole moment \\(\\mathbf{p}\\) by \\[\n\\mathbf{p}' \\equiv \\int d^3\\mathbf{x} \\ \\rho(\\mathbf{x}) (\\mathbf{x} - \\mathbf{a}) = \\int d^3\\mathbf{x} \\ \\rho(\\mathbf{x}) \\mathbf{x} - \\mathbf{a} \\int d^3\\mathbf{x} \\ \\rho(\\mathbf{x}) = \\mathbf{p} - q\\mathbf{a} \\ .\n\\] That is, under a translation of coordinates, the dipole shifts by a constant amount \\(q\\mathbf{a}\\) that depends on the total net charge \\(q\\). In the special case the net charge is zero this term is zero and \\(\\mathbf{p}' = \\mathbf{p}\\). It’s only in that special case that the dipole moment remains invariant under a translation of coordinates.\nLet’s go ahead and write down the electric field due to the dipole potential. By writing \\(\\mathbf{E} = -\\nabla \\phi\\) in index notation and plugging in the dipole potential above, while keeping in mind that \\(\\mathbf{p}\\) doesn’t depend on \\(\\mathbf{x}\\), one can show that the electric field is \\[\n\\boxed{\n\\mathbf{E}_1(\\mathbf{x}) = \\frac{3(\\mathbf{p} \\cdot \\mathbf{x}) \\mathbf{x}}{r^5} - \\frac{\\mathbf{p}}{r^3}\n} \\ .\n\\] Notice that, while the dipole potential falls off like \\(1/r^2\\) that, the dipole field falls off like \\(1/r^3\\), as we’d expect.\nLet’s now work an example that involves calculating the dipole moment and potential for some general charge distribution.\n\nExample: Dipole moment of a spherical shell with an azimuthally symmetric charge distribution\nConsider a hollow spherical shell of radius \\(R\\), but instead of having uniform charge density, we have a polar-dependent surface charge density of the form \\(\\sigma' = k \\cos\\theta'\\). We’d like to find the dipole moment and potential associated with this distribution.\nFirst, notice that this distribution has no net charge, since the monopole moment is \\[\nq = \\int da' \\ \\sigma' = 2\\pi R^2 k \\int_0^\\pi d\\theta' \\ \\cos\\theta' = 0 \\ .\n\\] This means the first term in the multipole expansion must be at least a dipole potential. Let’s now calculate the dipole moment. Notice first that the charge density is azimuthally symmetric about the \\(z\\)-axis. This means the dipole potential must point along the \\(z\\)-direction, with \\(\\mathbf{p} = p_z \\mathbf{e}_z\\). It thus suffices to calculate only the \\(p_z\\) component of the dipole moment. We have \\[\np_z = \\int da' \\ \\sigma' z' = \\int_0^\\pi R^2 \\sin\\theta' d\\theta' \\ k R \\cos^2\\theta' = \\frac{4\\pi}{3} k R^3 \\ .\n\\] With the dipole moment in hand we can now calculate the dipole potential. Evidently, we have \\[\n\\phi_1(\\mathbf{x}) = \\frac{\\mathbf{p} \\cdot \\mathbf{x}}{r^3} = \\frac{p_z \\cos\\theta}{r^2} = \\frac{4\\pi}{3} kR \\cos\\theta \\bigg(\\frac{R}{r}\\bigg)^2 \\ .\n\\] Since there is no monopole moment, this means in the far field limit the full potential can be approximated by \\[\n\\phi(\\mathbf{x}) \\approx \\frac{4\\pi}{3} kR \\cos\\theta \\bigg(\\frac{R}{r}\\bigg)^2 \\ .\n\\] In fact, this is the exact potential for this charge distribution. We actually calculated it in the last chapter using separation of variables in spherical coordinates. This means that this charge distribution is already exactly a pure dipole.\nWe can calculate the associated electric field as well. We have \\[\n\\mathbf{E}(\\mathbf{x}) = \\frac{3(\\mathbf{p} \\cdot \\mathbf{e}_r) \\mathbf{e}_r}{r^3} - \\frac{\\mathbf{p}} {r^3} = \\frac{4\\pi}{3} k \\bigg(\\frac{R}{r}\\bigg)^3 \\bigg(3\\cos\\theta \\mathbf{e}_r - \\mathbf{e}_z\\bigg) \\ .\n\\] As expected, the electric field falls off like \\(1/r^3\\), with field lines coming out from the top of the sphere (which we can think of as a \\(+q\\) charge, and going into the bottom of the sphere (which we can think of as a \\(-q\\) charge).\nFIGURE (sketch the field lines of this sphere, showing it looks like a dipole)\n\n\n\nQuadrupole Moment\nFinally, let’s look at the quadratic term in the multipole expansion, which can be written \\[\n\\phi_2(\\mathbf{x}) \\equiv \\frac{1}{2r^3} \\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') (3 \\cos^2\\alpha - 1) r'^2 \\ .\n\\] This term in the multipole expansion is called the quadrupole potential. Recall above that we also defined the multipole moment \\[\n\\mathbf{Q} = \\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') \\bigg[3 \\mathbf{x}' \\otimes \\mathbf{x}' - r'^2 \\mathbf{1}\\bigg] \\ .\n\\] We call this multipole moment the quadrupole moment or the quadrupole tensor.\nWe’d like to rewrite the quadrupole potential to show its explicit dependence on the quadrupole moment. To do that, we’ll rewrite the quadrupole moment in index notation. In index notation the outer product \\(\\mathbf{x}' \\otimes \\mathbf{x}'\\) can be written \\(x_i' x_j'\\) and the identity tensor \\(\\mathbf{1}\\) can be written \\(\\delta_{ij}\\). We thus have \\[\nQ_{ij} \\equiv \\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') \\bigg[3 x_i' x_j' - r'^2 \\delta_{ij}\\bigg] \\ .\n\\] Now, let’s look again at the potential. Observe if we substitute \\(\\mathbf{x} \\cdot \\mathbf{x}' = rr' \\cos \\alpha\\) we can write the quadrupole potential as \\[\n\\phi_2(\\mathbf{x}) = \\frac{1}{2r^3} \\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') \\bigg[3 \\bigg(\\frac{\\mathbf{x} \\cdot \\mathbf{x}'}{r}\\bigg)^2 - r'^2\\bigg] \\ .\n\\] We’ll go ahead and rewrite this potential in index notation as well, \\[\n\\phi_2(\\mathbf{x}) = \\frac{1}{2r^3} \\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') \\bigg[3 \\frac{(x_i x'_i) (x_j x_j')}{r^2} - r'^2\\bigg] \\ .\n\\] We want the pull all dependence on \\(\\mathbf{x}\\) out of the integrand. We can do this be factoring \\(x_i x_j\\) out of the first term, but if we do that we need to insert a \\(\\delta_{ij}\\) into the second term. We then have \\[\n\\phi_2(\\mathbf{x}) = \\frac{x_i x_j}{2r^5} \\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') \\bigg[3 x_i' x_j' - r'^2 \\delta_{ij}\\bigg] \\ .\n\\] Notice now that the remaining integral is just the \\(Q_{ij}\\) component of the quadrupole moment. We thus have \\[\n\\phi_2(\\mathbf{x}) = \\frac{Q_{ij} x_i x_j}{2r^5} \\ .\n\\] This is the usual way the quadrupole potential is written. We can also write it in abstract form by observing that \\(Q_{ij} x_i x_j\\) is just the quadratic form \\(\\mathbf{x} \\cdot \\mathbf{Q} \\cdot \\mathbf{x}\\), that is, the inner product of \\(\\mathbf{x}\\) with the vector \\(\\mathbf{Q} \\cdot \\mathbf{x}\\). We can thus also write \\[\n\\phi_2(\\mathbf{x}) =\\frac{\\mathbf{x} \\cdot \\mathbf{Q} \\cdot \\mathbf{x}}{2r^5} \\ .\n\\] With the quadrupole potential re-expressed in terms of the quadrupole moment, we’ve completed our derivation of the basic multipole expansion above up to the quadrupole term, \\[\n\\phi(\\mathbf{x}) = \\frac{q}{r} + \\frac{\\mathbf{p} \\cdot \\mathbf{x}}{r^3} + \\frac{\\mathbf{x} \\cdot \\mathbf{Q} \\cdot \\mathbf{x}}{2r^5} + \\cdots \\ .\n\\] Let’s now say a bit about the properties of the quadrupole moment and what it represents physically. As we already mentioned, the quadrupole moment is indeed a rank-2 tensor. That is, it transforms as a rank-2 tensor under coordinate transformations, \\[\nQ_{i'j'} = \\frac{\\partial x_{i'}}{\\partial x_i} \\frac{\\partial x_{j'}}{\\partial x_j} Q_{ij} \\ .\n\\] Indeed, this follows immediately from the fact that both the outer product and the identity tensor are valid rank-2 tensors, which means any linear superposition of them is also a rank-2 tensor.\nIt’s also easy to see that the quadrupole moment is symmetric, meaning \\(Q_{ij} = Q_{ji}\\). This also follows from the fact that the outer product of a vector with itself is symmetric, and the identity tensor is clearly also symmetric. Perhaps less intuitive though, the quadrupole moment is also traceless, meaning \\(Q_{ii} = 0\\) when summed over \\(i\\). To see why, observe that \\[\nQ_{ii} = \\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') \\bigg[3 x_i' x_i' - r'^2 \\delta_{ii}\\bigg] = \\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') \\bigg[3 r'^2 - 3 r'^2\\bigg] = 0 \\ .\n\\] Here, we used the fact that \\(x_i' x_i'\\) is just the inner product \\(r'^2 = \\mathbf{x}' \\cdot \\mathbf{x}'\\), along with the fact that the trace of the identity is \\(\\delta_{ii} = 3\\) in three dimensions. We’ve thus shown that the quadrupole moment is a symmetric, traceless tensor of rank-2. Such a tensor is usually called an irreducible tensor. These conditions imply that the quadrupole moment only has \\(3^2 - 3 - 1 = 5\\) independent components, since \\(3\\) terms in a \\(3 \\times 3\\) symmetric matrix are redundant due to the \\(Q_{ij} = Q_{ji}\\) requirement, and tracelessness implies that one of the terms in the diagonal depends on the rest, for instance \\(Q_{zz} = -Q_{xx}-Q_{yy}\\).\nAs with many rank-2 tensors, it’s common to express the components of the quadrupole moment as a matrix. If we enforce the redundancy requirements above for instance, we can write the quadrupole moment in matrix form as \\[\n\\mathbf{Q} = \\begin{pmatrix}\nQ_{xx} & Q_{xy} & Q_{xz} \\\\\nQ_{xy} & Q_{yy} & Q_{yz} \\\\\nQ_{xz} & Q_{yz} & -Q_{xx} - Q_{yy}\n\\end{pmatrix} \\ .\n\\] So what does the quadrupole moment represent physically? As we did with the dipole moment, we’ll consider a simple charge configuration, and show that in a certain limit its potential becomes the quadrupole potential. Consider then a configuration of point charges consisting of two oppositely oriented but parallel physical dipoles. We assume the charges inside each dipole is separated by a distance \\(d\\), and that the charge on each dipole is separated by the charge on the opposite dipole by the same distance \\(d\\). This will lead to a configuration of four opposite point charges \\(\\pm q\\) arranged as shown below.\nFIGURE\nWe call this configuration of charges the physical quadrupole. First, notice that the physical quadrupole has no net charge, since all the charges sum to zero. Second, notice it also has no net dipole moment, since it consists of two opposite dipole moments \\(\\pm q\\mathbf{d}\\), which cancel each other when added together. These together evidently imply that whatever terms remain in the potential must fall off at least like \\(1/r^3\\) in the limit \\(d \\ll r\\).\nWe can write down the exact potential for the physical quadrupole using the principle of superposition. We have \\[\n\\phi(\\mathbf{x}) = \\frac{q}{|\\mathbf{x} - d/2 (\\mathbf{e}_y + \\mathbf{e}_z)|} - \\frac{q}{|\\mathbf{x} - d/2 (\\mathbf{e}_y - \\mathbf{e}_z)|} + \\frac{q}{|\\mathbf{x} + d/2 (\\mathbf{e}_y + \\mathbf{e}_z)|} - \\frac{q}{|\\mathbf{x} - d/2 (\\mathbf{e}_z - \\mathbf{e}_y)|} \\ .\n\\] Written out in Cartesian components, this becomes \\[\n\\begin{align*}\n\\phi(\\mathbf{x}) &= \\frac{q}{\\sqrt{x^2 + (y-d/2)^2 + (z-d/2)^2}} - \\frac{q}{\\sqrt{x^2 + (y-d/2)^2 + (z+d/2)^2}} \\\\\n&- \\frac{q}{\\sqrt{x^2 + (y+d/2)^2 + (z-d/2)^2}} + \\frac{q}{\\sqrt{x^2 + (y+d/2)^2 + (z+d/2)^2}} \\ .\n\\end{align*}\n\\] Here is a plot of what the field lines look like for the physical quadrupole. Again, the positive charges are shown in red, and the negative charges in blue. As usual, the equipotentials curves are tangential to the field lines.\n\n\n\n\n\nWe can again proceed as we did with the physical dipole and take a binomial expansion of the roots when \\(d \\ll r\\). The end result of all the algebra is that in the far field limit we can approximate the potential of the physical quadrupole as \\[\n\\phi(\\mathbf{x}) \\approx \\frac{3qd^2 yz}{r^5} \\ .\n\\] Evidently, in the far field limit the potential of the physical quadrupole goes like \\(1/r^3\\), which suggests the lowest expansion term of this potential is a quadrupole potential. However, since this approximation depends on \\(yz\\), it appears that only the \\(Q_{yz}\\) and \\(Q_{zy}\\) components of the quadrupole moment appear to contribute anything to the potential. We can see this by writing \\[\n\\phi(\\mathbf{x}) \\approx \\frac{3d^2 yz}{r^5} = \\frac{Q_{yz} yz}{2r^5} + \\frac{Q_{zy} zy}{2r^5} \\ .\n\\] Evidently, we have \\(Q_{yz} = Q_{zy} = 3qd^2\\). The remaining components of \\(\\mathbf{Q}\\) all vanish, leaving us with the quadrupole matrix \\[\n\\mathbf{Q} = 3 qd^2\\begin{pmatrix}\n0 & 0 & 0 \\\\\n0 & 0 & 1 \\\\\n0 & 1 & 0\n\\end{pmatrix} \\ .\n\\] Just as we did with the physical dipole, we can model the behavior of the physical quadrupole in the far field limit by considering an idealized physical quadrupole where we let \\(d \\to 0\\) while keeping \\(qd\\) finite. This will give a potential completely equivalent to that of the physical quadrupole in the far field limit, since the higher order multipole terms all vanish. We call this ideal version of the physical quadrupole the pure quadrupole. The potential of the pure quadrupole is exactly the quadrupole potential.\nTo find the electric field associated to the quadrupole term we can differentiate it in the usual way. By writing the potential in index notation, one can show the components of the quadrupole field are given by \\[\nE_k(\\mathbf{x}) = - \\frac{Q_{ik} x_k}{r^5} + \\frac{5 Q_{ij} x_i x_j x_k}{2r^7} \\ .\n\\] As expected, the quadrupole field falls off like \\(1/r^4\\). To write this expression in vector notation, we can use the fact that the quadrupole tensor is symmetric to write \\[\n\\boxed{\n\\mathbf{E}_2(\\mathbf{x}) = - \\frac{\\mathbf{Q} \\cdot \\mathbf{x}}{r^5} + \\frac{5 (\\mathbf{x} \\cdot \\mathbf{Q} \\cdot \\mathbf{x}) \\mathbf{x}}{r^7}\n} \\ .\n\\] Below is a plot of the field lines of the pure quadrupole, with the charges shown all in red. Notice that these field lines agree with those of the physical quadrupole in the far field limit, but differ close to the charges due to the lack of higher order moments. The density of field lines indicate the strength of the field at a given point. Near the charges the field lines are extremely strong compared to farther away, due to the fact that the quadrupole field falls off very rapidly, as \\(1/r^4\\).\n\n\n\n\n\nJust as the physical dipole suggested something about what the dipole moment physically represents, the physical quadrupole suggests something about what the quadrupole moment physically represents. Observe that for the physical quadrupole the moment is proportional to \\(qd^2\\). This dependence on \\(d^2\\) suggests that the quadrupole moment says something about the spread of a charge distribution. The higher \\(d\\) is, the more diffused the charge distribution is. The lower \\(d\\) is, the more bunched up the distribution is.\nThe quadrupole moment says something about slightly more than the spread of the charge distribution though. To see this, consider the uniformly charged sphere. If the quadrupole moment were really just the spread, we’d expect that a sphere of radius \\(R\\) would have a quadrupole moment proportional to \\(R^2\\). But as we’ll see it’s zero.\nTo see why, notice that by symmetry, the diagonal components must all be equal, with \\(Q_{xx} = Q_{yy} = Q_{zz}\\), and the off diagonal components must also all be equal, with \\(Q_{xy} = Q_{xz} = Q_{yz}\\). Since the trace of \\(\\mathbf{Q}\\) must vanish, the only way the diagonal components can all be equal is if they’re all zero. To show that the off diagonal components also vanish, consider \\(Q_{xy}\\). Since \\(\\rho\\) is constant for a uniformly charged sphere and \\(\\delta_{xy} = 0\\), we have \\[\nQ_{xy} = \\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') \\ [3 x' y' - r'^2 \\delta_{xy}] = 3\\rho \\int d^3\\mathbf{x}' \\ x' y' = 0 \\ .\n\\] That the last integral is zero can be shown in any number of ways, for instance by evaluating the volume integral in spherical coordinates, or noting that the integrand is odd in \\(x'\\) and \\(y'\\), which due to symmetry means the integral must vanish. We’ve thus shown that the quadrupole moment of a uniformly charged sphere is zero, regardless of its radius.\nThis means we should interpret what the quadrupole is slightly differently. It reflects not just the spread of the charge distribution, but also how anisotropic or non-spherical the charge distribution is.\nFor a general charge distribution the quadrupole moment will always be a rank-2 tensor with 5 independent components. However there is one special case where the quadrupole moment can be simplified down to a single scalar, namely whenever we have a charge distribution with azimuthal symmetry. We’ll show that for these kinds of distributions the off diagonal components of the quadrupole tensor all vanish, and the diagonal components must satisfy \\(Q_{xx} = Q_{yy} = -2Q_{zz}\\). This means we can express the quadrupole moment for an azimuthally symmetric charge distribution by a single scalar \\(Q\\), which we call the scalar quadrupole moment.\nSuppose \\(\\rho(\\mathbf{x}') = \\rho(r',\\theta')\\) is some azimuthally symmetric potential.\n\\[\nQ_{zz} = \\int \\varrho' d\\varrho' d\\varphi' dz' \\ \\rho(\\varrho', z') \\bigg[3 z'^2 - (\\varrho'^2+z'^2)\\bigg]\n\\]\n\nExample: Quadrupole moment of a ring of uniform charge\n\nFind the dipole moment/potential of an example with a non-zero dipole moment. See notes, Griffiths, maybe Jackson/Greiner.\nDo the exact same thing for the quadrupole moment. Mention the special case of axial symmetry, a setting in which we only need a scalar quadrupole moment (similar to moment of inertia).",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Boundary Value Problems III</span>"
    ]
  },
  {
    "objectID": "electrodynamics/bvps-3.html#spherical-multipole-expansion",
    "href": "electrodynamics/bvps-3.html#spherical-multipole-expansion",
    "title": "Boundary Value Problems III",
    "section": "Spherical Multipole Expansion",
    "text": "Spherical Multipole Expansion\nWe’ve now studied the first few terms of the multipole expansion in depth. In practice these are often the only terms we care about when finding an approximate expansion of the potential of some given. Nevertheless, it’s illuminating to find the general multipole expansion for all powers of \\(1/r\\), not just the first few. We will do that now.\nRecall in the previous section that we wrote the Green’s function in the following form, \\[\n\\frac{1}{|\\mathbf{x} - \\mathbf{x}'|} = \\frac{1}{r} \\frac{1}{\\sqrt{1 + (r'/r)^2 - 2 (r'/r) \\cos\\alpha}} \\ .\n\\] In that section, we then used the binomial expansion in the limit \\(r \\gg r'\\) to find an expansion of the Green’s function up to the first few terms. We’ll now do something slightly different. Recall from the appendix that we used the following generating function to define the Legendre polynomials, \\[\ng(x,t) \\equiv \\frac{1}{\\sqrt{1 + t^2 - 2xt}} = \\sum_{\\ell=0}^\\infty P_\\ell(x) t^\\ell \\ .\n\\] When expanded in a Taylor series in powers of \\(t\\), the expansion coefficients of the generating function \\(g(x,t)\\) turn out to be the ordinary Legendre polynomials \\(P_\\ell(x)\\). Indeed, this is why \\(g(x,t)\\) is called the generating function for the Legendre polynomials.\nNow, notice that this generating function looks exactly like the Green’s function, except with \\(t = r'/r\\) and \\(x = \\cos\\alpha\\). This means we immediately have an expansion of the Green’s function in powers of \\(1/r\\) given by \\[\n\\frac{1}{|\\mathbf{x} - \\mathbf{x}'|} = \\frac{1}{r} \\sum_{\\ell=0}^\\infty P_\\ell(\\cos\\alpha) \\bigg(\\frac{r'}{r}\\bigg)^\\ell \\ .\n\\] We now want to eliminate the explicit dependent on \\(\\cos\\alpha\\). We can do that by making use of the addition theorem of spherical harmonics. We proved in the appendix that we can expand \\(P_\\ell(\\cos\\alpha)\\) as a series in spherical harmonics by \\[\nP_\\ell(\\cos\\alpha) = \\frac{4\\pi}{2\\ell+1} \\sum_{m=-\\ell}^\\ell Y_{\\ell m}(\\theta,\\varphi) Y_{\\ell m}^*(\\theta',\\varphi') \\ .\n\\] If we plug this back into the Green’s function, we finally get \\[\n\\frac{1}{|\\mathbf{x} - \\mathbf{x}'|} = \\sum_{\\ell=0}^\\infty \\frac{4\\pi}{2\\ell+1} \\frac{r'^\\ell}{r^{\\ell+1}} \\sum_{m=-\\ell}^\\ell Y_{\\ell m}(\\theta,\\varphi) Y_{\\ell m}^*(\\theta',\\varphi') \\ .\n\\] Notice that this expansion is now over two indices, \\(\\ell\\) and \\(m\\). For each \\(\\ell\\) there will be \\(2\\ell+1\\) terms in the sum indexed by \\(m\\).\nIf we now plug this Green’s function expansion back into the integral formula for the potential, we get \\[\n\\phi(\\mathbf{x}) = \\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') \\sum_{\\ell=0}^\\infty \\frac{4\\pi}{2\\ell+1} \\frac{r'^\\ell}{r^{\\ell+1}} \\sum_{m=-\\ell}^\\ell Y_{\\ell m}(\\theta,\\varphi) Y_{\\ell m}^*(\\theta',\\varphi') \\ .\n\\] Now, notice that only the term \\(r'^\\ell Y_{\\ell m}^*(\\theta',\\varphi')\\) depend on the source points \\(\\mathbf{x}'\\). Terms of this form are called solid harmonics, sometimes denoted by \\(\\mathcal{Y}_{\\ell m}(r,\\theta, \\varphi) \\equiv r^\\ell Y_{\\ell m}(\\theta,\\varphi)\\). We’ll thus define a quantity \\[\nq_{\\ell m} \\equiv \\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') r'^\\ell Y_{\\ell m}^*(\\theta',\\varphi') \\ .\n\\] These quantities are the only terms in the expansion that depend on the source points. They’re called the spherical multipole moments. These moments aren’t exactly the usual multipole moments, but they’re related to them in ways we’ll show shortly. At any rate, if we substitute \\(q_{\\ell m}\\) in for this integral, we can finally write \\[\n\\phi(\\mathbf{x}) = \\sum_{\\ell=0}^\\infty \\frac{4\\pi}{2\\ell+1} \\frac{1}{r^{\\ell+1}} \\sum_{m=-\\ell}^\\ell q_{\\ell m} Y_{\\ell m}(\\theta,\\varphi) \\ .\n\\] As written, this is the most general form of the multipole expansion. We usually call the multipole expansion in this form the spherical multipole expansion since it involves an expansion in spherical coordinates.\nBefore proceeding, it’s worth briefly recalling a few properties of spherical harmonics. First, \\(Y_{\\ell m}(\\theta,\\varphi)\\) and \\(Y_{\\ell,-1m}(\\theta,\\varphi)\\) are related by the formula \\(Y_{\\ell,-m}(\\theta,\\varphi) = (-1)^m Y_{\\ell m}^*(\\theta,\\varphi)\\). This evidently implies that the moment \\(q_{\\ell m}\\) is related to the moment \\(q_{\\ell,-m}\\) by \\(q_{\\ell,-m} = (-1)^m q_{\\ell m}^*\\). The first few spherical harmonics when \\(\\ell=0,1,2\\) are given by $$ \\[\\begin{align*}\nY_{00}(\\theta,\\varphi) &= \\sqrt{\\frac{1}{4\\pi}} \\ , \\quad\n\n\\begin{cases}\nY_{1,-1}(\\theta,\\varphi) &= \\sqrt{\\frac{3}{8\\pi}} \\sin\\theta e^{-i\\varphi} \\\\\nY_{10}(\\theta,\\varphi)& = \\sqrt{\\frac{3}{4\\pi}} \\cos\\theta \\\\\nY_{11}(\\theta,\\varphi) &= -\\sqrt{\\frac{3}{8\\pi}} \\sin\\theta e^{i\\varphi} \\\\\n\\end{cases} \\ , \\quad\n\n\\begin{cases}\nY_{2,-2}(\\theta,\\varphi) &= \\sqrt{\\frac{15}{32\\pi}} \\sin^2 \\theta e^{-2i\\varphi} \\\\\nY_{2,-1}(\\theta,\\varphi) &= \\sqrt{\\frac{15}{8\\pi}} \\sin\\theta \\cos\\theta e^{-i\\varphi} \\\\\nY_{20}(\\theta,\\varphi) &= \\sqrt{\\frac{5}{16\\pi}} (3\\cos^2 \\theta - 1) \\\\\nY_{21}(\\theta,\\varphi) &= -\\sqrt{\\frac{15}{8\\pi}} \\sin\\theta \\cos\\theta e^{i\\varphi} \\\\\nY_{22}(\\theta,\\varphi) &= \\sqrt{\\frac{15}{32\\pi}} \\sin^2 \\theta e^{2i\\varphi} \\\\\n\\end{cases} \\ .\n\\end{align*}\\] \\[\nWe now want to show that the spherical multipole expansion agrees with the basic multipole expansion when $\\ell=0,1,2$. Let's proceed case by case. When $\\ell = 0$, we only have one term, $m=0$. The moment $q_{00}$ is evidently given by\n\\] q_{00} = d^3’  (’) Y_{00}^*(‘,’) = q  , \\[\nwhere $q$ is the usual monopole moment, or total net charge of the distribution. The $\\ell=0$ expansion term is then just the monopole potential,\n\\] 0() =  . \\[\nNext, when $\\ell = 1$ we have $m=-1,0,1$. The associated multipole moments are evidently then\n\\] \\[\\begin{align*}\nq_{10} &= \\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') r' Y_{10}^*(\\theta',\\varphi') = \\sqrt{\\frac{3}{4\\pi}}\\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') r' \\cos\\theta \\ , \\\\\nq_{1,\\pm1} &= \\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') r' Y_{1,\\pm 1}^*(\\theta',\\varphi') = \\mp \\sqrt{\\frac{3}{8\\pi}}\\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') r' \\sin\\theta e^{\\mp i\\varphi} \\ .\n\\end{align*}\\] \\[\nIf we write $e^{\\pm i\\varphi} = \\cos\\varphi \\pm i \\sin\\varphi$, and use the formulas to convert spherical coordinates $(r',\\theta',\\varphi')$ to Cartesian coordinates $(x',y',z')$, we get\n\\] \\[\\begin{align*}\nq_{10} &= \\sqrt{\\frac{3}{4\\pi}}\\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') r' \\cos\\theta = \\sqrt{\\frac{3}{4\\pi}}\\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') z' \\ , \\\\\nq_{1,\\pm 1} &= \\mp \\sqrt{\\frac{3}{8\\pi}} \\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') r' \\sin\\theta (\\cos\\varphi \\mp i \\sin\\varphi) = \\mp \\sqrt{\\frac{3}{8\\pi}} \\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') (x' \\mp iy') \\ .\n\\end{align*}\\] \\[\nNow, notice that the remaining terms in each integral are just the components of the dipole vector $\\mathbf{p}$, with\n\\] q{10} = p_z , q_{1,} = (p_x i p_y)  . \\[\nThen the $\\ell=1$ terms in the spherical multipole expansion are\n\\] \\[\\begin{align*}\n\\phi_1(\\mathbf{x}) &= \\frac{4\\pi}{3r^2} \\big[q_{1,-1} Y_{1,-1}(\\theta,\\varphi) + q_{10} Y_{10}(\\theta,\\varphi) + q_{11} Y_{11}(\\theta,\\varphi)\\big] \\\\\n&= \\frac{4\\pi}{3r^2} \\bigg[\\frac{3}{8\\pi} \\sin\\theta e^{-i\\varphi} (p_x + i p_y) + \\frac{3}{4\\pi} \\cos\\theta p_z + \\frac{3}{8\\pi} \\sin\\theta e^{i\\varphi} (p_x - i p_y) \\bigg] \\\\\n&= \\frac{1}{r^2} \\bigg[\\frac{1}{2} \\sin\\theta e^{-i\\varphi} (p_x + i p_y) + \\cos\\theta p_z + \\frac{1}{2} \\sin\\theta e^{i\\varphi} (p_x - i p_y)\\bigg] \\\\\n&= \\frac{1}{r^2} \\big[x p_x + y p_y + z p_z \\big] \\ .\n\\end{align*}\\] \\[\nIn the last step we again used the fact that $e^{\\pm i\\varphi} = \\cos\\varphi \\pm i \\sin\\varphi$. When this is plugged in and we simplify terms, we find that the imaginary parts all vanish. The remaining real parts then contain terms that turn out to be the Cartesian coordinates $(x,y,z)$. What remains in brackets is clearly just the dot product between $\\mathbf{x}$ and $\\mathbf{p}$. We thus have\n\\] _1() =  , $$ which is of course the dipole potential.\nFinally we’ll consider the \\(\\ell=2\\) expansion terms. In this case \\(m=-2,-1,0,1,2\\), which means there will be five terms. Using the same logic we did with the dipole term, one can show that these spherical moments can be written in the form \\[\n\\begin{align*}\nq_{20} &= \\frac{1}{2} \\sqrt{\\frac{5}{4\\pi}} Q_{33} \\ , \\\\\nq_{2,\\pm 1} &= \\mp \\frac{1}{3} \\sqrt{\\frac{15}{8\\pi}} (Q_{13} \\mp 2i Q_{23}) \\ , \\\\\nq_{2,\\pm 2} &= \\frac{1}{12} \\sqrt{\\frac{15}{2\\pi}} (Q_{11} - Q_{22} \\mp 2i Q_{12}) \\ ,\n\\end{align*}\n\\] where each \\(Q_{ij}\\) are the components of the usual quadrupole tensor \\(\\mathbf{Q}\\). By plugging these into the \\(\\ell=2\\) expansion term and simplifying as before, we eventually end up with the usual quadrupole potential, \\[\n\\phi_2(\\mathbf{x}) = \\frac{Q_{ij} x_i x_j}{2r^5} = \\frac{\\mathbf{x} \\cdot \\mathbf{Q} \\cdot \\mathbf{x}}{2 r^5} \\ .\n\\] This shows that the spherical multipole expansion agrees with the basic multipole expansion up to the quadrupole term.\n\nMention the interior multipole moments, where \\(r \\ll r'\\) instead of \\(r \\gg r'\\). Basically give the same moments with \\(r \\leftrightarrow r'\\).\nIf feeling judicious, maybe derive the general cartesian expansion using the irreducible representations of tensors",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Boundary Value Problems III</span>"
    ]
  },
  {
    "objectID": "electrodynamics/bvps-3.html#multipole-expansion-in-an-external-field",
    "href": "electrodynamics/bvps-3.html#multipole-expansion-in-an-external-field",
    "title": "Boundary Value Problems III",
    "section": "Multipole Expansion in an External Field",
    "text": "Multipole Expansion in an External Field\n\nRederive multipole expansion for a localized charge distribution in the presence of an external electric field\nSee: Notes, Greiner, Jackson",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Boundary Value Problems III</span>"
    ]
  },
  {
    "objectID": "electrodynamics/bvps-3.html#tmp",
    "href": "electrodynamics/bvps-3.html#tmp",
    "title": "Boundary Value Problems III",
    "section": "TMP",
    "text": "TMP\nThe remaining integrals in each term depend only on the source. We call these integrals the spherical multipole moments \\(q_{\\ell m}\\), \\[\nq_{\\ell m} \\equiv \\int d^3\\mathbf{x}' r'^\\ell \\rho(\\mathbf{x}') Y_{\\ell m}^*(\\theta',\\varphi') \\ .\n\\] Note that since \\(Y_{\\ell,-m}(\\theta,\\varphi) = (-1)^m Y_{\\ell,-m}^*(\\theta,\\varphi)\\), the \\(q_{\\ell m}\\) and \\(q_{\\ell,-m}\\) moments must evidently satisfy \\(q_{\\ell, -m} = (-1)^m q_{\\ell m}^*\\).\nIf we substitute these moments into the integral, we finally get the spherical multipole expansion for the potential, \\[\n\\boxed{\n\\phi(\\mathbf{x}) = \\sum_{\\ell=0}^\\infty \\sum_{m=-\\ell}^\\ell \\frac{4\\pi}{2\\ell+1} q_{\\ell m}\\frac{Y_{\\ell m}(\\theta,\\varphi)}{r^{\\ell+1}}\n} \\ .\n\\] Note that since the spherical harmonics are complex-valued, the potential becomes complex valued in this expansion.\nTo get a feel for this, let’s expand out the first few terms \\(\\ell=0,1\\). We have \\[\n\\begin{align*}\n\\phi(\\mathbf{\\mathbf{x}}) &= \\frac{4\\pi}{r} q_{00} Y_{oo}(\\theta,\\varphi) + \\frac{4\\pi}{3r^2}\\bigg[q_{1,-1}Y_{1,-1}(\\theta,\\varphi) + q_{10}Y_{10}(\\theta,\\varphi) + q_{11}Y_{11}(\\theta,\\varphi) \\bigg] + \\cdots \\\\\n&= \\frac{4\\pi}{r} q_{00} \\sqrt{\\frac{1}{4\\pi}} + \\frac{4\\pi}{3r^2}\\bigg[q_{1,-1}\\sqrt{\\frac{3}{8\\pi}} \\sin\\theta e^{-i\\varphi} + q_{10}\\sqrt{\\frac{3}{4\\pi}} \\cos\\theta - q_{11}\\sqrt{\\frac{3}{8\\pi}} \\sin\\theta e^{i\\varphi} \\bigg] + \\cdots \\\\\n&= \\frac{\\sqrt{4\\pi} q_{00}}{r} + \\sqrt{\\frac{4\\pi}{3}} \\frac{1}{r^2} \\bigg[\\frac{q_{1,-1}}{2} \\sin\\theta e^{-i\\varphi} + q_{10} \\cos\\theta - \\frac{q_{11}}{2} \\sin\\theta e^{i\\varphi} \\bigg] + \\cdots \\ .\n\\end{align*}\n\\]\n\nRead Jackson, Griffiths, Greiner before coming back to this. Feel like I’m flapping in the wind here.\n\n\\[\nq_{00} = \\sqrt{\\frac{1}{4\\pi}} \\int d^3\\mathbf{x}' \\rho(\\mathbf{x}') = \\sqrt{\\frac{1}{4\\pi}} Q \\ .\n\\]\n\\[\n\\begin{cases}\nq_{1,-1} &= \\sqrt{\\frac{3}{8\\pi}} \\int d^3\\mathbf{x}' r' \\rho(\\mathbf{x}') \\sin\\theta' e^{i\\varphi'} \\\\\nq_{10} & = \\sqrt{\\frac{3}{4\\pi}} \\int d^3\\mathbf{x}' r' \\rho(\\mathbf{x}') \\cos\\theta' \\\\\nq_{11} &= -\\sqrt{\\frac{3}{8\\pi}} \\int d^3\\mathbf{x}' r' \\rho(\\mathbf{x}') \\sin\\theta' e^{-i\\varphi'} \\\\\n\\end{cases}\n\\]\n$$ \\[\\begin{align*}\nY_{00}(\\theta,\\varphi) &= \\sqrt{\\frac{1}{4\\pi}} \\ , \\quad\n\n\\begin{cases}\nY_{1,-1}(\\theta,\\varphi) &= \\sqrt{\\frac{3}{8\\pi}} \\sin\\theta e^{-i\\varphi} \\\\\nY_{10}(\\theta,\\varphi)& = \\sqrt{\\frac{3}{4\\pi}} \\cos\\theta \\\\\nY_{11}(\\theta,\\varphi) &= -\\sqrt{\\frac{3}{8\\pi}} \\sin\\theta e^{i\\varphi} \\\\\n\\end{cases} \\ , \\quad\n\n\\begin{cases}\nY_{2,-2}(\\theta,\\varphi) &= \\sqrt{\\frac{15}{32\\pi}} \\sin^2 \\theta e^{-2i\\varphi} \\\\\nY_{2,-1}(\\theta,\\varphi) &= \\sqrt{\\frac{15}{8\\pi}} \\sin\\theta \\cos\\theta e^{-i\\varphi} \\\\\nY_{20}(\\theta,\\varphi) &= \\sqrt{\\frac{5}{16\\pi}} (3\\cos^2 \\theta - 1) \\\\\nY_{21}(\\theta,\\varphi) &= -\\sqrt{\\frac{15}{8\\pi}} \\sin\\theta \\cos\\theta e^{i\\varphi} \\\\\nY_{22}(\\theta,\\varphi) &= \\sqrt{\\frac{15}{32\\pi}} \\sin^2 \\theta e^{2i\\varphi} \\\\\n\\end{cases} \\ .\n\\end{align*}\\] $$\n\nWork out this in detail on paper first, especially the octupole term\nConsider doing as Jackson does and derive the spherical version first. Seems more natural, and avoids all the tensor stuff.\n\nOf course, each \\(P_\\ell(\\cos\\alpha)\\) depends on the angle \\(\\alpha\\), which depends on both \\(\\mathbf{x}\\) and \\(\\mathbf{x}'\\) as \\[\n\\cos\\alpha = \\frac{\\mathbf{x} \\cdot \\mathbf{x}'}{rr'} \\ .\n\\] This means we don’t yet have a clean expansion of the Green’s function in powers of \\(\\frac{1}{r}\\) yet. To rectify this issue let’s for now focus instead on the first few terms in the series. For the first few polynomials we can write them out in index notation as\n\n\\(n=0\\): \\(P_0(\\cos\\alpha) = 1\\),\n\\(n = 1\\): \\(P_1(\\cos\\alpha) = \\cos\\alpha = \\frac{x_i x_i'}{rr'}\\),\n\\(n = 2\\): \\(P_2(\\cos\\alpha) = \\frac{1}{2} (3\\cos^2\\alpha - 1) = \\frac{1}{2} \\big(3\\frac{(x_i x_i') (x_j x_j')}{r^2r'^2} - 1\\big)\\),\n\\(n = 3\\): \\(P_3(\\cos\\alpha) = \\frac{1}{2} (5\\cos^3\\alpha - 3\\cos\\alpha) = \\frac{1}{2} \\big(5\\frac{(x_i x_i') (x_j x_j') (x_k x_k')}{r^3 r'^3} - 3\\frac{x_i x_i'}{rr'}\\big)\\).\n\nAs always, any repeated index in a term is assumed to be summed over. If we plug these back into the Green’s function, we get \\[\n\\begin{align*}\nG(\\mathbf{x} - \\mathbf{x}') &= \\frac{1}{r} + \\frac{x_i x_i'}{rr'} \\frac{r'}{r^2} + \\frac{1}{2} \\bigg(\\frac{3(x_i x_i') (x_j x_j')}{r^2r'^2} - 1\\bigg) \\frac{r'^2}{r^3} + \\frac{1}{2} \\bigg(5\\frac{(x_i x_i') (x_j x_j') (x_k x_k')}{r^3 r'^3} - 3\\frac{x_i x_i'}{rr'}\\bigg) \\frac{r'^3}{r^4} + \\cdots \\\\\n&= \\frac{1}{r} + \\frac{x_i}{r^3} x_i' + \\frac{x_i x_j}{2r^5} \\bigg(3x_i'x_j'- \\delta_{ij}\\bigg) +\n\\frac{x_ix_jx_k}{2r^7} \\bigg(5x_i'x_j'x_k' - 3r'^2  \\frac{x_i x_i'}{r^5}\\bigg) \\frac{r'^3}{r^4}\n\\end{align*}\n\\]\nBut what we really want is an expansion of the potential \\(\\phi(\\mathbf{x})\\). If we plug this Green’s function expansion into the integral formula for the potential given above, we can write \\[\n\\phi(\\mathbf{x}) = \\sum_{\\ell=0}^\\infty \\frac{1}{r^{\\ell+1}} \\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') P_\\ell(\\cos\\alpha) r'^\\ell \\ .\n\\] Let’s now expand this sum out into the first few terms. We have \\[\n\\phi(\\mathbf{x}) = \\frac{\\int d^3\\mathbf{x}' \\rho(\\mathbf{x}')}{r} + \\frac{\\int d^3\\mathbf{x}' \\rho(\\mathbf{x}') r' \\cos\\alpha}{r^2} + \\frac{\\int d^3\\mathbf{x}' \\rho(\\mathbf{x}') r'^2 (3\\cos^2\\alpha - 1)}{2r^3} + \\cdots \\ .\n\\] The numerator in the first term depends only on \\(\\mathbf{x}'\\). In fact it’s just the total charge \\(Q\\) of the charge distribution, \\[\nQ \\equiv \\int d^3\\mathbf{x}' \\rho(\\mathbf{x}') \\ .\n\\] The numerator in the second term depends on \\(r' \\cos \\alpha\\), which depends on both \\(\\mathbf{x}\\) and \\(\\mathbf{x}'\\). We can re-express this term as \\[\nr' \\cos\\alpha = \\frac{\\mathbf{x} \\cdot \\mathbf{x}'}{r} \\ .\n\\] Plugging this in and pulling the \\(\\mathbf{x}'\\)-independent terms out of the integral, we get \\[\n\\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') r' \\cos\\alpha = \\frac{\\mathbf{x}}{r} \\cdot \\bigg(\\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') \\mathbf{x}'\\bigg) \\ .\n\\] Evidently then, the second term in the expansion depends on the source only via the vector integral \\[\n\\mathbf{p} \\equiv \\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') \\mathbf{x}' \\ .\n\\] The numerator in the third term depends now on \\(r'^2 \\cos^2\\alpha\\). We can rewrite this part of the integrand as \\[\nr'^2 (3\\cos^2\\alpha - 1) = 3\\bigg(\\frac{\\mathbf{x} \\cdot \\mathbf{x}'}{r}\\bigg)^2 - r'^2 = \\frac{x_i x_j}{r^2} x_i' x_j' - r'^2 \\ .\n\\] Plugging this in and pulling the \\(\\mathbf{x}'\\)-independent terms out of the integral, we get \\[\n\\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') r'^2 (3\\cos^2\\alpha - 1) = \\frac{x_i}{r} \\cdot \\bigg(\\int d^3\\mathbf{x}' \\ \\rho(\\mathbf{x}') (3 x_i' x_j' - \\delta_{ij}) \\bigg) \\cdot \\frac{x_j}{r} \\ .\n\\]\nNow, since each Legendre polynomial \\(P_\\ell(\\cos\\alpha)\\) is a polynomial of degree \\(\\ell\\), the highest-degree term in each polynomial will be \\[\n\\begin{align*}\n\\cos^\\ell \\alpha &= \\bigg(\\frac{\\mathbf{x} \\cdot \\mathbf{x}'}{r'r}\\bigg)^\\ell \\\\\n&= \\frac{1}{(r'r)^\\ell} (x_{i_1} x_{i_1}') (x_{i_2} x_{i_2}') \\cdots (x_{i_\\ell} x_{i_\\ell}') \\\\\n&= \\frac{x_{i_1} x_{i_2} \\cdots x_{i_\\ell}}{r^\\ell} \\frac{x_{i_1}' x_{i_2}' \\cdots x_{i_\\ell}'}{r'^\\ell} \\ .\n\\end{align*}\n\\] Each term can be thought of as a rank-\\(n\\) outer product of vectors \\(\\mathbf{x}\\) and \\(\\mathbf{x}'\\) respectively. We’ll pull out the first term and write the potential in the form \\[\n\\phi(\\mathbf{x}) = \\sum_{\\ell=0}^\\infty \\frac{x_{i_1} x_{i_2} \\cdots x_{i_\\ell}}{r^{2\\ell+1}} \\int d^3\\mathbf{x}' \\rho(\\mathbf{x}') P_\\ell(\\cos\\alpha) r'^\\ell \\ .\n\\]",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Boundary Value Problems III</span>"
    ]
  },
  {
    "objectID": "electrodynamics/magnetostatics.html",
    "href": "electrodynamics/magnetostatics.html",
    "title": "Magnetostatics",
    "section": "",
    "text": "Ampere’s Force Law\nIn the 18th century, it was discovered that aside from mass, every physical body has associated to it another scalar quantity called electric charge, which can take on any real value, positive, negative, or zero. From these facts and other experiments, Coulomb discovered that the force between two static, charged bodies satisfies the following properties:",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Magnetostatics</span>"
    ]
  },
  {
    "objectID": "electrodynamics/magnetostatics.html#amperes-force-law",
    "href": "electrodynamics/magnetostatics.html#amperes-force-law",
    "title": "Magnetostatics",
    "section": "",
    "text": "The force between the two charges depends linearly on the magnitude of each charge. The larger the magnitude, the stronger the force between them.\nThe force obeys an inverse square law nature similar to gravity. That is, the strength of the force between the two charges varies with the inverse square of the distance between them.\nAs with gravity, the force is directed along the line of force joining the two charges.\nThe force is attractive if the two bodies have charges of opposite sign, and repulsive if the two bodies have charges of the same sign. If either body has zero charge there is no force between them.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Magnetostatics</span>"
    ]
  },
  {
    "objectID": "electrodynamics/magnetostatics.html#magnetic-fields",
    "href": "electrodynamics/magnetostatics.html#magnetic-fields",
    "title": "Magnetostatics",
    "section": "Magnetic Fields",
    "text": "Magnetic Fields",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Magnetostatics</span>"
    ]
  },
  {
    "objectID": "electrodynamics/magnetostatics.html#amperes-law",
    "href": "electrodynamics/magnetostatics.html#amperes-law",
    "title": "Magnetostatics",
    "section": "Ampere’s Law",
    "text": "Ampere’s Law",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Magnetostatics</span>"
    ]
  },
  {
    "objectID": "electrodynamics/magnetostatics.html#vector-potential",
    "href": "electrodynamics/magnetostatics.html#vector-potential",
    "title": "Magnetostatics",
    "section": "Vector Potential",
    "text": "Vector Potential",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Magnetostatics</span>"
    ]
  },
  {
    "objectID": "electrodynamics/magnetostatics.html#multipole-expansion",
    "href": "electrodynamics/magnetostatics.html#multipole-expansion",
    "title": "Magnetostatics",
    "section": "Multipole Expansion",
    "text": "Multipole Expansion",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Magnetostatics</span>"
    ]
  },
  {
    "objectID": "electrodynamics/magnetostatics.html#field-energy",
    "href": "electrodynamics/magnetostatics.html#field-energy",
    "title": "Magnetostatics",
    "section": "Field Energy",
    "text": "Field Energy",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Magnetostatics</span>"
    ]
  },
  {
    "objectID": "electrodynamics/orthogonal-functions.html",
    "href": "electrodynamics/orthogonal-functions.html",
    "title": "Appendix I: Orthogonal Functions",
    "section": "",
    "text": "Orthogonal Functions\nWe’ll begin our discussion of orthogonal functions by defining what we mean when we say a function is orthogonal. This will involve defining and discussing the inner product of functions, which is a direct generalization of the dot product from linear algebra. We’ll see that the theory of orthogonal functions indeed shares much in common with linear algebra, and can in a sense be thought of as a continuous limit of that subject.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Appendix I: Orthogonal Functions</span>"
    ]
  },
  {
    "objectID": "electrodynamics/orthogonal-functions.html#orthogonal-functions",
    "href": "electrodynamics/orthogonal-functions.html#orthogonal-functions",
    "title": "Appendix I: Orthogonal Functions",
    "section": "",
    "text": "Inner Products\nSuppose \\(f\\) and \\(g\\) are two potentially complex-valued functions defined on some interval \\(a \\leq x \\leq b\\). We will assume both of these functions are square integrable on the given interval, meaning \\[\n\\int_a^b dx \\ |f(x)|^2 &lt; \\infty \\ .\n\\] If this is the case, we can define an inner product between the two functions on this interval by the integral \\[\n\\langle f | g \\rangle \\equiv \\int_a^b dx \\ f^*(x) g(x) \\ .\n\\] Here \\(f^*(x)\\) denotes the complex conjugate of \\(f(x)\\). The range of the integration can be between any two points, or even the whole real line, so long as we’re consistent. Notice how similar this definition looks to the inner product of two vectors, apart from the notation. If we have two complex-valued vectors \\(\\mathbf{v}\\) and \\(\\mathbf{w}\\), their inner product is given by \\[\n\\mathbf{v} \\cdot \\mathbf{w} = \\sum_n v_n^* w_n \\ ,\n\\] hence the inner product of functions is essentially the continuous analogue of the inner product of vectors. Like the inner product of vectors, the inner product of functions is linear in each of its arguments and its output will always be a complex number.\nAs with vectors, we’ll say two functions \\(f\\) and \\(g\\) are orthogonal if their inner product is zero, \\[\n\\langle f | g \\rangle = \\int_a^b dx \\ f^*(x) g(x) = 0 \\ .\n\\] Similarly, we can define a norm of a function \\(f\\) as being the square root of its self inner product, \\[\n||f|| \\equiv \\sqrt{\\langle f | f \\rangle} = \\sqrt{\\int_a^b dx \\ |f(x)|^2} \\ .\n\\] Notice that for this to make sense the self inner product \\(\\langle f | f \\rangle\\) should always be a non-negative real number. We can see from the integrand that this will indeed always be the case, since \\(|f(x)|^2\\) will always be a non-negative real number as well. As with vectors, we say that a nonzero function is normalized or unit length if its norm is one, i.e. \\(||f|| = 1\\).\nFrom linear algebra, we also know that if we have an orthogonal set of vectors \\(\\mathbf{e}_n\\) that span the vector space, then those vectors form a basis for that space, and we can represent any vector in the space as a linear superposition of those basis vectors, with \\[\n\\mathbf{v} = \\sum_n c_n \\mathbf{e}_n \\ .\n\\] To find the coefficients \\(c_n\\) we need only dot \\(\\mathbf{v}\\) with any basis vector, say \\(\\mathbf{e}_m \\cdot \\mathbf{v} = c_m |\\mathbf{e}_m|^2\\). This means the \\(c_n\\) are given by \\[\nc_n = \\frac{\\mathbf{e}_n \\cdot \\mathbf{v}}{|\\mathbf{e}_n|^2} \\ .\n\\] These ideas extend to functions as well. We say a set of functions \\(f_n(x)\\) forms an orthogonal set provided each pair of functions is mutually orthogonal, i.e. \\(\\langle f_m | f_n \\rangle = 0\\) whenever \\(m \\neq n\\). If furthermore each of the functions \\(f_n(x)\\) is normalized, we say the set of functions forms an orthonormal set. An orthonormal set of functions satisfies the nice property that \\[\n\\langle f_m | f_n \\rangle = \\delta_{mn} \\ ,\n\\] where \\(\\delta_{mn}\\) is the usual Kronecker delta. If the set is orthogonal but not orthonormal, we have to modify this expression slightly by factoring out the norm of each function, giving instead \\[\n\\langle f_m | f_n \\rangle = ||f_m|| \\ ||f_n|| \\ \\delta_{mn} \\ .\n\\]\n\n\nOrthogonal Expansions\nNow, we’d like to get to the idea of a basis of functions, but we have to be more careful by what we mean when we say any function can be expanded as a linear superposition of basis functions. We’d like to write something like \\[\nf(x) = \\sum_n c_n f_n(x) \\ .\n\\] But for this equality to hold like we want, we have to reinterpret what we mean by the word equals. It will not in general be true that the two sides equal pointwise, in the sense that the equality holds for any value of \\(x\\) we plug into the formula. Instead, when we write an equals sign like this, we really mean that the two expressions are equal in norm, meaning the norm of their difference goes to zero as \\(n\\) becomes infinite, \\[\n\\bigg|\\bigg| f(x) - \\sum_n c_n f_n(x) \\bigg|\\bigg| \\rightarrow 0 \\quad \\text{as} \\quad n \\rightarrow \\infty \\ .\n\\] If two functions are equal in norm, they won’t always be equal at every point \\(x\\), but they will be equal at almost all \\(x\\). This is a minor mathematical point that we mostly gloss over in physics, but it does lead to some interesting phenomena, e.g. the Gibbs phenomenon that arises in the Fourier series expansion of rectangular functions.\nWe say a set of functions \\(f_n(x)\\) is a complete set provided we can represent any function \\(f(x)\\) on the given interval as a linear superposition of these functions, in the equals in norm sense defined above, \\[\nf(x) = \\sum_n c_n f_n(x) \\ .\n\\] If the complete set is also orthogonal, we call this an orthogonal expansion of \\(f(x)\\) in the basis of functions \\(f_n(x)\\). In this case, we can easily determine the expansion coefficients \\(c_n\\) by taking the inner product of both sides with respect to some \\(f_m\\), \\[\n\\langle f_m | f \\rangle = \\sum_n c_n \\langle f_m | f_n \\rangle = c_m ||f_m||^2  \\ ,\n\\] which implies the expansion coefficients are given by \\[\nc_n = \\frac{\\langle f_n | f \\rangle}{||f_n||^2} = \\frac{1}{||f_n||^2} \\int_a^b dx \\ f_n^*(x) f(x) \\ .\n\\] This method of obtaining the expansion coefficients is sometimes called the Fourier trick. We’ll use it a good bit in this course.\nNow, observe if we plug this expressions back into the orthogonal expansion for \\(f(x)\\), we get \\[\n\\begin{align*}\nf(x) &= \\sum_n c_n f_n(x) \\\\\n&= \\sum_n \\bigg(\\frac{1}{||f_n||^2}\\int_a^b dx' \\ f_n^*(x') f(x')\\bigg) f_n(x) \\\\\n&= \\int_a^b dx' \\ \\bigg(\\frac{1}{||f_n||^2}\\sum_n f_n^*(x') f_n(x)\\bigg) f(x') \\ .\n\\end{align*}\n\\] Evidently, this expression can only be true provided \\[\n\\frac{1}{||f_n||^2} \\sum_n f_n^*(x') f_n(x) = \\delta(x-x') \\ .\n\\] This relation is called the completeness relation. It’s a necessary condition for the set of \\(f_n(x)\\) to form a complete set. This gives us a relatively simple way to check whether a given an orthogonal set of functions is complete or not. Provided the completeness condition holds, we know we can write down an orthogonal expansion in terms of those basis functions.\nLast, we’ll derive one more useful result known as Parseval’s Identity. Suppose we’ve expanded \\(f(x)\\) in terms of an orthogonal set \\(f_n(x)\\). If we consider the squared norm \\(||f||^2 = \\langle f | f \\rangle\\) and expand \\(f(x)\\) out on both sides and plug in the formula for the coefficients, we have \\[\n\\begin{align*}\n||f||^2 &= \\bigg\\langle \\sum_{n'} c_{n'} f_{n'} \\bigg| \\sum_n c_n f_n \\bigg\\rangle \\\\\n&= \\sum_{n,n'} c_{n'}^* c_n \\langle f_{n'} | f_n \\rangle \\\\\n&= \\sum_{n,n'} c_{n'}^* c_n ||f_{n'}|| \\ ||f_n|| \\ \\delta_{nn'} \\\\\n&= \\sum_n |c_n|^2 ||f_n||^2 \\ .\n\\end{align*}\n\\] That is, the squared function norm of \\(f(x)\\) is equal to the squared vector norm of the coefficients \\(c_n\\), weighted by \\(f_n\\). If the set is orthonormal then the weights disappear, and we can simply write \\(||f||^2 = |\\mathbf{c}|^2\\), where \\(\\mathbf{c}\\) is an infinite vector of coefficients. One immediate implication of this identity is that if \\(f(x)\\) is square-integrable, then the coefficients must decay to zero as \\(n \\rightarrow \\infty\\).",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Appendix I: Orthogonal Functions</span>"
    ]
  },
  {
    "objectID": "electrodynamics/orthogonal-functions.html#sturm-liouville-theory",
    "href": "electrodynamics/orthogonal-functions.html#sturm-liouville-theory",
    "title": "Appendix I: Orthogonal Functions",
    "section": "Sturm-Liouville Theory",
    "text": "Sturm-Liouville Theory\nFor a large class of problems we don’t need to go through the hard work of figuring out whether a set of functions is complete or orthogonal. These are so-called Sturm-Liouville problems. Provided we can prove that a set of functions satisfies a Sturm-Liouville problem, we automatically know that it will form a complete orthogonal set of functions, which saves us the hard work of having to verify each of these properties independently.\n\nHermitian Operators\nSuppose we have some linear differential operator \\(\\mathcal{L}\\) satisfying a differential equation \\[\n\\mathcal{L} f = \\lambda f \\ .\n\\] We call this an eigenvalue problem. Any function that satisfies the differential equation is called an eigenfunction with associated eigenvalue \\(\\lambda\\). Indeed, this is just a continuous generalization of the eigenvalue problem \\(\\mathbf{A}\\mathbf{x} = \\lambda\\mathbf{x}\\) from linear algebra, with the vector \\(\\mathbf{x}\\) replaced by a function \\(f(x)\\) and the matrix \\(\\mathbf{A}\\) replaced by a linear operator \\(\\mathcal{L}\\).\nIf we restrict the class of functions to those that are square-normalizable on some interval \\(a \\leq x \\leq b\\), we can define an inner product on them in the usual way by \\[\n\\langle f | g \\rangle \\equiv \\int_a^b dx \\ f^*(x) w(x) g(x) \\ .\n\\] Notice we’ve introduced an optional positive-valued weighting function \\(w(x) &gt; 0\\) in the inner product, which will be useful below.\nThe most useful types of differential operators in physics are the Hermitian or self-adjoint operators, which are operators satisfying the self-adjoint relation \\[\n\\langle \\mathcal{L} f | g \\rangle = \\langle f | \\mathcal{L}g \\rangle \\ .\n\\] If we think of \\(\\mathcal{L}\\) as a type of matrix, it’s easy to see that this is equivalent to requiring that the \\(\\mathcal{L}\\) be Hermitian, i.e. \\(\\mathcal{L}^\\dagger = \\mathcal{L}\\), where \\(\\mathcal{L}^\\dagger\\) is the conjugate transpose of \\(\\mathcal{L}\\). This is where the term Hermitian operator comes from.\nAs an example, suppose \\(\\mathcal{L}\\) is the second derivative operator \\(\\mathcal{L} = \\frac{d^2}{dx^2}\\) and we take \\(w(x)=1\\). If we plug this into the inner product and integrate by parts twice, we get \\[\n\\begin{align*}\n\\langle \\mathcal{L} f | g \\rangle &= \\int_a^b dx \\ \\frac{d^2f^*}{dx^2} g(x) \\\\\n&= \\frac{d}{dx} f^*(x) \\frac{d}{dx}g(x) \\bigg|_{x=a}^{x=b} - \\int_a^b dx \\ \\frac{df^*}{dx} \\frac{dg}{dx} \\\\\n&= g(x) \\frac{d}{dx} f^*(x) \\bigg|_{x=a}^{x=b} - f^*(x) \\frac{d}{dx}g(x) \\bigg|_{x=a}^{x=b} + \\int_a^b dx \\ f^*(x) \\frac{dg}{dx} \\ .\n\\end{align*}\n\\] Provided either of these functions or their first derivatives vanish at the endpoints \\(x=a\\) and \\(x=b\\), we can satisfy the self-adjoint condition \\(\\langle \\mathcal{L} f | g \\rangle = \\langle f | \\mathcal{L} g \\rangle\\). That is, the second derivative operator is Hermitian when applied to functions with Dirichlet, Neumann, or indeed mixed boundary conditions.\nOne can easily check the following two facts about Hermitian operators:\n\nAny operator of the form \\(\\mathcal{L} = g(x)\\) where \\(g(x)\\) is a real-valued function will be Hermitian.\nAny linear superposition of Hermitian operators will be Hermitian as well.\n\nSo why are Hermitian operators so important? It turns out that any Hermitian operator satisfies these two conditions:\n\nThe eigenvalues \\(\\lambda_n\\) of a Hermitian operator will always be real-valued.\nThe eigenfunctions \\(f_n\\) corresponding to distinct eigenvalues with always be orthogonal.\n\nBoth of these are easy to check from the definition. To check the first statement, we pick an nonzero eigenfunction \\(f_n(x)\\) and notice that since \\(\\mathcal{L}\\) is Hermitian and \\(\\mathcal{L} f_n = \\lambda_n f_n\\) we must have \\[\n\\langle \\mathcal{L} f_n | f_n \\rangle = \\lambda_n^* \\langle f_n | f_n \\rangle = \\langle f_n | \\mathcal{L} f_n \\rangle = \\lambda_n \\langle f_n | f_n \\rangle \\quad \\Longrightarrow \\quad (\\lambda_n^* - \\lambda_n) \\langle f_n | f_n \\rangle = 0 \\ .\n\\] The only way this can be true is if \\(f_n = 0\\) or \\(\\lambda_n = \\lambda_n^*\\). Since \\(f_n = 0\\) is disallowed, the eigenvalue \\(\\lambda_n\\) must be real. To check the second statement, we pick two eigenfunctions \\(f_m(x)\\) and \\(f_n(x)\\) with distinct eigenvalues \\(\\lambda_n \\neq \\lambda_m\\) and do the same thing, \\[\n\\langle \\mathcal{L} f_m | f_n \\rangle = \\lambda_m \\langle f_m | f_n \\rangle = \\langle f_m | \\mathcal{L} f_n \\rangle = \\lambda_n \\langle f_m | f_n \\rangle \\quad \\Longrightarrow \\quad (\\lambda_m - \\lambda_n) \\langle f_m | f_n \\rangle = 0 \\ .\n\\] Since \\(\\lambda_m \\neq \\lambda_n\\) by assumption, the only way this can be true is if \\(\\langle f_m | f_n \\rangle = 0\\), meaning \\(f_m(x)\\) and \\(f_n(x)\\) are orthogonal.\n\n\nSturm-Liouville Problems\nWith this theory in hand, let’s now focus specifically the Sturm-Liouville problem. A Sturm-Liouville problem is any boundary value problem of the form \\[\n\\begin{align*}\n\\begin{cases}\n-\\frac{d}{dx} \\big[p(x) \\frac{df}{dx}\\big] + q(x) f(x) = \\lambda w(x) f(x) \\ , \\\\\n\\text{where} \\ \\alpha_1 f(a) + \\alpha_2 \\frac{d}{dx} f(a) = 0 \\ , \\quad \\alpha_1 \\neq 0 \\ \\text{or} \\  \\beta_1 \\neq 0 \\ , \\\\\n\\text{and} \\quad \\beta_1 f(b) + \\beta_2 \\frac{d}{dx} f(b) = 0 \\ , \\quad \\ \\ \\alpha_2 \\neq 0 \\ \\text{or} \\  \\beta_2 \\neq 0 \\ .\n\\end{cases}\n\\end{align*}\n\\] We require that \\(p(x), q(x), w(x)\\) all be real-valued continuous functions with \\(p(x),w(x) &gt; 0\\). By expressing the boundary conditions this way, we’re just saying in a fancy way that the boundary conditions must be of type Dirichlet, Neumann, or mixed. We can recover the Dirichlet conditions by setting \\(\\beta_1 = \\beta_2 = 0\\), and the Neumann conditions by setting \\(\\alpha_1 = \\alpha_2 = 0\\).\nNow let’s look closer at the differential equation itself. If we expand things out, we get \\[\np(x) \\frac{d^2f}{dx^2} + \\frac{dp}{dx} \\frac{df}{dx} + \\big(q(x) - \\lambda w(x)\\big) f(x) = 0 \\ .\n\\] Notice this is just the general form for any linear second order homogeneous ODE. Thus, in some sense the Sturm-Liouville problem covers every linear second order ODE subject to the right boundary conditions.\nThough perhaps not obvious, the Sturm-Liouville problem is Hermitian. We can see this by defining an operator of the form \\[\n\\mathcal{L}f \\equiv \\frac{1}{w(x)} \\bigg[-\\frac{d}{dx} \\bigg(p(x) \\frac{df}{dx}\\bigg) + q(x) f\\bigg] \\ .\n\\] Since the second term is a function operator we know it will be Hermitian. We also know that the sum of Hermitian operators is Hermitian. This means it suffices for our purposes to check that the operator \\(\\mathcal{L} - \\frac{q(x)}{w(x)}\\) is Hermitian, meaning it satisfies the self-adjoint condition \\(\\langle (\\mathcal{L}-\\frac{q}{w}) f | g \\rangle = \\langle f | (\\mathcal{L}-\\frac{q}{w}) g \\rangle\\). To do that we integrate by parts twice again to get \\[\n\\begin{align*}\n\\big\\langle \\big(\\mathcal{L}-\\frac{q}{w}\\big) f \\big| g \\big\\rangle &= -\\int_a^b dx \\ \\frac{d}{dx} \\bigg(p(x) \\frac{d}{dx}f^*(x)\\bigg) g(x) \\\\\n&= -p(x)g(x) \\frac{d}{dx}f^*(x) \\bigg|_{x=a}^{x=b} + \\int_a^b dx \\ \\bigg(p(x) \\frac{d}{dx}f^*(x)\\bigg) \\frac{d}{dx}g(x) \\\\\n&= \\bigg[p(x)f^*(x) \\frac{d}{dx}g(x) - p(x)g(x) \\frac{d}{dx}f^*(x)\\bigg]_{x=a}^{x=b} - \\int_a^b dx \\ f^*(x) \\frac{d}{dx} \\bigg(p(x) \\frac{d}{dx}g(x)\\bigg) \\\\\n&= \\bigg[p(x)f^*(x) \\frac{d}{dx}g(x) - p(x)g(x) \\frac{d}{dx}f^*(x)\\bigg]_{x=a}^{x=b} + \\big\\langle f \\big| \\big(\\mathcal{L}-\\frac{q}{w}\\big) g \\big\\rangle \\ .\n\\end{align*}\n\\] It’s not hard to show that the Sturm-Liouville boundary conditions now require that both boundary terms vanish. In fact, we don’t even need the boundary conditions to be satisfied. Notice that the boundary terms will also vanish if \\(p(x)\\) happens to vanish on the endpoints. If that’s the case, we only require that the functions and their derivatives be finite at the endpoints. This may seem academic, but we’ll see this is exactly what happens with the Legendre polynomials in the next section.\nAt any rate, provided the boundary terms vanish, we’re left with \\[\n\\big\\langle \\big(\\mathcal{L}-\\frac{q}{w}\\big) f \\big| g \\big\\rangle = \\big\\langle f \\big| \\big(\\mathcal{L}-\\frac{q}{w}\\big) g \\big\\rangle \\ .\n\\] Thus, the Sturm-Liouville operator \\(\\mathcal{L}\\) must be Hermitian. An immediately consequence of this is that we know that the eigenvalues of \\(\\mathcal{L}\\) are real-valued, and eigenfunctions with different eigenvalues must be orthogonal.\nWe can actually say something stronger about the eigenvalues and eigenfunctions of the Sturm-Liouville problem. The proof is a bit technical so we’ll just state the result: For any Sturm-Liouville problem the following facts must be true:\n\nThere will be infinitely many eigenvalues and eigenfunctions.\nThe eigenvalues will always be distinct, and can be linearly ordered such that \\(\\lambda_1 &lt; \\lambda_2 &lt; \\cdots &lt; \\lambda_n &lt; \\cdots \\rightarrow \\infty\\).\nCorresponding to each eigenvalue \\(\\lambda_n\\) is a unique function \\(f_n(x)\\) satisfying the Sturm-Liouville problem.\nThe eigenfunctions form a complete orthogonal set of functions on \\(a \\leq x \\leq b\\) that can be made orthonormal.\n\nThe last condition is probably the most useful for our purposes. It says that for any function \\(f(x)\\) satisfying the boundary conditions of a Sturm-Liouville problem, we can do an orthogonal expansion of \\(f(x)\\) in terms of the eigenfunctions \\(f_n(x)\\) as \\[\nf(x) = \\sum_{n=1}^\\infty c_n f_n(x) \\ ,\n\\] where the coefficients are given in the usual way by \\(||f_n||^2 c_n = \\langle f_n | f_m \\rangle\\). This is a remarkable result. It means that to find a set of complete orthogonal functions on some interval, all we need to do is show that it satisfies some type of Sturm-Liouville problem. If it does, the orthogonal expansion is just given by the eigenfunctions of that problem.\nWe’ll see a few important example of this in the following sections, where we’ll cover some of the most important classes of orthogonal functions we see in electromagnetism, the so-called special functions.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Appendix I: Orthogonal Functions</span>"
    ]
  },
  {
    "objectID": "electrodynamics/orthogonal-functions.html#fourier-series",
    "href": "electrodynamics/orthogonal-functions.html#fourier-series",
    "title": "Appendix I: Orthogonal Functions",
    "section": "Fourier Series",
    "text": "Fourier Series\nFirst, we’ll look at perhaps the most important class of functions in physics, the complex exponentials. The complex exponentials won’t in general be orthogonal to each other, but we can make them orthogonal by choosing the right constants. Suppose \\[\nf_n(x) = a_n e^{i k_n x} \\\n\\] is defined on some closed interval \\(-L \\leq x \\leq L\\) of length \\(2L\\). We’ll show that for certain choices of \\(a_n\\) and \\(k_n\\) this set of functions forms a complete orthonormal set on the above interval. We’ll do that by finding a Sturm Liouville problem whose eigenfunctions are these complex exponentials.\nConsider the following boundary value problem, \\[\n\\begin{align*}\n\\begin{cases}\n\\frac{d^2f}{d^2x} = \\lambda f \\ , \\\\\n\\text{where} \\ f(-L) = \\frac{d}{dx} f(L) = 0 \\ .\n\\end{cases}\n\\end{align*}\n\\] This is a clearly a Sturm-Liouville problem, with \\(p(x) = 1\\), \\(q(x) = 0\\), \\(w(x) = 1\\), \\(\\alpha_1 = \\beta_2 = 1\\), and \\(\\alpha_2 = \\beta_1 = 0\\).\nTo solve this problem we recognize that it’s just a simple harmonic oscillator with \\(\\lambda = -k^2\\). The general solution can be written \\[\nf(x) = a e^{i kx} + b e^{-i kx} \\ .\n\\] Plugging in the boundary conditions evidently gives \\[\n\\begin{align*}\n0 &= a e^{-ikL} + b e^{ikL} \\ ,\\\\\n0 &= ik \\big(a e^{ikL} - b e^{-ikL}\\big) \\ .\n\\end{align*}\n\\] The only way these conditions can both be true is if \\(kL\\) is an integer multiple of \\(\\pi\\). That is, if \\[\nk_n = \\frac{n\\pi}{L} \\quad , \\quad n = 0, \\pm 1, \\pm 2, \\cdots \\ .\n\\] We’ve thus found an infinite set of solutions that satisfy a Sturm-Liouville problem, given by \\[\nf_n(x) = a_n e^{in\\pi x/L} \\quad , \\quad n = 0, \\pm 1, \\pm 2, \\cdots \\ .\n\\] Let’s go ahead and normalize them as well so we get a complete orthonormal set of functions. We do that by requiring that \\(\\langle f_n | f_n \\rangle = 1\\). Taking this inner product and requiring it equal one, we have \\[\n\\langle f_n | f_n \\rangle = \\int_{-L}^L dx \\ a_n^* e^{-i k_n x} a_n e^{i k_n x} = 2L |a_n|^2 \\quad \\Longrightarrow \\quad a_n = \\frac{1}{\\sqrt{2L}} \\ .\n\\] According to Sturm Liouville theory, we’ve thus found a complete orthonormal set on the interval \\(-L \\leq x \\leq L\\) given by the infinite set of functions \\[\nf_n(x) = \\frac{1}{\\sqrt{2L}} e^{in\\pi x/L} \\quad , \\quad n = 0, \\pm 1, \\pm 2, \\cdots \\ .\n\\] ### Complex Fourier Series\nThis means we can do an orthogonal expansion any function \\(f(x)\\) on this interval and write \\[\nf(x) = \\frac{1}{\\sqrt{2L}} \\sum_{n=-\\infty}^\\infty c_n e^{in\\pi x/L} \\ .\n\\] This important series expansion is known as a Fourier series. It’s arguably the most important series in science and engineering. It’s conventional with Fourier series to absorb the normalization constant into the coefficients \\(c_n\\) and instead write \\[\n\\boxed{\nf(x) = \\sum_{n=-\\infty}^\\infty c_n e^{in\\pi x/L}\n} \\ .\n\\] Note that, strictly speaking, Sturm-Liouville only guarantees that any functions \\(f(x)\\) that satisfy the boundary conditions of the Sturm-Liouville problem are guaranteed to have an orthogonal expansion. However, further results from the theory of Fourier analysis show that any function on this interval can be expanded this way, not just ones satisfying the boundary conditions.\nThe coefficients \\(c_n\\) are given in the usual way, except we have to account for the absorption of \\(\\frac{1}{2\\sqrt{L}}\\) into the \\(c_n\\). With this, we must have \\(c_n = \\frac{1}{\\sqrt{2L}} \\langle f_n | f \\rangle\\), which gives \\[\n\\boxed{\nc_n = \\frac{1}{2L} \\int_{-L}^L dx \\ f(x) e^{-in\\pi x/L}\n} \\ .\n\\] Notice that the set of basis functions \\(f_n(x)\\) are all periodic on the real line with period \\(2L\\), i.e. \\(f_n(x) = f_n(x + 2L)\\). This means we can also think of the Fourier series as a periodic expansion over the real line. An implication of this is that any \\(2L\\)-periodic function \\(f(x)\\) can be expanded into a Fourier series.\n\nReal Fourier Series\nIt’s common to rewrite the Fourier series in a different form by making the basis functions real-valued. To achieve this, we’ll first rewrite the series in a slightly different from by grouping terms and restricting \\(n\\) to be non-negative, \\[\nf(x) = c_0 + \\sum_{n=1}^\\infty \\big[c_n e^{in\\pi x/L} + c_{-n} e^{-in\\pi x/L}\\big] \\ .\n\\] We can now use the Euler identity to write each complex exponential into sines and cosines, and regroup terms to get \\[\n\\begin{align*}\nf(x) &= c_0 + \\sum_{n=1}^\\infty \\bigg[c_n e^{in\\pi x/L} + c_{-n} e^{-in\\pi x/L}\\bigg] \\\\\n&= c_0 + \\sum_{n=1}^\\infty \\bigg[c_n \\bigg(\\cos \\frac{n\\pi x}{L} + i \\sin \\frac{n\\pi x}{L}\\bigg) + c_{-n} \\bigg(\\cos \\frac{n\\pi x}{L} - i \\sin \\frac{n\\pi x}{L}\\bigg)\\bigg] \\\\\n&= c_0 + \\sum_{n=1}^\\infty \\bigg[(c_n + c_{-n}) \\cos \\frac{n\\pi x}{L} + i (c_n - c_{-n}) \\sin \\frac{n\\pi x}{L}\\bigg] \\ .\n\\end{align*}\n\\] Now, we’ll define new expansion coefficients \\(a_n\\) and \\(b_n\\) in terms of \\(c_n\\) by \\[\na_n \\equiv c_n + c_{-n} \\quad , \\quad b_n \\equiv i(c_n - c_{-n}) \\ .\n\\] Plugging this back into the Fourier series, we get \\[\n\\boxed{\nf(x) = \\frac{a_0}{2} + \\sum_{n=1}^\\infty \\bigg[a_n \\cos \\frac{n\\pi x}{L} + b_n \\sin \\frac{n\\pi x}{L}\\bigg]\n} \\ .\n\\] The expansion coefficients can then be found by plugging in the formulas for \\(c_n\\) and \\(c_{-n}\\) and grouping terms to get \\[\n\\boxed{\n\\begin{align*}\na_0 &= \\frac{1}{L} \\int_{-L}^L dx \\ f(x) \\\\\na_n &= \\frac{1}{L} \\int_{-L}^L dx \\ f(x) \\cos \\frac{n\\pi x}{L} \\\\\nb_n &= \\frac{1}{L} \\int_{-L}^L dx \\ f(x) \\sin \\frac{n\\pi x}{L}\n\\end{align*}\n} \\ .\n\\] Though perhaps not immediately obvious, this set of sines and cosines also forms an orthogonal expansion. Indeed, if we define \\[\nC_n(x) \\equiv \\frac{1}{\\sqrt{L}} \\cos \\frac{n\\pi x}{L} \\quad , \\quad S_n(x) \\equiv \\frac{1}{\\sqrt{L}} \\sin \\frac{n\\pi x}{L} \\ ,\n\\] then each set of functions forms an orthonormal set, with \\(\\langle C_m | C_n \\rangle = \\langle S_m | S_n \\rangle = \\delta_{mn}\\), and the functions in each set are always orthogonal to each other, with \\(\\langle C_m | S_n \\rangle = 0\\). These facts can easily be shown by writing \\(C_n\\) and \\(S_n\\) in terms of \\(f_n\\) and plugging those expressions into the inner product and simplifying terms, with no integration needed.\nLet’s work a brief example to show how to actually find the Fourier series for some simple function.\n\nExample: Fourier series of a rectangular pulse\nSuppose we have a function \\(f(x)\\) representing a rectangular pulse of height \\(h\\) on the interval \\(-L \\leq x \\leq L\\), with \\[\nf(x) = \\begin{cases}\n0 , & -L \\leq x \\leq -\\frac{L}{2} \\ , \\\\\nh , & -\\frac{L}{2} &lt; x &lt; \\frac{L}{2} \\ , \\\\\n0 , & \\frac{L}{2} \\leq x \\leq L \\ .\n\\end{cases}\n\\] We’d like to expand this function as a Fourier series. To do that, we need to find the coefficients \\(c_n\\). According to the formula above, we have \\[\n\\begin{align*}\nc_n &= \\frac{1}{2L} \\int_{-L}^L dx \\ f(x) e^{-in\\pi x/L} \\\\\n&= \\frac{1}{2L} \\int_{-\\frac{L}{2}}^{\\frac{L}{2}} dx \\ h e^{-in\\pi x/L} \\\\\n&= \\frac{h}{2L} \\frac{2L}{n\\pi} \\frac{1}{2i} \\bigg[\\exp\\bigg(\\frac{in\\pi}{L}\\frac{L}{2}\\bigg) - \\exp\\bigg(-\\frac{in\\pi}{L}\\frac{L}{2}\\bigg)\\bigg] \\\\\n&= \\frac{h}{n\\pi} \\sin \\frac{n\\pi}{2} \\\\\n&= \\begin{cases}\n\\frac{h}{n\\pi} & n=\\pm 1, \\pm 5, \\pm 9, \\cdots \\\\\n-\\frac{h}{n\\pi} & n=\\pm 3, \\pm 7, \\pm 11, \\cdots \\\\\n0 & n=\\pm 2, \\pm 4, \\pm 6, \\cdots\n\\end{cases} \\ .\n\\end{align*}\n\\] The case when \\(n=0\\) we have to check separately. In that case, the integral is just \\(\\frac{1}{2L}\\) times the area of the pulse, which is \\(hL\\). This gives \\(c_0 = \\frac{h}{2}\\). Now, could proceed to plug these coefficients into the complex Fourier series, but in this case it’s more useful to work with the real Fourier series as we’ll see. Using the conversion formulas between \\(c_n\\) and \\(a_n, b_n\\) we have \\[\na_0 = h \\quad , \\quad a_n = \\pm \\frac{2h}{n\\pi} \\quad , \\quad b_n = 0 \\ .\n\\] Using these coefficients, we can express the series in closed form by letting \\(n=2k+1\\) to get \\[\nf(x) = \\frac{h}{2} + \\sum_{k=0}^\\infty \\frac{(-1)^k}{2k+1} \\cos \\frac{(2k+1) \\pi x}{L} = \\frac{h}{2} + \\frac{2h}{\\pi} \\bigg[\\cos \\frac{\\pi x}{L} - \\frac{1}{3}\\cos \\frac{3\\pi x}{L} + \\frac{1}{5}\\cos \\frac{5\\pi x}{L} - \\frac{1}{7}\\cos \\frac{7\\pi x}{L} + \\cdots \\bigg] \\ .\n\\] Notice that each term in the series decays as \\(\\frac{1}{n}\\). This means we can approximate this series by keeping only the first few terms, and the approximation gets better and better the more terms we include.\nBelow we show a plot \\(f(x)\\) where \\(h=1\\) and \\(L=2\\) along with its Fourier approximations \\(S_N\\) for \\(N=1, 5, 10, 100\\). Notice that as we keep more terms, the series better and better approximates the behavior of \\(f(x)\\), which is what we’d expect.\n\n\n\n\n\nNotice something curious from this plot. Around the discontinuous points at \\(x = \\pm \\frac{L}{2}\\) the series never seems to converge at those two points. In fact, the series approximations seem to have a spike around \\(y \\approx 1.09h\\) near \\(x = \\pm \\frac{L}{2}\\), or about \\(9\\%\\) of the gap. In fact, these spikes persists no matter how high we take \\(N\\) to be in the series approximation. It’s known as the Gibb’s phenomenon, and can be proven analytically.\nThis behavior around discontinuities is a general fact about Fourier series. They will only converge at points where the function is actually continuous. At discontinuous points the series will converge to the average value of the left and right limits, and will always have this Gibbs phenomenon type behavior nearby.\nAnyway, had we been smarter, we’d notice something that could’ve greatly simplified this problem: The pulse function \\(f(x)\\) is even. If we stare at the Fourier series, we see that only the cosine terms are even, while the sine terms are all odd. This means the only way we could expand an even function is if we require all the odd coefficients to vanish, leaving us with \\[\nf(x) = \\frac{a_0}{2} + \\sum_{n=1}^\\infty a_n \\cos \\frac{n\\pi x}{L} \\ .\n\\] This is called a cosine series. Any even function can be expanded this way. Had we recognized this, we could’ve just calculated \\(a_0\\) and \\(a_n\\) and we’d be done. A similar fact is true for odd functions. In that case, all the even coefficients must vanish, leaving us with a sine series instead.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Appendix I: Orthogonal Functions</span>"
    ]
  },
  {
    "objectID": "electrodynamics/orthogonal-functions.html#fourier-transform",
    "href": "electrodynamics/orthogonal-functions.html#fourier-transform",
    "title": "Appendix I: Orthogonal Functions",
    "section": "Fourier Transform",
    "text": "Fourier Transform\nIt turns out that the Fourier series also has a continuous analogue to it known as the Fourier transform. The Fourier transform can be thought of the continuous analogue of the Fourier series as we let the interval length \\(L \\rightarrow \\infty\\). When a well-behaved function \\(f(x)\\) is defined on the entire real line we can take its Fourier transform. As innocuous as this all sounds, the Fourier transform is without a doubt one of the most important mathematical operations in all of science in engineering. It can be used to analyze signals, create filters, and even solve complex differential equations.\n\nDefinition\nWe can derive the Fourier transform from Fourier series pretty easily. To do that, we suppose \\(f(x)\\) can be expressed by a complex Fourier series of the form \\[\nf(x) = \\sum_{n=-\\infty}^\\infty c_n e^{ik_nx} \\ ,\n\\] where \\(k_n \\equiv = \\frac{n\\pi}{L}\\) and the coefficients \\(c_n\\) are given by the integral \\[\nc_n = \\frac{1}{2L} \\int_{-L}^L dx \\ f(x) e^{-i k_n x} \\ .\n\\] Substituting this expression into the Fourier series, we get the completeness relation \\[\nf(x) = \\sum_{n=-\\infty}^\\infty \\bigg(\\frac{1}{2L} \\int_{-L}^L dx' \\ f(x') e^{-i k_n x'}\\bigg) e^{ik_nx} \\ .\n\\] Now, suppose \\(L \\gg 1\\). Then the difference between successive \\(k_n\\) becomes infinitesimal, with each \\(\\Delta k_n = \\frac{\\pi}{L}\\). This means we can approximate the sum over \\(n\\) by an integral over \\(k \\equiv k_n = \\frac{n\\pi}{L}\\) with \\[\n\\sum_{n=-\\infty}^\\infty \\approx \\frac{L}{\\pi} \\int_0^\\infty dk \\ .\n\\] This means the completeness relation becomes \\[\nf(x) \\approx \\int_0^\\infty \\frac{dk}{2\\pi} \\ \\bigg(\\int_{-L}^L dx' \\ f(x') e^{-i k x'}\\bigg) e^{ikx} \\ .\n\\] Now, the inside integral is some function of \\(k\\). We’ll abuse notation and call this function \\(f(k)\\). Letting \\(L \\rightarrow \\infty\\), this inside integral evidently becomes \\[\n\\boxed{\nf(k) = \\int_{-\\infty}^\\infty dx \\ f(x) e^{-i k x}\n} \\ .\n\\] This function \\(f(k)\\) is called the Fourier transform of \\(f(x)\\). It’s common to denote the operator that transforms \\(f(x)\\) into \\(f(k)\\) by \\(\\mathcal{F}\\), and also write \\(f(k) = \\mathcal{F}[f(x)](k)\\) as a shorthand for the integral defined above.\nThe function \\(f(k)\\) is defined on the whole real line, but in a different space, known as \\(k\\)-space or frequency space. From dimensional analysis, it’s easy to see that \\(k\\) must have dimensions of \\(\\frac{1}{x}\\), which has units of angular frequency if \\(x\\) is time, and wavenumber if \\(x\\) is position. In this sense, the Fourier transform is an integral transform that converts a function of time into a function of frequency, or a function of position into a function of wavenumber.\nIf we plug \\(f(k)\\) back into the completeness relation, we get another integral that converts \\(f(k)\\) back into \\(f(x)\\), \\[\n\\boxed{\nf(x) = \\int_0^\\infty \\frac{dk}{2\\pi} \\ f(k) e^{ikx}\n}\\ .\n\\] This function is known as the inverse Fourier transform. This transform can be thought of as the inverse operator to the Fourier transform operator \\(\\mathcal{F}\\). We thus denote it by \\(\\mathcal{F}^{-1}\\), and write \\(f(x) = \\mathcal{F}^{-1}[f(k)](x)\\). The inverse Fourier transform takes a function defined in \\(k\\)-space, and converts it back into a function in ordinary space. That is, it converts a function of frequency back into a function of time, or a function of wavenumber back into a function of position.\n\n\nOrthogonality\nThe complex integrals \\(e^{ikx}\\) are still orthogonal in the continuum limit, except in a slightly different sense. We can define a set of basis functions \\(f_k(x)\\) by \\[\nf_k(x) \\equiv \\frac{1}{2\\pi} e^{ikx} \\ .\n\\] Notice that this set of functions is now indexed by a continuous parameter \\(k\\) instead of a discrete number \\(n\\). If we take \\(L \\rightarrow \\infty\\) and consider the inner product \\(\\langle f_{k'} | f_k \\rangle\\), we evidently have \\[\n\\langle f_{k'} | f_k \\rangle = \\int_{-\\infty}^\\infty dx \\ f_k^*(x) f_{k'}(x) = \\frac{1}{2\\pi} \\int_{-\\infty}^\\infty \\frac{dx}{2\\pi} \\ e^{i(k-k')x} = \\frac{1}{2\\pi} \\delta(k-k') \\ .\n\\] When \\(k \\neq k'\\) we see that \\(\\langle f_{k'} | f_k \\rangle = 0\\), which means \\(f_{k'}(x)\\) and \\(f_k(x)\\) are orthogonal. But when \\(k=k'\\) we have something new. Instead of the inner product being some number, it’s now infinite. Nevertheless, we can think of this as defining an orthogonality relation for a continuous set of basis functions, with Kronecker deltas \\(\\delta_{nn'}\\) replaced by Dirac deltas \\(\\delta(k-k')\\).\nIf we ignore the delta function though, we can see that the basis functions are no longer normalized, since \\(\\langle f_{k'} | f_k \\rangle \\sim \\frac{1}{2\\pi} \\neq 1\\). We could normalize them if we wanted to by redefining \\(f_k(x) \\equiv \\frac{1}{\\sqrt{2\\pi}} e^{ikx}\\), but then we’d end up with a slightly different definition of the Fourier transform. This normalized version of the Fourier transform is usually chosen in quantum mechanics, but rarely in electromagnetism or other fields of physics, so we won’t use it in this course.\n\n\nProperties\nThe Fourier transform turns out to be a very powerful operation. Much of its utility comes from the properties it satisfies. Before listing these, it’s worth introducing the useful notation \\(f(x) \\leftrightarrow f(k)\\) as a shorthand for the much more cumbersome notation \\(\\mathcal{F}[f(x)](k) = f(k)\\). Think of the \\(\\leftrightarrow\\) symbol as meaning “is the Fourier duel of”, in the sense that the relations on both sides are related by a Fourier transform.\nFrom the definition, it’s easy to see that the Fourier transform satisfies the following properties:\n\nLinearity: \\(af(x) + bg(x) \\leftrightarrow af(k) + bg(k)\\).\nScaling: \\(f(\\alpha x) \\leftrightarrow \\frac{1}{|\\alpha|} f\\big(\\frac{k}{\\alpha}\\big)\\).\nTranslation: \\(f(x-x') \\leftrightarrow e^{ikx'} f(k)\\).\nReversal: \\(f(-x) \\leftrightarrow f(-k)\\).\nComplex Conjugation: \\(f^*(x) \\leftrightarrow f^*(k)\\).\n\n\nExample: Fourier transform of a Gaussian\nLet’s briefly work an example to show how one can use these properties to calculate Fourier transforms. Consider the function \\[\nf(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\bigg[-\\frac{1}{2\\sigma^2} (x-\\mu)^2\\bigg] \\ .\n\\] This function describes the probability density function of a Gaussian distributed random variable with mean \\(\\mu\\) and variance \\(\\sigma^2\\).\nUsing the linearity, scaling, and translation properties of the Fourier transform together, we must have \\[\nf(k) = \\frac{e^{ik\\mu}}{\\sqrt{2\\pi\\sigma^2}} \\mathcal{F}\\big[e^{-x^2/2\\sigma^2}\\big](k) = \\frac{1}{\\pi} e^{ik\\mu} \\mathcal{F}\\big[e^{-x^2}\\big](\\sqrt{2}\\sigma k) \\ .\n\\] All that remains then is to find the transform of \\(g(x) \\equiv e^{-x^2}\\). We can do this by completing the square and integrating to get $$ \\[\\begin{align*}\ng(k) &= \\int_{-\\infty}^\\infty dx \\ g(x) e^{-ikx} \\\\\n&= \\int_{-\\infty}^\\infty dx \\ e^{-x^2} e^{-ikx} \\\\\n&= \\int_{-\\infty}^\\infty dx \\ e^{-(x-ik/2)^2} \\\\\n&= \\sqrt{\\pi} e^{-k^2/4} \\ .\n\n\\end{align*}\\] \\[\nPutting these results together, we finally have\n\\] f(k) = e^{ik} e{-2 k^2/2} = e{-2/2^2}  . $$ Thus, the Fourier transform of a Gaussian is evidently just another Gaussian, except with a complex mean \\(\\frac{i\\mu}{\\sigma^2}\\) and a variance \\(\\frac{1}{\\sigma^2}\\) in \\(k\\)-space. This means that the more spread out \\(f(x)\\) is, the less spread out \\(f(k)\\) will be, and vice versa. This essentially follows from the scaling property of the Fourier transform, which sends a function \\(f(\\sigma x)\\) to a function \\(f(k/\\sigma)\\).\nThe class of Gaussian functions is unique in the sense that they’re the fixed points of the Fourier transform operator, meaning the Fourier transform of a Gaussian will always be another Gaussian. This fact is used in quantum mechanics for formalize the idea of a wave packet, which formalizes the sense in which particles and waves are related.\n\nA few more important properties are worth mentioning as well, but these aren’t as easy to see. First, suppose we have some function \\(h(x)\\) that’s a convolution of two other functions \\(f(x)\\) and \\(g(x)\\), i.e. \\[\nh(x) = (f \\ast g)(x) \\equiv \\int_{-\\infty}^\\infty dx' \\ f(x') g(x-x') \\ .\n\\] If we take the Fourier transform of both sides, interchange integrals, and substitute \\(u=x-x'\\), we get \\[\n\\begin{align*}\nh(k) &= \\int_{-\\infty}^\\infty dx \\bigg(\\int_{-\\infty}^\\infty dx' \\ f(x') g(x-x')\\bigg) e^{-ikx} \\\\\n&= \\int_{-\\infty}^\\infty dx' \\ f(x') \\int_{-\\infty}^\\infty dx \\ g(x-x') e^{-ikx} \\\\\n&= \\int_{-\\infty}^\\infty dx' \\ f(x') e^{-ikx'} \\int_{-\\infty}^\\infty du \\ f(u) e^{-iku} \\\\\n&= f(k) g(k) \\ .\n\\end{align*}\n\\] We’ve thus shown that the Fourier transform converts convolutions in \\(x\\)-space to products in \\(k\\)-space, with \\[\n(f \\ast g)(x) \\leftrightarrow f(k) g(k) \\ .\n\\] By following the exact same argument starting with \\(h(k) \\equiv (f \\ast g)(k)\\) and taking its inverse Fourier transform, one can show that the Fourier transform converts products in \\(x\\)-space into convolutions in \\(k\\)-space, with \\[\nf(x) g(x) \\leftrightarrow \\frac{1}{2\\pi} (f \\ast g)(k) \\ .\n\\] The next non-trivial property of the Fourier transform is that it preserves the inner product of functions in a sense. Suppose \\(f(x)\\) and \\(g(x)\\) are two functions with an inner product \\(\\langle f | g \\rangle_x\\) in \\(x\\)-space and an inner product \\(\\langle f | g \\rangle_k\\) in \\(k\\)-space. Then \\[\n\\langle f | g \\rangle_x = \\frac{1}{2\\pi} \\langle f | g \\rangle_k \\ .\n\\] This result is known as Parseval’s Theorem. To prove this theorem, we start with the inner product \\(\\langle f | g \\rangle_x\\), take the inverse Fourier transform of \\(f(x)\\) and \\(g(x)\\), and then interchange the \\(x\\) and \\(k\\) integrals to get a delta function. We get \\[\n\\begin{align*}\n\\int_{-\\infty}^\\infty dx \\ f^*(x) g(x) &= \\int_{-\\infty}^\\infty dx \\ \\mathcal{F}^{-1}[f^*(k')](x) \\cdot \\mathcal{F}^{-1}[g(k)](x) \\\\\n&= \\int_{-\\infty}^\\infty dx \\ \\int_{-\\infty}^\\infty \\frac{dk'}{2\\pi} \\ f^*(k') e^{-ik'x} \\int_{-\\infty}^\\infty \\frac{dk}{2\\pi} \\ g(k) e^{ikx} \\\\\n&= \\int_{-\\infty}^\\infty \\frac{dk'}{2\\pi} \\ f^*(k') \\int_{-\\infty}^\\infty \\frac{dk}{2\\pi} \\ g(k) \\int_{-\\infty}^\\infty dx \\ e^{i(k-k')x} \\\\\n&= \\int_{-\\infty}^\\infty \\frac{dk'}{2\\pi} \\ f^*(k') \\int_{-\\infty}^\\infty \\frac{dk}{2\\pi} \\ g(k) \\delta(k-k') \\\\\n&= \\frac{1}{2\\pi} \\int_{-\\infty}^\\infty dk \\ f^*(k) g(k) \\ .\n\\end{align*}\n\\] We’ve thus shown what we wanted to prove, i.e. that \\(\\langle f | g \\rangle_x = \\frac{1}{2\\pi} \\langle f | g \\rangle_k\\). An immediate corollary to this result is that the Fourier transform preserves the norm of a function (up to a factor of \\(2\\pi\\)), with \\(||f||_x^2 = \\frac{1}{2\\pi} ||f||_k^2\\). If \\(f(x)\\) represents some time-varying signal, we can think of \\(||f||^2\\) as representing the energy of the signal. Parseval’s theorem says that we can calculate this energy in either \\(x\\)-space or \\(k\\)-space and get the same result, up to a constant. We can use this fact, for example, to calculate the energy output of an electromagnetic wave, which we will in this course.\nThe last non-trivial property of the Fourier transform is how it transforms differentiation operators. Suppose we take the Fourier transform of the first derivative of some function \\(f(x)\\). We can use integration by parts to move the derivate off of \\(f(x)\\) onto the complex exponential, which is easy to differentiate. Observe \\[\n\\begin{align*}\n\\mathcal{F} \\bigg[\\frac{d}{dx} f(x)\\bigg](k) &= \\int_{-\\infty}^\\infty dx \\ \\frac{df}{dx} e^{-ikx} \\\\\n&= f(x) e^{ikx} \\bigg|_{x=-\\infty}^{x=\\infty} - \\int_{-\\infty}^\\infty dx \\ f(x) \\frac{d}{dx} e^{-ikx} \\\\\n&= f(x) e^{ikx} \\bigg|_{x=-\\infty}^{x=\\infty} - ik \\int_{-\\infty}^\\infty dx \\ f(x) e^{-ikx} \\\\\n&= f(x) e^{ikx} \\bigg|_{x=-\\infty}^{x=\\infty} - ikf(k) \\ .\n\\end{align*}\n\\] Provided \\(f(x)\\) goes to zero at \\(\\pm \\infty\\) the boundary terms vanish, and we end up with the useful relation \\[\n\\frac{d}{dx} f(x) \\leftrightarrow -ik f(k) \\ .\n\\] Thus, the Fourier transform converts derivatives in \\(x\\)-space into algebraic functions in \\(k\\)-space. By successive application of this rule, it’s easy to see that the \\(n\\)th derivative transforms as \\[\n\\frac{d^n}{dx^n} f(x) \\leftrightarrow (-ik)^n f(k) \\ .\n\\] This property of the Fourier transform turns out to be extremely useful for solving differential equations. particularly partial differential equations in both space and time. If we can use the Fourier transform to deal with the spatial derivatives, we end up with a differential equation in \\(k\\)-space that depends only on time derivatives, which is often easier to solve. Here’s an example.\n\n\nExample: Wave equation in one dimension\nConsider the following time-dependent initial value problem in one spatial dimension, \\[\n\\begin{cases}\n\\frac{\\partial^2 u}{\\partial x^2} = \\frac{1}{c^2} \\frac{\\partial^2 u}{\\partial t^2} \\ , \\\\\nu(x,0) = \\delta(x) \\ , \\\\\n\\frac{\\partial}{\\partial t} u(x,0) = 0 \\ .\n\\end{cases}\n\\] This problem can be used to model a wave \\(u(x,t)\\) propagating along the \\(x\\)-axis at a constant speed \\(c\\), where an impulse response is applied at the origin at time \\(t=0\\) and there is initially no wave propagation taking place before the impulse. The second order PDE is called the wave equation in one-dimension. We’ll see wave equations a lot in this course. The goal of this problem is of course to solve this problem for the wavefunction \\(u(x,t)\\).\nNow, let’s take the Fourier transform of both sides of the wave equation with respect to \\(x\\) only, leaving \\(t\\) alone, \\[\n\\mathcal{F} \\bigg[\\frac{\\partial^2 u}{\\partial x^2}\\bigg](k,t) = \\mathcal{F}\\bigg[\\frac{1}{c^2} \\frac{\\partial^2 u}{\\partial t^2}\\bigg](k,t) \\ .\n\\] The left-hand side involves a second derivative in \\(x\\), so its Fourier transform will be \\(-k^2 u(k,t)\\). The right-hand side involves a constant times a second derivative in \\(t\\). Since we’re taking the transform with respect to \\(x\\), we can treat the time derivative as essentially a constant, and so by linearity the right-hand side will be \\(\\frac{1}{c^2} \\partial_t^2 u(k,t)\\). Setting both sides must equal and multiplying through by \\(c^2\\), we thus have \\[\n-c^2 k^2 u(x,t) = \\frac{\\partial^2}{\\partial t^2} u(k,t) \\ .\n\\] We’ve thus used the Fourier transform to eliminate the derivatives in \\(x\\). All that remains now is a second derivative in \\(t\\), which we can easily solve for \\(u(k,t)\\). This is just a simple harmonic oscillator with general solution \\[\nu(k,t) = a \\cos ckt + b \\sin ckt \\ .\n\\] Now we need to deal with the initial conditions. Since we’re working in \\(k\\)-space, we need to Fourier transform the initial conditions first. It’s easy to see that \\[\n\\begin{align*}\n&u(k,0) = \\mathcal{F}[\\delta(x)](k) = 1 \\ , \\\\\n&\\frac{\\partial}{\\partial t} u(k,0) = \\mathcal{F}[0](k) = 0 \\ .\n\\end{align*}\n\\] Plugging these initial conditions into the general solution, we end up with \\[\nu(k,t) = \\cos ckt = \\frac{1}{2} \\big[e^{ickt} + e^{-ickt}\\big] \\ .\n\\] Here we wrote \\(\\cos ckt\\) in terms of complex exponentials to make the next step easier. Now, we have a solution in terms of \\(k\\) and \\(t\\), but we need a solution in terms of \\(x\\) and \\(t\\). To get \\(u(x,t)\\) we need to take the inverse Fourier transform of \\(u(k,t)\\). Plugging the general solution above into the inverse Fourier transform, we have \\[\n\\begin{align*}\nu(x,t) &= \\int_{-\\infty}^\\infty \\frac{dk}{2\\pi} \\ u(k,t) e^{ikx} \\\\\n&= \\frac{1}{2} \\int_{-\\infty}^\\infty \\frac{dk}{2\\pi} \\ \\big[e^{ickt} + e^{-ickt}\\big] e^{ikx} \\\\\n&= \\frac{1}{2} \\bigg[\\int_{-\\infty}^\\infty \\frac{dk}{2\\pi} \\ e^{ik(x+ct)} + \\int_{-\\infty}^\\infty \\frac{dk}{2\\pi} \\ e^{ik(x-ct)} \\bigg] \\\\\n&= \\frac{1}{2} \\big[\\delta(x+ct) + \\delta(x-ct) \\big] \\ .\n\\end{align*}\n\\] In the last step we use the definition of the delta function to evaluate the two integrals. We thus finally end up with a general solution in ordinary space of the form \\[\nu(x,t) = \\frac{1}{2} \\big[\\delta(x+ct) + \\delta(x-ct) \\big] \\ .\n\\] Incidentally, we can use this solution derived for an impulse response to get the solution for any wave generated by some arbitrary response \\(f(x)\\) at the origin simply by convolving \\(f(x)\\) with the two delta functions above. We end up with \\[\nu(x,t) = \\frac{1}{2} \\big[f(x+ct) + f(x-ct) \\big] \\ .\n\\] Physically, this solution says that a response at the origin will give rise to two traveling waves each propagating out from the origin at a constant speed \\(c\\), one in the positive direction and another in the negative direction.\n\n\n\nHigher Dimensions\nThe Fourier transform extends easily into higher dimensions as well. Suppose \\(f(\\mathbf{x})\\) is a function of an \\(n\\)-dimensional vector \\(\\mathbf{x}\\) with Cartesian coordinates \\((x_1,x_2,\\cdots,x_n)\\). Suppose we took the Fourier transform of the first coordinate \\(x_1\\) and left the other coordinates alone. Then we’d end up with a function \\(f(k_1,x_2,\\cdots,x_n)\\) of the form \\[\nf(k_1,x_2,\\cdots,x_n) = \\int_{-\\infty}^\\infty dx_1 \\ f(x_1,x_2,\\cdots,x_n) e^{-i k_1 x_1} \\ .\n\\] We could now take the Fourier transform of this function with respect to the second coordinate \\(x_2\\), in which case we’d end up with another function \\(f(k_1,k_2,\\cdots,x_n)\\) of the form \\[\n\\begin{align*}\nf(k_1,k_2,\\cdots,x_n) &= \\int_{-\\infty}^\\infty dx_2 \\ f(k_1,x_2,\\cdots,x_n) e^{-i k_2 x_2} \\\\\n&= \\int_{-\\infty}^\\infty dx_2 \\bigg(\\int_{-\\infty}^\\infty dx_1 \\ f(x_1,x_2,\\cdots,x_n) e^{-i k_1 x_1}\\bigg) e^{-i k_2 x_2} \\\\\n&= \\int_{-\\infty}^\\infty dx_1 \\ \\int_{-\\infty}^\\infty dx_2 \\ f(x_1,x_2,\\cdots,x_n) e^{-i(k_1 x_1+k_2 x_2)} \\ .\n\\end{align*}\n\\] We can repeat this until we’ve taken the Fourier transform of the last coordinate \\(x_n\\) to end up with a function \\(f(k_1,k_2,\\cdots,k_n)\\) that’s only a function of the \\(k\\)-space coordinates \\((k_1,k_2,\\cdots,k_n)\\). If we call the vector of \\(k\\)-space coordinates \\(\\mathbf{k}\\), we can write \\[\n\\boxed{\nf(\\mathbf{k}) = \\int d^n\\mathbf{x} \\ f(\\mathbf{x}) e^{-i \\mathbf{k} \\cdot \\mathbf{x}}\n} \\ ,\n\\] where the integral is taken over all \\(n\\)-dimensions of space. This is called the \\(n\\)-dimensional Fourier transform. Notice all we’re doing is repeatedly applying Fourier transform operators on each coordinate one-by-one. If we let \\(\\mathcal{F}_i\\) denote the Fourier transform operator of the \\(i\\)th coordinate and \\(\\mathcal{F}^{(n)}\\) denote the \\(n\\)-dimensional Fourier transform, we can write \\[\n\\mathcal{F}^{(n)}[f(\\mathbf{x})](\\mathbf{k}) = \\mathcal{F}_1 \\mathcal{F}_2 \\cdots \\mathcal{F}_n [f(\\mathbf{x})](\\mathbf{k}) \\ .\n\\] We can do the exact same thing for the inverse Fourier transform, by starting with \\(f(k_1,k_2,\\cdots,k_n)\\) and take the inverse transform of each coordinate \\(k_i\\) one by one. We end up with \\[\n\\boxed{\nf(\\mathbf{x}) = \\int \\frac{d^n\\mathbf{k}}{(2\\pi)^n} \\ f(\\mathbf{k}) e^{i \\mathbf{k} \\cdot \\mathbf{x}}\n} \\ ,\n\\] where again the integral is taken over all \\(n\\)-dimensions of \\(k\\)-space. This is the \\(n\\)-dimensional inverse Fourier transform. Perhaps the main thing to be aware of here is that each dimension contributes its own factor of \\(2\\pi\\) in the integral. We can express this integral relation equivalently in terms of Fourier transform operators by writing \\[\n\\big(\\mathcal{F}^{(n)}\\big)^{-1}[f(\\mathbf{k})](\\mathbf{x}) = \\mathcal{F}_1^{-1} \\mathcal{F}_2^{-1} \\cdots \\mathcal{F}_n^{-1} [f(\\mathbf{k})](\\mathbf{x}) \\ .\n\\] It’s not hard to see that these higher-dimensional Fourier transforms will also be invertible, and satisfy similar properties and orthogonality relations to the ordinary Fourier transform. For instance, the derivative property carries over. This means, for example, that the Fourier transform of the Laplacian \\(\\nabla^2\\) is simply \\(-|\\mathbf{k}|^2\\) in \\(k\\)-space, \\[\n\\nabla^2 f(\\mathbf{x}) \\leftrightarrow -|\\mathbf{k}|^2 f(\\mathbf{k}) \\ .\n\\] We can use this fact to solve many linear PDEs of interest in higher dimensions, including Poisson’s equation and the Helmholtz equation. We’ll see this done in detail in other chapters in the course.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Appendix I: Orthogonal Functions</span>"
    ]
  },
  {
    "objectID": "electrodynamics/orthogonal-functions.html#legendre-polynomials",
    "href": "electrodynamics/orthogonal-functions.html#legendre-polynomials",
    "title": "Appendix I: Orthogonal Functions",
    "section": "Legendre Polynomials",
    "text": "Legendre Polynomials\nWe’ll now look at another class of orthogonal functions known as the Legendre polynomials. The Legendre polynomials arise in physics primarily when trying working with the Laplacian in spherical coordinates.\nThere are several ways one can define these polynomials. To keep the math as simple as possible we’ll define these via a generating function. A generating function for a set of functions \\(f_n(x)\\) is any function \\(g(x,t)\\) such that \\[\ng(x,t) = \\sum_n f_n(x) t^2 \\ .\n\\] In our case, we’ll define a generating function of the form \\[\ng(x,t) \\equiv \\frac{1}{\\sqrt{1 - 2xt + t^2}} \\ .\n\\] If we expand \\(g(x,t)\\) in a Taylor series in \\(t\\) about \\(t=0\\), we get \\[\ng(x,t) = 1 + xt + \\frac{1}{2} (3x^2 - 1) t^2 + \\frac{1}{2} x(5x^2 - 3) t^3 + \\frac{1}{8} (35x^4 - 30x^2 + 3) t^4 + \\cdots \\ .\n\\] We’ll define the Legendre polynomials as the set of coefficient functions \\(P_n(x)\\) in this series expansion of \\(g(x,t)\\), \\[\ng(x,t) = \\sum_{n=0}^\\infty P_n(x) t^n \\ .\n\\] Matching coefficients from the two series expansions, the first few Legendre polynomials are evidently \\[\n\\begin{align*}\nP_0(x) &= 1 \\ , \\\\\nP_1(x) &= x \\ , \\\\\nP_2(x) &= \\frac{1}{2} (3x^2 - 1) \\ , \\\\\nP_3(x) &= \\frac{1}{2} x(5x^2 - 3) \\ , \\\\\nP_4(x) &= \\frac{1}{8} (35x^4 - 30x^2 + 3) \\ , \\\\\nP_5(x) &= \\frac{1}{8} (63x^5 - 70x^3 + 15x) \\ .\n\\end{align*}\n\\] As the name suggests, the Legendre polynomials are all polynomials, with each \\(P_n(x)\\) being a polynomial of degree \\(n\\). We can see a plot of the first few polynomials in the figure below.\n\n\n\n\n\nNotice that \\(P_n(x)\\) is odd when \\(n\\) is odd, and even when \\(n\\) is even. That is, \\(P_n(x)\\) satisfies the parity relation \\[\nP_n(-x) = (-1)^n P_n(x) \\ .\n\\] This can also be easily seen from the generating function by expanding \\(g(-x,t)\\) and getting an alternating series. We can also see that \\(P_n(1) = 1\\), which immediately implies that \\(P_n(-1) = (-1)^n\\) from the parity relation.\n\nProperties\nBy using the binomial theorem to expand \\(g(x,t)\\) in powers of \\(2xt-t^2\\) and collecting terms, it’s not too hard to show that \\[\nP_n(x) = \\sum_{j=0}^{\\lfloor n/2 \\rfloor} (-1)^j \\frac{(2n-2j)!}{2^n j! (n-2j)! (n-j)!} x^{n-2j} \\ .\n\\] Through some manipulation, we can re-write this series expression in a different form by differentiating \\(n\\) times to get \\[\nP_n(x) = \\frac{1}{2^n n!} \\frac{d^n}{dx^n} \\sum_{j=0}^{n} \\frac{(-1)^j n!}{j! (n-j)!} x^{2n-2j} \\ .\n\\] Now, notice the sum is just the binomial expansion of \\((x^2-1)^n\\). This means we have \\[\n\\boxed{\nP_n(x) = \\frac{1}{2^n n!} \\frac{d^n}{dx^n} (x^2 - 1)^n\n}\\ .\n\\] This formula is called the Rodrigues’ Formula. Among other uses, it’s perhaps one of the easier ways to find \\(P_n(x)\\) in practice.\nWe’ll now define several useful recursive relations for the Legendre polynomials, which will be useful later on. Notice if we differentiate the generating function \\(g(x,t)\\) with respect to \\(x\\) and \\(t\\) that we get \\[\n\\begin{align*}\n\\frac{\\partial g}{\\partial x} &= \\frac{t}{(1 - 2xt + t^2)^{3/2}} = \\frac{t g(x,t)}{1 - 2xt + t^2} = \\sum_n \\frac{dP_n}{dx} t^n \\ , \\\\\n\\frac{\\partial g}{\\partial t} &= \\frac{x-t}{(1 - 2xt + t^2)^{3/2}} = \\frac{(x-t) g(x,t)}{1 - 2xt + t^2} = \\sum_n n P_n(x) t^{n-1} \\ .\n\\end{align*}\n\\] By collecting terms in the series and requiring the coefficient of each power of \\(t\\) to independently vanish, one can show that we get the following recursive relations, \\[\n\\begin{align*}\n(2n+1) x P_n(x) &= (n+1) P_{n+1}(x) + n P_{n-1}(x) \\ , \\\\\n\\frac{d}{dx} P_{n+1}(x) + \\frac{d}{dx} P_{n-1} &= 2x \\frac{d}{dx} P_n(x) + P_n(x) \\ , \\\\\n\\frac{d}{dx} P_{n+1}(x) - \\frac{d}{dx} P_{n-1} &= (2n+1) P_n(x) \\ .\n\\end{align*}\n\\] We can then combine these relations together to get two more useful relations, \\[\n\\begin{align*}\n(1 - x^2) \\frac{d}{dx} P_n(x) &= n P_{n-1}(x) - n x P_n(x) \\ , \\\\\n\\frac{d}{dx} P_{n-1}(x) &= -n P_n(x) + x \\frac{d}{dx} P_n(x) \\ .\n\\end{align*}\n\\] Now, we can differentiate the first equation and use the second equation to eliminate \\(\\frac{d}{dx} P_{n-1}(x)\\). We then get \\[\n\\boxed{\n(1 - x^2) \\frac{d^2}{dx^2} P_n(x) - 2x \\frac{d}{dx} P_n(x) + n(n+1) P_n(x) = 0\n} \\ .\n\\] This differential equation is known as the Legendre equation. It turns out to be very important as we’ll see in the next section.\n\n\nOrthogonality\nThe Legendre polynomials turn out to provide a complete orthogonal set of functions on the interval \\(-1 \\leq x \\leq 1\\). To see that, we need only place Legendre’s equation into Sturm-Liouville form. Observe we can write this equation in the form \\[\n-\\frac{d}{dx} \\bigg((1-x^2)\\frac{df}{dx}\\bigg) = n(n+1) f(x) \\ .\n\\] This is a valid Sturm-Liouville form, with \\(p(x) = 1-x^2\\), \\(q(x) = 0\\), and \\(w(x) = 1\\). The eigenvalues are \\(\\lambda_n = n(n+1)\\).\nWhat about the boundary conditions though? It turns out that we don’t need to specify in boundary conditions in this case. Notice that \\(p(-1) = p(1) = 0\\). This means the boundary terms will vanish in the self-adjoint condition, so long as \\(f(x)\\) is finite at \\(x=\\pm 1\\), which will clearly be the case since each \\(P(x)\\) is a polynomial.\nWe can clearly see then that the Legendre polynomials solve this Sturm-Liouville problem with eigenvalues \\(\\lambda_n = n(n+1)\\). Since the Legendre polynomials satisfy a Sturm-Liouville problem, we know they must form a complete orthogonal set of functions on the interval \\(-1 \\leq x \\leq 1\\). This means we can expand any function \\(f(x)\\) on this interval in terms of them, as \\[\nf(x) = \\sum_{n=0}^\\infty c_n P_n(x) \\ .\n\\] This series expansion for \\(f(x)\\) is sometimes called a Legendre series, or a Fourier-Legendre series.\nWe still don’t know though whether the Legendre polynomials are normalized. Since evaluating the inner product is too cumbersome, we’ll again appeal to the generating function for this. Notice if we square \\(g(x,t)\\) and integrate over the interval with a change of variable \\(u = 1 - 2tx + t^2\\), we get \\[\n\\int_{-1}^1 \\frac{dx}{1 - 2tx + t^2} = \\frac{1}{2t} \\int_{(1-t)^2}^{(1+t)^2} \\frac{du}{u} = \\frac{1}{t} \\log \\frac{1+t}{1-t} \\ .\n\\] Since we can expand \\(g(x,t)\\) as a series of Legendre polynomials, we also must have \\[\n\\int_{-1}^1 dx \\ \\bigg(\\sum_n P_n(x) t^n \\bigg)^2 = \\sum_n t^{2n} \\int_{-1}^1 dx \\ \\big(P_n(x)\\big)^2 \\ .\n\\] Expanding the logarithm and equating the two series, we get \\[\n\\frac{1}{t} \\log \\frac{1+t}{1-t} = \\sum_n \\frac{2t^{2n}}{2n+1} = \\sum_n t^{2n} \\int_{-1}^1 dx \\ \\big(P_n(x)\\big)^2 \\ .\n\\] This means at each power \\(t^{2n}\\) we must have \\[\n\\langle P_n | P_n \\rangle = \\int_{-1}^1 dx \\ \\big(P_n(x)\\big)^2 = \\frac{2}{2n+1} \\ .\n\\] Thus, the Legendre polynomials aren’t quite normalized. Instead we have the orthogonality condition \\[\n\\boxed{\n\\langle P_k | P_n \\rangle = \\frac{2}{2n+1} \\delta_{kn}\n}\\ .\n\\] This means the coefficients in the orthogonal expansion are given in the usual way by \\[\nc_n = \\bigg(\\frac{2n+1}{2}\\bigg) \\int_{-1}^1 dx \\ f(x) P_n(x) \\ .\n\\] Let’s now work a relatively simple example.\n\nExample: Legendre Series of a Step Function\nLet’s calculate the Legendre series expansion for the following step function defined on \\(-1 \\leq x \\leq 1\\), \\[\nf(x) = \\begin{cases}\n-1 & -1 \\leq x &lt; 0 \\ , \\\\\n1 & 0 &lt; x \\leq 1 \\ .\n\\end{cases}\n\\] We insist the function has a Legendre series of the form \\[\nf(x) = \\sum_{n=0}^\\infty c_n P_n(x) \\ .\n\\] To calculate the coefficients \\(c_n\\), we use the formula \\[\nc_n = \\frac{\\langle P_n | f \\rangle}{\\langle P_n | P_n \\rangle} = \\bigg(\\frac{2n+1}{2}\\bigg) \\int_{-1}^1 dx \\ f(x) P_n(x) \\ .\n\\] Plugging in \\(f(x)\\), we then have \\[\nc_n = \\bigg(\\frac{2n+1}{2}\\bigg) \\bigg[\\int_0^1 dx \\ P_n(x) - \\int_{-1}^0 dx \\ P_n(x)\\bigg] \\ .\n\\] Now, observe that since \\(P_0(x) = 1\\), we can use the orthogonality relation to write \\[\n\\int_{-1}^1 dx \\ P_n(x) = \\int_{-1}^1 dx \\ P_n(x) P_0(x) = \\frac{2}{2n+1} \\delta_{n0} \\ .\n\\] In particular, this means this integral will vanish whenever \\(n \\neq 0\\). Since \\(P_n(-x) = (-1)^n P_n(x)\\), we know that \\(P_n(x)\\) will be an odd function when \\(n\\) is odd, and even when \\(n\\) is even. This means when \\(n \\geq 1\\) we have \\[\n\\int_{-1}^0 dx \\ P_n(x) = \\begin{cases}\n-\\int_0^1 dx \\ P_n(x) & n=1,3,5,\\cdots \\ , \\\\\n\\int_0^1 dx \\ P_n(x) & n=2,4,6,\\cdots \\ .\n\\end{cases}\n\\] Plugging this into the expression for \\(c_n\\), this means that the even coefficients must vanish, while the odd coefficients satisfy \\[\nc_n = (2n+1) \\int_0^1 dx \\ P_n(x) \\ .\n\\] To evaluate this integral we can use one of the recursive relations we found before, \\[\n(2n+1) P_n(x) = \\frac{d}{dx} P_{n+1}(x) - \\frac{d}{dx} P_{n-1} \\ .\n\\] Notice if we integrate both sides of this relation from \\(0\\) to \\(1\\) the left-hand side becomes \\(c_n\\), and so we get \\[\nc_n = \\big[P_{n+1}(x) - P_{n-1}(x)\\big]_{x=0}^{x=1} = P_{n-1}(0) - P_{n+1}(0) \\ .\n\\] Here we used the fact that \\(P_{n+1}(1) = P_{n-1}(1) = 1\\) to eliminate one term. What’s left is a difference of two even Legendre polynomials evaluated at \\(x=0\\). We can determine these values by setting \\(x=0\\) and expanding the generating function \\(g(x,t)\\) to get a binomial expansion of the form \\[\ng(0,t) = \\frac{1}{\\sqrt{1 + t^2}} = \\sum_{k=0}^\\infty \\frac{(-1)^k}{2^{2k}} \\frac{(2k)!}{(k!)^2} t^{2k} = 1 - \\frac{1}{2} t^2 + \\frac{3}{8} t^4 - \\frac{5}{16} t^6 + \\cdots \\ .\n\\] The coefficients in this expansion must evidently be the Legendre polynomials \\(P_{2k}(0)\\). Plugging this back into \\(c_n\\) and simplifying a bit, we get \\[\nc_n = \\bigg(\\frac{-1}{2}\\bigg)^{\\frac{n-1}{2}} \\frac{(2n+1)(n-2)!!}{2\\big(\\frac{n+1}{2}!\\big)^2} \\quad , \\quad n=1,3,5,\\cdots \\ .\n\\] Finally, plugging these coefficients back into the Legendre series, we get the expansion we seek, \\[\nf(x) = \\sum_{n=1,3,\\cdots}^\\infty \\bigg(\\frac{-1}{2}\\bigg)^{\\frac{n-1}{2}} \\frac{(2n+1)(n-2)!!}{2\\big(\\frac{n+1}{2}!\\big)^2} P_n(x) = \\frac{3}{2} P_1(x) - \\frac{7}{8} P_3(x) + \\frac{11}{16} P_5(x) - \\cdots \\ .\n\\] To visually verify that this expansion is sensible, we show a plot below of the series approximations for different partial sums \\(S_N\\), for \\(N=3,5,7,99\\). Notice again as \\(N\\) increases that the expansion gets better and better at approximating the step function. Also, similar to what we saw with Fourier series, the expansion doesn’t do well near the discontinuity at \\(x=0\\), even when \\(N=99\\). In fact, the Gibbs phenomenon seems to carry over as well, given we see spikes forming around \\(x=0\\).\n\n\n\n\n\n\n\n\nAssociated Legendre Functions\nWe can define a more general class of Legendre functions by taking Legendre’s equation and differentiating it \\(m\\) times. If we do that, we end up with a differential equation of the form \\[\n(1-x^2) \\frac{d^2g}{dx^2} - 2x (m+1) \\frac{dg}{dx} + (n-m)(n+m+1) g(x) = 0 \\ ,\n\\] where \\(g(x) \\equiv \\frac{d^m}{dx^m} P(x)\\) and \\(P(x)\\) is the solution to the Legendre equation for some fixed \\(n\\).\nAs stated though, this differential equation isn’t in a valid Sturm-Liouville form since the operator isn’t Hermitian. But we can put it into Sturm-Liouville form as follows. We’ll define \\(f(x) \\equiv (1-x^2)^{m/2} g(x)\\). If we solve for \\(g(x)\\) and plug it back into the previous equation, we end up with \\[\n\\boxed{\n(1-x^2) \\frac{d^2 f}{dx^2} - 2x \\frac{df}{dx} + \\bigg(n(n+1) - \\frac{m^2}{1-x^2}\\bigg) f(x) = 0\n}\\ .\n\\] This equation is called the associated Legendre equation. Notice it reduces to the ordinary Legendre equation when \\(m=0\\) as we’d expect. The solutions are given by the associated Legendre functions \\(P_n^m(x)\\) defined by \\[\n\\boxed{\nP_n^m(x) \\equiv (1-x^2)^{m/2} \\frac{d^m}{dx^m} P_n(x)\n}\\ .\n\\] It’s clear that the associated Legendre functions are not in general polynomials due to the \\((1-x^2)^{m/2}\\) factors. It’s also clear that these functions are only defined when \\(m\\) is an integer with \\(m \\leq n\\), since the \\(m\\)th derivatives of \\(P_n(x)\\) will vanish when \\(m &gt; n\\). When \\(m=0\\), we see that these functions reduce to the ordinary Legendre polynomials, with \\(P_n^0(x) = P_n(x)\\).\nIf we plug \\(P_n(x)\\) into the Rodrigues’ formula, we evidently get a similar formula for \\(P_n^m(x)\\) as well, \\[\n\\boxed{\nP_n^m(x) = \\frac{1}{2^n n!} (1-x^2)^{m/2} \\frac{d^{n+m}}{dx^{n+m}} (x^2 - 1)^n\n} \\ .\n\\] From this formula, we see that we can allow \\(m\\) to be negative as well, so long as \\(-n \\leq m \\leq n\\). This means that for each fixed \\(n\\) there will be \\(2n+1\\) associated Legendre functions. We can use this formula to easily calculate the first few associated Legendre functions, a few of which we list below. $$ \\[\\begin{align*}\nP_0^0(x) &= 1 \\ , \\quad\n\n\\begin{cases}\nP_1^{-1}(x) &= \\frac{1}{2} (1-x^2)^{1/2} \\\\\nP_1^0(x)& = x \\\\\nP_1^1(x) &= (1-x^2)^{1/2} \\\\\n\\end{cases} \\ , \\quad\n\n\\begin{cases}\nP_2^{-2}(x) &= \\frac{1}{6} (1-x^2) \\\\\nP_2^{-1}(x) &= -\\frac{1}{2} x (1-x^2)^{1/2}  \\\\\nP_2^0(x) &= \\frac{1}{2} (3x^2-1) \\\\\nP_2^1(x) &= 3x (1-x^2)^{1/2} \\\\\nP_2^2(x) &= 3 (1-x^2) \\\\\n\\end{cases} \\ .\n\\end{align*}\\] $$\nNotice from these first few functions that each \\(P_n^m(x)\\) and \\(P_n^{-m}(x)\\) seem to be proportional. Indeed, using the Leibniz rule it’s not hard to show that they’re always proportional, according to the formula \\[\nP_n^{-m}(x) = (-1)^m \\frac{(n-m)!}{(n+m)!} P_n^m(x) \\ .\n\\] It’s also easy to see that these functions are even when \\(n-m\\) is even and odd when \\(n-m\\) is odd. That is, \\[\nP_n^m(-x) = (-1)^{n-m} P_n^m(x) \\ .\n\\] As with the ordinary Legendre polynomials, we can show that the associated Legendre functions form a complete orthogonal set on the interval \\(-1 \\leq x \\leq 1\\). To do that, we’ll put the associated Legendre equation into standard Sturm-Liouville form to get \\[\n-\\frac{d}{dx} \\bigg((1-x^2) \\frac{df}{dx}\\bigg) + \\frac{m^2}{1-x^2} f(x) = n(n+1) f(x) \\ ,\n\\] with \\(p(x) = 1-x^2\\), \\(q(x) = m^2 (1-x^2)^{-1}\\), and \\(w(x) = 1\\). Notice that the eigenvalues are the same as they were for the ordinary Legendre equation, with \\(\\lambda_n = n(n+1)\\). This means that for each \\(n\\), there will be \\(2n+1\\) possible eigenfunctions, meaning this is a degenerate eigenvalue problem. For distinct \\(n\\) and the same \\(m\\), we can again guarantee from Sturm-Liouville theory that the associated Legendre functions form a complete orthogonal set on the interval \\(-1 \\leq x \\leq 1\\). Indeed, it’s possible to show that \\[\n\\boxed{\n\\langle P_n^m | P_{n'}^m \\rangle = \\frac{2(n+m)!}{(2n+1)(n-m)!} \\delta_{nn'}\n}\\ .\n\\] Though more a mathematical curiosity than practically useful, it turns out that the associated Legendre functions are also orthogonal for fixed \\(n\\) but distinct \\(m\\). This can be done, for instance, by showing that for fixed \\(n\\), each \\(P_n^m(x)\\) can be constructed via the Gram-Schmidt procedure with a weighting function of \\(w(x) = 1-x^2\\). In the end, we end up with the orthogonality relation \\[\n\\langle P_n^m | P_n^{m'} \\rangle =  \\frac{(n+m)!}{m(n-m)!} \\delta_{mm'} \\ .\n\\] Note this relation technically only holds when \\(n \\neq 0\\), since \\(P_0^0(x) = 1\\) implies that \\(\\langle P_0^0 | P_0^0 \\rangle = \\infty\\). Also note that it’s not generally true that any \\(P_n^m(x)\\) will be orthogonal to any \\(P_{n'}^{m'}(x)\\).\nIn electromagnetism, the Legendre polynomials and associated Legendre functions usually appear when trying to perform separation of variables on the Laplacian operator in spherical coordinates. If we do that, we end up needing to solve the differential equation \\[\n\\frac{1}{\\sin\\theta} \\frac{d}{d\\theta} \\bigg(\\sin\\theta \\frac{d}{d\\theta} P(\\cos\\theta) \\bigg) + \\bigg[\\ell (\\ell+1) - \\frac{m^2}{\\sin^2\\theta}\\bigg] P(\\cos\\theta) = 0 \\ .\n\\] It’s easy to see that if we do a change of variables \\(x = \\cos\\theta\\) this equation reduces to the associated Legendre equation. Since \\(-1 \\leq \\cos\\theta \\leq 1\\), we can be sure that it will be defined on the same interval as well. The solutions are thus given by the associated Legendre functions \\(P_\\ell^m(\\cos\\theta)\\). In the special case of azimuthal symmetry we end up with \\(m=0\\), which reduces this equation to the ordinary Legendre equation. In that case the solutions will be given by the Legendre polynomials \\(P_\\ell(\\cos\\theta)\\). We’ll talk more about this in a few sections when we cover the spherical harmonics.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Appendix I: Orthogonal Functions</span>"
    ]
  },
  {
    "objectID": "electrodynamics/orthogonal-functions.html#bessel-functions",
    "href": "electrodynamics/orthogonal-functions.html#bessel-functions",
    "title": "Appendix I: Orthogonal Functions",
    "section": "Bessel Functions",
    "text": "Bessel Functions\nWe’ll now consider a different class of orthogonal functions called Bessel functions. In physics, Bessel functions usually arise when working with the Laplacian in cylindrical coordinates.\nAs with Legendre polynomials, there are any number of ways we can define Bessel functions. We’ll again use the generating function approach since it’s the easiest. Define \\[\ng(x,t) \\equiv e^{xt/2} e^{-x/2t} \\ .\n\\] If we expand each exponential in the usual way we get a product of two sums, \\[\ng(x,t) = \\bigg[\\sum_{j=0}^\\infty \\frac{1}{j!} \\bigg(\\frac{x}{2}\\bigg)^j t^j \\bigg]\\bigg[\\sum_{k=0}^\\infty \\frac{(-1)^k}{k!} \\bigg(\\frac{x}{2}\\bigg)^k t^{-k}\\bigg] = \\sum_{j=0}^\\infty \\sum_{k=0}^\\infty \\frac{(-1)^k}{j!k!} \\bigg(\\frac{x}{2}\\bigg)^{j+k} t^{j-k} \\ .\n\\] Note the second sum isn’t strictly speaking a valid Taylor series expansion since the second term is singular at \\(t=0\\). We can still formally do an expansion of this type formally speaking though by thinking of it as a Laurent series in \\(t\\). We will now change indices by letting \\(n=j-k\\). This means \\(n\\) will now range from \\(-\\infty\\) to \\(\\infty\\), giving \\[\ng(x,t) = \\sum_{n=-\\infty}^\\infty \\bigg[\\sum_{k=0}^\\infty \\frac{(-1)^k}{k!(n-k)!} \\bigg(\\frac{x}{2}\\bigg)^{n+2k}\\bigg] t^n \\ .\n\\] The coefficients in this expansion are called Bessel functions of the first kind, defined by the alternating series above, \\[\nJ_n(x) \\equiv \\sum_{k=0}^\\infty \\frac{(-1)^k}{k!(n-k)!} \\bigg(\\frac{x}{2}\\bigg)^{n+2k} = \\frac{x^n}{2^n n!} - \\frac{x^{n+2}}{2^{n+2}(n+1)!} + \\cdots \\ .\n\\]\nUnfortunately, the Bessel functions do not have a closed form expression, so we can’t easily write down the first few functions like we did the Legendre polynomials. We can still plot them though. Below is a plot of \\(J_n(x)\\) for \\(n=1,\\cdots,5\\).\n\n\n\n\n\n\nProperties\nNotice each of these functions appears to behave like a damped oscillation. Indeed, as \\(x \\rightarrow \\infty\\) it’s possible to show that \\[\nJ_n(x) \\approx \\sqrt{\\frac{2}{\\pi x}} \\bigg[\\cos\\bigg(x - \\bigg(n + \\frac{1}{2}\\bigg)\\frac{\\pi}{2}\\bigg) + O\\bigg(\\frac{1}{x}\\bigg)\\bigg] \\ .\n\\] In the other limit as \\(x \\rightarrow 0\\) it’s easy to see from the series expansion that \\(J_n(x) \\sim x^n\\), which means that \\(J_n(x) \\rightarrow 0\\). The one exception evidently is when \\(n=0\\), in which case \\(J_0(0) = 1\\) exactly. The transition point between the low limit and high limit regimes evidently occurs when \\(x \\sim n\\).\nWe can relate \\(J_n(x)\\) and \\(J_{-n}(x)\\) by taking the series for \\(J_{-n}(x)\\) and changing index to \\(j=k+n\\) to get \\[\nJ_{-n}(x) \\equiv \\sum_{k=0}^\\infty \\frac{(-1)^k}{k!(k-n)!} \\bigg(\\frac{x}{2}\\bigg)^{2k-n} = \\sum_{j=0}^\\infty \\frac{(-1)^{j+n}}{j!(j+n)!} \\bigg(\\frac{x}{2}\\bigg)^{n+2j} \\ .\n\\] Since the sum on the right is just \\((-1)^n J_n(x)\\), we evidently have \\[\nJ_{-n}(x) = (-1)^n J_n(x) \\ .\n\\] This means the negative Bessel functions are just the positive Bessel functions, but with a flipped sign when \\(n\\) is odd. Note this fact is only true when \\(n\\) is an integer, which we’ve implicitly assumed thus far. We’ll come back to non-integer \\(n\\) later.\nAs we did with Legendre polynomials, we can use the partial derivatives of the generating function to derive several useful recursive relations. By differentiating \\(g(x,t)\\) with respect to \\(x\\) and \\(t\\) we get \\[\n\\begin{align*}\n\\frac{\\partial g}{\\partial x} &= \\frac{1}{2} \\bigg(t - \\frac{1}{t}\\bigg) e^{xt/2} e^{-x/2t} = \\frac{1}{2} \\bigg(t - \\frac{1}{t}\\bigg) g(x,t) = \\sum_n \\frac{dJ_n}{dx} t^n \\ , \\\\\n\\frac{\\partial g}{\\partial t} &= \\frac{x}{2} \\bigg(1 + \\frac{1}{t^2}\\bigg) e^{xt/2} e^{-x/2t} = \\frac{x}{2} \\bigg(1 + \\frac{1}{t^2}\\bigg) g(x,t) = \\sum_n nJ_n(x) t^{n-1}  \\ .\n\\end{align*}\n\\] If we now take both derivatives and rearrange terms by powers of \\(t\\) and equate coefficients, we’ll get a recursive relation for each derivative. Those turn out to be \\[\n\\begin{align*}\nJ_{n-1}(x) + J_{n+1}(x) &= \\frac{2n}{x} J_n(x) \\ , \\\\\nJ_{n-1}(x) - J_{n+1}(x) &= 2 \\frac{dJ_n}{dx} \\ .\n\\end{align*}\n\\] If we now add and subtract the two equations and multiple by \\(2\\), we get \\[\n\\begin{align*}\nJ_{n-1}(x) &= \\frac{n}{x} J_n(x) + \\frac{dJ_n}{dx} \\ , \\\\\nJ_{n+1}(x) &= \\frac{n}{x} J_n(x) - \\frac{dJ_n}{dx} \\ .\n\\end{align*}\n\\] If we differentiate the first equation, multiply by \\(x\\), and subtract the second equation, we then get \\[\nx^2 \\frac{d^2 J_n}{dx^2} + x \\frac{dJ_n}{dx} - n^2 J_n(x) + (n-1) x J_{n-1}(x) - x^2 \\frac{dJ_{n-1}}{dx} = 0 \\ .\n\\] If we now take the second equation, multiply by \\(x\\), and shift \\(n\\) to \\(n+1\\), we get \\[\nx \\frac{dJ_{n-1}}{dx} = (n-1) J_{n-1}(x) - x J_n(x) \\ .\n\\] Finally, we can use this equation to eliminate \\(J_{n-1}(x)\\) and \\(\\frac{d}{dx} J_{n-1}(x)\\) from the previous equation to get \\[\n\\boxed{\nx^2 \\frac{d^2 J_n}{dx^2} + x \\frac{dJ_n}{dx} + (x^2-n^2) J_n(x) = 0\n}.\n\\] This second order linear differential equation is known as Bessel’s Equation. For a given \\(n\\) it has a solution given by \\(J_n(x)\\). In fact, since it’s a second order equation it has another solution as well that we’ll come back to.\n\n\nOrthogonality\nWe’d now like to use Bessel’s equation to formulate a Sturm-Liouville problem. However, as stated it’s not quite in a valid Sturm-Liouville form since it lacks an eigenvalue \\(\\lambda\\). To address this issue we’ll instead consider the parametric Bessel equation \\[\nx^2 \\frac{d^2 J}{dx^2} + x \\frac{dJ}{dx} - (\\lambda x^2-n^2) J(x) = 0 .\n\\] The only difference between this equation and Bessel’s equation is the insertion of an eigenvalue \\(\\lambda\\). We can convert this equation into Sturm-Liouville form by dividing both sides by \\(-x\\) and combining derivatives to write \\[\n-\\frac{d}{dx} \\bigg(x \\frac{dJ}{dx}\\bigg) - \\frac{n^2}{x} J(x) = \\lambda xJ(x) \\ .\n\\] This is a valid Sturm-Liouville form with \\(p(x) = x\\), \\(q(x) = -\\frac{n^2}{x}\\), and \\(w(x) = x\\). To impose boundary conditions, we’ll assume that \\(x\\) is defined on some positive interval \\(0 \\leq x \\leq a\\), where \\(a\\) is some parameter. Since \\(p(0) = 0\\), at \\(x=0\\) we need only require that \\(J(x)\\) be finite. At \\(x = a\\) we’ll require that \\(J(a) = 0\\). Taken together, we have a valid Sturm-Liouville problem, which means its solutions will form a complete orthogonal set of functions on the given interval.\nIt’s perhaps not obvious that the Bessel functions \\(J_n(x)\\) will solve this boundary value problem, and indeed they don’t in their current form unless \\(\\lambda = 1\\). But there’s a simple fix. Suppose we change variables \\(x \\rightarrow \\frac{\\lambda}{a} x\\), and consider instead the scaled Bessel functions of the form \\(J_{nm}(x) \\equiv J_n\\big(\\frac{k_{nm}}{a} x\\big)\\) where \\(k_{nm}\\) is some parameter to be determined. If we take these functions and differentiate with respect to \\(x\\), we get \\[\nx^2 \\frac{d^2 J_{nm}}{dx^2} + x \\frac{dJ_{nm}}{dx} - \\bigg(\\frac{k_{nm}^2}{a^2} x^2-n^2\\bigg) J_{nm}(x) = 0 .\n\\] This evidently means the eigenvalues will be given by \\(\\lambda_n = \\frac{k_{nm}^2}{a^2}\\), provided we can find \\(\\omega_{nk}\\). We can do that by imposing the boundary conditions. At \\(x=0\\) we know that \\(J_n(x) \\sim x^n\\) as \\(x \\rightarrow 0\\). Clearly this will be true for \\(J_{nm}(x)\\) as well. This means \\(J_{nm}(x)\\) will be finite at \\(x=0\\), ensuring the first boundary condition holds.\nAt the other endpoint \\(x=a\\) we require that \\(J_{nm}(a) = 0\\). The only way this can be true is if \\(k_{nm}\\) is a root of \\(J_n(x)\\). Since each Bessel function is a damped oscillation, we can be sure it will have infinitely many roots \\(x_{nm}\\), where \\(m=1,2,\\cdots\\). If we set \\(k_{nm} = x_{nm}\\) for any \\(m\\) we can be sure the boundary condition at \\(x=a\\) will be solved.\nNote that the roots of a Bessel function don’t in general have an nice form except for the trivial root at \\(x=0\\). They’re not equally spaced, nor are they the same for different \\(n\\). In practice we have to find these roots numerically for a given \\(J_n(x)\\).\nThus, on the interval \\(0 \\leq x \\leq a\\), we’ve shown that the scaled Bessel functions of the form \\(J_{nm}(x) = J_n\\big(\\frac{x_{nm}}{a} x\\big)\\) solve the parametric Bessel’s equation, and hence a Sturm-Liouville problem. This means that, we immediately know that, for any fixed \\(n\\), any pair of functions \\(J_{nm}(x)\\) and \\(J_{n\\ell}(x)\\) will be orthogonal on the interval \\(0 \\leq x \\leq a\\), with respect to the the weight \\(w(x) = x\\), \\[\n\\langle J_{nm} | J_{n\\ell} \\rangle = \\int_0^a dx \\ x \\ J_n\\bigg(\\frac{x_{nm}}{a} x\\bigg) J_n\\bigg(\\frac{x_{n\\ell}}{a} x\\bigg) = 0 \\quad , \\ m \\neq \\ell \\ .\n\\] Notice this subtle point. It’s not distinct Bessel functions \\(J_n\\) and \\(J_{n'}\\) that are orthogonal. We can’t say \\(\\langle J_n | J_{n'} \\rangle = 0\\). Instead it’s the scaled Bessel functions for a fixed \\(n\\) that are orthogonal, i.e. \\(\\langle J_{nm} | J_{nm'} \\rangle = 0\\). This may seem strange, but it’s completely a consequence of the Sturm-Liouville problem we posed, which was posed assuming a fixed value of \\(n\\) already.\nWhile we know that these functions are orthogonal, we still don’t know what their normalization factors are. Finding these factors can be done any number of ways, though the math is a bit tedious in each case. We’ll just state the result. We end up with \\[\n\\langle J_{nm} | J_{nm} \\rangle = \\frac{a}{2} J_{n+1}^2(x_{nm}) \\ .\n\\] Putting this all together, we end up with the following simple orthogonality relation, \\[\n\\boxed{\n\\langle J_{nm} | J_{nm'} \\rangle = \\frac{a}{2} J_{n+1}^2(x_{nm}) \\delta_{mm'}\n} \\ .\n\\] With this information in hand, we know that the Bessel functions form a complete set on the interval \\(0 \\leq x \\leq a\\), and hence any function \\(f(x)\\) on that interval can be expanded as a linear superposition of them, \\[\nf(x) = \\sum_{m=1}^\\infty c_m J_n\\bigg(\\frac{x_{nm}}{a} x\\bigg) \\ ,\n\\] where the coefficients \\(c_m\\) are given in the usual way by solving \\(||J_{nm}||^2 c_m = \\langle J_{nm} | f \\rangle\\), which gives \\[\nc_m = \\frac{2}{a^2 J_{n+1}^2(x_{nm})} \\int_0^a dx \\ x \\ f(x) J_n\\bigg(\\frac{x_{nm}}{a} x\\bigg) \\ .\n\\]\nThis series expansion for \\(f(x)\\) is sometimes called a Bessel series, or a Fourier-Bessel series.\n\n\nGeneral Bessel Functions\nThus far, we’ve only studied Bessel functions of the first kind with an integer parameter \\(n\\). It turns out that we can consider Bessel functions for non-integer \\(n\\) as well. It’s conventional in this more general case to use \\(\\nu\\) as the parameter instead of \\(n\\). For non-integer \\(\\nu\\) we can no longer rely on the generating function. Instead we’ll define Bessel functions in terms of the series expression we derived before, but with a non-integer \\(\\nu\\) instead of \\(n\\), \\[\n\\boxed{\nJ_\\nu(x) \\equiv \\sum_{k=0}^\\infty \\frac{(-1)^k}{k!(\\nu-k)!} \\bigg(\\frac{x}{2}\\bigg)^{\\nu+2k}\n}\\ .\n\\] Note that when \\(\\nu\\) is non-integer the factorial \\((\\nu-k)!\\) isn’t well-defined in the usual way. It turns out though that we can analytically continue the factorial function by converting it to the gamma function. In that sense, when we say \\((\\nu-k)!\\), what we really mean is the gamma function equivalent \\(\\Gamma(\\nu-k+1)\\).\nSince the same series definition applies, all of the relations we’ve derived for integer Bessel functions carry over to non-integer Bessel functions as well, with one exception. For non-integer \\(\\nu\\), it’s no longer true that \\(J_{-\\nu}(x) = (-1)^\\nu J_\\nu(x)\\). Indeed, recall that to prove this relation for integer \\(n\\) we wrote \\(J_{-n}(x)\\) in series form and did a change of index \\(k \\rightarrow n-k\\).\nWhen \\(\\nu\\) is non-integer it turns out that \\(J_\\nu(x)\\) and \\(J_{-\\nu}(x)\\) are linearly independent functions. This means that for non-integer \\(\\nu\\), the general solution to Bessel’s equation can be written as a linear superposition of \\(J_\\nu(x)\\) and \\(J_{-\\nu}(x)\\), i.e. \\[\nf(x) = c_1 J_\\nu(x) + c_2 J_{-\\nu}(x) \\ .\n\\] It’s more conventional, however, to express the general solution to Bessel’s equation in a slightly different way that also holds for integer \\(\\nu\\). We can do that by defining a new function \\(Y_\\nu(x)\\), sometimes also denoted \\(N_\\nu(x)\\), called a Bessel function of the second kind, or a Neumann function, defined by \\[\n\\boxed{\nY_\\nu(x) \\equiv \\frac{\\cos\\nu\\pi \\ J_\\nu(x) - J_{-\\nu}(x)}{\\sin\\nu\\pi}\n}\\ .\n\\] Since \\(Y_\\nu(x)\\) is just a particular linear combination of \\(J_\\nu(x)\\) and \\(J_{-\\nu}(x)\\), it’s clear that these functions will solve Bessel’s equation as well when \\(\\nu\\) is non-integer. However, these functions also solve the equation for integer-valued \\(\\nu=n\\). This can be rectified by instead taking the limit as \\(\\nu \\rightarrow n\\) and employing L’Hopital’s rule to write \\[\nY_n(x) = \\frac{1}{\\pi} \\bigg[\\frac{\\partial J_\\nu}{\\partial \\nu} \\bigg|_{\\nu=n} - (-1)^n \\frac{\\partial J_{-\\nu}}{\\partial \\nu} \\bigg]   \\ ,\n\\] which is clearly well-defined when \\(\\nu=n\\). By expanding each Bessel function on the right as a series and collecting terms, one can show from this result that for \\(n=1,2,\\cdots\\) we have \\[\nY_n(x) = \\frac{2}{\\pi} \\bigg[J_n(x) \\log\\frac{x}{2} - \\frac{1}{n} \\sum_{k=0}^{n-1} J_k(x) - \\frac{(-1)^n}{2n} \\sum_{k=0}^{n-1} (-1)^k (n+k-1)! \\bigg(\\frac{x}{2}\\bigg)^{k-n} \\bigg] \\ .\n\\] An implication of this expansion is that evidently \\(Y_n(x) \\sim x^n \\log x\\) as \\(x \\rightarrow 0\\), which means these functions will diverge at \\(x=0\\). When \\(x\\) is large these functions behave similarly to \\(J_n(x)\\), acting as damped oscillations. We illustrate these behavior below with a plot of \\(Y_n(x)\\) for the first few non-negative values of \\(n\\).\n\n\n\n\n\nSince \\(Y_\\nu(x)\\) is just a weighted sum of \\(J_\\nu(x)\\) and \\(J_{-\\nu}(x)\\), it’s easy to show that all of the recursive formulas that hold for \\(J_\\nu(x)\\) also must hold for \\(Y_\\nu(x)\\) as well. This means that \\(Y_\\nu(x)\\) also solves Bessel’s equation, and since \\(Y_\\nu(x)\\) is now an independent function of \\(J_\\nu(x)\\) even for integer \\(\\nu\\), we can express any solution to Bessel’s equation as a linear superposition of these two, \\[\nf(x) = c_1 J_\\nu(x) + c_2 Y_{\\nu}(x) \\ .\n\\] Indeed, this is the most general solution to Bessel’s equation we can write down for a fixed \\(\\nu\\). Note that in electromagnetism problems the physical requirement that the solution not blow up at the origin will force us to set \\(c_2 = 0\\) and discard the \\(Y_\\nu(x)\\) term completely. We state the general solution here mainly for completeness.\nThough we won’t really use them in this course, it’s also possible to define yet another complex-valued function by taking \\(J_\\nu(x)\\) as the real part and \\(Y_\\nu(x)\\) as the imaginary part. These are called Bessel functions of the third kind, or Hankle functions, defined by \\[\nH_\\nu(x) \\equiv J_\\nu(x) + i Y_\\nu(x) \\ .\n\\] One can check that \\(H_\\nu(x)\\) satisfies the same recursive relations, and hence also solves Bessel’s equation as well, with \\[\nf(x) = c_1 H_\\nu(x) + c_2 H_\\nu^*(x) \\ .\n\\] Notice how similar this is to the relationship between the complex exponential and sines and cosines. The same thing is going on here, with \\(J_\\nu(x)\\) behaving as a sort of cosine, \\(Y_\\nu(x)\\) as a sort of sine, and \\(H_\\nu(x)\\) as a sort of complex exponential.\nThere is one more class of Bessel functions we’ll mention, called the modified Bessel functions of the first and second kind. These functions are respectively defined by \\[\nI_\\nu(x) \\equiv i^{-\\nu} J_\\nu(ix) \\quad , \\quad K_\\nu(x) \\equiv \\frac{\\pi}{2} \\frac{I_{-\\nu}(x) - I_\\nu(x)}{\\sin \\nu\\pi} \\ .\n\\] Unlike the ordinary Bessel functions, the modified Bessel functions do not oscillate. They behave essentially like real exponentials, with \\(I_\\nu(x)\\) behaving like a growing exponential and \\(K_\\nu(x)\\) like a decaying exponential.\nIt’s possible to show that the modified Bessel functions are solutions to the modified Bessel equation given by \\[\nx^2 \\frac{d^2 f}{dx^2} + x \\frac{df}{dx} - (x^2 + \\nu^2) f(x) = 0 \\ .\n\\] Its general solutions are linear combinations of the modified Bessel functions, with \\[\nf(x) = c_1 I_\\nu(x) + c_2 K_\\nu(x) \\ .\n\\] In electromagnetism, we’ll see these various Bessel functions arise primarily when solving linear PDEs in cylindrical coordinates. For example, when trying to solve Laplace’s equation in cylindrical coordinates, we end up with the following radial equation, \\[\n\\varrho^2 \\frac{d^2 R}{d\\varrho^2} + \\varrho \\frac{dR}{d\\varrho} + \\big(k^2 \\varrho^2 - n^2\\big)R(\\varrho) = 0 \\ .\n\\] This equation is clearly just the Bessel’s equation with an eigenvalue of \\(k^2\\). Once we impose boundary conditions, we can solve this equation for a general solution that satisfies Laplace’s equation.\n\n\nHankel Transform\nJust as we can define an integral transform from Fourier series, we can define a similar transform from a Bessel series. These are called Hankel transforms. Suppose we’ve expressed expanded some \\(f(x)\\) on the interval \\(0 \\leq x \\leq a\\) as a Bessel series with \\[\nf(x) = \\sum_{m=1}^\\infty c_m J_n(k_{mn} x) \\ ,\n\\]\nwhere \\(k_{mn} \\equiv \\frac{x_{nm}}{a}\\), and the coefficients \\(c_m\\) are given by the inner product relation \\[\nc_m = \\frac{2}{a^2 J_{n+1}^2(x_{nm})} \\int_0^a dx \\ x \\ f(x) J_n(k_{mn} x) \\ .\n\\] Now, suppose we send \\(a \\to \\infty\\). In this limit, the difference between roots \\(x_{nm}\\) goes like \\(\\Delta x_{nm} \\sim \\pi\\), which means \\(k_{nm}\\) becomes dense with \\(\\Delta k_{nm} \\sim \\frac{\\pi}{a}\\). This means we can treat it as a continuous variable \\(k \\equiv \\frac{m\\pi}{a}\\) and replace the sum over \\(m\\) by an integral \\[\n\\sum_{m=1}^\\infty \\approx \\frac{a}{\\pi} \\int_0^\\infty dk \\ .\n\\] Moreover, we know from the asymptotic relation for Bessel functions that \\(J_n(x) \\sim \\sqrt{2/\\pi x}\\) when \\(x \\gg n\\). This means when \\(m \\gg n\\) we have \\(J_{n+1}(x_{nm}) \\sim \\sqrt{2/m \\pi^2}\\). Now, if we plug \\(c_m\\) directly into the Bessel series, we get \\[\nf(x) = \\sum_{m=1}^\\infty \\frac{2}{a^2 J_{n+1}^2(x_{nm})} \\bigg[\\int_0^a dx' \\ x' \\ f(x') J_n(k_{mn} x')\\bigg] J_n(k_{mn} x) \\ .\n\\] If we now put all this together, simplify terms, and send \\(a \\to \\infty\\) we finally end up with \\[\nf(x) \\approx \\int_0^\\infty dk \\ k \\bigg[\\int_0^\\infty dx' \\ x' \\ f(x') J_n(k x')\\bigg] J_n(k x) \\ .\n\\] This gives us a completeness relation between \\(f(x)\\) and the inner integral that we’ll call \\(f(k)\\), where \\[\n\\boxed{\nf(k) \\equiv \\mathcal{H}_n f(x) = \\int_0^\\infty dx \\ x \\ f(x) J_n(k x)}\n\\] is called a Hankel transform of order \\(n\\). The Hankel operator \\(\\mathcal{H}_n\\) maps the function \\(f(x)\\) to its Hankel transform \\(f(k)\\). If we plug \\(f(k)\\) back into the outer integral, we get the inverse Hankel transform of order \\(n\\), \\[\n\\boxed{\nf(x) = \\mathcal{H}_n^{-1} f(x) = \\int_0^\\infty dk \\ k \\ f(k) J_n(k x)\n} \\ .\n\\] The Hankel transform is clearly invertible by the completeness relation. By definition, it also satisfies many of the relations that the Fourier transform does. It’s a linear operator, has a scaling property, converts convolutions into products and vice versa, and satisfies Parseval’s theorem. It also transforms derivatives in a standard way we won’t mention here, but is easy to derive.\nIn the continuum limit, the Bessel functions \\(J_n(kx)\\) are still orthogonal, but in a continuous sense, with \\[\n\\langle J_n(k) | J_n(k') \\rangle = \\int_0^\\infty dx \\ x J_n(kx) J_n(k'x) = \\frac{\\delta(k-k')}{k} \\ .\n\\] In electromagnetism, the Hankel transform usually shows up when trying to solve Laplace’s equation in cylindrical coordinates. When the radius of the cylinder is finite we end up with a radial equation to solve that can be written as a Bessel series. But if we let that radius become infinite, the Bessel series converts into a Hankel transform in the same manner described above.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Appendix I: Orthogonal Functions</span>"
    ]
  },
  {
    "objectID": "electrodynamics/orthogonal-functions.html#spherical-harmonics",
    "href": "electrodynamics/orthogonal-functions.html#spherical-harmonics",
    "title": "Appendix I: Orthogonal Functions",
    "section": "Spherical Harmonics",
    "text": "Spherical Harmonics\nYet another class of orthogonal functions that are extremely prevalent in physics are the spherical harmonics. The spherical harmonics most often arise in electromagnetism as the basis of solutions when solving Laplace’s equation on the sphere.\n\nDerivation\nIn spherical coordinates, we can express Laplace’s equation on the unit sphere in the form \\[\n\\frac{1}{\\sin \\theta} \\frac{\\partial}{\\partial \\theta} \\bigg(\\sin\\theta \\frac{\\partial}{\\partial \\theta} f(\\theta,\\varphi)\\bigg) + \\frac{1}{\\sin^2 \\theta} \\frac{\\partial^2}{\\partial \\varphi^2} f(\\theta,\\varphi) = 0 \\ .\n\\] When separation of variables is applied to this equation by supposing \\(f(\\theta,\\varphi) = \\Theta(\\theta)\\Phi(\\varphi)\\), we end up needing to solve the following eigenvalue problem, \\[\n\\frac{\\Phi(\\varphi)}{\\sin\\theta} \\frac{d}{d\\theta} \\bigg(\\sin\\theta \\frac{d}{d\\theta} \\Theta(\\theta)\\bigg) + \\frac{\\Theta(\\theta) }{\\sin^2\\theta} \\frac{d^2}{d\\varphi^2} \\Phi(\\varphi) + \\ell(\\ell+1) \\Theta(\\theta) \\Phi(\\varphi) = 0 \\ .\n\\] This equation can be separated yet again into separate differential equations for \\(\\Theta(\\theta)\\) and \\(\\Phi(\\varphi)\\), giving $$ \\[\\begin{align*}\n\n&\\frac{d^2}{d\\varphi^2} \\Phi(\\varphi) = -m^2 \\Phi(\\varphi) \\ , \\\\\n&\\frac{1}{\\sin\\theta} \\frac{d}{d\\theta} \\bigg(\\sin\\theta \\frac{d}{d\\theta} \\Theta(\\cos\\theta) \\bigg) + \\bigg[\\ell (\\ell+1) - \\frac{m^2}{\\sin^2\\theta}\\bigg] \\Theta(\\cos\\theta) = 0 \\ .\n\\end{align*}\\] $$\nThe first equation we recognize as a simple harmonic oscillator with eigenvalue \\(-m^2\\). For a given eigenvalue \\(m\\), its general solution can be written in the form \\[\n\\Phi_m(\\varphi) = c_1 e^{im\\varphi} + c_2 e^{-im\\varphi} \\ .\n\\] Since \\(0 \\leq \\varphi \\leq 2\\pi\\), we require that these solutions satisfy the periodic boundary condition \\(\\Phi_m(\\varphi) = \\Phi_m(\\varphi + 2\\pi)\\). This forces \\(m\\) to be an integer. By allowing \\(m\\) to run negative, we can combine these two solutions into one, absorb the integration constants into the final solution, and normalize the function on this interval to finally write \\(\\Phi_m(\\varphi)\\) in the form \\[\n\\Phi_m(\\varphi) = \\frac{e^{imx}}{\\sqrt{2\\pi}} \\ .\n\\] These functions are just complex Fourier functions, and so form a complete orthonormal set on the unit circle, meaning we can write any general function \\(\\Phi(\\varphi)\\) on the circle as a linear superposition of these basis functions.\nThe second equation we should recognize immediately as the associated Legendre equation with \\(x=\\cos\\theta\\). If we impose the boundary condition that \\(\\Theta(\\theta)\\) be finite on the interval \\(-\\pi \\leq \\theta \\leq \\pi\\), then its solutions will be given by the associated Legendre functions \\(P_\\ell^m(\\cos\\theta)\\), where \\(\\ell=0,1,2,\\cdots\\) and \\(-n \\leq m \\leq n\\). These functions form a complete orthogonal set on the interval \\(-\\pi \\leq \\theta \\leq \\pi\\), which means we can express any polar function \\(\\Theta(\\theta)\\) using the basis of solutions \\[\n\\Theta_{\\ell m}(\\theta) = (-1)^m \\sqrt{\\frac{(2\\ell+1)(\\ell-m)!}{2(\\ell+m)!}} P_\\ell^m(\\cos\\theta) \\ .\n\\] Note that we went ahead and normalized these solutions, which will be useful in what follows. We also introduced an extra factor of \\((-1)^m\\) to agree with common convention, which doesn’t affect much really.\nIf we multiply these two basis solutions together, we get a set of basis functions defined on the unit sphere by \\[\n\\boxed{\nY_{\\ell m}(\\theta,\\varphi) \\equiv (-1)^m \\sqrt{\\frac{(2\\ell+1)(\\ell-m)!}{4\\pi(\\ell+m)!}} P_\\ell^m(\\cos\\theta) e^{im\\varphi}\n}\\ .\n\\] These basis functions on the sphere are called the spherical harmonics. By construction, these functions form a basis of solutions for Laplace’s equation on the unit sphere, which is why they’re called spherical harmonics.\nNote that readers familiar with quantum mechanics will observe that the spherical harmonics can also be thought of as the eigenfunctions of the square of the angular momentum operator \\(\\mathbf{L} \\equiv -i\\hbar \\mathbf{x} \\times \\nabla\\). That is, \\[\n\\mathbf{L}^2 Y_{\\ell m}(\\theta,\\varphi) = \\hbar^2 \\ell(\\ell+1) Y_{\\ell m}(\\theta,\\varphi) \\ .\n\\] Indeed, it’s possible to show that expanding the operator \\(\\mathbf{L}^2 = \\mathbf{L} \\cdot \\mathbf{L}\\) in spherical coordinates yields the same differential equation we solved above when \\(\\hbar = 1\\). Similarly, the azimuthal functions \\(\\Phi_m(\\varphi)\\) turn out to be the eigenfunctions of the \\(z\\)-component of the angular momentum operator \\(L_z = -i\\hbar\\partial_\\varphi\\) , with \\(L_z \\Phi_m = \\hbar m \\Phi_m\\).\n\n\nProperties\nUsing the generalized Rodrigues’ formula for the associated Legendre functions it’s possible to write down expressions for spherical harmonics. We list the spherical harmonics for \\(\\ell=0,1,2\\) below. $$ \\[\\begin{align*}\nY_{00}(\\theta,\\varphi) &= \\sqrt{\\frac{1}{4\\pi}} \\ , \\quad\n\n\\begin{cases}\nY_{1,-1}(\\theta,\\varphi) &= \\sqrt{\\frac{3}{8\\pi}} \\sin\\theta e^{-i\\varphi} \\\\\nY_{10}(\\theta,\\varphi)& = \\sqrt{\\frac{3}{4\\pi}} \\cos\\theta \\\\\nY_{11}(\\theta,\\varphi) &= -\\sqrt{\\frac{3}{8\\pi}} \\sin\\theta e^{i\\varphi} \\\\\n\\end{cases} \\ , \\quad\n\n\\begin{cases}\nY_{2,-2}(\\theta,\\varphi) &= \\sqrt{\\frac{15}{32\\pi}} \\sin^2 \\theta e^{-2i\\varphi} \\\\\nY_{2,-1}(\\theta,\\varphi) &= \\sqrt{\\frac{15}{8\\pi}} \\sin\\theta \\cos\\theta e^{-i\\varphi} \\\\\nY_{20}(\\theta,\\varphi) &= \\sqrt{\\frac{5}{16\\pi}} (3\\cos^2 \\theta - 1) \\\\\nY_{21}(\\theta,\\varphi) &= -\\sqrt{\\frac{15}{8\\pi}} \\sin\\theta \\cos\\theta e^{i\\varphi} \\\\\nY_{22}(\\theta,\\varphi) &= \\sqrt{\\frac{15}{32\\pi}} \\sin^2 \\theta e^{2i\\varphi} \\\\\n\\end{cases} \\ .\n\\end{align*}\\] $$\nNotice from these first few harmonics that \\(Y_{\\ell m}(\\theta,\\varphi)\\) and \\(Y_{\\ell, -m}(\\theta,\\varphi)\\) are evidently related, with \\[\nY_{\\ell, -m}(\\theta,\\varphi) = (-1)^m Y_{\\ell m}^*(\\theta,\\varphi) \\ .\n\\] We can also see how the spherical harmonics behave under the parity transformations \\(\\theta \\rightarrow -\\theta\\) or \\(\\varphi \\rightarrow -\\varphi\\). Evidently, we have \\[\nY_{\\ell m}(-\\theta,\\varphi) = (-1)^m Y_{\\ell m}(\\theta,\\varphi) \\quad , \\quad Y_{\\ell m}(\\theta,-\\varphi) = Y_{\\ell m}^*(\\theta,\\varphi) \\ .\n\\] It’s common to visualize the spherical harmonics by doing a 3D surface plot. For a given harmonic, these surfaces represent the size of the absolute value of the real part of \\(Y_{\\ell m}(\\theta,\\varphi)\\) at a given solid angle \\((\\theta,\\varphi)\\). We show such a plot below for the first few harmonics. The blue surfaces represent surfaces with positive \\(Y_{\\ell m}(\\theta,\\varphi)\\), while the yellow surfaces represent surfaces with negative \\(Y_{\\ell m}(\\theta,\\varphi)\\). The harmonics are ordered top-to-bottom as \\(\\ell=0,1,2,3\\), and left-to-right as \\(m=-\\ell,\\cdots,\\ell\\).\n\n\n\n\n\nNotice that only the middle harmonics where \\(m=0\\) have azimuthally symmetric surfaces. This just follows from the fact that \\(e^{im\\varphi} = 0\\) when \\(m=0\\). In this simple case, the spherical harmonics can be written in the somewhat simpler form \\[\nY_{\\ell 0}(\\theta,\\varphi) = \\sqrt{\\frac{(2\\ell+1)}{4\\pi}} P_\\ell(\\cos\\theta) \\ .\n\\] Evidently these harmonics are just normalized Legendre polynomials on the sphere.\nBy construction, the spherical harmonics form a complete orthonormal set of functions on the sphere, which means they satisfy the orthonormality condition \\[\n\\boxed{\n\\langle Y_{\\ell m} | Y_{\\ell' m'} \\rangle = \\delta_{\\ell\\ell'}\\delta_{mm'}\n} \\ ,\n\\] where the inner product is defined by integration over the unit sphere with a unit weighting function, \\[\n\\langle Y_{\\ell m} | Y_{\\ell' m'} \\rangle \\equiv \\int d\\Omega \\ Y_{\\ell m}^*(\\theta,\\varphi) Y_{\\ell' m'}(\\theta,\\varphi) \\ .\n\\] This means we can represent any well-behaved function \\(f(\\theta,\\varphi)\\) on the sphere as a linear superposition of spherical harmonics, \\[\nf(\\theta,\\varphi) = \\sum_{\\ell=0}^\\infty \\sum_{m=-\\ell}^\\ell c_{\\ell m} Y_{\\ell m}(\\theta,\\varphi) \\ ,\n\\] where the coefficients are given in the usual way by \\(c_{\\ell m} = \\langle Y_{\\ell m} | f \\rangle\\), or written out, \\[\nc_{\\ell m} = \\int d\\Omega \\ f(\\theta,\\varphi) Y_{\\ell m}^*(\\theta,\\varphi) \\ .\n\\] This series expansion of \\(f(\\theta,\\varphi)\\) is sometimes called a Laplace series, or a Fourier-Laplace series.\nGiven that the spherical harmonics are basis functions for the sphere, it’s natural to ask how these functions behave under rotations. For azimuthal rotations this is easy to see from the definition. If \\(\\phi \\rightarrow \\phi' =\\phi + \\phi_0\\), then \\[\nY_{\\ell m}(\\theta,\\varphi') = Y_{\\ell m}(\\theta,\\varphi) e^{im\\phi_0} \\ .\n\\] Under more arbitrary rotations it’s not as obvious. Under a more general rotation that maps a unit vector at at \\((\\theta,\\varphi)\\) to another unit vector at \\((\\theta',\\varphi')\\), the rotated harmonic \\(Y_{\\ell m}(\\theta',\\varphi')\\) isn’t given in terms of one harmonic, but a linear combination of them, \\[\nY_{\\ell m}(\\theta',\\varphi') = \\sum_{m'=-\\ell}^\\ell D_{mm'}^* Y_\\ell^{m'}(\\theta,\\varphi) \\ .\n\\] Here \\(D_{mm'}\\) are the elements of a size \\((2\\ell+1) \\times (2\\ell+1)\\) unitary matrix known as a Wigner D-matrix. These matrices turn out to be very important in the theory of representation groups and the quantum theory of angular momentum, but less so for electromagnetism. We thus won’t say anymore about them in this course.\nAs we’ve defined them, the spherical harmonics are inherently complex-valued due to the presence of the complex exponentials. In some fields, it’s common to express the spherical harmonics in a slightly different way by using sines and cosines as basis functions in place of complex exponentials, similar to how the real Fourier series uses these basis pairs instead of the complex exponential. Each \\(\\ell, m\\) pair leads to a pair of real spherical harmonics defined by \\[\n\\begin{align*}\nY_{\\ell m}^e(\\theta,\\varphi) &\\equiv P_n^m(\\cos\\theta) \\cos m \\varphi \\ , \\\\\nY_{\\ell m}^o(\\theta,\\varphi) &\\equiv P_n^m(\\cos\\theta) \\sin m \\varphi \\ .\n\\end{align*}\n\\] In this setting, \\(m\\) is required to run positive from \\(m=0,\\cdots,\\ell\\). Notice that unlike the ordinary spherical harmonics, these real spherical harmonics haven’t been normalized in the definition. Nevertheless, it’s not hard to see that they also form an orthogonal expansion of functions on the unit sphere, and hence any function \\(f(\\theta,\\varphi)\\) can be expanded in a series of the form \\[\nf(\\theta,\\varphi) = a_{00} + \\sum_{\\ell=0}^\\infty \\sum_{m=1}^\\ell \\big[a_{\\ell m} Y_{\\ell m}^e(\\theta,\\varphi) + b_{\\ell m} Y_{\\ell m}^o(\\theta,\\varphi) \\big] \\ .\n\\] The coefficients are determined in a similar way to the way they are with real Fourier series. We won’t use this form of spherical harmonics in this course, but it’s good to be aware of their existence.\n\n\nAddition Theorem\nOne very useful result involving the spherical harmonics is the addition theorem, which provides a way to relate a single Legendre polynomial to a sum of spherical harmonics. We will use this result, for example. to derive the Green’s function and multipole expansion of an electrostatic charge distribution in spherical coordinates.\nSuppose \\(\\mathbf{x}\\) and \\(\\mathbf{x}'\\) are two unit vectors at different angles on the sphere, \\((\\theta,\\varphi)\\) and \\((\\theta',\\varphi')\\) respectively. The angle \\(\\gamma\\) between these two vectors will then be given by \\(\\cos\\gamma = \\mathbf{x} \\cdot \\mathbf{x}'\\). The addition theorem states that \\[\n\\boxed{\nP_\\ell(\\cos\\gamma) = \\frac{4\\pi}{2\\ell+1} \\sum_{m=-\\ell}^\\ell Y_{\\ell m}(\\theta,\\varphi) Y_{\\ell m}^*(\\theta',\\varphi')\n}\\ .\n\\] We will now give a brief proof of this important result. Suppose without loss of generality that \\(\\mathbf{x}'\\) is fixed in space at an angle \\((\\theta',\\varphi')\\) in a base reference frame \\(\\mathcal{S}\\). In that case, we can think of \\(P_\\ell(\\cos\\gamma)\\) as being only a function of \\(\\theta\\) and \\(\\varphi\\).\nNow, suppose we rotate to a new reference frame \\(\\mathcal{S}'\\) such that \\(\\mathbf{x}'\\) is along the \\(z'\\)-axis in the new frame and \\(\\mathbf{x}\\) is at an angle \\((\\gamma,\\beta)\\). In this frame, we can expand the harmonic \\(Y_{\\ell m}(\\theta,\\varphi)\\) in terms of the harmonics \\(Y_{\\ell m'}(\\gamma,\\beta)\\) in the new frame by writing \\[\nY_{\\ell m}(\\theta,\\varphi) = \\sum_{m'=-\\ell}^\\ell c_{\\ell m'} Y_{\\ell m'}(\\gamma,\\beta) \\ .\n\\] This follows from the fact that the harmonics on both sides must satisfy the same eigenvalue equation, and since the Laplacian is invariant under rotations we can express the eigenfunctions in one frame as a superposition of the eigenfunctions in the other.\nIt suffices to consider only the \\(m'=0\\) coefficient, which in the \\(\\mathcal{S}'\\) frame is given by \\[\nc_{\\ell 0} = \\int d\\Omega' \\ Y_{\\ell m}(\\theta,\\varphi) Y_{\\ell 0}^*(\\gamma,\\beta) \\ .\n\\] This follows from the fact that in this frame \\(P_\\ell(\\cos\\gamma)\\) is proportional to \\(Y_{\\ell 0}(\\gamma, \\beta)\\), with \\[\nP_\\ell(\\cos\\gamma) = \\sqrt{\\frac{4\\pi}{2\\ell+1}} Y_{\\ell 0}(\\gamma, \\beta) \\ .\n\\] This also implies that \\(P_\\ell(\\cos\\gamma)\\) must be an eigenfunction of the Laplacian \\(\\nabla'^2\\) in the \\(\\mathcal{S}'\\) frame, with \\[\n\\nabla'^2 P_\\ell(\\cos\\gamma) + \\frac{\\ell(\\ell+1)}{r^2} P_\\ell(\\cos\\gamma) = 0 \\ .\n\\] Now, we know that the Laplacian operator is invariant under rotations, which means the Laplacian \\(\\nabla^2\\) in the \\(\\mathcal{S}\\) frame must be the same as the rotated Laplacian \\(\\nabla'^2\\) in the \\(\\mathcal{S}'\\) frame. This means the same differential equation must hold in the \\(\\mathcal{S}\\) frame, and since the eigenfunctions in that frame are given by \\(Y_{\\ell m}(\\theta,\\varphi)\\), we can write \\(P_\\ell(\\cos\\gamma)\\) as a superposition of these, with \\[\nP_\\ell(\\cos\\gamma) = \\sum_{m=-\\ell}^\\ell a_m Y_{\\ell m}(\\theta,\\varphi) \\ .\n\\] Putting the expressions for \\(P_\\ell(\\cos\\gamma)\\) in both reference frames together, we have \\[\nP_\\ell(\\cos\\gamma) = \\sqrt{\\frac{4\\pi}{2\\ell+1}} Y_{\\ell 0}(\\gamma, \\beta) = \\sum_{m=-\\ell}^\\ell a_m Y_{\\ell m}(\\theta,\\varphi) \\ ,\n\\] where the coefficients \\(a_m\\) are given in the \\(\\mathcal{S}\\) frame by \\[\na_m = \\int d\\Omega \\ P_\\ell(\\cos\\gamma) Y_{\\ell m}^*(\\theta,\\varphi) \\ .\n\\] We now substitute the expression for \\(P_\\ell(\\cos\\gamma)\\) in the \\(\\mathcal{S}'\\) frame into this integral to get \\[\na_m = \\sqrt{\\frac{4\\pi}{2\\ell+1}} \\int d\\Omega \\ Y_{\\ell 0}(\\gamma, \\beta) Y_{\\ell m}^*(\\theta,\\varphi) \\ .\n\\] Since the integral depends only on the angles in one of the reference frames, we can freely change this from an integral in the \\(\\mathcal{S}\\) frame to an integral in the \\(\\mathcal{S}'\\) frame by replacing \\(d\\Omega\\) with \\(d\\Omega'\\). Then the integral is just the complex conjugate of the integral for \\(c_{\\ell 0}\\) from before. That is, \\[\na_m^* = \\sqrt{\\frac{4\\pi}{2\\ell+1}} \\ c_{\\ell 0} \\ .\n\\] Now, we still need to deal with \\(Y_{\\ell m}(\\theta',\\varphi')\\). We do that by observing that in the \\(\\mathcal{S}'\\) frame we simply have \\[\nY_{\\ell m}(\\theta',\\varphi') = c_{\\ell 0} Y_{\\ell 0}(0,0) = c_{\\ell 0} \\sqrt{\\frac{2\\ell+1}{4\\pi}} \\ .\n\\] Substituting this result into the previous expression for \\(a_m^*\\) and complex conjugating, we get \\[\na_m = \\frac{4\\pi}{2\\ell+1} Y_{\\ell m}^*(\\theta',\\varphi') \\ .\n\\] Finally, plugging this back into the series expansion for \\(P_\\ell(\\cos\\gamma)\\) in the \\(\\mathcal{S}\\) frame, we get what we wanted to prove, \\[\nP_\\ell(\\cos\\gamma) = \\frac{4\\pi}{2\\ell+1} \\sum_{m=-\\ell}^\\ell Y_{\\ell m}(\\theta,\\varphi) Y_{\\ell m}^*(\\theta',\\varphi') \\ .\n\\] To conclude, notice if we set \\(\\gamma = 0\\) in this formula, then \\(\\theta'=\\theta\\), \\(\\varphi'=\\varphi\\), and \\(P_\\ell(\\cos\\gamma) = 1\\), giving us the relation \\[\n\\sum_{m=-\\ell}^\\ell |Y_{\\ell m}(\\theta,\\varphi)|^2 = \\frac{2\\ell+1}{4\\pi} \\ .\n\\] This can be thought of as a sort of squared vector norm or sum rule for the set of \\(\\ell\\)th spherical harmonics.\n\n\nSpherical Basis\nWe’ve defined the spherical harmonics as the system of orthonormal functions that solve the angular part of Laplace’s equation in spherical coordinates. But we can also think of them in another way that’s more geometric and physical, as the representation of a vector in a particular basis.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Appendix I: Orthogonal Functions</span>"
    ]
  },
  {
    "objectID": "electrodynamics/complex-analysis.html",
    "href": "electrodynamics/complex-analysis.html",
    "title": "Appendix II: Complex Analysis",
    "section": "",
    "text": "Complex Functions\nRecall from the first chapter that a complex variable is any variable \\(z\\) of the form \\[\nz = x + iy \\ ,\n\\] where \\(x\\) and \\(y\\) are real numbers and \\(i \\equiv \\sqrt{-1}\\) is the imaginary number. We call \\(x = \\text{Re} \\ z\\) the real part of \\(z\\) and \\(y = \\text{Im} \\ z\\) the imaginary part of \\(z\\). Recall that we can think of \\(z\\) geometrically as representing a point in the complex plane \\(\\mathbb{C}\\), where the \\(x\\)-axis is the real axis and the \\(y\\)-axis is the imaginary axis. We showed that any complex variable could also be written in the polar form \\[\nz = r e^{i\\varphi} \\ ,\n\\] where \\(r \\equiv |z| = \\sqrt{zz^*}\\) is the modulus of \\(z\\) and \\(\\varphi \\equiv \\text{Arg} \\ z\\) is the argument or phase of \\(z\\). In the complex plane, the modulus \\(|z|\\) represents the radial distance of the point \\(z\\) in the plane, while \\(\\varphi\\) represents its angle relative to the positive real axis.\nWe showed that when two complex variables are multiplied together that their phases add, with \\[\n\\text{Arg} \\ z_1 z_2 = \\text{Arg} \\ z_1 + \\text{Arg} \\ z_2 \\ .\n\\] We also introduced the complex exponential \\(e^{i\\varphi}\\), and derived the Euler identity \\[\ne^{i \\varphi} = \\cos\\varphi + i\\sin\\varphi \\ .\n\\] ### Complex Functions\nWe’ll now introduce the notion of functions of a complex variable. Just as we can create functions \\(f(x)\\) of a real variable \\(x\\), we can just as well create functions \\(f(z)\\) of a complex variable \\(z\\). We define a complex function \\(f(z)\\) as any function that can be expressed in the form \\[\nf(z) = u(x,y) + iv(x,y) \\ ,\n\\] where \\(u(x,y)\\) and \\(v(x,y)\\) are both real bivariate functions of the real and imaginary parts of \\(z\\).\nAs an example, consider the exponential function \\(f(z) = e^z\\). If we substitute \\(z = x + iy\\) into this function and use Euler’s identity, we can write \\(f(z)\\) in the form \\[\ne^z = e^{x + iy} = e^x e^{iy} = e^x \\cos y + i e^x \\sin y \\quad \\Longrightarrow \\quad \\begin{cases}\nu(x,y) = e^x \\cos y \\ ,\\\\\nv(x,y) = e^x \\sin y \\ .\n\\end{cases}\n\\] As another example, consider the sine function \\(f(z) = \\sin z\\). If we use Euler’s identity and the hyperbolic trig functions to simplify terms, we can write \\[\n\\sin z = \\frac{1}{2i} \\big(e^{iz} - e^{-iz}\\big) = \\sin x \\cosh y + i \\cos x \\sinh y \\quad \\Longrightarrow \\quad \\begin{cases}\nu(x,y) = \\sin x \\cosh y \\ , \\\\\nv(x,y) = \\sin x \\sinh y \\ .\n\\end{cases}\n\\] As a final example, consider the function \\(f(z) = 1/z\\). If we multiply the numerator and denominator by \\(z^*\\) and simplify, we have \\[\n\\frac{1}{z} = \\frac{z^*}{zz^*} = \\frac{x}{x^2 + y^2} - i \\frac{y}{x^2 + y^2} \\quad \\Longrightarrow \\quad \\begin{cases}\nu(x,y) = \\frac{x}{x^2 + y^2} \\ , \\\\\nv(x,y) = -\\frac{y}{x^2 + y^2} \\ .\n\\end{cases}\n\\] ### Continuous Functions\nWe’ll now discuss the concept of the continuity of a complex function. We know from calculus that a real function \\(f(x)\\) is continuous at a point \\(x=a\\) provided the difference \\(f(x) - f(a)\\) is infinitesimal whenever \\(x-a\\) is infinitesimal, that is, whenever \\(x \\approx a\\) we have \\(f(x) \\approx f(a)\\). In terms of limits, this is equivalent to the statement that \\[\nf(a) = f\\bigg(\\lim_{x \\to a} x\\bigg) = \\lim_{x \\to a} f(x) \\ .\n\\] We say \\(f(x)\\) is continuous on some interval if \\(f(x)\\) is continuous at all points \\(a\\) in that interval.\nWe can define something analogous for complex functions. We say a complex function \\(f(z)\\) is continuous at a point \\(z=a\\) provided \\(f(z) - f(a)\\) is infinitesimal whenever \\(z-a\\) is infinitesimal, or equivalently \\[\nf(a) = f\\bigg(\\lim_{z \\to a} z\\bigg) = \\lim_{z \\to a} f(z) \\ .\n\\] Note that in the complex plane limits can be more than two-sides. When we say the limit exists, we mean the limit from all directions must exist, a much stronger condition. Similarly, when we say \\(z-a\\) is infinitesimal, we mean that \\(z-a\\) is infinitesimal for all choice of \\(z\\) near the point \\(a\\). We say \\(f(z)\\) is continuous in some region \\(R\\) provided \\(f(z)\\) is continuous at each point \\(a\\) inside the region \\(R\\).\nAn equivalent but more useful condition for a complex function \\(f(z)\\) to be continuous is that both \\(u(x,y)\\) and \\(v(x,y)\\) are continuous in both \\(x\\) and \\(y\\). We can use this idea to quickly list off a bunch of continuous complex functions:",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Appendix II: Complex Analysis</span>"
    ]
  },
  {
    "objectID": "electrodynamics/complex-analysis.html#complex-functions",
    "href": "electrodynamics/complex-analysis.html#complex-functions",
    "title": "Appendix II: Complex Analysis",
    "section": "",
    "text": "The exponential function \\(e^z = e^x \\cos y + i e^x \\sin y\\) is everywhere continuous.\nThe sine function \\(\\sin z = \\sin x \\cosh y + i \\cos x \\sinh y\\) is everywhere continuous.\nThe cosine function \\(\\cos z = \\cos x \\cosh y - i \\sin x \\sinh y\\) is everywhere continuous.\nThe power function \\(z^n = |z|(\\cos n\\varphi + i\\sin n\\varphi)\\) is everywhere continuous when \\(n\\) is an integer.\nThe reciprocal function \\(1/z = x/|z|^2 - i y/|z|^2\\) is continuous at every point except the origin \\(z=0\\).\nThe sum or product of continuous functions is also continuous. For example, \\(f(z) = 3e^z - z^2 \\sin z\\) is continuous.\nThe composition of continuous functions is also continuous. For example, \\(f(z) = e^{2 \\cos z}\\) is continuous.\n\n\nMultivalued Functions\nWe know though that not all real functions are single-valued everywhere. For example, the inverse of the real function \\(f(x) = x^2\\) is the multivalued function \\(g(x) = \\pm \\sqrt{x}\\). To deal with this issue we often restrict the range of \\(f(x)\\) to \\(x \\geq 0\\) so that it has a well-defined inverse of \\(g(x) = +\\sqrt{x}\\). This is known as the principle root of \\(f(x) = x^2\\).\nThe same kinds issues also arise when dealing with complex functions. For example, consider the complex log function \\(f(z) = \\log z\\). By expressing \\(z\\) in polar form, we can write \\[\n\\log z = \\log |z| e^{i\\varphi} = \\log |z| + i\\varphi \\ .\n\\] Notice first that \\(\\log z\\) can’t be defined at \\(z=0\\) since \\(u(x,y) = \\log |z|\\) is undefined when \\(x=y=0\\). More interesting though is what happens with \\(v(x,y) = \\varphi\\). Since \\(\\varphi\\) is an angle, if we add or subtract any multiple of \\(2\\pi\\) we must get back the same point in the complex plane. This means that in general we have \\(v(x,y) = \\phi + 2\\pi n\\) for any integer \\(n\\). That is, \\(v(x,y)\\) is multivalued since it depends on \\(n\\). This evidently implies that the complex logarithm must be a multivalued function as well.\nTo force the complex logarithm to be single-valued, we have to thus choose a fixed value of \\(n\\). By convention we usually choose \\(n=0\\), which defines the principle logarithm. This is equivalent to requiring that the phase be bounded in some \\(2\\pi\\) interval, which by convention we choose to be \\(-\\pi &lt; \\varphi &lt; \\pi\\), which is called the principal branch. Along the negative real axis \\(\\varphi = \\pm \\pi\\), and there the principal logarithm is not defined. We call this ray a branch cut. At any point away from the branch cut, the principle logarithm is well-defined and single-valued.\nFIGURE (show branch cut)\nTo differentiate the principle and multi-valued logarithms, people sometimes write \\(\\text{Log} \\ z\\) to refer to the principle logarithm, and \\(\\log z\\) to exclusively refer to the multi-valued logarithm, with the two related by the formula \\[\n\\text{log} \\ z = \\text{Log} \\ z + i2n\\pi \\ .\n\\] Provided we restrict ourselves to the principle logarithm, we can define an inverse for the exponential function in the usual way, \\[\nz = \\text{Log} \\ e^z = e^{\\text{Log} \\ z} \\ .\n\\] A similar issue arises with many other complex functions as well. Another common class of functions with branch cuts are polynomial functions with rational powers. For example, suppose \\(f(z) = z^{p/q}\\). We can also write this function as \\[\nz^{p/q} = e^{p/q \\cdot \\log z} = \\big(e^{\\text{Log} \\ z + 2n\\pi i}\\big)^{p/q} = \\big(e^{\\text{Log} \\ z})^{p/q} e^{i2\\pi n p/q} \\ .\n\\] The first term \\(\\big(e^{\\text{Log} \\ z})^{p/q}\\) is just the ordinary single-valued part of \\(z^{p/q}\\). The second term \\(e^{i2\\pi n p/q}\\) is a phase factor that depends on \\(n\\). If \\(p/q\\) is an integer then \\(e^{i2\\pi n p/q} = 1\\) for all \\(n\\), and \\(f(z)\\) is hence single-valued. If \\(p/q\\) is not an integer this won’t happen, which means the phase factor will depend on \\(n\\), and so \\(f(z)\\) becomes multi-valued. To force \\(f(z)\\) to be single-valued we can again restrict the phase of \\(z\\) to some \\(2\\pi\\) range, e.g. \\(-\\pi &lt; z &lt; \\pi\\). This means any single-valued version of \\(f(z) = z^{p/q}\\) will also have a branch cut along some ray from the origin in the complex plane, e.g. the negative real axis.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Appendix II: Complex Analysis</span>"
    ]
  },
  {
    "objectID": "electrodynamics/complex-analysis.html#analytic-functions",
    "href": "electrodynamics/complex-analysis.html#analytic-functions",
    "title": "Appendix II: Complex Analysis",
    "section": "Analytic Functions",
    "text": "Analytic Functions\nJust as we could define the notion of a derivative for real functions, we can define it just as well for complex functions. We’ll see though that complex differentiation turns out to be a much stronger restriction on a function’s behavior than real differentiation.\n\nDefinition\nRecall how the derivative was defined for real functions \\(f(x)\\). We say that a function \\(y=f(x)\\) is differentiable at a point \\(x\\) provided for any infinitesimal \\(-1 \\gg dx \\ll 1\\) the difference \\[\ndy \\equiv f(x+dx) - f(x)\n\\] is also infinitesimal. When this is the case, we can take their ratio and define the derivative of \\(f(x)\\) at \\(x\\) by \\(dy/dx\\). This is equivalent to saying that the limit of the ratio \\(\\Delta y / \\Delta x\\) becomes a finite number as \\(\\Delta x \\to 0\\). In particular, this must be true for both the left-hand and right-hand limits, which must be equal to the same ratio \\(dy/dx\\).\nThe same notion of derivative exists for complex functions \\(f(z)\\) as well. We say \\(w = f(z)\\) is differentiable at \\(z\\) provided for any infinitesimal \\(0 &lt; |dz| \\ll 1\\) the difference \\[\ndw \\equiv f(z + dz) - f(z)\n\\] is also infinitesimal. When this is the case, we can take their ratio and define the derivative of \\(f(z)\\) at \\(z\\) by \\(dw/dz\\). This is equivalent to saying that the limit of the ratio \\(\\Delta w / \\Delta z\\) approaches the same finite ratio \\(dw/dz\\) as \\(\\Delta z \\to 0\\) for any choice of \\(\\Delta z\\). That is, this limit must approach the same ratio no matter which direction of approach for \\(\\Delta z\\) we choose.\nNote that it’s necessary that \\(f(z)\\) be continuous at \\(z\\) for its derivative to exist, for otherwise if it would be impossible for \\(dw\\) to be infinitesimal. However, this is not a sufficient condition for the derivative to exist, since the ratio must be defined for every \\(dz\\).\nIf \\(f(z)\\) is differentiable at \\(z\\) and some region around \\(z\\), we say \\(f(z)\\) is analytic (or holomorphic) at the point \\(z\\). More generally, iif \\(f(z)\\) is differentiable in some region \\(\\mathcal{R}\\) in the complex plane, we say that \\(f(z)\\) is analytic inside \\(\\mathcal{R}\\). If that region is the whole complex plane, we say \\(f(z)\\) is an entire function. In each case, we say \\(f(z)\\) is an analytic function.\nIt’s easy to see from the definition that analytic functions obey the usual differentiation rules:\n\nLinearity: \\(d(\\alpha f + \\beta g) = \\alpha df + \\beta dg\\),\nProduct Rule: \\(d(fg) = fdg + gdf\\),\nQuotient Rule: \\(g^2 d(f/g) = gdf - fdg\\).\nChain Rule: \\(d\\big[f(g(z))\\big] = \\frac{df}{dg} \\frac{dg}{dz} dz\\).\n\nAnother property of analytic functions is that the composition of analytic functions is also analytic. That is, if \\(w=f(z)\\) is analytic at \\(z\\), and \\(s=g(w)\\) is analytic at the point \\(w\\), then the composition \\(s = g(f(z))\\) is analytic at \\(z\\).\nThe final property of analytic functions we’ll mention for now involves the inverses of analytic functions. Suppose \\(w=f(z)\\) is analytic at \\(z\\), and suppose at the point \\(z\\) we can invert the function to get \\(z = f^{-1}(w)\\). Then \\(f^{-1}(w)\\) is analytic at \\(w\\), with \\[\n\\frac{d}{dw} f^{-1}(w) = \\frac{1}{dw/dz} \\bigg|_{z=f^{-1}(w)} \\ .\n\\] In simpler terms, this says that the derivative of the inverse is just \\(dz/dw\\), as we’d expect. Of course, we do have to be careful to ensure that the inverse function is single-valued, so that each \\(w\\) maps to a distinct \\(z\\). If the inverse function is multi-valued, we can achieve this by restricting the inverse to some branch, like we did with the logarithm before.\n\n\nCauchy-Riemann Equations\nSupposing that \\(w = f(z)\\) is analytic, we can write \\[\ndw = \\frac{dw}{dz} dz \\ .\n\\] However, we also know that both \\(z\\) and \\(w\\) can be expressed in terms of real variables, with \\(w = u(x,y)+iv(x,y)\\). This means it must also be the case that \\(f(z)\\) is differentiable with respect to both \\(x\\) and \\(y\\) in a real-variable sense. This means we can also write \\(dw\\) as a differential sum of the partial derivatives in \\(u\\) and \\(v\\), with \\[\ndw = \\frac{\\partial w}{\\partial x} dx + \\frac{\\partial w}{\\partial y} dy = \\bigg(\\frac{\\partial u}{\\partial x} + i\\frac{\\partial v}{\\partial x}\\bigg) dx + \\bigg(\\frac{\\partial u}{\\partial y} + i\\frac{\\partial v}{\\partial y}\\bigg) dy \\ .\n\\] Now, both differential formulas for \\(dw\\) must be equal. Writing \\(dz = dx + idy\\), we must have \\[\ndw = \\frac{dw}{dz} (dx + idy) = \\frac{dw}{dz} dx + i \\frac{dw}{dz} dy \\ .\n\\] It follows then that we must have \\[\n\\frac{dw}{dz} = \\frac{\\partial u}{\\partial x} + i\\frac{\\partial v}{\\partial x} = -i \\bigg(\\frac{\\partial u}{\\partial y} + i\\frac{\\partial v}{\\partial y}\\bigg) \\ .\n\\] Notice that this is in fact a very strong condition. The partial derivatives \\(\\frac{\\partial w}{\\partial x}\\) and \\(\\frac{\\partial w}{\\partial y}\\) must be related in a very specific way. This is not something that is true for ordinary 2-dimensional functions \\(f(x,y)\\). This strong condition makes complex differentiation a much stronger and interesting concept than real differentiation, as we’ll soon see.\nTo see what conditions these partial derivatives must satisfy, notice if we move everything to one side, we get \\[\n\\bigg(\\frac{\\partial u}{\\partial x} - \\frac{\\partial v}{\\partial y}\\bigg) + i\\bigg(\\frac{\\partial u}{\\partial y} + \\frac{\\partial v}{\\partial x}\\bigg) = 0 \\ .\n\\] Since both the real and imaginary parts must separately vanish, we end up with the following two conditions, \\[\n\\boxed{\n\\frac{\\partial u}{\\partial x} = \\frac{\\partial v}{\\partial y} \\quad , \\quad\n\\frac{\\partial u}{\\partial y} = -\\frac{\\partial v}{\\partial x}\n} \\ .\n\\] We call these conditions the Cauchy-Riemann equations. These two equations are necessary conditions for a complex function to be analytic. In fact, if we further require that these partial derivatives be continuous at the point of interest, then they’re necessary and sufficient conditions for the function to be analytic at that point.\nChecking that the Cauchy-Riemann equations hold is usually the easiest way to verify whether a given complex function is analytic. As an easy example of this, consider again the exponential function \\(f(z) = e^z = e^x \\cos y + e^x \\sin y\\). Let’s check that this function satisfy the Cauchy-Riemann equations. It’s easy to see we have \\[\n\\begin{align*}\n\\frac{\\partial u}{\\partial x} &= e^x \\cos y = \\frac{\\partial v}{\\partial y} \\ , \\\\\n\\frac{\\partial u}{\\partial y} &= -e^x \\sin y = -\\frac{\\partial v}{\\partial x} \\ .\n\\end{align*}\n\\] This means the exponential function \\(f(z) = e^z\\) is analytic. In fact, it’s analytic on the whole complex plane, hence it’s also entire.\nAs another example, consider again the reciprocal function \\[\nf(z) = \\frac{1}{z} = \\frac{x}{x^2 + y^2} - i \\frac{y}{x^2 + y^2} \\ .\n\\] If we apply the Cauchy-Riemann equations to this function, we get \\[\n\\begin{align*}\n\\frac{\\partial u}{\\partial x} &= -\\frac{x^2 - y^2}{(x^2 + y^2)^2} = \\frac{\\partial v}{\\partial y} \\ , \\\\\n\\frac{\\partial u}{\\partial y} &= -\\frac{2xy}{(x^2 + y^2)^2} = -\\frac{\\partial v}{\\partial x} \\ .\n\\end{align*}\n\\] Evidently, the reciprocal function \\(f(z) = 1/z\\) is also analytic, but only when \\(|z| \\neq 0\\). When \\(z = 0\\) the denominator of both equations blow up and the equations are no longer well-defined. We call functions of this type that are analytic at all but a finite number of points meromorphic functions.\nA few examples of complex functions that are continuous but not analytic are the real part \\(f(z) = \\text{Re} \\ z\\), the imaginary part \\(f(z) = \\text{Im} \\ z\\), and the complex conjugate \\(f(z) = z^*\\). These are all easy to check by the Cauchy-Riemann equations.\nIt’s easy to check that pretty much all of the usual differentiable functions from calculus are analytic functions in complex analysis if we replace \\(f(x)\\) by \\(f(z)\\). Here are some of the most common ones:\n\nThe exponential function \\(e^z\\) is everywhere analytic.\nThe sine and cosine functions \\(\\sin z\\) and \\(\\cos z\\) are both everywhere analytic.\nAny power function \\(z^p\\) is everywhere analytic when \\(\\text{Re} \\ p \\geq 1\\), and analytic everywhere but the point \\(z=0\\) when \\(\\text{Re} \\ p &lt; 1\\).\nAny polynomial function of \\(z\\) is everywhere analytic.\nRatios of polynomial functions of \\(z\\) are analytic at any point where the denominator isn’t zero.\nThe principal logarithm \\(\\log z\\) is analytic everywhere but the point \\(z = 0\\).\n\n\n\nHarmonic Functions\nAnother important fact about analytic functions is that their real and imaginary parts each independently satisfy Laplace’s equation in two dimensions. That is, if a function \\(f(z) = u(x,y) + i v(x,y)\\) is analytic in some region, then we have \\[\n\\begin{align*}\n&\\nabla^2 u = \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} = 0 \\ , \\\\\n&\\nabla^2 v = \\frac{\\partial^2 v}{\\partial x^2} + \\frac{\\partial^2 v}{\\partial y^2} = 0 \\ .\n\\end{align*}\n\\] To see why this is true we again appeal to the Cauchy-Riemann equations. If we substitute these equations into \\(\\nabla^2 u\\), we have \\[\n\\begin{align*}\n\\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2}\n&= \\frac{\\partial}{\\partial x} \\frac{\\partial u}{\\partial x} + \\frac{\\partial}{\\partial y} \\frac{\\partial u}{\\partial y} \\\\\n&= \\frac{\\partial}{\\partial x} \\frac{\\partial v}{\\partial y} - \\frac{\\partial}{\\partial y} \\frac{\\partial v}{\\partial x} \\\\\n&= \\frac{\\partial^2 v}{\\partial x \\partial y} - \\frac{\\partial^2 v}{\\partial y \\partial x} \\ .\n\\end{align*}\n\\] Since mixed partial derivatives commute the last line must vanish, leaving \\(\\nabla^2 u = 0\\). Similarly, for \\(\\nabla^2 v\\) we have \\[\n\\begin{align*}\n\\frac{\\partial^2 v}{\\partial x^2} + \\frac{\\partial^2 v}{\\partial y^2}\n&= \\frac{\\partial}{\\partial x} \\frac{\\partial v}{\\partial x} + \\frac{\\partial}{\\partial y} \\frac{\\partial v}{\\partial y} \\\\\n&= -\\frac{\\partial}{\\partial x} \\frac{\\partial u}{\\partial y} + \\frac{\\partial}{\\partial y} \\frac{\\partial u}{\\partial x} \\\\\n&= -\\frac{\\partial^2 u}{\\partial x \\partial y} + \\frac{\\partial^2 u}{\\partial y \\partial x} \\ .\n\\end{align*}\n\\] Again, since mixed partial derivatives commute, the last line vanishes, leaving \\(\\nabla^2 v = 0\\). Functions that satisfy Laplace’s equation are called harmonic functions. We’ve thus shown that the real and imaginary parts of an analytic function must each be a harmonic function inside the region in the \\(xy\\)-plane where the function is analytic.\nMoreover, it turns out that the level curves of \\(u(x,y)\\) and \\(v(x,y)\\) must always be orthogonal inside the analytic region, i.e. \\[\n\\nabla u(x,y) \\cdot \\nabla v(x,y) = 0 \\ .\n\\] This again follows immediately from the Cauchy-Riemann equations. Indeed, we have \\[\n\\nabla u \\cdot \\nabla v = \\frac{\\partial u}{\\partial x} \\frac{\\partial v}{\\partial x} + \\frac{\\partial u}{\\partial y} \\frac{\\partial v}{\\partial y} = \\frac{\\partial v}{\\partial y} \\frac{\\partial v}{\\partial x} - \\frac{\\partial v}{\\partial x} \\frac{\\partial v}{\\partial y} = 0 \\ .\n\\] The Cauchy-Riemann conditions imply something else as well. Given a harmonic function \\(u(x,y)\\), we can determine the function \\(v(x,y)\\), called the harmonic conjugate of \\(u(x,y)\\), that makes \\(f(z) = u(x,y) + i v(x,y)\\) analytic, up to constants. To see why this is true, we can write the total differential of \\(v(x,y)\\) in the form \\[\ndv = \\frac{\\partial v}{\\partial x} dx + \\frac{\\partial v}{\\partial y} dy \\ .\n\\] If we now use the Cauchy-Riemann conditions and integrate both sides, we get \\[\nv(x,y) = -\\int dx \\ \\frac{\\partial u}{\\partial y} + \\int dy \\ \\frac{\\partial u}{\\partial x} \\ .\n\\] Thus, up to additive constants, we’ve completely determined the form of \\(v(x,y)\\) from the derivatives of \\(u(x,y)\\).\nAs an example, consider the function \\[\nu(x,y) = y^3 - 3x^3 y \\ .\n\\] It’s easy to check that \\(\\nabla^2 u = 0\\), which means \\(u(x,y)\\) is harmonic on the \\(xy\\)-plane. To find its conjugate \\(v(x,y)\\), we can impose the Cauchy-Riemann conditions. We have \\[\n\\begin{align*}\n\\frac{\\partial v}{\\partial x} &= -\\frac{\\partial u}{\\partial y} = -3y^2 - 3x^2 \\ , \\\\\n\\frac{\\partial v}{\\partial y} &= \\frac{\\partial u}{\\partial x} = -6x^2 y \\ .\n\\end{align*}\n\\] Then we have \\[\n\\begin{align*}\nv(x,y) &= -\\int dx \\ \\frac{\\partial u}{\\partial y} + \\int dy \\ \\frac{\\partial u}{\\partial x} \\\\\n&= \\int dx \\ (-3y^2 - 3x^2) + \\int dy \\ (-6x^2 y) \\\\\n&= -3xy^2 - x^3 + C \\ .\n\\end{align*}\n\\] It’s again easy to check that \\(\\nabla^2 v = 0\\), so \\(v(x,y)\\) is harmonic on the \\(xy\\)-plane. We’ve thus found an analytic function \\(f(z)\\) whose real and imaginary functions are harmonic, \\[\nf(z) = (y^3 - 3x^3 y) + i(-3xy^2 - x^3 + C) \\ .\n\\] Evidently, the condition that a complex function be analytic is much stronger than the condition that a real function be differentiable. It implies a whole host of added properties we don’t see in calculus. In the next section we’ll show a few more.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Appendix II: Complex Analysis</span>"
    ]
  },
  {
    "objectID": "electrodynamics/complex-analysis.html#complex-integration",
    "href": "electrodynamics/complex-analysis.html#complex-integration",
    "title": "Appendix II: Complex Analysis",
    "section": "Complex Integration",
    "text": "Complex Integration\nBefore discussing analytic functions further we need to introduce the concept of complex integration. The integration of complex functions is a good bit different from differentiation of real functions due to the fact that the integration is now being done in a plane instead of over a line. This means integration of complex numbers is much more akin to contour integration of a bivariate real function \\(f(x,y)\\) than it is to integration of univariate real functions \\(f(x)\\).\n\nContour Integration\nSuppose \\(f(z)\\) is some complex function that’s well-defined on some path \\(\\mathcal{C}\\) in the complex plane that starts at a point \\(z=a\\) and ends at a point \\(z=b\\). Suppose we can parametrize this path via some function \\(z(t)\\), where \\(t_a \\leq t \\leq t_b\\) is some parameter such that \\(z(t_a) = a\\) and \\(z(t_b) = b\\). Then we can define the contour integral of \\(f(z)\\) over \\(\\mathcal{C}\\) by \\[\n\\int_\\mathcal{C} dz \\ f(z) \\equiv \\int_a^b dz \\ f(z) \\equiv \\int_{t_a}^{t_b} dt \\ f(z(t)) \\frac{dz}{dt} \\ .\n\\] As with real path integrals, we often find ourselves dealing with contour integrals over closed loops, i.e. closed paths where \\(a=b\\). In that case we often write the contour integral with the notations \\(\\oint dz \\ f(z)\\) or \\(\\oint_\\mathcal{C} dz \\ f(z)\\).\nAs an example, let’s find the integral of the reciprocal function \\(f(z) = 1/z\\) along a counterclockwise circular closed loop \\(\\mathcal{C}\\) of unit radius centered at the origin. We can parametrize this path by defining a parameter \\(-\\pi \\leq t \\leq \\pi\\) and letting \\(z = e^{it}\\). Then \\[\n\\oint_\\mathcal{C} \\frac{dz}{z} = \\int_{-\\pi}^\\pi dt \\ e^{-it} \\frac{d}{dt} e^{it} = i \\int_{-\\pi}^\\pi dt = 2\\pi i \\ .\n\\] It’s easily checked that the contour integral satisfies all of the usual properties the path integral of real variables satisfies:\n\nLinearity: \\(\\int_\\mathcal{C} dz \\ [af(z) + bg(z)] = a \\int_\\mathcal{C} dz \\ f(z) + b \\int_\\mathcal{C} dz \\ g(z)\\),\nChange of Variables: If \\(w = g(z)\\), then \\(\\int_\\mathcal{C} dw \\ f(w) = \\int_\\mathcal{C} dz \\ f(g(z)) \\frac{dw}{dz}\\),\nPath Decomposition: If \\(\\mathcal{C}\\) is decomposed into two paths \\(\\mathcal{C}_1\\) and \\(\\mathcal{C}_2\\), then \\(\\int_\\mathcal{C} dz \\ f(z) = \\int_\\mathcal{C_1} dz \\ f(z) + \\int_\\mathcal{C_2} dz \\ f(z)\\),\nPath Reversal: If the path \\(-\\mathcal{C}\\) is the reverse of the path \\(\\mathcal{C}\\), then \\(\\int_{-\\mathcal{C}} dz \\ f(z) = -\\int_\\mathcal{C} dz \\ f(z)\\),\nBoundedness: If \\(M\\) is the maximum of \\(|f(z)|\\) along the path and \\(L\\) the path length, then \\(\\big| \\int_\\mathcal{C} dz \\ f(z) \\big| \\leq ML\\).\n\n\n\nCauchy’s Theorem\nAnalytic functions satisfy a property when it comes to contour integration that’s akin to the property that conservative fields have in real Euclidean space, namely path independence. Suppose \\(f(z)\\) is analytic inside some closed loop \\(\\mathcal{C}\\). Then \\[\n\\oint_{\\mathcal{C}} dz \\ f(z) = 0 \\ .\n\\] This result is known as Cauchy’s Theorem. It says that any contour integral of an analytic function is independent of path, meaning its result depends only on the endpoints. Note that anytime we say \\(\\mathcal{C}\\) is a closed loop, we mean not only that the path closes back on itself, but also that it does not intersect at any other point. For example, a circle traversed once is a closed loop, while a figure eight is not. Mathematicians call a closed loop a simple closed curve, and the region inside the closed loop simply connected.\nLet’s verify Cauchy’s Theorem real quick on a function we know to be analytic, \\(f(z) = e^z\\). We’ll again choose a path to be the unit circle traversed counterclockwise in a closed loop. We again parametrize this path with \\(z(t) = e^{it}\\) where \\(-\\pi \\leq t \\leq \\pi\\). Then \\[\n\\int_\\mathcal{C} dz \\ e^z = \\int_{-\\pi}^\\pi dt \\ e^{e^{it}} \\frac{d}{dt} e^{it} = i \\int_{-\\pi}^\\pi dt \\ e^{e^{it} + it} \\ .\n\\] Now, if we substitute \\(u = e^{it}\\) then \\(du = i e^{it} dt\\) and \\(u(\\pm \\pi) = e^{\\pm i\\pi} = -1\\), and so \\[\n\\int_\\mathcal{C} dz \\ e^z = \\int_{-1}^{-1} du \\ e^u = 0 \\ .\n\\] Of course, Cauchy’s theorem says something stronger than this. The closed loop integral will vanish for any choice of path.\nCauchy’s theorem isn’t that difficult to prove. If we write \\(f(z) = u(x,y) + iv(x,y)\\) and \\(dz = dx + idy\\), then we can separate the integral into real and imaginary parts as \\[\n\\oint_{\\mathcal{C}} dz \\ f(z) = \\oint_{\\mathcal{C}} (dx + idy) \\ \\big(u(x,y) + iv(x,y)\\big)\n= \\oint_{\\mathcal{C}} (udx - vdy) + i \\oint_{\\mathcal{C}} (udy + vdx) \\ .\n\\] Now, notice that both of these integrals are just integrals of real bivariate functions \\(u(x,y)\\) and \\(v(x,y)\\). If we let \\[\n\\mathbf{F}(\\mathbf{x}) = u(x,y) \\mathbf{e}_x - v(x,y) \\mathbf{e}_y \\quad , \\quad \\mathbf{G}(\\mathbf{x}) = v(x,y) \\mathbf{e}_x + u(x,y) \\mathbf{e}_y \\ ,\n\\] then we can write \\[\n\\oint_{\\mathcal{C}} dz \\ f(z) = \\oint_{\\mathcal{C}} \\mathbf{F} \\cdot d\\mathbf{x} + \\oint_{\\mathcal{C}} \\mathbf{G} \\cdot d\\mathbf{x} \\ .\n\\] If we now apply Stokes’ theorem to these two contour integrals, we can convert them into surface integrals to get \\[\n\\oint_{\\mathcal{C}} dz \\ f(z) = \\int_{\\mathcal{S}} (\\nabla \\times \\mathbf{F}) \\cdot d\\mathbf{a} + \\int_{\\mathcal{S}} (\\nabla \\times \\mathbf{G}) \\cdot d\\mathbf{a} \\ ,\n\\] where \\(\\mathcal{S}\\) is any surface bounded by the closed loop \\(\\mathcal{C}\\). If we choose \\(\\mathcal{S}\\) to lie in the \\(xy\\)-plane then we can write \\(d\\mathbf{a} = dxdy \\mathbf{e}_z\\), in which case \\((\\nabla \\times \\mathbf{F}) \\cdot d\\mathbf{a} = (\\nabla \\times \\mathbf{F})_z\\) and \\((\\nabla \\times \\mathbf{G}) \\cdot d\\mathbf{a} = (\\nabla \\times \\mathbf{G})_z\\), and so we have \\[\n\\begin{align*}\n\\int_{\\mathcal{S}} (\\nabla \\times \\mathbf{F}) \\cdot d\\mathbf{a} &= \\int_\\mathcal{S} dxdy \\ \\bigg(\\frac{\\partial u}{\\partial x} - \\frac{\\partial v}{\\partial y}\\bigg) \\ , \\\\\n\\int_{\\mathcal{S}} (\\nabla \\times \\mathbf{G}) \\cdot d\\mathbf{a} &= \\int_\\mathcal{S} dxdy \\ \\bigg(\\frac{\\partial v}{\\partial y} + \\frac{\\partial u}{\\partial x}\\bigg) \\ .\n\\end{align*}\n\\] Now, if \\(f(z)\\) is analytic in this region, then the Cauchy-Riemann equations must be satisfied. This means each integrand must vanish, which means the original closed loop integral must vanish, thus proving Cauchy’s theorem.\nNote that this proof implicitly assumes that the partial derivatives of both \\(u(x,y)\\) and \\(v(x,y)\\) are continuous so that Stokes’ theorem could be applied. While this will almost always be the case in physics, it’s not strictly speaking necessary. Cauchy’s theorem holds even if the partial derivatives are not continuous, though that proof is a bit more technical.\n\n\nCauchy’s Integral Formula\nPerhaps the most important consequence of Cauchy’s theorem is the following integral formula. Suppose \\(f(z)\\) is analytic in some region \\(\\mathcal{R}\\) and \\(\\mathcal{C}\\) is some arbitrary closed loop inside \\(\\mathcal{R}\\). Then for any point \\(z\\) inside \\(\\mathcal{R}\\) we can write \\[\n\\boxed{\nf(z) = \\frac{1}{2\\pi i} \\oint_{\\mathcal{C}} dw \\ \\frac{f(w)}{w-z}\n}\\ .\n\\] This result is known as Cauchy’s Integral Formula. Geometrically, this formula says that the value of an analytic function at a point \\(z\\) is completely determined by the function’s values along any closed loop around \\(z\\). This is a powerful statement that’s analogous to Gauss’s Law in electrostatics, where the value of the electric field on any Gaussian surface enclosing a charge distribution must uniquely determine the charge distribution enclosed.\nLet’s now quickly prove this formula. First, notice that the integrand is analytic inside any region not containing the point \\(z_0\\). According to Cauchy’s theorem then, the integral will vanish for all closed loops that don’t include \\(z\\). It thus suffices for this proof to choose a closed loop containing \\(z\\)​. We can choose any closed loop we like. To keep things simple, let’s choose the loop to be a counterclockwise circle centered at \\(z\\) with radius \\(\\varepsilon \\ll 1\\). We can parametrize this path by choosing \\(-\\pi \\leq t \\leq \\pi\\) and letting \\[\nw(t) = \\varepsilon e^{it} + z \\ .\n\\] Now, if we add and subtract \\(f(z)\\) to the numerator of the integrand and plug in this parametrization, we get \\[\n\\begin{align*}\n\\frac{1}{2\\pi i} \\oint_{\\mathcal{C}} dw \\ \\frac{f(w)}{w-z} &= \\frac{1}{2\\pi i} \\oint_{\\mathcal{C}} dz \\ \\frac{f(z)}{w-z} + \\frac{1}{2\\pi i} \\oint_{\\mathcal{C}} dw \\ \\frac{f(w) - f(z)}{w-z} \\\\\n&= \\frac{1}{2\\pi i} f(z)  \\int_{-\\pi}^\\pi dt \\ \\frac{i\\varepsilon e^{it}}{\\varepsilon e^{it}} + \\frac{1}{2\\pi i} \\int_{-\\pi}^\\pi dt \\ \\frac{f(\\varepsilon e^{it} + z) - f(z)}{\\varepsilon e^{it}} i\\varepsilon e^{it} \\\\\n&= f(z) + \\frac{1}{2\\pi} \\int_{-\\pi}^\\pi dt \\ \\big[f(\\varepsilon e^{it} + z) - f(z)\\big] \\ .\n\\end{align*}\n\\] Now, observe that the remaining integral on the right-hand side is bounded by \\[\n\\bigg|\\int_{-\\pi}^\\pi dt \\ \\big[f(\\varepsilon e^{it} + z) - f(z)\\big]\\bigg| \\leq 2\\pi \\varepsilon \\cdot \\max \\big|f(\\varepsilon e^{it} + z) - f(z)\\big| \\ .\n\\] Since we assume \\(f(z)\\) is analytic it must also be continuous. This means as \\(\\varepsilon \\to 0\\) that \\(f(w) \\to f(z)\\), which means the right-hand side vanishes, which means the integral itself must vanish, thus proving Cauchy’s integral formula.\nCauchy’s integral formula turns out to imply something very powerful about analytic functions, namely that every analytic function is infinitely differentiable. This is not true for differentiable real functions. Just because a real function has a first derivative doesn’t mean it has a second derivative or any higher derivatives.\nTo see why this is true, suppose we take the derivative of both sides with respect to \\(z\\). We can then pull the derivative inside the integral sign to get \\[\n\\frac{d}{dz} f(z) = \\frac{1}{2\\pi i} \\oint_{\\mathcal{C}} dw \\ \\frac{f(w)}{(w-z)^2} \\ .\n\\] Now, the right-hand side is still an integral of an analytic function over a numerator of some power of \\(w-z\\). This means we can apply the same logic as we did in the proof above to show that it must equal the left-hand side. Moreover, it implies that the derivative of \\(f(z)\\) must be analytic as well at \\(z\\).\nWe can do this as many times as we like by continuing to differentiate both sides. Taking \\(n\\) derivatives with respect to \\(z\\), we get \\[\n\\frac{d^n}{dz^n} f(z) = \\frac{n!}{2\\pi i} \\oint_{\\mathcal{C}} dw \\ \\frac{f(w)}{(w-z)^{n+1}} \\ .\n\\] This implies that for all \\(n\\), the \\(n\\)th derivative of \\(f(z)\\) must exist at the point \\(z\\), and must be analytic. That is, any function \\(f(z)\\) that is analytic on some region \\(\\mathcal{R}\\) is also infinitely differentiable on that same region, and all its derivatives are analytic as well. Interestingly, this formula can also be used as a basis to define fractional derivatives where \\(n\\) need no longer be an integer.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Appendix II: Complex Analysis</span>"
    ]
  },
  {
    "objectID": "electrodynamics/complex-analysis.html#power-series",
    "href": "electrodynamics/complex-analysis.html#power-series",
    "title": "Appendix II: Complex Analysis",
    "section": "Power Series",
    "text": "Power Series\nWe’ll now derive the two important types of power series we see in complex analysis, the complex Taylor series for analytic functions, and its meromorphic extension known as the Laurent series. We will also introduce an important concept in mathematical physics known as analytic continuation.\n\nTaylor Series\nSuppose we have a complex-valued power series of the form \\[\n\\sum_{n=0}^\\infty a_n (z - z_0)^n = a_0 + a_1 (z-z_0) + a_2 (z-z_0)^2 + \\cdots \\ .\n\\] As with a real power series, these will converge to a valid function so long as the root test is satisfied, \\[\n\\lim_{n \\to \\infty} |a_n z^n|^{1/n} &lt; 1 \\ .\n\\] If we solve for the value of \\(|z|\\) such that \\(|a_n z^n|^{1/n} \\to 1\\) we get the radius of convergence \\(R\\) of the power series, \\[\nR = \\lim_{n \\to \\infty} \\frac{1}{|a_n z_n|^{1/n}} \\ .\n\\] A power series will converge to a valid function inside any region where \\(|z| &lt; R\\), called its disk of convergence \\(\\mathcal{D}\\).\nMoreover, suppose we have two power series that equal each other in some region \\(\\mathcal{R}\\) containing the point \\(z_0\\), where \\(\\mathcal{R}\\) lies inside the disk of convergence of both power series, \\[\n\\sum_{n=0}^\\infty a_n (z - z_0)^n = \\sum_{n=0}^\\infty b_n (z - z_0)^n \\ .\n\\] If we move everything to the left-hand side, we get \\[\n\\sum_{n=0}^\\infty (a_n-b_n) (z - z_0)^n = 0 \\ .\n\\] The only way this can be true for all \\(z\\) in \\(\\mathcal{R}\\) is if \\(a_n = b_n\\) for all \\(n\\). That is, the two power series must be identical inside \\(\\mathcal{R}\\). In fact, the two series must be identical inside the overlapping region of their disks of convergence. This seemingly trivial fact is sometimes called the identity theorem for power series.\nNow, suppose \\(f(z)\\) is analytic inside some region \\(\\mathcal{R}\\) containing \\(z_0\\). Suppose we can express \\(f(z)\\) as a power series of the form \\[\nf(z) = \\sum_{n=0}^\\infty a_n (z - z_0)^n \\ ,\n\\] where the power series is defined on some disk of convergence \\(\\mathcal{D}\\). In the region where \\(\\mathcal{R}\\) and \\(\\mathcal{D}\\) overlap, \\(f(z)\\) must also be analytic, which according to Cauchy’s integral formula means it will have infinitely many derivatives. If we differentiate both sides \\(n\\) times at the point \\(z=z_0\\), we can find the unique choice of coefficients \\(a_n\\) that determine the power series, \\[\n\\frac{d^n}{dz^n} f(z_0) = a_n n! \\quad \\Longrightarrow \\quad a_n = \\frac{1}{n!} \\frac{d^n}{dz^n} f(z_0) \\ .\n\\] Plugging these back into the power series representation, we have \\[\nf(z) = \\sum_{n=0}^\\infty \\frac{(z-z_0)^n}{n!} \\frac{d^n}{dz^n} f(z_0) \\ .\n\\] This is called the Taylor series of \\(f(z)\\) about the point \\(z=z_0\\). According to Taylor’s theorem, we know that this series will be well-defined and unique inside the overlapping region containing both \\(\\mathcal{R}\\) and \\(\\mathcal{D}\\).\nIn most respects, the complex Taylor series behaves pretty much identically to the real Taylor series. For instance, we have \\[\ne^z = \\sum_{n=0}^\\infty \\frac{z^n}{n!} \\ .\n\\] Like its real counterpart, the radius of convergence is infinite, which means this series is valid for all \\(z\\) in the complex plane.\n\n\nAnalytic Continuation\nIf a power series is analytic, we can often extend it to an analytic function that’s well-defined even beyond the disk of convergence. This is known as analytic continuation. More formally, suppose we have a complex power series \\(P(z)\\) with a disk of convergence \\(\\mathcal{D}\\), and \\(P'(z)\\) is some other power series with a disk of convergence \\(\\mathcal{D}'\\). If \\(\\mathcal{D}\\) is a subregion of \\(\\mathcal{D}'\\), we say that the power series \\(P'(x)\\) is an analytic continuation of \\(P(x)\\) from the smaller disk \\(\\mathcal{D}\\) to the larger disk \\(\\mathcal{D}'\\).\nIt’s a known fact that if \\(P'(x)\\) is an analytic continuation of \\(P(x)\\) from \\(\\mathcal{D}\\) to \\(\\mathcal{D}'\\), then \\(P'(x)\\) is the unique analytic continuation of \\(P(x)\\) to \\(\\mathcal{D}'\\). This means that \\(P'(x)\\) is the only possible analytic function to \\(\\mathcal{D}'\\) such that \\(P'(x) = P(x)\\) on \\(\\mathcal{D}\\). Of course, \\(P'(x)\\) may have many functional representations, but when expanded as a power series it must equal the original power series on \\(\\mathcal{D}\\).\nThe canonical example of analytic continuation is the geometric series. Consider the power series \\[\nP(z) = \\sum_{n=0}^\\infty z^n = 1 + z + z^2 + \\cdots \\ .\n\\] It’s easy to see that this power series has a radius of convergence \\(R=1\\), and so its disk of convergence \\(\\mathcal{D}\\) will be the disk of all points \\(z\\) where \\(|z| &lt; 1\\). However, we know that the geometric series can also be written in a closed form by the function \\[\nf(z) = \\frac{1}{1 - z} \\ .\n\\] This function \\(f(z)\\) is analytic anywhere \\(z \\neq 1\\), which means we can Taylor expand it about any point \\(z_0 \\neq 1\\) we like. If we do that, we get a new power series \\(P'(x)\\) of the form \\[\nP'(x) = \\sum_{n=0}^\\infty \\frac{(z-z_0)^n}{(1-z_0)^{n+1}} = \\frac{1}{1-z_0} + \\frac{z-z_0}{(1-z_0)^2} + \\frac{(z-z_0)^2}{(1-z_0)^3} + \\cdots \\ .\n\\] The radius of convergence of this power series is \\(R' = |1-z_0|\\), and so its disk of convergence \\(\\mathcal{D}'\\) will be the disk of all points \\(z\\) where \\(|z-z_0| &lt; |1-z_0|\\). Provided \\(|z_0| &gt; 1\\), \\(P'(x)\\) will be an analytic continuation of \\(P(x)\\) to this larger disk, and it must be the case that \\(P'(x) = P(x)\\) in the region where the two disks overlap. In fact, we can repeat this as often as we like by expanding the function about different points, creating an ever larger analytic continuation. In the end we’ll end up with a function \\(f(z)\\) that’s analytic everywhere except \\(z=1\\), which is the closed form above.\nThere are many more interesting examples of analytic continuation than this. In fact, we can often analytically continue a function \\(f(z)\\) to another function \\(g(z)\\) whether \\(f(z)\\) is a power series or not. If \\(f(z)\\) is analytic on some region \\(\\mathcal{R}\\) and \\(g(z)\\) is some other function that’s analytic on a larger region \\(\\mathcal{R}'\\), we say \\(g(z)\\) is an analytic continuation of \\(f(z)\\) to the larger region \\(\\mathcal{R}'\\) provided \\(f(z) = g(z)\\) on the smaller region \\(\\mathcal{R}\\).\nFor instance, consider the factorial function \\(n!\\) defined for integers \\(n=1,2,3,\\cdots\\) by \\[\nn! = n (n-1) (n-2) \\cdots 1 \\ .\n\\] Now, observe that we can also express \\(n!\\) by the following real integral, \\[\nn! = \\int_0^\\infty dx \\ x^n e^{-x} \\ .\n\\] This can easily be shown by using integration by parts \\(n\\) times and noting the boundary terms always vanish. Now, we can extend the integral on the right into the complex plane by replacing \\(n\\) with \\(z-1\\) to get a function \\(\\Gamma(z)\\) defined by \\[\n\\Gamma(z) = \\int_0^\\infty dx \\ x^{z-1} e^{-x} \\ .\n\\] This function is well-defined and analytic so long as \\(\\text{Re} \\ z \\geq 0\\). It’s called the gamma function. When \\(z\\) is an integer we have \\[\n\\Gamma(n) = (n+1)! \\ .\n\\] In fact, one can show that the gamma function satisfies the recursive relation \\[\n\\Gamma(z+1) = z \\Gamma(z) \\ .\n\\] If we now solve for \\(\\Gamma(z)\\) and keep applying this recursive relation \\(n\\) times, we get \\[\n\\Gamma(z) = \\frac{\\Gamma(z+n)}{z(z+1)(z+2) \\cdots (z+n-1)} \\ .\n\\] As expressed in this form, \\(\\Gamma(z)\\) will be well-defined and analytic at any point where \\(z \\neq 0,-1,-2,\\cdots\\). We can thus think of this relation as an analytic continuation of the Gamma function, and hence of the factorial function, to the whole complex plane.\n\n\nLaurent Series\nNow that we’ve discussed analytic functions in some depth, we will now turn our attention to functions with singularities, or points where either the function isn’t well-defined or the derivative doesn’t exist.\nSuppose a function \\(f(z)\\) has a pole at a point \\(z=z_0\\). If we tried to expand \\(f(z)\\) into a Taylor series, we could only do so at non-singular points away from \\(z=z_0\\). But what would happen if we insisted we wanted to expand \\(f(z)\\) right at the pole \\(z=z_0\\)?\nTo address this question let’s consider a more general setup. Suppose \\(f(z)\\) is potentially non-analytic inside some region \\(\\mathcal{S}\\) containing a point \\(z_0\\), which may or may not be singular, but \\(f(z)\\) is analytic outside of \\(\\mathcal{S}\\) in some larger region \\(\\mathcal{R}\\). We now want to use Cauchy’s integral formula, but to do that we need to make sure we do so on a region where \\(f(z)\\) is analytic. We define a contour on the analytic region \\(\\mathcal{S}\\) as follows:\n\nSuppose the inner non-analytic region \\(\\mathcal{R}\\) has a maximum radius \\(d_1\\) and the outer analytic region \\(\\mathcal{S}\\) a minimum radius of \\(d_2\\).\nLet \\(\\mathcal{C}_1\\) be a circular path centered at \\(z_0\\) of radius \\(r_1 &gt; d_1\\). This will be our inner loop.\nLet \\(\\mathcal{C}_2\\) be another circular path of a larger radius \\(d_2 &gt; r_2 &gt; r_1\\). This will be our outer loop.\nLet \\(\\mathcal{L}\\) be a linear path connecting the inner and outer circles radially.\n\nWe now define a combined closed loop \\(\\mathcal{C}\\) from these paths as follows:\n\nWe start at the intersection point of \\(\\mathcal{L}\\) and \\(\\mathcal{C}_2\\) and traverse \\(\\mathcal{C}_2\\) counterclockwise in a full rotation.\nNext, we traverse inward radially along \\(\\mathcal{L}\\) until we reach the inner circle \\(\\mathcal{C}_1\\).\nNext, we traverse \\(\\mathcal{C}_1\\) clockwise in a full rotation until we return to the intersection point of \\(\\mathcal{L}\\) and \\(\\mathcal{C}_1\\).\nFinally, we traverse \\(\\mathcal{L}\\) radially outward until we get back to the point on \\(\\mathcal{C}_2\\) where we started.\n\nSee the figure below for an illustration of this closed loop.\nFIGURE\nNow, \\(f(z)\\) will be analytic anywhere where \\(d_1 &lt; |z-z_0| &lt; d_2\\). Since \\(\\mathcal{C}\\) lies inside this region by construction, we can use Cauchy’s integral formula to write \\[\nf(z) = \\frac{1}{2\\pi i} \\oint_{\\mathcal{C}} dw \\ \\frac{f(w)}{w-z} \\ .\n\\] Next, we decompose the combined loop \\(\\mathcal{C}\\) into its constituent paths, but we have to make sure the signs are correct. Since we traverse the outer circle \\(\\mathcal{C}_2\\) counterclockwise, that integral will get a plus sign. Since we traverse the inner circle \\(\\mathcal{C}_1\\) clockwise, that integral will get a plus sign. The two integrals over the radial path \\(\\mathcal{L}\\) run in opposite direction, and so those will cancel each other out. We thus end up with \\[\nf(z) = \\frac{1}{2\\pi i} \\oint_{\\mathcal{C}_2} dw \\ \\frac{f(w)}{w-z} - \\frac{1}{2\\pi i} \\oint_{\\mathcal{C}_1} dw \\ \\frac{f(w)}{w-z} \\ .\n\\] Notice that each integrand contains a factor \\(1/(w-z)\\). We want to expand this in a power series, but we need to do so in a way such that the power series is well-defined in the annular region where \\(r_1 \\leq |z-z_0| \\leq r_2\\). First, notice that along the outer circle \\(\\mathcal{C}_2\\) that \\(|z-z_0| &lt; r_2\\) but \\(|w-z_0| = r_2\\) since \\(w\\) is integrated along the circle. We can thus expand \\(1/(w-z)\\) here as a geometric series of the form \\[\n\\text{on} \\ \\mathcal{C}_2: \\ \\frac{1}{w-z} = \\frac{1}{w-z_0} \\frac{1}{1-\\frac{z-z_0}{w-z_0}} = \\frac{1}{w-z_0} \\sum_{n=0}^\\infty \\bigg(\\frac{z-z_0}{w-z_0}\\bigg)^n \\ .\n\\] This geometric series is guaranteed to converge along \\(\\mathcal{C}_2\\) by construction. Next, we want to do the same thing, but along the inner circle \\(\\mathcal{C}_1\\). Along this circle we have \\(|z-z_0| &gt; r_1\\), but \\(|w-z_0| = r_1\\) since \\(w\\) is integrated along the circle. We can thus expand \\(1/(w-z)\\) here as a geometric series of the form \\[\n\\text{on} \\ \\mathcal{C}_1: \\ \\frac{1}{w-z} = -\\frac{1}{z-z_0} \\frac{1}{1-\\frac{w-z_0}{z-z_0}} = -\\frac{1}{z-z_0} \\sum_{n=0}^\\infty \\bigg(\\frac{w-z_0}{z-z_0}\\bigg)^n \\ .\n\\] Again, this geometric series is guaranteed to converge along \\(\\mathcal{C}_1\\) by construction. Plugging these expressions back into Cauchy’s integral formula for \\(f(z)\\), we have \\[\n\\begin{align*}\nf(z) &= \\frac{1}{2\\pi i} \\oint_{\\mathcal{C}_2} dw \\ f(w) \\bigg[\\frac{1}{w-z_0} \\sum_{n=0}^\\infty \\bigg(\\frac{z-z_0}{w-z_0}\\bigg)^n\\bigg] - \\frac{1}{2\\pi i} \\oint_{\\mathcal{C}_1} dw \\ f(w) \\bigg[-\\frac{1}{z-z_0} \\sum_{n=0}^\\infty \\bigg(\\frac{w-z_0}{z-z_0}\\bigg)^n\\bigg] \\\\\n&= \\frac{1}{2\\pi i} \\sum_{n=0}^\\infty (z-z_0)^n \\oint_{\\mathcal{C}_2} dw \\ \\frac{f(w)}{(w-z_0)^{n+1}} + \\frac{1}{2\\pi i} \\sum_{n=0}^\\infty \\frac{1}{(z-z_0)^{n+1}} \\oint_{\\mathcal{C}_1} dw \\ f(w) (w-z_0)^n \\ .\n\\end{align*}\n\\] We now make a change of index on the second sum by letting \\(n \\to -(n+1)\\). Doing that means \\(n\\) now runs from \\(n=-\\infty\\) to \\(n=-1\\) in this sum and \\(z-z_0\\) and \\(w-w_0\\) swap places. We then end up with \\[\nf(z) = \\frac{1}{2\\pi i} \\sum_{n=0}^\\infty (z-z_0)^n \\oint_{\\mathcal{C}_2} dw \\ \\frac{f(w)}{(w-z_0)^{n+1}} + \\frac{1}{2\\pi i} \\sum_{n=-\\infty}^{-1} (z-z_0)^n \\oint_{\\mathcal{C}_1} dw \\ \\frac{f(w)}{(w-z_0)^{n+1}} \\ .\n\\] Notice now that each integral is identical apart from the path they traverse. We can now join the two paths together by letting the inner circle \\(\\mathcal{C}_2\\) be traversed counterclockwise instead of clockwise. Then we can combine the sums together and write \\[\nf(z) = \\sum_{n=-\\infty}^\\infty \\bigg(\\frac{1}{2\\pi i}\\oint_{\\mathcal{C}} dw \\ \\frac{f(w)}{(w-z_0)^{n+1}} \\bigg) (z-z_0)^n \\ ,\n\\] where we’ve now redefined \\(\\mathcal{C} \\equiv \\mathcal{C}_1 = \\mathcal{C}_2\\) for convenience. What remains is an infinite power series that runs over all positive and negative integer powers of \\(z-z_0\\) with coefficients \\(a_n\\) given by the integral \\[\n\\boxed{\na_n \\equiv \\frac{1}{2\\pi i}\\oint_{\\mathcal{C}} dz \\ \\frac{f(z)}{(z-z_0)^{n+1}}\n} \\ .\n\\] Note that it’s not too hard to see that the closed loop \\(\\mathcal{C}\\) we take to find the coefficients \\(a_n\\) in this integral can be anything, so long as \\(\\mathcal{C}\\) lies in a region where \\(f(z)\\) is analytic. Provided this is the case, we can expand \\(f(z)\\) about the point \\(z=z_0\\) as \\[\n\\boxed{\nf(z) = \\sum_{n=-\\infty}^\\infty a_n (z-z_0)^n = \\cdots + \\frac{a_{-2}}{(z-z_0)^2} + \\frac{a_{-1}}{z-z_0} + a_0 + a_1 (z-z_0) + a_2 (z-z_0)^2 + \\cdots\n} \\ .\n\\] This is called the Laurent series of \\(f(z)\\) about the point \\(z=z_0\\). By the identity theorem for power series, the Laurent series will be unique for any analytic path \\(\\mathcal{C}\\) and any point \\(z_0\\).\nIt should be clear that the Laurent series will converge inside an annulus centered about \\(z_0\\) provided there are no other singularities contained inside the annulus. If the closest singularity to \\(z_0\\) is \\(z_1\\), then the Laurent series will converge inside any annulus whose outer radius is less than \\(|z_1-z_0|\\). If \\(z_0\\) is itself singular, then the inner radius must be non-zero.\nThe Laurent series is perhaps best thought of as an extension of the Taylor series to non-analytic functions. To see why, suppose that \\(f(z)\\) is analytic inside the region \\(\\mathcal{R}\\) where we initially assumed \\(f(z)\\) might have singularities. Then the negative coefficients \\(a_{-n}\\) in the Laurent series will all vanish since \\[\na_{-n} = \\frac{1}{2\\pi i} \\oint_{\\mathcal{C}} dz \\ \\frac{f(z)}{(z-z_0)^{-n+1}} = \\oint_{\\mathcal{C}} dz \\ f(z) (z-z_0)^{n-1} \\ ,\n\\] whose integrand is evidently an analytic function when \\(n\\) is positive, and so \\(a_{-n}\\) will vanish by Cauchy’s theorem. Moreover, the positive coefficients \\(a_n\\) will be given by the Cauchy integral formula for derivatives, which says \\[\na_n = \\frac{1}{2\\pi i}\\oint_{\\mathcal{C}} dz \\ \\frac{f(z)}{(z-z_0)^{n+1}} = \\frac{1}{n!} \\frac{d^n}{dz^n} f(z_0) \\ .\n\\] Plugging these coefficients back into the Laurent series then gives a Taylor series for \\(f(z)\\), provided \\(f(z)\\) is analytic.\nWhat if \\(f(z)\\) is not analytic? How do we find its Laurent series then? One way would be to define a contour and calculate the coefficients \\(a_n\\) via the integral defined above. But we often don’t need to. If we can find an expansion of \\(f(z)\\) in powers of \\(z\\) about a point \\(z=z_0\\), we know it must be unique inside its annulus of convergence by the identity theorem.\nFor example, consider the function \\(f(z) = e^{1/z}\\). Clearly this function is non-analytic at the point \\(z=0\\). Nevertheless we can Laurent expand it at \\(z=0\\) by Taylor expanding the exponential in powers of \\(1/z\\), in which case we get \\[\ne^{1/z} = \\sum_{n=0}^\\infty \\frac{(1/z)^n}{n!} = \\sum_{n=-\\infty}^0 \\frac{z^n}{(-n)!} = 1 + \\frac{1}{z} + \\frac{1}{2z^2} + \\cdots \\ .\n\\]\nThis expansion is well-defined on any annulus with a positive inner radius \\(r &gt; 0\\). That is, its annulus of convergence is the complex plane with the origin \\(z=0\\) removed. This function is interesting in that all the positive coefficients are zero, while all the negative coefficients are non-zero. This is an example of a function with an essential singularity.\nIt turns out that functions with essential singularities behave unusually. If \\(f(z)\\) has an essential singularity at \\(z=z_0\\), then for any region containing this point \\(f(z)\\) takes on all possible complex values except possibly one, infinitely many times. For example, inside any disk centered at \\(z=0\\), the function \\(f(z) = e^{1/z}\\) takes on all values except \\(z=0\\) infinitely many times. This strange result is known as Picard’s Great Theorem. Its proof is well beyond the scope of this course.\nAs another example, consider the function \\[\nf(z) = \\frac{1}{z(z-1)} \\ .\n\\] This function is clearly singular at the points \\(z=0\\) and \\(z=1\\), and analytic everywhere else. We can easily Laurent expand this function about \\(z=0\\) by noting that we can also write it as a partial fraction expansion involving a geometric series, \\[\n\\frac{1}{z(z-1)} =  -\\frac{1}{z} - \\frac{1}{1-z} = -\\frac{1}{z} - \\sum_{n=0}^\\infty z^n = -\\sum_{n=-1}^\\infty z^n \\ ,\n\\] where in the last step we combined the fractions together by shifting the index \\(n\\) down one. This expansion is evidently valid inside any annulus with an inner radius \\(r&gt;0\\) and an outer radius \\(R &lt; 1\\). Evidently, all negative coefficients except \\(a_{-1}\\) vanish in this expansion. Functions with finitely many nonzero negative expansion coefficients like this are special. Such functions are called meromorphic functions. We’ll study these in more detail in the next section.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Appendix II: Complex Analysis</span>"
    ]
  },
  {
    "objectID": "electrodynamics/complex-analysis.html#residue-calculus",
    "href": "electrodynamics/complex-analysis.html#residue-calculus",
    "title": "Appendix II: Complex Analysis",
    "section": "Residue Calculus",
    "text": "Residue Calculus\nWe will now study the behavior of the singularities of complex functions in more depth. This will lead us to a brief study of meromorphic functions, and then finally to the powerful residue theorem.\n\nSingularities\nSuppose \\(f(z)\\) is some complex function with a singularity at a point \\(z=z_0\\), meaning \\(|f(z)| \\to \\infty\\) as \\(z \\to z_0\\). If we Laurent expand \\(f(z)\\) about some annulus centered at the point \\(z_0\\) we get an infinite power series in both the positive and negative powers of \\(z-z_0\\) of the form \\[\nf(z) = \\sum_{n=-\\infty}^\\infty a_n (z-z_0)^n = \\cdots + \\frac{a_{-2}}{(z-z_0)^2} + \\frac{a_{-1}}{z-z_0} + a_0 + a_1 (z-z_0) + a_2 (z-z_0)^2 + \\cdots \\ .\n\\] If all negative coefficients \\(a_{-n} = 0\\) then \\(f(z)\\) will be analytic at \\(z_0\\), and hence \\(z_0\\) won’t be a singularity. If any of the negative coefficients are nonzero \\(z_0\\) will be a singularity, and we can classify the nature of this singularity by counting how many nonzero negative coefficients the expansion has:\n\nIf only \\(a_{-1} \\neq 0\\) and all other \\(a_{-n} = 0\\), we say that \\(z_0\\) is a simple pole, or pole of order one, of \\(f(z)\\).\nIf \\(a_{-1}, a_{-2}, \\cdots, a_{-m} \\neq 0\\) and all other \\(a_{-n} = 0\\), we say that \\(z_0\\) is a pole of order \\(m\\) of \\(f(z)\\).\nIf infinitely many \\(a_{-n} \\neq 0\\), we say that \\(z_0\\) is an essential singularity of \\(f(z)\\).\n\nAn example of a function with a simple pole is the function \\(f(z) = 1/z\\), which has a simple pole at \\(z=0\\). Its Laurent expansion about any annulus at \\(z=0\\) is just the function itself, with \\(a_{-1} = 1\\) and all other \\(a_{\\pm n} = 0\\).\nAn example of a function with a pole of order \\(m\\) is \\(f(z) = 1/z^m\\), which has a pole of order \\(m\\) at \\(z=0\\). Its Laurent expansion about any annulus at \\(z=0\\) is also just the function itself, with \\(a_{-m} = 1\\) and all other \\(a_{\\pm n} = 0\\).\nAn example of a function with an essential singularity is the function \\(f(z) = e^{1/z}\\). We saw in the previous section that we could Laurent expand this function about any annulus at \\(z=0\\) by \\[\ne^{1/z} = \\sum_{n=-\\infty}^0 \\frac{z^n}{(-n)!} = 1 + \\frac{1}{z} + \\frac{1}{2z^2} + \\cdots \\ .\n\\] In this expansion the negative coefficients \\(a_{-n} = 1/(-n)!\\) for all \\(n\\), meaning they never vanish at a finite \\(n\\).\nPoles are special in that we can get rid of them with simple transformations. This contrasts heavily with essential singularities, which can’t be removed, hence the term essential. A function \\(f(z)\\) with a pole of order \\(m\\) at \\(z_0\\) will always be analytic in some region around \\(z_0\\). We can simply multiply \\(f(z)\\) by \\((z-z_0)^m\\) to remove the singularity. That is, the function \\[\ng(z) \\equiv (z-z_0)^m f(z)\n\\] is analytic in some region around \\(z_0\\). This can’t be done for essential singularities.\nIf \\(z_0\\) is a pole of some function \\(f(z)\\), we also call \\(z_0\\) an isolated singularity. This means that in some small region about \\(z_0\\), the function \\(f(z)\\) is analytic except at the point \\(z_0\\). Poles aren’t the only type of isolated singularity, but they’re the most important. Another type of isolated singularity is a removable singularity. We say \\(z_0\\) is a removable singularity if the function is just not defined at a given point, not if it blows up at that point. A trivial example is \\(f(z) = z/z\\), which is one when \\(z \\neq 0\\) but undefined at the removable singularity \\(z=0\\). Removable singularities aren’t terribly interesting, since we could just define \\(f(z_0)\\) by a limit.\nA function that is analytic every except at a set of isolated poles is called a meromorphic function. Meromorphic functions are in a sense “almost analytic”, in the sense that it’s analytic except at a few poles, and those poles we can get rid of via simple transformations. Functions of this type often involve ratios of analytic functions, for example \\(f(z) = 1/z\\) or \\(f(z) = \\tan z\\).\nFunctions that blow up at infinity are said to have a singularity at infinity. If \\(f(z)\\) has a singularity at infinity, then we must have \\(f(z) \\to \\infty\\) as \\(z \\to \\infty\\) by definition. Observe that this is equivalent to the statement that \\(f(1/z) \\to 0\\) as \\(1/z \\to 0\\). This means we can study singularities at infinity by looking at \\(f(1/z)\\) as \\(z \\to 0\\). For example, consider the analytic function \\[\nf(z) = \\sin z = \\sin x \\cosh y + i \\cos x \\sinh y \\ .\n\\] Since both \\(\\cosh y\\) and \\(\\sinh y\\) go to infinity as \\(y \\to \\infty\\), we see that \\(f(z)\\) must have a singularity at infinity. This is an interesting result, since it’s not true for the real-valued sine function \\(f(x) = \\sin x\\), which stays bounded at infinity. To understand what kind, we can expand \\(f(z)\\) into a Taylor series about \\(z=0\\) and make the transformation \\(z \\to 1/z\\) to see that \\[\nf(1/z) = \\sin 1/z = \\sum_{n=0}^\\infty \\frac{(-1)^n}{(2n+1)!} \\frac{1}{z^{2n+1}} \\ .\n\\] Under this transformation, the Taylor series of \\(f(z)\\) at \\(z=0\\) becomes the Laurent series of \\(f(1/z)\\) at \\(z=0\\). Since this Laurent series contains infinitely many nonzero negative-power terms, the function \\(f(1/z)\\) has an essential singularity at \\(1/z=0\\), which means the original function \\(f(z) = \\sin z\\) has an essential singularity at \\(z=\\infty\\).\nThere is a final type of singularity briefly worth mentioning, namely branch points. Recall that many complex functions are multi-valued, for example the functions \\(f(z) = \\log z\\) or \\(f(z) = z^{p/q}\\). These functions both diverge at \\(z=0\\) and \\(z=\\infty\\). The multi-valued nature of these functions means it’s impossible to classify these singularities into the groups defined above, since to make the functions single-valued we need to specify a branch cut to join the two singularities together, and along that entire branch cut the function is neither continuous nor analytic.\n\n\nResidue Theorem\nSuppose \\(f(z)\\) has an isolated singularity at \\(z_0\\) and is analytic around \\(z_0\\). We can do a Laurent expansion of \\(f(z)\\) about \\(z_0\\) to get \\[\nf(z) = \\sum_{n=-\\infty}^\\infty a_n (z-z_0)^n \\ .\n\\] Now, suppose we wanted to integrate \\(f(z)\\) in some closed loop \\(\\mathcal{C}\\) about the singularity \\(z_0\\). We’ll assume the closed loop is a small counterclockwise circle centered at \\(z_0\\) of some small radius \\(\\varepsilon\\). We can make \\(\\varepsilon\\) as small as we like to ensure that no other singularities are contained inside the closed loop. Inside this small loop we can integrate \\(f(z)\\) by instead integrating its Laurent series term by term. Pulling the integral inside the summation sign, we have \\[\n\\oint_\\mathcal{C} dz \\ f(z) = \\sum_{n=-\\infty}^\\infty a_n \\oint_\\mathcal{C} dz \\ (z-z_0)^n \\ .\n\\] We now need to evaluate the integral of each power function \\((z-z_0)^n\\). We can do that by again parametrizing the circle in the usual way by letting \\(z(t) = z_0 + \\varepsilon e^{it}\\) and integrating from \\(t=-\\pi\\) to \\(t=\\pi\\) to get \\[\n\\oint_\\mathcal{C} dz \\ (z - z_0)^n = \\int_{-\\pi}^\\pi dt \\ (\\varepsilon e^{it})^n (i\\varepsilon e^{it}) = i\\varepsilon^{n+1} \\int_{-\\pi}^\\pi dt \\ e^{i(n+1)t} \\ .\n\\] Now, since the function \\(e^{i(n+1)t}\\) is periodic on the interval \\(-\\pi \\leq t \\leq \\pi\\), the integral will vanish whenever \\(n \\neq -1\\). When \\(n=-1\\) the integrand becomes one, in which case the integral is just \\(2\\pi\\). We thus have \\[\n\\oint_\\mathcal{C} dz \\ (z - z_0)^n = \\begin{cases}\n2\\pi i & n = -1 \\\\\n0 & n \\neq -1\n\\end{cases} \\ .\n\\] Plugging this back into the integral for \\(f(z)\\), we see that all but the \\(n=-1\\) terms in the series vanish, leaving \\[\n\\oint_\\mathcal{C} dz \\ f(z) = 2\\pi i a_{-1} \\ .\n\\] Evidently the \\(a_{-1}\\) coefficient is special, in that it’s the only one that remains when \\(f(z)\\) is integrated. For this reason we call the coefficient \\(a_{-1}\\) the residue of \\(f(z)\\) at the point \\(z_0\\). Residues turn out to be very important to the theory of complex integration.\nBut what we’ve shown is only true when integrating over a small loop about a single isolated singularity \\(z_0\\). What if we want to integrate \\(f(z)\\) over some more general closed loop of arbitrary size and shape? It turns out we get the same result, except now we need to sum over the residues of all the isolated singularities inside the closed loop.\nTo see why this is true, suppose \\(\\mathcal{C}\\) is some counterclockwise closed loop whose inner region contains some number of isolated singularities \\(z_1, z_2, \\cdots, z_k\\). We assume that no singularities lie directly on the closed loop itself, so that \\(f(z)\\) is analytic on \\(\\mathcal{C}\\). For each singularity \\(z_j\\), suppose \\(\\mathcal{C}_j\\) is a small counterclockwise circular path enclosing only the singularity \\(z_j\\). We can traverse the outer closed loop \\(\\mathcal{C}\\) by joining it to each \\(\\mathcal{C}_j\\) via a cut as we did when proving Cauchy’s integral formula.\nFIGURE\nBy traversing the inner circular paths in the opposite direction of the outer closed loop, we end up with \\[\n\\oint_\\mathcal{C} dz \\ f(z) = \\sum_{j=1}^k \\oint_{\\mathcal{C}_j} dz \\ f(z) \\ .\n\\] Using the same argument applied before, the integral over each \\(\\mathcal{C}_j\\) will yield \\(2\\pi i a_{-1}(z_j)\\). We thus have \\[\n\\boxed{\n\\oint_C dz \\ f(z) = 2\\pi i \\sum_{j=1}^k a_{-1}(z_k)\n} \\ .\n\\] This important result is known as the Residue Theorem. It says that so long as we have a function with isolated singularities, we can evaluate its complex contour integral over any path by finding all the residues inside the closed loop, summing them up, and multiplying by \\(2\\pi i\\).\nNote that as stated, the residue theorem is only true for simple closed loops that loop around each singularity \\(z_j\\) only once counterclockwise. In general, we can imagine a loop that loops around each singularity \\(w_j\\) times, where \\(w_j\\) is known as the winding number of \\(z_j\\). Each counterclockwise traversal of \\(z_j\\) adds one from \\(w_j\\), while each clockwise traversal of \\(z_j\\) subtracts one from \\(w_j\\). Any singularities not looped over have a winding number \\(w_j = 0\\). We can then write the residue theorem as \\[\n\\oint_C dz \\ f(z) = 2\\pi i \\sum_{j=1}^k w_j a_{-1}(z_k) \\ .\n\\] We won’t use this more general formula as much in practice. Most important is to note that if \\(\\mathcal{C}\\) is traversed clockwise exactly once, each winding number will be \\(w_j = -1\\), and hence the right-hand side will acquire a minus sign.\n\n\nResidues\nOf course, for the residue theorem to be useful, we need an easier way to find the residues than to do the integral the hard way. We can find residues in a few ways. The first way is to find the Laurent series of \\(f(z)\\) at each singularity inside the closed loop and extract the \\(a_{-1}\\) coefficients. Sometimes this can be helpful, but there’s often an even easier way to find residues for lower order poles that lets us avoid having to calculate the entire Laurent series.\nSuppose \\(z_0\\) is a pole of order \\(m\\) of \\(f(z)\\). If we expand \\(f(z)\\) in a Laurent series about \\(z_0\\), we get \\[\nf(z) = \\frac{a_{-m}}{(z-z_0)^m} + \\cdots + \\frac{a_{-1}}{z-z_0} + a_0 + \\cdots \\ .\n\\] If we now multiply both sides by \\((z-z_0)^m\\) we get a new function \\(g(z) = (z-z_0)^m f(z)\\) with \\[\ng(z) = (z-z_0)^m f(z) = a_{-m} + \\cdots + a_{-1} (z-z_0)^{m-1} + a_0 (z-z_0)^m + \\cdots \\ .\n\\] This new function \\(g(z)\\) is evidently analytic at \\(z_0\\). This means \\(g(z)\\) also has a Taylor series expansion at \\(z_0\\), with \\[\ng(z) = g(z_0) + \\cdots + \\frac{(z-z_0)^{m-1}}{(m-1)!} \\frac{d^{m-1}}{dz^{m-1}} g(z_0) + \\frac{(z-z_0)^m}{m!} \\frac{d^m}{dz^m} g(z_0) + \\cdots \\ .\n\\] The two expansions of \\(g(z)\\) must be equal term by term by the identity theorem, which means we must have \\[\na_{-1} = \\frac{1}{(m-1)!} \\frac{d^{m-1}}{dz^{m-1}} g(z_0) \\ .\n\\] This means if \\(z_0\\) is a pole of order \\(m\\) of \\(f(z)\\), we have the following formula for the residue \\(a_{-1}(z_0)\\), \\[\n\\boxed{\na_{-1}(z_0) = \\frac{1}{(m-1)!} \\frac{d^{m-1}}{dz^{m-1}} \\bigg|_{z=z_0} (z-z_0)^m f(z)\n} \\ .\n\\] In most cases, this is the quickest and simplest way to find the residues of a given function.\nAs an easy example, consider the function \\[\nf(z) = \\frac{e^z}{z - 1} \\ ,\n\\] This function has a single pole of order 1 at \\(z=1\\), with a residue of \\[\na_{-1}(1) = (z - 1) f(z) \\bigg |_{z=1} = e \\ .\n\\] As another example, consider the function \\[\nf(z) = \\frac{1 + z^2}{z^2} \\ .\n\\] This function has a single pole of order 2 at \\(z=0\\), with residue \\[\na_{-1}(0) = \\frac{d}{dz} \\bigg|_{z=0} z^2 f(z) = \\frac{d}{dz} \\bigg|_{z=0} (1 + z^2) = 0 \\ .\n\\] As a final example let’s consider a function with multiple distinct poles. Consider the function \\[\nf(z) = \\frac{\\cos z}{z (z-\\pi)(z+\\pi)} \\ .\n\\] This function has three simple poles at \\(z=0\\), \\(z= \\pi\\), and \\(z=-\\pi\\). The residues are given by \\[\n\\begin{align*}\n&a_{-1}(0) = z f(z) \\bigg |_{z=0} = -\\frac{1}{\\pi^2}  \\ , \\\\\n&a_{-1}(\\pi) = (z-\\pi) f(z) \\bigg |_{z=\\pi} = -\\frac{1}{2\\pi^2}  \\ , \\\\\n&a_{-1}(-\\pi) = (z+\\pi) f(z) \\bigg |_{z=-\\pi} = -\\frac{1}{2\\pi^2} \\ .\n\\end{align*}\n\\] Sometimes we’ll find ourselves needing to integrate over a closed loop that goes to infinity, for example over the upper half plane where \\(\\text{Im} \\ z &gt; 0\\). When this is the case, we need to account for the fact that we can have poles at infinity, which means we can have residues at infinity as well. Provided \\(f(z)\\) is a meromorphic function, its residue at infinity will just be minus the sum of all its finite residues. That is, if \\(f(z)\\) is meromorphic with isolated finite singularities \\(z_1, z_2, \\cdots, z_k\\), then \\[\na_{-1}(\\infty) = -\\sum_{j=1}^k a_{-1}(z_j) \\ .\n\\] An immediate implication of this result is that the integral of a meromorphic function over the whole complex plane is zero.\nWith this knowledge in hand, let’s now evaluate a few complex integrals using the residue theorem.\n\nExample: Evaluate \\(\\oint dz/z\\) over a counterclockwise unit circular path centered at the origin\nAs a simple example we’ve seen before, suppose we want to evaluate the following integral over a counterclockwise circular path of unit radius centered at the origin \\(z=0\\), \\[\n\\oint \\frac{dz}{z} \\ .\n\\] We saw before that the answer should be \\(2\\pi i\\). Let’s verify this with the residue theorem.\nThe function \\(f(z) = 1/z\\) has a single simple pole at \\(z=0\\), with residue \\[\na_{-1}(0) = z f(z) \\bigg |_{z=0} = 1 \\ .\n\\] By the residue theorem, we thus must have that \\[\n\\oint \\frac{dz}{z} = 2\\pi i \\ a_{-1}(0) = 2\\pi i \\ .\n\\] Notice that since the residue theorem only depends on the residues poles inside the closed loop, this answer will be the same for any counterclockwise closed loop we choose, so long as it contains the origin. If the loop doesn’t contain the origin then there are no residues inside, hence the integral will vanish as we’d expect by Cauchy’s theorem.\n\n\nExample: Evaluate \\(\\oint dz/(z^2 + 1)\\) over a counterclockwise circular path of radius \\(R&gt;1\\) centered at the origin\nSuppose we want to evaluate the following integral over a counterclockwise circular loop of radius \\(R &gt; 1\\) centered at the origin, \\[\n\\oint \\frac{dz}{z^2 + 1} \\ .\n\\] Notice that we can factor the denominator of the integrand \\(f(z) = \\frac{1}{z^2+1}\\) as \\[\nf(z) = \\frac{1}{(z-i)(z+i)} \\ .\n\\] This function evidently has two simple poles at \\(z = \\pm i\\). The residues are evidently \\[\na_{-1}(i) = -\\frac{i}{2} \\quad , \\quad a_{-1}(-i) = \\frac{i}{2} \\ .\n\\] Since we need to integrate over a circular loop of radius \\(R &gt; 1\\), both poles will be contained inside the loop, since \\(|\\pm i| = 1\\). By the residue theorem, we thus have \\[\n\\oint \\frac{dz}{z^2 + 1} = 2\\pi i \\bigg(\\frac{i}{2} - \\frac{i}{2}\\bigg) = 0 \\ .\n\\] The integral thus vanishes over closed loops containing both poles. Note that if we only integrated over one of the two poles the integral would not vanish. For instance, if we only considered a circular loop of radius \\(R=1\\) centered at \\(z=i\\), we’d instead have \\[\n\\oint \\frac{dz}{z^2 + 1} = 2\\pi i \\bigg(-\\frac{i}{2}\\bigg) = \\pi \\ .\n\\] This is a good reminder that in complex analysis, the value of a complex integral depends not only on the function, but also on the path chosen.\n\n\n\nDefinite Integrals\nIn physics, the residue theorem is most useful for evaluating certain types of real definite integrals that are difficult or impossible to evaluate in any other way.\nOne class of definite integrals amenable to this method are integrals of the form \\[\n\\int_0^{2\\pi} d\\varphi \\ f(\\sin\\varphi, \\cos\\varphi) \\ .\n\\] To convert this into a complex integral we let \\(z = e^{i\\varphi}\\). Then we have \\[\nd\\varphi = -i \\frac{dz}{z} \\quad , \\quad \\sin\\varphi = \\frac{z - 1/z}{2i} \\quad , \\quad \\cos\\varphi = \\frac{z + 1/z}{2} \\ .\n\\] Under this transformation, the path of integration becomes a counterclockwise circular loop of unit radius. We thus have \\[\n\\int_0^{2\\pi} d\\varphi \\ f(\\sin\\varphi, \\cos\\varphi) = -i \\oint \\frac{dz}{z} \\ f\\bigg(\\frac{z - 1/z}{2i}, \\frac{z + 1/z}{2}\\bigg) \\ .\n\\] Provided we can evaluate the closed loop integral on the right-hand side using the residue theorem, we have an answer for the original definite integral as well.\n\nExample: Evaluate \\(\\int_0^{2\\pi} d\\varphi/(1 + \\varepsilon \\cos\\varphi)\\) where \\(|\\varepsilon| &lt; 1\\)\nTo evaluate this integral we again let \\(z = e^{i\\varphi}\\). Plugging this in, we end up with a closed loop integral of the form \\[\n\\oint \\frac{dz}{z} \\frac{1}{1 + \\frac{\\varepsilon}{2} (z + 1/z)} = \\frac{2}{\\varepsilon} \\oint \\frac{dz}{z^2 + (2/\\varepsilon)z + 1} \\ .\n\\] The function \\(f(z)\\) in the integrand has two simple poles when the denominator is zero. These are evidently \\[\nz_\\pm = \\frac{1}{\\varepsilon} \\big(-1 \\pm \\sqrt{1 - \\varepsilon^2}\\big) \\ .\n\\] Since \\(|\\varepsilon| &lt; 1\\), we have \\(|z_+| &lt; 1\\) and \\(|z_-| &gt; 1\\), so only the pole \\(z_+\\) is inside of the circle of integration. Its residue is evidently \\[\na_{-1}(z_+) = (z-z_+) f(z) \\bigg|_{z=z_+} = \\frac{1}{z_+ - z_-} = \\frac{\\varepsilon}{2\\sqrt{1 - \\varepsilon^2}} \\ .\n\\] By the residue theorem, we thus have \\[\n\\frac{2}{\\varepsilon} \\oint \\frac{dz}{z^2 + (2/\\varepsilon)z + 1} = \\frac{2}{\\varepsilon} 2\\pi i a_{-1}(z_+) = \\frac{2\\pi i}{\\sqrt{1 - \\varepsilon^2}} \\ .\n\\] Finally, multiplying both sides by \\(-i\\) then gives the value of the definite integral we sought, \\[\n\\int_0^{2\\pi} \\frac{d\\varphi}{1 + \\varepsilon \\cos\\varphi} = \\frac{2\\pi}{\\sqrt{1 - \\varepsilon^2}} \\ .\n\\] Note if \\(|\\varepsilon| &gt; 1\\) the exact same logic would apply, except we’d use the residue of \\(z_-\\) instead, which would add a minus sign to the answer given.\n\nAnother class of definite integrals amenable to this method are integrals over the whole real line, \\[\n\\int_{-\\infty}^\\infty dx \\ f(x) \\ .\n\\] For the method of residues to work on these integrals, we need \\(f(z)\\) to be meromorphic in either the upper or lower half plane, and for \\(f(z)\\) to vanish at infinity at least as fast as \\(1/z^2\\). We will assume \\(f(z)\\) has no poles on the real axis in this discussion. We’ll see in the examples how to deal with situations where there are poles on the real axis.\nWe now define a closed loop integral over a semicircular loop \\(\\mathcal{C}\\) of radius \\(R \\gg 1\\) centered on the real axis. Letting \\(\\mathcal{C}_R\\) be the circular part of the path, we can decompose the closed loop integral into a real integral and the circular integral as \\[\n\\oint_\\mathcal{C} dz \\ f(z) = \\int_{-R}^R dx \\ f(x) + \\int_{\\mathcal{C}_R} dz \\ f(z) \\ .\n\\] The circular integral we can parametrize by letting \\(z(t) = R e^{it}\\) with \\(0 \\leq t \\leq \\pi\\), giving \\[\n\\oint_\\mathcal{C} dz \\ f(z) = \\int_{-R}^R dx \\ f(x) + \\int_0^\\pi dt \\ f(Re^{it}) i Re^{it} \\ .\n\\] Sending \\(R \\to \\infty\\) and requiring that \\(f(z)\\) vanish at infinity faster than \\(1/z^2\\), the circular part vanishes, leaving us with \\[\n\\oint_\\mathcal{C} dz \\ f(z) = \\int_{-\\infty}^\\infty dx \\ f(x) \\ .\n\\] To evaluate the closed loop integral on the left-hand side we can use the residue theorem, being sure to include all residues inside the semicircle, which will be all residues in either the upper or lower half plane as \\(R \\to \\infty\\). Once we’ve done that, we have the answer for the original definite integral as well.\n\n\nExample: Evaluate \\(\\int_{-\\infty}^\\infty dx/(1+x^2)\\)\nThis definite integral is of the form specified above. We thus consider the closed loop integral \\[\n\\oint \\frac{dz}{1 + z^2} \\ ,\n\\] where the closed loop is taken as a counterclockwise semicircular path of radius \\(R \\gg 1\\) in the upper half plane.\nThe denominator of the integrand \\(f(z)\\) can be factored, giving \\[\nf(z) = \\frac{1}{(z + i)(z - i)} \\ .\n\\] This means \\(f(z)\\) has two simple poles at the points \\(z = \\pm i\\). Since only \\(z = i\\) lies inside the closed loop, we need only find its residue, which is evidently \\[\na_{-1}(i) = (z-i) f(z) \\bigg|_{z=i} = \\frac{1}{2i} \\ .\n\\] By the residue theorem, we thus have \\[\n\\oint \\frac{dz}{1 + z^2} = 2\\pi i a_{-1}(i) = \\pi \\ .\n\\] Now, as we send \\(R \\to \\infty\\), the circular component of the integral vanishes since \\(f(z) \\to 0\\) as fast as \\(1/z^2\\). What remains is the definite integral we seek. Thus, we have \\[\n\\int_{-\\infty}^\\infty \\frac{dx}{1 + x^2} = \\pi \\ .\n\\] Note the result would be the same if we used a clockwise semicircular loop in the lower half plane. In that case, the residue \\(a_{-1}(-i) = -1/2i\\) would have an opposite sign, which would compensate for the sign from traversing in the opposite direction.\n\nAnother, closely related, class of definite integrals amenable to the method of residues are those of the form \\[\n\\int_{-\\infty}^\\infty dx \\ f(x) e^{iax} \\ .\n\\] Integrals of this type usually show up as Fourier transforms, and thus occur quite often in physics. We can solve integrals of this type in a similar was as the previous class of integrals, except with some slight modifications. We again extend \\(f(x)\\) to a complex function \\(f(z)\\), and require \\(f(z)\\) be meromorphic. We also require that \\(f(z)\\) vanish at infinity, but place no restriction on how fast \\(f(z)\\) decays at infinity.\nAs before, we consider a semicircular loop \\(\\mathcal{C}\\) of radius \\(R\\) whose diameter lies on the real axis, and whose circular part \\(\\mathcal{C}'\\) is traversed counterclockwise if in the upper half plane, and clockwise if in the lower half plane. Then we can write \\[\n\\oint_\\mathcal{C} dz \\ f(z) = \\int_{-R}^R dx \\ f(x) e^{iax} + \\int_{\\mathcal{C}_R} dz \\ f(z) e^{iaz} \\ .\n\\] Now, before we took \\(R \\to \\infty\\) and argued that the circular part of the integral vanishes, leaving the original definite integral. This time though we can’t easily follow the same argument. Instead we appeal to Jordan’s Lemma, which says that so long as \\(f(z)\\) is continuous along a circular path and goes to zero at infinity, then the circular part vanishes, leaving \\[\n\\oint_\\mathcal{C} dz \\ f(z) = \\int_{-\\infty}^\\infty dx \\ f(x) e^{iax} \\ .\n\\] Provided this is the case, we can again use the residue theorem to evaluate the definite integral as before.\n\n\nExample: Evaluate \\(\\int_0^\\infty dx \\ \\sin x / x\\)\nNotice that the integrand \\(f(x)\\) is even since \\(f(-x) = f(x)\\). This means we have \\[\n\\int_0^\\infty dx \\ \\frac{\\sin x}{x} = \\frac{1}{2} \\int_{-\\infty}^\\infty dx \\ \\frac{\\sin x}{x} \\ .\n\\] We can thus focus on evaluating the definite integral of \\(f(x)\\) over the whole real line. Consider the complex function \\[\nf(z) = \\frac{e^{iz}}{z} = \\frac{\\cos z}{z} + i \\frac{\\sin z}{z} \\ .\n\\] Evidently, the original real function \\(f(x)\\) is the imaginary part of the complex function \\(f(z)\\). The function \\(f(z)\\) has a single simple pole at the origin \\(z=0\\), with residue \\[\na_{-1}(0) = z f(z) \\bigg|_{z=0} = 1 \\ .\n\\] However, we run into a slight problem, in that the pole \\(z=0\\) lies on the real axis. To deal with this problem, we place a third clockwise circular path \\(\\mathcal{C}_r\\) of radius \\(r \\ll 1\\) around \\(z=0\\). The rest of the closed loop will again be a counterclockwise semicircular loop \\(\\mathcal{C}\\) of radius \\(R \\gg 1\\) with diameter along the real axis.\nFIGURE\nWe can then decompose \\(\\mathcal{C}\\) as follows, \\[\n\\oint_\\mathcal{C} dz \\ f(z) = \\int_{-R}^{-r} dx \\ f(x) + \\int_r^R dx \\ f(x) + \\int_{\\mathcal{C}_r} dz \\ f(z) + \\int_{\\mathcal{C}_R} dz \\ f(z) \\ .\n\\] First, notice that along this closed loop there are no residues inside, which means we have \\[\n\\oint_\\mathcal{C} dz \\ f(z) = 0 \\ .\n\\] In the end we’ll send \\(r \\to 0\\) and \\(R \\to \\infty\\) to recover the original definite integral, but first we need to deal with the two circular integrals over \\(\\mathcal{C}_r\\) and \\(\\mathcal{C}_R\\). Now, clearly \\(f(z) \\to 0\\) at infinity and is continuous along the outer path \\(\\mathcal{C}_R\\), which means by Jordan’s Lemma the outer \\(\\mathcal{C}_R\\) integral vanishes at infinity, \\[\n\\int_{\\mathcal{C}_R} dz \\ f(z) \\to 0 \\ .\n\\] Along the inner path \\(\\mathcal{C}_r\\), notice that integral is just half that of a counterclockwise circular loop of radius \\(r\\) centered at the origin, which means by the residue theorem we must have \\[\n\\int_{\\mathcal{C}_r} dz \\ f(z) = \\frac{1}{2} \\oint dz \\ f(z) = -\\pi i,\n\\] where the minus sign comes from traversing the inner loop clockwise. This is true for any radius \\(r \\ll 1\\).\nSending \\(r \\to 0\\) and \\(R \\to \\infty\\), we thus have \\[\n0 = \\int_{-\\infty}^\\infty dx \\ \\frac{\\sin x}{x} - \\pi i \\ .\n\\] Moving \\(\\pi i\\) to the left-hand side, taking its imaginary part, and dividing by a half, we finally see that \\[\n\\int_0^\\infty dx \\ \\frac{\\sin x}{x} = \\frac{\\pi}{2} \\ .\n\\] Definite integral turn out to be important in physics and engineering. They’re known as Dirichlet integrals. We’ll make use of this result in other sections in this course, for example in deriving the Green’s function of Laplace’s equation in electrostatics.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Appendix II: Complex Analysis</span>"
    ]
  },
  {
    "objectID": "electrodynamics/complex-analysis.html#transformations",
    "href": "electrodynamics/complex-analysis.html#transformations",
    "title": "Appendix II: Complex Analysis",
    "section": "Transformations",
    "text": "Transformations\nThus far we’ve said little about the geometry of complex functions, that is, how complex functions change the geometry of the complex plane under transformations. We will now introduce the idea of complex transformations, and show how they can be used to visualize complex functions. We will also introduce the important idea of conformal mappings. We’ll find these ideas quite useful to electromagnetism, since they allow us to transform many boundary value problems into simpler boundary value problems that are much more easily solved in a different space.\n\nAffine Transformations\nSuppose \\(w = f(z)\\) is some complex function that maps each point \\(z\\) in the complex \\(z\\)-plane to some point \\(w\\) in the complex \\(w\\)-plane. When thinking of a function this way, we call it a transformation or a mapping.\nTo see how this whole idea works, let’s consider first the simple transformation \\(w = z\\). This function maps each point \\(z\\) in the \\(z\\)-plane to the same point \\(w=z\\) in the \\(w\\)-plane. Interpreting this geometrically, we can thus think of this transformation as mapping the complex plane to itself, leaving all points fixed. Nothing is happening. This is the identity transformation.\nNow let’s consider a slightly more interesting example. Consider the transformation \\(w = z + 1\\). For each point \\(z\\) in the \\(z\\)-plane, this transformation sends \\(z\\) to the point \\(w = z+1\\) in the \\(w\\)-plane. Interpreted geometrically, this means each point is being translated to the right one unit. This is thus an example of a pure translation. Every point just gets translated right by one.\nAnother example of a pure translation is the transformation \\(w = z + i\\). Instead of translating each point to the right by one, it instead translates each point up by one along the imaginary axis. In general, a pure translation of a complex variable is any transformation of the form \\(z = z + z_0\\) for some fixed \\(z_0\\). This translates each \\(z\\) by a distance \\(|z_0|\\) in the \\(z_0\\)-direction.\nLet’s now consider a different kind of transformation. Consider the transformation \\(w = i z\\). Evidently this transformation maps each \\(z\\) in the \\(z\\)-plane to the point \\(w = iz\\) in the \\(w\\)-plane. To see what this represents geometrically we can rewrite it in polar notation. If we let \\(z = re^{i\\varphi}\\) and observe that \\(i = e^{i\\pi/2}\\), we then have \\[\nw = i z = r e^{i(\\varphi + \\pi/2)} \\ .\n\\] This is just a rotation. Each point \\(z\\) simply gets rotated counterclockwise by \\(\\pi/2\\) under this transformation. That is, the transformation \\(w = iz\\) is a pure rotation counterclockwise by \\(90^\\circ\\). More generally, any transformation of the form \\(w = e^{i\\alpha} z\\) defines a pure rotation, rotating each \\(z\\) in the \\(z\\)-plane by an angle \\(\\alpha\\) in the \\(w\\)-plane. Equivalently, it’s a pure rotation of the entire complex plane by an angle \\(\\alpha\\).\nNext, let’s consider the transformation \\(w = 2 z\\). In this case, each \\(z\\) gets mapped to a point \\(w = 2z\\). Interpreted geometrically, this says that each \\(z\\) gets scaled by a factor of two. This is an example of a pure scaling transformation, where each point just gets rescaled by some constant factor. More generally, any transformation of the form \\(w = az\\) where \\(a &gt; 0\\) is a positive real number is an example of a scaling transformation, which scales each point \\(z\\) in the \\(z\\)-plane by a factor of \\(a\\) in the \\(w\\)-plane. Equivalently, we can think of transformations like this as scaling the whole complex plane by a factor of \\(a\\).\nBy combining these different types of pure transformations together we can build more interesting transformations. For example, consider the transformation \\(w = -z/2 + i\\). To interpret this geometrically we break the transformation into pieces. Consider the sequence of intermediate transformations \\(z \\to -z \\to -z/2 \\to -z/2 + i\\). On the left we have \\(z\\), and on the right we have \\(w = -z/2 + i\\). Since \\(-z = e^{i\\pi} z\\), the first step \\(z \\to -z\\) as a pure rotation counterclockwise by \\(180^\\circ\\). The next step in the transformation is then \\(-z \\to -z/2\\), which is a pure scaling of \\(-z\\) by a factor of \\(1/2\\). Finally, the last step \\(-z/2 \\to -z/2 + i\\) is just a pure translation of \\(-z/2\\) up by one. All together then, this transformation takes the complex \\(z\\)-plane and performs a pure rotation by \\(180^\\circ\\), followed be a pure scaling by \\(1/2\\), followed by a translation up by one.\nTransformations give us a nice way to visualize the behavior of complex functions. For real functions \\(y = f(x)\\) we could visualize the function using its graph. Since the graph of such a function is just a curve, we can plot it in a 2-dimensional plane and easily visualize the function’s behavior. Unfortunately, we cannot do this for complex functions \\(w = f(z)\\) since the graph would lie in a 4-dimensional space, which we can’t easily visualize.\nInstead what we can do is draw two plots, one of the \\(z\\)-plane and another of the \\(w\\)-plane. Each mapping of a point \\(z \\to w\\) can be visualized by drawing an arrow connecting \\(z\\) in the \\(z\\)-plane to \\(w\\) in the \\(w\\)-plane. More usefully though, we often see how curves or regions of the \\(z\\)-plane get mapped under the transformation \\(w = f(z)\\). As an example, let’s visualize the transformation in the previous example, \\(w = -z/2 + i\\). To do so, we’ll focus on looking at how the four points \\(z = 0, 1, i, 1+i\\) transform. Notice that these points define the unit square in the \\(z\\)-plane. We can thus see what the unit square maps to in the \\(w\\)-plane. It’s easy to see that these four points map, in order, to the points \\(w = i, -1/2 + i, i/2, -1/2 + i/2\\), as shown below.\nFIGURE (visualize this unit square under the mapping)\nWe can see visually here what’s going on. We see that each point is being rotated, scaled, and translated as describe above. This is easy to see since we can just visualize how the unit square gets distorted under the transformation. Notice that the area of the transformed unit square is now evidently \\(1/2\\), which is the same scaling factor we see in the transformation.\nThe simple transformations we’ve covered so far are examples of the more general class of affine transformations \\[\nw = a z + z_0 \\ .\n\\] Any affine transformation can be thought of as a combination of a rotation by the phase \\(\\text{Arg} \\ a\\), a scaling by \\(|a|\\), and a translation by \\(z_0\\). For what it’s worth, the special case where \\(z_0 = 0\\) is called a linear transformation. These only involve rotation and scaling.\nAn important property of affine transformations is that they always map lines to lines, and parallelograms to parallelograms. Both of these facts can be easily seen by looking at the definition of an affine transformation.\n\nExample: Analyze the affine transformation \\(w = i + z e^{i\\pi / 4}\\)\nWe can again break this transformation up into the intermediate transformations \\(z \\to z e^{i\\pi/4} \\to z e^{i\\pi/4} + i\\). The first transformation is evidently a counterclockwise rotation by \\(45^\\circ\\). The second transformation is a translation by \\(i\\), or equivalently a translation up by one. Clearly then, this transformation is just a rotation followed by a translation.\nBut let’s try to be a bit more precise. Observe if we substitute \\(z = x+iy\\) into \\(w = u+iv\\), we have \\[\nw = i + (x+iy) e^{i\\pi / 4} = \\frac{x-y}{\\sqrt{2}} + i \\bigg(1 + \\frac{x+y}{\\sqrt{2}}\\bigg)  \\quad \\Longrightarrow \\quad \\begin{cases}\nu = \\frac{x-y}{\\sqrt{2}} \\ ,\\\\\nv = \\frac{x+y}{\\sqrt{2}} \\ .\n\\end{cases}\n\\] This relation gives the exact point \\(w = u+iv\\) in the \\(w\\)-plane that each point \\(z = x+iy\\) in the \\(z\\)-plane gets mapped to. Let’s now try to use this information to see how various curves in the \\(z\\)-plane get transformed under this mapping. Notice that we can eliminate either \\(x\\) or \\(y\\) from the equations for \\(u\\) and \\(v\\) by adding and subtracting them together. We end up with \\[\nv = u + (1 + \\sqrt{2}y) \\quad , \\quad v = -u + (1 + \\sqrt{2}x) \\ .\n\\] Now, consider first the horizontal lines \\(y=\\text{const}\\) in the \\(z\\)-plane. If we treat \\(y\\) as a parameter in the equations above, we see that in the \\(w\\)-plane these horizontal lines get transformed to lines of the form \\(v = u + (1 + \\sqrt{2}y)\\), which are \\(45^\\circ\\) lines passing through the point \\(v = 1 + \\sqrt{2}y\\). Thus, horizontal lines get mapped to a family of \\(45^\\circ\\) lines under this transformation.\nNext, let’s consider the vertical lines \\(x = \\text{const}\\) in the \\(z\\)-plane. Again treating \\(x\\) as a parameter, we see that these lines get transformed to lines of the form \\(v = -u + (1+\\sqrt{2} x)\\) in the \\(w\\)-plane, which are \\(135^\\circ\\) lines passing through the point \\(v=1+\\sqrt{2}x\\). Thus, vertical lines get mapped to a family of \\(135^\\circ\\) lines under this transformation.\nLast, let’s look at how the unit square gets mapped under this transformation. Consider again the points \\(z = 0, 1, i, 1+i\\). Under the mapping, these respectively transform to the points \\(w = i, e^{i\\pi/4} + i, (-1 + i\\sqrt{3+2\\sqrt{2}})/\\sqrt{2}, i\\sqrt{3 + 2\\sqrt{2}}\\). The area of the transformed rectangle is evidently one, indicating no scaling took place under this transformation.\nFIGURE (visualize the above transformation)\n\n\n\nNon-Affine Transformations\nSo far we’ve considered only affine transformations, which are especially simple. But most transformations we could write down aren’t affine. For example, the transformations \\(w = 1/z\\), \\(w = e^z\\), or \\(w = z^2\\) are all non-affine transformations. How then should we interpret more complicated translations like these geometrically?\nLet’s first consider the transformation \\(w = 1/z\\). Evidently, each point \\(z\\) in the \\(z\\)-plane gets mapped to the point \\(w = 1/z\\) in the \\(w\\)-plane. By convention, we agree that \\(\\infty = 1/0\\) and \\(0 = 1/\\infty\\), so that \\(z=0\\) gets mapped to \\(w=\\infty\\) and \\(z=\\infty\\) gets mapped to \\(w=0\\). To see what’s going on, we can re-express this transformation in polar form. If \\(z = re^{i\\varphi}\\), then \\[\nw = \\frac{1}{z} = \\frac{1}{r} e^{-i\\varphi} \\ .\n\\] Geometrically, this means each \\(z = re^{i\\varphi}\\) in the \\(z\\)-plane is getting scaled by a \\(z\\)-dependent factor of \\(1/r\\), and then reflected across the real axis from the angle \\(\\varphi\\) to the angle \\(-\\varphi\\). We call a transformation of this kind an inversion. Notice that the inverse transformation \\(z = 1/w\\) is also an inversion transformation.\nAn inversion maps points inside the unit disk \\(|z| &lt; 1\\) to points outside the unit disk \\(|z| &gt; 1\\), and points outside the unit disk to points inside the unit disk. Evidently, points on the unit circle \\(|z| = 1\\) remain on the unit circle \\(|w| = 1\\) under an inversion, except reflected across the real axis.\nInversion transformations have a useful but interesting property that we won’t prove. Namely, they map circles in the \\(z\\)-plane to lines in the \\(w\\)-plane, and lines in the \\(z\\)-plane to circles in the \\(w\\)-plane. For example, the counterclockwise unit circle \\(z(\\varphi) = e^{i\\varphi}\\) gets mapped to the horizontal line \\(w=1\\), and the horizontal line \\(z=1\\) gets mapped to the clockwise circle \\(w(\\varphi) = e^{-i\\varphi}\\). The loan exception are lines or circles that pass through the origin \\(z=0\\), which always map to lines in the \\(w\\)-plane.\nFIGURE (draw the inversion of a few lines and circles)\nIt turns out we can combine affine transformations and inversion transformations together into a single class of transformations known as bilinear transformations (or linear fractional transformations, or Möbius transformations). These have the form \\[\nw = \\frac{az + b}{cz + d} \\quad , \\ ad-bc \\neq 0 \\ .\n\\] We can recover affine transformations by setting \\(c=0\\), and inversion transformations by setting \\(a=d=0\\) and \\(b=c=1\\). Geometrically, bilinear transformations can be thought of as an affine transformation, followed by an inversion transformation, followed by another affine transformation. It’s easily seen that the inverse of a bilinear transformation is also a bilinear transformation.\nBilinear transformations inherit the properties of both of these kinds of transformations. For example, circles still map to lines, and lines still map to circles. They also have the property that a bilinear transformation can always be found to map any three distinct points in the \\(z\\)-plane to any three distinct points in the \\(w\\)-plane. One useful example of a bilinear transformation is \\[\nw = \\frac{i - z}{i + z} \\ .\n\\] This transformation is useful because it maps the upper half of the \\(z\\)-plane to the interior of the unit disk \\(|w| &lt; 1\\) in the \\(w\\)-plane, and the real axis \\(x = 0\\) gets mapped precisely to the boundary of the unit disk \\(|w| = 1\\). By inverting this transformation we can do the opposite, map the unit disk to the upper half plane. We’ll occasionally find this fact useful for solving 2-dimensional boundary value problems in cylindrical coordinates.\nNext, consider the quadratic transformation \\(w = z^2\\). It makes most sense to analyze this transformation in polar coordinates. If we again let \\(z = r e^{i\\varphi}\\), then we see that \\(w = r^2 e^{i 2\\varphi}\\).\n\nConsider first a circle in the \\(z\\)-plane, or curves \\(z(\\varphi) = re^{i\\varphi}\\), where \\(r=\\text{const}\\) and \\(0 \\leq \\varphi &lt; 2\\pi\\). Under this transformation, this circle evidently maps to \\(w(\\varphi) = r^2 e^{i 2\\varphi}\\). This is a circle in the \\(w\\)-plane of radius \\(r^2\\), but a circle with twice the phase, meaning it does two full rotations instead of one. This geometrically reflects the fact that \\(w=z^2\\) is a two-to-one mapping, meaning each point in the \\(w\\)-plane is the mapping of exactly two points \\(z\\)-plane.\nEvidently then, circles in the \\(z\\)-plane map to two circles in the \\(w\\)-plane. Equivalently, a semi-circle maps to a full circle, and a quarter circle maps to a semi-circle.\nIn fact, this transformation preserves all quadratic surfaces, not just circles. For example, hyperbolas map to hyperbolas.\nThe inverse transformation \\(z = \\sqrt{w}\\) does these actions all in reverse. Note that this transformation will generally be multivalued unless we restrict ourselves to a particular branch in the \\(w\\)-plane.\n\nFIGURE (draw quadratic map of circles and hyperbolas)\nNext, consider the exponential transformation \\(w = e^z\\). By writing \\(z = x+iy\\), we see that \\(w = e^x e^{iy}\\). This means we can interpret this transformation as a \\(z\\)-dependent scaling by \\(e^x\\) followed by a \\(z\\)-dependent rotation by a angle \\(y\\). Evidently then, the exponential transformation has the following properties:\n\nBy setting \\(x=\\text{const}\\) in the \\(z\\)-plane, we see that vertical lines get mapped to circles of radius \\(e^x\\) in the \\(w\\)-plane. Since the phase \\(y = \\text{Arg} \\ w\\) can take on any real value, these circles loop around counterclockwise infinitely many times. This reflects the fact that the inverse transformation \\(z = \\log w\\) has infinitely many branches.\nBy setting \\(y=\\text{const}\\) in the \\(z\\)-plane, we see that horizontal lines get mapped to rays emanating out from the origin. The angle of these rays are determined by the phase \\(y\\).\nNon axis lines of the form \\(y = kx\\) in the \\(z\\)-plane map to curves of the form \\(w = e^{x(1+ik)}\\) in the \\(w\\)-plane. If we write \\(w = \\varrho e^{i\\theta}\\) in polar coordinates, we can eliminate \\(x\\) to get \\(\\varrho(\\theta) = e^{\\theta/k}\\). These curves evidently then represent exponentially growing spirals in the \\(w\\)-plane. Such curves are called logarithmic spirals.\nThe unit square gets mapped to an annular segment bounded by circles of radius \\(e^0 = 1\\) and \\(e^1 = e\\). The segment is bounded between the angles \\(y=0\\) and \\(y=1\\) radians in the \\(w\\)-plane. Indeed, all rectangles map to annular regions.\nThe inverse transformation \\(z = \\log w\\) does these actions in reverse. Note that this inverse transformation is multivalued unless we restrict ourselves to a particular branch in the \\(w\\)-plane.\n\nFIGURE (draw exponential map)\nLast, we’ll mention the sine transformation \\(w = \\sin z\\). This transformation is best analyzed in rectangular coordinates. If we write \\(z = x + iy\\), it’s not hard to see that \\(w = \\sin x \\cosh y + i \\cos x \\sinh y\\).\n\nSetting \\(x=\\text{const}\\), it’s not too hard to show that vertical lines get mapped to hyperbolas in the \\(w\\)-plane of the form \\((u/\\sin x)^2 - (v/\\cos x)^2 = 1\\).\nSimilarly, setting \\(y=\\text{const}\\), it’s not hard to show that horizontal lines get mapped to ellipses in the \\(w\\)-plane of the form \\((u/\\cosh y)^2 + (v/\\sinh y)^2 = 1\\).\nRectangular regions in the \\(z\\)-plane get mapped to regions bounded by orthogonal ellipses and hyperbolas, each having the same focal point.\nThe related transformation \\(w = \\cos z\\) has exactly the same behavior, except compared to the sine transformation the hyperbolas get reflected across the real axis, and the ellipses get reflected across the imaginary axis.\n\n\n\nConformal Mappings\nAnalytic functions possess yet another very special property, namely analytic function are conformal mappings. That is, analytic functions preserve the angles between curves. To see why this is the case, suppose \\(w=f(z)\\) is analytic at \\(z\\), and suppose \\(\\mathcal{C}_1\\) and \\(\\mathcal{C}_2\\) are two curves in the \\(z\\)-plane that intersect at the point \\(z\\).\nAt the point \\(z\\) we can create a tangent line \\(dz_1\\) to \\(\\mathcal{C}_1\\) and a tangent line \\(dz_2\\) to \\(\\mathcal{C}_2\\), with these tangent lines intersecting at \\(z\\) at some angle \\(\\alpha\\). Under the transformation \\(w = f(z)\\), these tangent lines get mapped to tangent lines \\(dw_1\\) and \\(dw_2\\) in the \\(w\\)-plane that intersect at the point \\(w = f(z)\\) at some other angle \\(\\alpha'\\).\nFIGURE\nNow, since \\(w=f(z)\\) is analytic at \\(z\\), we can relate the tangent lines in the two planes via \\[\ndw_1 = \\frac{dw}{dz} dz_1 \\quad , \\quad dw_2 = \\frac{dw}{dz} dz_2 \\ .\n\\] So long as \\(dw/dz \\neq 0\\), we can take the ratio of these tangent lines to get \\[\n\\frac{dw_1}{dw_2} = \\frac{dw/dz \\ dz_1}{dw/dz \\ dz_2} = \\frac{dz_1}{dz_2} \\ .\n\\] This means that the ratios of the two sets of tangent lines are identical. But this in fact implies the angles must be identical as well. To see why this is true, notice at the point \\(z\\) we can write \\(dz_1 = |z| e^{i \\varphi_1}\\) and \\(dz_2 = |z| e^{i \\varphi_2}\\). Since \\(\\alpha = \\varphi_1 - \\varphi_2\\), we have \\[\n\\frac{dz_1}{dz_2} = e^{i (\\varphi_1 - \\varphi_2)} = e^{i\\alpha} \\ .\n\\] Similarly, at the point \\(w = f(z)\\) we can write \\(dw_1 = |w| e^{i \\theta_1}\\) and \\(dw_2 = |w| e^{i \\theta_2}\\). Since \\(\\alpha' = \\theta_1 - \\theta_2\\), we have \\[\n\\frac{dw_1}{dw_2} = e^{i (\\theta_1 - \\theta_2)} = e^{i\\alpha'} \\ .\n\\] Thus, since the two ratios must equal, the angles must be the same, i.e. \\(\\alpha' = \\alpha\\). That is, the transformation \\(w=f(z)\\) is conformal, meaning it preserves the angle between curves at points where the function is analytic with non-vanishing derivative.\nWhat if the derivative is zero at \\(z\\)? In that case, it’s possible to show that under the transformation the angle between curves gets multiplied by \\(n\\), where \\(d^n w / dz^n\\) is the first non-vanishing derivative of \\(f(z)\\) at \\(z\\). This can be shown by expanding \\(f(z)\\) as a Taylor series at \\(z\\) and applying the same logic as above on the first non-vanishing derivative.\nWhile angles stay invariant under conformal mappings, areas do not. They scale in a very particular way. To see this, consider an area element \\(dxdy\\) in the \\(xy\\)-plane, and its transformed area element \\(dudv\\) in the \\(uv\\)-plane. According to the change of variables theorem, these two area elements can be related by the formula \\(dxdy = |J| dudv\\), where \\(|J|\\) is the absolute Jacobian determinant given by \\[\n|J| = \\bigg|\\frac{\\partial u}{\\partial x} \\frac{\\partial v}{\\partial y} - \\frac{\\partial u}{\\partial y} \\frac{\\partial v}{\\partial x}\\bigg| \\ .\n\\] If we now insist the Cauchy-Riemann conditions be satisfied, we can rewrite this determinant factor as \\[\n|J| = \\bigg|\\bigg(\\frac{\\partial u}{\\partial x}\\bigg)^2 + \\bigg(\\frac{\\partial u}{\\partial y}\\bigg)^2\\bigg| = \\bigg|\\frac{dw}{dz}\\bigg|^2 \\ .\n\\] Thus, the area element transforms under a conformal mapping \\(w = f(z)\\) as \\[\ndudv = \\bigg|\\frac{dw}{dz}\\bigg|^2 dxdy \\ .\n\\] Evidently, an infinitesimal patch of area in the \\(z\\)-plane gets transformed to an infinitesimal patch of area in the \\(w\\)-plane that’s rescaled by a factor of \\(|dw/dz|^2\\). Evidently, when \\(|dw/dz|^2 &lt; 1\\) this scaling is contracts the area element, and when \\(|dw/dz|^2 &gt; 1\\) it dilates the area element. Only in the special situation where \\(|dw/dz|^2 = 1\\) does the area element stay the same, hence in general a conformal mapping is not area preserving (and hence not an orthogonal transformation).\nNote that as with all area elements, this scale factor only says how infinitesimal patches of areas change under transformation, not how larger patches of areas change. One needs to integrate the area element over a region to see how its area changes.",
    "crumbs": [
      "Electromagnetism",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Appendix II: Complex Analysis</span>"
    ]
  },
  {
    "objectID": "circuits/circuit-abstraction.html",
    "href": "circuits/circuit-abstraction.html",
    "title": "The Lumped Circuit Abstraction",
    "section": "",
    "text": "Maxwell’s Equations\nMaxwell’s Equations are taught in electrodynamics courses. In SI units, they’re given as follows.\nRather than use these equations directly we’ll derive three simpler laws that hold for circuits:",
    "crumbs": [
      "Circuit Analysis",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>The Lumped Circuit Abstraction</span>"
    ]
  },
  {
    "objectID": "circuits/circuit-abstraction.html#maxwells-equations",
    "href": "circuits/circuit-abstraction.html#maxwells-equations",
    "title": "The Lumped Circuit Abstraction",
    "section": "",
    "text": "Name\nDifferential Form\nIntegral Form\n\n\n\n\nGauss’s Law\n\\(\\nabla \\cdot \\mathbf{E} = \\frac{\\rho}{\\varepsilon_0}\\)\n\\(\\oint \\mathbf{E} \\cdot d\\mathbf{a} = \\frac{q}{\\varepsilon_0}\\)\n\n\nFaraday’s Law\n\\(\\nabla \\times \\mathbf{E} = -\\frac{\\partial \\mathbf{B}}{\\partial t}\\)\n\\(\\oint \\mathbf{E} \\cdot d\\boldsymbol{\\ell} = -\\frac{\\partial \\Phi_M}{\\partial t}\\)\n\n\nNo Magnetic Monopoles\n\\(\\nabla \\cdot \\mathbf{B} = 0\\)\n\\(\\oint \\mathbf{B} \\cdot d\\mathbf{a} = 0\\)\n\n\nAmpere’s Law\n\\(\\nabla \\times \\mathbf{B} = \\mu_0 \\mathbf{J} + \\frac{1}{\\varepsilon_0 \\mu_0} \\frac{\\partial \\mathbf{E}}{\\partial t}\\)\n\\(\\oint \\mathbf{B} \\cdot d\\boldsymbol{\\ell} = \\mu_0 I + \\frac{1}{\\varepsilon_0 \\mu_0} \\frac{\\partial \\Phi_E}{\\partial t}\\)\n\n\nContinuity Equation\n\\(\\frac{\\partial \\rho}{\\partial t} - \\nabla \\cdot \\mathbf{J} = 0\\)\n\\(\\frac{\\partial q}{\\partial t} - \\oint \\mathbf{J} \\cdot d\\mathbf{a} = 0\\)\n\n\n\n\n\nOhm’s Law: \\(v = iR\\).\nKirchoff’s Voltage Law (KVL): \\(\\sum_{loop} v = 0\\).\nKirchoff’s Current Law (KCL): \\(\\sum_{node} i = 0\\).",
    "crumbs": [
      "Circuit Analysis",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>The Lumped Circuit Abstraction</span>"
    ]
  },
  {
    "objectID": "circuits/circuit-abstraction.html#ohms-law",
    "href": "circuits/circuit-abstraction.html#ohms-law",
    "title": "The Lumped Circuit Abstraction",
    "section": "Ohm’s Law",
    "text": "Ohm’s Law\nFor many materials, a linear relation holds between the electric field \\(\\mathbf{E}\\) inside the material and its current density \\(\\mathbf{J}\\). This is the Generalized Ohm’s Law: \\[\\mathbf{E} = \\rho \\mathbf{J},\\] where \\(\\rho\\) is the material’s resistivity. Consider a piece of cylindrical material, called a resistor, with a current \\(i\\) pumped through its ends.\n\n\n\n\n\nSince \\(\\mathbf{E} = E \\mathbf{e}_y\\) and \\(\\mathbf{J} = J \\mathbf{e}_y\\), and \\(A\\) and \\(\\ell\\) are constant, we have\n\\[\\begin{align*}\n\ni &= \\oint \\mathbf{J} \\cdot d\\mathbf{a} = J \\cdot A, \\\\\\\n\nv &= \\oint \\mathbf{E} \\cdot d\\mathbf{\\ell} = E \\cdot l.\n\n\\end{align*}\\]\nThus, we have \\(v = \\frac{\\rho \\ell}{A}i \\equiv Ri\\), where \\(R \\equiv \\frac{\\rho \\ell}{A}\\) is a constant, called the resistence of the material. The relation then becomes \\[v = iR,\\] which is the standard Ohm’s Law. Note Ohm’s Law as stated is only true for resistive materials.",
    "crumbs": [
      "Circuit Analysis",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>The Lumped Circuit Abstraction</span>"
    ]
  },
  {
    "objectID": "circuits/circuit-abstraction.html#the-lumped-circuit-abstraction",
    "href": "circuits/circuit-abstraction.html#the-lumped-circuit-abstraction",
    "title": "The Lumped Circuit Abstraction",
    "section": "The Lumped Circuit Abstraction",
    "text": "The Lumped Circuit Abstraction\nTo easily and reliably analyze circuits we make a number of simplifying assumptions, or abstractions. By restricting ourselves to situations where these abstractions hold, we set up a simpler playground in which to work.\nThe most fundamental abstraction in circuit analysis is the lumped circuit abstraction or LCA. In the LCA, we assume a circuit is made of a set of lumped elements that are connected to each other with ideal wires (i.e. wires with no voltage drop across any two points and a uniform current throughout).\nAs an example, let’s consider a lightbulb connected to a battery supplying a voltage \\(v\\), which causes a current \\(i\\) to flow across the bulb from the positive terminal of the battery to the negative terminal.\n\n\n\n\n\nWe’d like to solve for the current \\(i\\) as a function of the input voltage \\(v\\). How should we do this? The hard way would be to just use Maxwell’s Equations. But this is unnecessary.\nNotice that we don’t care about many of the physical properties of the circuit, including the bulb’s shape, temperature, filament design, or what the wires are made of. We only care about the bulb’s resistance, since Ohm’s law says \\(v=iR\\). We can thus abstract the details of the bulb and the battery away, treating the bulb as a resistor and the battery as a voltage source.\n\n\n\n\n\nOnce we’ve done this, we can simply solve for the current in terms of the voltage simply as \\[i = \\frac{v}{R}.\\]\nA more abstract way to express this simple circuit is to use special symbols for the resistor and the voltage source. We’d write the exact same setup like this.\n\n\n\n\n\nNow, how do we know we can do this? How do we even know that \\(v\\) and \\(i\\) are even defined? After all, neither voltage nor current need exist in a well-defined way. However, under certain conditions, they do exist. Consider the following setup, where a current \\(i\\) flows through a wire from \\(A\\) to \\(B\\). The voltage across the wire is \\(v\\). The cross-sectional areas through \\(A\\) and \\(B\\) are \\(s_A\\) and \\(s_B\\), respectively.\n\n\n\n\n\nBy the continuity equation, we have \\[i_A - i_B \\equiv \\int_{s_A} \\mathbf{J} \\cdot d\\mathbf{a} - \\int_{s_B} \\mathbf{J} \\cdot d\\mathbf{a} = \\frac{\\partial q}{\\partial t}.\\] Provided no charge can build up inside the wire, we have \\[\\frac{\\partial q}{\\partial t} = 0 \\Rightarrow i_A = i_B \\equiv i.\\] That is, we have a well-defined current \\(i\\) flowing through the wire provided we forbid a buildup of charge inside the wire.\nBy Faraday’s Law, we also have \\[v_A - v_B \\equiv \\int_A^B \\mathbf{E} \\cdot d \\boldsymbol{\\ell} = -\\frac{\\partial \\Phi_M}{\\partial t}.\\] Provided magnetic flux is constant outside the wires, we can conclude \\[\\frac{\\partial \\Phi_M}{\\partial t} = 0 \\Rightarrow v_A = v_b \\equiv v.\\] That is, we have a well-defined voltage \\(v\\) across the wire provided we forbid any change in magnetic flux outside the wire.\nThe last condition we must require is that currents move much slower than the speed of light. This says that currents aren’t allowed to radiate.\nThe requirement that circuits obey each of these properties is called the lumped matter discipline:\n\nElements are discrete and independent of each other.\nNo charge can build up inside of wires.\nMagnetic flux is constant outside of the circuit.\nCurrents must move much slower than the speed of light.",
    "crumbs": [
      "Circuit Analysis",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>The Lumped Circuit Abstraction</span>"
    ]
  },
  {
    "objectID": "circuits/circuit-abstraction.html#lumped-elements",
    "href": "circuits/circuit-abstraction.html#lumped-elements",
    "title": "The Lumped Circuit Abstraction",
    "section": "Lumped Elements",
    "text": "Lumped Elements",
    "crumbs": [
      "Circuit Analysis",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>The Lumped Circuit Abstraction</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/thermodynamics.html",
    "href": "statistical-mechanics/thermodynamics.html",
    "title": "Thermodynamics",
    "section": "",
    "text": "Thermodynamic Systems\nIn thermodynamics we seek to describe the macroscopic properties of a thermodynamic system. Unlike in classical mechanics, we won’t think of a system as a particle or a collection of particles, but rather as an object describable by a set of macroscopic properties. By macroscopic we mean properties that describe the state of the entire system, like its temperature, pressure, volume, etc. These properties are called state variables or thermodynamic coordinates.\nIn thermodynamics we’re interested in studying a few different kinds of systems, depending on what is allowed to flow into and out of the system. We assume the system is submerged in some external environment, called a heat bath.\nWe say a system is in equilibrium when its internal temperature has had sufficient time to relax to some steady state value. More precisely, the internal temperature doesn’t change appreciably over some given observation time. In a large sense, thermodynamics is about the study of equilibrium. We require that an equilibrium state exist for the system before we can even talk about thermodynamic variables. Of course, we haven’t even defined what temperature is, or shown that it must exist. We’ll do that in the next section.\nThe specific variables we seek to measure depend on the type of system under consideration. Here are some examples of mechanical variables that might depend on the system:\nOn top of these mechanical variables that vary by system, we also may be interested in a system’s thermal variables, i.e. variables that arise due to the system’s internal interactions. The macroscopic thermal variables might be temperature, entropy, or heat.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Thermodynamics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/thermodynamics.html#thermodynamic-systems",
    "href": "statistical-mechanics/thermodynamics.html#thermodynamic-systems",
    "title": "Thermodynamics",
    "section": "",
    "text": "An isolated system is a system in which no energy exchange is allowed with the heat bath, either through heat or work. Isolated systems have the property that total energy is conserved.\nAn adiabatic system is a system in which no heat exchange is allowed with the heat bath. An exchange of work is still allowed, which means total energy isn’t conserved.\nA closed system is a system in which energy is allowed to be exchanged with the heat bath, either through heat or work. The total energy of the closed system plus the heat bath is conserved.\nA diathermic system is a system in which heat is allowed to be exchanged with the heat bath, but work may or may not be exchanged.\n\n\n\n\nGas in a container: We might be interested in its volume or the pressure it exerts on the container.\nA wire under tension: We might be interested in its length or the tension forces exerted on it.\nA magnet in a field: We might be interested in its magnetization or its external magnetic field.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Thermodynamics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/thermodynamics.html#zeroth-law",
    "href": "statistical-mechanics/thermodynamics.html#zeroth-law",
    "title": "Thermodynamics",
    "section": "Zeroth Law",
    "text": "Zeroth Law\nSuppose we have three distinct systems \\(A\\), \\(B\\), and \\(C\\). The zeroth law of thermodynamics states that if \\(A\\) is in equilibrium with \\(B\\), and \\(B\\) is in equilibrium with \\(C\\), then \\(A\\) is in equilibrium with \\(C\\). That is, the property of equilibrium is transitive.\n\n\n\n\n\nNotice that for any two systems to be in equilibrium with each other they must be allowed to exchange heat. If they were isolated, even the smallest change to one system wouldn’t affect the other. The zeroth law evidently implies that this holds for any number of systems in equilibrium. You can’t isolate any one from the other, since heat can always flow through any two pairs of systems in equilibrium with each other.\nThe zeroth law implies the existence of a thermal quantity called the empirical temperature that’s the same among systems in equilibrium, a quantity that doesn’t change when no net heat is flowing between any two systems.\nTheorem: Suppose two systems \\(A\\) and \\(B\\) are in thermodynamic equilibrium with each other. Suppose \\(A\\) has thermodynamic coordinates \\(A_1, A_2, \\cdots, A_n\\) and \\(B\\) has thermodynamic coordinates \\(B_1, B_2, \\cdots, B_m\\). Then there exists a value \\(\\theta\\), called the empirical temperature, that depends only on the state of each system, and in equilibrium satisfies the property that for some functions of the coordinates \\[\n\\theta = \\theta_A(A_1, A_2, \\cdots, A_n) = \\theta_B(B_1, B_2, \\cdots, B_m).\n\\] Proof: Suppose a third system \\(C\\) is in equilibrium with \\(A\\) and \\(B\\) with coordinates \\(C_1, C_2, \\cdots, C_k\\). Since \\(A\\) is in equilibrium with \\(C\\), there must be some function of constraint \\(f_{AC}\\) such that \\[\nf_{AC}(A_1, A_2, \\cdots, A_n, C_1, C_2, \\cdots, C_k) = 0.\n\\] Similarly, if \\(B\\) is in thermal equilibrium with \\(C\\) then there is some other constraint function \\(f_{BC}\\) such that \\[\nf_{BC}(B_1, B_2, \\cdots, B_m, C_1, C_2, \\cdots, C_k) = 0.\n\\] Now, we can imagine solving for each function in terms of a common variable \\(C_1\\) to get new functions \\[\n\\begin{align*}\nC_1 &= g_{AC}(A_1, A_2, \\cdots, A_n, C_2, \\cdots, C_k), \\\\\nC_1 &= g_{BC}(B_1, B_2, \\cdots, B_m, C_2, \\cdots, C_k). \\\\\n\\end{align*}\n\\] Setting these two functions equal thus says that \\[\ng_{AC}(A_1, A_2, \\cdots, A_n, C_2, \\cdots, C_k) - g_{BC}(B_1, B_2, \\cdots, B_m, C_2, \\cdots, C_k) = 0.\n\\] By the zeroth law, we also know that \\(A\\) must be in thermal equilibrium with \\(B\\). This means there’s yet another function \\(f_{AB}\\) such that \\[\nf_{AB}(A_1, A_2, \\cdots, A_n, B_1, B_2, \\cdots, B_m) = 0.\n\\] Taken together, this says that we can take \\(f_{AB}\\) and spread it out into two functions \\(g_{AC}\\) and \\(g_{BC}\\), where \\(g_{AC}\\) depends only on the coordinates of \\(A\\) and \\(C\\), and \\(g_{BC}\\) depends only on the coordinates \\(B\\) and \\(C\\). If we imagine using the coordinates of \\(C\\) as some kind of reference values we can treat them as constants. That means we’re left with an expression of the form \\[\ng_{AC}(A_1, A_2, \\cdots, A_n, \\text{const}) - g_{BC}(B_1, B_2, \\cdots, B_k, \\text{const}) = 0.\n\\] This says we have a function of \\(A\\) that must equal a similar function of \\(B\\) at thermal equilibrium, \\[\n\\theta \\equiv \\theta_A(A_1, A_2, \\cdots, A_n) = \\theta_B(B_1, B_2, \\cdots, B_m). \\qquad \\text{Q.E.D.}\n\\] The empirical temperature is evidently reference dependent since we had to fix values for some third system \\(C\\) just to properly define it. We can choose \\(C\\) to be anything we like as long as we agree on a convention. The most common is the triple point of water, the state where water coexists in its gas, liquid, and solid forms simultaneously. This occurs at a temperature of about \\(T = 273.16 \\ \\degree \\text{K}\\) and pressure of about \\(p = 0.006 \\text{ atm}\\).\n\n\n\n\n\nThe condition that \\(\\theta = \\theta_A\\) says that in the space of coordinates of \\(A\\), in thermal equilibrium the system must be constrained to a surface of constant \\(\\theta_A = \\theta\\). This surface is called an isotherm, a surface of constant temperature. Similarly for \\(B\\).\nAnalogy: Think of defining temperature similarly to how one might empirically define mass by using a scale. You first establish a reference mass \\(C\\), for example some standard block of metal in a vault, and then use that to talk about how much the masses \\(A\\) and \\(B\\) weigh in units of \\(C\\).\n\nIdeal Gas\nOne practically useful way to define an empirical temperature scale uses the properties of the ideal gas. An ideal gas is a large number of dilute particles that satisfy the property that the product of the gas’s pressure \\(P\\) and volume \\(V\\) is proportional temperature in the dilute limit, i.e. \\[\n\\lim_{V \\rightarrow \\infty} PV = \\lim_{P \\rightarrow 0} PV \\propto \\theta.\n\\] We’ll assume the gas is allowed to interact diathermally with the heat bath. That is, the gas is allowed to exchange energy with its environment, but nothing else.\nSuppose now that we submerge the gas in one heat bath and record values for \\(P, V, \\theta\\) once the system has reached equilibrium. Then, we take the gas and submerge it again in a different reference heat bath. Once the system has again reached equilibrium, we again record the new values \\(P_0, V_0, \\theta_0\\). Now, since the gas is ideal, we must have \\[\n\\frac{\\theta}{\\theta_0} = \\frac{PV}{P_0 V_0}.\n\\] Provided we’ve fixed a value for \\(\\theta_0\\), we can thus define the temperature \\(T\\) of the system by \\[\nT \\equiv \\theta \\equiv \\theta_0 \\frac{PV}{P_0 V_0} = \\frac{\\theta_0}{P_0} \\frac{PV}{V_0}.\n\\] In the Kelvin scale, \\(\\theta_0\\) and \\(P_0\\) are again defined by the triple point of water. This means that to measure the temperature, we’d need to first measure the pressure and volume of the gas in the heat bath of interest, and then compare that with the volume the same gas would have at the triple point.\nFor an ideal gas, we evidently have the relation then that \\(PV \\propto T\\). It turns out that \\(PV\\) is also proportional to the number of particles \\(N\\) in the gas, \\(PV \\propto N\\). We can write the full ideal gas law in the form \\[\n\\boxed{PV = Nk_B T} \\ ,\n\\] where \\(k_B\\) is a proportionality constant, called the Boltzmann constant. Its value is measured to be \\[\n\\boxed{k_B = 1.381 \\cdot 10^{-23} \\frac{\\text{J}}{\\degree \\text{K}} \\approx \\frac{1}{40} \\frac{\\text{eV}}{\\degree \\text{K}}} \\ .\n\\]",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Thermodynamics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/thermodynamics.html#first-law",
    "href": "statistical-mechanics/thermodynamics.html#first-law",
    "title": "Thermodynamics",
    "section": "First Law",
    "text": "First Law\nIn classical mechanics the conservation of energy is a fundamental principle of a microscopic system. We’d like to extend this idea to thermodynamics as well. Observations indicate that a similar principle operates at the level of macroscopic systems provided that the system is properly insulated, that is, when the only sources of energy are of mechanical origin.\n\nWork, Energy, Heat\nSuppose a thermodynamic system \\(A\\) is adiabatically isolated from its environment. If such a system is changed by some amount of work \\(\\Delta W\\), then the amount of work is only dependent on its initial and final state. That is, if \\(a_i=(A_{1,i}, \\cdots, A_{n,i})\\) is the initial state and \\(a_f=(A_{1,f}, \\cdots, A_{n,f})\\), then \\[\n\\Delta W = \\Delta E = E(a_f) - E(a_i),\n\\] where \\(E = E(a)\\) is some scalar function of state called the internal energy of the system. It’s the total energy of the system \\(A\\) when it’s adiabatically isolated.\nHaving a system be adiabatically isolated is a strong assumption that we’d like to relax, but doing so then means the system can exchange energy with its environment, which means \\(\\Delta W \\neq \\Delta E\\). There’s a flow of energy \\(\\Delta Q\\) in and out of the system now, called the heat. It’s the heat plus the work that’s conserved, \\[\n\\Delta E = \\Delta Q + \\Delta W.\n\\] This experimental fact is called the first law of thermodynamics. We assume this quantity called heat exists in such a fashion that the internal energy stays conserved. It’s not a theorem.\nAside: Note the work \\(\\Delta W\\) is done on the system, not by the system. Many engineering texts adopt the opposite convention, where they like to think of work being done by the system (e.g. by an engine). In that case, the \\(\\Delta W\\) would change its sign, in which case we’d write \\(\\Delta E = \\Delta Q - \\Delta W\\).\nSince thermodynamic state variables only make sense when a system is in equilibrium, if we want to think about the first law in differential form we have to imagine we can change the system differentially in such a way that it stays in equilibrium. Doing so is called a quasi-static process. We vary the system very slowly from its initial to its final state, allowing the system to come to equilibrium again at each point. This allows us to fill in the path continuously with points so we can then talk about differential changes.\nIn differential form, the first law of thermodynamics has the form \\[\n\\boxed{dE = \\delta Q + \\delta W} \\ .\n\\] The notation \\(\\delta Q\\) and \\(\\delta W\\) is used to make it explicit that those variables are path dependent. That is, they’re not a function of only the initial and final states. This means we can’t integrate them directly to get the total heat or work done. However, the energy is a state variable, it is a function only of its end points, and so we can integrate \\(dE\\) to get the total internal energy \\(\\Delta E\\), \\[\n\\Delta E = \\int dE = \\int (\\delta Q + \\delta W).\n\\]\n\n\nTypes of Work\nThe work done on the system is inherently mechanical in that it’s a sum of forces times displacements. Since we want to imagine generalized forces and generalized displacements, we’ll write it in the notation \\[\n\\delta W = \\sum_i J_i d X_i,\n\\] where \\(J_i\\) is a generalized force conjugate to some generalized displacement variable \\(X_i\\). Here are some of the most common conjugate force-displacement pairs:\n\n\n\n\n\n\n\n\nSystem\nGeneralized Force: \\(J\\)\nGeneralized Displacement: \\(X\\)\n\n\n\n\nWire\nTension: \\(F\\)\nLength: \\(L\\)\n\n\nFilm\nSurface Tension: \\(\\sigma\\)\nArea: \\(A\\)\n\n\nFluid\nPressure: \\(-P\\)\nVolume: \\(V\\)\n\n\nMagnet\nMagnetic Field: \\(B\\)\nMagnetization: \\(M\\)\n\n\nDielectric\nElectric Field: \\(E\\)\nPolarization: \\(P\\)\n\n\nChemical Reaction\nChemical Potential: \\(\\mu\\)\nParticle Number: \\(N\\)\n\n\n\nThe generalized forces have the property that their values are independent of the size of the system. Doubling the size of the system doesn’t double the forces acting on it. These are called intensive variables. Conversely, the generalized displacements are directly proportional to the size of the system. If the system’s size is doubled, so too are the displacements. These are called extensive variables. Intensive and extensive variables always tend to occur in conjugate pairs like this.\nUsing the new notation, we can re-write the work in the form \\[\n\\delta W = \\sum_{i=1}^k J_i dX_i.\n\\] For reasons we’ll get into soon, it’s also convenient to break up the work component into non-chemical and chemical work components. If we explicitly split off the chemical work terms, we’d instead write \\[\n\\delta W = \\sum_{i=1}^n J_i dX_i + \\sum_{j=1}^m \\mu_i dN_i.\n\\] Of course, we still don’t know how to simplify \\(\\delta Q\\) into a useful form. We’ll deal with that soon. For simplicity, in the rest of this section we’ll express things in vector notation by letting \\(J, dX, \\mu, dN\\) represent the vectorized forms of their component terms. Then we can just write the total work as just \\[\n\\delta W = J \\cdot dX + \\mu \\cdot dN.\n\\]\n\n\nHeat Capacities\nSuppose we pump some amount of heat \\(\\delta Q\\) into the system. Provided heat is a function of temperature, we’d have \\(\\Delta Q = C \\Delta T\\), where \\(C = C(T)\\) is some function of temperature, called the heat capacity. The functional form of \\(C\\) depends on the nature of the system. Evidently, the heat capacity is given by \\[\n\\boxed{C(T) \\equiv \\frac{\\delta Q}{dT}} \\ .\n\\] Since heat is path dependent, the heat capacity must be too. If \\(\\gamma\\) is some path taken to get from the initial to the final point in state space, then we might write \\(C = C_\\gamma\\) to be explicit about this. The most important case is when we’re dealing with a gas. If a gas is only has work done \\(\\delta W = -PdV\\), then we can think of the gas as only being a function of two state variables, \\(P\\) and \\(V\\). Two paths of interest in \\(pV\\)-space are paths of constant \\(P\\) or \\(V\\). Using the first law, the heat capacity \\(C_V\\) at constant volume is evidently \\[\nC_V = \\frac{\\delta Q_V}{dT} = \\frac{dE + PdV}{dT} \\bigg |_V = \\frac{\\partial E}{\\partial T}\\bigg |_V.\n\\] Similarly, the heat capacity \\(C_P\\) at constant pressure is evidently \\[\nC_P = \\frac{\\delta Q_P}{dT} = \\frac{dE + PdV}{dT} \\bigg |_P =  \\frac{\\partial E}{\\partial T}\\bigg |_P + P \\frac{\\partial V}{\\partial T} \\bigg |_P.\n\\] It turns out that the two \\(\\frac{\\partial E}{\\partial T}\\) derivatives are the same. This follows empirically from the Joule Free Expansion Experiment. Suppose we have two chambers connected by a thin hole that’s initially closed. Initially, all the gas is in the left chamber at an equilibrium temperature \\(T\\). Suppose the hole is then suddenly opened, allowing the gas to adiabatically expand into the right chamber.\n\n\n\n\n\nSince the gas isn’t pushing on anything, it can’t do any work. Since the process is adiabatic, no heat is flowing either. This means the total energy isn’t changing either. Once the system has settle down to equilibrium, the temperature in the two chambers must be the same. This evidently implies the energy must be a function of temperature alone, i.e. \\[\nE = E(T) = E(PV).\n\\] Using this fact, for an ideal gas we can evidently write \\[\nC_p - C_V = P \\frac{\\partial V}{\\partial T} \\bigg |_P.\n\\] Since \\(V = \\frac{Nk_B T}{P}\\), this reduces to just \\[\nC_P - C_V = N k_B.\n\\] It turns out that in fact \\(E \\propto PV\\). This result is called the equipartition theorem. It must be taken as an empirical law in thermodynamics, but it can be proven with statistical mechanics. The equipartition theorem says that an ideal gas whose individual particles each have \\(n\\) degrees of freedom will have a total energy given by \\[\n\\boxed{E = \\frac{n}{2} Nk_B T = \\frac{n}{2} PV} \\ .\n\\] For example, a monoatomic gas is a gas whose particles only have \\(n=3\\) translational degree of freedom. In that case, we’d have \\(E = \\frac{3}{2} PV\\). A diatomic gas is a gas whose particles also have two rotational degrees of freedom plus one vibrational degree of freedom, giving \\(n=7\\) total degrees of freedom, and \\(E = \\frac{7}{2} PV\\).\nUsing the equipartition theorem, we can find the heat capacity of an ideal gas directly. Since \\[\n\\frac{d E}{d T} = \\frac{n}{2} Nk_B,\n\\] we evidently have \\[\nC_V = \\frac{n}{2} Nk_B, \\quad C_P = \\bigg(\\frac{n}{2}+1\\bigg) Nk_B.\n\\] Notice that these heat capacities are extensive since they’re both proportional to \\(N\\). In practice we’re interested in an intensive measure of how responsive heat is to changes in temperature. We can achieve this by dividing by \\(N\\) to get a specific heat. More commonly, specific heats are measured per unit mass, not per particle. If the system has mass \\(m\\), its specific heat capacity is defined by \\(c \\equiv \\frac{C}{m}\\).\nUsually it’s the specific heats that are tabulated for various substances. We’d need to look them up to do any kind of numerical calculations. The most useful specific heat to remember is the specific heat of water at standard temperature and pressure or STP, i.e. when \\(P \\approx 1 \\text{ atm}, T \\approx 300 \\ \\degree K\\). In energy units of calories, the specific heat of water at STP is just \\(c_P = 1 \\ \\frac{\\mathrm{cal}}{\\mathrm{g} \\mathrm{\\degree K}}\\). Note that the specific heat does depend on the phase of a substance. For example, ice has a specific heat of \\(c_P = 0.5 \\ \\frac{\\mathrm{cal}}{\\mathrm{g} \\mathrm{\\degree K}}\\).\nAnother important quantity that’s similar to the specific heat is the latent heat. It’s an intensive measure of how much heat is needed for a system to fully undergo a phase change. The most common definition is the change in heat per unit mass, \\[\n\\boxed{L \\equiv \\frac{\\Delta Q}{m}} \\ .\n\\] In general, latent heat values will be different than the specific heat values. They’ll also be different for different phase changes. For example, the latent heat of melting ice is \\(L = 80 \\ \\frac{\\text{cal}}{g}\\), while the latent heat of boiling water is \\(L = 540 \\ \\frac{\\text{cal}}{g}\\). Again, we’d look these up in tables when we need them.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Thermodynamics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/thermodynamics.html#second-law",
    "href": "statistical-mechanics/thermodynamics.html#second-law",
    "title": "Thermodynamics",
    "section": "Second Law",
    "text": "Second Law\nWe saw that were able to break the work \\(\\delta W\\) up into a sum of generalized force-displacement pairs as \\(\\delta W = \\sum J_i dX_i\\). We’d like to be able to break up the heat \\(\\delta Q\\) somehow. It’s reasonable to assume that \\(T\\) is the generalized force for heat, but what is the generalized displacement? This leads us to the second law and the concept of entropy.\n\nEngines\nThe second law of thermodynamics arose historically out of an interest among engineers in converting back and forth between heat and mechanical work. A device that converts heat into mechanical work is called an engine. A device that converts mechanical work into heat is called a heat pump or a refrigerator (the difference between the two being whether we want to pump heat into or out of a system).\nSuppose an engine takes in heat \\(Q_H\\) from a heat reservoir, outputs some amount of work \\(W\\), and dumps any remaining output heat \\(Q_C\\) into a cold reservoir. By the first law, \\(Q_H = Q_C + W\\). Define the efficiency \\(\\eta\\) of the engine as the ratio of work extracted to the total amount of heat put in, \\[\n\\boxed{\\eta \\equiv \\frac{W}{Q_H}} \\ .\n\\] Since \\(W = Q_H - Q_C\\), we can also write the efficiency as \\[\n\\eta = 1 - \\frac{Q_C}{Q_H}.\n\\] Since we must have \\(Q_C \\leq Q_H\\) by the first law, this means \\(0 \\leq \\eta \\leq 1\\) generally speaking. A perfectly efficient engine would convert all heat into work, in which case \\(\\eta = 1\\).\nWe can define a similar measure of efficiency for a heat pump or a refrigerator. In that case, we’re interested in how much heat we can extract per unit work put in. This measure is called the coefficient of performance \\(\\omega\\), given by \\(\\omega_{fr} \\equiv \\frac{Q_C}{W}\\) for a refrigerator, and \\(\\omega_{hp} \\equiv \\frac{Q_H}{W}\\) for a heat pump. Again using the fact that \\(Q_H = Q_C + W\\), it’s easy to show that \\(\\omega_{fr} \\geq 1\\) and \\(0 \\leq \\omega_{hp} \\leq 1\\).\nHere’s a diagram showing the difference between an engine and a refrigerator. Notice that the refrigerator is just an engine with the arrows reversed. We’ll exploit this fact a good bit shortly.\n\n\n\n\n\n\n\nStatement of Second Law\nThe second law of thermodynamics can be stated in several ways that are all equivalent. I’ll state it first using the definition given by Kelvin, and then use that to prove it’s equivalent to a different statement made by Clausius.\nSecond Law (Kelvin): No thermodynamic process is possible whose sole result is the complete conversion of heat to work or work to heat. Equivalently, there is no ideal engine with efficiency \\(\\eta = 1\\).\nSecond Law (Clausius): No thermodynamic process is possible whose sole result is the transfer of heat from a colder body to a hotter body. Equivalently, there is no ideal refrigerator with performance \\(\\omega = \\infty\\).\nProof: We’ll prove these are equivalent by showing if Kelvin is false, then so is Clausius, and vice versa.\n\nIf Kelvin is false, so is Clausius: If Kelvin is false, then there exists an engine with that outputs heat \\(Q\\) to work \\(W\\) with 100% efficiency. We can use this \\(W\\) to then power a refrigerator. Suppose the refrigerator pumps heat \\(Q_C\\) from a cold reservoir to a new heat \\(Q_H\\) that dumps into the same hot reservoir as the engine. Then on net we have a system that pumps in a heat \\(Q_C\\) and pumps out a heat \\(Q_H-Q\\). That is, we’ve built a refrigerator that pumps heat from a cold body to a warm body, violating Clausius. \\(\\text{Q.E.D.}\\)\n\n\n\n\n\nIf Clausius is false, so is Kelvin: If Clausius is false, then it’s possible to build a heat pump to pump heat from a cold reservoir to a hot reservoir with no input work required. Let’s hook an engine up to the same reservoir, taking an input heat \\(Q_H\\) from the hot reservoir and converting it to some combination of work \\(W\\) and output heat \\(Q_C\\). Then on net we have a system that takes in heat \\(Q_H-Q\\) and converts it purely into work, i.e. \\(W = Q_H - Q\\), which violates Kelvin. \\(\\text{Q.E.D.}\\)\n\n\n\n\n\n\n\n\nCarnot Engines\nIf we can’t have an engine with perfect efficiency, what’s the highest possible efficiency we can possibly have? As we’ll soon prove, the highest efficiency engine is a Carnot engine. A Carnot engine is defined to be any engine that’s reversible, runs in a cycle, and whose reservoir temperatures are held fixed, with the hot reservoir at \\(T_H\\) and the cold reservoir at \\(T_C\\).\n\n\n\n\n\nA thermodynamic process is called reversible if it can be run backward in time by simply reversing the inputs and outputs. It’s the thermodynamic equivalent of frictionless motion in classical mechanics. Since reversibility implies the system stays in equilibrium, reversible processes must be quasi-static. However, not all quasi-static processes need be reversible. Any process that dissipates energy to its environment, even if done quasi-statically, is not reversible.\nTheorem: Of all engines operating between two reservoir temperatures \\(T_H\\) and \\(T_C\\), the Carnot engine is the most efficient.\nProof: Suppose we had some arbitrary non-Carnot engine with efficiency \\(\\eta\\) that takes in heat \\(Q_H'\\) from the hot reservoir, generates work \\(W\\), and dumps the remaining heat \\(Q_C'\\) into the cold reservoir. Using the same trick, hook a reversed Carnot engine (i.e. a Carnot refrigerator) up to take in the output work \\(W\\) and use it to pump heat \\(Q_C\\) from the cold reservoir to a heat \\(Q_H\\) in the hot reservoir. On net, this gives a cycle that takes in heat \\(Q_H'-Q_H\\) and converts it to heat \\(Q_C'-Q_C\\) .\n\n\n\n\n\nBut by the second law, we must have \\(Q_H'-Q_H \\geq Q_C'-Q_C\\). Dividing both sides by \\(W\\) and reorganizing, we get \\[\n\\eta = \\frac{W}{Q_H'} \\leq \\frac{W}{Q_H} = \\eta_{carnot}.\n\\] That is, the Carnot engine is more efficient. \\(Q.E.D.\\)\nCorollary: All Carnot engines between \\(T_H\\) and \\(T_C\\) have the same efficiency.\nProof: Follow the previous proof, but this time hook up another Carnot engine to the Carnot refrigerator to get \\(\\eta = \\eta_{carnot}\\). \\(Q.E.D.\\)\nWe can use the Carnot engine to construct yet another temperature scale, except this time we can do it without reference to any material properties at all. This is called the thermodynamic temperature scale. What we can do is hook two Carnot engines up in series as follows. Suppose a Carnot engine \\(CE_1\\) takes heat from \\(T_1\\) to \\(T_2\\), and Carnot engine \\(CE_2\\) takes heat from \\(T_2\\) to \\(T_3\\). We can also think of the whole thing as a single Carnot engine \\(CE\\) that takes heat from \\(T_1\\) to \\(T_3\\).\n\n\n\n\n\nNow, if we look at the heat output for each engine, we have \\[\n\\begin{align*}\nCE_1: Q_2 &= Q_1 - W_{12} = Q_1(1 - \\eta_{12}), \\\\\nCE_2: Q_3 &= Q_2 - W_{23} = Q_2(1 - \\eta_{23}), \\\\\nCE: Q_3 &= Q_1 - W_{13} = Q_1(1 - \\eta_{13}). \\\\\n\\end{align*}\n\\] We can equate both terms for \\(Q_3\\) and simplify to get \\[\n1 - \\eta_{13} = (1 - \\eta_{12})(1 - \\eta_{23}).\n\\] Now, if we divide both sides by \\(1 - \\eta_{23}\\) we get \\[\n1 - \\eta_{12} = \\frac{Q_2}{Q_1} = \\frac{f(T_1)}{f(T_2)}.\n\\] The system must satisfy this constraint for any function \\(f(T)\\) we choose. We might as well just choose \\(f(T) \\equiv T\\), in which case we get \\[\n\\eta_{12} = 1 - \\frac{T_2}{T_1}.\n\\] That is, any Carnot engine between \\(T_H\\) and \\(T_C\\) must have a Carnot efficiency given by \\[\n\\boxed{\\eta_c \\equiv 1 - \\frac{T_C}{T_H}} \\ .\n\\] Notice that since \\(T_C &lt; T_H\\), the Carnot efficiency can never be \\(1\\). For reasonable temperature ranges, say from freezing to boiling at STP, we’d have \\(\\eta_c \\approx 0.268\\). That’s under 27% efficiency! In fact, the Carnot engine, while the best we can do efficiency-wise, it’s not practical for real engines. One major reason for this is that isothermal processes are really slow, meaning it takes too impractically long to complete a single cycle.\nSince the Carnot efficiency \\(\\eta_c\\) between two temperatures is fixed, we can use it to define a temperature scale provided we fix a base temperature \\(T_0\\). We can define the temperature \\(T\\) as the value that gives a Carnot efficiency \\(\\eta_c\\) between \\(T\\) and \\(T_0\\). That is, \\[\nT \\equiv T_0 (1 - \\eta_c).\n\\] The thermodynamic definition also implies that temperature \\(T\\) must be positive. If we had \\(T &lt; 0\\), then an engine operating between it and a positive temperature could extract heat from both reservoirs and convert the sum total to work, in violating of the second law.\n\nExample: Carnot Cycle of an Ideal Gas\nTo make the topic somewhat more concrete, suppose we have an ideal gas inside a piston, consisting of a single type of molecule with no exchange of particles taking place. Then the only work being done is the work done by the piston to change the volume \\(V\\) and pressure \\(P\\) of the gas. Then by the first law, \\[\ndE = \\delta Q + \\delta W = \\delta Q - PdV.\n\\] This means the state variables are \\((P, V)\\). In \\(PV\\)-space, the Carnot engine will be a cycle consisting of two isotherms at \\(T_H\\) and \\(T_C\\) that are connected by curves where \\(\\delta Q = 0\\), called adiabatics.\nSuppose a cycle starts on the upper left point, say \\((P_A, V_A)\\). It expands isothermally to \\((P_B, V_B)\\), then adiabatically expands to \\((P_C, V_C)\\), then isothermally compresses to \\((P_D, V_D)\\), before finally adiabatically compressing back to \\((P_A, V_A)\\).\n\n\n\n\n\nAlong the isotherms, the ideal gas law says the curves must be hyperbolas, \\[\nPV = N k_B T_H, \\quad PV = N k_B T_C.\n\\] Along the adiabatics, the condition \\(\\delta Q = 0\\) along with the equipartition theorem implies \\[\ndE = \\frac{n}{2} d(PV) = -PdV \\quad \\Longrightarrow \\quad \\bigg(\\frac{n}{2}+1\\bigg) PdV = -\\frac{n}{2} VdP.\n\\] This is a differential equation for \\(P(V)\\). Using separation of variables on both sides gives \\[\nPV^\\gamma = P_0 V_0^\\gamma = const, \\quad \\text{where} \\quad \\gamma \\equiv \\frac{2}{n}\\bigg(\\frac{n}{2}+1\\bigg).\n\\] For example, with a monoatomic gas we’d have \\(\\gamma = \\frac{5}{3}\\), so the adiabatics are \\(PV^{5/3} = const\\). For the two adiabatic curves in the cycle, taking \\((P_0, V_0)\\) to be the two initial points along the curves gives \\[\nPV^\\gamma = P_B V_B^\\gamma, \\quad PV^\\gamma = P_D V_D^\\gamma.\n\\] Note that since the Carnot cycle is reversible, the total work done during a full cycle is zero.\n\n\n\nEntropy\nWe’re finally ready to construct the state function that’s conjugate to temperature. Let’s look again at the previous theorem that said \\(\\eta \\leq \\eta_c\\) for any engine between \\(T_H\\) and \\(T_C\\). We can rewrite this inequality in the form \\[\n\\frac{W}{Q_H} = 1 - \\frac{Q_C}{Q_H} \\leq 1 - \\frac{T_C}{T_H}.\n\\] Rearranging both sides, we get \\[\n\\frac{Q_H}{T_H} - \\frac{Q_C}{T_C} \\leq 0.\n\\] What’s interesting to notice here is that the quantity \\(\\frac{Q}{T}\\), whatever it is, depends only on the initial and final points. That is, it’s a state function. In fact, the above statement is extremely general.\nClausius’ Theorem: For any cyclic process (not necessarily quasi-static), if \\(\\delta Q\\) is an increment of heat delivered to a system at some temperature \\(T\\), then the sum total ratio of heat to temperature across the entire cycle is negative, i.e. \\[\n\\boxed{\\oint \\frac{\\delta Q}{T} \\leq 0} \\ .\n\\] Proof: What we’ll do is imagine pumping a heat increment \\(\\delta Q\\) into the system by hook a Carnot engine with hot reservoir temperature \\(T_0\\) , which takes input heat \\(\\delta Q_0\\) and uses that to generate some amount of work \\(\\delta W\\), expelling the remaining heat into the system as \\(\\delta Q\\) at a cold reservoir temperature \\(T\\).\n\n\n\n\n\nNow, since the engine is a Carnot engine, we have \\[\n1 - \\eta = \\frac{\\delta Q}{\\delta Q_0} = \\frac{T}{T_0} \\quad \\Longrightarrow \\quad \\delta Q_0 = T_0 \\frac{\\delta Q}{T}.\n\\] At the end of a full cycle, the net effect of the combined process is the extraction of heat \\(Q_0 = \\oint \\delta Q_0\\) from the hot reservoir, which is converted purely to external work \\(W = \\oint \\delta W\\). The total work \\(W\\) is the sum of the work done by the engine and the work done by the system. Now, by the second law, we must have \\(Q_0 = W \\leq 0\\), i.e. \\[\nQ_0 = T_0 \\oint \\frac{\\delta Q}{T} \\leq 0 \\quad \\Longrightarrow \\quad \\oint \\frac{\\delta Q}{T} \\leq 0. \\quad \\text{Q.E.D.}\n\\] Corollary: For a reversible process, we must have exact equality, i.e. \\[\n\\oint \\frac{\\delta Q_{rev}}{T} = 0.\n\\] Proof: This is easy to see. If we run the process forward we get \\(\\frac{\\delta Q_{rev}}{T} \\leq 0\\). By reversibility though, we can also run the process backwards, in which case \\(\\delta Q_{rev} \\rightarrow -\\delta Q_{rev}\\), and so \\(\\frac{\\delta Q_{rev}}{T} \\geq 0\\). This implies the integral between any two points \\(A\\) and \\(B\\) must be path independent, since for any two paths \\(\\mathcal{C}\\) and \\(\\mathcal{C}'\\), we have \\[\n\\int_A^B \\frac{\\delta Q_{rev}^{{\\mathcal{C}}}}{T_{{\\mathcal{C}}}} + \\int_B^A \\frac{\\delta Q_{rev}^{{\\mathcal{C}'}}}{T_{{\\mathcal{C}'}}} = 0 \\quad \\Longrightarrow \\quad \\oint \\frac{\\delta Q_{rev}}{T} = 0. \\quad \\text{Q.E.D.}\n\\] This corollary implies the existence a state function \\(S\\), defined by the path integral \\[\n\\boxed{\\Delta S \\equiv \\int_A^B \\frac{\\delta Q_{rev}}{T}} \\ .\n\\] This state function is called the entropy of the system. Since \\(\\delta Q_{rev} = TdS\\), we’ve finally found the conjugate variable to temperature . It’s just the entropy. Plugging this into the first law, we finally have that for any quasi-static, reversible process in equilibrium, \\[\n\\boxed{dE = TdS + J \\cdot dX + \\mu \\cdot dN} \\ .\n\\] This formula is without doubt the most useful identity in thermodynamics. Notice that this implies that we only need \\(n+m+1\\) total quantities to completely specify the state of the system. We can obtain the rest by partial differentiation. Assuming the mechanical displacements are independent, we have \\[\nT = \\frac{\\partial E}{\\partial S} \\bigg |_{X,N} \\ , \\quad J_i = \\frac{\\partial E}{\\partial X_i} \\bigg |_{S, \\ \\{X_k: \\ k \\neq i\\}, \\ N} \\ , \\quad \\mu_j = \\frac{\\partial E}{\\partial X_i} \\bigg |_{S, \\ X, \\ \\{N_k: \\ k \\neq j\\}} \\ .\n\\] Corollary: For an irreversible process, we have the inequality \\[\n\\int_A^B \\frac{\\delta Q}{T} \\leq \\Delta S.\n\\] Proof: This proof is similar to the previous corollary. What we’ll do is close the cycle by taking a reversible process backwards, which by Clausius’ theorem gives \\[\n\\int_A^B \\frac{\\delta Q}{T} + \\int_B^A \\frac{\\delta Q_{rev}}{T} \\leq 0. \\quad \\text{Q.E.D.}\n\\] In differential form, this corollary implies that \\(dS \\geq \\frac{\\delta Q}{T}\\) for any transformation. Suppose we take some number of adiabatically isolated systems each in equilibrium and bring them all together to thermally interact. Such a system is called a closed system, in that the subsystems are allowed to interact thermally, but not exchange matter. Once the joint system has settled down to equilibrium, the total heat must still be \\(\\delta Q = 0\\), which means that \\(\\delta S \\geq 0\\).\nThis result implies that the net adiabatic system attains its maximum entropy at equilibrium, since any spontaneous change can only act to further increase \\(S\\). This implies that the second law is not time reversible. The direction of increasing entropy points out the arrow of time in its path to equilibrium.\nAnalogy: Compare the statement that entropy increases up to thermal equilibrium with a mechanical statement. Suppose we drop an object some distance above the Earth’s surface, allowing it to free fall under gravity. As the object falls, it will only settle down once it’s reached its mechanical equilibrium, when the total forces are zero. This happens when the potential energy is minimized. In this sense, the statement that entropy increases is no more mysterious than the observation that objects tend to fall downwards under gravity so as to minimize their potential energy.\n\nExample: Entropy of a Monatomic Ideal Gas\nSuppose we have a monatomic ideal gas in a closed system with work \\(\\delta W = -PdV\\). Then \\[\ndE = TdS - PdV.\n\\] What is the change \\(\\Delta S\\) in the entropy along any path in \\(PV\\)-space?\nSolving for \\(dS\\) and using the fact that \\(dE = \\frac{3}{2} Nk_B dT\\) gives \\[\ndS = \\frac{1}{T}dE - \\frac{P}{T} dV = Nk_B \\bigg[\\frac{3}{2} \\frac{dT}{T} + \\frac{dV}{V} \\bigg].\n\\] Integrating both sides and simplifying terms, we finally have \\[\n\\Delta S = Nk_B \\bigg[\\frac{3}{2} \\log \\frac{T}{T_0} + \\log \\frac{V}{V_0} \\bigg] = Nk_B \\log\\bigg[ \\frac{V}{V_0} \\bigg(\\frac{T}{T_0}\\bigg)^{3/2} \\bigg].\n\\] It’s interesting to note from this formula that the entropy is extensive since it depends linearly on \\(N\\). It also seems to increase logarithmically with the volume and the temperature. Since \\(k_B\\) has units of energy over temperature, so too does the entropy.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Thermodynamics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/thermodynamics.html#thermodynamic-potentials",
    "href": "statistical-mechanics/thermodynamics.html#thermodynamic-potentials",
    "title": "Thermodynamics",
    "section": "Thermodynamic Potentials",
    "text": "Thermodynamic Potentials\nLet’s look more closely again at the differential of the energy. We have \\[\ndE = TdS + J \\cdot dX + \\mu \\cdot dN.\n\\] This differential implies that \\(E = E(S, X, N)\\) explicitly, with \\(T, J, \\mu\\) determined implicitly by partial differentiation. Suppose, however, that we wanted the energy as an explicit function of other variables instead. For example, it may be easier to control the temperature or pressure of a gas in the lab than entropy or volume. We can go back and forth between conjugate pairs using Legendre transformations.\nSuppose we have some function \\(f(x, y)\\). Suppose \\(x\\) is conjugate to another variable \\(p\\) in the sense that \\[\ndf = pdx + vdy.\n\\] Notice if we add and subtract \\(xdp\\) to both sides and rearrange, we get a new differential of the form \\[\ndg \\equiv d(f-px) = -xdp + vdy.\n\\] This evidently defines a new function \\(g(p,y) = f(x,y) - px\\) that’s now an explicit function of \\(p\\) and \\(y\\). This new function is called a Legendre transformation of \\(f(x,y)\\). We created a new dual function by swapping \\(x\\) with its conjugate variable \\(p\\). This dual function is completely equivalent in content to the original function since we can always go back and forth between the two via the same kind of transformation.\nWe can apply the Legendre transformation to the energy \\(E=E(S,J,N)\\) to get the energy as a function of the other state variables. The only thing is that these new functions won’t be the original energy exactly, but rather shifted versions of the energy called thermodynamic potentials. In total there are four valid thermodynamic potentials other than the energy: enthalpy, Helmholtz free energy, Gibbs free energy, and the grand potential. Note that all of these potentials still have units of energy.\n\nEnthalpy\nSuppose we wanted to swap \\(J\\) with \\(X\\) to express the energy as a function \\(H = H(S, X, N)\\). We can figure out the form of \\(H\\) by doing a Legendre transformation between \\(J\\) and \\(X\\). Adding \\(X \\cdot dJ\\) to both sides of the first law and rearranging gives \\[\ndH = d(E - J \\cdot X) = TdS - X \\cdot dJ + \\mu \\cdot dN.\n\\] That is, the equation for \\(H\\) is evidently \\[\n\\boxed{H \\equiv E - J \\cdot X} \\ .\n\\] This function is called the enthalpy. We can think of it as a form of energy where the mechanical work gets subtracted out. When dealing with a gas, we’d have \\(J \\cdot dX = -PdV\\), in which case the enthalpy would be \\[\nH = E + pV.\n\\] The enthalpy is perhaps most useful when dealing with adiabatic systems. In that case, \\(\\delta Q = 0\\) means the enthalpy is just the work done, i.e. \\(dH = -X \\cdot dJ + \\mu \\cdot dN\\). Adiabatic processes tend to happen very quickly, like the combustion of gas in a cylinder.\n\n\nHelmholtz Free Energy\nSuppose now we wanted to instead swap \\(T\\) with \\(S\\) to get a function \\(F = F(T, X, N)\\). If we add and subtract \\(SdT\\) to both sides of \\(dE\\) and rearrange, we get \\[\ndF = -SdT + J \\cdot dX + \\mu \\cdot dN.\n\\] The function \\(F\\) is called the Helmholtz free energy, evidently given by \\[\n\\boxed{F = E - TS} \\ .\n\\] We can think of the Helmholtz free energy as a kind of energy in which the heat has been subtracted out of the system. The Helmholtz free energy is perhaps most useful when dealing with isothermal processes, in which case \\(dF\\) reduces to just \\(dF = J \\cdot dX + \\mu \\cdot dN\\). Isothermal processes happen very slowly, so slowly they’re impractical for real-world engines.\n\n\nGibbs Free Energy\nSuppose now we wanted to swap both \\(q\\) with \\(J\\) as well as \\(T\\) with \\(S\\) to get a function \\(G = G(T, J, N)\\). If we start with the enthalpy \\(dH\\) and add and subtract \\(SdT\\) to both sides and rearrange, we get \\[\ndG = d(H - TS) = -SdT - X \\cdot dJ + \\mu \\cdot dN.\n\\] The function \\(G\\) is called the Gibbs free energy, evidently given by \\[\n\\boxed{G = H - TS = E - TS - J \\cdot X} \\ .\n\\] We can think of the Gibbs free energy as a kind of energy in which both the mechanical work done as well as the heat have been subtracted out of the system. When dealing with a gas, \\(G\\) takes the form \\[\nG = E - TS + PV.\n\\] The Helmholtz free energy is perhaps most useful when dealing with processes that take place at fixed temperature and pressure, e.g. processes that take place at STP. These often include, for example, biological processes, like the thermodynamics in and around a cell.\n\n\nGrand Potential\nSo far we haven’t touched the chemical work terms at all. Suppose now though that we want a kind of Gibbs free energy that swaps \\(\\mu\\) with \\(N\\) instead of \\(J\\) with \\(X\\) to get a function \\(\\mathcal{G} = \\mathcal{G}(T,X,\\mu)\\). If we this time start with the Helmholtz free energy and add and subtract \\(N \\cdot d\\mu\\) to both sides and re-arrange, we get \\[\nd\\mathcal{G} = d(F - \\mu \\cdot N) = -SdT + J \\cdot dX - N \\cdot d\\mu.\n\\] This function \\(\\mathcal{G}\\) is called the grand potential, evidently given by \\[\n\\boxed{\\mathcal{G} = F - \\mu \\cdot N = E - TS - \\mu \\cdot N} \\ .\n\\] We can think of the grand potential as a kind of energy in which both the heat and the chemical work have been subtracted out of the system.\n\n\nExtensivity\nIf you look carefully, you’ll see that all of the thermodynamic potentials we defined are a function of at least one extensive variable. It’s fair to ask why we didn’t consider a potential function of all the intensive variables, i.e. some \\(L = L(T,J,\\mu)\\). The reason for this has to do with a mathematical relationship known as extensivity. We say a system is extensive if its energy satisfies the property of homogeneity. That is, for any scalar \\(\\lambda\\), we must have \\[\nE(\\lambda S, \\lambda X, \\lambda N) = \\lambda E(S, X, N).\n\\] Note that extensivity is not a required property of every thermodynamic system. It doesn’t follows from the laws of thermodynamics. It’s in fact an extra constraint that’s satisfied by most systems of real world interest. One example of a system that’s not extensive is a star where gravitational work is being done.\nWe can derive a useful relationship by differentiating both sides of this definition with respect to \\(\\lambda\\), \\[\n\\begin{align*}\n\\frac{\\partial}{\\partial\\lambda} \\lambda E(S, X, N) &= \\frac{\\partial}{\\partial\\lambda} E(\\lambda S, \\lambda X, \\lambda N), \\\\\n\\Longrightarrow E(S, X, N) &= \\frac{\\partial E}{\\partial S} \\bigg |_{X,N} S + \\frac{\\partial E}{\\partial X} \\bigg |_{S,N} \\cdot X + \\frac{\\partial E}{\\partial N} \\bigg |_{S,X} \\cdot N, \\\\\n\\Longrightarrow E(S, X, N) &= TS + J \\cdot X + \\mu \\cdot N. \\\\\n\\end{align*}\n\\] That is, for an extensive system, the energy is just given directly by \\[\n\\boxed{E = TS + J \\cdot X + \\mu \\cdot N} \\ .\n\\] If we take the differential of both sides and apply the first law, we get \\[\n\\begin{align*}\ndE &= d(TS) + d(J \\cdot X) + d(\\mu \\cdot N) \\\\\n&= (TdS + J \\cdot dX + \\mu \\cdot dN) + (SdT + X \\cdot dJ + N \\cdot d\\mu) \\\\\n&= TdS + J \\cdot dX + \\mu \\cdot dN. \\\\\n\\end{align*}\n\\] This means the second term must be zero for an extensive system, \\[\n\\boxed{SdT + X \\cdot dJ + N \\cdot d\\mu = 0} \\ .\n\\] This relation is called the Gibbs-Dunham relation. Notice it’s just the differential of a function \\(L = L(T,J,\\mu)\\) of the intensive variables. We’ve thus shown that no thermodynamic potential of the intensive variables alone can exist for an extensive system.\nExtensivity gives us a new constraint that we can often use to solve problems. Here’s an example.\nThe Gibbs free energy can be used to give a useful interpretation of the chemical potential \\(\\mu\\) of a gas. By extensivity, we must have \\[\nG = E - TS - J \\cdot X = \\mu N.\n\\] That is, the chemical potential of a gas can be thought of as the Gibbs free energy per particle. If there is a mixture of \\(m\\) types of particles in the gas, then \\(\\mu_i\\) is the Gibbs free energy per particle \\(i\\).\n\nExample: Chemical potential along isotherms\nSuppose we wanted to find \\(\\mu\\) for an ideal gas consisting of a single molecule. Since an ideal gas is extensive, along an isotherm we must have the simplified constraint \\[\n-VdP + N d\\mu = 0.\n\\] Now, by the ideal gas law, \\(\\frac{V}{N} = \\frac{k_B T}{P}\\). We can thus re-write this expression as \\[\nd\\mu = \\frac{k_B T}{P} dP.\n\\] Integrating both sides and solve for \\(\\mu\\), we finally have that along an isotherm \\[\n\\mu = \\mu_0 + k_B T \\log \\frac{P}{P_0}.\n\\] Evidently, the chemical potential is an increasing function of temperature, pressure, and volume.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Thermodynamics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/thermodynamics.html#maxwell-relations",
    "href": "statistical-mechanics/thermodynamics.html#maxwell-relations",
    "title": "Thermodynamics",
    "section": "Maxwell Relations",
    "text": "Maxwell Relations\nRecall from calculus that for any function with continuous second partial derivatives, the mixed second partial derivatives commute. For example, a function \\(z = f(x,y)\\) would have \\[\n\\frac{\\partial^2 z}{\\partial x \\partial y} = \\frac{\\partial^2 z}{\\partial y \\partial x}.\n\\] We generally assume that the state functions in thermodynamics are sufficiently smooth enough that their mixed partial derivatives all commute like this. This condition imposes another set of constraints on the potentials, which we can use to find interesting, non-trivial relationships between various state variables. They’re called the Maxwell relations. If \\(dE = TdS + J \\cdot dX + \\mu \\cdot dN\\), then there are in total 3 Maxwell relations per potential, which means there are \\(3 \\cdot 5 = 15\\) relations across all 5 potentials, though some of these are duplicates. Here are the differential forms of all 5 potentials again, \\[\n\\boxed{\n\\begin{align*}\ndE &= \\quad TdS + J \\cdot dX + \\mu \\cdot dN \\\\\ndH &= \\quad TdS - X \\cdot dJ + \\mu \\cdot dN \\\\\ndF &= \\;-SdT + J \\cdot dX + \\mu \\cdot dN \\\\\ndG &= \\;-SdT - X \\cdot dJ + \\mu \\cdot dN \\\\\nd\\mathcal{G} &= \\;-SdT + J \\cdot dX - N \\cdot d\\mu \\\\\n\\end{align*}\n} \\ .\n\\]\nIn the simple case of a closed system, we’d have \\(dN=0\\), which reduces the total number of relations to \\(1 \\cdot 4 = 4\\). Those 4 Maxwell relations are evidently \\[\n\\boxed{\n\\begin{align*}\n&\\frac{\\partial^2 E}{\\partial S \\partial X}& &=& &\\frac{\\partial T}{\\partial X} \\bigg |_{S,N}& &=& &\\frac{\\partial J}{\\partial S} \\bigg |_{X,N}& \\\\\n&\\frac{\\partial^2 H}{\\partial S \\partial J}& &=& -&\\frac{\\partial T}{\\partial J} \\bigg |_{S,N}& &=& &\\frac{\\partial X}{\\partial S} \\bigg |_{J,N}& \\\\\n&\\frac{\\partial^2 F}{\\partial T \\partial X}& &=& -&\\frac{\\partial S}{\\partial X} \\bigg |_{T,N}& &=& &\\frac{\\partial J}{\\partial T} \\bigg |_{X,N}& \\\\\n&\\frac{\\partial^2 G}{\\partial T \\partial J}& &=& &\\frac{\\partial S}{\\partial J} \\bigg |_{T,N}& &=& &\\frac{\\partial X}{\\partial T} \\bigg |_{J,N}& \\\\\n\\end{align*}\n} \\ .\n\\] Though the relations themselves are non-intuitive, the process for deriving them is straight forward. Suppose for example we wanted to find a Maxwell relation for \\[\n\\frac{\\partial \\mu}{\\partial P} \\bigg |_{T,N}.\n\\] To get a relation like this, we’d need a potential that’s an explicit function of \\(P, T, N\\). That’s of course the Gibbs free energy. In this case, we’d have \\[\n\\frac{\\partial \\mu}{\\partial P} \\bigg |_{T,N} = \\frac{\\partial}{\\partial P} \\bigg |_{T,N} \\frac{\\partial G}{\\partial N} \\bigg |_{T,P} = \\frac{\\partial}{\\partial N} \\bigg |_{T,P} \\frac{\\partial G}{\\partial P} \\bigg |_{T,N} = \\frac{\\partial V}{\\partial N} \\bigg |_{T,P}.\n\\] Compare this relation with the one for an extensive system that we saw in a previous example, \\[\n\\frac{\\partial \\mu}{\\partial P} \\bigg |_{T,N} = \\frac{V}{N}.\n\\]",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Thermodynamics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/thermodynamics.html#stability-conditions",
    "href": "statistical-mechanics/thermodynamics.html#stability-conditions",
    "title": "Thermodynamics",
    "section": "Stability Conditions",
    "text": "Stability Conditions\nThermodynamics depends on systems being in equilibrium. We already know that systems at equilibrium with each other will have the same temperature, but what else can we say?\n\nMechanical Stability\nRecall from classical mechanics what it means for a classical system to be in mechanical equilibrium. A classical system is said to be in mechanical equilibrium when the total forces acting on the system are zero, i.e. \\(\\mathbf{F} = \\mathbf{0}\\). For conservative systems, that’s equivalent to saying the potential \\(V=V(\\mathbf{x})\\) has gradient zero, i.e. \\(\\nabla V(\\mathbf{x}) = \\mathbf{0}\\).\nThe equilibrium point \\(\\mathbf{x}^*\\) is a stable equilibrium if \\(V(\\mathbf{x}^* )\\) is a local minimum. A sufficient condition for this to be true is that the second-order deviations around \\(V(\\mathbf{x}^* )\\) are positive, or equivalently that the Hessian of \\(V(\\mathbf{x})\\) is positive definite about \\(\\mathbf{x}^*\\), i.e. \\[\n\\delta^2 V \\equiv \\delta\\mathbf{x} \\cdot \\frac{d^2}{d\\mathbf{x}^2} V(\\mathbf{x}^*) \\cdot \\delta\\mathbf{x} = \\sum_{i,j=1}^3\\frac{\\partial^2 V}{\\partial x_i \\partial x_j}\\delta x_i \\delta x_j &gt; 0 \\quad \\forall\\delta\\mathbf{x} \\neq \\mathbf{0}.\n\\] Intuitively, a stable equilibrium means that if the system is nudged by a small displacement it will experience a tension force pulling it back to equilibrium. Think of a spring as the canonical example.\n\n\nThermodynamic Stability\nWe’d like to derive an analogue of this formula to characterize what it means for a thermodynamic system to be in a stable equilibrium. To do that, it’s convenient to symmetrize the positive definite expression with respect to \\(\\mathbf{F}\\) and \\(\\mathbf{x}\\). Notice that if we let \\[\n\\delta \\mathbf{F} \\equiv \\frac{d^2 V}{d\\mathbf{x}^2} \\cdot \\delta\\mathbf{x} = \\sum_{j=1}^3 \\frac{\\partial^2 V}{\\partial x_i \\partial x_j} \\delta x_j,\n\\] then we can re-write the condition for mechanical stability as \\[\n\\delta \\mathbf{F} \\cdot \\delta\\mathbf{x} = \\sum_{i=1}^3 \\delta F_i \\delta x_i &gt; 0.\n\\] We can extend this same idea to thermodynamical systems, except there we require that all equilibrium points be stable. That is, the stability condition is required to be in thermodynamic equilibrium.\nTheorem: Any thermodynamic system in equilibrium must satisfy the stability condition \\[\n\\boxed{\\delta T \\delta S + \\delta J \\cdot \\delta X + \\delta \\mu \\cdot \\delta N \\geq 0} \\ .\n\\] Proof: Consider an isolated system in equilibrium. Then any two subsystems \\(A\\) and \\(B\\) must be in equilibrium with each other. It must be the case then that their intensive quantities are identical, i.e. \\[\nT \\equiv T_A = T_B, \\quad J \\equiv J_A = J_B, \\quad \\mu \\equiv \\mu_A = \\mu_B.\n\\] It must also be the case that their extensive quantities add to give the ones for the full system, \\[\nE \\equiv E_A + E_B, \\quad S \\equiv S_A + S_B, \\quad X \\equiv X_A + X_B, \\quad N \\equiv N_A + N_B.\n\\] Suppose that \\(B\\) spontaneously transfers energy to \\(A\\) in the form of both heat and work. Let’s look at the first order change in the system’s total entropy. Evidently, we’d have \\[\n\\begin{align*}\n\\delta S &= \\delta S_A + \\delta S_B \\\\\n&= \\delta\\bigg(\\frac{E_A}{T_A} - \\frac{J_A}{T_A} \\cdot X_A - \\frac{\\mu_A}{T_A} \\cdot N_A \\bigg) + \\delta\\bigg(\\frac{E_B}{T_B} - \\frac{J_B}{T_B} \\cdot X_B - \\frac{\\mu_B}{T_B} \\cdot N_B \\bigg) \\\\\n&= 2\\bigg[\\delta\\bigg(\\frac{1}{T_A}\\bigg) \\delta E_A - \\delta\\bigg(\\frac{J_A}{T_A}\\bigg)\\cdot \\delta X_A - \\delta\\bigg(\\frac{\\mu_A}{T_A}\\bigg)\\cdot \\delta N_A \\bigg] \\\\\n&= -\\frac{2}{T_A}\\bigg[\\delta T_A \\bigg(\\frac{\\delta E_A - J_A \\cdot \\delta X_A - \\mu_A \\cdot \\delta N_A}{T_A}\\bigg) + \\delta J_A \\cdot \\delta X_A + \\delta\\mu_A \\cdot \\delta N_A\\bigg] \\\\\n&= -\\frac{2}{T_A}\\big[\\delta T_A \\delta S_A + \\delta J_A \\cdot \\delta X_A + \\delta \\mu_A \\cdot \\delta N_A\\big].\n\\end{align*}\n\\] To be in equilibrium, any change to the system should lead to a decrease in entropy since entropy is maximized at equilibrium. This implies that \\(\\delta S \\leq 0\\), or equivalently that \\[\n\\delta T_A \\delta S_A + \\delta J_A \\cdot \\delta X_A + \\delta \\mu_A \\cdot \\delta N_A \\geq 0.\n\\] This condition should apply for any subsystem, which means it should apply to the whole system as well, \\[\n\\delta T \\delta S + \\delta J \\cdot \\delta X + \\delta \\mu \\cdot \\delta N \\geq 0.\n\\] The above condition was obtained assuming the system’s extensive variables \\(E,q,N\\) were held constant. In fact, since all coordinates appear symmetrically in the expression, the same result is obtained for any other set of constraints as well. \\(\\text{Q.E.D.}\\)\nAnother way of expressing the stability condition is that any second order deviations in the energy around equilibrium must be positive, i.e. \\(\\delta^2 E \\geq 0\\). This also means that the energy function should be convex about its equilibrium states.\n\n\nClosed Systems\nSuppose a system is closed, so \\(dN = 0\\). Then the first law says \\(dE = TdS + J \\cdot dX\\), and the stability condition says \\(\\delta T \\delta S + \\delta J \\cdot \\delta X \\geq 0\\). We can always solve for any two variables in terms of the rest. For example, we can write \\[\n\\begin{align*}\n\\delta S &= \\frac{\\partial S}{\\partial T} \\bigg |_{X,N} \\delta T + \\frac{\\partial S}{\\partial X} \\bigg |_{T,N} \\delta X, \\\\\n\\delta J &= \\frac{\\partial J}{\\partial T} \\bigg |_{X,N} \\delta T + \\frac{\\partial J}{\\partial X} \\bigg |_{T,N} \\delta X. \\\\\n\\end{align*}\n\\] Substituting these into the stability condition, we can write \\[\n\\begin{align*}\n0 &\\leq \\delta T \\bigg(\\frac{\\partial S}{\\partial T} \\bigg |_{X,N} \\delta T + \\frac{\\partial S}{\\partial X} \\bigg |_{T,N} \\delta X\\bigg) + \\bigg(\\frac{\\partial J}{\\partial T} \\bigg |_{X,N} \\delta T + \\frac{\\partial J}{\\partial X} \\bigg |_{T,N} \\delta X\\bigg) \\delta X \\\\\n&\\leq \\frac{\\partial S}{\\partial T} \\bigg |_{X,N} \\delta T^2 + \\bigg(\\frac{\\partial S}{\\partial X} \\bigg |_{T,N} + \\frac{\\partial J}{\\partial T} \\bigg |_{X,N} \\bigg) \\delta T \\delta X + \\frac{\\partial J}{\\partial X} \\bigg |_{T,N} \\delta X^2 \\\\\n&\\leq \\frac{\\partial S}{\\partial T} \\bigg |_{X,N} \\delta T^2 + \\frac{\\partial J}{\\partial X} \\bigg |_{T,N} \\delta X^2. \\\\\n\\end{align*}\n\\] The last line follows from the fact that \\(\\frac{\\partial S}{\\partial X} \\big |_{T,N} = -\\frac{\\partial J}{\\partial T} \\big |_{X,N}\\) via a Maxwell relation. Let’s look at this in two cases, first when along curves of constant \\(X\\), and then along curves of constant \\(T\\). In the first case we’d have \\(\\delta X = 0\\), which says \\[\n\\frac{\\partial S}{\\partial T} \\bigg |_{X,N} \\delta T^2 \\geq 0.\n\\] This says that along curves of constant \\(X\\), the entropy must be an increasing function of temperature. This evidently implies that the heat capacity along constant \\(X\\) must be non-negative, since \\[\nC_q = \\frac{\\delta Q}{\\partial T} \\bigg |_{X,N} = T \\frac{\\partial S}{\\partial T} \\bigg |_{X,N} \\geq 0.\n\\] Let’s now look at curves of constant \\(T\\), i.e. the isotherms. In that case we’d have \\[\n\\frac{\\partial J}{\\partial X} \\bigg |_{T,N} \\delta X^2 \\geq 0,\n\\] which evidently implies \\(J\\) must be an increasing function of \\(X\\) along the isotherms. In the case of a gas, this condition just says that pressure \\(p\\) must be a decreasing function of \\(V\\) along isotherms, which we’ve already seen.\n\nExample: Stability of Gases\nSuppose we have some gas that’s kept a constant temperature \\(T\\) and particle number \\(N\\). If we apply the stability condition to a gas, in general we’d have \\[\n\\delta T \\delta S - \\delta P \\delta V + \\delta \\mu \\delta N \\geq 0.\n\\] Since \\(\\delta T = \\delta N = 0\\), this simplifies to just \\(-\\delta P \\delta V \\geq 0\\), or equivalently \\[\n\\delta P = \\frac{\\partial P}{\\partial V} \\bigg |_{T,N} \\delta V \\leq 0.\n\\] This says that evidently \\(P\\) must be a decreasing function of \\(V\\). If we define the compressibility \\(\\kappa\\) of a gas by \\[\n\\kappa \\equiv -\\frac{1}{V} \\frac{\\partial V}{\\partial P} \\bigg |_{T,N},\n\\] then the stability condition evidently says that \\(\\kappa \\geq 0\\) at equilibrium. That is, the gas must be compressible, i.e. increasing the pressure on the gas should decrease its volume.\nIt’s interesting to examine the special isotherm \\(T=T_c\\) where \\(\\frac{\\partial P}{\\partial V} \\big |_{T,N} = 0\\). Along this isotherm there’s a flat spot near some critical point \\((P_c,V_c)\\). Around this point \\(\\delta P = 0\\), which means we need to look at the higher-order deviations in \\(P(V)\\). If we expand to third order about \\(V_c\\), we’d have \\[\n\\delta P \\approx \\frac{\\partial P}{\\partial V} \\bigg |_{T_c,N} \\delta V + \\frac{1}{2} \\frac{\\partial^2 P}{\\partial V^2} \\bigg |_{T_c,N} \\delta V^2 + \\frac{1}{6} \\frac{\\partial^3 P}{\\partial V^3} \\bigg |_{T_c,N} \\delta V^3.\n\\] To satisfy the stability condition we can only keep terms with odd powers in \\(\\delta V\\), since otherwise \\(\\delta P \\delta V\\) wouldn’t be non-negative. Evidently then, to maintain stability, about the critical point we must have \\[\n\\delta P \\approx \\frac{1}{6} \\frac{\\partial^3 P}{\\partial V^3} \\bigg |_{T_c,N} \\delta V^3, \\quad \\text{where} \\quad \\frac{\\partial^3 P}{\\partial V^3} \\bigg |_{T_c,N} \\geq 0.\n\\] This means that the isotherm along \\(T=T_c\\) must be a decreasing cubic with stationary point at \\((P_c,V_c)\\).\nIn reality, this condition requires that \\(P(V)\\) be an analytic function around \\(T_c\\). But it turns out that it’s not analytic around this point. There’s a phase transition. In fact, near \\(T_c\\) it’s the case that \\(\\delta P \\propto \\delta V^\\gamma\\), where \\(\\gamma \\approx 4.7\\) is an experimentally determined constant. To understand this better we’d need field theory.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Thermodynamics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/thermodynamics.html#third-law",
    "href": "statistical-mechanics/thermodynamics.html#third-law",
    "title": "Thermodynamics",
    "section": "Third Law",
    "text": "Third Law\nSuppose we take a reversible system and change its state from \\(x_1\\) to \\(x_2\\). Then its entropy changes by \\[\n\\Delta S = S_2 - S_1 = \\int_{x_1}^{x_2} \\frac{\\delta Q_{rev}}{T}.\n\\] We can say this for any positive temperature \\(T\\). Now suppose we allow \\(T \\rightarrow 0\\). What happens to \\(\\Delta S\\)? It turns out experimentally that \\(\\Delta S \\rightarrow 0\\). This is an independent fact due to Nernst, which gives us a narrow statement of the third law of thermodynamics.\nThird Law (Nernst): The entropy of all systems at zero absolute temperature is a universal constant that can be taken to be zero. That is, between any two states we must have \\[\n\\boxed{\\lim_{T \\rightarrow 0} \\Delta S = 0} \\ .\n\\] This statement turns out to be experimentally equivalent to an even stronger statement. Not only does \\(\\Delta S \\rightarrow 0\\), but in fact \\(S \\rightarrow 0\\) for any substance.\nThird Law (General): The entropy of all substances at zero absolute temperature is the same universal constant, which can be defined to be zero. That is, for any system, \\[\n\\boxed{\\lim_{T \\rightarrow 0} S = S_0 \\equiv 0} \\ .\n\\] This extended version of the third law can be experimentally tested by looking at the behavior of certain materials like sulfur or phosphine, which can exist near absolute zero in multiple crystalline structures called allotropes. Each allotrope has its own heat capacity \\(C(T)\\). It’s been shown that as \\(T \\rightarrow 0\\), each of these paths sends \\(C \\rightarrow 0\\), which implies \\(S \\rightarrow 0\\) as well.\n\n\n\n\n\nHere are a few notable consequences that follow from the third law. First, since \\(S \\rightarrow 0\\) as \\(T \\rightarrow 0\\), it must also be true that any partial derivative of \\(S\\) must go to zero as well, \\[\n\\lim_{T \\rightarrow 0} \\frac{\\partial S}{\\partial X} \\bigg |_T = 0.\n\\] The heat capacities must go to zero as well since \\[\n\\Delta S = \\int_0^T \\frac{C(T')}{T'} dT' \\rightarrow 0.\n\\] This integral would diverge as \\(T \\rightarrow 0\\) unless \\(C \\rightarrow 0\\) as well.\nThe thermal expansion coefficients must also go to zero since by a Maxwell relation we have \\[\n\\alpha \\equiv \\frac{1}{X} \\frac{\\partial X}{\\partial T} \\bigg |_J = \\frac{1}{X} \\frac{\\partial S}{\\partial J} \\bigg |_T \\rightarrow 0.\n\\] The last consequence of note is that it must be impossible to cool any system to absolute zero in a finite number of steps, which for practical purposes means it’s impossible to cool a system to zero exactly. For example, suppose we tried to cool a gas by adiabatically reducing its pressure. Since all \\(S(T)\\) curves must intersect at \\(0\\), any successive step would involve progressively smaller changes in \\(S\\) and \\(T\\) as \\(T \\rightarrow 0\\).\n\n\n\n\n\nIt’s worth mentioning that in a certain sense the third law is less reliable than the other laws of thermodynamics since at its root its validity rests entirely on quantum mechanics, and the quantum mechanical behavior of different systems can vary wildly near absolute zero. This contrasts with the other laws, which at a microscopic level only depend on things like the conservation of energy, or the emergent effect of a large number of degrees of freedom. We’ll see a microscopic derivation of each of these laws in future chapters.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Thermodynamics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/probability.html",
    "href": "statistical-mechanics/probability.html",
    "title": "Probability",
    "section": "",
    "text": "Univariate Probability",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/probability.html#univariate-probability",
    "href": "statistical-mechanics/probability.html#univariate-probability",
    "title": "Probability",
    "section": "",
    "text": "Probability Measures\nAt its root, probability is based on the study of events or random variables. Suppose \\(\\mathcal{S}\\) is the set of all possible outcomes of an experiment, called the sample space. Any subset \\(E \\subset \\mathcal{S}\\) is called an event. A probability measure is a set function \\(\\mathbb{Pr}(E)\\) that maps events to numerical values between zero and one. It’s meant to formalize the concept of chance. If an event has probability one, we think of that event as being 100% certain to occur. If it has probability zero, we think of the event as having 0% chance to occur. Any values in between mean we’re uncertain whether the event will occur.\nFormally, a probability measure on a sample space \\(\\mathcal{S}\\) satisfies the following properties:\n\nPositivity: For any event \\(E \\subset \\mathcal{S}\\), \\(\\mathbb{Pr}(E) \\geq 0\\).\nAdditivity: If \\(A \\subset \\mathcal{S}\\) and \\(B \\subset \\mathcal{S}\\) are distinct, disjoint events, then \\(\\mathbb{Pr}(A \\text{ or } B) = \\mathbb{Pr}(A) + \\mathbb{Pr}(B)\\).\nNormalization: For the entire sample space \\(\\mathcal{S}\\), \\(\\mathbb{Pr}(\\mathcal{S}) = 1\\).\n\nWhile this is a nice formal definition of probability, it’s not practically useful for saying how we should design a probability measure in a practical setting. There are two common approaches for designing probability measures:\n\nThe objective approach: In this approach, we imagine running a bunch of experiments and counting the frequency of occurrences of an event. That is, if we run a large number \\(N\\) of experiments and observe an event \\(A\\) occurs exactly \\(N_A\\) times, then we define \\(\\mathbb{Pr}(A)\\) by the ratio \\[\n\\boxed{\\mathbb{Pr}(A) \\equiv \\lim_{N \\rightarrow \\infty} \\frac{N_A}{N}} \\ .\n\\] The fact that the ratio \\(\\frac{N_A}{N}\\) stabilizes to a fixed value as \\(N\\) gets infinitely large follows from the law of large numbers, which we’ll take as a kind of experimental fact.\nThe subjective approach: In this approach we take a more theoretical view by looking for a “maximally random” probability distribution that matches what we know to be true. That is, we seek to find the maximum entropy probability distribution that satisfies some given set of known constraints. We’ll talk more about the principle of maximum entropy when we get to information theory. The subjective approach is the one used most heavily in statistical mechanics.\n\n\n\nRandom Variables\nA random variable is a variable \\(X\\) that doesn’t take on a fixed value, but rather a random value determined by a probability distribution. If \\(E \\subset \\mathcal{S}\\) is an event, a random variable encodes that event using a numerical variable \\(X=X(E)\\). More formally, \\(X(E)\\) is a function that maps events to a numerical value. It could be a real number, a complex number, or a real or complex vector, for example.\nA one-dimensional random variable is a mapping \\(X(E)\\) from events \\(E \\subset \\mathcal{S}\\) into the real numbers \\(\\mathbb{R}\\). In this case, we can define a cumulative distribution function or CDF as the function \\[\n\\boxed{P(x) \\equiv \\mathbb{Pr}\\big(\\{X \\leq x\\}\\big)} \\ .\n\\] That is, the CDF is the probability that the random variable \\(X \\leq x\\), where \\(x\\) is just some real number. To obey the laws of probability, the CDF must satisfy the following properties:\n\nIt’s an increasing function of \\(x\\). That is, if \\(x_1 \\leq x_2\\) then \\(P(x_1) \\leq P(x_2)\\).\nIt has probability zero at \\(x=-\\infty\\). That is, \\(\\lim_{x \\rightarrow -\\infty} P(x) = 0\\).\nIt has probability one at \\(x=\\infty\\). That is, \\(\\lim_{x \\rightarrow \\infty} P(x) = 1\\).\n\nIf the set of all values \\(X\\) can take on are discrete, we say \\(X\\) is a discrete random variable. In this case, we can define a probability mass function or PMF as the function \\[\n\\boxed{p(x) \\equiv \\mathbb{Pr}(X = n)} \\ .\n\\] By the laws of probability the PMF must satisfy the following properties:\n\nIt’s between zero and one: \\(0 \\leq p(n) \\leq 1\\).\nIt sums to one over all values, i.e. \\(\\sum_{n \\in \\mathcal{S}} \\ p(n) = 1\\).\nIt’s related to the CDF by \\(P(x) = \\sum_{n \\leq x} \\ p(n)\\).\n\nIf the set of all values it can take on are continuous, we say \\(X\\) is a continuous random variable. In this case, we can define a probability density function or PDF by the function \\[\n\\boxed{p(x) = \\mathbb{Pr}(x \\leq X \\leq x + dx)} \\ .\n\\] By the laws of probability, the PDF must satisfy the following properties:\n\nIt’s a positive function \\(p(x) \\geq 0\\).\nIt integrates to one over all values, \\(\\int_\\mathcal{S} p(x) dx = 1\\).\nIt’s related to the CDF by differentiation, \\(p(x) = \\frac{d}{dx} P(x)\\).\n\nNote that in physics the PDF has units. If \\(x\\) has units of \\([x]\\), then evidently \\(p(x)\\) must have units of \\(\\frac{1}{[x]}\\). This is why we think of the PDF as a density. It’s a probability per unit \\(x\\).\nBy convention, if \\(S \\subset \\mathbb{R}\\) we’ll assume \\(p(x) = 0\\) on values of \\(x\\) outside of \\(S\\). This means we can treat the PMF as a PDF by using delta functions to indicate where each discrete value of \\(x\\) has non-zero \\(p(x)\\). That is, \\[\np(k) = p(x) \\delta (x - k).\n\\] For this reason, we’ll generally state results in the form of a continuous random variable.\nWhere there’s no risk of confusion, we’ll frequently abuse notation by using the lower case letter \\(x\\) for both the random variable as well as the value it can take on.\n\n\nMoments and Cumulants\nFor both discrete and continuous random variables we can define the expected value of a random function \\(F(x)\\) by summing or integrating the function, weighted by the PMF or PDF. In the continuous case, we’d define the expected value \\(\\langle F(x) \\rangle\\) by \\[\n\\boxed{\\langle F(x) \\rangle \\equiv \\int_{\\mathbb{R}} dx \\ F(x) p(x)} \\ .\n\\] Some of the functions \\(F(x)\\) have special names:\n\nWe call \\(\\mu \\equiv \\langle x \\rangle\\) the mean of \\(x\\).\nWe call \\(\\mu_n \\equiv \\langle x^n \\rangle\\) the nth moment of \\(x\\).\nWe call \\(\\langle e^{-ikx} \\rangle\\) the characteristic function or CF of \\(x\\).\n\nNote the characteristic function is just the Fourier transform of the PDF since \\[\n\\langle e^{-ikx} \\rangle = \\tilde p(k) = \\int_{\\mathbb{R}} dx \\ e^{-ikx} p(x).\n\\] This means we can always go from the CF back to the PDF by taking the inverse Fourier transform, \\[\np(x) = \\int_{\\mathbb{R}} \\frac{dx}{2\\pi} \\ e^{ikx} \\tilde p(k).\n\\] If we Taylor expand the CF, we can also evidently write \\[\n\\langle e^{-ikx} \\rangle = \\bigg\\langle \\sum_{n=0}^\\infty \\frac{(-ik)^n}{n!} x^n \\bigg\\rangle = \\sum_{n=0}^\\infty \\frac{(-ik)^n}{n!} \\mu_n.\n\\] This means that the CF can be used to generate moments for a given distribution. Once we have a closed form for the CF, just expand it into a series and pick off each \\(\\mu_n = \\langle x^n \\rangle\\) term by term.\nWe can translate the CF to any other point \\(x_0\\) by observing that \\[\n\\langle e^{-ik(x-x_0)} \\rangle = \\int_{\\mathbb{R}} dx \\ e^{-ik(x-x_0)} p(x) = e^{ikx_0} \\tilde p(k).\n\\] More useful to us in practice is not the characteristic function, but its logarithm, called the cumulant function. We’ll assume we can expand \\(\\log \\tilde p(k)\\) as a Taylor Series about \\(k=0\\) weighted by some coefficients \\(\\kappa_n\\). By expanding out the MGF inside the log, we can evidently then write \\[\n\\log \\tilde p(k) = \\sum_{n=1}^\\infty \\frac{(-ik)^n}{n!} \\kappa_n = \\log\\bigg(1 + \\sum_{n=1}^\\infty \\frac{(-ik)^n}{n!} \\mu_n \\bigg).\n\\] The sum inside the log is of the form \\(1+\\varepsilon\\). We can thus expand the log in powers of \\(\\varepsilon\\) to get \\[\n\\log\\big(1 + \\varepsilon \\big) = 1 + \\varepsilon - \\frac{1}{2} \\varepsilon^2 + \\frac{1}{3} \\varepsilon^3 - \\frac{1}{4} \\varepsilon^4 + \\cdots\n\\] Using this expansion and matching term-by-term to the original expansion of \\(\\log \\tilde p(k)\\) we can find expressions for the coefficients \\(\\kappa_n\\) in terms of the moments \\(\\mu_n\\). These coefficients are called the nth cumulants of \\(x\\). The first cumulant turns out to be the mean of \\(x\\), \\[\n\\kappa_1 = \\langle x \\rangle.\n\\] Intuitively, the mean \\(\\mu\\) of a distribution represents its center of mass or average value. To see why, suppose \\(x\\) is a discrete random variable taking on values \\(1, 2, \\cdots, n\\) each with probability \\(p(x) = \\frac{1}{n}\\). Then we’d have \\[\n\\mu = \\sum_{x=1}^n x p(x) = \\frac{1}{n} \\sum_{x=1}^n x = \\overline x.\n\\] That is, the mean is just the unweighted average \\(\\overline x\\) from elementary math. In general each \\(x\\) will be weighted by its probability \\(p(x)\\) giving a weighted average.\nThe second cumulant is evidently given by \\[\n\\kappa_2 = \\langle x^2 \\rangle - \\langle x \\rangle^2.\n\\] This is called the variance of \\(x\\), usually denoted \\(\\sigma^2\\). By rearranging the right-hand side a little bit we can also write the variance in the form \\[\n\\boxed{\\sigma^2 \\equiv \\langle x^2 \\rangle - \\langle x \\rangle^2 = \\langle (x-\\mu) \\rangle^2} \\ .\n\\] This gives an intuitive interpretation of the variance. It’s the mean squared difference from the mean. It’s a squared measure of the spread of the distribution. For this reason we often prefer to take its square root to get a measure of the spread in units of \\(x\\) itself. This is called the standard deviation, \\(\\sigma \\equiv \\sqrt{\\sigma^2}\\).\nThe third cumulant is evidently given by \\[\n\\kappa_3 = \\langle x^3 \\rangle - 3\\langle x^2 \\rangle\\langle x \\rangle + 2 \\langle x \\rangle^3.\n\\] It’s not obvious what this represents, but it turns out to represent the skewness of \\(x\\). That is, the tendency for the distribution to skew left or right by some amount. A distribution symmetric about its mean will have zero skew since all of the odd moments will vanish, hence \\(\\kappa_3 = 0\\). Strictly speaking, the skewness is often normalized by dividing by \\(\\sigma^3\\).\nThere’s a useful graphical trick that can be used to quickly find the relationship between cumulants and moments. The idea is to represent the nth cumulant \\(\\kappa_n\\) is a bag of \\(n\\) points. Then we can get the nth moment by summing over all possible ways of distributing \\(n\\) points among all possible bags \\(1, 2, \\cdots, n\\). It’s easiest to show this by example. Here’s how to get the first few moments from the first few cumulants:\n\n\n\n\n\n\n\nChange of Variables\nOccasionally we’ll want to make a change of variables from one random variable to another. To do that we need to figure out how the probabilities change under the change of variables. Suppose \\(F=F(X)\\) is a random function of a random variable \\(X\\). If \\(f = F(x)\\), then probability that \\(X \\in [x, x+dx]\\) must be the same as the probability that \\(F \\in [f, f+df]\\). Provided \\(F(x)\\) is single-valued, that means we’d have \\[\np_F(f) df = p_X(x) dx.\n\\] Dividing both sides by \\(df\\) and noting that probabilities have to be positive, we have \\[\np_F(f) = p_X(x) \\bigg|\\frac{dx}{df}\\bigg|.\n\\] In general \\(F(x)\\) need not be single-valued. This means we have to sum over all possible values \\(x_i\\) such that \\(f=F(x_i)\\). In this case, we’d instead have \\[\n\\boxed{p_F(f) = \\sum p_X(x_i) \\bigg|\\bigg(\\frac{dx}{df}\\bigg)_{x=x_i}\\bigg|} \\ .\n\\]\n\n\n\n\n\n\nExample: The Laplace Distribution\nSuppose \\(p(x) \\propto e^{-\\lambda |x|}\\) where \\(\\lambda &gt; 0\\) is some scale parameter.\n\nFind the normalization constant \\(\\mathcal{N}\\) such that \\(p(x) = \\mathcal{N} e^{-\\lambda |x|}\\).\nThe PDF must integrate to one from \\(-\\infty\\) to \\(\\infty\\). We have \\[\n1 = \\int_{-\\infty}^\\infty dx \\ p(x) = \\int_{-\\infty}^\\infty dx \\  \\mathcal{N} e^{-\\lambda |x|} = \\frac{2\\mathcal{N}}{\\lambda}.\n\\] Thus, \\(\\mathcal{N} = \\frac{\\lambda}{2}\\), so we finally just have \\(p(x) = \\frac{\\lambda}{2} e^{-\\lambda x}\\). This is called the Laplace distribution.\nSuppose \\(f = x^2\\). Find the new PDF \\(p_F(f)\\) using a change of variables.\nThis transformation is multi-valued, with \\(x = \\pm \\sqrt{f}\\). Using the change of variables, we have \\[\n\\begin{align*}\np_F(f) &= p(\\sqrt{f}) \\bigg|\\frac{d}{df} \\sqrt{f}\\bigg| + p(-\\sqrt{f}) \\bigg|-\\frac{d}{df} \\sqrt{f}\\bigg| \\\\\n&= \\frac{\\lambda}{2} e^{-\\lambda \\sqrt{f}} \\bigg(\\frac{1}{2\\sqrt{f}} +  \\frac{1}{2\\sqrt{f}} \\bigg) \\\\\n&= \\frac{\\lambda}{2\\sqrt{f}} e^{-\\lambda \\sqrt{f}}. \\\\\n\\end{align*}\n\\] Note that this new PDF is only defined when \\(f \\geq 0\\) due to the square root.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/probability.html#probability-distributions",
    "href": "statistical-mechanics/probability.html#probability-distributions",
    "title": "Probability",
    "section": "Probability Distributions",
    "text": "Probability Distributions\nSo far I’ve used the term distribution rather loosely. More formally, given a random variable \\(x\\), a probability distribution is a specific functional form for \\(p(x)\\). We’d write \\(x \\sim p(x)\\) to indicate that \\(x\\) is distributed as \\(p(x)\\). Usually \\(p(x)\\) will be parametric, meaning it will have external parameters that tune the shape of the distribution. Here are some common univariate distributions we’ll see in statistical mechanics:\n\nUniform Distribution\nThe uniform distribution is perhaps the simplest distribution of all, with \\(p(x) = const\\) on some set \\(x \\in \\mathcal{S}\\). As a shorthand we might write \\(x \\sim U(\\mathcal{S})\\) to say \\(x\\) is uniform on the set \\(\\mathcal{S}\\). In the discrete case, \\(x\\) takes on some number of values \\(N\\) each with equal probability, for example if \\(\\mathcal{S} = \\{1, 2, \\cdots, n\\}\\) we have \\[\n\\boxed{p(x) = \\frac{1}{N}} \\ .\n\\] We can easily calculate the moments of a uniform random variable directly. In the discrete case, we’d have \\[\n\\langle x^n \\rangle = \\sum_{x=1}^N \\ x^n \\ p(x) = \\frac{1}{N} (1^n + 2^n + \\cdots + N^n).\n\\] This is just an arithmetic sum in powers of \\(n\\). For example, the first two moments are \\[\n\\begin{align*}\n\\langle x \\rangle &= \\frac{(N+1)}{2}, \\\\\n\\langle x^2 \\rangle &= \\frac{(N+1)(2N+1)}{6}. \\\\\n\\end{align*}\n\\] Using these we can directly calculate the mean and variance, which are \\[\n\\begin{align*}\n\\mu &= \\langle x \\rangle = \\frac{(N+1)}{2}, \\\\\n\\sigma^2 &= \\langle x^2 \\rangle - \\langle x \\rangle^2 = \\frac{N^2-1}{12}. \\\\\n\\end{align*}\n\\] The characteristic function is just given by a geometric series in powers of \\(e^{-ik}\\), \\[\n\\tilde p(k) = \\sum_{x=1}^N p(x) e^{-ikx} = \\sum_{x=1}^N \\frac{1}{N} \\big(e^{-ik}\\big)^n = \\frac{e^{-ik}-e^{-ik(N+1)}}{1-e^{-ik}}.\n\\] We could in principle calculate the cumulant function \\(\\log \\tilde p(k)\\) as well, though it’s clearly not going to be as useful for finding the cumulants here. We’ll see later that the uniform distribution is the maximum entropy distribution when the only known constraints are that \\(x\\) lies in some set \\(S\\).\n\n\nGaussian Distribution\nThe Gaussian distribution is one of the most fundamental distributions in physics. In statistical mechanics, for example, it describes the velocity of gases in a box. Suppose \\(x\\) is a continuous random variable defined on the whole real line. We say it’s Gaussian distributed if its PDF is given by \\[\n\\boxed{p(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\bigg(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\bigg)} \\ .\n\\] The Gaussian distribution has two parameters, a real number \\(\\mu\\) and a positive number \\(\\sigma^2\\). As a shorthand we’ll sometimes say \\(x\\) is Gaussian distributed by writing \\(x \\sim \\mathcal{N}(\\mu, \\sigma^2)\\). The PDF’s curve is the distinctive bell-shaped curve that falls off exponentially fast symmetrically around \\(\\mu\\). For practical purposes, almost all of the probability mass lies in the range \\(-3\\sigma \\leq x \\leq 3\\sigma\\).\nWe can calculate the characteristic function by taking the Fourier transform of \\(p(x)\\). By using a couple of changes of variables and completing the square inside the exponent, we have, \\[\n\\begin{align*}\n\\tilde p(k) &= \\int_\\mathbb{R} dx \\ p(x) e^{-ikx} \\\\\n&= \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\int_\\mathbb{R} dx \\ e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}-ikx} \\\\\n&= \\frac{e^{-ik\\mu}}{\\sqrt{2\\pi\\sigma^2}} \\int_\\mathbb{R} dy \\ e^{-\\frac{y^2}{2\\sigma^2}-ikx} \\quad &y \\equiv& \\ x - \\mu \\\\\n&= e^{-ik\\mu-\\frac{1}{2}k^2 \\sigma^2} \\int_\\mathbb{R} \\frac{dz}{\\sqrt{2\\pi\\sigma^2}} \\ e^{-\\frac{z^2}{2\\sigma^2}} \\quad &z \\equiv& \\ y + ik\\sigma^2 \\\\\n&= e^{-ik\\mu-\\frac{1}{2}k^2 \\sigma^2}. \\\\\n\\end{align*}\n\\] Notice the characteristic function is also itself a Gaussian, just with an imaginary shift. Taking the log immediately gives the cumulant function, which is just the exponent terms, \\[\n\\log \\tilde p(k) = -ik\\mu-\\frac{1}{2}k^2 \\sigma^2.\n\\] Notice only the first two powers of \\(k\\) appear in the cumulant. This means \\(\\kappa_1 = \\mu\\), \\(\\kappa_2 = \\sigma^2\\), and all higher cumulants are zero. Evidently, the parameter \\(\\mu\\) is just the mean and the parameter \\(\\sigma^2\\) is just the variance.\nIf we like, we can use the graphical trick to read off the moments as well. In this case, there can’t be any bags with more than two points, which greatly simplifies terms. The first few moments are, \\[\n\\begin{align*}\n\\langle x \\rangle &= \\kappa_1 = \\mu, \\\\\n\\langle x^2 \\rangle &= \\kappa_2 + \\kappa_1^2 = \\sigma^2 + \\mu^2, \\\\\n\\langle x^3 \\rangle &= 3 \\kappa_2 \\kappa_1 + \\kappa_1^3 = 3\\sigma^2 \\mu + \\mu^3, \\\\\n\\langle x^4 \\rangle &= 3 \\kappa_2^2 + 6 \\kappa_2 \\kappa_1^2 + \\kappa_1^4 = 3\\sigma^4 + 6 \\sigma^2 \\mu^2 + \\mu^4.\n\\end{align*}\n\\] ### Binomial Distribution\nSuppose we have a binary random variable \\(x = 0, 1\\) that takes on the value one with a fixed probability \\(p\\). We can express its PMF simply as \\[\np(x) = p^x (1-p)^{1-x}.\n\\] We’d call such an \\(x\\) a Bernoulli random variable. A common example would be flipping a coin, where heads occurs with a fixed probability \\(p=0.5\\). Now suppose we allow the binary outcome to repeat \\(n\\) times independently. It turns out that the sum of those \\(n\\) outcomes is distributed in a similar way, except now \\(x\\) can take on any value in the range \\(x = 0, 1, \\cdots, n\\). Accounting for normalization, we have \\[\n\\boxed{p(x) = \\binom{n}{x} p^x (1-p)^{n-x}} \\ .\n\\] We’d say \\(x\\) is binomially distributed with parameters \\(p\\) and \\(n\\), sometimes written as \\(x \\sim \\text{Bin}(n,p)\\). The normalization constant is the binomial coefficient, \\[\n\\binom{n}{x} \\equiv \\frac{n!}{x!(n-x)!}.\n\\] The binomial coefficient represents the number of ways to choose \\(x\\) points from a total of \\(n\\) points, assuming the order the points are chosen is irrelevant.\nThe characteristic function of the binomial distribution can be found using the binomial theorem, \\[\n\\begin{align*}\n\\tilde p(k) &= \\sum_{x=0}^n \\binom{n}{x} p^x (1-p)^{n-x} e^{-ikx} \\\\\n&= \\sum_{x=0}^n \\binom{n}{x} \\big(p e^{-ik}\\big)^x (1-p)^{n-x} \\\\\n&= \\big(pe^{-ik} + (1-p) \\big)^n.\n\\end{align*}\n\\] Notice the parameter \\(n\\) appears only in the exponent. This means the cumulant function is just \\(n\\) times the cumulant function for the Bernoulli distribution, \\[\n\\log \\tilde p_n(k) = n \\log \\tilde p_1(k).\n\\] In particular, the cumulants are all proportional to \\(n\\) times the Bernoulli cumulants. Expanding out \\(\\log \\tilde p_1(k)\\), we have \\[\n\\begin{align*}\n\\log \\tilde p_1(k) &= \\log\\big(pe^{-ik} + (1-p)\\big) \\\\\n&= \\log\\big(1 + p(e^{-ik}-1)\\big) \\\\\n&= p(e^{-ik}-1) - \\frac{1}{2} p^2(e^{-ik}-1)^2 + \\cdots \\\\\n&= p\\bigg(-ik + \\frac{(-ik)^2}{2} + \\cdots\\bigg) - \\frac{1}{2} p^2 \\bigg(-ik + \\frac{(-ik)^2}{2} + \\cdots\\bigg)^2 + \\cdots \\\\\n&= -ik p + \\frac{(-ik)^2}{2} p(1-p) + \\cdots\n\\end{align*}\n\\] Thus, the mean and variance of the binomial distribution are just \\[\n\\mu = np, \\quad \\sigma^2 = np(1-p).\n\\] These distributions can be straight-forwardly generalized to situations with more than binomial outcomes. The Bernoulli distribution generalizes to the categorical distribution, where \\(x\\) is allowed to be one of \\(k\\) categories, each with a fixed probability \\(p_j\\). Clearly those probabilities must sum to one. If the categories are \\(x = 1, 2, \\cdots, k\\) the PMF would be given by \\[\np(x) = p_1^{\\delta_{1x}} p_2^{\\delta_{2x}} \\cdots p_k^{\\delta_{kx}}, \\quad x = 1, 2, \\cdots, k.\n\\] The binomial distribution generalizes to the multinomial distribution, where \\(x\\) is now a vector whose jth component is the number of times category \\(j\\) occurred in \\(n\\) total trials. Each \\(x_j = 0, 1, \\cdots, n_j\\) is essentially its own binomial distribution, except we require \\(n = n_1 + n_2 + \\cdots n_k\\). The PMF is given by \\[\np(x) = \\frac{n!}{n_1!n_2!\\cdots n_k!} p_1^{n_1} p_2^{n_2} \\cdots p_2^{n_2}.\n\\] The coefficient \\(\\frac{n!}{n_1!n_2!\\cdots n_k!}\\) is called a multinomial coefficient. It’s a count of the number of ways to distribute \\(n\\) points into \\(k\\) bins such that each bin \\(j\\) contains exactly \\(n_j\\) points. We might say \\(x\\) is multinomially distributed by writing \\(x \\sim \\text{Multinomial}(n_1,n_2,\\cdots,n_k; p_1, p_2, \\cdots, p_k)\\).\n\n\nPoisson Distribution\nSuppose we’re interested in answering the following question: What is the probability that \\(x\\) events occur inside a time interval \\([0,T]\\) provided each event is independent of the others, and that the probability of any one event occurring in an infinitesimal interval \\([0,dt]\\) is a constant \\(\\alpha dt\\). To figure out what \\(p(x)\\) is, let’s imagine subdividing \\([0,T]\\) up into \\(N = \\frac{T}{dt}\\) subintervals. In each subinterval, any single event is a Bernoulli random variable that either occurs with probability \\(\\alpha dt\\) or doesn’t occur with probability \\((1-\\alpha)dt\\). If we assume each subinterval is independent of the others, the characteristic function of \\(p(x)\\) is just \\[\n\\begin{align*}\n\\tilde p(k) &= (\\tilde p_1(k))^N \\\\\n&= \\big(\\alpha e^{-ik}dt + (1-\\alpha)dt\\big)^N \\\\\n&= \\big(1 + \\alpha dt(e^{-ik}-1)\\big)^{T/dt} \\\\\n&\\approx e^{\\alpha T(e^{-ik} - 1)}. \\\\\n\\end{align*}\n\\] The last equality becomes exact when \\(dt\\) is infinitesimal. Let’s define \\(\\lambda \\equiv \\alpha T\\) as a dimensionless rate parameter. Then we can write the characteristic function as \\[\n\\tilde p(k) = e^{\\lambda(e^{-ik} - 1)}.\n\\] To get the sought after PDF \\(p(x)\\) we just need to take the inverse Fourier transform of \\(\\tilde p(k)\\). We have \\[\n\\begin{align*}\np(x) &= \\int_{\\mathbb{R}} \\frac{dk}{2\\pi} \\ \\tilde p(k) e^{ikx} \\\\\n&= \\int_{\\mathbb{R}} \\frac{dk}{2\\pi} \\ e^{\\lambda (e^{-ik}-1)}e^{ikx} \\\\\n&= e^{-\\lambda} \\int_{\\mathbb{R}} \\frac{dk}{2\\pi} \\  e^{ikx} \\sum_{n=0}^\\infty \\frac{(\\lambda e^{-ik})^n}{n!} \\\\\n&= e^{-\\lambda} \\sum_{n=0}^\\infty \\frac{\\lambda^n}{n!} \\int_{\\mathbb{R}} \\frac{dk}{2\\pi} e^{-ik(x-n)} \\\\\n&= e^{-\\lambda} \\sum_{n=0}^\\infty \\frac{\\lambda^n}{n!} \\delta(x-n). \\\\\n\\end{align*}\n\\] The delta function forces \\(x\\) to be a positive integer for \\(p(x)\\) to be non-zero. That is, \\(p(x)\\) is actually a PMF \\[\n\\boxed{p(x) = e^{-\\lambda} \\frac{\\lambda^x}{x!}} \\ .\n\\] This is called the Poisson distribution. The Poisson distribution is used to model counts of events, where each event is allowed to occur independently with some fixed rate \\(\\lambda = \\alpha T\\). We can denote that \\(x\\) is Poisson distributed by writing \\(x \\sim \\text{Poisson}(\\lambda)\\).\nThis distribution has the unusual property that all its cumulants are equal. Indeed, observe we have \\[\n\\log \\tilde p(k) = \\lambda (e^{-ik} - 1) = \\sum_{n=1}^\\infty \\frac{(-ik)^n}{n!} \\lambda.\n\\] That is, all the cumulants are just \\(\\lambda\\). In particular, \\(\\mu = \\sigma^2 = \\lambda\\).",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/probability.html#multivariate-probability",
    "href": "statistical-mechanics/probability.html#multivariate-probability",
    "title": "Probability",
    "section": "Multivariate Probability",
    "text": "Multivariate Probability\n\nRandom Vectors\nLet’s now look at the situation where we have \\(N\\) random variables \\(X_1, X_2, \\cdots, X_N\\). The vector of all such random variables is called a random vector, i.e. a vector \\(\\mathbf{X} = (X_1, X_2, \\cdots, X_N)\\). To each random vector we can assign a joint CDF of the form \\[\nP(\\mathbf{x}) \\equiv \\mathbb{Pr}(\\{\\mathbf{X} \\leq \\mathbf{x}\\}) = \\mathbb{Pr}(\\{X_1 \\leq x_1, X_2 \\leq x_2, \\cdots, X_N \\leq x_N\\}).\n\\] The CDF must be an increasing function in each \\(x_i\\), go to \\(0\\) as all \\(x_i \\rightarrow -\\infty\\), and go to \\(1\\) as all the \\(x_i \\rightarrow \\infty\\).\nIf \\(\\mathbf{X}\\) is discrete, we can assign a joint PMF to each value in the support \\(S \\in \\mathbb{R}^N\\) by defining \\[\n\\boxed{p(\\mathbf{x}) \\equiv \\mathbb{Pr}(\\{\\mathbf{X} = \\mathbf{x}\\})} \\ .\n\\] The joint PMF is a valid probability, meaning it must satisfy \\(0 \\leq p(\\mathbf{n}) \\leq 1\\) and \\(\\sum_{\\mathbf{n} \\in S} p(\\mathbf{n}) = 1\\).\nSimilarly, if \\(\\mathbf{X}\\) is continuous, we can assign a joint PDF to each value in \\(S \\in \\mathbb{R}^N\\) by defining \\[\np(\\mathbf{x}) d^Nx \\equiv \\mathbb{Pr}(\\{x_1 \\leq X_1 \\leq x_1 + dx_1, x_2 \\leq X_2 \\leq x_2 + dx_2, \\cdots, x_N \\leq X_N \\leq x_N + dx_N\\}),\n\\] where \\(d^N x = dx_1dx_2\\cdots dx_N\\) is the \\(N\\)-dimensional volume element. The joint PMF must satisfy both \\(p(\\mathbf{x}) \\geq 0\\), and \\(\\int_S d^N x \\ p(\\mathbf{x}) = 1\\). Clearly the joint PMF is just a special case of the joint PDF, since we can always just use delta functions to express a PMF as a PDF.\nAs with ordinary random variables, we’ll frequently abuse notation by using \\(\\mathbf{x}\\) for both the random vector itself as well as its value where there’s no risk of confusion.\n\n\nJoint Moments and Cumulants\nFor any function \\(F(\\mathbf{x})\\) of a random vector \\(\\mathbf{x}\\) we can define its expectation value as \\[\n\\boxed{\\langle \\mathbf{x} \\rangle \\equiv \\int_S d^N x \\ F(\\mathbf{x}) p(\\mathbf{x})} \\ .\n\\] For both discrete and continuous random vectors we can define the joint characteristic function \\[\n\\boxed{\\tilde p(\\mathbf{k}) \\equiv \\langle e^{-i\\mathbf{k} \\cdot \\mathbf{x}} \\rangle \\equiv \\int_{\\mathbb{R}^N} d^Nx \\ p(\\mathbf{x}) e^{-i\\mathbf{k} \\cdot \\mathbf{x}}} \\ .\n\\] By taking the logarithm of the joint CF, we can also define the joint cumulant function \\(\\log \\tilde p(\\mathbf{k})\\). From these two functions we can extract the joint moments and cumulants. The \\(n_1, n_2, \\cdots, n_N\\) joint moment \\(\\mu_{n_1,n_2,\\cdots,n_N} \\equiv \\langle x_1^{n_1} x_2^{n_2} \\cdots x_N^{n_N} \\rangle\\) of \\(\\mathbf{X}\\) is given by taking partial derivatives of the joint characteristic function, \\[\n\\langle x_1^{n_1} x_2^{n_2} \\cdots x_N^{n_N} \\rangle \\equiv \\frac{\\partial^{n_1}}{\\partial (-i k_1)^{n_1}} \\frac{\\partial^{n_2}}{\\partial (-i k_2)^{n_2}} \\cdots \\frac{\\partial^{n_N}}{\\partial (-i k_N)^{n_N}} \\tilde p(k_1, k_2, \\cdots, k_N) \\bigg |_{k_1=k_2=\\cdots=k_N=0}.\n\\] Similarly, the \\(n_1, n_2, \\cdots, n_N\\) joint cumulant \\(\\kappa_{n_1,n_2,\\cdots,n_N}\\) is given by taking partial derivatives of the joint cumulant function, \\[\n\\kappa_{n_1,n_2,\\cdots,n_N} \\equiv \\frac{\\partial^{n_1}}{\\partial (-i k_1)^{n_1}} \\frac{\\partial^{n_2}}{\\partial (-i k_2)^{n_2}} \\cdots \\frac{\\partial^{n_N}}{\\partial (-i k_N)^{n_N}} \\log \\tilde p(k_1, k_2, \\cdots, k_N) \\bigg |_{k_1=k_2=\\cdots=k_N=0}.\n\\] The sum \\(n \\equiv n_1 + n_2 + \\cdots n_N\\) determines the order of the moment or cumulant. Of particular interest are the first and second cumulants. The first cumulants are the means \\(\\mu_i \\equiv \\langle x_i \\rangle\\). We can think of these together by putting them all into a mean vector \\(\\boldsymbol{\\mu} \\equiv \\langle \\mathbf{x} \\rangle \\equiv \\big(\\mu_1, \\mu_2, \\cdots, \\mu_N\\big)\\). The second cumulants are the covariances, \\(\\sigma_{ij} \\equiv \\kappa_{ij}\\). We can put all these into an \\(N \\times N\\) matrix to get the covariance matrix \\(\\mathbf{\\Sigma} \\equiv \\big(\\sigma_{ij}\\big)_{i,j=1,\\cdots,N}\\). The diagonal entries of the covariance matrix correspond to the usual variances \\(\\sigma_i^2 = \\sigma_{ii}\\). The off diagonal terms are the covariances, capturing the dependence or correlation between \\(x_i\\) and \\(x_j\\).\nWe can use the same graphical trick to express joint cumulants in terms of joint moments. The only difference is we need to label each point by its index and bag them appropriately. We can use this to show that the covariance \\(\\sigma_{ij} \\equiv \\kappa_{ij}\\) can be written as \\[\n\\sigma_{ij} = \\langle x_i x_j \\rangle - \\langle x_i \\rangle \\langle x_j \\rangle = \\langle (x_i - \\mu_i)(x_j - \\mu_j) \\rangle.\n\\] In matrix notation, the entire covariance matrix can be expressed using moments as \\[\n\\boxed{\\mathbf{\\Sigma} = \\langle \\mathbf{x}\\mathbf{x}^\\top \\rangle - \\langle \\mathbf{x} \\rangle \\langle \\mathbf{x} \\rangle^\\top = \\langle (\\mathbf{x}-\\boldsymbol{\\mu})(\\mathbf{x}-\\boldsymbol{\\mu})^\\top \\rangle} \\ .\n\\] This implies the covariance matrix must in fact be a positive semi-definite matrix. That is, \\[\n\\mathbf{\\Sigma} = \\mathbf{\\Sigma}^\\top, \\quad \\mathbf{v}^\\top\\mathbf{\\Sigma}\\mathbf{v} \\geq 0 \\quad \\forall \\mathbf{v} \\neq \\mathbf{0}.\n\\]\n\n\nConditional and Marginal Probability\nWe can get smaller joint probabilities by “summing out” the random variables we don’t need. These are called marginal probabilities or unconditional probabilities. For example, if we have two random variables \\(x\\) and \\(y\\), the marginal PDF \\(p(y)\\) is given by integrating \\(x\\) out of the joint PDF \\(p(x,y)\\), \\[\n\\boxed{p(y) \\equiv \\int_\\mathbb{R} dx \\ p(x,y)} \\ .\n\\] If we have \\(N\\) random variables \\(x_1,x_2,\\cdots, x_s, x_{s+1},\\cdots,x_N\\) and integrate out the last \\(N-s\\) variables \\(x_s, x_{s+1},\\cdots,x_N\\), then we get the marginal PDF \\(p(x_1,x_2,\\cdots, x_s)\\), \\[\np(x_1,x_2,\\cdots, x_s) \\equiv \\int_{\\mathbb{R}^{N-s}} dx_s, dx_{s+1},dx_N \\ p(x_1,x_2,\\cdots, x_s, x_s, x_{s+1},\\cdots,x_N).\n\\] Similarly, we can define the conditional probabilities, which allow for random variables to depend on the outcome of other random variables directly. For example, for two random variables \\(x\\) and \\(y\\) with joint PDF \\(p(x,y)\\), we can define the conditional probability of \\(y\\) given \\(x\\) as \\[\n\\boxed{p(y|x) \\equiv \\frac{p(x,y)}{p(x)}} \\ .\n\\] We can think of \\(p(x,y)\\) as a kind of prior distribution and \\(p(x)\\) as a kind of normalization constant. Notice we can similarly write \\(p(x,y) = p(x|y) p(y)\\). If we plug this into the formula for \\(p(y|x)\\) we get the well-known Bayes’ Rule, which says that \\[\np(y|x) = \\frac{p(x|y)p(y)}{p(x)}.\n\\] If we have \\(N\\) random variables \\(x_1,x_2,\\cdots, x_s, x_{s+1},\\cdots,x_N\\) and want to condition the first \\(s\\) variables on the last \\(N-s\\) variables, we’d similarly write \\[\np(x_1,x_2,\\cdots, x_s) \\equiv \\frac{p(x_1,x_2,\\cdots, x_s, x_{s+1},\\cdots,x_N)}{p(x_{s+1},\\cdots,x_N)}.\n\\] We haven’t proven it, but it’s not hard to show that the marginal and conditional probabilities are indeed valid probabilities and PDFs.\nWhen conditioning a random variable \\(y\\) on another random variable \\(x\\) gives no information about \\(y\\), we say that \\(x\\) and \\(y\\) are independent, sometimes written \\(x \\perp y\\). If \\(x\\) gives no information about \\(y\\), that means we must have \\(p(y|x) = p(y)\\), which is equivalent to saying the joint PDF factors, \\(p(x,y) = p(x) p(y)\\). Clearly, if \\(x\\) gives no information about \\(y\\), then \\(y\\) gives no information about \\(x\\) either. Independence is symmetric.\nMore generally, we say \\(N\\) random variables \\(x_1,x_2,\\cdots,x_N\\) are mutually independent provided \\[\n\\boxed{p(x_1,x_2,\\cdots,x_N) = p_1(x_1) p_2(x_2) \\cdots p_N(x_N)} \\ .\n\\] In the special case where all \\(N\\) variables also happen to come from the same distribution \\(p(x)\\) we say they’re independent identically distributed or IID. In this simple case we just have \\[\np(x_1,x_2,\\cdots,x_N) = \\big(p(x)\\big)^N.\n\\] Independent random variables have the property that their mixed cumulants will always be zero. This is equivalent to saying that the joint expectation of any product of random variables value factors, \\[\n\\langle F_1(x_1) F_2(x_2) \\cdots F_N(x_N) \\rangle = \\langle F_1(x_1) \\rangle \\langle F_2(x_2) \\rangle \\cdots \\langle F_N(x_N) \\rangle.\n\\]\n\n\nThe Multivariate Gaussian Distribution\nWhile there are many joint probability distributions, the most important one to be aware of is the multivariate Gaussian distribution. Suppose \\(\\mathbf{x} = (x_1, x_2, \\cdots, x_N)\\) are independent, with each \\(x_i\\) Gaussian distributed with mean \\(\\mu_i\\) and variance \\(\\sigma_i^2\\). Then it’s easy to show their joint PDF is given by \\[\np(x_1, x_2, \\cdots, x_N) = \\bigg(\\frac{1}{(2\\pi)^N\\sigma_1^2\\sigma_2^2\\cdots\\sigma_N^2}\\bigg)^{1/2} \\exp\\bigg(-\\frac{1}{2} \\sum_{i=1}^N \\frac{(x_i-\\mu_i)^2}{\\sigma_i^2} \\bigg).\n\\] But what if \\(\\mathbf{x}\\) is not independent? All we have to do in that case is make a change of basis. Notice that joint PDF above is just the diagonalized form for the following joint PDF in vector form, \\[\n\\boxed{p(\\mathbf{x}) = \\bigg(\\frac{1}{(2\\pi)^N \\det(\\mathbf{\\Sigma})}\\bigg)^{1/2} \\exp\\bigg(-\\frac{1}{2} (\\mathbf{x} - \\boldsymbol{\\mu})^\\top \\mathbf{\\Sigma}^{-1}(\\mathbf{x} - \\boldsymbol{\\mu}) \\bigg)} \\ .\n\\] By making a change of basis or rotating \\(\\mathbf{\\Sigma}\\), this vectorized PDF gives the most general form of the Gaussian distribution for \\(N\\) variables. This is the multivariate Gaussian distribution, denoted \\(\\mathbf{x} \\sim \\mathcal{N}(\\boldsymbol{\\mu},\\mathbf{\\Sigma})\\).\nUsing the same diagonalization trick, it’s just as easy to show that the joint characteristic function is \\[\n\\boxed{\\tilde p(\\mathbf{k}) = \\exp(-i\\mathbf{k} \\cdot \\boldsymbol{\\mu} - \\frac{1}{2} \\mathbf{k}^\\top \\mathbf{\\Sigma} \\mathbf{k})} \\ ,\n\\] and the joint cumulant is just \\(\\log \\tilde p(\\mathbf{k}) = -i\\mathbf{k} \\cdot \\boldsymbol{\\mu} - \\frac{1}{2} \\mathbf{k}^\\top \\mathbf{\\Sigma} \\mathbf{k}\\). This again implies that only the first and second joint cumulants are non-zero for the multivariate Gaussian. All higher-order terms vanish. For this reason, multivariate Gaussian random variables satisfy a special condition known as Wick’s Theorem.\nWick’s Theorem: Suppose \\(\\mathbf{x} = (x_1, x_2, \\cdots, x_N)\\) is a Gaussian random vector with mean \\(\\boldsymbol{\\mu} = \\mathbf{0}\\). Then the \\(n\\)th joint moments are given by \\[\n\\boxed{\n\\langle x_1^{n_1} x_2^{n_2} \\cdots x_N^{n_N} \\rangle =\n\\begin{cases}\n0 & n = \\text{odd} \\\\\n\\text{sum of all pairwise contractions} & n = \\text{even} \\\\\n\\end{cases}\n} \\ .\n\\] For example, suppose we wanted to calculate \\(\\langle x_1^2 x_2 x_3 \\rangle\\). In this case, the possible pairwise contractions are\n\n\\(x_1 x_1\\) and \\(x_2 x_3\\) , which gives a term \\(\\sigma_{11} \\sigma_{23}\\),\n\\(x_1 x_2\\) and \\(x_1 x_3\\) , which gives a term \\(\\sigma_{12} \\sigma_{13}\\),\n\\(x_1 x_3\\) and \\(x_1 x_2\\) , which gives a term \\(\\sigma_{13} \\sigma_{12}\\).\n\nSumming each of these pairwise contractions together, we just have \\[\n\\langle x_1^2 x_2 x_3 \\rangle = \\sigma_{11} \\sigma_{23} + 2 \\sigma_{12} \\sigma_{13}.\n\\]",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/probability.html#asymptotic-analysis",
    "href": "statistical-mechanics/probability.html#asymptotic-analysis",
    "title": "Probability",
    "section": "Asymptotic Analysis",
    "text": "Asymptotic Analysis\nIn this section we’ll focus on important results that apply for large numbers of random variables \\(N \\gg 1\\).\n\nThe Central Limit Theorem\nIt turns out that the sum of random variables will often by approximately Gaussian distributed provided some minor regularity assumptions are met. This important result is called the central limit theorem.\nCentral Limit Theorem: Suppose \\(x = \\sum_{i=1}^N x_i\\) is a sum of \\(N\\) IID random variables with finite mean \\(\\mu\\) and variance \\(\\sigma^2\\). Then when \\(N \\gg 1\\) the probability density satisfies \\[\n\\boxed{p\\bigg(\\frac{x-N\\mu}{\\sqrt{N\\sigma^2}}\\bigg) \\approx \\frac{1}{\\sqrt{2 \\pi}} \\exp\\bigg(-\\frac{1}{2}\\bigg(\\frac{x-N\\mu}{\\sqrt{N\\sigma^2}}\\bigg)^2\\bigg)} \\ .\n\\] Proof: Suppose each \\(x_i\\) is IID with distribution \\(p_1(x_1)\\). The characteristic function for \\(p(x)\\) must then be \\[\n\\tilde p(k) = \\langle e^{-i kx} \\rangle = \\langle e^{-i k\\sum_{i=1}^N x_i} \\rangle = \\prod_{i=1}^N \\langle e^{-i k x_i} \\rangle = \\tilde p(k_1, k_2, \\cdots, k_N) \\bigg |_{k_1=k_2=\\cdots=k_N=k}.\n\\] If we take the cumulant function \\(\\log \\tilde p(k)\\) and expand it out directly, we have \\[\n\\log \\tilde p(k) = \\sum_{n=1}^\\infty \\frac{(-ik)^n}{n!} \\kappa_n(x) = -ik \\kappa_1(x) + \\frac{(-ik)^2}{2} \\kappa_2(x) + \\cdots\n\\] Expanding out the cumulant function \\(\\log \\tilde p(k_1, k_2, \\cdots, k_N)\\) and setting all \\(k_i=k\\), we have \\[\n\\begin{align*}\n\\log \\tilde p(k_1, k_2, \\cdots, k_N) &= \\sum_{n=0}^\\infty \\sum_{\\sum n_j=n} \\frac{(-ik_1)^{n_1} (-ik_2)^{n_2} \\cdots (-ik_N)^{n_N}}{n!} \\kappa_{n_1 n_2 \\cdots n_N} \\bigg |_{k_1=k_2=\\cdots=k_N=k} \\\\\n&= \\sum_{n=0}^\\infty \\sum_{\\sum n_j=n} \\frac{(-ik)^n}{n!} \\kappa_{n_1 n_2 \\cdots n_N} \\\\\n&= (-ik) \\sum_{\\sum n_j=1} \\kappa_{n_1 n_2 \\cdots n_N} + \\frac{(-ik)^2}{2} \\sum_{\\sum n_j=2} \\kappa_{n_1 n_2 \\cdots n_N} + \\cdots\n\\end{align*}\n\\] Equating the two equations, we thus have \\[\n\\kappa_n(x) = \\sum_{\\sum n_j=n} \\kappa_{n_1 n_2 \\cdots n_N}.\n\\] That is, the \\(n\\)th cumulant of the sum is the sum of all the joint \\(n\\)th cumulants. Now, suppose all the \\(x_i\\) are independent. Then their joint PDF must factor as \\[\np(x_1,x_2,\\cdots,x_N) = p_1(x_1) p_2(x_2) \\cdots p_N(x_N).\n\\] Moreover, since their mixed cumulants must be zero, the cumulants of the sum further reduce to \\[\n\\kappa_n(x) = \\sum_{i=1}^N \\kappa_n(x_i),\n\\] Now suppose all the \\(x_i\\) are identically distributed with the same PDF \\(p_1(x_i)\\). Then we further have just \\[\n\\kappa_n = N \\kappa_{n,i}.\n\\] Define another random variable \\(y\\) by re-centering and rescaling \\(x\\) as \\[\nz \\equiv \\frac{x - N\\mu}{\\sqrt{N\\sigma^2}}.\n\\] Then the cumulants of \\(z\\) are given by \\[\n\\begin{align*}\n\\kappa_1(z) &= 0, \\\\\n\\kappa_2(z) &= 1, \\\\\n\\kappa_n(z) &= \\frac{N\\kappa_n(x_1)}{(N\\sigma^2)^{n/2}} = O\\big(N^{1-n/2}\\big). \\\\\n\\end{align*}\n\\] The higher order cumulants of \\(z\\) evidently go to zero when \\(N \\gg 1\\). But we already know the only distribution whose higher moments are zero is the Gaussian distribution. Thus, we’ve shown \\[\np(z) \\approx \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{z^2}{2}}. \\qquad \\text{Q.E.D.}\n\\] Note the central limit theorem is also true for non-IID random variables, provided the higher cumulants decay as \\(\\kappa_n(x) = O(N^{n/2})\\).\nIn the proof of the CLT we implicitly assumed that the cumulants were all finite. What if that weren’t the case? This will happen if the PDF of each \\(x_i\\) is heavy-tailed. Heavy-tailed distributions are commonly used to model rare events. It turns out then that the sum won’t in general converge to a Gaussian. In fact, if it does converge, it’ll converge to a Levy distribution, a general class of heavy-tailed distributions.\n\n\nThe Saddlepoint Approximation\nIn the section on thermodynamics, we saw both intensive variables and extensive variables. The intensive variables are ones that don’t depend on particle number at all, i.e. they’re \\(O(1)\\) functions of \\(N\\). The extensive variables are linear in particle number, i.e. they’re \\(O(N)\\). In principle we could imagine other functional dependences on \\(N\\) as well. For example, a variable could be polynomial in \\(N\\), i.e. \\(O(N^p)\\) for some \\(p\\). More importantly, a variable can be exponential in \\(N\\), i.e. \\(O(e^{N\\phi})\\) for some \\(\\phi\\). For example, the volume of a gas would be a variable that can scale exponentially with \\(N\\), since it often goes like \\(V^N\\).\nWhen \\(N \\gg 1\\), the sum of many exponential variables can be well approximated by the maximum term. Suppose we have \\(n\\) non-negative variables \\(x_1,x_2,\\cdots,x_n\\) of the form \\(x_i \\sim e^{N\\phi_i}\\) as \\(N \\rightarrow \\infty\\). Then their sum \\(S = \\sum x_i\\) satisfies \\[\nS \\sim x_{max} = \\max_{i=1,\\cdots,n} x_i, \\quad \\text{when} \\quad N \\rightarrow \\infty.\n\\] When each \\(x_i = A_i e^{N\\phi_i}\\), this just says \\(S \\approx A_{max} e^{N\\phi_{max}}\\) when \\(N \\gg 1\\). To see why this fact is true, note that since each \\(x_i \\geq 0\\), we must have \\(x_{max} \\leq S \\leq nx_{max}\\). Since the logarithm is monotonic, if we take the log of each term and divide by \\(N\\), we have \\[\n\\frac{\\log x_{max}}{N} \\leq \\frac{\\log S}{N} \\leq \\frac{\\log x_{max}}{N} + \\frac{\\log n}{N}.\n\\] If we take \\(N \\rightarrow \\infty\\) while holding \\(n\\) fixed, then the term \\(\\frac{\\log n}{N} \\rightarrow 0\\), which gives \\[\n\\frac{\\log S}{N} \\sim \\frac{\\log x_{max}}{N} = \\phi_i.\n\\]\nMore useful for our purposes will be the continuous analog of this result, the saddlepoint approximation.\nSaddlepoint Approximation: Suppose we have a function of the form \\(f(x) = e^{N\\phi(x)}\\) where \\(\\phi(x)\\) grows polynomially. Then we have \\[\n\\boxed{S = \\int_\\mathbb{R} dx \\ e^{N\\phi(x)} \\sim \\sqrt{\\frac{2\\pi}{N|\\phi''(x_{max})|}} e^{N\\phi_{max}}} \\ , \\quad \\text{as} \\ \\ N \\rightarrow \\infty.\n\\] Proof: To see why this is true let’s first Taylor expand \\(\\phi(x)\\) around its global maximum \\(x_{max}\\). Since \\(\\phi'(x_{max}) = 0\\) and \\(\\phi''(x_{max}) \\leq 0\\), we have \\[\n\\phi(x) = \\phi(x_{max}) - \\frac{1}{2} |\\phi''(x_{max})| (x-x_{max})^2 + O\\big((x-x_{max})^3\\big).\n\\] Plugging this into the integral and simplifying then gives \\[\n\\begin{align*}\nS &= \\int_\\mathbb{R} dx \\ \\exp\\bigg(N\\phi_{max} - \\frac{N}{2} |\\phi''(x_{max})| (x-x_{max})^2 + \\frac{N}{6} |\\phi'''(x_{max})| (x-x_{max})^3 + \\cdots\\bigg) \\\\\n&= \\int_\\mathbb{R} dx \\ \\exp\\bigg(N\\phi_{max} - \\frac{N}{2} |\\phi''(x_{max})| (x-x_{max})^2\\bigg) \\exp\\bigg(\\frac{N}{6} |\\phi'''(x_{max})| (x-x_{max})^3 + \\cdots\\bigg) \\\\\n&= e^{N\\phi_{max}} \\int_\\mathbb{R} dx \\ \\exp\\bigg(- \\frac{N}{2} |\\phi''(x_{max})| (x-x_{max})^2\\bigg) \\bigg(1 + \\frac{N}{6}|\\phi'''(x_{max})|(x-x_{max})^3 + \\cdots\\bigg) \\\\\n&= e^{N\\phi_{max}} \\sqrt{\\frac{2\\pi}{N|\\phi''(x_{max})|}} \\bigg(1 + O\\bigg(\\frac{1}{N}\\bigg)\\bigg).\n\\end{align*}\n\\] The last line follows from the fact that the integral with \\((x-x_{max})^3\\) vanishes since it’s an odd function, which means the next term \\((x-x_{max})^4\\) has to be considered, which integrates to order \\(O\\big(N^{-3/2}\\big)\\).\nNow, let’s again look at \\(\\frac{\\log S}{N}\\) as \\(N \\rightarrow \\infty\\). We have \\[\n\\frac{\\log S}{N} = \\phi_{max} - \\frac{1}{2N} \\log \\frac{N|\\phi''(x_{max})|}{2\\pi} + O\\bigg(\\frac{1}{N^2}\\bigg).\n\\] We can see that as \\(N \\rightarrow \\infty\\), \\(\\frac{\\log S}{N} \\rightarrow \\phi_{max}\\) with a correction of order \\(O\\big(\\frac{\\log N}{N}\\big)\\). \\(\\text{Q.E.D.}\\)\nIt’s interesting to observe that only the global maximum appears in this approximation. What if \\(\\phi(x)\\) had some other local maximum \\(\\phi(x_{max}')\\)? Strictly speaking we’d have to do the same approximation scheme about each of the maxima one-by-one. However, due to the presence of the exponential, if \\(\\phi(x_{max}') &lt; \\phi(x_{max})\\), then for large \\(N\\) we’d have \\[\ne^{N\\phi(x_{max}')} \\ll e^{N\\phi(x_{max})}.\n\\] In the limit where \\(N \\rightarrow \\infty\\), the correction term \\(e^{-N\\big(\\phi(x_{max})-\\phi(x_{max}')\\big)} \\rightarrow 0\\). In this sense, we can indeed neglect the other local maxima as long as they’re less than \\(\\phi(x_{max})\\) and \\(N \\gg 1\\).\n\n\n\n\n\nBy far the most useful corollary to this result for our purposes is the Stirling Approximation.\nStirling Approximation: As \\(N \\rightarrow \\infty\\), we have \\[\n\\boxed{N! \\sim N^N e^{-N} \\sqrt{2\\pi N}} \\ .\n\\] Proof: Observe by induction that we can write \\(N!\\) as the following integral, \\[\nN! = \\int_0^\\infty dx \\ x^N e^{-x} = \\int_0^\\infty dx \\ \\exp\\bigg(N\\bigg(\\log x - \\frac{x}{N}\\bigg)\\bigg).\n\\] Take \\(\\phi(x) = \\log x - \\frac{x}{N}\\). This function is maximized when \\(x_{max} = N\\), where \\(\\phi_{max} = \\log N - 1\\). At this point we have \\(\\phi''(x_{max}) = - \\frac{1}{N^2}\\). Plugging all this into the saddlepoint approximation, we have \\[\n\\begin{align*}\nN! &= e^{N(\\log N - 1)} \\sqrt{\\frac{2\\pi}{N|-N^{-2}|}} \\bigg(1 + O\\bigg(\\frac{1}{N}\\bigg)\\bigg) \\\\\n&= N^N e^{-N} \\sqrt{2\\pi N} \\bigg(1 + O\\bigg(\\frac{1}{N}\\bigg)\\bigg). \\quad \\text{Q.E.D.}\n\\end{align*}\n\\] Usually we’ll be more interested in \\(\\log N!\\) rather than \\(N!\\) itself. In that case we just have \\[\n\\log N! = N \\log N - N + \\frac{1}{2} \\log 2\\pi N + O\\bigg(\\frac{1}{N}\\bigg).\n\\] We’ll typically imagine \\(N\\) to be really big, like \\(N \\sim 10^{23}\\). In that case we can generally neglect the sublinear terms and write \\[\n\\boxed{\\log N! \\approx N\\log N - N} \\ .\n\\] This will usually be the form of Stirling’s approximation that we use in statistical mechanics. We’ll often write Stirling’s approximation in exponentiated form like this as well, where it’s understood what we really mean is the two sides equal only logarithmically as above, \\[\nN! \\sim N^N e^{-N}.\n\\]",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/probability.html#information-theory",
    "href": "statistical-mechanics/probability.html#information-theory",
    "title": "Probability",
    "section": "Information Theory",
    "text": "Information Theory\n\nInformation and Entropy\nWe can think about probabilities in a completely different sense by thinking about the information content contained in a system and how uncertain we are about what that information content is. Suppose we wanted to transmit a message containing \\(N\\) characters, where each character is sampled from some alphabet \\(\\Sigma\\) containing \\(M\\) total characters. We’d like to ask the following question: How many bits of information does a typical message of \\(N\\) characters from this alphabet contain?\nSuppose we had no information at all about how often any one particular character \\(x_m \\in \\Sigma\\) occurs in a message. In this case, we’d have to assume that all messages of length \\(N\\) are typical. Since there are \\(M^N\\) possible messages of length \\(N\\), we’d say there are \\(g = M^N\\) typical messages. Since \\(g\\) contains \\(\\log_2 g\\) bits of information, this means a typical message would contain \\(\\log g = N \\log_2 M\\) bits of information.\nSuppose now that we had an estimate of the frequency \\(p_m\\) that each character \\(x_m \\in \\Sigma\\) occurs in a message. That is, in a message of length \\(N\\), we expect each character \\(x_m\\) to occur \\(N_m \\approx Np_m\\) total times, or to be more precise \\(N_m = Np_m + O\\big(\\sqrt{N}\\big)\\) since each character is a Bernoulli random variable, hence a message of length \\(N\\) is a binomial random variable. In this case, the number of typical messages is just the number of ways of placing \\(N\\) random characters into \\(M\\) bins of sizes \\(N_1, N_2, \\cdots, N_M\\), which is \\[\ng = \\frac{N!}{\\prod_{m=1}^M N_m!}.\n\\] The total number of bits contained in a typical message would then be \\(\\log_2 g\\). If we assume the message length \\(N\\) is large compared to the alphabet size \\(M\\), then we can apply the Stirling approximation to each term containing a factorial. Using the fact \\(N_m = Np_m\\) and \\(\\sum N_m = N\\), we have \\[\n\\begin{align*}\n\\log_2 g &= \\log_2 N! - \\sum_{m=1}^M \\log_2 N_m! \\\\\n&\\approx \\big(N\\log_2 N - N\\big) - \\sum_{m=1}^M \\big(N_m \\log_2 N_m - N_m \\big) \\\\\n&\\approx N \\log_2 N - \\sum N_m \\log_2 N_m \\\\\n&\\approx - N \\sum_{m=1}^M p_m \\log_2 p_m.\n\\end{align*}\n\\] The term \\(-\\sum p_m \\log_2 p_m\\) is just a function of the underlying probability distribution of characters, not of the message length \\(N\\) itself. It captures our uncertainty or surprise in what message we’d receive. We call this term the information entropy or Shannon entropy. Since the choice of base for the logarithm merely adds a constant to this sum, in physics we more typically use the natural logarithm instead of the base-2 logarithm, which expresses entropy in nats instead of bits. In this form, the information entropy can be defined as \\[\n\\boxed{S \\equiv -\\sum_{m=1}^M p_m \\log p_m} \\ .\n\\] We’ve thus answered the question sought: a typical message of length \\(N\\) contains about \\(\\log_2 g \\approx NS\\) bits of information, up to an additive constant that depends on the base of logarithm. Notice that if we knew exactly which message to expect, that would mean \\(g = 1\\), which means \\(S = 0\\). Since we already know the most number of messages possible is \\(g=M^N\\), the information entropy must evidently satisfy \\[\n0 \\leq S \\leq N \\log M.\n\\] In thermodynamics, the information entropy corresponds to the mixing entropy up to a factor of Boltzmann’s constant \\(k_B\\). One implication of this is that while information entropy is dimensionless, thermodynamic entropy has units, namely units of \\(k_B\\), which is energy per degree.\nThe terms \\(I_m \\equiv -\\log p_m\\) capture the information content contained in any one particular character \\(x_m\\). If \\(p_m \\approx 0\\) then \\(I_m \\approx \\infty\\), meaning \\(x_m\\) contains an infinite number of bits of new information relative to what we already know. If \\(p_m \\approx 1\\) then \\(I_m \\approx 0\\), meaning \\(x_m\\) contains no new bits of information. We can thus also think of the entropy as the expected information content of a message, since \\[\nS = -\\sum_{m=1}^M p_m \\log p_m = -\\langle \\log p \\rangle = \\langle I \\rangle.\n\\] While information theory was built around the idea of transmitting messages, there’s nothing inherently limiting these ideas to messages alone. We can apply the concept of entropy as defined to any discrete probability distribution, where each \\(x_m\\) corresponds to some value taken on by a random variable.\nWhat about continuous distributions though? We can try to extend entropy to these as well, but we have to be careful. Since density functions needn’t be positive, the entropy will no longer in general be positive either, meaning it doesn’t make sense to think about it as a direct measure of information content. Nevertheless, we could define the information entropy of a continuous distribution as \\[\n\\boxed{S \\equiv -\\int_{\\mathbb{R}} dx \\ p(x) \\log p(x)} \\ .\n\\] From a physical perspective, a more troublesome problem with this definition is that in general \\(dx\\) will have units, which means \\(p(x)\\) will have units as well. But we can’t have a function with units inside a logarithm. The right way to deal with this will be to convert \\(dx\\) to some kind of dimensionless measure so that \\(p(x)\\) will also be dimensionless. For example, in statistical mechanics we’ll usually be looking at distributions over phase space, where the integration measure is \\(d\\Gamma \\propto d^3 x d^3 p\\). In this case, we’d need to divide by a constant that has units of \\([xp]\\). We’ll see from quantum mechanics that the correct constant is in fact Planck’s constant \\(h\\). That is, the right integration measure is \\[\nd\\Gamma = \\frac{d^3 x d^3 p}{h^3}.\n\\] ### The Principle of Maximum Entropy\nWe can use the idea of information entropy to finally answer the question regarding what the correct way is to define probabilities subjectively or theoretically. The idea is to use the principle of maximum entropy.\nPrinciple of Maximum Entropy: The unbiased assignment of probability is the one that maximizes the information entropy subject to known constraints. More formally, assign a probability distribution \\(p(x)\\) that maximizes the constrained problem \\[\n\\boxed{\n\\begin{align*}\n&\\max_{p(x)} S[p(x)] =  \\max_{p(x)} \\bigg(- \\sum_{x \\in \\mathcal{S}} p(x) \\log p(x) \\bigg) \\\\\n&\\text{subject to} \\ \\sum_{x \\in \\mathcal{S}} p(x) = 1 \\ \\text{and} \\ g(x) = 0 \\\\\n\\end{align*}\n} \\ .\n\\] where \\(g(x) = 0\\) is any set of known constraints on the probability distribution. The first constraint that probabilities sum to one will always be there so that \\(p(x)\\) yields a valid probability function.\nThis is in essence just a generalization of the principle of indifference. If we don’t have any information to go on, we should assume all outcomes have equal probability. The principle of maximum entropy extends this idea to general distributions where we might know some information, like what its mean or variance is, or what range it’s bounded to.\nUsing Lagrange multipliers, the principle of maximum entropy is equivalent to maximizing the Lagrange multiplier function \\[\nL(p(x),\\lambda) \\equiv - \\sum_{x \\in \\mathcal{S}} p(x) \\log p(x) - \\alpha \\bigg(\\sum_{x \\in \\mathcal{S}} p(x) - 1\\bigg) - \\beta \\cdot g(x).\n\\] subject to \\(p(x)\\) and \\(\\alpha\\) and \\(\\beta\\).\nExample: Let’s formally prove the principle of indifference using the principle of maximum entropy. That is, in the absence of no known information, the unbiased probabilities to assign are the ones where each outcome has an equal probability to occur. Suppose the random variable is discrete with \\(n\\) outcomes of probabilities \\(p_1, p_2, \\cdots, p_n\\). In this case, the problem to solve is \\[\n\\begin{align*}\n&\\max_{p} \\bigg(- \\sum_{i=1}^n p_i \\log p_i \\bigg) \\\\\n&\\text{subject to} \\ \\sum_{i=1}^n p_i = 1.\n\\end{align*}\n\\] This is equivalent to maximizing the Lagrange multiplier function \\[\nL(p,\\alpha) \\equiv - \\sum_{i=1}^n p_i \\log p_i - \\alpha \\bigg(\\sum_{i=1}^n p_i - 1\\bigg).\n\\] Differentiating with respect to each \\(p_j\\) and \\(\\alpha\\) and setting the derivatives to zero, we have \\[\n\\begin{align*}\n\\frac{\\partial L}{\\partial p_j} &= -\\log p_j - 1 - \\alpha \\equiv 0\\\\\n\\frac{\\partial L}{\\partial \\alpha} &= \\sum_{i=1}^n p_i - 1 \\equiv 0\\\\\n\\end{align*}\n\\] Solving this system of equations implies that \\[\n\\sum_{j=1}^n p_j = \\sum_{j=1}^n e^{-(1+\\alpha)} = 1 \\quad \\Longrightarrow \\quad e^{1+\\alpha} = n.\n\\] Thus, the maximum entropy probabilities are just \\(p_j = \\frac{1}{n}\\) for all \\(j\\), as expected.\nThe same method can be used in the continuous case as well by replacing the sums \\(\\sum_{i=1}^n p_i\\) by integrals \\(\\int_a^b dx \\ p(x)\\). The main subtlety to be aware of in the continuous case is that we’re no longer maximizing a function of \\(n\\) probabilities, but a functional of the form \\(S[p(x)]\\) over all possible functions \\(p(x)\\). These can be solved for \\(p(x)\\) by finding the choice of \\(p(x)\\) that extremizes the functional \\(S[p(x)]\\). In that case, the maximum entropy probabilities will turn out to be \\(p(x) = \\frac{1}{b-a}\\) as expected.\nExample: Here’s an interesting example involving continuous distributions. Suppose we knew that a random variable \\(x\\) on the real line had a given mean \\(\\mu\\) and variance \\(\\sigma^2\\). What is the maximum entropy distribution \\(p(x)\\) such that these two cumulants are known? The problem to solve is now \\[\n\\begin{align*}\n&\\max_{p(x)} \\bigg(- \\int_\\mathbb{R} dx \\ p(x) \\log p(x) \\bigg) \\\\\n&\\text{subject to} \\ \\int_\\mathbb{R} dx \\ p(x) = 1, \\\\\n&\\text{and} \\int_\\mathbb{R} dx \\ x p(x) = \\mu, \\ \\ \\int_\\mathbb{R} dx \\ x^2 p(x) - \\mu^2 = \\sigma^2. \\\\\n\\end{align*}\n\\] The Lagrange multiplier function is then \\[\n\\begin{align*}\nL(p(x),\\alpha,\\beta,\\gamma) = -&\\bigg(\\int_\\mathbb{R} dx \\ p(x) \\log p(x) \\bigg) - \\alpha\\bigg(\\int_\\mathbb{R} dx \\ p(x) - 1\\bigg) \\\\\n- \\beta&\\bigg(\\int_\\mathbb{R} dx \\ x p(x) - \\mu\\bigg) - \\gamma \\bigg(\\int_\\mathbb{R} dx \\ x^2 p(x) - \\mu^2 - \\sigma^2\\bigg).\n\\end{align*}\n\\] To maximize this function, consider a functional perturbation \\(p + \\delta p\\). Notice every term is linear in \\(p\\) except the first term, which is \\(p \\log p\\). In that term, we have \\[\n\\begin{align*}\n(p + \\delta p) \\log (p + \\delta p) &= (p + \\delta p) \\log(1 + \\frac{\\delta p}{p}) \\log p \\\\\n&= (p + \\delta p) \\bigg(1 + \\frac{\\delta p}{p}\\bigg) \\log p \\\\\n&= p \\log p + \\delta p (\\log p + 1) + O(\\delta p^2).\n\\end{align*}\n\\] If we ignore terms of order higher than \\(\\delta p\\), then solving for \\(\\delta L\\) and setting it to zero gives \\[\n\\begin{align*}\n\\delta L &= L(p + \\delta p,\\alpha,\\beta,\\gamma) - L(p,\\alpha,\\beta,\\gamma) \\\\\n&= -\\int_\\mathbb{R} dx \\delta p \\ \\bigg[\\log p + 1 + \\alpha + \\beta x + \\gamma(x^2 - 2\\mu x) \\bigg] \\equiv 0.\n\\end{align*}\n\\] Since this must be true for any perturbation \\(\\delta p\\), the integrand must be zero, \\[\n\\log p + 1 + \\alpha + \\beta x + \\gamma(x^2 - 2\\mu x) = 0.\n\\] Solving then for \\(p(x)\\) we have \\[\np(x) = \\exp\\big(-1 - \\alpha - \\beta x - \\gamma(x^2 - 2\\mu x)\\big).\n\\] The exponent is just a quadratic function of \\(x\\), hence we can rewrite \\(p(x)\\) in terms of new constants as \\[\np(x) = \\mathcal{N} \\exp\\bigg(-\\frac{(x-a\\mu)^2}{2b\\sigma^2}\\bigg).\n\\] Since this has the form of a Gaussian, integrating over the real line gives a normalization constant of the form \\(\\mathcal{N} = (2\\pi b \\sigma^2)^{-1/2}\\). Similarly, by shift invariance, integrating the mean function requires that \\(a=1\\). Last, the variance constraint requires that \\(b=1\\). We’ve thus shown that the continuous probability distribution whose mean and variance are known must be a Gaussian distribution.\nExample: Let’s do one more example that’s very relevant to statistical mechanics. Suppose we have a discrete random variable \\(x\\) that can take on a possibly countably infinite number of values. Suppose we know that some positive function \\(E(x) \\geq 0\\) of \\(x\\) has expectation \\(\\langle E(x) \\rangle = E\\). Then the problem to solve is \\[\n\\begin{align*}\n&\\max_p \\bigg(- \\sum_{i=0}^\\infty p_i \\log p_i \\bigg) \\\\\n&\\text{subject to} \\ \\sum_{i=0}^\\infty p_i = 1, \\ \\text{and} \\ \\sum_{i=0}^\\infty p_i E_i = E. \\\\\n\\end{align*}\n\\] The Lagrange multiplier function is then given by \\[\nL(p,\\alpha) \\equiv - \\sum_{i=0}^\\infty p_i \\log p_i - \\alpha \\bigg(\\sum_{i=0}^\\infty p_i - 1\\bigg) - \\beta \\bigg(\\sum_{i=0}^\\infty p_i E_i - E\\bigg).\n\\] Differentiating with respect to each \\(p_j\\), \\(\\alpha\\), and \\(\\beta\\) and setting all the derivatives to zero, we have \\[\n\\begin{align*}\n\\frac{\\partial L}{\\partial p_j} &= -\\log p_j - 1 - \\alpha - \\beta E_i \\equiv 0, \\\\\n\\frac{\\partial L}{\\partial \\alpha} &= \\sum_{i=0}^\\infty p_i - 1 \\equiv 0, \\\\\n\\frac{\\partial L}{\\partial \\alpha} &= \\sum_{i=0}^\\infty p_i E_i - E \\equiv 0. \\\\\n\\end{align*}\n\\] Together, these imply that the probabilities must have the form \\[\np_j = e^{-(1+\\alpha)} e^{-\\beta E_j}.\n\\] Again, the factor \\(e^{-(1+\\alpha)}\\) is just a normalization constant. If we redefine it to be \\(\\frac{1}{Z}\\), then we finally have \\[\np_j = \\frac{1}{Z} e^{-\\beta E_j},\n\\] where by normalization \\(Z\\) must satisfy the relation \\[\nZ = \\sum_{i=0}^\\infty e^{-\\beta E_i}.\n\\] More generally, we could imagine \\(\\mathbf{E}(x)\\) being a vector-valued function, in which case the same results apply just be replacing the scalars \\(\\beta E_i\\) with vectors \\(\\boldsymbol{\\beta} \\cdot \\mathbf{E}_i\\). We’ll see later that the normalization constant \\(Z\\) is very important to statistical mechanics. It’s called the partition function. In that case, \\(E_j\\) represents the energy of the system in the \\(j\\)th state and \\(E\\) represents the average internal energy of the system, i.e. the energy that satisfies the first law of thermodynamics.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/kinetic-theory.html",
    "href": "statistical-mechanics/kinetic-theory.html",
    "title": "Kinetic Theory",
    "section": "",
    "text": "Hamiltonian Mechanics\nTo start, we’ll review the classical mechanics of particles via the Hamiltonian formulation.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Kinetic Theory</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/kinetic-theory.html#hamiltonian-mechanics",
    "href": "statistical-mechanics/kinetic-theory.html#hamiltonian-mechanics",
    "title": "Kinetic Theory",
    "section": "",
    "text": "Hamilton’s Equations\nConsider a system with \\(3N\\) degrees of freedom. For simplicity, we’ll assume the generalized coordinates are just the ordinary position vectors \\(\\mathbf{x}_i\\) and ordinary momentum vectors \\(\\mathbf{p}_i\\) for a given particle \\(i\\). In that case, \\(N\\) represents the number of particles in the system. Let \\(\\mathbf{x} \\equiv (\\mathbf{x}_1,\\mathbf{x}_2,\\cdots,\\mathbf{x}_N)\\) and \\(\\mathbf{p} \\equiv (\\mathbf{p}_1,\\mathbf{p}_2,\\cdots,\\mathbf{p}_N)\\). The \\(6N\\)-dimensional vector \\((\\mathbf{x}, \\mathbf{p})\\) characterizes the state of the system. The state is also a point in an abstract \\(6N\\)-dimensional space, called the phase space of the system.\nAssuming the system is conservative, the dynamics of the system are completely determined by the joint Hamiltonian \\(H = H(\\mathbf{x}, \\mathbf{p})\\). We can then in principle solve for the microscopic equations of motion \\(\\big(\\mathbf{x}(t), \\mathbf{p}(t)\\big)\\) by solving Hamilton’s equations, a system of \\(6N\\) differential equations given by \\[\n\\boxed{\\mathbf{\\dot x} = \\frac{\\partial H}{\\partial \\mathbf{p}}, \\quad \\mathbf{\\dot p} = -\\frac{\\partial H}{\\partial \\mathbf{x}}} \\ .\n\\] Said differently, the Hamiltonian induces a flow on the phase space, with the flow described by Hamilton’s equations. Each flow represents the time evolution of a particular state, determined by the initial conditions.\nIt’s important to note that the microscopic equations of motion are time reversal invariant. That is, if the momenta are reversed, \\(\\mathbf{p} \\rightarrow -\\mathbf{p}\\), then the trajectories also reverse, \\(\\mathbf{x}(t) \\rightarrow \\mathbf{x}(-t)\\). This is because the Hamiltonian \\(H(\\mathbf{x},\\mathbf{p})\\) is invariant to time reversal transformations \\((\\mathbf{x}, \\mathbf{p}) \\rightarrow (\\mathbf{x}, -\\mathbf{p})\\). Why is this important to note? Because thermodynamics is not time reversal invariant. Once an isolated system is in equilibrium it will stay in equilibrium. We thus need to figure out how this time reversal invariance property gets lost in the thermodynamic limit.\n\n\nPoisson Brackets\nFor two functions \\(F(\\mathbf{x}, \\mathbf{p})\\) and \\(G(\\mathbf{x}, \\mathbf{p})\\) defined on phase space, define their Poisson bracket by \\[\n\\boxed{\\{F, G\\} \\equiv \\frac{\\partial F}{\\partial \\mathbf{x}} \\cdot \\frac{\\partial G}{\\partial \\mathbf{p}} - \\frac{\\partial G}{\\partial \\mathbf{x}} \\cdot \\frac{\\partial F}{\\partial \\mathbf{p}}} \\ .\n\\] It’s easy to show that the Poisson bracket is anti-symmetric, i.e. \\(\\{F,G\\} = -\\{G,F\\}\\). It’s also bilinear, \\[\n\\begin{align*}\n\\{aF+bG,J\\} &= a\\{F,J\\} + b\\{G,J\\}, \\\\\n\\{F, aG + bJ\\} &= a\\{F,G\\} + b\\{F,J\\}. \\\\\n\\end{align*}\n\\] The Poisson bracket also satisfies the product rule, \\[\n\\frac{d}{dt} \\{F,G\\} = \\bigg\\{\\frac{dF}{dt}, G\\bigg\\} + \\bigg\\{F, \\frac{dG}{dt}\\bigg\\}.\n\\] The total time derivative of any function \\(F(\\mathbf{x}, \\mathbf{p})\\) is given by its Poisson bracket with the Hamiltonian, \\[\n\\frac{dF}{dt} = \\{F, H\\}.\n\\] Evidently, if \\(F\\) is a conserved quantity, its Poisson bracket with \\(H\\) must vanish, i.e. \\(\\{F,H\\} = 0\\). By Taylor expanding, it’s also possible to show that the Poisson bracket of any function of \\(F\\) with \\(H\\) must vanish, i.e. that \\(\\{f(F), H\\} = 0\\) for any analytic function \\(f(F)\\).\nOne result that we’ll frequently use is that the integral of a Poisson bracket \\(\\{F,H\\}\\) vanishes when integrated over an unbounded region of phase space (which is almost always the case). Denote the \\(3N\\)-dimensional phase space volume element by \\(d\\Gamma \\equiv d^{3N} \\mathbf{x} \\ d^{3N} \\mathbf{p}\\). Then we have \\[\n\\int d\\Gamma \\ \\{F,H\\} = 0.\n\\] To see why this is true we just use the definition of the Poisson bracket and integration by parts, \\[\n\\begin{align*}\n\\int d\\Gamma \\ \\{F,H\\} &= \\int d\\Gamma \\ \\bigg(\\frac{\\partial F}{\\partial \\mathbf{x}} \\cdot \\frac{\\partial H}{\\partial \\mathbf{p}} - \\frac{\\partial H}{\\partial \\mathbf{x}} \\cdot \\frac{\\partial F}{\\partial \\mathbf{p}}\\bigg) \\\\\n&= \\int d\\Gamma \\ \\frac{\\partial H}{\\partial \\mathbf{p}} \\cdot \\frac{\\partial F}{\\partial \\mathbf{x}} - \\int d\\Gamma \\ \\frac{\\partial H}{\\partial \\mathbf{x}} \\cdot \\frac{\\partial F}{\\partial \\mathbf{p}} \\\\\n&= -\\int d\\Gamma \\ \\frac{\\partial^2 H}{\\partial \\mathbf{x}\\partial \\mathbf{p}} F + \\int d\\Gamma \\ \\frac{\\partial^2 H}{\\partial \\mathbf{p}\\partial \\mathbf{x}} F + (\\text{boundary terms}). \\\\\n\\end{align*}\n\\] Since second partials commute, the two integrals cancel each other. Since \\(H\\) is a Hamiltonian describing a physical system, it must go to zero as \\(\\mathbf{p}\\) or \\(\\mathbf{x}\\) go to infinity, which means the boundary terms must also vanish as well. Note that for this to be true it’s also important that both \\(F\\) and \\(H\\) depend on all of the integration variables. If not then some of the terms can’t be exchanged. For example, if \\(F\\) is constant, we can pull the entire integral inside the Poisson bracket to get \\[\n\\int d\\Gamma \\ \\{F,H\\} = \\bigg\\{F, \\int d\\Gamma \\ H\\bigg\\} \\neq 0.\n\\]",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Kinetic Theory</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/kinetic-theory.html#liouvilles-equation",
    "href": "statistical-mechanics/kinetic-theory.html#liouvilles-equation",
    "title": "Kinetic Theory",
    "section": "Liouville’s Equation",
    "text": "Liouville’s Equation\nThe Hamiltonian formulation of classical mechanics implies an important result called Liouville’s theorem, a statement about how phase space densities evolve in time. From this theorem we can derived Liouville’s equation, our starting point for kinetic theory.\n\nLiouville’s Theorem\nSuppose a system of \\(N\\) particles has some given thermodynamic macrostate \\(M\\), which will in general be a function of the thermodynamic variables \\(T, V, N\\), etc. The system will also have some microstate \\(\\mu\\) that’s a function of all the positions \\(\\mathbf{x}\\) and momenta \\(\\mathbf{p}\\). In general, there will be many possible microstates \\(\\mu\\) for any given macrostate \\(M\\). Each microstate corresponds to some point in the phase space, which evolves in time. Define a Gibbs ensemble as the set of all possible microstates \\(\\mu\\) that correspond to a given macrostate \\(M\\). An ensemble represents a cloud of points in phase space, with the cloud of points each evolving in time. Suppose there are \\(\\mathcal{N}\\) points in the ensemble. For a given infinitesimal phase space volume element \\(d\\Gamma\\), we can define an ensemble density \\(\\rho\\) as the limiting ratio of ensemble points inside of a cube \\(d\\Gamma\\) with the total number of ensemble points \\(\\mathcal{N}\\), \\[\n\\boxed{\\rho(\\mathbf{x}, \\mathbf{p}, t) d\\Gamma \\equiv \\lim_{\\mathcal{N} \\rightarrow \\infty} \\frac{d\\mathcal{N}}{\\mathcal{N}}} \\ .\n\\] The phase space density defines a proper probability density on the phase space since \\(\\rho \\geq 0\\) and \\[\n\\int d\\Gamma \\ \\rho = \\int \\frac{d\\mathcal{N}}{\\mathcal{N}} = \\frac{\\mathcal{N}}{\\mathcal{N}} = 1.\n\\] We can define an ensemble average for any function \\(F(\\mathbf{x}, \\mathbf{p},t)\\) on the phase space, \\[\n\\boxed{\\langle F(\\mathbf{x}, \\mathbf{p},t) \\rangle \\equiv \\int d\\Gamma \\ \\rho(\\mathbf{x}, \\mathbf{p},t) F(\\mathbf{x}, \\mathbf{p},t)} \\ .\n\\] Liouville’s Theorem: Phase space volumes are preserved under time evolution. That is, for any two times \\(t\\) and \\(t'\\), the differential volume element \\(d\\Gamma\\) must be the same, \\[\nd\\Gamma(\\mathbf{x}', \\mathbf{p}',t') = d\\Gamma(\\mathbf{x}, \\mathbf{p},t).\n\\] Proof: Let \\(d\\Gamma \\equiv d\\Gamma(\\mathbf{x}, \\mathbf{p},t)\\) and \\(d\\Gamma' \\equiv d\\Gamma(\\mathbf{x}', \\mathbf{p}',t+dt)\\), where \\(dt\\) is infinitesimal. Then we must have \\[\n\\begin{align*}\n\\mathbf{x}' &= \\mathbf{x} + \\mathbf{\\dot x} dt, \\\\\n\\mathbf{p}' &= \\mathbf{p} + \\mathbf{\\dot p} dt. \\\\\n\\end{align*}\n\\] The goal is to show that \\(d\\Gamma = d^{3N} \\mathbf{x} \\ d^{3N} \\mathbf{p}\\) is the same as \\(d\\Gamma' = d^{3N} \\mathbf{x}' \\ d^{3N} \\mathbf{p}'\\). Let’s focus on a particular component \\(\\alpha\\) and show \\(dx_\\alpha dp_\\alpha = dx'_{\\alpha} dp'_{\\alpha}\\). Taking the differentials of \\(x'_\\alpha\\) and \\(p'_\\alpha\\), we have \\[\n\\begin{align*}\ndx'_\\alpha &= dx_\\alpha + \\frac{\\partial \\dot x_\\alpha}{\\partial x_\\alpha} dt, \\\\\ndp'_\\alpha &= dp_\\alpha + \\frac{\\partial \\dot p_\\alpha}{\\partial p_\\alpha} dt. \\\\\n\\end{align*}\n\\] Then evidently \\[\ndx'_\\alpha dp'_\\alpha = dx_\\alpha dp_\\alpha \\bigg[1 + \\bigg(\\frac{\\partial \\dot x_\\alpha}{\\partial x_\\alpha} + \\frac{\\partial \\dot p_\\alpha}{\\partial p_\\alpha} \\bigg)  \\bigg].\n\\] Using Hamilton’s equations, however, we have that \\[\n\\frac{\\partial \\dot x_\\alpha}{\\partial x_\\alpha} + \\frac{\\partial \\dot p_\\alpha}{\\partial p_\\alpha} = \\frac{\\partial}{\\partial x_\\alpha} \\frac{\\partial H}{\\partial p_\\alpha} - \\frac{\\partial}{\\partial p_\\alpha} \\frac{\\partial H}{\\partial x_\\alpha} = 0.\n\\] Thus, to first order we have \\(dx_\\alpha dp_\\alpha = dx'_{\\alpha} dp'_{\\alpha}\\) for each \\(\\alpha\\). Multiplying them all together, we finally have \\(d\\Gamma' = d\\Gamma\\), as desired. \\(\\text{Q.E.D.}\\)\n\n\nDerivation\nLiouville’s theorem as stated is equivalent to saying that the phase space density is an incompressible fluid. That is, the flow velocity on phase space has zero divergence. Indeed, we have \\[\n\\nabla_{\\mathbf{x}, \\mathbf{p}} \\cdot (\\mathbf{\\dot x}, \\mathbf{\\dot p}) = \\frac{\\partial \\mathbf{\\dot x}}{\\partial \\mathbf{x}} + \\frac{\\partial \\mathbf{\\dot p}}{\\partial \\mathbf{p}} = \\frac{\\partial}{\\partial \\mathbf{x}} \\frac{\\partial H}{\\partial \\mathbf{p}} - \\frac{\\partial}{\\partial \\mathbf{p}} \\frac{\\partial H}{\\partial \\mathbf{x}} = 0.\n\\] Define the stream derivative or the material derivative of a function \\(f(\\mathbf{x}, \\mathbf{p},t)\\) as the total time derivative, \\[\n\\boxed{\\frac{Df}{Dt} \\equiv \\frac{df}{dt}} \\ .\n\\] The stream derivative represents how any given flow of \\(f\\) changes in time. If you follow any given set of points in time, they’ll evolve according to the stream derivative. This contrasts with the point derivative \\(\\frac{\\partial f}{\\partial t}\\), which represents how \\(f\\) changes at a fixed point \\(\\mathbf{x},\\mathbf{p}\\) in time.\nThe stream derivative of the phase space density can evidently be related to the point derivative by \\[\n\\begin{align*}\n\\frac{D\\rho}{Dt} &= (\\mathbf{\\dot x}, \\mathbf{\\dot p}) \\cdot \\nabla_{\\mathbf{x}, \\mathbf{p}} \\ \\rho \\ + \\frac{\\partial \\rho}{\\partial t} \\\\\n&= \\mathbf{\\dot x} \\cdot \\frac{\\partial \\rho}{\\partial \\mathbf{x}} + \\mathbf{\\dot p} \\cdot\\frac{\\partial \\rho}{\\partial \\mathbf{p}} + \\frac{\\partial \\rho}{\\partial t} \\\\\n&= \\frac{\\partial \\rho}{\\partial \\mathbf{x}} \\cdot \\frac{\\partial H}{\\partial \\mathbf{p}} - \\frac{\\partial \\rho}{\\partial \\mathbf{p}} \\cdot \\frac{\\partial H}{\\partial \\mathbf{x}} \\\\\n&= \\{\\rho, H\\} + \\frac{\\partial \\rho}{\\partial t}.\n\\end{align*}\n\\] Liouville’s theorem implies that the stream derivative of \\(\\rho\\) must vanish. Since \\(d\\Gamma' = d\\Gamma\\), we must have \\(\\rho' d\\Gamma' = \\rho d\\Gamma\\), or \\((\\rho'-\\rho) d\\Gamma = 0\\), which implies \\(\\rho'=\\rho\\). We’ve thus derived Liouville’s equation, which says how the density at any given point in phase space evolves in time, \\[\n\\boxed{\\frac{\\partial \\rho}{\\partial t} = -\\{\\rho, H\\} = \\{H,\\rho\\}} \\ .\n\\] For convenience, it’s also common to define a Liouville operator \\(\\mathcal{L}\\) by \\[\n\\boxed{\\mathcal{L}[\\rho] \\equiv \\{\\rho, H\\} + \\frac{\\partial \\rho}{\\partial t}} \\ .\n\\] In this language, Liouville’s equation can also be written as \\(\\mathcal{L}[\\rho] = 0\\).\nWe can use Liouville’s equation to find the time derivative of an ensemble average. If \\(F(\\mathbf{x},\\mathbf{p})\\) is some time-independent function on phase space. Using integration by parts, we have \\[\n\\frac{d}{dt} \\langle F \\rangle = \\int d\\Gamma \\ F \\frac{\\partial \\rho}{\\partial t} = -\\int d\\Gamma \\ F \\ \\{\\rho, H\\} = \\int d\\Gamma \\ \\rho \\ \\{F, H\\} = \\bigg\\langle \\frac{dF}{dt} \\bigg\\rangle.\n\\] That is, the time derivative of an ensemble average is the ensemble average of the time derivative.\n\n\nEquilibrium Conditions\nWhile all this is nice, our entire purpose is to figure out what happens at or near equilibrium. At equilibrium, the density can’t depend explicitly on time, i.e. \\(\\rho_{eq} = \\rho(\\mathbf{x}, \\mathbf{p})\\). This evidently implies \\[\n\\frac{\\partial \\rho_{eq}}{\\partial t} = -\\{\\rho_{eq}, H\\} = 0.\n\\] A sufficient condition for \\(\\{\\rho_{eq}, H\\}\\) to vanish is that \\(\\rho_{eq}\\) only be an explicit function of the conserved quantities in the system, since conserved quantities all have vanishing Poisson bracket with \\(H\\). This is called the basic assumption of statistical mechanics. If only energy is conserved, which is the typical case, we’d have \\[\n\\rho_{eq} = \\rho(H(\\mathbf{x}, \\mathbf{p})).\n\\] Recall that this requires the Poisson bracket to vanish since we can expand \\(\\rho\\) in powers of \\(H\\). The two most important equilibrium densities we’ll see in statistical mechanics are the microcanonical ensemble \\(\\rho_{eq} = \\delta(H(\\mathbf{x}, \\mathbf{p})-E)\\), and the canonical ensemble \\(\\rho_{eq} \\propto e^{-\\beta H(\\mathbf{x}, \\mathbf{p})}\\).\nNote that we still haven’t shown that it’s even possible that \\(\\rho \\rightarrow \\rho_{eq}\\) as \\(t \\rightarrow \\infty\\). This must happen for the basic assumption of statistical mechanics to be true. However, convergence to a stationary distribution contradicts time reversal symmetry, which \\(\\rho\\) itself must in principle satisfy. In fact, \\(\\rho \\nrightarrow \\rho_{eq}\\) exactly since such a process is irreversible. In principle, if we could follow every point in the ensemble exactly, we could trace the density both forward and backward in time. In practice, however, we can’t do this, meaning we lose information over time. Only in a coarse-grained sense will it be true \\(\\rho \\rightarrow \\rho_{eq}\\).\n\nTALK ABOUT ERGODICITY HERE",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Kinetic Theory</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/kinetic-theory.html#the-bbgky-hierarchy",
    "href": "statistical-mechanics/kinetic-theory.html#the-bbgky-hierarchy",
    "title": "Kinetic Theory",
    "section": "The BBGKY Hierarchy",
    "text": "The BBGKY Hierarchy\nThe full phase space density of all \\(N\\) particles contains far more information than we need for thermodynamic purposes. In fact, we can often get away with looking at densities of a small number of particles in the background of all the other particles. We can derive a recursive expression for these densities that will be useful for making the approximations that will lead us into thermodynamics.\n\nParticle Densities\nDefine the (un-normalized) density of a single particle as the expected number of particles \\(f_1\\) that occur at some \\(\\mathbf{x},\\mathbf{p},t\\), i.e. \\[\nf_1(\\mathbf{x}, \\mathbf{p},t) \\equiv \\bigg\\langle \\sum_{i=1}^N \\delta^3(\\mathbf{x}_i-\\mathbf{x}) \\delta^3(\\mathbf{p}_i-\\mathbf{p}) \\bigg\\rangle.\n\\] Assuming each particle is identical, we can simplify the right-hand side by noting that the expected value of \\(N\\) identical particles is just \\(N\\) times the expectation of a single particle, \\[\n\\begin{align*}\nf_1(\\mathbf{x}, \\mathbf{p},t) &= N \\big\\langle \\delta^3(\\mathbf{x}_1-\\mathbf{x}) \\delta^3(\\mathbf{p}_1-\\mathbf{p}) \\big\\rangle \\\\\n&= N \\int d^3 \\mathbf{x}_1 d^3 \\mathbf{p}_1 \\ \\rho(\\mathbf{x}_1=\\mathbf{x}, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N, \\mathbf{p}_1=\\mathbf{p}, \\mathbf{p}_2, \\cdots, \\mathbf{p}_N,t) \\\\\n&= N \\rho_1(\\mathbf{x}, \\mathbf{p}, t),\n\\end{align*}\n\\] where \\(\\rho_1(\\mathbf{x}, \\mathbf{p}, t)\\) is just the one-particle marginal PDF of the full density \\(\\rho\\). As expected, the expected number of particles at a point is just \\(N\\) times the normalized one-particle density. We can similarly ask about the expected number of tuples of particles. The density \\(f_s\\) of \\(s\\) particles occurring at some given set of \\(s\\) phase space points at some time \\(t\\) is given by \\[\n\\boxed{f_s(\\mathbf{x}_1, \\cdots, \\mathbf{x}_s,\\mathbf{p}_1, \\cdots, \\mathbf{p}_s,t) \\equiv \\frac{N!}{(N-s)!} \\rho_s(\\mathbf{x}_1, \\cdots, \\mathbf{x}_s,\\mathbf{p}_1, \\cdots, \\mathbf{p}_s,t)} \\ .\n\\] Clearly, \\(f_N\\) is just the un-normalized full density of finding all \\(N\\) particles at their given points, which is \\[\nf_N(\\mathbf{x}_1, \\cdots, \\mathbf{x}_N,\\mathbf{p}_1, \\cdots, \\mathbf{p}_N,t) = N! \\ \\rho(\\mathbf{x}_1, \\cdots, \\mathbf{x}_N,\\mathbf{p}_1, \\cdots, \\mathbf{p}_N,t).\n\\]\n\n\nDerivation\nWhat we’d like to try to do is to find a way of expressing \\(f_N\\) as a hierarchy of lower-particle densities. If we can get that then we can start approximating the full density using the much simpler one or two particle densities. This hierarchy of densities is called the BBGKY Hierarchy, which we’ll now derive.\nTo do that we need to make an assumption about the functional form of the full Hamiltonian \\(H\\). We’ll assume that it’s composed of the kinetic energy for each particle, where each particle has the same mass \\(m\\), some external potential energy \\(V\\) acting on each particle (e.g. the force resulting from the walls of the box of a container), and some interaction potential energy \\(\\nu\\) between particles, which we’ll approximate as being some central potential between all pairs of distinct particles (an adequate approximate for a weakly interacting gas). All together, we thus have \\[\nH = \\sum_{i=1}^N \\bigg(\\frac{\\mathbf{p}_i^2}{2m} + V(\\mathbf{x}_i)  + \\sum_{j &lt; i} \\nu\\big(|\\mathbf{x}_i-\\mathbf{x}_j|\\big)\\bigg).\n\\] We need to figure out the time evolution of each \\(s\\)-particle density \\(f_s\\). To do that it’s convenient to split the full Hamiltonian up into three pieces: One piece \\(H_s\\) that only involves interactions between the \\(s\\) particles themselves. One piece \\(H_{N-s}\\) that only involves interactions between the remaining \\(N-s\\) particles. And finally one piece \\(H'\\) that completely specifies the interactions between the \\(s\\) particles with the other \\(N-s\\) particles. We can then write \\[\nH = H_s + H_{N-s} + H'.\n\\] The first two terms are just the full Hamiltonian, but with \\(i\\) running from \\(1\\) to \\(s\\) or \\(s+1\\) to \\(N\\) respectively. The interaction term only involves the interaction potential energies between the two sets, \\[\nH' = \\sum_{i=1}^s \\sum_{j=s+1}^N \\nu\\big(|\\mathbf{x}_i-\\mathbf{x}_j|\\big).\n\\] By Liouville’s equation, we have \\(\\frac{\\partial \\rho}{\\partial t} = -\\{\\rho, H\\}\\). But this is only true for the full density. Let’s try to see what Liouville’s equation for the marginal density \\(\\rho_s\\) might look like. Then we have \\[\n\\begin{align*}\n\\frac{\\partial \\rho_s}{\\partial t} &= \\int \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\frac{\\partial \\rho}{\\partial t} \\\\\n&= -\\int \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\ \\{\\rho, H\\} \\\\\n&= -\\int \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\ \\bigg(\\{\\rho, H_s\\} + \\{\\rho, H_{N-s}\\} + \\{\\rho, H'\\} \\bigg). \\\\\n\\end{align*}\n\\] Starting with the first term, the Hamiltonian \\(H_s\\) is constant with respect to the integration variables, so we just have \\[\n\\int \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\{\\rho, H_s\\} = \\bigg\\{ \\int \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\rho \\ , \\ H_s \\bigg\\} = \\{\\rho_s, H_s\\}.\n\\] That is, the first term is just Liouville’s equation for the first \\(s\\) particles. This makes sense, since we’re ignoring the presence of the other \\(N-s\\) particles in the dynamics of \\(\\rho_s\\) via \\(H_s\\). The second term is an integral over two functions that depend on the integration variables, which means it vanishes as usual, \\[\n\\int \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\{\\rho, H_{N-s}\\} = 0.\n\\] Finally we have the integral of the interaction terms. If we split the Poisson bracket \\(\\{\\rho, H'\\}\\) into a sum of two terms, one over the \\(s\\) variables and the other over the \\(N-s\\) variables, we have \\[\n\\{\\rho, H'\\} = \\{\\rho, H'\\}_s + \\{\\rho, H'\\}_{N-s.}\n\\] Integrating the second Poisson bracket again gives zero since it’s a bracket of the integration variables. The first bracket is more interesting. Noting that \\(H'\\) depends only on the positions, we have \\[\n\\begin{align*}\n\\int \\ \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\{\\rho, H'\\}_s &= \\int \\ \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\sum_{j=1}^s \\bigg(\\frac{\\partial \\rho}{\\partial \\mathbf{x}_j} \\cdot \\frac{\\partial H'}{\\partial \\mathbf{p}_j} - \\frac{\\partial H'}{\\partial \\mathbf{x}_j} \\cdot \\frac{\\partial \\rho}{\\partial \\mathbf{p}_j}\\bigg) \\\\\n&= - \\sum_{j=1}^s \\int \\ \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\frac{\\partial H'}{\\partial \\mathbf{x}_j} \\cdot \\frac{\\partial \\rho}{\\partial \\mathbf{p}_j} \\\\\n&= - \\sum_{j=1}^s \\int \\ \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\bigg(\\sum_{k=s+1}^N \\frac{\\partial \\nu}{\\partial \\mathbf{x}_j} \\bigg) \\cdot \\frac{\\partial \\rho}{\\partial \\mathbf{p}_j} \\\\\n&= (N-s) \\sum_{j=1}^s \\int \\ d^3 \\mathbf{x}_{s+1} d^3 \\mathbf{p}_{s+1} \\ \\mathbf{F}_{j,s+1} \\cdot \\frac{\\partial}{\\partial \\mathbf{p}_j} \\bigg(\\int \\ \\prod_{k=s+2}^N d^3 \\mathbf{x}_k d^3 \\mathbf{p}_k \\ \\rho \\bigg) \\\\\n&= (N-s) \\sum_{j=1}^s \\int \\ d^3 \\mathbf{x}_{s+1} d^3 \\mathbf{p}_{s+1} \\ \\mathbf{F}_{j,s+1} \\cdot \\frac{\\partial \\rho_{s+1}}{\\partial \\mathbf{p}_j}. \\\\\n\\end{align*}\n\\] The last equalities follow from the fact that the integral over the third line is just \\(N-s\\) copies of the same integral over particle \\(s+1\\), except we have to be careful to still integrate \\(\\rho\\) over the remaining terms from \\(s+2\\) to \\(N\\), which give the \\(s+1\\) particle density \\(\\rho_{s+1}\\). Since the negative gradient of a potential energy is a force, each term \\(\\mathbf{F}_{j,i} = -\\nabla_j \\nu(\\mathbf{x}_j-\\mathbf{x}_i)\\) represents the force on particle \\(j\\) due to its interaction with particle \\(s+1\\), which by Newton’s Third Law is of course the negative of the opposite force \\(\\mathbf{F}_{i,j}\\).\nWe thus finally have a modified form of Liouville’s equation for \\(\\rho_s\\), which adds a new term representing the collisions of the \\(s\\) particles with the other \\(N-s\\) particles. We have \\[\n\\frac{\\partial \\rho_s}{\\partial t} + \\{\\rho_s, H_s\\} = (N-s) \\sum_{j=1}^s \\int \\ d^3 \\mathbf{x}_{s+1} d^3 \\mathbf{p}_{s+1} \\ \\mathbf{F}_{s+1,j} \\cdot \\frac{\\partial \\rho_{s+1}}{\\partial \\mathbf{p}_j}.\n\\] It’s more common to express things in terms of the un-normalized densities \\(f_s\\) instead. Doing this eliminates the \\(N-s\\) factor in front of the collision term and replaces each \\(\\rho_s\\) with \\(f_s\\). We’ve thus finally arrived at the BBGKY Hierarchy we sought after, \\[\n\\boxed{\\frac{\\partial f_s}{\\partial t} + \\{f_s, H_s\\} = \\sum_{j=1}^s \\int \\ d^3 \\mathbf{x}_{s+1} d^3 \\mathbf{p}_{s+1} \\ \\mathbf{F}_{s+1,j} \\cdot \\frac{\\partial f_{s+1}}{\\partial \\mathbf{p}_j}} \\ .\n\\] We can think of this as a kind of ladder of densities. The one-particle density \\(f_1\\) depends via the collision integral on the two-particle density \\(f_2\\), which itself depends on \\(f_3\\), and so on until we get to the full density \\(f_N\\). It’s worth noting that the BBGKY Hierarchy is completely equivalent to Liouville’s equation for a box of \\(N\\) particles obeying the Hamiltonian specified above.\nOf most use to use will be the equations for \\(f_1\\) and \\(f_2\\). If we expand the Poisson brackets, they become \\[\n\\begin{align*}\n\\frac{\\partial f_1}{\\partial t} + &\\frac{\\mathbf{p}_1}{m} \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{x}_1} + \\mathbf{F}_1 \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{p}_1} = \\int d^3 \\mathbf{x}_2 d^3 \\mathbf{p}_2 \\ \\mathbf{F}_{2,1} \\cdot \\frac{\\partial f_2}{\\partial \\mathbf{p}_1}, \\\\\n\\frac{\\partial f_2}{\\partial t} + \\frac{\\mathbf{p}_1}{m} \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{x}_1} + &\\mathbf{F}_1 \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{p}_1} + \\frac{\\mathbf{p}_2}{m} \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{x}_2} + \\mathbf{F}_2 \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{p}_2} +\\mathbf{F}_{1,2} \\cdot \\bigg(\\frac{\\partial f_1}{\\partial \\mathbf{p}_1} - \\frac{\\partial f_1}{\\partial \\mathbf{p}_2}\\bigg) = \\\\ &\\int d^3 \\mathbf{x}_3 d^3 \\mathbf{p}_3 \\ \\bigg(\\mathbf{F}_{3,1} \\cdot \\frac{\\partial f_3}{\\partial \\mathbf{p}_1} + \\mathbf{F}_{3,2} \\cdot \\frac{\\partial f_3}{\\partial \\mathbf{p}_2}\\bigg). \\\\\n\\end{align*}\n\\]\nHere \\(\\mathbf{F}_i = -\\nabla V(\\mathbf{x}_i)\\) represents the force on particle \\(i\\) due to the external potential energy \\(V\\). The combination of derivatives in the \\(\\mathbf{F}_{1,2}\\) term is done by using Newton’s third law to get \\(\\mathbf{F}_{2,1} = -\\mathbf{F}_{1,2}\\). This is equivalent to assume that the interaction potential \\(\\nu\\) is symmetric in \\(i\\) and \\(j\\), which is true of central forces.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Kinetic Theory</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/kinetic-theory.html#the-boltzmann-equation",
    "href": "statistical-mechanics/kinetic-theory.html#the-boltzmann-equation",
    "title": "Kinetic Theory",
    "section": "The Boltzmann Equation",
    "text": "The Boltzmann Equation\nThus far we really haven’t made much progress in studying the approach to equilibrium. Both Liouville’s equation and the BBGKY hierarchy are fully reversible, describing the microscopic behavior of the system. To study equilibrium we need to coarse grain things more, giving up the ability to track the exact dynamics of any given particle. We’ll start by looking at the time scales involved in the BBGKY hierarchy to get an idea of which terms in the equations are most important.\n\nCoarse-Graining\nSuppose the system involved is a box of gas whose sides are each of length of order \\(L\\). Suppose the particles in the box move with some average speed \\(v\\). Evidently then, it takes a given particle an average time \\(\\tau_{ext} \\equiv \\frac{L}{v}\\) to traverse the length of the box. This defines a time-scale for the external force terms, \\[\n\\mathbf{F}_i \\cdot \\frac{\\partial}{\\partial \\mathbf{p}_i} \\sim \\frac{v}{L} = \\frac{1}{\\tau_{ext}}.\n\\] In the box particles will collide with a certain frequency. Suppose interaction forces are felt when particles are within some distance \\(d \\ll L\\) of each other. The time that particles spend interacting in an interaction is then evidently on the order of \\(\\tau_{int} \\equiv \\frac{d}{v}\\). This defines another time-scale for the interaction force terms, \\[\n\\mathbf{F}_{i,j} \\cdot \\frac{\\partial}{\\partial \\mathbf{p}_i} \\sim \\frac{v}{d} = \\frac{1}{\\tau_{int}}.\n\\] Since \\(d \\ll L\\), we typically have \\(\\tau_{int} \\ll \\tau_{ext}\\), which means the interaction terms should typically dominate the external force terms on the left-hand side of the equations. For example, for a gas we might have \\(L \\sim 1 \\ \\text{m}\\) while \\(d \\sim 10^{-10} \\ \\text{m}\\), with \\(v \\sim 10^2 \\ \\text{m/s}\\) at room temperature. This gives time scales on the order of \\(\\tau_{ext} \\sim 10^{-3} \\ \\text{s}\\) and \\(\\tau_{int} \\sim 10^{-12} \\ \\text{s}\\).\nOn the right-hand side of these equations we have another set of time scales that say something about how long we have to wait for \\(s+1\\) particles to all come together and collide with each other. Call that time scale \\(\\tau_X\\). If we look at the ratio of \\(\\frac{f_{s+1}}{f_s}\\) as a ratio of densities, it goes roughly like the number density \\(n \\equiv \\frac{N}{d^3}\\) of particles inside a unit volume \\(d^3\\). Since the collisions only happen inside a volume \\(d^3\\), essentially the entire integral falls off to zero outside this region. Thus, we’d have \\[\n\\int \\ d^3 \\mathbf{x}_{s+1} \\ d^3 \\mathbf{p}_{s+1} \\ \\mathbf{F}_{s+1,j} \\cdot \\frac{\\partial }{\\partial \\mathbf{p}_j} \\frac{f_{s+1}}{f_s} \\sim \\frac{nd^3}{\\tau_{int}} \\equiv \\frac{1}{\\tau_X}.\n\\] This new time scale \\(\\tau_X = \\frac{1}{nvd^2}\\) is called the mean free time. It represents the typical time a particle will spend between collisions. Its relative size with respect to \\(\\tau_{col}\\) depends on \\(nd^3\\). This reflects the fact we have to wait for \\(s+1 \\sim N\\) particles to all come together and collide. The range of interactions between particles determines two limiting regions of consideration. When interactions short-range, we’d say we’re in the dilute limit where \\(nd^3 \\ll 1\\). This is the typical setting for gases, where we might have \\(nd^3 \\sim 10^{-4}\\), and so \\(\\tau_X \\sim 10^4 \\ \\tau_{int}\\). Conversely, when interactions are long-range, we’d say we’re in the dense limit where \\(nd^3 \\gg 1\\). This limit is the setting for studying plasmas, where \\(\\tau_X \\ll \\tau_{int}\\). We’ll see that the dilute limit leads us to the Boltzmann equation, and hence to thermodynamics, while the dense limit leads us to the Vlasov equation, and hence to plasma physics.\nAll the equations in the BBGKY hierarchy appear to look something like \\[\n\\text{(external interactions)} + \\text{(internal interactions)} = \\text{(collision terms)}.\n\\] In this situation the time scale comparisons look something like \\[\n\\frac{1}{\\tau_{ext}} + \\frac{1}{\\tau_{int}} = \\frac{nd^3}{\\tau_{int}}.\n\\] In the dilute limit the right-hand side is much smaller than the left-hand side, so we can evidently ignore the collision terms at least to zeroth order. This appears to be a problem though, since it says that we shouldn’t look at the background interactions at all and just treat each \\(f_s\\) as its own Liouvillian system. Fortunately, the equation for \\(f_1\\) does not look like this. In that case there are no internal interaction terms on the left-hand side, which means we can’t say much about how the left and right-hand sides compare. We have to keep both terms, which preserves the dependence of \\(f_1\\) on \\(f_2\\). But, we can treat \\(f_2\\) as having a right-hand side of zero, so we can ignore the dependence on \\(f_3\\) and higher terms and only focus on the relationship between \\(f_1\\) and \\(f_2\\).\n\n\nDerivation\nLet’s try to find a way under this approximation to combine the equations for \\(f_1\\) and \\(f_2\\) into a single equation. To do that we need to figure out how to substitute the \\(f_2\\) equation into the \\(f_1\\) equation. If we assume the collision term for \\(f_2\\) is zero, we have \\[\n\\begin{align*}\n\\frac{\\partial f_1}{\\partial t} + &\\frac{\\mathbf{p}_1}{m} \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{x}_1} + \\mathbf{F}_1 \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{p}_1} = \\int d^3 \\mathbf{x}_2 \\ d^3 \\mathbf{p}_2 \\ \\mathbf{F}_{2,1} \\cdot \\frac{\\partial f_2}{\\partial \\mathbf{p}_1}, \\\\\n\\frac{\\partial f_2}{\\partial t} + \\frac{\\mathbf{p}_1}{m} \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{x}_1} + &\\mathbf{F}_1 \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{p}_1} + \\frac{\\mathbf{p}_2}{m} \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{x}_2} + \\mathbf{F}_2 \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{p}_2} +\\mathbf{F}_{1,2} \\cdot \\bigg(\\frac{\\partial f_1}{\\partial \\mathbf{p}_1} - \\frac{\\partial f_1}{\\partial \\mathbf{p}_2}\\bigg) = 0. \\\\\n\\end{align*}\n\\] The second equation involves a density of two interaction particles. It’s convenient thus to express things in terms of center of mass and relative coordinates. Let \\(\\boldsymbol{\\mathcal{x}} \\equiv \\mathbf{x}_2 - \\mathbf{x}_1\\) represent coordinates between the two particles and \\(\\mathbf{X} \\equiv \\mathbf{x}_2 + \\mathbf{x}_1\\) represent the center of mass coordinates. Typically the center of mass coordinates will vary much slower than the relative coordinates, making the center of mass frame a good approximation of the lab frame dynamics as well. In this situation, we’d have \\(\\boldsymbol{\\mathcal{x}} = -\\mathbf{x}_1 = \\mathbf{x}_2\\). Near equilibrium we’d expect \\(\\frac{\\partial f_2}{\\partial t} \\approx 0\\). Changing variables in and writing \\(\\mathbf{F}_{2,1} = -\\mathbf{F}_{1,2}\\), the second equation becomes \\[\n\\frac{\\mathbf{p}}{m} \\cdot \\frac{\\partial f_2}{\\partial \\boldsymbol{\\mathcal{x}}} - \\mathbf{F}_{2,1} \\cdot  \\bigg(\\frac{\\partial f_2}{\\partial \\mathbf{p}_1} - \\frac{\\partial f_2}{\\partial \\mathbf{p}_2}\\bigg) \\approx 0.\n\\] Now, in the first equation, the right-hand side contains an integral over \\(d^3 \\mathbf{x}_2\\). We can evidently add any total derivative that depends on \\(\\mathbf{x}_2\\) to the integrand since its integral will vanish. Let’s thus re-write \\[\n\\int d^3 \\mathbf{x}_2 d^3 \\mathbf{p}_2 \\ \\mathbf{F}_{2,1} \\cdot \\frac{\\partial f_2}{\\partial \\mathbf{p}_1} = \\int d^3 \\mathbf{x}_2 \\ d^3 \\mathbf{p}_2 \\ \\mathbf{F}_{2,1} \\cdot \\bigg(\\frac{\\partial f_2}{\\partial \\mathbf{p}_1} - \\frac{\\partial f_2}{\\partial \\mathbf{p}_2}\\bigg).\n\\] Since \\(\\boldsymbol{\\mathcal{x}} = \\mathbf{x}_2\\) we also must have \\(d^3 \\boldsymbol{\\mathcal{x}} = d^3 \\mathbf{x}_2\\). We can now see how to substitute in the second equation into the first. We have \\[\n\\frac{\\partial f_1}{\\partial t} + \\frac{\\mathbf{p}_1}{m} \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{x}_1} + \\mathbf{F}_1 \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{p}_1} = \\int d^3 \\boldsymbol{\\mathcal{x}} \\ d^3 \\mathbf{p}_2 \\ \\frac{\\mathbf{p}_2 - \\mathbf{p}_1}{m} \\cdot \\frac{\\partial f_2}{\\partial \\boldsymbol{\\mathcal{x}}}.\n\\] Note this equation is only true when we’re near equilibrium since we neglected the time derivative \\(\\frac{\\partial f_2}{\\partial t}\\). More correctly, this equation is valid when \\(t\\) is much larger than the interaction time \\(\\tau_{int}\\).\nAt this point it’s helpful to re-express the integral in terms of collision coordinates. The collision forces are felt inside some sphere of interaction radius \\(d\\). In the center of mass frame, two particles collide along the same line. If two particles with momenta \\(\\mathbf{p}_1\\) and \\(\\mathbf{p}_2\\) come in and collide along some line, they’ll exit the collision with some new momenta \\(\\mathbf{p}'_1\\) and \\(\\mathbf{p}'_2\\) along some other line. In an elastic collision both kinetic energy and momentum must be conserved. Define a parameter \\(a \\equiv \\frac{1}{m} |\\mathbf{p}_2 - \\mathbf{p}_1|\\) to represent the relative velocity between the two particles. Perpendicular to the \\(a\\) is a plane that can be specified by another vector \\(\\mathbf{b} \\equiv (b,\\vartheta)\\). This vector has a magnitude \\(b\\), called the impact parameter, equal to the perpendicular distance between the incoming trajectories in the center of mass frame. It also has an angle \\(\\vartheta\\) representing how the incoming momenta get rotated to the outgoing momenta in the collision.\n\n\n\n\n\nNow, in collision coordinates we can write \\(d^3 \\boldsymbol{\\mathcal{x}} = d^2 \\mathbf{b} \\ da\\). It turns out that if momentum is conserved, the collision itself doesn’t depend on \\(a\\), only \\(\\mathbf{b}\\). This means the integral \\(\\int da\\) just gives \\(a\\). If we further assume the collision happens almost at a single point, we can think of the gradient of \\(f_2\\) as the instantaneous change if \\(f_2\\) before and after the collision, i.e. \\[\n\\Delta f_2 \\equiv f_2(\\mathbf{x}'_1, \\mathbf{x}'_2, \\mathbf{p}'_1, \\mathbf{p}'_2,t) - f_2(\\mathbf{x}_1, \\mathbf{x}_2, \\mathbf{p}_1, \\mathbf{p}_2,t).\n\\] Plugging all this in, we thus have \\[\n\\frac{\\partial f_1}{\\partial t} + \\frac{\\mathbf{p}_1}{m} \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{x}_1} + \\mathbf{F}_1 \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{p}_1} = \\int d^3 \\mathbf{p}_2 \\ d^2 \\mathbf{b} \\ \\frac{|\\mathbf{p}_2 - \\mathbf{p}_1|}{m} \\cdot \\Delta f_2.\n\\] The last assumption we’ll make is perhaps the most important, since it’s the coarse-graining that leads to the second law of thermodynamics: the assumption of molecular chaos. For short-range interactions the density \\(f_2\\) mixes coordinates only inside the interaction radius \\(d\\). For distances much greater than \\(d\\) it’s a good assumption to say that \\(f_2\\) is a product of two one-particle densities, i.e. that the two particles’ states are statistically independent of each other. The assumption of molecular chaos says we send \\(d \\rightarrow 0\\), meaning we lose information about the nature of collisions and just assume particles collide at a single point. In this setting, we can globally assume that \\(f_2\\) factors into a product of one-particle densities \\[\nf_2(\\mathbf{x}_1, \\mathbf{x}_2, \\mathbf{p}_1, \\mathbf{p}_2,t) = f_1(\\mathbf{x}_1, \\mathbf{p}_1, t) f_1(\\mathbf{x}_2, \\mathbf{p}_2, t).\n\\] This means we can factor \\(\\Delta f_2\\) as well to get \\[\n\\Delta f_2 = f_1(\\mathbf{x}_1, \\mathbf{p}'_1, t) f_1(\\mathbf{x}_2, \\mathbf{p}'_2, t) - f_1(\\mathbf{x}_1, \\mathbf{p}_1, t) f_1(\\mathbf{x}_2, \\mathbf{p}_2, t).\n\\] Notice how the coordinates after collision are now assumed to be the same as the coordinates before collision. This is another consequence of course-graining away \\(d \\rightarrow 0\\). Plugging this result into the previous equation for \\(f_1\\) finally gives us the Boltzmann Equation, \\[\n\\begin{align*}\n&\\frac{\\partial f_1}{\\partial t} + \\frac{\\mathbf{p}_1}{m} \\cdot \\frac{\\partial f}{\\partial \\mathbf{x}_1} + \\mathbf{F}_1 \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{p}_1} = \\\\\n\\int d^3 \\mathbf{p}_2 \\ d^2 \\mathbf{b} \\ \\frac{|\\mathbf{p}_2 - \\mathbf{p}_1|}{m} &\\big[f_1(\\mathbf{x}_1, \\mathbf{p}'_1, t) f_1(\\mathbf{x}_2, \\mathbf{p}'_2, t) - f_1(\\mathbf{x}_1, \\mathbf{p}_1, t) f_1(\\mathbf{x}_2, \\mathbf{p}_2, t)\\big].\n\\end{align*}\n\\] Since we no longer need the higher particle densities we’ll from now on just write \\(f \\equiv f_1\\) and assume we’re working with one particle at a time. In this simplified notation we’ll write \\[\n\\boxed{\\frac{\\partial f}{\\partial t} + \\frac{\\mathbf{p}}{m} \\cdot \\frac{\\partial f}{\\partial \\mathbf{x}} + \\mathbf{F} \\cdot \\frac{\\partial f}{\\partial \\mathbf{p}} = \\frac{\\partial f}{\\partial t} \\bigg|_{\\text{col}}} \\ .\n\\] We can write the Boltzmann Equation even more succinctly by noting that the left-hand side is just a Liouville operator \\(L[f]\\) and defining a collision operator \\(C[f]\\) to represent the right-hand side. We then have \\[\n\\boxed{L[f] = C[f]} \\ .\n\\] Evidently, the Boltzmann equation looks like a modified Liouville equation with a non-zero right-hand side arising from a background of particles to collide with. The term \\(L[f]\\) characterizes the dynamics of particles with respect to the external forces alone, while \\(C[f]\\) characterizes the dynamics of particles due to their interactions with other particles.\n\n\nH-Theorem\nSince we’re neglecting dynamics on the scale of the interaction radius we’re losing information on the system’s microscopic dynamics. This means the Boltzmann equation also comes with a notion of increasing entropy. This result is called the H-Theorem (pronounced “Eta Theorem”).\nH-Theorem: Suppose \\(f(\\mathbf{x}, \\mathbf{p}, t)\\) satisfies the Boltzmann equation \\(L[f] = C[f]\\). Then there exists a quantity \\(\\mathrm{H}(t)\\) defined by \\[\n\\boxed{\\mathrm{H}(t) \\equiv \\int d^3 \\mathbf{x} \\ d^3 \\mathbf{p} \\ f(\\mathbf{x}, \\mathbf{p}, t) \\log f(\\mathbf{x}, \\mathbf{p}, t)}\n\\] such that \\(\\mathrm{H}(t)\\) is a decreasing function of time. That is, \\(\\frac{d\\mathrm{H}}{dt} \\leq 0\\).\nProof: We need to do is take the time derivative of \\(\\mathrm{H}(t)\\) and show its time derivative is negative. Differentiating both sides, we have \\[\n\\begin{align*}\n\\frac{d\\mathrm{H}}{dt} &= \\int d^3 \\mathbf{x} \\ d^3 \\mathbf{p} \\ \\frac{\\partial}{\\partial t}(f \\log f) \\\\\n&= \\int d^3 \\mathbf{x} \\ d^3 \\mathbf{p} \\ \\big(1 + \\log f \\big) \\frac{\\partial f}{\\partial t} \\\\\n&= \\int d^3 \\mathbf{x} \\ d^3 \\mathbf{p} \\ \\big(1 + \\log f \\big) \\big(C[f]-\\{f,H\\}\\big).\n\\end{align*}\n\\] The term involving \\(\\frac{\\partial}{\\partial t}(f \\log f)\\) just integrate to \\(N\\), a constant, and hence vanishes. Both integrals involving \\(\\{f,H\\}\\) vanish by the usual integration by parts argument. We’re thus left to calculate one term, \\[\n\\begin{align*}\n\\frac{d\\mathrm{H}}{dt} &= \\int d^3 \\mathbf{x} \\ d^3 \\mathbf{p} \\ \\log f \\ C[f] \\\\\n&= \\int d^3 \\mathbf{x}_1 \\ d^3 \\mathbf{p}_1 \\ d^3 \\mathbf{p}_2 d^2 \\mathbf{b} \\ \\frac{|\\mathbf{p}_2 - \\mathbf{p}_1|}{m} \\big[f(\\mathbf{p}'_1) f(\\mathbf{p}'_2) - f(\\mathbf{p}_1) f(\\mathbf{p}_2)\\big] \\log f(\\mathbf{p}_1).\n\\end{align*}\n\\] Here the dependence of \\(f\\) on position and time are suppressed for convenience. Now we’re going to make use of a trick. Notice the integral is symmetric in the momenta of particles \\(1\\) and \\(2\\). This means we can permute the indices and get the same answer. It also means we can average the two permutations. Though much less obvious, we can permute the primed and unprimed momenta as well since their Jacobian is \\(1\\). We can thus take the average of the primed and unprimed momenta as well. Using these facts, we have \\[\n\\begin{align*}\n\\frac{d\\Eta}{dt} &= \\int d^3 \\mathbf{x}_1 \\ d^3 \\mathbf{p}_1 d^3 \\mathbf{p}_2 d^2 \\mathbf{b} \\ \\frac{|\\mathbf{p}_2 - \\mathbf{p}_1|}{m} \\big[f(\\mathbf{p}'_1) f(\\mathbf{p}'_2) - f(\\mathbf{p}_1) f(\\mathbf{p}_2)\\big] \\log f(\\mathbf{p}_1) \\\\\n&= \\frac{1}{2}  \\int d^3 \\mathbf{x}_1 \\ d^3 \\mathbf{p}_1 d^3 \\mathbf{p}_2 d^2 \\mathbf{b} \\ \\frac{|\\mathbf{p}_2 - \\mathbf{p}_1|}{m} \\big[f(\\mathbf{p}'_1) f(\\mathbf{p}'_2) - f(\\mathbf{p}_1) f(\\mathbf{p}_2)\\big] \\log \\big(f(\\mathbf{p}_1) f(\\mathbf{p}_2)\\big) \\\\\n&= \\frac{1}{4} \\int d^3 \\mathbf{x}_1 \\ d^3 \\mathbf{p}_1 d^3 \\mathbf{p}_2 d^2 \\mathbf{b} \\ \\frac{|\\mathbf{p}_2 - \\mathbf{p}_1|}{m} \\big[f(\\mathbf{p}'_1) f(\\mathbf{p}'_2) - f(\\mathbf{p}_1) f(\\mathbf{p}_2)\\big] \\log \\bigg(\\frac{f(\\mathbf{p}_1)f(\\mathbf{p}_2)}{f(\\mathbf{p}'_1)f(\\mathbf{p}'_2)}\\bigg). \\\\\n\\end{align*}\n\\] Evidently, the integrand is proportional to a function of the form \\[\n-(f'_1 f'_2 - f_1 f_2) \\log \\bigg(\\frac{f'_1 f'_2}{f_1 f_2}\\bigg),\n\\] which is negative since the log is an increasing function of its arguments. This of course means the integral must be negative as well, i.e. \\(\\frac{d\\mathrm{H}}{dt} \\leq 0\\). \\(\\text{Q.E.D.}\\)\nThe quantity \\(\\mathrm{H}(t)\\) looks similar to the differential entropy of a continuous density function. It’s actually just a negative affine shift of the entropy of the one-particle density \\(f\\). In fact, for an \\(N\\)-particle system, we can relate the thermodynamic entropy of the system to \\(\\mathrm{H}\\) via \\(S \\equiv -k_B \\mathrm{H}\\). Thus, if \\(\\mathrm{H}\\) is a decreasing function, then \\(S\\) must be an increasing function, and vice versa.\n\n\nAside: Vlasov Equation\nWhat happens in the dense limit where \\(nd^3 \\gg 1\\)? In that case we can only say \\(\\tau_{\\text{int}} \\gg \\tau_X\\), which means we can drop the collision terms from the left-hand side of each BBGKY hierarchy. If we again assume each density \\(f_s\\) factors into a product of one-particle densities then it’ll turn out all the equations for \\(f_s\\) are equivalent, leaving a single equation to be satisfied, \\[\n\\boxed{\\frac{\\partial f}{\\partial t} + \\frac{\\mathbf{p}}{m} \\cdot \\frac{\\partial f}{\\partial \\mathbf{x}} + \\mathbf{F}_{\\text{eff}} \\cdot \\frac{\\partial f}{\\partial \\mathbf{p}} = 0} \\ ,\n\\] where \\(\\mathbf{F}_{\\text{eff}}\\) represents a kind of averaged background force on \\(f\\) given by \\[\n\\mathbf{F}_{\\text{eff}} \\equiv - \\frac{d}{d\\mathbf{x}} \\bigg(V(\\mathbf{x}) + \\int d^3\\mathbf{x}' d^3\\mathbf{p} \\ \\nu(\\mathbf{x}-\\mathbf{x}') f(\\mathbf{x}', \\mathbf{p}, t)\\bigg).\n\\] This is the Vlasov Equation. We can write the equation more succinctly by assuming an affective Hamiltonian \\(H_{\\text{eff}}\\) gives rise to the above dynamics. Then we’re back to Liouville’s equation, \\[\n\\frac{\\partial f}{\\partial t} + \\{f, H_{\\text{eff}}\\} = 0.\n\\] In this setting there’s in general no relaxation towards equilibrium. In fact, any function \\(f(\\mathbf{x},\\mathbf{p}) = g(\\mathbf{p})\\) is a valid steady state solution to the Vlasov equation. The Vlasov equation is used to characterize the behavior of plasmas. Typically when studying plasmas, one assumes the background forces are electromagnetic fields, in which case \\(\\mathbf{F}_{\\text{eff}}\\) just becomes the Lorentz force on each charged particle, \\[\n\\mathbf{F}_{\\text{eff}} = e\\mathbf{E} +  e\\frac{\\mathbf{v}}{c} \\times \\mathbf{B}.\n\\]",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Kinetic Theory</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/kinetic-theory.html#equilibrium",
    "href": "statistical-mechanics/kinetic-theory.html#equilibrium",
    "title": "Kinetic Theory",
    "section": "Equilibrium",
    "text": "Equilibrium\nWe’re now in a position to find what the density \\(f\\) has to be at equilibrium. Recall that the equilibrium distribution \\(f_{eq}\\) must satisfy the property that \\[\n\\frac{\\partial}{\\partial t} f_{eq}(\\mathbf{x}, \\mathbf{p}) = 0.\n\\] Using the Boltzmann equation and the H-theorem we can figure out what \\(f_{eq}\\) must be.\n\nEquilibrium Distributions\nSuppose \\(f\\) satisfies the Boltzmann equation. Let’s see if we can try to figure out what distribution \\(f\\) must have at equilibrium. At equilibrium we said we must have \\(\\frac{\\partial f}{\\partial t} = 0\\). As we saw, this is equivalent to requiring \\(\\frac{d\\mathrm{H}}{dt} = 0\\). For that to be true over any region of phase space as \\(t \\rightarrow \\infty\\), we must have the steady state requirement that \\[\n\\log \\bigg(\\frac{f(\\mathbf{x},\\mathbf{p}_1)f(\\mathbf{x},\\mathbf{p}_2)}{f(\\mathbf{x},\\mathbf{p}'_1)f(\\mathbf{x},\\mathbf{p}'_2)}\\bigg) = 0.\n\\] That is, for any position \\(\\mathbf{x}\\), \\[\n\\log f(\\mathbf{x}, \\mathbf{p}_1) + \\log f(\\mathbf{x},\\mathbf{p}_2) = \\log f(\\mathbf{x},\\mathbf{p}'_1) + \\log f(\\mathbf{x},\\mathbf{p}'_2).\n\\] This is a law of detailed balance, in that it states that some quantity before a collision must equal the same quantity after collision. Detailed balance evidently implies that the sum \\(\\log f(\\mathbf{x}, \\mathbf{p}_1) + \\log f(\\mathbf{x},\\mathbf{p}_2)\\) must be conserved during collisions. In an elastic collision we require that particle number, momentum and kinetic energy be conserved, \\[\n\\begin{align*}\n1 + 1 &= 1' + 1',\\\\\n\\mathbf{p}_1 + \\mathbf{p}_2 &= \\mathbf{p}'_1 + \\mathbf{p}'_2, \\\\ \\frac{\\mathbf{p}^2_1}{2m} + \\frac{\\mathbf{p}^2_2}{2m} &= \\frac{\\mathbf{p}'^{2}_1}{2m} + \\frac{\\mathbf{p}'^{2}_2}{2m}.\n\\end{align*}\n\\] It thus makes sense to suppose that in equilibrium each \\(\\log f(\\mathbf{x}, \\mathbf{p},t)\\) is only a quadratic function in \\(\\mathbf{p}\\). Suppose then that \\[\n\\log f(\\mathbf{x},\\mathbf{p}) \\equiv \\nu(\\mathbf{x}) + \\boldsymbol{\\alpha}(\\mathbf{x}) \\cdot \\mathbf{p} - \\beta(\\mathbf{x}) \\frac{\\mathbf{p}^2}{2m}.\n\\] By completing the square and exponentiating, we can write the density in the form \\[\nf(\\mathbf{x}, \\mathbf{p}) = \\mathcal{N}(\\mathbf{x}) \\exp\\bigg(-\\frac{\\beta(\\mathbf{x})}{2m}(\\mathbf{p}-\\boldsymbol{\\pi}(\\mathbf{x}))^2\\bigg).\n\\] However, this equation doesn’t solve the entire Boltzmann equation. It only solves the equation \\(C[f] = 0\\). We still need to impose that \\(L[f] = 0\\) as well. If we like, we can add to the kinetic energy an external potential energy \\(V(\\mathbf{x})\\) that represents, for example, the walls of a box of fixed volume. Then \\[\nH(\\mathbf{x},\\mathbf{p}) = \\frac{\\mathbf{p}^2}{2m} + V(\\mathbf{x}).\n\\] To satisfy \\(L[f] = 0\\), we saw that \\(f\\) must be conserved under \\(H\\), i.e. \\(\\{f, H\\} = 0\\). This also must be true for any other quantity conserved under \\(H\\), in this case the momentum vector \\(\\mathbf{p}\\) and particle number \\(1\\). Enforcing that all these Poisson brackets vanish then forces \\(\\mathcal{N}\\), \\(\\beta\\), and \\(\\boldsymbol{\\pi}\\) to all be constant. The final equilibrium one-particle density for a gas is thus just a Gaussian in the momentum \\(\\mathbf{p}\\), \\[\n\\boxed{f_{eq}(\\mathbf{x}, \\mathbf{p}) = n(\\mathbf{x}, t) \\bigg(\\frac{\\beta}{2\\pi m}\\bigg)^{3/2} \\exp\\bigg(-\\frac{\\beta}{2m}(\\mathbf{p}-\\boldsymbol{\\pi})^2\\bigg)} \\ .\n\\] Here \\(n\\) is just the number density \\(n(\\mathbf{x}, t)\\), representing the fact that \\(f\\) isn’t normalized over the volume of the box. This can also be written in the form \\[\nf_{eq}(\\mathbf{x}, \\mathbf{p}) \\propto e^{-\\beta H(\\mathbf{x},\\mathbf{p})}.\n\\] This is called the Boltzmann Distribution. We’ll see it derived again when we get to statistical mechanics. This distribution describes how the energy of a closed system is distributed in equilibrium.\n\n\nIdeal Gas\nSuppose we’re dealing with a stationary gas of free particles, so \\(\\boldsymbol{\\pi} = \\mathbf{0}\\) and \\(V(\\mathbf{x}) = 0\\) inside the box. Then \\[\n\\rho_{eq}(\\mathbf{p}) = \\bigg(\\frac{\\beta}{2\\pi m}\\bigg)^{3/2} \\exp\\bigg(-\\frac{\\beta}{2m}\\mathbf{p}^2\\bigg).\n\\] Since this is an uncorrelated Gaussian, we can read off that each component of \\(\\mathbf{p}\\) has variance \\(\\langle p_i^2 \\rangle = \\frac{m}{\\beta}\\). The variance of \\(\\mathbf{p}\\) is thus evidently just \\[\n\\langle \\mathbf{\\mathbf{p}}^2 \\rangle = \\langle p_x^2 \\rangle + \\langle p_y^2 \\rangle + \\langle p_z^2 \\rangle = \\frac{3m}{\\beta}.\n\\] Plugging this into the Hamiltonian we can find an expression for the average internal kinetic energy of a free gas at equilibrium. We have \\[\nE \\equiv \\langle H \\rangle = \\frac{\\langle \\mathbf{p}^2 \\rangle}{2m} = \\frac{3}{2\\beta} = \\frac{3}{2} k_B T.\n\\] Evidently, a gas of free particles in a box is just the ideal gas, with \\(\\beta = \\frac{1}{k_B T}\\).\nIf we like we can also find the equation of state by calculating the force exerted on the walls of the box. To do that, let’s look at the force exerted on one of the walls of the box, say the wall on the positive x-axis. Evidently the number of particles \\(\\delta N_x\\) with momentum \\(p_x = mv_x\\) that collide with the wall in a time \\(\\delta t\\) is given by density times volume, i.e. \\[\n\\delta N_x = d^3 \\mathbf{p} \\ f(\\mathbf{p}) \\ A v_x \\delta t.\n\\] Assuming each collision is elastic, the momentum change in colliding with the wall is \\(\\Delta p_x = 2p_x\\). Then the force \\(F\\) exerted on the wall is \\[\nF = \\frac{1}{2\\delta t} \\int \\delta N_x \\ \\Delta p_x = \\int d^3 \\mathbf{p} \\ f(\\mathbf{p}) \\ A \\frac{p_x^2}{m}.\n\\] Using this force on the wall we can calculate the pressure of the gas by dividing by the wall area \\(A\\). Plugging in the distribution for momenta, we have \\[\nP = \\int d^3 \\mathbf{p} \\ f(\\mathbf{p}) \\ \\frac{p_x^2}{m} = \\int d^3 \\mathbf{p} \\ \\frac{p_x^2}{m} n\\bigg(\\frac{\\beta}{2\\pi m}\\bigg)^{3/2} \\exp\\bigg(-\\frac{\\beta}{2m}\\mathbf{p}^2\\bigg) = \\frac{n}{\\beta}.\n\\] Using the fact that \\(n = \\frac{N}{V}\\) and \\(\\beta = \\frac{1}{k_B T}\\), we’ve evidently derived the ideal gas law, \\[\nPV = N k_B T.\n\\] Insisting a free gas reduce to an ideal gas at equilibrium again supports that \\(\\beta = \\frac{1}{k_B T}\\).\nIf desired, one can calculate the entropy too by using \\(S \\equiv -k_B \\mathrm{H}\\) and doing the integral for \\(\\mathrm{H}\\). The result will be (up to an additive constant) the entropy for a monoatomic ideal gas. ### Maxwell-Boltzmann Distribution\nWe can also ask about the distribution for the speed \\(v\\) of an ideal gas at equilibrium. Using the relation \\(\\mathbf{p} = m \\mathbf{v}\\), we then have \\[\n\\rho_{eq}(\\mathbf{v}) = \\bigg(\\frac{m}{2\\pi k_B T}\\bigg)^{3/2} \\exp\\bigg(-\\frac{m\\mathbf{v}^2}{2k_B T}\\bigg).\n\\] This is the distribution for the velocity of a gas in the rest frame, not the speed. It’s evidently a mean-zero Gaussian distribution with variance \\(\\frac{k_B T}{m}\\). The ratio \\(v_{th}^2 \\equiv \\frac{k_B T}{m}\\) has dimensions of velocity squared. That velocity \\(v_{th}\\) is amply referred to as the root mean square (RMS) velocity. We’ve actually seen it already. It’s the velocity one gets from setting the kinetic energy equal to the mean thermal energy \\(k_B T\\). Practically all velocities of interest in thermodynamics are on the order of the RMS velocity.\nAnyway, notice the distribution depends only on the speed since \\(v^2 = \\mathbf{v}^2\\). It may seem like the distribution for \\(v\\) should be a Gaussian, but it’s not. The reason is we have to integrate over the volume element, \\[\n1 = \\int d^3 \\mathbf{v} \\ \\rho_{eq}(\\mathbf{v}) = \\int v^2 dv d\\Omega \\ \\rho_{eq}(|\\mathbf{v}|) = \\int dv \\ 4\\pi v^2\\rho_{eq}(|\\mathbf{v}|) \\equiv \\int dv \\ \\rho_{eq}(v).\n\\] This distribution for the particle speeds at equilibrium is called the Maxwell-Boltzmann Distribution, \\[\n\\boxed{\\rho_{eq}(v) = \\bigg(\\frac{m}{2\\pi k_B T}\\bigg)^{3/2} 4\\pi v^2 \\exp\\bigg(-\\frac{mv^2}{2k_B T}\\bigg)} \\ .\n\\] Since speeds are non-negative this is a rightward-skewed distribution. This means its mean won’t be zero like with the vector velocities. This makes sense, as a mean zero speed would imply the particles aren’t moving at all. In fact, the mean speed is proportional to the RMS velocity, \\[\n\\langle v \\rangle = 2\\sqrt{\\frac{2}{\\pi}} \\sqrt{\\frac{k_B T}{m}} \\approx 1.6 \\ v_{th}.\n\\]",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Kinetic Theory</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/kinetic-theory.html#conservation-laws",
    "href": "statistical-mechanics/kinetic-theory.html#conservation-laws",
    "title": "Kinetic Theory",
    "section": "Conservation Laws",
    "text": "Conservation Laws\nSo far all we’ve done is derived the equilibrium distribution for a gas at equilibrium. But we don’t need kinetic theory to do this. As we’ll see, we can do that much more easily using statistical mechanics. What kinetic theory is really useful for is describing how the system approaches equilibrium. Specifically, what we really want to know is how the usual conserved quantities like particle number, energy, and momentum approach equilibrium. To do that we need to figure out what the dynamics are of conserved quantities.\n\nCollision-Conserved Quantities\nWe’ll specifically want to focus on collision conserved quantities. The ones that satisfy detailed balance conditions. We say \\(\\chi\\) is a collision conserved quantity if for any two colliding particles we have \\[\n\\chi_1 + \\chi_2 = \\chi'_1 + \\chi'_2.\n\\] A collision conserved quantity satisfies the useful property that the quantity \\(J(\\mathbf{x},t)\\) defined by \\[\nJ(\\mathbf{x},t) \\equiv \\int d^3 \\mathbf{p} \\ \\chi(\\mathbf{x}, \\mathbf{p},t) C[f]\n\\] vanishes. To see why, just substitute in the integral for \\(C[f]\\) and perform the same steps used in the proof of the H-theorem. Doing those manipulations with \\(\\log f\\) replaced by \\(\\chi\\) will give an integral of the form \\[\nJ(\\mathbf{x},t) = \\frac{1}{4} \\int d^3 \\mathbf{p}_1 \\ d^3 \\mathbf{p}_2 \\ \\frac{|\\mathbf{p}_2 - \\mathbf{p}_1|}{m} \\big[f(\\mathbf{p}_1)f(\\mathbf{p}_2)-f(\\mathbf{p}'_1)f(\\mathbf{p}'_2)\\big] \\big[\\chi(\\mathbf{p}_1) + \\chi(\\mathbf{p}_2) - \\chi(\\mathbf{p}'_1) - \\chi(\\mathbf{p}'_2)\\big].\n\\]\nProvided \\(\\chi\\) is a collision-conserved quantity the last term is zero, hence we get \\(J(\\mathbf{x},t) = 0\\).\nNow, notice if the system satisfies the Boltzmann equation we can replace \\(C[f]\\) with \\(L[f]\\) in the integral, \\[\n0 = \\int d^3 \\mathbf{p} \\ \\chi \\ L[f] = \\int d^3 \\mathbf{p} \\ \\chi \\ \\bigg(\\frac{\\partial}{\\partial t} + \\frac{\\mathbf{p}}{m} \\cdot \\frac{\\partial }{\\partial \\mathbf{x}} + \\mathbf{F} \\cdot \\frac{\\partial}{\\partial \\mathbf{p}} \\bigg) f.\n\\] We can manipulate this expression to get a useful differential equation for the field \\(\\chi(\\mathbf{x},t)\\). Since \\(L\\) is an operator of first derivatives we can apply the product rule to write \\[\n\\chi \\cdot L[f] = L[f \\cdot \\chi] - f \\cdot L[\\chi].\n\\] Plugging this in, we get \\[\n0 = \\int d^3 \\mathbf{p} \\ \\bigg[\\bigg(\\frac{\\partial (f \\cdot \\chi)}{\\partial t} + \\frac{\\mathbf{p}}{m} \\cdot \\frac{\\partial (f \\cdot \\chi)}{\\partial \\mathbf{x}} + \\mathbf{F} \\cdot \\frac{\\partial (f \\cdot \\chi)}{\\partial \\mathbf{p}} \\bigg) - \\bigg(\\frac{\\partial \\chi}{\\partial t} + \\frac{\\mathbf{p}}{m} \\cdot \\frac{\\partial \\chi}{\\partial \\mathbf{x}} + \\mathbf{F} \\cdot \\frac{\\partial \\chi}{\\partial \\mathbf{p}} \\bigg) f \\bigg].\n\\] At this point it’s useful to define a collision average. Notice the number density can be given by marginalizing out the momentum, \\[\nn(\\mathbf{x}, t) = \\int d^3 \\mathbf{p} \\ f(\\mathbf{x}, \\mathbf{p}, t).\n\\] Using this fact, we can define a collision average on any phase space function \\(\\chi\\) by \\[\n\\boxed{\\big\\langle \\chi(\\mathbf{x},t) \\big\\rangle_{c} \\equiv \\frac{1}{n(\\mathbf{x}, t)} \\int d^3 \\mathbf{p} \\ f(\\mathbf{x}, \\mathbf{p}, t) \\ \\chi(\\mathbf{x}, \\mathbf{p}, t)} \\ .\n\\] Going back to our expression for \\(J(\\mathbf{x},t)\\), notice we can pull any terms and derivatives that doesn’t depend on \\(\\mathbf{p}\\) out of the integral. The terms remaining under the integral can then be written as collision averages, \\[\n\\boxed{\\frac{\\partial}{\\partial t} n\\big\\langle \\chi \\big\\rangle_{c} + \\frac{\\partial}{\\partial \\mathbf{x}} \\cdot n\\bigg\\langle \\frac{\\mathbf{p}}{m} \\chi \\bigg\\rangle_{c} - \\ n \\bigg\\langle \\frac{\\partial \\chi}{\\partial t} \\bigg\\rangle_{c} - \\ n \\bigg\\langle \\frac{\\mathbf{p}}{m} \\cdot\\frac{\\partial \\chi}{\\partial \\mathbf{x}}\\bigg\\rangle_{c} - n \\mathbf{F} \\cdot \\bigg\\langle \\frac{\\partial \\chi}{\\partial \\mathbf{p}}\\bigg\\rangle_{c} = 0 } \\ .\n\\] Note the integral over \\(\\mathbf{F} \\cdot \\frac{\\partial (f \\cdot \\chi)}{\\partial \\mathbf{p}}\\) vanishes since it’s a total time derivative. The above equation is called the hydrodynamics equation or the conservation law for the field \\(\\chi(\\mathbf{x},t)\\). Unlike typical conservation laws in classical mechanics, these conservation laws are local.\n\n\nParticle Number\nThe particular conservation laws we’ll focus on are the usual ones for a gas: particle number (or mass), momentum, and kinetic energy. To find the conservation law for particle number or mass, take \\(\\chi = 1\\). In that case, all the derivatives of \\(\\chi\\) vanish, so we’re left with \\[\n\\frac{\\partial n}{\\partial t} + \\frac{\\partial}{\\partial \\mathbf{x}} n\\bigg\\langle \\frac{\\mathbf{p}}{m} \\bigg\\rangle_{c} = 0.\n\\] The collision average of \\(\\frac{\\mathbf{p}}{m}\\) gives some kind of velocity field \\(\\mathbf{u}(\\mathbf{x},t)\\). This is the flow velocity of the gas, treated as a kind of continuous fluid. We can thus write \\[\n\\boxed{\\frac{\\partial n}{\\partial t} + \\nabla \\cdot n \\mathbf{u}  = 0} \\ .\n\\] This is the well-known continuity equation, in this case for the particle number.\nThis says that at any region of space, particle number must be conserved. To see why, if we integrate the equation with respect to volume and use the divergence theorem, we have \\[\n\\frac{d}{dt} \\int_\\mathcal{V} d^3 \\mathbf{x} \\ n = \\int_\\mathcal{S} n \\mathbf{u} \\cdot d\\mathbf{a}.\n\\] That is, the only way particle number inside a region \\(\\mathcal{V}\\) can change is by flowing out of its surface \\(\\mathcal{S}\\). Over all space, the right-hand side must vanish for physical reasons, which just says total particle number is conserved, \\[\n\\frac{dN}{dt} = 0.\n\\] The same equation holds for mass density \\(\\rho \\equiv mn\\) by multiplying both sides of the continuity equation by the mass \\(m\\). In that language it expresses the conservation of mass for the gas. It’s sometimes useful to re-write the continuity equation in terms of the material derivative. To do that we need to factor out the \\(\\mathbf{u}\\) from the divergence using the product rule. We then get \\[\n\\boxed{\\frac{Dn}{Dt} = -n \\nabla \\cdot \\mathbf{u}} \\ .\n\\] This form is particularly useful when dealing with an incompressible fluid, since in that case \\(\\nabla \\cdot \\mathbf{u} = 0\\), implying the fluid has uniform density. Incompressible fluids are more characteristic of liquids than gases, however, since we can practically always compress a gas by applying pressure to it.\n\n\nMomentum\nThe next conservation law we’ll derive is conservation of momentum. Rather than take \\(\\chi\\) to be the momentum \\(\\mathbf{p}\\) directly, it’s more useful to take it to be the relative particle velocity \\[\n\\mathbf{c} \\equiv \\frac{\\mathbf{p}}{m} - \\mathbf{u}.\n\\] Let’s apply the conservation law to one of the components of \\(\\mathbf{c}\\) by taking \\(\\chi = c_\\alpha\\). This definition has the advantage that \\(\\langle c_\\alpha \\rangle_{c}\\) vanishes, which simplifies calculations somewhat. Noting that \\(\\frac{\\mathbf{p}}{m} = \\mathbf{c} + \\mathbf{u}\\), and using the summation convention, we have $$ \\[\\begin{align*}\n0 &= \\frac{\\partial}{\\partial x_\\beta} n\\bigg\\langle \\frac{p_\\beta}{m} c_\\alpha \\bigg\\rangle_c - \\ n \\bigg\\langle \\frac{\\partial c_\\alpha}{\\partial t} \\bigg\\rangle_c - \\ n \\bigg\\langle \\frac{p_\\beta}{m} \\frac{\\partial c_\\alpha}{\\partial x_\\beta}\\bigg\\rangle_c - n F_\\beta \\cdot \\bigg\\langle \\frac{\\partial c_\\alpha}{\\partial p_\\beta}\\bigg\\rangle_c \\\\\n\n&= \\frac{\\partial}{\\partial x_\\beta} n\\bigg\\langle (c_\\beta+u_\\beta) c_\\alpha \\bigg\\rangle_c - \\ n \\bigg\\langle \\frac{\\partial c_\\alpha}{\\partial t} \\bigg\\rangle_c - \\ n \\bigg\\langle (c_\\beta+u_\\beta) \\frac{\\partial c_\\alpha}{\\partial x_\\beta}\\bigg\\rangle_c - n F_\\beta \\cdot \\bigg\\langle \\frac{\\partial c_\\alpha}{\\partial p_\\beta}\\bigg\\rangle_c \\\\\n&= \\frac{\\partial}{\\partial x_\\beta} n \\big\\langle c_\\alpha c_\\beta \\big\\rangle_c + n \\frac{\\partial u_\\alpha}{\\partial t} + n u_\\beta \\frac{\\partial u_\\alpha}{\\partial x_\\beta} - n F_\\beta \\frac{\\delta_{\\alpha\\beta}}{m} \\\\\n&= \\frac{\\partial}{\\partial x_\\beta} nm \\big\\langle c_\\alpha c_\\beta \\big\\rangle_c + nm \\frac{\\partial u_\\alpha}{\\partial t} + nm u_\\beta \\frac{\\partial u_\\alpha}{\\partial x_\\beta} - n F_\\alpha.\n\\end{align*}\\] $$\nWe evidently have a differential equation for the flow velocity \\(\\mathbf{u}\\). The only unfamiliar term is the first one, which is evidently the gradient of a symmetric rank-two tensor. This is the pressure tensor, defined by \\[\nP_{\\alpha\\beta} \\equiv nm \\big\\langle c_\\alpha c_\\beta \\big\\rangle_c \\ , \\quad \\text{or} \\quad \\mathbf{P} \\equiv nm\\langle \\mathbf{c} \\otimes \\mathbf{c} \\rangle_c \\ .\n\\] Plugging the pressure tensor in and re-arranging, we see that each component of the flow velocity satisfies a conservation law of the form \\[\n\\frac{\\partial u_\\alpha}{\\partial t} + u_\\beta \\frac{\\partial u_\\alpha}{\\partial x_\\beta} = \\frac{F_\\alpha}{m} - \\frac{1}{nm} \\frac{\\partial P_{\\alpha\\beta}}{\\partial x_\\beta}.\n\\] If we think of the velocity gradient as being done component-wise and the divergence on the right as a contraction over one of the indices, then we can write this conservation law in vector notation as \\[\n\\boxed{nm \\frac{D \\mathbf{u}}{Dt} = n \\mathbf{F} - \\nabla \\cdot \\mathbf{P}} \\ .\n\\] This is called the Cauchy momentum equation. Notice how this conservation law looks something like Newton’s second law. On the left is a kind of mass times acceleration term, while on the right are the two kinds of forces acting on each gas particle, the external forces and the internal pressure-driven forces.\n\n\nEnergy\nThe final conservation law we’ll consider is the one for kinetic energy. Again, it’s convenient to look instead at the relative kinetic energy \\(\\chi = \\frac{1}{2} m \\mathbf{c}^2\\). Define the energy density or the heat flux \\(\\varepsilon\\) to be the collision average of the relative kinetic energy, \\[\n\\varepsilon \\equiv \\frac{1}{2} m \\big\\langle \\mathbf{c}^2 \\big\\rangle_c.\n\\] It’s also helpful to define a vector \\(\\mathbf{h}\\) called the heat flux given by \\[\n\\mathbf{h} \\equiv \\frac{1}{2} nm \\big\\langle \\mathbf{c}^2 \\mathbf{c} \\big\\rangle_c.\n\\] Last, it’s helpful to define another symmetric rank-two tensor \\(\\mathbf{U}\\) called the rate of strain tensor. Its components are the symmetrized gradients of \\(\\mathbf{c}\\), i.e. \\[\nU_{\\alpha\\beta} \\equiv \\frac{\\partial u_\\alpha}{\\partial x_\\beta} + \\frac{\\partial u_\\beta}{\\partial x_\\alpha}.\n\\] With these definitions, after a lot of tedious work we can express the conservation law for kinetic energy in component form (again using the summation convention) as \\[\n\\frac{\\partial \\varepsilon}{\\partial t} + u_\\alpha \\frac{\\partial \\varepsilon}{\\partial x_\\alpha}  = -\\frac{1}{n}\\frac{\\partial h_\\alpha}{\\partial x_\\alpha} - \\frac{1}{n}P_{\\alpha\\beta} U_{\\alpha\\beta} \\ .\n\\] The first term on the right is the divergence of the heat flux. The second term is the trace over the matrix product of the pressure tensor with the rate of strain. With this in mind, we can express this equation in vector notation as \\[\n\\boxed{n\\frac{D\\varepsilon}{Dt} = -\\nabla \\cdot \\mathbf{h} - \\text{tr}(\\mathbf{P} \\cdot \\mathbf{U})} \\ .\n\\] Roughly speaking, this conservation law expresses the first law of thermodynamics. The left-hand-side is the change in the total energy, while the right-hand side is the change in heat plus the change in work.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Kinetic Theory</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/kinetic-theory.html#approach-to-equilibrium",
    "href": "statistical-mechanics/kinetic-theory.html#approach-to-equilibrium",
    "title": "Kinetic Theory",
    "section": "Approach to Equilibrium",
    "text": "Approach to Equilibrium\nAs was already mentioned, our whole purpose in deriving collision conserved quantities and conservation laws was to study how systems approach equilibrium. To do this we’ll want to study the solutions of the conservation laws as \\(t \\rightarrow \\infty\\). To approach equilibrium, each conserved quantity should approach a constant value, its equilibrium value.\n\nZeroth-Order Solutions\nWhile all these conservation equations are nice, we still don’t know how to solve them. To do that we’d need to know the pressure tensor and the heat flux, both of which require that we already know the density. Usually we don’t know the full density. What we’ll try to do instead is expand the density in terms of the parameter \\(\\frac{\\tau_X}{\\tau_{\\text{ext}}}\\), the characteristic inverse time scale of \\(L[f]\\). In the limit where external forces act on much larger time scales than the collision forces this parameter will be small.\nLet’s start by calculating the zeroth order density \\(f^0\\). In the zeroth order case we’re assuming \\(\\tau_{\\text{ext}} \\rightarrow \\infty\\), hence \\(C[f^0] = 0\\). We already saw using detailed balance that such a distribution is just a Gaussian in terms of the momenta or velocity. If we write \\[\n\\mathbf{c}(\\mathbf{x}, t) = \\mathbf{p} - m\\mathbf{u}(\\mathbf{x}, t) = \\mathbf{p} - \\boldsymbol{\\pi}(\\mathbf{x}, t),\n\\] and choose \\(\\beta = \\frac{1}{k_B T}\\) as before, then the zeroth order distribution can be written as \\[\nf^0(\\mathbf{x}, \\mathbf{p}, t) \\equiv n(\\mathbf{x}, t)\\bigg(\\frac{m}{2\\pi k_B T(\\mathbf{x}, t)}\\bigg)^{3/2} \\exp\\bigg(-\\frac{m\\mathbf{c}^2}{2k_B T(\\mathbf{x}, t)}\\bigg).\n\\] This is a mean-zero Gaussian distribution in \\(\\mathbf{c}\\) with variance \\(\\frac{k_B T}{m}\\). Let’s assume this is the density and see what we can deduce about the conservation laws and how they approach equilibrium.\nSince we’re dealing with a Gaussian, we can use Wick’s theorem to conclude the odd-power moments are zero. This means that the heat flux vanishes, since \\[\n\\mathbf{h} = \\frac{1}{2} nm \\big\\langle \\mathbf{c}^2 \\mathbf{c} \\big\\rangle_c = \\mathbf{0} .\n\\] The pressure tensor, however, is an even moment. Since the covariance of \\(f^0\\) is diagonal, we just have \\[\n\\mathbf{P} = nm \\big\\langle \\mathbf{c} \\otimes \\mathbf{c} \\big\\rangle_c = nm \\frac{k_B T}{m} \\ \\mathbf{1} = nk_B T \\ \\mathbf{1}.\n\\] Last, the energy density is just \\[\n\\varepsilon = \\frac{m}{2} \\big\\langle \\mathbf{c}^2 \\big\\rangle_c = \\frac{m}{2} \\frac{3k_B T}{m} = \\frac{3}{2} k_B T.\n\\]\nTogether, these mean that the three conservation laws can be written as \\[\n\\begin{align*}\n\\frac{Dn}{Dt} &= -n \\nabla \\cdot \\mathbf{u}  \\\\\n\\frac{D\\mathbf{u}}{Dt} &= \\frac{1}{m} \\mathbf{F} -\\frac{k_B}{nm} \\nabla nT  \\\\\n\\frac{DT}{Dt} &= -\\frac{2}{3} T \\ \\nabla \\cdot \\mathbf{u} \\ \\ . \\\\\n\\end{align*}\n\\] Let’s try to combine the first and last equation and see what we get. Notice both terms contain a divergence \\(\\nabla \\cdot \\mathbf{u}\\). If we solve for the divergence in the first equation and plug it into the third, we get \\[\n\\begin{align*}\n&\\frac{DT}{Dt} = -\\frac{2}{3} T \\ \\nabla \\cdot \\mathbf{u} = \\frac{2T}{3n} \\frac{Dn}{Dt} \\\\\n&\\Longrightarrow \\quad \\frac{3}{2} \\frac{D}{Dt} \\log T - \\frac{D}{Dt} \\log n = 0 \\\\\n&\\Longrightarrow \\quad \\frac{D}{Dt} \\log n T^{-3/2} = 0.\n\\end{align*}\n\\] That is, along any given streamline the quantity \\(\\log n T^{-3/2}\\) is constant. This quantity is a kind of local entropy since \\(dS \\sim \\log n T^{-3/2} d^3 \\mathbf{x}\\). We’ve thus shown that the zeroth order solution implies \\(dS=0\\), i.e. the entire process is adiabatic for all time. This in particular means entropy can’t increase to a maximum, which implies that the system will never come to equilibrium unless it starts out in equilibrium. Evidently the zeroth order approximation isn’t enough to get equilibrium. We’ll need to go further.\nLet’s look at this more formally first. For the system to always converge to equilibrium the solutions need to be stable. That is, if any conserved quantity is nudged from equilibrium it should relax back to equilibrium. Suppose the system is initially in equilibrium. Suppose we make the following first-order perturbations, \\[\n\\begin{align*}\nn(\\mathbf{x}, t) &= n_0 + \\nu(\\mathbf{x}, t) \\\\\nT(\\mathbf{x}, t) &= T_0 + \\theta(\\mathbf{x}, t) \\ . \\\\\n\\end{align*}\n\\] For simplicity, assume no external forces act inside the box and at equilibrium the box is at rest. In that case, to first order \\(\\frac{D}{Dt} \\approx \\frac{\\partial}{\\partial t}\\). Plugging these into the conservation laws and keeping only terms to first order, we get \\[\n\\begin{align*}\n\\frac{\\partial\\nu}{\\partial t} &\\approx -n_0 \\nabla \\cdot \\mathbf{u}  \\\\\n\\frac{\\partial\\mathbf{u}}{\\partial t} &\\approx -\\frac{k_B T_0}{mn_0} \\nabla \\nu - \\frac{k_B}{m} \\nabla \\theta \\\\\n\\frac{\\partial\\theta}{\\partial t} &\\approx -\\frac{2}{3} T_0 \\ \\nabla \\cdot \\mathbf{u} \\ \\ . \\\\\n\\end{align*}\n\\]\nNow let’s Fourier transform these first order quantities and look at their normal modes. The natural frequencies \\(\\omega(\\mathbf{k})\\) and the normal modes are the solutions to the following eigenvalue equation, \\[\n\\begin{pmatrix}\n0 & n_0 \\mathbf{k} & 0 \\\\\n\\frac{k_B T_0}{mn_0} \\mathbf{k} & 0 & \\frac{k_B}{m} \\mathbf{k}  \\\\\n0 & \\frac{2}{3} T_0 \\mathbf{k} & 0 \\\\\n\\end{pmatrix}\n\\begin{pmatrix}\n\\tilde \\nu \\\\\n\\mathbf{\\tilde u} \\\\\n\\tilde \\theta \\\\\n\\end{pmatrix} =\n\\omega\n\\begin{pmatrix}\n\\tilde \\nu \\\\\n\\mathbf{\\tilde u} \\\\\n\\tilde \\theta \\\\\n\\end{pmatrix}.\n\\] Note the block notation being used. This is really a \\(5 \\times 5\\) matrix multiplying a size \\(5\\) vector. There are thus \\(5\\) distinct normal modes that satisfy this equation. To get the modes we need to solve the characteristic equation, which turns out to be \\[\n\\text{det}(\\mathbf{A} - \\omega \\mathbf{I}) = \\omega^3\\bigg(\\omega^2 - \\frac{5k_B T_0}{3m} \\bigg) = 0.\n\\]\n\nThe first mode is a stationary mode, one of the zero modes with \\(\\omega = 0\\). The modes themselves are \\[\n\\tilde\\nu = \\text{const}, \\quad \\mathbf{\\tilde u} = \\mathbf{0}, \\quad \\tilde \\theta = \\text{const},\n\\] meaning that the fluid is essentially stationary for all frequencies. This implies the fluid maintains uniform pressure \\(P = n k_B T_0\\), which ensures that the fluid can’t start moving due to pressure variations since \\(\\Delta S \\sim nT_0\\) is constant.\nThe next two modes are sound modes, where \\(\\omega = \\pm v_s |\\mathbf{k}|\\). Here \\(v_s\\) is the speed of sound of the fluid, given by \\[\nv_s \\equiv \\sqrt{\\frac{\\gamma k_B T_0}{m}}, \\quad \\text{where} \\quad \\gamma = \\frac{5}{3}\n\\] is the adiabatic constant for a monoatomic ideal gas. Sound modes represent pressure waves propagating outward forever without damping. All of the conserved quantities propagate as longitudinal waves along the \\(\\mathbf{k}\\) direction, since \\[\n\\tilde\\nu = n_0 |\\mathbf{k}|, \\quad \\mathbf{\\tilde u} = \\pm v_s \\mathbf{k}, \\quad \\tilde\\theta = \\frac{2}{3} T_0 |\\mathbf{k}|.\n\\]\nThe last two modes are shearing modes. These are also zero modes with \\(\\omega = 0\\), but they correspond to motion in the transverse directions orthogonal to \\(\\mathbf{k}\\). This means we’d have \\[\n\\tilde \\nu = \\text{const}, \\quad \\mathbf{\\tilde u} \\cdot \\mathbf{k} = 0, \\quad \\tilde \\theta = \\text{const}.\n\\] Transverse motions in a fluid create a shearing effect. Since \\(\\mathbf{\\tilde u}\\) stays constant for shearing modes, each quantity will just continue forever without damping.\n\nWe thus find that none of the conserved quantities relax to equilibrium to zeroth-order. Shear flow and entropy modes persist forever, while the two sound modes have undamped oscillations. Since none of the normal modes in general relax to equilibrium, neither will any general solutions, which are themselves just superpositions of normal modes.\n\n\nFirst-Order Solutions\nWe thus have to move onto first order solutions. Instead of assuming an infinite \\(\\tau_{\\text{ext}}\\), we’ll assume it’s small to first order compared to \\(\\tau_X\\). This brings the left-hand side \\(L[f]\\) of Boltzmann’s equation back into the game. We’ll assume a first-order density of the form \\[\nf^1(\\mathbf{x}, \\mathbf{p}, t) = f^0(\\mathbf{x}, \\mathbf{p}, t) \\big(1 + g(\\mathbf{x}, \\mathbf{p}, t)\\big),\n\\] where \\(g(\\mathbf{x}, \\mathbf{p}, t)\\) is assumed to be related to the inverse time scale \\(\\frac{\\tau_X}{\\tau_{\\text{ext}}} \\ll 1\\). To evaluate \\(C[f^1]\\) we have to linearize the integral. To do so we’ll employ the single collision time approximation, which says that \\[\nC[f^1] \\approx -f^0 \\frac{g}{\\tau_X}.\n\\] If we assume \\(g\\) is in some sense small, then \\(L[f^1] = L[f^0]+L[f^0g]] \\approx L[f^0]\\). We thus have that \\[\nL[f^0] \\approx -f^0 \\frac{g}{\\tau_X},\n\\] Using the expression for \\(f^0\\) found already, this means \\[\ng = - \\tau_X L[\\log f^0] = - \\tau_X L\\bigg[\\log \\bigg(n\\bigg(\\frac{m}{2\\pi k_B T}\\bigg)^{3/2} \\exp\\bigg(-\\frac{m\\mathbf{c}^2}{2k_B T}\\bigg)\\bigg)\\bigg].\n\\] Now, observe we can re-write the Liouville operator in a more useful way in terms of \\(\\mathbf{u}\\) instead of \\(\\mathbf{p}\\) as \\[\nL[f] = \\frac{Df}{Dt} + \\mathbf{c} \\cdot \\frac{\\partial f}{\\partial \\mathbf{x}} + \\mathbf{F} \\cdot \\frac{\\partial f}{\\partial \\mathbf{p}}.\n\\] Combining all of these facts together and using the zeroth-order conservation laws we already derived, we finally get \\[\n\\begin{align*}\ng &= -\\tau_X \\ L[\\log f^0] \\\\\n&= -\\tau_X \\ L\\bigg[\\log n - \\frac{3}{2} \\log \\frac{2\\pi k_B T}{m} - \\frac{mc^2}{2 k_B T} \\bigg] \\\\\n&= -\\tau_X \\ \\bigg(\\frac{D}{Dt} + \\mathbf{c} \\cdot \\frac{\\partial}{\\partial \\mathbf{x}} + \\mathbf{F} \\cdot \\frac{\\partial}{\\partial \\mathbf{p}}\\bigg)\\bigg[\\log n - \\frac{3}{2} \\log \\frac{2\\pi k_B T}{m} - \\frac{mc^2}{2 k_B T} \\bigg] \\\\\n&= -\\tau_X \\bigg[\\frac{m}{k_B T} U_{ij} \\bigg(c_i c_j - \\frac{c^2}{3} \\delta_{ij}\\bigg) + \\bigg(\\frac{m c^2}{2k_B T} - \\frac{5}{2} \\bigg) \\frac{c_i}{T} \\frac{\\partial T}{\\partial x_i}\\bigg]. \\\\\n\\end{align*}\n\\] This means the first-order density in full is given in vector notation as \\[\n\\begin{align*}\nf^1(\\mathbf{x}, \\mathbf{p},t) = \\ &n\\bigg(\\frac{m}{2\\pi k_B T}\\bigg)^{3/2} \\exp\\bigg(-\\frac{m\\mathbf{c}^2}{2k_B T}\\bigg) \\ \\times \\\\\n&\\bigg\\{1 -\\tau_X \\bigg[\\frac{m}{k_B T}\\text{tr}\\bigg( \\mathbf{U} \\cdot \\bigg(\\mathbf{c} \\otimes \\mathbf{c} - \\frac{c^2}{3} \\mathbf{I}\\bigg)\\bigg) + \\bigg(\\frac{m c^2}{2k_B T} - \\frac{5}{2} \\bigg) \\mathbf{c} \\cdot \\frac{\\nabla T}{T} \\bigg]\\bigg\\}.\n\\end{align*}\n\\] The term involving the trace of velocities represents the correlation of particle velocity with the rate of strain tensor. It describes how velocities vary due to fluid strain. The term involving the temperature gradient says something about how velocities depend on temperature gradients across the fluid. Together, these effects give the density an anisotropic, multimodal behavior.\nAfter some work, it turns out that integrating \\(f^1\\) again gives the particle density, \\[\nn(\\mathbf{x},t) = \\int d^3 \\mathbf{p} \\ f^1(\\mathbf{x}, \\mathbf{p}, t).\n\\] We can more quickly calculate the first-order collision averages in terms of the zeroth-order averages as \\[\n\\langle \\chi(\\mathbf{x},t) \\rangle_c^1 = \\frac{1}{n(\\mathbf{x},t)} \\int d^3 \\mathbf{p} \\ \\chi(\\mathbf{x},t) f^0(\\mathbf{x}, \\mathbf{p}, t)\\big(1+g(\\mathbf{x}, \\mathbf{p}, t)\\big) = \\big\\langle \\chi(\\mathbf{x},t) \\big\\rangle_c^0 + \\big\\langle g(\\mathbf{x}, t) \\chi(\\mathbf{x},t) \\big\\rangle_c^0 \\ .\n\\] All quantities of interest involve calculating moments of \\(\\mathbf{c}\\). Notice that the first-order correction now contains terms proportional to both \\(c\\) and \\(c^3\\), which means the first and third moments no longer vanish. Together, these will imply the existence of a non-zero heat flux vector and a non-diagonal pressure tensor. We can use Wick’s theorem to calculate these values to eventually get \\[\n\\begin{align*}\n\\mathbf{P} &= nm \\langle \\mathbf{c}\\otimes\\mathbf{c} \\rangle_c^1 = nk_B T \\bigg[\\mathbf{1} - 2 \\tau_X \\bigg(\\mathbf{U} - \\frac{u^2}{3} \\mathbf{1}\\bigg)\\bigg], \\\\\n\\varepsilon &= \\frac{1}{2} m \\langle c^2 \\rangle_c^1 = \\frac{3}{2} k_B T, \\\\\n\\mathbf{h} &= \\frac{1}{2} mn \\langle c^2 \\mathbf{c} \\rangle_c^1 = -\\frac{5 \\tau_X nk_B^2 T}{2m} \\nabla T.\n\\end{align*}\n\\] The coefficient \\(\\mu \\equiv nk_B T \\tau_X\\) in the off diagonals of the pressure tensor is the viscosity coefficient. The off-diagonals cause the fluid to shear against opposing viscous forces that go like \\(\\mu \\nabla^2 \\mathbf{u}\\). Similarly, the coefficient \\(K \\equiv \\frac{5 \\tau_X nk_B^2 T}{2m}\\) is the thermal conductivity coefficient of the gas. In particular, when the gas is at rest and the pressure is uniform, we get \\[\n\\frac{\\partial T}{\\partial t} = \\alpha \\nabla^2 T,\n\\] which is a classic diffusion equation for the temperature, called the Fourier equation. Recall that solutions to diffusion equations will always settle down into an equilibrium state as \\(t \\rightarrow \\infty\\). The diffusion coefficient \\[\n\\alpha(T) \\equiv \\frac{2K}{3nk_B} = \\frac{5\\tau_X k_B T}{3m}\n\\] characterizes the inverse time scale over which the temperature relaxes to its equilibrium temperature. For variations on distance scales of \\(\\lambda\\), the heat equation relaxes on a time scale of \\[\n\\tau_{\\text{diff}} \\sim \\frac{\\lambda^2}{\\alpha}.\n\\] The fluid velocity relaxes according to a similar diffusion equation brought on by the shearing in the pressure tensor.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Kinetic Theory</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/classical-stat-mech.html",
    "href": "statistical-mechanics/classical-stat-mech.html",
    "title": "Classical Statistical Mechanics",
    "section": "",
    "text": "Formal Definition\nSuppose we have a system of \\(N\\) particles in equilibrium whose phase space configuration is described by a microstate \\(\\boldsymbol{\\mu} \\equiv \\{\\mathbf{x}_i, \\mathbf{p}_i\\}\\) . Suppose we’re interested in studying some set of macroscopic equilibrium properties described by a macrostate \\(M=(E,X,N)\\). For a given macrostate \\(M\\), suppose the equilibrium phase space density for the system to be in some microstate \\(\\boldsymbol{\\mu}\\) is given by a probability distribution \\(p_M(\\boldsymbol{\\mu})\\). Let’s define statistical mechanics as the probabilistic study of the equilibrium macrostates \\(M\\) of a system with a large number of degrees of freedom \\(N \\gg 1\\) using the equilibrium probability distribution \\(p_M(\\boldsymbol{\\mu})\\).\nRecall that to be in equilibrium the phase space density should be time independent. By Liouville’s equation, this means \\[\n\\frac{\\partial}{\\partial t} p_M(\\boldsymbol{\\mu}) = -\\{p_M(\\boldsymbol{\\mu}), H\\} = 0.\n\\] In general this will be true so long as \\(p_M(\\boldsymbol{\\mu})\\) is an explicit function only of the Hamiltonian \\(H(\\boldsymbol{\\mu})\\) and possibly any other conserved quantities. If there are no other conserved quantities then the equilibrium distribution should be an explicit function of \\(H(\\boldsymbol{\\mu})\\) alone, i.e. \\[\np_M(\\boldsymbol{\\mu}) \\equiv p_M(H(\\boldsymbol{\\mu})).\n\\] In statistical mechanics we’re primarily interested in probability distributions corresponding to specific classes of system constraints, or ensembles. We’ll focus on the following ensembles, each of which corresponds to a conserved free energy.\nAll of these distributions arise from the principle of maximum entropy given certain known constraints, particularly the assumption that the expected values of zero or more quantities are given. We’ll study the implications of each ensemble one at a time and discuss when to use which for a given problem.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Classical Statistical Mechanics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/classical-stat-mech.html#formal-definition",
    "href": "statistical-mechanics/classical-stat-mech.html#formal-definition",
    "title": "Classical Statistical Mechanics",
    "section": "",
    "text": "The microcanonical ensemble: \\(p_M(\\boldsymbol{\\mu}) \\propto \\delta(H(\\boldsymbol{\\mu}) - E)\\). This corresponds to the energy \\(E\\) being conserved.\nThe canonical ensemble: \\(p_M(\\boldsymbol{\\mu}) \\propto e^{-\\beta H(\\boldsymbol{\\mu})}\\). This corresponds to the Hemlholtz free energy \\(F\\) being conserved.\nThe Gibbs canonical ensemble: \\(p_M(\\boldsymbol{\\mu}) \\propto e^{-\\beta (H(\\boldsymbol{\\mu}) - J \\cdot X)}\\). This corresponds to the Gibbs free energy \\(G\\) being conserved.\nThe grand canonical ensemble: \\(p_M(\\boldsymbol{\\mu}) \\propto e^{-\\beta (H(\\boldsymbol{\\mu}) - \\mu \\cdot N)}\\). This corresponds to the grand potential \\(\\mathcal{G}\\) being conserved.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Classical Statistical Mechanics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/classical-stat-mech.html#microcanonical-ensemble",
    "href": "statistical-mechanics/classical-stat-mech.html#microcanonical-ensemble",
    "title": "Classical Statistical Mechanics",
    "section": "Microcanonical Ensemble",
    "text": "Microcanonical Ensemble\nSuppose we have an isolated system, where the macrostate \\(M=(E,X,N)\\) is assumed to be constant. This is called the microcanonical ensemble. The corresponding probability distribution is given by the assumption of a-priori probability. We assume all microstates are equally likely so long as \\(M\\) stays fixed. More specifically, the probability distribution is assumed to be uniform on phase space manifolds of constant energy, \\[\n\\boxed{\np(\\boldsymbol{\\mu}) = \\frac{1}{\\Omega(M)} \\delta\\big(H(\\boldsymbol{\\mu}) - E\\big)\n} \\ ,\n\\] The variable \\(\\Omega(M)\\) is some normalization constant ensuring the probability integrates to one. In fact, it’s just a count of the total number of microstates corresponding to the macrostate \\(M\\). We’ll call it the multiplicity. The multiplicity also corresponds to the surface area of the phase space manifold of constant energy \\(E\\), \\[\n\\boxed{\\Omega(M) = \\int_{H(\\boldsymbol{\\mu})=E} d \\boldsymbol{\\mu}} \\ .\n\\] Given the probability distribution, we can calculate the thermodynamic entropy using the formula \\(S = -k_B \\langle \\log p \\rangle\\), \\[\n\\begin{align*}\nS(M) &= -k_B \\int d \\boldsymbol{\\mu} \\ p(\\boldsymbol{\\mu}) \\log p(\\boldsymbol{\\mu}) \\\\\n&= k_B \\int_{H(\\mathbf{x},\\mathbf{p})=E} d \\boldsymbol{\\mu} \\ \\frac{\\log \\Omega(M)}{\\Omega(M)} \\\\\n&= k_B \\log \\Omega(M). \\\\\n\\end{align*}\n\\] That is, the entropy is simply proportional to the logarithm of the number of microstates, \\[\n\\boxed{\nS = k_B \\log \\Omega\n} \\ .\n\\]\n\nLaws of Thermodynamics\nWith a probability distribution and a definition of entropy in hand, we can proceed to derive almost all of the laws of thermodynamics from the assumption of a microcanonical ensemble. Let’s start with the zeroth law.\nZeroth Law: Suppose two otherwise isolated systems \\(A\\) and \\(B\\) are in thermal contact with each other and allowed to exchange energy. When they both reach equilibrium, there will be some temperature function such that \\(T = T_A = T_B\\).\nProof: Suppose system \\(A\\) has energy \\(E_A\\) and system \\(B\\) has energy \\(E_B\\). The entire system \\(A+B\\) is isolated, which means it has some constant energy that must be given by \\(E = E_A + E_B\\). The multiplicity of the full system is just the product of multiplicities of each subsystem, integrated over all energies that sum up to \\(E\\). That is, \\[\n\\Omega(E) = \\int_{E=E_A+E_B} dE \\ \\Omega(E_A) \\Omega(E_B) = \\int dE_A \\ \\Omega(E_A) \\Omega(E-E_A).\n\\] We can write this in terms of entropies as well. We have \\[\n\\Omega(E) = \\int dE_A \\ e^{\\frac{1}{k_B} S_A} e^{\\frac{1}{k_B} S-S_A} = \\int dE_A \\ e^{\\frac{1}{k_B}(S_A+S_B)}\n\\] Now, entropy is an extensive quantity, meaning \\(S \\propto N\\). Since \\(N\\) is large we can employ the saddlepoint approximation, evaluating the integrand at the energies \\(E_A^*\\) and \\(E_B^*\\) that maximize the total entropy to get \\[\n\\Omega(E) \\approx e^{\\frac{1}{k_B} \\big(S(E_A^*) + S(E_B^*)\\big)}.\n\\] This maximum must occur when the partial derivatives at the maximum energies vanish, i.e. \\[\n\\frac{\\partial }{\\partial E_A} S(E_A^*) \\bigg|_{X,N} - \\frac{\\partial }{\\partial E_B} S(E_B^*) \\bigg|_{X,N} = 0.\n\\] When \\(A\\) and \\(B\\) are in equilibrium, the total entropy \\(S\\) must be maximized, meaning the partial derivatives must be equal. This condition defines a function whose values must equal at equilibrium, which by convention is the inverse temperature, \\[\n\\frac{1}{T} \\equiv \\frac{\\partial S}{\\partial E_A} \\bigg|_{X,N} = \\frac{\\partial S}{\\partial E_B} \\bigg|_{X,N}. \\quad \\text{Q.E.D.}\n\\] Notice in the above proof that we paid no attention to how the system reached equilibrium, only that it did eventually reached equilibrium, meaning that it satisfies the microcanonical probability distribution. Let’s look now at the first law.\nFirst Law: Consider a system having some form of mechanical work done on it by a force \\(J\\). It’s also allowed to exchange particles with the environment via a chemical potential \\(\\mu\\). If the force causes a differential displacement \\(dX\\) and \\(dN\\) particles are exchanged, then the total change in energy is given in differential form by \\[\ndE = TdS + J \\cdot dX + \\mu \\cdot dN.\n\\] Proof: Let’s calculate the change in the system’s entropy when a differential amount of work is done on the system. The amount of work done on a system in response to a displacement \\(\\delta X\\) and particle exchange \\(\\delta N\\) is given by \\[\n\\delta E = J \\cdot \\delta X + \\mu \\cdot \\delta N.\n\\] Suppose the system is initially at a constant energy \\(E\\) and increased by \\(\\delta E\\). Then to first order we have \\[\n\\begin{align*}\n\\delta S &= S(E+\\delta E, X+\\delta X, N+\\delta N) - S(E,X,N) \\\\\n&= \\frac{\\partial S}{\\partial E} \\bigg|_{X,N} (J \\cdot \\delta X + \\mu \\cdot \\delta N) + \\frac{\\partial S}{\\partial X} \\bigg|_{E,N} \\delta X + \\frac{\\partial S}{\\partial N} \\bigg|_{E,X} \\delta N \\\\\n&= \\bigg(\\frac{J}{T} - \\frac{\\partial S}{\\partial X} \\bigg|_{E,N}\\bigg)\\delta X + \\bigg(\\frac{N}{T} - \\frac{\\partial S}{\\partial N} \\bigg|_{E,X}\\bigg)\\delta N. \\\\\n\\end{align*}\n\\] Now, at equilibrium we must have \\(\\delta S = 0\\) for any \\(\\delta X\\) and \\(\\delta N\\). This means each term must vanish, giving \\[\n\\delta S = \\frac{1}{T} \\delta E - \\frac{J}{T} \\delta X - \\frac{\\mu}{T} \\delta N. \\quad \\text{Q.E.D.}\n\\] Using the first law, we can now find any other thermodynamic quantity of interest once we have the entropy. We have \\[\n\\begin{align*}\n\\frac{1}{T} &= \\frac{\\partial S}{\\partial E} \\bigg |_{X,N} \\ , \\\\\n-\\frac{J}{T} &= \\frac{\\partial S}{\\partial X} \\bigg |_{E,N} \\ , \\\\\n-\\frac{\\mu}{T} &= \\frac{\\partial S}{\\partial N} \\bigg |_{E,X} \\ . \\\\\n\\end{align*}\n\\] This gives us a sort of recipe we can use to calculate equations of state for systems in the microcanonical ensemble:\n\nCalculate \\(\\Omega(E,X,N)\\) and use that to get the entropy via \\(S = k_B \\log \\Omega\\).\nUse the first law to get other thermodynamic variables of interest via \\[\ndS =  \\frac{1}{T} dE -  \\frac{J}{T} \\cdot dX - \\frac{\\mu}{T} \\cdot dN.\n\\]\n\nThe second law is trivial. We’ve essentially already proved it.\nSecond Law: The entropy of a system is non-decreasing over time.\nProof: We’ve already shown this. For any two subsystems \\(A\\) and \\(B\\), suppose they start with energies \\(E_A^0\\) and \\(E_B^0\\). Over time the system will move to equilibrium to reach a maximum entropy, with energies of \\(E_A^*\\) and \\(E_B^*\\). It must be the case then that \\[\nS(E_A) + S(E_B) \\leq S(E_A^*) + S(E_B^*). \\quad \\text{Q.E.D.}\n\\]\nIt turns out that we can’t derive the third law from classical statistical mechanics alone. For that we’ll need quantum statistical mechanics, a topic we’ll get to later. Let’s go ahead and also check the stability conditions though while we’re here. For entropy to be maximized at equilibrium, we require the entropy near equilibrium to be concave, i.e. \\[\n\\frac{\\partial^2}{\\partial E_A^2} S(E_A^*) \\bigg|_{X,N} - \\frac{\\partial^2}{\\partial E_B^2} S(E_B^*) \\bigg|_{X,N} \\leq 0.\n\\] Using the same logic as we did in the thermodynamics lesson, we can then show this implies the heat capacity of the system be non-negative. Moreover, the requirement that any second-order perturbations be non-positive requires \\(\\frac{\\partial^2 S}{\\partial X_i \\partial X_j}\\) to be positive-definite at any constant energy \\(E\\).\n\n\nExample: Two-State Systems\nLet’s consider a simple example of a system we can actually solve in the microcanonical ensemble, indeed one of the few we can solve. Suppose we have a collection of particles that can take on only one of two states. We can imagine only caring about the spin of an electron, for example, in which case the two states would be spin-up and spin-down for each electron. Since there are only two states we can’t really think in terms of phase space in this case, so we have to cheat a bit. We’ll just sum over all states instead of integrating over phase space.\nSuppose each particle can take on an energy of the form \\(\\varepsilon n_i\\) where \\(n_i=0,1\\). That is, the particle has no energy if the state is down and a constant \\(\\varepsilon\\) energy if the spin is up. Then for \\(N\\) particles the Hamiltonian will just be the sum of all these energies, \\[\nH = \\sum_{i=0}^N \\varepsilon n_i \\equiv \\varepsilon N_1.\n\\] On the right we just defined \\(N_1\\) to be the total number of all states that are up. In the microcanonical we assert that \\(H\\) is held to a constant energy \\(E\\). This means we can also write \\(N_1 = \\frac{E}{\\varepsilon}\\).\nNow, to find \\(\\Omega(E,N)\\) observe the following fact: The number of total states with energy \\(E\\) is equivalent to the number of ways of choosing exactly \\(N_1\\) particles with state up out of a total of \\(N\\) particles. Assuming both \\(N\\) and \\(N_1\\) are large, we have \\[\n\\Omega(E,N) = \\binom{N}{N_1} = \\frac{N_1!}{N_1!(N-N_1)!} \\approx \\frac{N^N}{N_1^{N_1}(N-N_1)^{N-N_1}} \\ .\n\\] The entropy of such a system is thus \\[\n\\begin{align*}\nS &= k_B \\log \\Omega(E) \\\\\n&= k_B \\bigg[\\log N - \\frac{N_1}{N}\\log N_1 - \\frac{N-N_1}{N}\\log (N-N_1) \\bigg] \\\\\n&= -Nk_B \\bigg[\\frac{E}{N\\varepsilon}\\log\\frac{E}{N\\varepsilon} + \\bigg(1-\\frac{E}{N\\varepsilon}\\bigg) \\log \\bigg(1-\\frac{E}{N\\varepsilon}\\bigg) \\bigg].\n\\end{align*}\n\\] From this we can get the temperature in terms of the energy, \\[\n\\frac{1}{T} = \\frac{\\partial S}{\\partial E} \\bigg |_N = \\frac{k_B}{\\varepsilon} \\log \\frac{E}{N\\varepsilon-E}.\n\\] If we like, we can then solve for the energy in terms of the temperature to get \\[\nE(T) = \\frac{N\\varepsilon}{1 + e^{\\frac{\\varepsilon}{k_B T}}}.\n\\] One interesting property of the two-state system is that it can in principle take on negative temperatures. This comes from the fact that the energy \\(E\\) can take on any value between \\(0\\) (all states down) and \\(N\\varepsilon\\) (all states up). Having \\(E \\leq \\frac{1}{2} N\\varepsilon\\) corresponds to positive temperatures, while having \\(E \\geq \\frac{1}{2} N\\varepsilon\\) corresponds to negative temperatures. Negative temperatures are counter-intuitive since they implies that entropy increases when energy is taken out of the system, not put in. In practice this isn’t an issue, since the system must always be in thermal contact with a heat bath, which forces it to have positive temperature.\nIf we like we can use \\(E(T)\\) to calculate the heat capacity by differentiating with respect to \\(T\\), \\[\nC(T) = \\frac{\\partial E}{\\partial T} \\bigg |_{N} = Nk_B \\bigg(\\frac{\\varepsilon}{k_B T}\\bigg)^2 \\frac{e^{\\frac{\\varepsilon}{k_B T}}}{\\big(1 + e^{\\frac{\\varepsilon}{k_B T}}\\big)^2}.\n\\] By looking at the limited cases where \\(\\varepsilon \\ll k_B T\\) and \\(\\varepsilon \\gg k_B T\\), it’s easy to see that \\(C(T) \\rightarrow 0\\) both as \\(T \\rightarrow 0\\) and as \\(T \\rightarrow \\infty\\). Vanishing at low temperatures has to do with the discrete energy gap for each particle, while vanishing at high temperatures has to do with energy saturation due to the finite number of states allowed.\nNotice that if we divide \\(E\\) by \\(\\varepsilon\\) what’s left is dimensionless. In fact, it’s just the mean number of particles with state up, i.e. \\[\n\\langle n \\rangle = \\frac{N}{1 + e^{\\frac{\\varepsilon}{k_B T}}}.\n\\] It’s also worth asking what \\(p(n)\\) is, the probability for a given particle to be up or down. Evidently that probability should be \\(p(0) = \\frac{N-N_1}{N}\\) and \\(p(1) = \\frac{N_1}{N}\\). Plugging in \\(N_1 = \\frac{E(T)}{\\varepsilon}\\), we can write the expression as \\[\np(n) = \\delta(n) \\frac{1}{1 + e^{-\\frac{\\varepsilon}{k_B T}}} + \\delta(n-1) \\frac{e^{-\\frac{\\varepsilon}{k_B T}}}{1 + e^{-\\frac{\\varepsilon}{k_B T}}}.\n\\] The shape of this curve depends on the temperature. At low temperatures \\(p(0) \\approx 1\\). At high temperatures \\(p(1) \\approx 1\\). And when \\(\\varepsilon \\approx k_B T\\) we get \\(p(0) \\approx p(1) \\approx \\frac{1}{2}\\).",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Classical Statistical Mechanics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/classical-stat-mech.html#distinguishability",
    "href": "statistical-mechanics/classical-stat-mech.html#distinguishability",
    "title": "Classical Statistical Mechanics",
    "section": "Distinguishability",
    "text": "Distinguishability\nWe’d like to use the microcanonical ensemble to work out the relations for a more interesting system, like an ideal gas. It turns out however that there’s some subtly involved that we need to address in applying statistical mechanics to realistic systems.\n\nExample: Ideal Gas\nLet’s start by trying to derive the ideal gas expressions using only what we’ve covered so far and seeing where things go wrong. Suppose an isolated system of gas particles has the non-interacting Hamiltonian for an ideal gas, namely \\[\nH(\\mathbf{x}_1,\\cdots,\\mathbf{x}_N,\\mathbf{p}_1,\\cdots,\\mathbf{p}_N) = \\sum_{i=1}^N \\frac{\\mathbf{p}_i^2}{2m} + V(\\mathbf{x}_1,\\cdots,\\mathbf{x}_N),\n\\] where the potential energy \\(V(\\mathbf{x}_1,\\cdots,\\mathbf{x}_N)\\) is zero inside a container of volume \\(V\\) and infinite otherwise. To calculate the equations of state we first need to find \\(\\Omega(E,V,N)\\). Integrating over the volume of the box and all valid momenta, we get \\[\n\\Omega(E,V,N) = \\int_{\\frac{\\mathbf{p}^2}{2m} = E} d^{3N} \\mathbf{x} \\ d^{3N} \\mathbf{p} = V^N  \\int_{|\\mathbf{p}| = \\sqrt{2mE}} d^{3N} \\mathbf{p} \\equiv V^N \\Sigma_{3N}.\n\\] The integral \\(\\Sigma_{3N}\\) is the surface area of a \\(3N\\)-dimensional hypersphere in momentum space of radius \\(R=\\sqrt{2mE}\\).\nTo make anymore progress we need to figure out what the surface area of a \\(d\\)-dimensional hypersphere is. Now, notice we can write the \\(d\\)-dimensional volume element as \\(d^d \\mathbf{x} = R^{d-1} dR \\ d\\Omega_{d-1}\\), where \\(d\\Omega_{d-1}\\) is the \\(d-1\\) dimensional solid angle. For a hypersphere we can factor the integral. If \\(S_d \\equiv \\int d\\Omega_{d-1}\\), then we have \\(\\Sigma_{d} = S_d R^{d-1}\\). Here \\(S_d\\) is a constant that depends only on the dimension \\(d\\). To find \\(S_d\\), the trick is to use the fact that the integral of a \\(d\\)-dimensional Gaussian is just \\[\nI_d \\equiv \\int d^d \\mathbf{x} \\ e^{-\\mathbf{x}^2} = \\bigg(\\int dx \\ e^{-x^2}\\bigg)^d = \\pi^{d/2}.\n\\] By changing variables to spherical coordinates, it’s easy to show \\[\nI_d = \\int R^{d-1} dR \\ d\\Omega_{d-1} \\ e^{-R^2} = \\frac{1}{2} \\bigg(\\frac{d}{2}-1\\bigg)! \\ S_d.\n\\] Equating the two expressions, we can solve for \\(S_d\\) and finally get the surface area of a \\(d\\)-dimensional hypersphere, \\[\n\\Sigma_d = \\frac{2\\pi^{d/2}}{\\big(\\frac{d}{2}-1\\big)!} R^{d-1}.\n\\] Back to the problem at hand. Plugging all this in, we finally get a multiplicity of \\[\n\\Omega(E,V,N) = \\frac{2\\pi^{\\frac{3N}{2}}}{\\big(\\frac{3N}{2}-1\\big)!} V^N (2mE)^{\\frac{3N-1}{2}} \\approx 2 V^N \\bigg(\\frac{4\\pi m E}{3N}\\bigg)^{3N/2}.\n\\] The right–hand side is simplified using Stirling’s approximation \\(N! \\sim N^N e{-N}\\). The entropy is then \\(S = k_B \\log \\Omega\\). If we ignore terms of order less than \\(O(N)\\), up to an added constant we get the same result we found using kinetic theory, namely \\[\nS = Nk_B \\log V\\bigg(\\frac{4\\pi emE}{3N}\\bigg)^{3/2}.\n\\] Aside: Suppose we didn’t know the energy \\(E\\) exactly, but only within some range \\(E \\pm \\delta E\\). In that case, the hypersphere radius would have an uncertainty \\(\\delta R = \\sqrt{\\frac{m}{2E}} \\delta E\\). The effect of this is that \\(\\Omega\\) now gains a multiplicative factor of \\(\\delta R\\). This causes the entropy to then gain an additive factor of \\(k_B \\log \\delta R \\propto \\log \\frac{\\delta E}{\\sqrt{E}}\\). Since energy is extensive, this new added factor will be \\(O(\\log N)\\), which is small compared to the original terms of \\(O(N)\\), and can hence be neglected. The net effect of all this is that none of the thermodynamic variables get materially affected by the uncertainty. For this reason we’ll ignore it from now on.\nUsing the entropy we can now proceed to calculate the temperature, pressure, and chemical potential. The equation for temperature gives the usual energy relation for a monoatomic ideal gas, \\[\n\\frac{1}{T} = \\frac{\\partial S}{\\partial E} \\bigg |_{X,N} = \\frac{3Nk_B}{2E} \\quad \\Longrightarrow \\quad E = \\frac{3}{2} Nk_B T.\n\\] The equation for the pressure gives the usual ideal gas law, \\[\nP = T \\frac{\\partial S}{\\partial V} \\bigg |_{E,N} = \\frac{Nk_B T}{V} \\quad \\Longrightarrow \\quad PV = Nk_B T.\n\\] Both of these seem perfectly fine. The problem, however, comes when we try to evaluate the chemical potential. We’d get \\[\n\\mu = -T \\frac{\\partial S}{\\partial N} \\bigg |_{E,V} = - k_B T \\bigg[\\log V\\bigg(\\frac{4\\pi mE}{3N}\\bigg)^{3/2} - \\frac{3}{2} \\bigg].\n\\] Now, the problem here is that the chemical potential should be intensive, but it’s not. It’s proportional to \\(\\log V\\). The same problem showed up in the entropy as well. The entropy should be extensive, yet it’s proportional to \\(V\\log N\\). It seems like we should have to divide by something else extensive inside the logarithm to cancel the effect of the \\(V\\).\n\n\nGibbs’ Paradox\nTo resolve this issue let’s look at another toy problem. Consider the mixing entropy of a container containing two distinct ideal gases of different types. Suppose the container initially split into two components, the first a gas with configuration \\((S_1,N_1,V_1)\\) and the second a gas with configuration \\((S_2,N_2,V_2)\\). Assume the system is at equilibrium, so both systems have the same temperature \\(T\\). An adiabatic wall is then removed, so the two gases are allowed to mix and come to a new equilibrium of the same temperature. The initial total entropy \\(S_i\\) in the container is evidently given by \\(S_i = S_1 + S_2\\), i.e. \\[\nS_i = k_B \\bigg( N_1 \\log V_1 + \\frac{3}{2} N_1 \\log 2\\pi e m_1 k_B T\\bigg) + k_B \\bigg(N_2 \\log V_2 + \\frac{3}{2} N_2 \\log 2\\pi e m_2 k_B T\\bigg),\n\\] where we’ve used the fact that \\(E = \\frac{3}{2} N k_B T\\). To find the final total entropy \\(S_f\\), observe that at the new equilibrium both gases should fill up the entire box uniformly, meaning \\(V_1 = V_2 = V\\), hence \\[\nS_f = k_B \\bigg( N_1 \\log V + \\frac{3}{2} N_1 \\log 2\\pi e m_1 k_B T\\bigg) + k_B \\bigg(N_2 \\log V + \\frac{3}{2} N_2 \\log 2\\pi e m_2 k_B T\\bigg).\n\\] All together, this means the change in total entropy is given by \\[\n\\Delta S = S_f - S_i = k_B \\bigg(N_1 \\log \\frac{V}{V_1} + N_2 \\log \\frac{V}{V_2}\\bigg).\n\\] So what’s the problem here? Well, suppose the two gases were the same, and we opened the adiabatic wall and allowed them to mix? What should happen physically? Nothing. They’re the same gas, at the same temperature. The thermodynamic variables shouldn’t change at all, meaning we should have \\(\\Delta S = 0\\). On the other hand, if the two gases were distinct, we should expect the total entropy of the system to increase like shown. This conundrum is known as the Gibbs Paradox.\nThe solution to this paradox is to notice that we have to treat identical systems separately from distinguishable systems. If a system is distinguishable we’re fine as is. But if a system is identical we have to account for the fact that we’re overcounting \\(\\Omega\\) any time we count two identical systems as distinct. The way to fix this is pretty easy. Just divide \\(\\Omega\\) by the number of ways to permute the particles in each identical system.\nTo resolve the above paradox and the issue with extensively, notice that if we have an ideal gas of \\(N\\) particles then we’re overcounting \\(\\Omega\\) by a factor of \\(N!\\), the number of ways to permute a set of \\(N\\) identical particles. Then \\(\\Omega\\) for an ideal gas becomes \\[\n\\Omega(E,V,N) = \\frac{V^N}{N!}\\frac{2\\pi^{\\frac{3N}{2}}}{\\big(\\frac{3N}{2}-1\\big)!} (2mE)^{\\frac{3N-1}{2}} \\approx 2\\bigg(\\frac{Ve}{N}\\bigg)^N \\bigg(\\frac{4\\pi m E}{3N}\\bigg)^{3N/2}.\n\\] This means the entropy \\(S\\) then becomes \\[\nS = Nk_B \\bigg[\\log \\frac{V}{N}\\bigg(\\frac{4\\pi mE}{3N}\\bigg)^{3/2} + \\frac{5}{2}\\bigg],\n\\] and hence that the chemical potential \\(\\mu\\) becomes \\[\n\\mu = - k_B T \\log \\frac{V}{N}\\bigg(\\frac{4\\pi mE}{3N}\\bigg)^{3/2}.\n\\] Now it appears that we’re dividing \\(V\\) by \\(\\frac{N}{e}\\) inside the logarithm, which makes \\(S\\) is properly extensive and \\(\\mu\\) properly intensive.\nTo resolve the Gibbs paradox, notice that if the two gases are distinct, we have to divide \\(\\Omega\\) by \\(N_1!N_2!\\). This ultimately gives \\[\n\\Delta S = k_B \\bigg(N_1 \\log \\frac{V}{V_1} + N_2 \\log \\frac{V}{V_2}\\bigg),\n\\] which is of course what we had before. If the two gases are identical, we instead have to divide \\(\\Omega\\) by \\(N!\\). This ultimately gives \\[\n\\Delta S = k_B \\bigg[(N_1+N_2) \\log \\frac{V}{N_1+N_2} - N_1 \\log \\frac{V_1}{N_1} - N_2 \\log \\frac{V_2}{N_2}\\bigg] = 0\n\\] since at equilibrium (both initially and finally) we must have \\(\\frac{V}{N}=\\frac{V_1}{N_1}=\\frac{V_2}{N_2}\\). The paradox is thus resolved.\nThis resolves one of the problems we had with the expressions for an ideal gas, but there’s one more. If we look careful, we can see that the expression inside the logarithm isn’t dimensionless, as it should be. In fact, it has units of action to some power. Recall that action has units of position times momentum, or energy times time. The dimensionality issue ultimately arises from the fact that we’re working with a continuous system and integrating over phase space. But phase space has units. To fix this problem, all we have to do is divide the phase space measure \\(d \\mathbf{x} d\\mathbf{p}\\) by some constant with units of action cubed. We’ll call this constant \\(h\\). Its value turns out to be largely immaterial for classical purposes. We’ll see what it is when we get to quantum statistical mechanics. At any rate, to fix the measure we just need to make the substitution \\[\nd^3 \\mathbf{x} d^3 \\mathbf{p} \\rightarrow \\frac{d^3 \\mathbf{x} d^3 \\mathbf{p}}{h^3}.\n\\] These two facts together resolve our problems. For \\(N\\) particles all of the same type, we substitute the following measures \\[\nd^{3N} \\mathbf{x} \\ d^{3N} \\mathbf{p} \\rightarrow\n\\begin{cases}\n\\frac{d^{3N} \\mathbf{x} \\ d^{3N} \\mathbf{p}}{h^{3N}} & N \\ \\text{distinguishable particles}, \\\\\n\\frac{d^{3N} \\mathbf{x} \\ d^{3N} \\mathbf{p}}{N! \\ h^{3N}} & N \\ \\text{identical particles}. \\\\\n\\end{cases}\n\\]\nFor an ideal gas, the right measure to use is the second one. Plugging this in, we finally get an entropy of \\[\nS = Nk_B \\bigg[\\log \\frac{V}{N}\\bigg(\\frac{4\\pi mE}{3Nh^2}\\bigg)^{3/2} + \\frac{5}{2}\\bigg].\n\\] This result, the correct entropy of a classical ideal gas, is known as the Sakur-Tetrode equation. The chemical potential is then \\[\n\\mu = - k_B T \\log \\frac{V}{N}\\bigg(\\frac{4\\pi mE}{3Nh^2}\\bigg)^{3/2}.\n\\] To finish up this section, it’s worth mentioning that statistical mechanics gives us even more information than thermodynamics gives us. Not only does it tell us what the variables are, but it can also tell us how variables are distributed. For example, we can derive the distribution for the momentum of a single ideal gas particle. We have \\[\n\\begin{align*}\np(\\mathbf{p}) &= \\frac{V^N}{\\Omega(E,V,N)} \\int_{|\\mathbf{p}| = \\sqrt{2mE}} d^{3N-1} \\mathbf{p} \\\\\n&= V\\frac{\\Omega\\big(E-\\frac{\\mathbf{p}^2}{2m},V,N-1\\big)}{\\Omega(E,V,N)} \\\\\n&= \\bigg(1 - \\frac{\\mathbf{p}^2}{2mE}\\bigg)^{3N/2-2} \\frac{1}{(2\\pi m E)^{3/2}} \\frac{(\\frac{3N}{2}-1)!}{(\\frac{3(N-1)}{2}-1)!} \\\\\n&\\approx \\bigg(\\frac{3N}{4\\pi m E}\\bigg)^{3/2} \\exp\\bigg(-\\frac{3N\\mathbf{p}^2}{4mE}\\bigg). \\\\\n\\end{align*}\n\\] The last line follows from the fact that \\(E\\) is extensive and \\(N \\gg 1\\), hence we can use the identity \\(e^x \\approx \\big(1+\\frac{x}{N}\\big)^{N}\\). Using the relation \\(E = \\frac{3}{2} N k_B T\\) then gives the usual form of this distribution, known as the Maxwell-Boltzmann distribution.\n\n\nExample: Ultrarelativistic Ideal Gas\nA similar example is the ultrarelativistic ideal gas. Recall from special relativity that the kinetic energy of a particle is given by the relativistic energy formula \\[\nE^2 = m^2c^4 + \\mathbf{p}^2 c^2.\n\\] In the limit where \\(|\\mathbf{p}| \\ll mc\\) we recover the classical kinetic energy \\(E=\\frac{\\mathbf{p}^2}{2m}\\). We can also ask about the limit where \\(|\\mathbf{p}| \\gg mc\\). This is called the ultrarelativistic limit. This limit includes massless particles like photons or neutrinos that move at or near the speed of light. In this limit the kinetic energy is just \\(E=|\\mathbf{p}| c\\).\nLet’s again suppose we have a gas of \\(N\\) non-interacting particles, but that they’re ultrarelativistic. In that case, the Hamiltonian is \\[\nH(\\mathbf{x}_1,\\cdots,\\mathbf{x}_N,\\mathbf{p}_1,\\cdots,\\mathbf{p}_N) = \\sum_{i=1}^N |\\mathbf{p}_i| c + V(\\mathbf{x}_1,\\cdots,\\mathbf{x}_N).\n\\] We’ll again assume the potential is zero inside a container of volume \\(V\\) and infinite otherwise. We proceed as usual by trying to find \\(\\Omega(E,V,N)\\). Supposing we’re dealing with a gas of \\(N\\) identical particles, we have \\[\n\\Omega(E,V,N) = \\frac{1}{N!h^{3N}} \\int_{E=|\\mathbf{p}| c} d^{3N} \\mathbf{x} \\ d^{3N} \\mathbf{p} = \\frac{V^N}{N!h^{3N}} \\int_{E=|\\mathbf{p}| c} d^{3N} \\mathbf{p}.\n\\] Again note that the momentum space integral is over a \\(3N\\)-dimensional hypersphere, this time of radius \\(R=\\frac{E}{c}\\). Thus, \\[\n\\Omega(E,V,N) = \\frac{V^N}{N!h^{3N}} \\Sigma_{3N} \\approx 2 \\bigg[\\frac{eV}{N} \\bigg(\\frac{2\\pi e E^2}{3h^2c^2 N}\\bigg)^{3/2}\\bigg]^N.\n\\] Again keeping terms only to \\(O(N)\\), the entropy is thus given by \\[\nS = N k_B \\bigg[\\log \\frac{V}{N} \\bigg(\\frac{2\\pi E^2}{3h^2c^2 N}\\bigg)^{3/2} + \\frac{5}{2}\\bigg].\n\\] It’s worth noting that the entropy in this case is no longer properly extensive, as it contains a term of order \\(O(N \\log N)\\) due to the presence of the \\(E^2\\) in the logarithm. There’s no obvious way to fix this problem. In fact, an ultrarelativistic gas is super-extensive. It’s in a class of systems with so-called anonomous scaling behaviors. In practice this isn’t a huge deal.\nWe can calculate the temperature the usual way. We have \\[\n\\frac{1}{T} = \\frac{\\partial S}{\\partial E} \\bigg |_{V,N} = \\frac{3Nk_B}{E} \\quad \\Longrightarrow \\quad E = 3Nk_B T.\n\\] Notice the entropy depends on volume in the same way as it does for the classical ideal gas. Indeed, we have \\[\n\\frac{P}{T} = \\frac{\\partial S}{\\partial V} \\bigg |_{E,N} = \\frac{Nk_B}{V} \\quad \\Longrightarrow \\quad PV = Nk_B T.\n\\] The chemical potential follows similarly. Following the same kind of calculation as before, we get \\[\n\\mu = - k_B T \\log \\frac{V}{N}\\bigg(\\frac{2\\pi E^2}{3c^2h^2N}\\bigg)^{3/2}.\n\\] Since the entropy isn’t properly extensive, the chemical potential evidently isn’t properly intensive as we’d expect. It’s not hard to show that the distribution of momenta is now longer a Gaussian either. It’s in fact a Laplace distribution, with \\[\np(\\mathbf{p}) = \\frac{3Nc}{2E} \\exp\\bigg(-\\frac{3N|\\mathbf{p}|c}{E}\\bigg) = \\frac{c}{2k_B T} \\exp\\bigg(-\\frac{|\\mathbf{p}| c}{k_B T}\\bigg).\n\\]\n\n\nExample: Hard Sphere Gas\nLet’s look at another problem similar to the ideal gas. Suppose that we have a gas of \\(N\\) non-interacting solid spheres each of volume \\(\\omega \\ll V\\), where \\(V\\) is again the volume of the container. The Hamiltonian otherwise remains the same as for the ordinary ideal gas. If we assume the spheres are identical, following the same logic as for the ordinary ideal gas we can write the multiplicity as \\[\n\\Omega(E,V,N) = \\frac{1}{N!}\\frac{2\\pi^{\\frac{3N}{2}}}{\\big(\\frac{3N}{2}-1\\big)!} (2mE)^{\\frac{3N-1}{2}} \\mathcal{V}_{N}.\n\\] Here \\(\\mathcal{V}_{N}\\) represents the volume integral over all \\(N\\) particles. For the ordinary ideal gas we just had \\(\\mathcal{V}_{N} = V^N\\). Now, imagine putting the spheres into the container one at a time. The first one could occupy the volume \\(V\\). The second would be the full volume minus the volume of the first sphere, so \\(V-\\omega\\). The third would be the full volume minus the volumes of the first two spheres, so \\(V-2\\omega\\). And so on until the last sphere, which would have an available volume of \\(V-(N-1)\\omega\\). Assuming \\(\\omega \\ll V\\), we can approximate \\(\\mathcal{V}_N\\) as \\[\n\\begin{align*}\n\\mathcal{V}_N &= V\\big(V-\\omega\\big)\\big(V-2\\omega\\big)\\cdots\\big(V-(N-1)\\omega\\big) \\\\\n&= V^N \\prod_{j=1}^{N-1}\\bigg(1-j\\frac{\\omega}{V}\\bigg) \\\\\n&\\approx V^N \\bigg(1-\\frac{N(N-1)}{2}\\frac{\\omega}{V}\\bigg) \\\\\n&\\approx V^N \\bigg(1-\\frac{N^2}{2}\\frac{\\omega}{V}\\bigg) \\\\\n&\\approx \\bigg(V-\\frac{N\\omega}{2}\\bigg)^N. \\\\\n\\end{align*}\n\\] Effectively, this says the total available volume for each particle in the container to explore gets reduced from \\(V\\) to \\(V-\\frac{N\\omega}{2}\\). The term \\(\\frac{N\\omega}{2}\\) is called the excluded volume. The multiplicity is evidently then \\[\n\\Omega(E,V,N) = \\frac{\\big(V-\\frac{N\\omega}{2}\\big)}{N!}\\frac{2\\pi^{\\frac{3N}{2}}}{\\big(\\frac{3N}{2}-1\\big)!} (2mE)^{\\frac{3N-1}{2}} \\approx 2\\bigg(\\frac{\\big(V-\\frac{N\\omega}{2}\\big)e}{N}\\bigg)^N \\bigg(\\frac{4\\pi m E}{3N}\\bigg)^{3N/2}.\n\\] This is exactly what we had for the ordinary ideal gas, except with \\(V\\) replaced by \\(V-\\frac{1}{2}N\\omega\\). This means the entropy is just \\[\nS = Nk_B \\bigg[\\log \\frac{V-\\frac{N\\omega}{2}}{N}\\bigg(\\frac{4\\pi mE}{3N}\\bigg)^{3/2} + \\frac{5}{2}\\bigg].\n\\] Clearly the equation for temperature isn’t affected at all. We still have \\(E = \\frac{3}{2} N k_B T\\). The equation for pressure though does change though. Since we’re differentiating \\(S\\) with respect to \\(V\\) and not \\(V-\\frac{1}{2}N\\omega\\), we have \\[\n\\frac{P}{T} = \\frac{\\partial S}{\\partial V} \\bigg |_{E,N} = \\frac{Nk_B}{V-\\frac{N\\omega}{2}} \\quad \\Longrightarrow \\quad P\\bigg(V-\\frac{N\\omega}{2}\\bigg) = Nk_B T.\n\\] The ideal gas law is thus slightly modified by reducing the volume from \\(V\\) to the available volume \\(V-\\frac{N\\omega}{2}\\).\nIncidentally, the hard sphere gas is almost a good model of a real interacting gas away from the dense limit. One change that can make it even more accurate is to reduce not just the volume, but also the pressure, to account for the fact that interactions tend to make particles slightly less likely to be near the walls of the container instead of around the center. This slight generalization will give us the van der Waals equation, which we’ll derive when we get to interacting particles.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Classical Statistical Mechanics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/classical-stat-mech.html#canonical-ensemble",
    "href": "statistical-mechanics/classical-stat-mech.html#canonical-ensemble",
    "title": "Classical Statistical Mechanics",
    "section": "Canonical Ensemble",
    "text": "Canonical Ensemble\nWhile the microcanonical ensemble is easy to understand, it’s usually not the easiest ensemble to work with for most problems. Usually finding the multiplicity \\(\\Omega(M)\\) directly isn’t easy since it involves a high level of combinatorial insight. Another approach we can take is to not take \\(M=(E,X,N)\\), but to instead take \\(M=(T,X,N)\\). That is, we consider a system with a fixed temperature, not a fixed energy. Physically, this means considering not an isolated system, but a closed system. We assume our system of interest is placed in contact with a large environment, or heat bath, and allowed to come to equilibrium. The system inherits its temperature from the heat bath and is allowed to exchange heat with it.\n\nBoltzmann Distribution\nTo derive the probability distribution for a canonical system let’s first consider the combined system of our system of interest plus the heat bath. We’ll suppose the combined system is isolated, meaning it follows the microcanonical ensemble. Denote the system of interest as \\(S\\), the heat bath as \\(R\\), and the combined system as \\(RS\\). The total energy \\(E\\) is just the sum of the Hamiltonians of \\(S\\) and \\(R\\) at a given point in their respective phase spaces, \\[\nE = H_R(\\boldsymbol{\\mu}_R) + H_S(\\boldsymbol{\\mu}_S).\n\\] In the microcanonical ensemble the probability of any given state \\((\\boldsymbol{\\mu}_R,\\boldsymbol{\\mu}_S)\\) is then just \\[\np_{RS}(\\boldsymbol{\\mu}_R,\\boldsymbol{\\mu}_S) = \\frac{1}{\\Omega_{RS}} \\delta\\big(E-H_R(\\boldsymbol{\\mu}_R)-H_S(\\boldsymbol{\\mu}_S)\\big).\n\\] To get the probability we seek, the probability of system states we need to find \\(p_S(\\boldsymbol{\\mu}_S)\\). By marginalizing, we have \\[\n\\begin{align*}\np_S(\\boldsymbol{\\mu}_S) &= \\int d \\boldsymbol{\\mu}_R \\ p_{RS}(\\boldsymbol{\\mu}_R,\\boldsymbol{\\mu}_S) \\\\\n&= \\frac{1}{\\Omega_{RS}} \\Omega_R\\big(E-H_S(\\boldsymbol{\\mu}_S)\\big) \\\\\n&= \\frac{1}{\\Omega_{RS}}\\exp\\bigg(\\frac{1}{k_B}S_R\\big(E-H_S(\\boldsymbol{\\mu}_S)\\big)\\bigg).\n\\end{align*}\n\\] Now, we assume the heat bath is much larger than the system of interest. This means the \\(S_{RS} \\approx S_R\\) and the total energy \\(E \\gg H_S\\). If we Taylor expand \\(S_R\\) about \\(E\\), to first order we thus have \\[\nS_R\\big(E-H_S(\\boldsymbol{\\mu}_S)\\big) \\approx S_{RS}(E) - \\frac{\\partial S_{RS}}{\\partial E} H_S(\\boldsymbol{\\mu}_S).\n\\] Since the heat bath is fixed at a temperature \\(T\\), we can write the partial derivative as \\(\\frac{\\partial S_R}{\\partial E} = \\frac{1}{T}\\). Plugging back in, we have \\[\np_S(\\boldsymbol{\\mu}_S) \\approx \\frac{e^{\\frac{1}{k_B} S_{RS}(E)}}{\\Omega_{RS}}e^{-\\frac{1}{k_B T} H_S(\\boldsymbol{\\mu}_S)}.\n\\] For convenience we’ll define \\(\\beta \\equiv \\frac{1}{k_B T}\\). Notice the first term above is just some normalization constant that we’ll denote as \\(\\frac{1}{Z(\\beta)}\\). Dropping the explicit \\(S\\) subscripts and ignoring the presence of the heat bath we finally have our canonical ensemble probability, called the Boltzmann distribution, \\[\n\\boxed{p(\\boldsymbol{\\mu}) = \\frac{1}{Z(T,X,N)}e^{-\\beta H(\\boldsymbol{\\mu})}} \\ .\n\\]\n\n\nPartition Function\nThe normalization constant \\(Z(T,X,N)\\) is so important it has a special name. It’s called the canonical partition function. We can find an expression for it by asserting that the probability density integrate to one. Evidently, we get \\[\n\\boxed{Z(T,X,N) = \\int d \\boldsymbol{\\mu} \\ e^{-\\beta H(\\boldsymbol{\\mu})}} \\ .\n\\] The partition function turns out to be very important to statistical mechanics, as it essentially encodes all the statistical mechanical information contained in the system. To see why it’s helpful to re-write the partition function as an integral (or sum) over all possible system energies \\(E\\). To do that multiple microstates can have the same energy. That means we need to multiply the integrand by a multiplicity \\(\\Omega(E)\\). We thus have \\[\nZ = \\int dE \\ \\Omega(E) \\ e^{-\\beta E} = \\int dE \\ e^{\\frac{1}{k_B} S} e^{-\\frac{1}{k_B T} E} = \\int dE \\ e^{-\\frac{1}{k_B T}(E-TS)}.\n\\] Recall from thermodynamics though that \\(E-TS\\) is just the Helmholtz free energy \\(F\\). Now, since \\(F\\) is extensive we can again employ the saddlepoint approximation about the maximum energy \\(E^*\\) to get \\[\nZ = \\int dE \\ e^{-\\beta F} \\approx e^{-\\beta F(E^*)} \\sqrt{\\frac{2\\pi}{|F''(E^*)|}}.\n\\] Taking the logarithm of both sides and solving for \\(F\\), we evidently have \\[\nF = -k_B T \\log Z + O\\big(\\log N\\big).\n\\] Since \\(N\\) is large, we can neglect the dependence on \\(\\log N\\). We thus have a nice expression for the free energy as \\[\n\\boxed{F = -k_B T \\log Z} \\ .\n\\] Why is this important? We already know \\(F\\) encodes all of the thermodynamic information in the system because \\[\ndF = -S dT + J \\cdot dX + \\mu \\cdot dN.\n\\] This formula gives a way to find the entropy, force, and chemical potential of the system just from \\(\\log Z\\). For example, \\[\n\\begin{align*}\nJ &= \\frac{\\partial F}{\\partial X} \\bigg |_{T,N} = -\\frac{1}{\\beta} \\frac{\\partial \\log Z}{\\partial X}, \\\\\n\\mu &= \\frac{\\partial F}{\\partial N} \\bigg |_{T,X} = -\\frac{1}{\\beta} \\frac{\\partial \\log Z}{\\partial N}. \\\\\n\\end{align*}\n\\] We can also derive a convenient expression for the energy \\(E\\) by looking at the expected value of the Hamiltonian. We have \\[\n\\langle H \\rangle = \\int d \\boldsymbol{\\mu} \\ H(\\boldsymbol{\\mu}) p(\\boldsymbol{\\mu}) = \\int d \\boldsymbol{\\mu} \\ H(\\boldsymbol{\\mu}) \\frac{e^{-\\beta H(\\boldsymbol{\\mu})}}{Z} = -\\frac{1}{Z} \\frac{\\partial Z}{\\partial \\beta} = - \\frac{\\partial \\log Z}{\\partial \\beta}.\n\\] Assuming we can equate the macrostate energy \\(E\\) with \\(\\langle H \\rangle\\), an issue we’ll discuss in a moment, we can thus write \\[\n\\boxed{E = \\langle H \\rangle = - \\frac{\\partial \\log Z}{\\partial \\beta}} \\ .\n\\] Using the formula \\(F = E - TS\\) we can also get a convenient formula for the entropy. We have \\[\nS = \\frac{E}{T} - \\frac{F}{T} = k_B \\big(\\beta E + \\log Z \\big).\n\\]\nFor systems of \\(N\\) non-interacting particles, it’s generally the case that the partition function can be factored into a product of single-particle partition functions. That is, \\(Z = Z_1^N\\). If the particles are identical we have to be sure to divide by \\(N!\\) as well. This trick will be useful in solving for equations of state in many examples.\n\n\nFluctuations\nBut why can we assert that the thermodynamic energy \\(E\\) is the same thing as the expected value of the Hamiltonian \\(\\langle H \\rangle\\)? The reason for this has to do almost entirely with the fact that \\(N\\) is really large. To see why, let’s ask the following question: How much can we expect the energy to fluctuate about its mean \\(\\langle H \\rangle\\)?\nTo answer this, we just need to find the variance \\(\\sigma_E^2\\). Using the same trick as before, the \\(k\\)th moment of \\(H\\) is given by \\[\n\\langle H^k \\rangle = \\int d \\boldsymbol{\\mu} \\ H^k(\\boldsymbol{\\mu}) p(\\boldsymbol{\\mu}) = \\int d \\boldsymbol{\\mu} \\ H^k(\\boldsymbol{\\mu}) \\frac{e^{-\\beta H(\\boldsymbol{\\mu})}}{Z} = (-1)^k\\frac{1}{Z} \\frac{\\partial^k Z}{\\partial \\beta^k}.\n\\] From this formula, it’s not hard to see the cumulants of \\(H\\) are simply given by \\[\n\\langle H^k \\rangle_c = (-1)^k \\frac{\\partial^k \\log Z}{\\partial \\beta^k}.\n\\] In particular, this means the variance is given by \\[\n\\sigma_E^2 = \\frac{\\partial^2 \\log Z}{\\partial \\beta^2} = - \\frac{\\partial \\langle H \\rangle}{\\partial \\beta} = k_B T^2 \\frac{\\partial \\langle H \\rangle}{\\partial T} \\bigg |_{X,N} \\ .\n\\] To the extent we can write \\(E \\approx \\langle H \\rangle\\), the right-hand derivative is just the heat capacity \\(C_X\\). The variance of \\(H\\) is thus \\[\n\\boxed{\\sigma_E^2 = k_B T^2 C_X} \\ .\n\\] Now, recall the heat capacity is in general extensive. This means the variance (and in fact all cumulants of \\(H\\)) are extensive as well. Thus, roughly speaking, we expect the energy \\(E\\) to fluctuation about the mean by an amount \\[\n\\sigma_E = \\sqrt{k_B T^2 C_X} = O(\\sqrt{N}).\n\\] This means that the energy \\(E\\) will with high probability lie within a few \\(\\sigma_E\\) of the mean, \\[\nE \\approx \\langle H \\rangle \\pm \\sigma_E = \\langle H \\rangle \\pm O(\\sqrt{N}).\n\\] Since \\(\\langle H \\rangle = O(N)\\) and \\(N\\) is large, we can neglect the \\(O(\\sqrt{N})\\) fluctuations in the thermodynamic limit and just write \\[\nE \\approx \\langle H \\rangle.\n\\] Note that the energy distribution can have pretty much any curve we like. All that matters is that it be extensive. It can even have multiple peaks. Due to extensivity, the global maximum \\(E^*\\) will always be exponentially larger than the other maxima. Around that maximum we can fit a Gaussian with mean \\(E^* \\approx \\langle H \\rangle\\) and variance \\(\\sigma_E^2\\). That Gaussian will be sharply peaked about \\(E^*\\) with a negligible fluctuation, meaning we can safely write \\(E \\approx E^* \\approx \\langle H \\rangle\\).\n\n\n\n\n\nThis is in essence the magic of thermodynamics. When \\(N\\) is really really large, at equilibrium we can pretty much ignore the shape of the distribution and just assume \\(E = E^* = \\langle H \\rangle\\). This holds for other extensive variables as well, not just energy. For all practical purposes, thermodynamic variables are deterministic due to the character of the thermodynamic limit.\nAs an example to see that fluctuations don’t really matter, if we looked at one mole of air at STP, we’d expect the energy to be about \\(E \\approx \\frac{5}{2} RT \\approx 6100 \\ \\text{J}\\). On the other hand, the energy is expected to fluctuate as \\(\\sigma_E = \\sqrt{k_B T^2 \\frac{5}{2} R} \\approx 3 \\cdot 10^{-10} \\ \\text{J}\\). That is, the fluctuations \\(\\sigma_E\\) are a full 13 orders of magnitude smaller than \\(E\\), hence completely negligible.\n\n\nExample: Ideal Gas\nFrequently, the canonical ensemble is much easier to work with than the microcanonical ensemble. Perhaps the best example of this is comparing both methods for solving the ideal gas problem. Consider again a gas with Hamiltonian \\[\nH(\\mathbf{x}_1,\\cdots,\\mathbf{x}_N,\\mathbf{p}_1,\\cdots,\\mathbf{p}_N) = \\sum_{i=1}^N \\bigg(\\frac{\\mathbf{p}_i^2}{2m} + V(\\mathbf{x}_i)\\bigg),\n\\] where \\(V(\\mathbf{x}_i)\\) is zero inside a container of volume \\(V\\) and infinite otherwise. Since this Hamiltonian factors into a product of single-particle terms, we can most easily calculate \\(Z\\) by first calculating the single particle partition function \\(Z_1\\). We have \\[\n\\begin{align*}\nZ_1 &= \\frac{1}{h^3} \\int d^{3} \\mathbf{x} \\ d^{3} \\mathbf{p} \\ \\exp\\bigg[-\\beta \\bigg(\\frac{\\mathbf{p}^2}{2m} + V(\\mathbf{x})\\bigg)\\bigg] \\\\\n&= \\frac{V}{h^3} \\int d^3 \\mathbf{p} \\ \\exp\\bigg[-\\beta \\bigg(\\frac{\\mathbf{p}^2}{2m}\\bigg)\\bigg] \\\\\n&= \\frac{V}{h^{3}} \\bigg(\\frac{2\\pi m}{\\beta}\\bigg)^{3/2} \\\\\n&= \\frac{V}{\\lambda_T^3}.\n\\end{align*}\n\\] Here we’ve defined a useful quantity \\(\\lambda_T \\equiv \\frac{h}{\\sqrt{2\\pi m k_B T}}\\) known as the thermal DeBroglie wavelength. For now this is just a convenience, but we’ll see in quantum statistical mechanics that this wavelength has physical meaning. It says something about how tightly packed particles in a gas need to be for quantum effects to become important. In classical statistical mechanics it won’t matter, since temperatures are assumed to be so large that particles are well-approximated as point particles.\nNow that we have \\(Z_1\\), we can find the full partition function by multiplying them together \\(N\\) times and dividing by \\(N!\\), \\[\nZ = \\frac{1}{N!} Z_1^N = \\frac{V^N}{N! \\lambda_T^{3N}} = \\frac{V^N}{N! h^{3N}} \\bigg(\\frac{2\\pi m}{\\beta}\\bigg)^{3N/2} \\ .\n\\] We can now get everything of interest from here by looking at the logarithm of the partition function, \\[\n\\log Z = N \\log \\frac{Ve}{N} \\bigg(\\frac{2\\pi m}{\\beta h^2}\\bigg)^{3/2}.\n\\] For example, the energy is given by \\[\nE = - \\frac{\\partial \\log Z}{\\partial \\beta} = \\frac{3N}{\\beta} = \\frac{3}{2} N k_B T,\n\\] and the pressure is given by \\[\nP = \\frac{1}{\\beta} \\frac{\\partial \\log Z}{\\partial V} = \\frac{N}{\\beta V} = \\frac{Nk_B T}{V}.\n\\] One way to see how useful the canonical ensemble can be is by calculating the distribution of momentum in the gas. The Maxwell-Boltzmann distribution pretty much falls right out of the Boltzmann factor. Indeed, we have \\[\n\\begin{align*}\np(\\mathbf{p}_1) &= \\frac{1}{N! Z} \\frac{1}{h^{3N}} \\int d^{3N} \\mathbf{x} \\ d^{3N-1} \\mathbf{p} \\ p(\\mathbf{x}_1,\\cdots,\\mathbf{x}_N,\\mathbf{p}_1,\\cdots,\\mathbf{p}_N)\n\\\\\n&= \\bigg(\\frac{\\lambda_T^{3}}{V}\\bigg)^N \\bigg(\\frac{V}{\\lambda_T^{3}}\\bigg)^{N-1} \\frac{V}{h} \\exp\\bigg[-\\beta \\bigg(\\frac{\\mathbf{p}_1^2}{2m}\\bigg)\\bigg] \\\\\n&= \\frac{1}{(2\\pi m k_B T)^{3/2}} \\exp\\bigg[-\\frac{1}{2}\\bigg(\\frac{\\mathbf{p}_1^2}{mk_B T}\\bigg) \\bigg].\n\\end{align*}\n\\]\n\n\nEquipartition Theorem\nRecall from thermodynamics that we have a quick rule of thumb for finding the energy of certain gases. Look at the Hamiltonian of the gas and count number of quadratic degrees of freedom (both momenta plus positions). If the gas has \\(d\\) quadratic degrees of freedom, then the energy of the gas is just \\[\nE = \\frac{d}{2} N k_B T.\n\\] For example, a monoatomic ideal gas has just \\(d=3\\) quadratic degrees of freedom per molecule, since each molecule has a total energy proportional to \\(p_x^2 + p_y^2 + p_z^2\\). This means the total energy is \\(E=\\frac{3}{2} Nk_B T\\), as we’ve already derived multiple times. Let’s use the canonical ensemble to quickly prove the most general case of the equipartition theorem.\nSuppose a system of \\(N\\) particles has a joint Hamiltonian \\(H\\) consisting of the sum of single-particle Hamiltonians \\(H_i\\). Each single-particle contains \\(d\\) degrees of freedom \\(\\boldsymbol{\\xi}=(\\xi_1,\\xi_2,\\cdots,\\xi_d)\\). Suppose each single-particle Hamiltonian has the same form \\(H_i = \\sum_{k=1}^d c_k |\\boldsymbol{\\xi}|^s\\) for some positive power \\(s\\). Then the joint Hamiltonian is given by \\[\nH = \\sum_{i=1}^N \\sum_{k=1}^d c_k |\\boldsymbol{\\xi}_{ik}|^s.\n\\] Equipartition Theorem: In equilibrium, the total thermodynamic energy \\(E = \\langle H \\rangle\\) is given by \\[\nE = \\frac{d}{s} N k_B T.\n\\] In particular, when \\(s=2\\) we recover the usual equipartition theorem for quadratic degrees of freedom.\nProof: Without loss of generality, suppose the system has all its degrees of freedom in the momenta, so we can write \\[\nH = \\sum_{i=1}^N \\sum_{k=1}^{d} c_k |\\mathbf{p}_{ik}|^s.\n\\] It’s convenient here to work in the canonical ensemble. Since all we’re interested in is the energy, for simplicity we’ll assume all particles are distinguishable and ignore factors of \\(h\\). The partition function is then \\[\nZ = \\int d^{dN} \\mathbf{x} \\ d^{dN} \\mathbf{p} \\ \\exp\\bigg[-\\beta \\sum_{i=1}^N \\sum_{k=1}^{d} c_k |\\mathbf{p}_{ik}|^s\\bigg].\n\\] Suppose the particles are confined to some \\(d\\)-dimensional hypervolume \\(V_d\\). Factoring the exponentials by particle, we have \\[\nZ = V_d^N \\bigg(\\prod_{k=1}^d \\int d^{d} \\mathbf{p} \\ e^{-\\beta c_k |\\mathbf{p}|^s}\\bigg)^N.\n\\] We can write the \\(d\\)-dimensional volume element \\(d^d \\mathbf{p}\\) as a product of the \\(d\\)-dimensional solid angle \\(d^d\\Omega\\) and a radial term \\(r^{d-1} dr\\), \\[\nd^d \\mathbf{p} = r^{d-1} dr d^d \\Omega.\n\\] Since the integral for \\(Z\\) is spherically symmetric, we can integrate each solid angle to just get the surface area of a \\(d\\)-dimensional hypersphere, which we’ll recall is given by \\(S_d\\). What remains inside the integral is just the factorial function up to a change of variable. We thus have \\[\n\\begin{align*}\nZ &= V_d^N \\bigg(\\prod_{k=1}^d \\int d^d\\Omega \\int_0^{\\infty} dp \\ p^{d-1} e^{-\\beta c_k p^s}\\bigg)^N \\\\\n&= V_d^N \\bigg(\\prod_{k=1}^d S_d \\int_0^{\\infty} dp \\ p^{d-1} e^{-\\beta c_k p^s}\\bigg)^N \\\\\n&= V_d^N \\bigg(\\prod_{k=1}^d\\frac{S_d\\big(\\frac{d}{s}-1\\big)!}{s(\\beta c_k)^{1/s}}\\bigg)^N. \\\\\n\\end{align*}\n\\] In particular, notice that \\(Z\\) is proportional to \\(\\beta^{-Nd/s}\\), which means \\(\\log Z \\sim -\\frac{Nd}{s} \\log \\beta\\). The energy is thus just \\[\nE = -\\frac{\\partial \\log Z}{\\partial \\beta} = \\frac{Nd}{s\\beta} = \\frac{d}{s} N k_B T. \\quad \\text{Q.E.D.}\n\\] The equipartition theorem is a useful shortcut for quickly figuring out how the partition function depends on temperature since we can use it to avoid having to do any integration, provided the degrees of freedom are all of the same power. For example, we saw for an ultrarelativistic ideal gas that \\(H = \\sum_{i=1}^N |\\mathbf{p}_i|c\\). In this case \\(s=1\\) and \\(d=3\\), so \\(E=3Nk_B T\\), which we’ve seen.\n\n\nExample: Diatomic Gas\nLet’s now consider a slightly more interesting variant of the ideal gas, namely one where the particles in question aren’t point particles anymore, but rather diatomic. That is, each particle consists of two masses that strongly interact with each other. Think of these particles as dumbbells with masses at each end. Except when these dumbbells are heated up enough, the bar holding them together becomes a spring that can oscillate at some frequency. While this may seem academic, diatomic molecules are actually very common in nature. Many atoms, like hydrogen, oxygen, nitrogen, etc only exist in nature in diatomic form because they’re more chemically stable. For example, each “particle” of hydrogen gas is actually a pair of interacting hydrogen atoms.\nWe’ll assume each diatomic gas particle does not interact with other particles, so there’s no external potential energy associated with each dumbbell. We’ll assume the two masses inside interact via some radial potential energy \\(u\\) undergoing small oscillations near some minimum energy. We can describe the Hamiltonian for each individual particle by \\[\nH_1 = \\frac{\\mathbf{p}_1^2}{2m_1} + \\frac{\\mathbf{p}_2^2}{2m_2} + u(|\\mathbf{x}_1-\\mathbf{x}_2|).\n\\] As usual when working with pairs of masses, it’s helpful to re-express the Hamiltonian in center of mass and relative coordinates. We’ll also assume the potential is approximately harmonic at some distance \\(d\\), with \\(u(r) \\approx \\frac{1}{2}\\mu\\omega^2 r^2 + u(d)\\) to get \\[\nH_1 = \\frac{\\mathbf{P}^2}{2M} + \\frac{\\mathbf{p}^2}{2\\mu} + \\frac{1}{2}\\mu\\omega^2 r^2 + u(d).\n\\] Now, before turning the crank, it’s worth stopping to take a look at what we’re doing. We’ve assumed that the two masses only undergo oscillations about some equilibrium distance \\(d\\). We’ve also assumed each particle oscillates at the same constant frequency \\(\\omega\\), not a horrible assumption for a large number of particles in equilibrium at sufficiently high temperatures. Since we’re assuming harmonic oscillations around this distance \\(d\\) there will be an added constant \\(u(d)\\) that we can ignore.\nNotice that each term in the Hamiltonian contributes quadratic degrees of freedom. This means we should be able to use the equipartition theorem to predict what the energy should be. Since each particle has \\(3+3+1=7\\) quadratic degrees of freedom, with no work we can predict the energy of this system to be \\(E=\\frac{7}{2} k_B T\\). Now we’ll verify this the hard way.\nAssuming the particles don’t interact, the partition function \\(Z\\) factors into a product of one-particle partition functions \\(Z_1\\). For indistinguishable particles, we’d thus have \\(Z = \\frac{1}{N!} Z_1^N\\). Writing out \\(Z_1\\) and integrating each term, we have \\[\n\\begin{align*}\nZ_1 &= \\frac{1}{h^6} \\int d^3 \\mathbf{X} \\ d^3 \\mathbf{P} \\ d^3 \\mathbf{x} \\ d^3 \\mathbf{p} \\ e^{-\\beta H_1} \\\\\n&= \\frac{1}{h^6} \\int d^3 \\mathbf{X} \\int d^3 \\mathbf{P} \\ e^{-\\beta \\frac{\\mathbf{P}^2}{2M}} \\int 4\\pi r^2 dr \\ e^{-\\frac{\\beta\\mu\\omega^2}{2} r^2} \\int d^3 \\mathbf{p} \\ e^{-\\beta \\frac{\\mathbf{p}^2}{2\\mu}} \\\\\n&= \\frac{4\\pi V}{h^6} \\bigg(\\frac{2\\pi M}{\\beta}\\bigg)^{3/2} \\bigg(\\frac{2\\pi \\mu}{\\beta}\\bigg)^{3/2} \\bigg(\\frac{2\\pi}{\\mu\\omega^2\\beta}\\bigg)^{1/2} \\\\\n&= \\frac{16\\pi^4 M^{3/2}}{h^6} \\frac{V}{\\beta^{7/2}} \\ .\n\\end{align*}\n\\] From this expression we can easily read off the energy and pressure. As predicted by the equipartition theorem, we indeed have \\[\nE=\\frac{7}{2} Nk_B T.\n\\] We can also easily see that the non-interacting diatomic gas has the same ideal gas law \\(PV=Nk_B T\\). If we like, we can also calculate the heat capacity \\(C\\), which turns out to be \\[\nC = \\frac{\\partial E}{\\partial T} \\bigg |_{V,N} = \\frac{7}{2} N k_B \\ .\n\\] This value for heat capacity is a precise prediction of classical statistical mechanics that we can test in the lab for any diatomic gas. In fact, at room temperature the measured heat capacity of most gases tends to be about \\(C = \\frac{5}{2} Nk_B\\). Essentially what’s going on is that at room temperature the vibrational mode gets frozen out, leaving only the translational and rotational modes to contribute to the energy. The reason for this behavior we’ll only be able to answer later with quantum statistical mechanics.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Classical Statistical Mechanics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/classical-stat-mech.html#higher-ensembles",
    "href": "statistical-mechanics/classical-stat-mech.html#higher-ensembles",
    "title": "Classical Statistical Mechanics",
    "section": "Higher Ensembles",
    "text": "Higher Ensembles\nWhile the microcanonical ensemble is perhaps the most intuitive, and the canonical ensemble is perhaps the most useful, there are other ensembles we can imagine as well. In fact, each free energy has its own ensemble. We’ve already seen the ensembles corresponding to the energy \\(E\\) and Helmholtz free energy \\(F\\). We’ll now look at two more ensembles corresponding to the last two free energies, the Gibbs free energy \\(G\\) and the grand potential \\(\\mathcal{G}\\). While all ensembles are in some sense equivalent, each ensemble has its advantages in certain situations. In particular, we’ll see the grand canonical ensemble arise in our treatment of quantum statistical mechanics.\n\nGibbs Canonical Ensemble\nSimilar to the canonical ensemble, the Gibbs canonical ensemble arises from considering a system in equilibrium with a much larger heat bath, except now we also allow for the possibility that work is done on the system as well. That is, we now take \\(M=(T,J,N)\\) and assume the total energy has the form \\(E = H(\\boldsymbol{\\mu}) + J \\cdot X\\). Then the probability of achieving a given microstate \\(\\boldsymbol{\\mu}\\) at a particular displacement \\(X\\) is given by \\[\np(\\boldsymbol{\\mu},X) = \\frac{1}{Z_G(T,J,N)}e^{-\\beta \\big(H(\\boldsymbol{\\mu})-J \\cdot X\\big)},\n\\] where \\(Z_G=Z_G(T,J,N)\\) is again a normalization constant, this time called the Gibbs partition function. It’s given by integrating over all microstates \\(\\boldsymbol{\\mu}\\) and displacements \\(X\\), \\[\nZ_G(T,J,N) \\equiv \\int dX \\ d \\boldsymbol{\\mu} \\ e^{-\\beta \\big(H(\\boldsymbol{\\mu})-J \\cdot X\\big)}.\n\\] By factoring the dependences on \\(\\boldsymbol{\\mu}\\) and \\(X\\) we can write the Gibbs partition function in terms of the canonical partition function \\(Z(T,X,N)\\) as \\[\nZ_G(T,J,N) = \\int dX \\ e^{-\\beta J \\cdot X} \\ Z(T,X,N).\n\\] Since the displacement \\(X\\) is now a random variable, we can ask how it varies about its mean \\(\\langle X \\rangle\\). Following the same logic as we did with the energy, it’s easy to see that \\[\n\\langle X \\rangle = \\frac{\\partial}{\\partial (\\beta J)} \\log Z_G.\n\\] The cumulants of \\(X\\) are similarly given by \\[\n\\langle X^k \\rangle_c = \\frac{\\partial^k \\log Z_G}{\\partial (\\beta J)^k} = \\frac{\\partial^{k-1} \\langle X \\rangle}{\\partial (\\beta J)^{k-1}}.\n\\] In particular, all cumulants of \\(X\\) are extensive. This means the variance is proportional to \\(\\langle X \\rangle\\), which means the fluctuations in \\(X\\) go like \\(\\sigma_X = \\sqrt{\\langle X \\rangle}\\). This means we can again assert that \\(X = X^* = \\langle X \\rangle\\) when \\(N\\) is really large.\nWe can relate the partition function to the Gibbs free energy by observing \\[\nZ_G = \\int dX \\ dE \\ e^{-\\beta(E-J \\cdot X)} \\Omega(E,X) = \\int dX \\ dE \\ e^{-\\beta(E-TS-J \\cdot X)}.\n\\] Here \\(G \\equiv E-TS-\\mu \\cdot N\\) is of course the Gibbs free energy. Using the saddlepoint approximation, in the thermodynamic limit we can write \\[\nZ_G \\approx e^{-\\beta G(E^*, \\ X^*)}.\n\\] Solving for \\(G\\) we have the familiar expression \\[\nG = -k_B T \\log Z_G.\n\\] From here all other thermodynamic variables we seek follow in the usual way using the identity \\[\ndG = -S dT - X \\cdot dJ + \\mu \\cdot dN.\n\\] In this ensemble the canonical energy formula no longer applies. Instead that formula gives the enthalpy \\(H = E - J \\cdot X\\), \\[\nH = -\\frac{\\partial \\log Z_G}{\\partial \\beta}.\n\\]\n\n\nGrand Canonical Ensemble\nThe grand canonical ensemble follows exactly the same logic as the Gibbs ensemble did, except now we imagine the system is in equilibrium with a heat bath and allowed to exchange particles with it via chemical work. That is, \\(M = (T,X,\\mu)\\) and the energy has the form \\(E = H(\\boldsymbol{\\mu}) + \\mu \\cdot N\\). Then the probability of a given microstate \\(\\boldsymbol{\\mu}\\) and a given particle number \\(N\\) is given as \\[\np(\\boldsymbol{\\mu},N) = \\frac{1}{\\mathcal{Z}(T,X,\\mu)}e^{-\\beta \\big(H(\\boldsymbol{\\mu})-\\mu \\cdot N\\big)},\n\\] where \\(\\mathcal{Z}(T,X,\\mu)\\) is another normalization constant gotten by integrating over all possible \\(\\boldsymbol{\\mu}\\) and summing over all possible \\(N\\). This is called the grand canonical partition function, given by \\[\n\\mathcal{Z}(T,X,\\mu) \\equiv \\sum_{N=0}^\\infty \\int d \\boldsymbol{\\mu} \\ e^{-\\beta \\big(H(\\boldsymbol{\\mu})-\\mu \\cdot N\\big)}.\n\\] We can again factor the \\(\\boldsymbol{\\mu}\\) and \\(N\\) dependences apart and write just \\[\n\\mathcal{Z}(T,X,\\mu) = \\sum_{N=0}^\\infty e^{\\beta\\mu \\cdot N} Z(T,X,N).\n\\] The dimensionless variable \\(\\log z \\equiv \\beta\\mu = \\frac{\\mu}{k_B T}\\) is sometimes called the log fugacity, where \\(z \\equiv e^{\\beta\\mu}\\) is the fugacity. The fugacity turns out to be important in quantum statistical mechanics since its size says something about the limiting behaviors of the equations of state at low temperatures.\nWhile not necessarily obvious, more mathematical care is needed to interpret the grand canonical ensemble due to the fact that \\(N\\) is no longer fixed, but allowed to vary. This means we can’t a priori just assume that \\(N\\) is large and the thermodynamic limit applies. Moreover, the phase spaces being integrated over aren’t even of the same dimensions since each \\(d=6N\\).\nInstead of interpreting things in terms of \\(N\\), a random variable, we instead need to interpret things in terms of \\(\\langle N \\rangle\\). Following the same logic as we did with the energy, it’s easy to see that \\[\n\\langle N \\rangle = \\frac{\\partial}{\\partial (\\beta\\mu)} \\log \\mathcal{Z}.\n\\] The cumulants of \\(N\\) are similarly given by \\[\n\\langle N^k \\rangle_c = \\frac{\\partial^k \\log \\mathcal{Z}}{\\partial (\\beta\\mu)^k} = \\frac{\\partial^{k-1} \\langle N \\rangle}{\\partial (\\beta\\mu)^{k-1}}.\n\\] In particular, all cumulants of \\(N\\) are proportional to \\(\\langle N \\rangle\\). In particular, this means the variance is proportional to \\(\\langle N \\rangle\\), which means the fluctuations in \\(N\\) go like \\(\\sigma_N = \\sqrt{\\langle N \\rangle}\\). By the same usual logic, this means we can assert that \\(N = N^* = \\langle N \\rangle\\) provided \\(N^*\\) is very large, which will typically be the case in thermodynamics.\nAgain using the same logic as before, we can relate the partition function to the free energy by observing \\[\n\\mathcal{Z} = \\sum_{N=0}^\\infty \\int dE \\ e^{-\\beta(E-\\mu \\cdot N)} \\Omega(E,N) = \\sum_{N=0}^\\infty \\int dE \\ e^{-\\beta(E-TS-\\mu \\cdot N)}.\n\\] Here \\(\\mathcal{G} \\equiv E-TS-\\mu \\cdot N\\) is of course the grand potential. Using the saddlepoint approximation, in the thermodynamic limit we can write \\[\n\\mathcal{Z} \\approx e^{-\\beta\\mathcal{G}(E^*,N^*)}.\n\\] Solving for \\(\\mathcal{G}\\) we again have the familiar expression \\[\n\\mathcal{G} = -k_B T \\log \\mathcal{Z}.\n\\] From here all other thermodynamic variables we seek follow in the usual way using the identity \\[\nd\\mathcal{G} = -S dT + J \\cdot dX - N \\cdot d\\mu.\n\\]\n\n\nExample: Ideal Gas\nAs an example, we’ll work out the equations of state again for the ideal gas, both in the Gibbs canonical and the grand canonical ensembles. Starting with the Gibbs canonical ensemble, the Gibbs partition function can be calculated by observing that the integral over \\(V\\) is almost a factorial function. We have \\[\n\\begin{align*}\nZ_G &= \\int_0^\\infty dV e^{-\\beta PV} Z \\\\\n&= \\frac{1}{N! h^{3N}} \\bigg(\\frac{2\\pi m}{\\beta}\\bigg)^{3N/2} \\int_0^\\infty dV e^{-\\beta PV} V^N \\\\\n&= \\frac{1}{N! h^{3N}} \\bigg(\\frac{2\\pi m}{\\beta}\\bigg)^{3N/2} \\frac{N!}{(\\beta P)^{N+1}} \\\\\n&= \\bigg(\\frac{2\\pi m}{h^2 \\beta}\\bigg)^{3N/2} (\\beta P)^{-(N+1)}. \\\\\n\\end{align*}\n\\] Taking the logarithm of both sides, we have \\[\n\\log Z_G \\approx \\frac{3N}{2} \\log \\frac{2\\pi m}{h^2 \\beta} - N \\log \\beta P.\n\\] We can get the mean volume \\(V \\approx \\langle V \\rangle\\) by differentiating both sides with respect to \\(-\\beta P\\), \\[\nV \\approx \\frac{\\partial \\log Z_G}{\\partial (-\\beta P)} = \\frac{N}{\\beta P} = \\frac{Nk_B T}{P}.\n\\] This is of course the usual equation of state, with \\(PV = N k_B T\\). We can easily find the enthalpy as well, \\[\nH = -\\frac{\\partial \\log Z_G}{\\partial \\beta} = \\frac{3N}{2\\beta} + \\frac{N}{\\beta} = \\frac{5}{2} N k_B T.\n\\] Since \\(H = E + PV\\), we can immediately read off the usual formula for energy, \\(E = \\frac{3}{2} N k_B T\\).\nMoving onto the grand canonical ensemble, the grand partition function is given by noting that the sum over \\(N\\) is just the Taylor series of an exponential function. We have \\[\n\\begin{align*}\n\\mathcal{Z} &= \\sum_{N=0}^\\infty dV e^{\\beta \\mu N} Z(\\beta) \\\\\n&= \\sum_{N=0}^\\infty e^{\\beta \\mu N} \\frac{V^N}{N! h^{3N}} \\bigg(\\frac{2\\pi m}{\\beta}\\bigg)^{3N/2} \\\\\n&= \\sum_{N=0}^\\infty \\frac{1}{N!} \\bigg[\\frac{Ve^{\\beta\\mu}}{h^3} \\bigg(\\frac{2\\pi m}{\\beta}\\bigg)^{3/2}\\bigg]^N \\\\\n&= \\exp \\bigg[\\frac{Ve^{\\beta\\mu}}{h^3} \\bigg(\\frac{2\\pi m}{\\beta}\\bigg)^{3/2}\\bigg]. \\\\\n\\end{align*}\n\\] This means \\(\\log \\mathcal{Z}\\) is just \\[\n\\log \\mathcal{Z} = \\frac{Ve^{\\beta\\mu}}{h^3} \\bigg(\\frac{2\\pi m}{\\beta}\\bigg)^{3/2}.\n\\] It’s helpful to first find \\(N \\approx \\langle N \\rangle\\). We have \\[\nN \\approx \\frac{\\partial \\log \\mathcal{Z}}{\\partial (\\beta\\mu)} = \\frac{Ve^{\\beta\\mu}}{h^3} \\bigg(\\frac{2\\pi m}{\\beta}\\bigg)^{3/2} = \\log \\mathcal{Z}.\n\\] This means all cumulants of \\(N\\) will be \\(\\log \\mathcal{Z}\\) as well. Recall all cumulants being equal implies that \\(N\\) must be Poisson distributed. The grand potential is evidently just \\(\\mathcal{G} = -N k_B T\\). But by extensivity \\(\\mathcal{G} = -PV\\). We thus get the ideal gas law, \\[\nPV = N k_B T.\n\\] Getting the energy is slightly trickier. It’s not too hard to show that \\[\nE - \\mu N = -\\frac{\\partial \\log \\mathcal{Z}}{\\partial \\beta} = N \\bigg(\\frac{3}{2} k_B T - \\mu\\bigg).\n\\] Cancelling \\(\\mu N\\) from both sides, we again get \\(E = \\frac{3}{2} N k_B T\\). Finally, if we like we can solve for the chemical potential by inverting the formula for \\(N\\). As expected, we have \\[\n\\mu = k_B T \\log \\frac{N}{V} \\bigg(\\frac{2\\pi m k_B T}{h^2}\\bigg)^{3/2}.\n\\]",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Classical Statistical Mechanics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/classical-gases.html",
    "href": "statistical-mechanics/classical-gases.html",
    "title": "Classical Gases",
    "section": "",
    "text": "Cumulant Expansion\nWe’ll start by formulating the partition function for a gas with an arbitrary interaction potential \\(U\\). Consider a gas of \\(N\\) indistinguishable particles in a fixed container \\(\\mathcal{B}\\) of volume \\(V\\). Suppose the gas has a Hamiltonian of the form \\[\nH = \\sum_{i=1}^N \\bigg(\\frac{\\mathbf{p}_i}{2m} + V(\\mathbf{x}_i)\\bigg) + U(\\mathbf{x}_1, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N),\n\\] where \\(V(\\mathbf{x}_i)\\) is the usual potential specifying that particle \\(i\\) must be inside the container, and \\(U(\\mathbf{x}_1, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N)\\) is some general interaction potential between the \\(N\\) particles. Let’s proceed using the canonical ensemble and try to find the partition function \\(Z(T,V,N)\\). Following the same logic as we did with the ideal gas, we have \\[\n\\begin{align*}\nZ &= \\frac{1}{N! h^{3N}} \\int d^{3N} \\mathbf{x} \\ d^{3N} \\mathbf{p} \\ e^{-\\beta H} \\\\\n&= \\frac{1}{N! h^{3N}}\\int_\\mathcal{B} d^{3N} \\mathbf{x} \\ e^{-\\beta U} \\int d^{3N} \\mathbf{p} \\ e^{-\\beta\\sum \\frac{\\mathbf{p}_i}{2m}} \\\\\n&= \\frac{1}{N!} \\bigg(\\frac{V}{\\lambda_T^3}\\bigg)^N \\int_\\mathcal{B} \\frac{d^{3N} \\mathbf{x}}{V^N} \\ e^{-\\beta U},\n\\end{align*}\n\\] where \\(\\lambda_T = \\frac{h}{\\sqrt{2\\pi m k_B T}}\\) is the Thermal DeBroglie wavelength defined previously. In this form, we recognize that the terms outside the integral are just the partition function of the ideal gas, which we’ll denote by \\(Z_0\\). If we think of \\(\\frac{1}{V^N}\\) is some kind of uniform probability density over the container \\(\\mathcal{B}\\) then we can imagine the above integral being some kind of expected value \\(\\langle e^{-\\beta U} \\rangle\\). We can thus write the partition function in the simple form \\[\nZ = Z_0 \\langle e^{-\\beta U} \\rangle.\n\\] Notice the expected value can be thought of as a kind of characteristic function for \\(U\\), except with \\(ik\\) replaced by \\(\\beta\\). If we expand the characteristic function as a series in terms of the moments, we get \\[\nZ = Z_0 \\sum_{k=0}^\\infty \\frac{(-\\beta)^k}{k!} \\langle U^k \\rangle.\n\\] That means if we instead look at \\(\\log Z\\), then the sum over the moments will become a sum over the cumulants, giving \\[\n\\log Z = \\log Z_0 + \\sum_{k=1}^\\infty \\frac{(-\\beta)^k}{k!} \\langle U^k \\rangle_c.\n\\] This is called the cumulant expansion. We’ve created an expansion of the free energy in terms of the cumulants of the interaction potential. Unfortunately though, we still have no systematic way to actually calculate these cumulants.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Classical Gases</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/classical-gases.html#cumulant-expansion",
    "href": "statistical-mechanics/classical-gases.html#cumulant-expansion",
    "title": "Classical Gases",
    "section": "",
    "text": "Pairwise Interactions\nTo make further progress we need to make assumptions about the functional form of the interaction potential. The most obvious first step is to imagine the potential consists only of pairwise interactions. While one could imagine interactions between three particles, four particles, or any higher number of them, it’s the pairwise interactions that encompass the common interactions found in nature for weakly interacting systems. Roughly speaking, provided we aren’t dealing with a dense plasma, pairwise interactions alone yield a sufficient description of the behavior of a gas.\nIn this form, the full potential \\(U\\) breaks up into a sum of potentials \\(u\\) over pairs of particles. We’ll assume the pairwise interactions only interact radially and ignore any self-interactions. We can thus write \\[\nU(\\mathbf{x}_1, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N) = \\sum_{i=1}^N \\sum_{j=i+1}^N u(|\\mathbf{x}_i - \\mathbf{x}_j|) \\equiv \\sum_{i &lt; j} u_{ij} \\ .\n\\]\nWith this functional form we can proceed to simplify the cumulants one by one. Let’s start with the mean. Notice that since all integrals are over the same potential over the same region, we can think of them as a multiple of a single pairwise integral. There are \\(\\binom{N}{2}\\) such integrals. Each integral is only over two coordinates. The rest yield a factor of \\(V^{N-2}\\). We thus have \\[\n\\begin{align*}\n\\langle U \\rangle_c &= \\sum_{i &lt; j} \\int_\\mathcal{B} \\frac{d^{3N} \\mathbf{x}}{V^N} \\ u_{ij} \\\\\n&= \\frac{N(N-1)}{2} \\frac{V^{N-2}}{V^N} \\int_\\mathcal{B} d^3\\mathbf{x}_1 \\ d^3\\mathbf{x}_2 \\ u_{12}.\n\\end{align*}\n\\] Finally, we can change variables and integrate over the center of mass coordinate \\(\\mathbf{X}\\) and relative coordinate \\(\\mathbf{x}\\). This lets us pull out another factor of \\(V\\). If we employ the thermodynamic limit and assume the interaction ranges are much less than the size of the container, we have \\[\n\\langle U \\rangle_c \\approx \\frac{N^2}{2V} \\int d^3\\mathbf{x} \\ u(r).\n\\] Using the same technique we can proceed to find the variance of \\(U\\) as well. Evidently, we have \\[\n\\langle U^2 \\rangle_c = \\sum_{i &lt; j} \\sum_{k &lt; \\ell} \\bigg(\\big\\langle u_{ij} u_{k\\ell} \\big\\rangle - \\big\\langle u_{ij} \\big\\rangle \\big\\langle u_{k\\ell} \\big\\rangle \\bigg).\n\\] We now have to proceed case-by-case. There are three cases to consider.\n\nCase 1 (\\(i \\neq k\\) and \\(j \\neq \\ell\\)): In this case all the position vectors are distinct. Since each position is independent, we can factor the joint moment to get \\(\\big\\langle u_{ij} u_{k\\ell} \\big\\rangle = \\big\\langle u_{ij} \\big\\rangle \\big\\langle u_{k\\ell} \\big\\rangle\\), which of course implies that the contributions of these terms must vanish in the variance calculation.\nCase 2 (\\(i=k\\) and \\(j \\neq \\ell\\)): In this case exactly two position vectors will be equal in each term. However, we can still change variables by defining \\(\\mathbf{x}_{ij} \\equiv \\mathbf{x}_i - \\mathbf{x}_j\\) and \\(\\mathbf{x}_{i\\ell} \\equiv \\mathbf{x}_i - \\mathbf{x}_\\ell\\). These relative position vectors are also independent of each other, which again means we can factor the joint moments to get \\(\\big\\langle u_{ij} u_{i\\ell} \\big\\rangle = \\big\\langle u_{ij} \\big\\rangle \\big\\langle u_{i\\ell} \\big\\rangle\\), which implies that the contributions of these terms must also vanish in the variance calculation.\nCase 3 (\\(i = k\\) and \\(j = \\ell\\)): The last case is when both pairs are the equal. This just implies that \\(\\big\\langle u_{ij} u_{ij} \\big\\rangle = \\big\\langle u_{ij}^2\\big\\rangle\\).\n\nWe finally have then that the variance of \\(U\\) is just \\[\n\\langle U^2 \\rangle_c = \\sum_{i &lt; j} \\bigg(\\big\\langle u_{ij}^2 \\big\\rangle -  \\big\\langle u_{ij}\\big\\rangle^2\\bigg).\n\\] In a way this kind of makes sense. The full variance is just the pairwise sum of the individual pairwise variances. Since each moment is just the same integral over \\(\\binom{N}{2}\\) possible configurations, we can simplify the expression to \\[\n\\langle U^2 \\rangle_c = \\frac{N(N-1)}{2} \\bigg[\\frac{1}{V}\\int_{\\mathcal{B}} d^3\\mathbf{x} \\ u^2(r) - \\frac{1}{V^2}\\bigg(\\int_{\\mathcal{B}} d^3\\mathbf{x} \\ u(r)\\bigg) \\bigg].\n\\] In the limit of large \\(N,V\\) the second term will be much smaller than the first, hence we can write \\[\n\\langle U^2 \\rangle_c \\approx \\frac{N^2}{2V} \\int d^3\\mathbf{x} \\ u^2(r).\n\\] This means to second order in the cumulants we can evidently write \\[\n\\begin{align*}\n\\log Z &\\approx \\log Z_0 - \\beta \\langle U \\rangle_c + \\frac{\\beta^2}{2} \\langle U^2 \\rangle_c - \\cdots \\\\\n&\\approx N \\log \\frac{Ve}{\\lambda^3} + \\frac{N^2}{2V} \\bigg(-\\beta \\int d^3\\mathbf{x} \\ u(r) + \\frac{\\beta^2}{2} \\int d^3\\mathbf{x} \\ u^2(r) - \\cdots\\bigg).\n\\end{align*}\n\\] To see what’s going on here it’s most useful to look at the pressure. Using the formula \\(\\beta P = \\frac{\\partial \\log Z}{\\partial V}\\), we have \\[\n\\beta P = \\frac{N}{V} - \\frac{N^2}{2V^2} \\bigg(-\\beta \\int d^3\\mathbf{x} \\ u(r) + \\frac{\\beta^2}{2} \\int d^3\\mathbf{x} \\ u^2(r) - \\cdots\\bigg).\n\\] It’s pretty clear now what we’ve done. We’ve created a series for the pressure in powers of the density \\(n=\\frac{N}{V}\\). This series is called the virial expansion. Had we kept higher-order interaction terms this series would continue on in higher powers of \\(n\\), \\[\n\\beta P = n - \\frac{n^2}{2} \\bigg(-\\beta\\int d^3\\mathbf{x} \\ u(r) + \\frac{\\beta^2}{2} \\int d^3\\mathbf{x} \\ u^2(r) - \\cdots\\bigg) + O(n^3).\n\\] In the most dilute limit we recover the ordinary ideal gas law. The first correction subtracts a term proportional to \\(n^2\\). And so on.\n\n\nMayer F-Function\nWhile it’s nice to have an expansion in terms of the density, what we have isn’t actually practical to work with. In particular, the second virial coefficient is a series of integrals that are not at all obvious to compute. We can attempt to sum it up though by using the expansion of the exponential function to write write \\[\n\\begin{align*}\n-\\beta \\int d^3\\mathbf{x} \\ u(r) + \\frac{\\beta^2}{2} \\int d^3\\mathbf{x} \\ u^2(r) - \\cdots &= \\int d^3\\mathbf{x} \\ \\sum_{k=1}^\\infty \\frac{(-\\beta)^k}{k!} u^k(r) \\\\\n&= \\int d^3\\mathbf{x} \\ \\bigg[\\exp\\big(-\\beta u(r)\\big) - 1\\bigg] . \\\\\n\\end{align*}\n\\] If we define the integrand to be \\(f(r) \\equiv \\exp\\big(-\\beta u(r)\\big) - 1\\), what we’ve done is found an expansion in terms of various integrals of \\(f(r)\\), called the Mayer f-function. The integral of this function will converge as long as the potential itself decays sufficiently rapidly, e.g. as the van der Waals interaction would. In terms of this function, we can re-write the virial expansion as \\[\n\\beta P = n - \\frac{n^2}{2} \\int d^3\\mathbf{x} \\ f(r) + O(n^3).\n\\] Provided we can integrate the Mayer f-function for some given interaction potential, we can find an expansion for the pressure at least up to second order in the density. It’s worth noting, however, that this is only a good expansion in the dilute limit when densities are small. In the opposite situation we’d have the dense limit, which describes the behavior of plasmas. In that scenario we’d want to use a completely different type of expansion, e.g. ring diagrams.\nOf course, we’d like to be able to look at all the higher virial coefficients as well, not just the second order term. Continuing to do so with cumulants will be cumbersome since we’re always stuck summing these kinds of series. The fact that things come out so cleanly in terms of the Mayer f-function suggests that we should instead consider expanding things in terms of it rather than the cumulants. This leads to the cluster expansion.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Classical Gases</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/classical-gases.html#cluster-expansion",
    "href": "statistical-mechanics/classical-gases.html#cluster-expansion",
    "title": "Classical Gases",
    "section": "Cluster Expansion",
    "text": "Cluster Expansion\nLet’s recall what it is we’re trying to evaluate. We’d like to find an expression for the partition function \\[\nZ = Z_0\\int_\\mathcal{B} \\frac{d^{3N} \\mathbf{x}}{V^N} \\ e^{-\\beta U} = Z_0 \\int_\\mathcal{B} \\frac{d^{3N} \\mathbf{x}}{V^N} \\prod_{i &lt; j} e^{-\\beta u_{ij}} \\ .\n\\] If we use the Mayer function to define \\(f_{ij} \\equiv e^{-\\beta u_{ij}}\\), we can instead write \\[\nZ = \\frac{Z_0}{V^N} \\int_\\mathcal{B} d^{3N} \\mathbf{x} \\prod_{i &lt; j} (1 + f_{ij}) \\equiv \\frac{Z_0}{V^N} Q.\n\\]\n\nCluster Diagrams\nOur challenge is to find a way to evaluate this integral over all possible pairs. If we expand the product \\(\\prod (1+f_{ij})\\) we’d get a series in increasing powers of \\(f\\), where each product appears exactly once, \\[\n\\prod_{i &lt; j} (1 + f_{ij}) = 1 + \\sum_{i &lt; j} f_{ij} \\ + \\sum_{i &lt; j &lt; k &lt; \\ell} f_{ij} f_{k\\ell} + \\cdots \\ .\n\\] It’s helpful to visualize this product in a different way using cluster diagrams. Imagine the \\(N\\) particles as representing \\(N\\) points in a graph. Think of each product of \\(f_{ij}\\) as an edge connecting the two points \\(i\\) and \\(j\\). In the expansion, a \\(1\\) represents no points being connected. A single \\(f_{ij}\\) represents only the points \\(i\\) and \\(j\\) being connected. A double term \\(f_{ij}f_{k\\ell}\\) represents two connections, one between \\(i\\) and \\(j\\), the other between \\(k\\) and \\(\\ell\\). And so on for higher order terms.\nIn this representation, we can schematically represent the general \\(Q\\) function as the sum over all possible graphs over \\(N\\) points, where each sum of \\(\\ell\\) powers of \\(f\\) represents a sum over all graphs with exactly \\(\\ell\\) edges, \\[\n\\begin{align*}\nQ &= \\int_\\mathcal{B} d^{3N} \\mathbf{x} \\prod_{i &lt; j} (1 + f_{ij}) \\\\\n&= \\int_\\mathcal{B} d^{3N} \\mathbf{x} \\bigg[1 + \\sum_{i &lt; j} f_{ij} \\ + \\sum_{i &lt; j &lt; k &lt; \\ell} f_{ij} f_{k\\ell} + \\cdots \\bigg] \\\\\n&= \\int_\\mathcal{B} d^{3N} \\mathbf{x} \\ \\bigg[(\\text{disconnected graph}) + \\sum (\\text{all graphs with one edge}) + \\sum (\\text{all graphs with two edges}) + \\cdots\\bigg] \\ .\n\\end{align*}\n\\] Though not necessarily obvious, we can use a trick from graph theory to reorganize this sum over graphs into something more convenient. For any one graph being summed, we can think of it as itself being a product of its own connected components. For example, suppose we had a particular graph of \\(N=6\\) points in which point \\(1\\) is disconnected, points \\(2\\) and \\(3\\) are connected, and points \\(4\\), \\(5\\), and \\(6\\) are all connected to each other. This would represent the product \\[\n\\int_\\mathcal{B} d^{3} \\mathbf{x}_1 \\int_\\mathcal{B} d^{3} \\mathbf{x}_2 d^{3} \\mathbf{x}_3 \\ f_{23} \\int_\\mathcal{B} d^{3} \\mathbf{x}_4 d^{3} \\mathbf{x}_5 d^{3} \\mathbf{x}_6 \\ f_{45} f_{56}.\n\\] Now, define \\(b_\\ell\\) to be the sum of all connected components connecting exactly \\(\\ell\\) points. That is, \\(b_1\\) is the sum over all completely disconnected clusters, \\(b_2\\) is the sum over all pairs of connected edges, \\(b_3\\) is the sum over all triplets of connected points, and so on. Diagrammatically these might look as follows.\n\n\n\n\n\nNote how the number of terms in the sum blows up with increasing \\(\\ell\\). For example, \\(b_1\\) and \\(b_2\\) each contain one configuration, \\(b_3\\) contains \\(4\\) configurations. It turns out that \\(b_4\\) contains \\(24\\) different terms. That is, there are \\(24\\) ways to connect \\(4\\) points with all possible configurations of edges. Etc.\nNow, for each graph being summed over in the \\(Q\\) function, we expect there to be some number \\(n_\\ell\\) of components in that graph connecting exactly \\(\\ell\\) points. Taking the product over all of these components for each \\(\\ell = 1, \\cdots, N\\) then gives the value of that one graph. In doing this, note that some components may end up being over-counted, so we have to include a multiplicity factor \\(W(\\{n_\\ell\\})\\) in each product to correct the counts. In the end, we’re now representing \\(Q\\) as a sum over all graphs such that each graph contains exactly \\(N\\) points and partitions into exactly \\(n_\\ell\\) clusters for each allowed \\(\\ell\\). As an equation, this means\n\\[\nQ = \\sideset{}{'}\\sum_{\\underset{N=\\sum n_\\ell \\ell}{\\{n_\\ell\\}}} W(\\{n_\\ell\\})\\prod_{\\ell=0}^N b_\\ell^{n_\\ell} \\ .\n\\] Notice the notation used here. This is a constrained sum, a sum over all partitions such that that \\(N=\\sum_\\ell n_\\ell \\ell\\). The multiplicity factor \\(W(\\{n_\\ell\\})\\) turns out to have the explicit form \\[\nW(\\{n_\\ell\\}) = \\frac{N!}{\\prod_\\ell (\\ell!)^{n_\\ell} n_\\ell!}.\n\\] This comes from the fact that for each graph we’re permuting \\(N\\) points. But for each connected component we need to divide out the number of ways of permuting those points. Since there are \\(n_\\ell\\) such components, this means we need to divide by \\((\\ell!)^{n_\\ell}\\) for each \\(\\ell\\). We’re still overcounting though, because exchanging any \\(\\ell\\) cluster with another \\(\\ell\\) cluster shouldn’t change anything, so we also need to divide by \\(n_\\ell!\\). This gives the full multiplicity factor.\nAt any rate, attempting to sum over all graphs to get \\(Q\\) still seems like a daunting task. This is mainly due to the constrained sum, which requires that we sum over all possible partition sizes \\(n_\\ell\\) consistent with the constraint \\(\\sum \\ell n_\\ell = N\\). In general finding constrained sums is hard. But there’s a work around. Namely, we can allow \\(N\\) to vary as well. We can do that by looking not at the canonical partition function \\(Z\\), but instead the grand canonical partition function \\(\\mathcal{Z}\\). Then all we have to do is replace any occurrence of \\(N\\) with \\(\\sum \\ell n_\\ell\\) and sum over all possible partitions \\(\\{n_\\ell\\}\\). Then we’ll have \\[\n\\begin{align*}\n\\mathcal{Z} &= \\sum_{N=0}^\\infty e^{\\beta\\mu N} Z \\\\\n&= \\sum_{N=0}^\\infty e^{\\beta\\mu N} \\sideset{}{'}\\sum_{\\underset{N=\\sum n_\\ell \\ell}{\\{n_\\ell\\}}} \\frac{W(\\{n_\\ell\\})}{N! \\lambda^{3N}}\\prod_{\\ell=0}^N b_\\ell^{n_\\ell} \\\\\n&= \\sum_{\\{n_\\ell\\}} \\bigg(\\frac{e^{\\beta\\mu}}{\\lambda^3}\\bigg)^{\\sum \\ell n_\\ell} \\frac{1}{\\prod_\\ell (\\ell!)^{n_\\ell} n_\\ell!} \\prod_{\\ell=0}^{\\sum \\ell n_\\ell} b_\\ell^{n_\\ell} \\\\\n&= \\prod_{\\ell=1}^\\infty \\sum_{n_\\ell=0}^\\infty \\frac{b_\\ell^{n_\\ell}}{(\\ell!)^{n_\\ell} n_\\ell!} \\bigg(\\frac{e^{\\beta\\mu}}{\\lambda^3}\\bigg)^{\\ell n_\\ell} \\\\\n&= \\prod_{\\ell=1}^\\infty \\exp\\bigg[\\frac{b_\\ell}{\\ell!} \\bigg(\\frac{e^{\\beta\\mu}}{\\lambda^3}\\bigg)^{\\ell}\\bigg] \\ .\n\\end{align*}\n\\] Taking the logarithm then converts the product into the simpler sum \\[\n\\boxed{\n\\log \\mathcal{Z} = \\sum_{\\ell=1}^\\infty \\frac{b_\\ell}{\\ell!} \\bigg(\\frac{e^{\\beta\\mu}}{\\lambda^3}\\bigg)^{\\ell}\n} \\ .\n\\]\n\n\nVirial Expansion\nAs with the cumulant expansion, what we’re mainly interested in here is getting a formula for the pressure. The easiest way to do that here is to use extensivity. Using the fact \\(\\mathcal{G} = -k_B T \\log \\mathcal{Z} = -PV\\) for an extensive system, we can express the pressure as \\[\n\\beta P = \\frac{1}{V} \\log \\mathcal{Z} = \\sum_{\\ell=1}^\\infty \\frac{1}{\\ell!} \\frac{b_\\ell}{V} \\bigg(\\frac{e^{\\beta\\mu}}{\\lambda^3}\\bigg)^{\\ell}.\n\\] Notice that this quantity must be intensive since \\(\\log \\mathcal{Z}\\) must be extensive and we’re dividing by the volume \\(V\\). To make this clear, let’s conveniently define \\(\\textblank_\\ell \\equiv \\frac{b_\\ell}{V}\\). Let’s also define \\(x \\equiv \\frac{e^{\\beta\\mu}}{\\lambda_T^3}\\). Noting that \\(b_1 = V\\) implies \\(\\textblank_1 = 1\\), we can thus write \\[\n\\beta P = \\sum_{\\ell=1}^\\infty \\frac{\\textblank_\\ell}{\\ell!} x^{\\ell} = x + \\frac{\\textblank_2}{2} x^2 + \\frac{\\textblank_3}{6} x^3 + \\cdots \\ .\n\\] We thus have a series for pressure in terms of this scaled fugacity variable \\(x\\). However, what we’d like to get is a virial expansion. That is, we’d like to express the pressure as a series in increasing powers of the density \\(n\\), \\[\n\\beta P = n + B_2 n^2 + B_3 n^3 + \\cdots \\ .\n\\] To do that, recall that we can express \\(N \\approx \\langle N \\rangle\\) in the grand canonical ensemble with the formula \\(N = \\frac{\\partial \\log \\mathcal{Z}}{\\partial (\\beta\\mu)}\\). Dividing both sides by \\(V\\) and again using extensivity, we can then express the number density \\(n\\) as its own series in powers of \\(x\\), \\[\nn = \\frac{1}{V} \\frac{\\partial \\log \\mathcal{Z}}{\\partial (\\beta\\mu)} = \\sum_{\\ell=1}^\\infty \\frac{\\textblank_\\ell}{(\\ell-1)!} x^{\\ell} = x + \\textblank_2 x^2 + \\frac{\\textblank_3}{2} x^3 + \\cdots \\ .\n\\] We’ve managed to express both \\(\\beta P\\) and \\(n\\) each as a series expansion in \\(x\\). To find \\(\\beta P\\) as a function of \\(n\\) we need to eliminate \\(x\\). To do that we need to invert the series \\(n=n(x)\\) to get \\(x=x(n)\\). In general, there’s no way to invert a series like this and get a closed form solution for \\(x=x(n)\\). However, we can get a series for \\(x\\) in powers of \\(n\\). This method will suffice for us, as we’re only interested in the first few terms in the virial expansion anyway.\nTo invert a power series we start by supposing that the inverse \\(x=x(n)\\) itself can be expanded as a power series in \\(n\\) with coefficients that need to be determined, \\[\nx = a_1 n + a_2 n^2 + a_3 n^3 + O(n^4) \\ .\n\\] To find the coefficients we substitute this expression back into the expression for \\(n=n(x)\\) and match terms by powers. We can find \\(a_1\\) immediately be noting that when \\(x\\) is infinitesimal we must have \\(n \\approx x\\), meaning \\(a_1 = 1\\). We’ll then proceed by finding coefficients up to \\(O(n^3)\\). Substituting \\(x\\) back into \\(n(x)\\) and keeping terms only up to \\(O(n^3)\\), we have \\[\n\\begin{align*}\nn &= x + \\textblank_2 x^2 + \\frac{\\textblank_3}{2} x^3 + O(x^4) \\\\\n&= (n + a_2 n^2 + a_3 n^3) + \\textblank_2 (n + a_2 n^2 + a_3 n^3)^2 + \\frac{\\textblank_3}{2} (n + a_2 n^2 + a_3 n^3)^3 + O(n^4) \\\\\n&= (n + a_2 n^2 + a_3 n^3) + \\textblank_2 (n^2 + 2 a_2 n^3) + \\frac{\\textblank_3}{2} n^3 + O(n^4) \\\\\n&= n + \\big(a_2 + \\textblank_2\\big) n^2 + \\bigg(a_3 + 2 \\textblank_2 a_2 + \\frac{\\textblank_3}{2}\\bigg) n^3 + O(n^4) \\ .\n\\end{align*}\n\\] Now, for the left side to equal the right-hand side the coefficients for each higher power of \\(n\\) must be zero. Starting with \\(n^2\\) we have \\(a_2 = -\\textblank_2\\). Plugging this into the coefficient for \\(n^3\\), we then get \\(a_3 = \\big(2\\textblank_2^2 - \\frac{\\textblank_3}{2}\\big)\\). We can continue onto as many powers as we like by working in this way, but we’ll stop here. We’ve evidently found that \\[\nx = n - \\textblank_2 n^2 + \\bigg(2\\textblank_2^2 - \\frac{\\textblank_3}{2}\\bigg) n^3 + O(n^4) \\ .\n\\] Now we can substitute this into \\(\\beta P\\) to get an expansion in powers of the density \\(n\\). We have \\[\n\\begin{align*}\n\\beta P &= x + \\frac{\\textblank_2}{2} x^2 + \\frac{\\textblank_3}{6} x^3 + \\cdots \\\\\n&\\approx \\bigg[n - \\textblank_2 n^2 + \\bigg(2\\textblank_2^2 - \\frac{\\textblank_3}{2}\\bigg)n^3\\bigg] \\\\\n&+ \\frac{\\textblank_2}{2}\\bigg[n - \\textblank_2 n^2 + \\bigg(2\\textblank_2^2 - \\frac{\\textblank_3}{2}\\bigg)n^3\\bigg]^2 \\\\\n&+ \\frac{\\textblank_3}{6}\\bigg[n - \\textblank_2 n^2 + \\bigg(2\\textblank_2^2 - \\frac{\\textblank_3}{2}\\bigg)n^3\\bigg]^3. \\\\\n\\end{align*}\n\\] Rearranging terms in increasing powers of \\(n\\), we finally have a virial expansion up to \\(O(n^4)\\), \\[\n\\beta P = n - \\frac{\\textblank_2}{2} n^2 + \\bigg(\\textblank_2^2-\\frac{\\textblank_3}{3}\\bigg) n^3 + O(n^4).\n\\] We now have a systematic way to get a virial expansion up to any arbitrary power of \\(n\\). After some simplification, the first few virial coefficients turn out to be given by \\[\n\\begin{align*}\nB_1(T) &= 1 \\ , \\\\\nB_2(T) &= -\\frac{\\textblank_2}{2} = -\\frac{1}{2} \\int_{\\mathcal{B}} d^3 \\mathbf{x} \\ f(\\mathbf{x}) \\ , \\\\\nB_3(T) &= \\bigg(\\textblank_2^2-\\frac{\\textblank_3}{3}\\bigg) = -\\frac{1}{3} \\int_{\\mathcal{B}} d^3 \\mathbf{x} \\ d^3 \\mathbf{x}' \\ f(\\mathbf{x}) f(\\mathbf{x}') f(\\mathbf{x}-\\mathbf{x}') \\ . \\\\\n\\end{align*}\n\\] Notice the first two virial coefficients agree with what we calculated from the cumulant expression. The \\(B_3\\) term is new, as we had no easy way to calculate it before. In principle we could keep going to higher order coefficients if we like, but we won’t.\nOf course, we still have no way to actually calculate what the virial coefficients are since we don’t know what the interaction potential \\(u\\) is, hence neither what the Mayer function \\(f\\) is. To proceed further we need to make some assumptions about the interaction potentials involved in a typical gas.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Classical Gases</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/classical-gases.html#van-der-waals-interactions",
    "href": "statistical-mechanics/classical-gases.html#van-der-waals-interactions",
    "title": "Classical Gases",
    "section": "Van der Waals Interactions",
    "text": "Van der Waals Interactions\nThe true interaction forces in real gases can be quite complicated. Typically gases will be electrically neutral, so Coulomb forces don’t tend to play a role. What’s left are much shorter-range forces arising from the permanent or induced dipole interactions between particles. These short-range forces are called van der Waals forces. Typically, such forces fall off very rapidly with the particle separation distance, and rapidly increase as the two particles get too close together. To understand exactly why these forces occur and how they really behave we’d need fairly advanced quantum mechanics. But for our purposes it suffices to adopt a highly simplified crude model, which will lead us to the van der Waals equation of state.\n\nSimple Model\nA very crude model of the van der Waals force is to assume interactions arise from a radially symmetric potential of the form \\[\nu(r) =\n\\begin{cases}\n-u_0 \\big(\\frac{r_0}{r}\\big)^6 & r \\geq r_0 \\ , \\\\\n\\infty & r &lt; r_0 \\ . \\\\\n\\end{cases}\n\\] At close distances we’ll assume the force is infinitely repulsive when \\(r &lt; r_0\\). This hard wall idea approximates the effect that particles will bounce off each other if they get too close, within some distance \\(r_0\\) that’s usually on the order of Angstroms for atoms or molecules. When \\(r \\gg r_0\\) the force becomes weakly attractive, with the potential falling off like \\(r^{-6}\\). The remaining positive constant \\(u_0\\) characterizes the strength of the interaction, usually around room temperature in temperature units.\n\n\n\n\n\nWe can now proceed to calculate the virial coefficients for such an interaction. We already know \\(B_1 = 1\\), so there’s nothing to do there. We’ll recover the ideal gas law at low densities as expected. For \\(B_2\\), we need to find the integral of \\(f(r)\\), which is \\[\n\\begin{align*}\n\\int_{\\mathcal{B}} d^3 \\mathbf{x} \\ f(r) &= \\int_0^\\infty 4\\pi r^2 dr \\ \\big(e^{-\\beta u(r)}-1\\big) \\\\\n&= -\\int_0^{r_0} 4\\pi r^2 dr + \\int_{r_0}^\\infty 4\\pi r^2 dr \\ \\bigg[\\exp\\bigg(\\beta u_0 \\bigg(\\frac{r_0}{r}\\bigg)^6\\bigg)-1\\bigg] \\\\\n&= -\\frac{4\\pi}{3} r_0^3 + \\int_{r_0}^\\infty 4\\pi r^2 dr \\ \\bigg[\\exp\\bigg(\\beta u_0 \\bigg(\\frac{r_0}{r}\\bigg)^6\\bigg)-1\\bigg] . \\\\\n\\end{align*}\n\\] To get at the second term analytically we’ll have to make a further approximation. Suppose \\(\\beta u_0 \\ll 1\\), meaning \\(u_0 \\ll k_B T\\). This is the high temperature regime of classical statistical mechanics. Here we can approximate the integral as \\[\n\\int_{r_0}^\\infty 4\\pi r^2 dr \\ \\bigg[\\exp\\bigg(\\beta u_0 \\bigg(\\frac{r_0}{r}\\bigg)^6\\bigg)-1\\bigg] \\approx \\int_{r_0}^\\infty 4\\pi r^2 dr \\ \\beta u_0\\bigg(\\frac{r_0}{r}\\bigg)^6 = \\frac{4\\pi}{3} r_0^3 \\beta u_0.\n\\] Notice both terms include the term \\(\\omega \\equiv \\frac{4\\pi}{3} r_0^3\\). This is just the volume of a sphere of radius \\(r_0\\), called the excluded volume. It’s the volume of each particle’s electron cloud in a sense. In terms of the excluded volume, we can thus write \\(B_2\\) simply as \\[\nB_2(T) = -\\frac{1}{2} \\int_{\\mathcal{B}} d^3 \\mathbf{x} \\ f(r) = \\frac{\\omega}{2} (1-\\beta u_0).\n\\] In principle, we could also then proceed to calculate the third virial coefficient \\(B_3\\). However, this turns out to be much harder, as now we have to integrate over three-particle interactions. We can eliminate one of the coordinates and write \\[\nB_3(T) = -\\frac{1}{3} \\int_{\\mathcal{B}} d^3 \\mathbf{x} \\ d^3 \\mathbf{x}' \\ f(\\mathbf{x}) f(\\mathbf{x}') f(\\mathbf{x}-\\mathbf{x}'),\n\\] but actually evaluating this integral analytically is an onerous task. Of course, it can often be found numerically. And on the story goes for the higher virial coefficients as well. We’re thus left with the approximation \\[\n\\beta P = n + \\frac{\\omega}{2} (1-\\beta u_0) n^2 + O(n^3) + \\cdots.\n\\] Let’s just focus on the second order part of this equation and see what happens in that case. Whatever it is should at least be more accurate than the ideal gas approximation. If we group the terms involving \\(\\beta\\) on the left-hand side, we have \\[\n\\beta \\bigg(P + \\frac{\\omega u_0}{2} n^2\\bigg) = n + \\frac{\\omega}{2} n^2 + \\cdots \\ .\n\\] Now, for small \\(n\\), the right-hand side looks like the binomial series expansion for \\(\\big(1-\\frac{N\\omega}{2}\\big)^{-1}\\). Let’s conveniently define two constants, \\(a \\equiv \\frac{1}{2} u_0 \\Omega\\) and \\(b \\equiv \\frac{\\omega}{2}\\). If we do that and use the fact that \\(n = \\frac{N}{V}\\), we can write the above equation as \\[\n\\boxed{\n\\bigg(P + a\\frac{N^2}{V^2}\\bigg)(V-Nb) = Nk_B T.\n}\n\\] In this form, the equation of state gives the well-known van der Waals equation of chemistry.\n\n\nValidity of van der Waals\nBefore proceeding, it’s worth stepping back and asking whether the virial expansion we just performed is a good expansion, that it makes sense physically. Let’s try to see what might cause the van der Waals equation to fail:\n\nHigh densities: Clearly if \\(n\\) is large we can’t truncate the virial expansion to second order like we did. We’d need to deal with all the higher order terms as well. Fortunately for a gas this isn’t really an issue. Notice that the series grows like the ratio of the first two terms, which goes like \\[\n\\frac{B_2n^2}{B_1n} = \\frac{\\frac{\\omega}{2} (1-\\beta u_0)n^2}{n} \\sim n\\omega.\n\\] Roughly speaking, \\(n\\omega\\) is the density of the gas divided by its density when liquified. For air at STP, we already saw that ratio of densities is about \\(10^{-3}\\), clearly small enough that we can justify neglecting higher order terms in the expansion. Of course, while this is true for gases, it’s not always true. For example, it’s not true for liquids or plasmas.\nLow temperatures: In deriving the virial coefficient \\(B_2\\) we made the crucial assumption that \\(k_B T \\gg u_0\\). That is, we assumed that temperatures are large compared to the molecular interaction strengths. For gases at room temperatures this is fine, but as temperatures go towards absolute zero things break down and this approximation no longer holds.\nLong-range interactions: Another failure mode we didn’t explicitly mention above is the nature of the interaction potential. We assumed a potential of the form \\(u(r) \\sim r^{-6}\\), which we were able to integrate from \\(r_0\\) to \\(\\infty\\). If we look back at the integral though, we can see that won’t be true for every power of \\(r\\). In particular, such an integral will diverge for powers \\(k &gt; -3\\). This means, for example, that we can’t treat Coulomb interactions this way, where \\(k=-1\\). These divergent integrals arise when interactions are long-range, i.e. when they don’t fall off reasonably fast. For the van der Waals potential we don’t have this problem. But if we’re dealing with, say plasmas, we do have to worry about this issue. In that case we’d need to do a completely different kind of expansion, e.g. using ring diagrams.\n\nThe van der Waals equation was originally derived phenomenologically based on the following two physical arguments:\n\nWe expect the available volume to each particle is reduced by an amount proportional to \\(N\\). Each particle occupies a definite volume, namely the excluded volume \\(\\omega\\). As we saw from the hard sphere gas, this means that the available volume gets reduced by \\(\\frac{N\\omega}{2}\\), not \\(N\\omega\\) as we might expect.\nThe presence of an interaction strength \\(u_0\\) means each particle spends more time away from the walls of the container due to particles in the center attracting it inward. This has the effect of reducing the pressure on the walls of the container by some amount proportional to \\(n^2\\).\n\nIn the lab, \\(a\\) and \\(b\\) are measured experimentally and tabulated for each gas of interest. For most real gases the parameters tend to be quite small at typical densities. For example, for water, tables give the van der Waals constants in chemistry units as \\(a = 5.464 \\ \\frac{\\text{L}^2 \\ \\text{atm}}{\\text{mol}^2}\\) and \\(b = 0.03049 \\ \\frac{\\text{L}}{\\text{mol}}\\). In SI units, these become \\(a = 1.53 \\cdot 10^{-48}\\) and \\(b = 5.06 \\cdot 10^{-29}\\).\nIn typical conditions the pressure correction will often be much larger than the volume correction. With water, the volume correction becomes important when \\(nb \\sim 1\\), or when the mass density gets up to \\(\\rho \\sim 0.6 \\ \\frac{\\text{g}}{\\text{cm}^3}\\). Note the density of liquid water is about \\(\\rho \\sim 1 \\ \\frac{\\text{g}}{\\text{cm}^3}\\), meaning water practically needs to liquify for the volume correction to become important. Compare that with the pressure correction, which becomes important when \\(an^2 \\ll P\\). At atmospheric pressure, this effect would seem to become important when \\(\\rho \\sim 0.008 \\ \\frac{\\text{g}}{\\text{cm}^3}\\), which is much smaller, closer to the density of air in fact.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Classical Gases</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/classical-gases.html#phase-transitions",
    "href": "statistical-mechanics/classical-gases.html#phase-transitions",
    "title": "Classical Gases",
    "section": "Phase Transitions",
    "text": "Phase Transitions\nThe fact that the van der Waals equation only seems to become important as a gas starts to liquify suggests that we should study this transition region from gas to liquid. This is one of many examples of a phase transition, a discontinuous change in the properties of a system as a state variable changes. When dealing with gases, phase transitions often manifest as sharp lines in the phase diagram, i.e. the diagram of pressure vs temperature. Recall such a diagram looks very roughly like the following.\n\n\n\n\n\nPhase diagrams often show similar patterns. At low \\(T\\) and \\(P\\) the gas is in its solid phase. All the particles are aligned in something like a crystal lattice. As \\(T\\) increases the gas moves into its liquid phase. In this phase, the particles are still close together, but they’re no longer locked into a lattice anymore. They’re allowed to move around on top of each other. As \\(T\\) increases further the gas moves into its gas phase. In this phase the particles start to move apart from each other, behaving more like an ideal gas.\nWhat’s more interesting are the sharp lines separating the phases, called coexistence curves. Suppose we fixed \\(T\\) relatively high and started increasing \\(P\\). The gas starts in its gas phase, but at some pressure \\(P=P(T)\\) the gas undergoes a phase transition, turning sharply into a liquid as it crosses the gas-liquid coexistence curve. What’s more interesting though is that this fact is only true for temperatures below some critical temperature \\(T_c\\). If \\(T &gt; T_c\\) no phase transition happens at all. The gas stays in the same phase and just gets continuously more dense. Something strange evidently happens at this critical point.\n\nCritical Points\nTo understand this in more depth let’s consider again the van der Waals interaction \\(PV\\) diagram. As a function of \\(P\\), we have \\[\nP = \\frac{Nk_B T}{V-Nb} - a \\frac{N^2}{V^2}.\n\\] If we plot the isotherms of this equation for different values of \\(T\\), we get something roughly like the following.\n\n\n\n\n\nFirst, notice that all the isotherms asymptotically approach the reduced volume \\(Nb=\\frac{N\\omega}{2}\\) as \\(V \\rightarrow 0\\). This is a consequence of the physical fact that the gas becomes incompressible once it reaches its liquid phase. The isotherms separate into three distinct regimes depending on whether \\(T\\) is greater than some special critical temperature \\(T_c\\),\n\nWhen \\(T \\gg T_c\\) the \\(n^2\\) term is negligible and we essentially recover the hard sphere isotherms with \\(P(V-Nb) \\propto T\\). These are the green curves plotted. As \\(V \\gg Nb\\) these reduce to the ideal gas isotherms with \\(PV \\propto T\\).\nWhen \\(T \\ll T_c\\) we get the curves plotted in red. Unlike the green curves, these have a region with a wiggle. For a given pressure in this region, the curve seems to imply the gas can coexist at three different volumes (and hence three different densities as well). In reality, one of these is disallowed by thermodynamic stability. The dashed part of the curve is unstable since it has negative compressibility. As we’ll see, the black line correctly describes the curve in this region.\nLast, the critical isotherm at \\(T=T_c\\) is plotted in blue. This curve is what separates the first two regimes. Each pressure corresponds to a unique volume, but the curve does have a flat region around some special critical point \\((V_c,P_c)\\).\n\nWe can pretty easily solve for the critical values \\((T_c,V_c,P_c)\\). Since we have three values to solve for, we need to find three independent equations. The first is easy, as \\((T,V,P)\\) must clearly satisfy the van der Waals equation to lie on any of these curves at all. For the other two equations, we impose the condition that we’re on the \\(T=T_c\\) isotherm. A sufficient condition for this to hold is that the first and second derivatives of \\(P(V)\\) must vanish at the critical point. That is, we need to solve the following, \\[\n\\begin{align*}\nP &= \\frac{Nk_B T}{V-Nb} - a \\frac{N^2}{V^2} \\ , \\\\\n\\frac{\\partial P}{\\partial V} \\bigg |_{T,N} &= -\\frac{Nk_B T}{(V-Nb)^2} + 2a \\frac{N^2}{V^3} \\equiv 0 \\ , \\\\\n\\frac{\\partial^2 P}{\\partial V^2} \\bigg |_{T,N} &= 2\\frac{Nk_B T}{(V-Nb)^3} - 6a \\frac{N^2}{V^4} \\equiv 0 \\ . \\\\\n\\end{align*}\n\\] These can be simultaneously solved to give \\[\nT_c = \\frac{8a}{27k_Bb} , \\qquad V_c = 3Nb , \\qquad P_c = \\frac{a}{27b^2} \\ .\n\\] The second equation is more often expressed in terms of a critical density to get rid of the dependence on \\(N\\), defined by \\(\\rho_c \\equiv mn_c \\equiv \\frac{Nm}{V_c}\\). As an example, for water, the critical values would be \\[\nT_c \\approx 650 \\ ^\\circ \\text{K} \\ , \\qquad \\rho_c \\approx 0.19 \\ \\frac{\\text{g}}{\\text{cm}^3} \\ , \\qquad P_c \\approx 218 \\text{ atm} \\ .\n\\] Note that while \\(T_c\\) and \\(P_c\\) agree with experiment, the critical density is slightly off. The measured value is actually \\(\\rho_c \\approx 0.33\\) in the same units. This discrepancy has to do with dipole-dipole interactions among water molecules that we’re not accounting for.\n\n\nStability\nBut what exactly do these critical values represent? Clearly something is going on around the critical temperature that we should investigate. Above \\(T_c\\) everything appears to be what we’d expect. We recover ideal gas like behavior, with some minor corrections as \\(T \\rightarrow T_c\\) from above. Let’s look at the situation where \\(T &lt; T_c\\) and see what might be happening. As mentioned above, the isotherms in this region exhibit non-physical behavior in the regions where the slope of the curve is increasing. Such a phenomenon would imply negative compressibility, since in the positively-sloped region we’d have \\[\n\\kappa = -\\frac{1}{V} \\frac{\\partial V}{\\partial P} \\bigg |_{T,N} &lt; 0.\n\\] Negative compressibility would imply a gas gets bigger as the pressure on it increases. But this is thermodynamically unstable. In fact it even violates the laws of statistical mechanics. To see why, recall by extensivity we have \\(\\log \\mathcal{Z} = \\beta PV\\), which implies \\[\n\\begin{align*}\nN &\\approx \\langle N \\rangle = \\frac{\\partial \\log\\mathcal{Z}}{\\partial (\\beta\\mu)} = V\\frac{\\partial P}{\\partial \\mu} \\bigg |_T \\ , \\\\\n\\sigma_N^2 &= \\frac{\\partial^2 \\log\\mathcal{Z}}{\\partial (\\beta\\mu)^2} = \\frac{\\partial N}{\\partial (\\beta\\mu)} = k_B T \\frac{\\partial N}{\\partial \\mu} \\bigg |_T \\ . \\\\\n\\end{align*}\n\\] Dividing the two expressions and using the chain rule, we have \\[\n\\begin{align*}\n\\frac{\\sigma_N^2}{N} &= \\frac{k_B T \\frac{\\partial N}{\\partial \\mu} \\big |_T}{V\\frac{\\partial P}{\\partial \\mu} \\big |_T} \\\\\n&= \\frac{k_B T}{V} \\frac{\\partial N}{\\partial P} \\bigg |_T \\\\\n&= \\frac{k_B T}{V} \\bigg(-\\frac{\\partial N}{\\partial V} \\bigg |_{T,P} \\ \\frac{\\partial V}{\\partial P} \\bigg |_{T,N}\\bigg) \\\\\n&= -\\frac{k_B T}{V} \\frac{N}{V} \\ \\frac{\\partial V}{\\partial P} \\bigg |_{T,N} \\\\\n&= \\frac{N k_B T}{V} \\bigg(- \\frac{1}{V} \\frac{\\partial V}{\\partial P} \\bigg |_{T,N} \\bigg) \\\\\n&= n k_B T \\ \\kappa_T \\ .\n\\end{align*}\n\\] Now, recall the variance of a random variable must always be non-negative. This implies the above ratio must also be non-negative, which implies the compressibility must be as well. From thermodynamics, we also know that this must also imply thermodynamical stability \\(\\delta P \\delta V \\leq 0\\), which we saw is equivalent to having \\(\\kappa \\geq 0\\). These stability conditions are essentially what determine which states are allowed and which aren’t. Thermodynamically unstable states can’t really happen, at least with any reasonable probability in the thermodynamic limit.\n\n\nMaxwell Construction\nSo what’s going on in the subcritical regime where \\(T &lt; T_c\\)? In fact a phase transition is happening. Imagine varying the pressure on the gas and seeing how the volume (and hence the density) of the gas changes, e.g. by applying a force to a piston.\n\nAt low pressures the allowed states are on the far right of the subcritical isotherms. In this region the ideal gas law more or less holds, perhaps with minor corrections. Any small changes in pressure will cause proportionally small changes in the volume of the gas. That is, the gas behaves like a gas. It’s in its gas phase.\nAt high pressures the allowed states are instead on the far left of the isotherms, asymptotically approaching the barrier at the excluded volume \\(Nb\\). In this region, to get a small change in volume we’d need to apply a huge change in pressure. The gas is almost incompressible. In fact, the gas is in its liquid phase, since \\(V \\approx Nb\\) implies the particles are densely packed together.\nIn between these two regions the gas is in coexistence. At a given pressure \\(P_{co}\\), the curve takes on three distinct volumes (i.e. three densities). Two of these volumes are stable, meaning they can occur. The third is unstable, meaning it can’t occur. This means if we’re exactly at \\(P_{co}\\) the gas seemingly exists in two volumes at once, call them \\(V_{gas}\\) and \\(V_{liq}\\). This region of the \\(PV\\) diagram where two densities can simultaneously coexist is called the coexistence region. Due to the discontinuity, when crossing this region, the volume of the gas will evidently change by some discontinuous amount \\(\\Delta V = V_{gas} - V_{liq}\\) as it apparently undergoes a phase transition from liquid to gas or vice versa.\n\nOf course, the van der Waals equation isn’t right for a real gas at arbitrary densities. It’s only a dilute approximation. It should and indeed does fail for dense gases. That it’s predicting the behavior of a liquid and the phase transition is thus interesting. Maybe we can correct the equation to work even better by fixing what’s going on in the coexistence region.\nConsider again the formula for the particle number along an isotherm, \\[\nN = V\\frac{\\partial P}{\\partial \\mu} \\bigg |_T.\n\\] To get the chemical potential along an isotherm we can rearrange and integrate \\(d\\mu = \\frac{V}{N}dP\\) to get \\[\n\\mu(P) - \\mu(P_0) = \\int_{P_0}^P dP' \\ \\frac{V(P')}{N}.\n\\] Let’s stop and think about what this integration is doing. It’s summing up horizontal slices under the isotherm from \\(P_0\\) to \\(P\\). As long as \\(V(P)\\) is single-valued this is perfectly fine. But inside the coexistence region \\(V(P)\\) is not single-valued, which means the integral will be path-dependent. For example, consider the following situation. Suppose we wanted to find the chemical potential from the point \\(A\\) to the point \\(F\\) along the isotherm shown below.\n\n\n\n\n\nAlong the path \\(ABC\\) the chemical potential \\(\\mu\\) keeps increasing since \\(dP\\) is positive. Along \\(CD\\) though \\(dP\\) is negative, which means \\(\\mu\\) goes back down. Then, along \\(DF\\), \\(dP\\) is positive again, causing \\(\\mu\\) to again start increasing. The trajectory \\(\\mu(P)\\) will cross at the points \\(B\\) and \\(E\\), causing the chemical potential to seemingly be multiple-valued in the region between \\(C\\) and \\(D\\). This crossing point occurs at the coexistence pressure \\(P_{co}=P_E=P_B\\).\nTo fix this problem we can make use of the thermodynamical fact that in equilibrium the gas should seek out the lowest available chemical potential at a given temperature and pressure. This means that in the multiple-valued region the gas should only traverse lower part of the path between \\(C\\) and \\(D\\) i.e. the path \\(ABF\\). For this to be true the closed loop \\(CDE\\) should vanish, \\[\n\\oint_{P_B}^{P_E} dP \\ \\frac{V(P)}{N} = 0 .\n\\] This is equivalent to saying the chemical potentials in the liquid and gas phases should equal in coexistence, i.e. \\(\\mu_{liq}=\\mu_{gas}\\). That is, in coexistence the gas is in chemical equilibrium, with the liquid and gas portions exchanging particles at an equal rate.\nEnforcing chemical equilibrium is equivalent to finding \\(P_{co}\\) by drawing a horizontal line between the points \\(B\\) and \\(E\\) on the isotherm such that the areas in regions \\(BDO\\) and \\(OCB\\) equal and cancel out. This method of graphically finding this pressure is called the Maxwell construction. This sort of thing can be done in the lab by starting with a liquid at pressure \\(P_{liq}\\) and slowly decreasing the pressure at constant temperature until the same value \\(P_{co}\\) occurs twice for two different volumes.\nInterestingly, the Maxwell construction seems to predict that at coexistence a gas can take on any volume between \\(V_{liq}\\) and \\(V_{gas}\\). The construction doesn’t tell us, however, which of these volumes will be taken on for a given gas in coexistence. We simply don’t know. Any mixture of densities in this region is possible.\nAnother relic of the Maxwell construction evidently is that the coexistence line extends beyond the non-physical region. While these added regions indeed have positive compressibility, they’re in fact metastable. It’s possible to show their chemical potential is in fact higher than the chemical equilibrium potential, for a given pressure and temperature. However, if we compress the gas very slowly we can coax the system into a metastable state. These states create what’s known as a super-cooled or super-heated liquid. But in these states any small disturbance will cause some amount of the gas to condense into the liquid, or vice versa.\n\n\nClausius-Clapyron Equation\nWe can also investigate the behavior of the coexistence region in the phase diagram. In the phase diagram, coexistence occurs along the sharp curve separating the gas and liquid phases. Along this curve the gas must again be in chemical equilibrium. We can use this condition to figure out the functional forms of these curves.\nRecall by extensivity the chemical potential is just the Gibbs free energy per particle, i.e. \\(G = \\mu N\\). In each phase we must have \\[\ndG = -SdT + VdP.\n\\] Dividing both sides by \\(N\\) and asserting the chemical equilibrium condition \\(d\\mu_{liq}=d\\mu_{gas}\\), we have \\[\nd\\mu_{liq} = -s_{liq} dT + v_{liq} dP = -s_{gas} dT + v_{gas} dP = d\\mu_{gas},\n\\] where \\(s \\equiv \\frac{S}{N}\\) is the entropy per particle and \\(v \\equiv \\frac{V}{N}\\) is the volume per particle. Rearranging this formula thus says that the slope of the coexistence line in the phase diagram must satisfy \\[\n\\frac{dP}{dT} = \\frac{s_{gas}-s_{liq}}{v_{gas}-v_{liq}} = \\frac{\\Delta s}{\\Delta v}.\n\\] Since the entropy and volume in the gas phase will practically always exceed their values in the liquid phase, we can immediately conclude that the slope of this coexistence curve will generally be positive.\nIt’s more common to write this expression in terms of the specific latent heat, defined by \\(L \\equiv T\\Delta s\\). This is the amount of heat released per particle as the gas passes through the phase transition. In this form the formula for the slope of the coexistence line is called the Clausius-Clapyron equation, \\[\n\\boxed{\n\\frac{dP}{dT} = \\frac{L}{T \\Delta v}\n} \\ .\n\\] In principle this can be a difficult formula to solve since we need to calculate the entropy of both phases. We can often make some simplifying assumptions though. For example, it’s often the case that \\(L\\) is roughly constant and \\(v_{gas} \\gg v_{liq}\\). If we further assume the ideal gas law is approximately valid, we can write \\(v_{gas} \\approx \\frac{k_B T}{P}\\). Together, these imply \\[\n\\frac{dP}{dT} \\approx \\frac{LP}{k_B T^2} \\qquad \\Longrightarrow \\qquad P(T) \\approx P_0 \\exp\\bigg[-\\frac{L}{k_B} \\bigg(\\frac{1}{T}-\\frac{1}{T_0}\\bigg)\\bigg] \\ .\n\\] Such a curve has the interesting behavior of being convex near \\(T \\approx T_0\\) before eventually turning over like \\(P \\sim -\\frac{1}{T}\\). Typically \\(T_0\\) is some reference temperature like the triple point of the gas. Of course, the curve completely stops at the critical temperature \\(T_c\\) anyway, so the high-temperature behavior of the curve is often unimportant.\n\n\n\n\n\nNote that this formula can also be used just as well for gas-solid phase transitions, except with \\(L\\) taking on a different value due to the different type of chemical equilibrium in that case. The solid-liquid transition is a different story. There we can’t use these approximations at all. These coexistence curves can take on very different shapes. For example, the coexistence curve between water and ice is negatively-sloped. This means ice is less dense than water, which is why ice floats on water.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Classical Gases</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/classical-gases.html#mean-field-condensation",
    "href": "statistical-mechanics/classical-gases.html#mean-field-condensation",
    "title": "Classical Gases",
    "section": "Mean Field Condensation",
    "text": "Mean Field Condensation\nWhile the Maxwell construction can be practically useful, from a theoretical perspective we’d like an approach that doesn’t require merely ad hoc fixing van der Waals equation to work in the coexistence region. Let’s step back and see if we can look at subcritical behavior from a more fundamental perspective.\n\nUniform Density Approximation\nConsider again the hard sphere gas of \\(N\\) particles in a container of volume \\(V\\), except we’ll allow for a general potential energy \\(U\\). Recall with the hard sphere gas each particle is allowed to occupy some finite volume \\(\\omega\\) of radius \\(r_0\\). The full Hamiltonian is \\[\nH = \\sum_{i=1}^N \\frac{\\mathbf{p}_i^2}{2m} + U(\\mathbf{x}_1, \\cdots, \\mathbf{x}_N).\n\\] Now, suppose \\(U\\) can be broken up into two components: One component to deal with the hard sphere gas potential, and the other to deal with all possible pairwise interactions \\(u(|\\mathbf{x}_i-\\mathbf{x}_j|)\\). Through some clever notation, we can write \\(U\\) as \\[\nU = \\sum_{i&lt;j} u(|\\mathbf{x}_i-\\mathbf{x}_j|) = \\frac{1}{2} \\int d^3\\mathbf{x} \\ d^3\\mathbf{x}' \\ n(\\mathbf{x}) n(\\mathbf{x}') u(|\\mathbf{x}-\\mathbf{x}'|),\n\\] where each \\(n(\\mathbf{x})\\) is the density of the count of the number of particles \\(N(\\mathbf{x})\\) that appear at the point \\(\\mathbf{x}\\). That is, \\[\nn(\\mathbf{x}) \\equiv \\bigg | \\frac{dN(\\mathbf{x})}{d\\mathbf{x}} \\bigg | = \\sum_{i=1}^N \\delta(\\mathbf{x}-\\mathbf{x}_i) \\ .\n\\] Notice now what we’re doing is looking at the potential not in terms of each particle, but instead in terms of each point in the container. We’re essentially asking, for each point, is there a particle there that contributes to the potential. This different way of viewing the problem will allow us to do the following clever approximation, often called a mean field approximation.\nSuppose that each point in the container contains on average the same density of particles \\(\\overline n\\). That is, the gas uniformly fills the container with constant number density \\(\\overline n = \\frac{N}{V}\\). Using this fact, we can replace each \\(n\\) with \\(\\overline n\\) in the integral. Using this plus the usual trick of expressing pairs of coordinates in center of mass and relative coordinates, we can write \\[\nU = \\frac{\\overline n^2}{2} \\int d^3\\mathbf{x} \\ d^3\\mathbf{x}' \\ u(|\\mathbf{x}-\\mathbf{x}'|) = \\frac{\\overline n^2 V}{2} \\int_{r_0}^\\infty 4\\pi r^2 dr \\ u(r) \\ .\n\\] Notice the integral over \\(r\\) doesn’t depend on which particles we’re talking about. For a short-range potential like the van der Waals interaction, we can assume it converges to some finite positive area \\(-a\\) and just write \\[\nU = -\\frac{\\overline n^2 V a}{2} = -\\frac{\\overline N^2 a}{2V}.\n\\] Let’s now plug all of this into the canonical partition function. Since \\(U\\) is constant, we can pull it outside the integral to get \\[\n\\begin{align*}\nZ &= \\frac{1}{N! h^{3N}} \\int d^{3N} \\mathbf{x} \\ d^{3N} \\mathbf{p} \\ e^{-\\beta H} \\\\\n&= \\frac{1}{N! \\lambda^{3N}} \\int_\\text{Hard Sphere} d^{3N} \\mathbf{x} \\ e^{-\\beta U} \\\\\n&= \\frac{1}{N! \\lambda^{3N}} \\exp\\bigg(-\\frac{\\beta N^2 a}{2V}\\bigg) \\int_\\text{Hard Sphere} d^{3N} \\mathbf{x} \\ .\n\\end{align*}\n\\] Note we can’t just assume the spatial integral integrates to \\(V^N\\) anymore since we’re dealing with a hard sphere gas. Recall for the hard sphere gas that this integral turns out to be not the full volume \\(V^N\\), but the reduced volume \\(\\big(V-\\frac{N\\omega}{2}\\big)^N\\). Defining again the reduced volume per particle to be \\(b \\equiv \\frac{\\omega}{2}\\), we finally have \\[\nZ = \\frac{(V-Nb)^N}{N! \\lambda^{3N}} \\exp\\bigg(-\\frac{\\beta N^2 a}{2V}\\bigg).\n\\] If we take the logarithm of \\(Z\\) we can again find the pressure. We again get the familiar van der Waals equation, except this time without having to do a virial expansion, \\[\n\\bigg(P + a\\frac{N^2}{V^2}\\bigg)(V-Nb) = Nk_B T \\ .\n\\] What’s interesting about this is we’ve made the assumptions needed to derive the van der Waals equation fully transparent. It’s the equation of state arising for a hard sphere gas assuming it uniformly fills its container. The latter assumption explains why the van der Waals equation is problematic for explaining gases in the coexistence region. In coexistence, a gas exists simultaneously in two phases, the gas phase and the liquid phase. This necessarily means the gas can’t be uniformly dense, for if it were it would be all gas or all liquid, not both.\n\n\nIsobaric Perspective\nIf we want to understand the behavior of a gas in coexistence, it’s important that we allow the density to vary. Perhaps the easiest way to do this is to use the same mean field approximation, but to work in a different ensemble. We want to be in an ensemble that allows us to vary the density \\(n\\). One way to do that is to vary the volume while keeping the pressure fixed. The Gibbs or isobaric ensemble is the natural ensemble for this purpose. Recall we can write the Gibbs partition function \\(Z_G\\) as \\[\nZ_G(T,P,N) = \\int_0^\\infty dV \\ e^{-\\beta PV} Z(T,V,N) \\ .\n\\] Physically, working in the isobaric ensemble is equivalent to placing a piston at the top of the container and applying some external \\(P\\). For the pressure to equilibrate, the density must be uniform inside the container. This means such a system cannot tolerate coexistence. It will choose whether to be in the liquid phase or the gas phase depending on \\(P\\).\nTrying to perform the integration for \\(Z_G\\) is pretty hopeless, but fortunately we don’t need to. We’re just trying to understand the behavior of a gas in coexistence. To that end, define \\(\\psi(V)\\) to be the logarithm of the integrand, \\[\n\\psi(V) \\equiv -\\beta PV + \\log Z .\n\\] Since \\(V\\) is extensive, we can employ the saddlepoint approximation and approximate the integral as the integrand around the global maximum volume \\(V^*\\) to get \\(Z_G \\approx e^{-\\psi(V^*)}\\). To find \\(V^*\\) we again imply the usual trick of setting the derivative of \\(\\psi\\) to zero, \\[\n\\frac{d\\psi}{dV} = -\\beta P + \\frac{\\partial \\log Z}{\\partial V} \\bigg |_{V=V^*} = 0 \\ .\n\\] Now, notice that \\(\\frac{\\partial \\log Z}{\\partial V} = \\beta P_{\\text{vdW}}\\), where \\(P_{\\text{vdW}}\\) is the pressure from the van der Waals equation. Evidently then, the integrand is maximized when the pressure on the gas equals its van der Waals pressure at \\(V^*\\), i.e. when \\(P = P_{\\text{vdW}}(V^*)\\).\nSo what is this saying exactly? Remember that the external pressure \\(P\\) is fixed. It’s being applied on the system. This corresponds to picking a horizontal line on the \\(PV\\) diagram, intersecting it with the van der Waals isotherm at temperature \\(T\\), and reading off the volume where the two curves intersect as \\(V=V^*\\). As long as \\(V_{\\text{vdW}}(P)\\) is single-valued this is fine since the curves will intersect at exactly one volume (and hence exactly one density since \\(N\\) is fixed).\nBut inside the coexistence region something different happens. In that case \\(V^* = V_{\\text{vdW}}(P)\\) will be multi-valued. It will in fact return three possible extrema that intersect the line of constant \\(P\\). Of course, one of these extrema will be non-physical as we saw with the Maxwell construction, meaning we’re left with only two possible extrema intersecting the isotherm on the left and right ends. Call the volumes at these extrema \\(V_{liq}\\) and \\(V_{gas}\\). Since \\(N\\) is fixed, these will also correspond to two densities \\(n_{liq}\\) and \\(n_{gas}\\). That is, at such a pressure \\(P\\), we have coexistence of the two phases.\nIt’s helpful to look at the situation graphically. Suppose we plot \\(Z_G \\approx e^{\\psi(V)}\\) as a function of \\(V\\) for a given pressure \\(P\\). Suppose we’re below the critical temperature so phase transitions can occur. If \\(P \\gg P_c\\) then \\(Z_G\\) will peak at a unique volume \\(V^* \\sim Nb\\). That is, we’re uniquely in the liquid phase. If \\(P \\ll P_c\\) then \\(Z_G\\) will peak at a different volume \\(V^* \\gg Nb\\). That is, we’re uniquely in the gas phase. When \\(P \\sim P_c\\) we’re in the multi-valued situation, where \\(Z_G\\) will peak at two extrema according to something like \\[\nZ_G \\sim e^{\\psi(V_{liq})} + e^{\\psi(V_{gas})} \\ .\n\\] Typically one of these peaks will be exponentially larger than the other for a given pressure, but as the pressure changes the two peaks may flip, corresponding to a phase transition. What about the third extremum? In fact it’s a minimum on the \\(Z_G\\) curve, which is why we can think of it as a non-physical (i.e. highly improbable) state.\n\n\n\n\n\nNote that by extensivity we can also write \\(Z_G \\approx e^{-\\beta \\mu N}\\). This means that maximizing \\(Z_G\\) is equivalent to minimizing the chemical potential \\(\\mu\\). This is in a sense the statistical justification behind the Maxwell construction, which we got by picking the part of the integration path of \\(\\mu(P,T)\\) with the lowest chemical potential.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Classical Gases</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/classical-gases.html#ising-model",
    "href": "statistical-mechanics/classical-gases.html#ising-model",
    "title": "Classical Gases",
    "section": "Ising Model",
    "text": "Ising Model\nWe can look at phase transitions yet another way using a very different type of model, the Ising model. Ising models were originally created to understand the phase transitions in ferromagnets, where an external magnetic field can flip the spins of particles inside the magnet, causing it to change its polarization. It turns out, though, that such simplified models can be used to understand many other types of phase transitions as well. We’ll focus on an Ising model for the liquid-gas transition here.\n\nModel\nSuppose we again have \\(N\\) particles that for simplicity are laid out in a \\(d\\)-dimensional grid. Of course, in the real world \\(d=3\\) and particles need not be locked into a grid, but we’ll be general for now. We’ll suppose each particle can only interact with its nearest neighbors. It’s not hard to show by induction that a particle in \\(d\\) dimensions has exactly \\(2d\\) neighbors, assuming diagonals are excluded. We’ll assume a Hamiltonian of the form \\[\nH = -J \\sum_{\\langle i,j \\rangle} \\sigma_i \\sigma_j - h \\sum_{i=1}^N \\sigma_i.\n\\] Here the symbol \\(\\langle i,j \\rangle\\) means to sum over all \\(i,j\\) nearest neighbor pairs. Each \\(\\sigma_i=-1,1\\) is a binary value representing whether particle \\(i\\) is in its gas state (\\(\\sigma_i=1\\)) or liquid state (\\(\\sigma_i=-1\\)). We’ll call these states spins for historical reasons. The parameter \\(J\\) is a measure of the strength of interaction between nearest neighbor pairs. We’ll assume each pair has the same interaction strength. Last, the parameter \\(h\\) is some sort of external field we imagine being allowed to vary. For ferromagnets, \\(h\\) would represent an applied external magnetic field. For gases, \\(h\\) would typically represent the chemical potential of the gas relative to its equilibrium chemical potential.\nGiven this Hamiltonian, we can again find its partition function and study its thermodynamic behavior. Since this is a discrete system the integral over phase space gets replaced by a sum over all possible states, which in this case are all possible configurations of \\(\\sigma_1, \\cdots, \\sigma_N\\). Working in the canonical ensemble and assuming particles are identical, we have \\[\nZ = \\frac{1}{N!} \\sum_{\\{\\sigma_i\\}} \\exp\\bigg[-\\beta\\bigg(-J \\sum_{\\langle i,j \\rangle} \\sigma_i \\sigma_j - h \\sum_{i=1}^N \\sigma_i\\bigg)\\bigg] \\ .\n\\]\n\n\nMean Field Approximation\nTrying to sum over all nearest-neighbor pairs is highly non-trivial. To proceed we’ll again invoke the mean field approximation. Provided \\(d\\) is sufficiently large (more on this soon), it’s reasonable to assume the spin each particle feels from one of its neighbors is roughly the average spin it feels from all its neighbors. We’ll denote the average spin by \\(m \\equiv \\frac{1}{N} \\sum_i \\langle \\sigma \\rangle\\), called the magnetization for historical purposes. Then we can re-write each pair as \\[\n\\sigma_i \\sigma_j = (\\sigma_i-m)(\\sigma_j-m) + m(\\sigma_i + \\sigma_j) - m^2 \\ .\n\\] If we assume each \\(\\sigma_i \\approx m\\) then each \\((\\sigma_i-m)\\) will be small. Since the first term above is second-order small we’ll neglect it, \\[\n\\sigma_i \\sigma_j \\approx m(\\sigma_i + \\sigma_j) - m^2 \\ .\n\\] With this approximation we can replace each \\(\\sum_{\\langle i,j \\rangle}\\) with \\(\\frac{2d}{2} \\sum_i\\) and simplify the Hamiltonian to get \\[\n\\begin{align*}\nH &= -J \\sum_{\\langle i,j \\rangle} \\big(m(\\sigma_i + \\sigma_j) - m^2\\big) - h \\sum_{i=1}^N \\sigma_i \\\\\n&= dJNm^2 - (2dJm + h) \\sum_{i=1}^N \\sigma_i \\ .\n\\end{align*}\n\\] The partition function can then be factored as a product of single-particle partition functions and simplified as \\[\n\\begin{align*}\nZ &= \\frac{1}{N!} \\sum_{\\{\\sigma_i\\}} \\exp\\bigg[-\\beta\\bigg(dJNm^2 - (2dJm + h) \\sum_{i=1}^N \\sigma_i \\bigg)\\bigg] \\\\\n&= \\frac{1}{N!} e^{-\\beta dJNm^2}\\bigg(\\sum_{\\sigma=\\pm 1} e^{\\beta(2dJm + h)\\sigma} \\bigg)^N \\\\\n&= \\frac{1}{N!} e^{-\\beta dJNm^2} \\bigg(e^{\\beta(2dJm + h)} + e^{-\\beta(2dJm + h)} \\bigg)^N \\\\\n&= \\frac{1}{N!} e^{-\\beta dJNm^2} \\cosh^N\\big(2dJm\\beta + h\\beta\\big) \\ .\n\\end{align*}\n\\] Of course, we still don’t know \\(m\\). To get \\(m\\) we need to impose the self consistency constraint that it equals the magnetization, \\[\nm = \\frac{1}{N} \\sum_{i=1}^N \\langle \\sigma \\rangle = \\frac{1}{N\\beta} \\frac{\\partial \\log Z}{\\partial h}.\n\\] Working out the math and simplifying, we get an equation of the form \\[\nm = \\tanh(2dJm\\beta + h\\beta) \\ .\n\\]\n\n\nGraphical Analysis\nThere’s no way to exactly solve this equation, but we don’t need to. We just want to understand the behavior of phase transitions. To do that we’ll resort to graphical methods. Let’s change variables by defining \\(x \\equiv \\frac{k_B T}{2dJ}m\\). Then we get \\[\n\\frac{k_B T}{2dJ} x = \\tanh\\bigg(x + \\frac{h}{k_B T}\\bigg).\n\\] Let’s start with the simplest case where there’s no external field, so \\(h=0\\). In this case we seek the points of intersection between the line \\(y=\\frac{k_B T}{2dJ}x\\) and the curve \\(y=\\tanh(x)\\). The \\(\\tanh\\) function looks like a sigmoid function. Near the origin it’s basically linear, with \\(\\tanh x \\approx x\\). As \\(x\\) gets larger the function turns over and asymptotes to \\(\\tanh x \\approx \\pm 1\\) depending on the sign. This means that the slope of the line determines how many points of intersection there are. How many points there are depend on how \\(T\\) compares to the critical temperature \\(T_c \\equiv \\frac{2dJ}{k_B}\\). As with the van der Waals equation there are three different possibilities:\n\nWhen \\(T &gt; T_c\\) the two curves intersect only at the origin. This corresponds to \\(m=0\\). The temperature is high enough in this case that the magnetization \\(m\\) is completely randomized. The entropy associated with the random temperature fluctuations wins over the energetically preferred state in which the spins align. This is analogous to the supercritical isotherms we saw.\nWhen \\(T &lt; T_c\\) the two curves still intersect at \\(m=0\\), except now they intersect at two other symmetric points \\(m = \\pm m_0\\). The solution at the origin turns out to be unstable, leaving only the two points \\(\\pm m_0\\). Here we see the effects of the interactions between the spins begin to win over temperature. As \\(T \\rightarrow 0\\) it seems \\(m_0 \\approx \\pm 1\\). That is, at zero temperature all the spins are aligned in the same direction, either all up or all down. This is analogous to the subcritical isotherms we saw.\nWhen \\(T = T_c\\) the two curves are basically the exact same line near the origin, but not exactly due to second order error. This means the curves only intersect at \\(m=0\\), but if \\(T\\) decreases any infinitesimal amount the two other solutions will appear. This is analogous to the critical isotherm we saw.\n\n\n\n\n\n\nThe results described above are perhaps rather surprising. Based on the intuition that things in physics always happen smoothly, one might have thought that \\(m\\) would decrease slowly to zero as \\(T \\rightarrow \\infty\\). But that’s not what happens. Instead \\(m\\) turns off abruptly at some finite temperature \\(T_c\\). This is the characteristic behavior of a phase transition. Because it arises from the first derivative of the free energy it’s by convention called a first-order phase transition. This contrasts with higher-order phase transitions, which arise from discontinuities in higher derivatives of the free energy.\nWhat happens now if we turn on an external field, allowing \\(h \\neq 0\\)? If we look at the above equation, we can see that the presence of \\(h\\) seems to shift the zero point of the \\(\\tanh\\) function left or right depending on the sign of \\(h\\). Meanwhile the left-hand line doesn’t shift at all. What does this do to the system? It breaks the symmetry. For any \\(T &lt; \\infty\\) it’s impossible to get \\(m=0\\). Moreover, since the shift \\(\\frac{h}{k_B T} \\rightarrow 0\\) as \\(T \\rightarrow \\infty\\), \\(m\\) will now go smoothly to zero, meaning there is no longer a phase transition. In fact, it’s possible to show that when \\(T &lt; T_c\\) only one of the intersection endpoints will be stable, which means the spins will always prefer one state over the other. This sort of phenomenon is called spontaneous symmetry breaking. Even the slightest stray external field is enough to ruin the ability of a phase transition to occur.\n\n\n\n\n\nIt’s worth mentioning that strictly speaking the mean field approximation only holds as \\(d \\rightarrow \\infty\\) due to the law of large numbers. In fact, the mean field approximation doesn’t work at all when \\(d=1\\). It can even be shown that phase transitions cannot exist in one-dimension. Yet, for \\(d \\geq 2\\) it’s perhaps surprising that the approximation is okay, at least qualitatively. Even by \\(d=2\\) and \\(d=3\\) phase transitions already start to occur in the Ising model. Proving phase transitions indeed occur in these lower dimensions is somewhat more difficult and beyond the scope of this lesson.\n\n\nGases\nWe can use the Ising model to study the liquid-gas phase transitions. In this case case, we just think of spin as representing whether a given spot on the lattice is occupied. A given spot \\(i\\) is occupied if \\(\\sigma_i=1\\) and not occupied if \\(\\sigma_i=-1\\). The external field \\(h\\) corresponds to the chemical potential \\(\\mu\\). In fact it’s the chemical potential relative to chemical equilibrium, i.e. \\(h=\\mu-\\mu_{eq}\\).\nFor gases it’s more insightful to re-write spins in terms of particle densities. We can transform the spins \\(\\sigma\\) to densities \\(n\\) via the formula \\(\\sigma = 2n-1\\). This ensures \\(n=0,1\\) corresponds to \\(\\sigma = -1,+1\\). In terms of densities the Hamiltonian becomes \\[\nH = -4J \\sum_{\\langle i,j \\rangle} n_i n_j - (\\mu-\\mu_{eq}) \\sum_{i=1}^N n_i \\ .\n\\] It’s not hard to show that the density equivalent of magnetization, call it \\(\\nu\\), is related to \\(m\\) by \\(m = 2\\nu - 1\\). This means the qualitative behavior of the liquid-gas phase transition is the same in this model except with the values shifted and rescaled. For example, the \\(\\tanh\\) function becomes instead a sigmoid function scaled between \\(0\\) and \\(1\\). When \\(\\mu=\\mu_{eq}\\) the gas is at chemical equilibrium, which is precisely when phase transitions can occur. As \\(\\mu\\) deviates ever so slightly from \\(\\mu_{eq}\\) the phase transition phenomenon disappears, with the gas staying in either its gas or liquid phase depending on the sign of \\(\\mu-\\mu_{eq}\\).",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Classical Gases</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/classical-gases.html#critical-behavior",
    "href": "statistical-mechanics/classical-gases.html#critical-behavior",
    "title": "Classical Gases",
    "section": "Critical Behavior",
    "text": "Critical Behavior\nWe’ll close this chapter by briefly studying the behavior of systems near the critical point. It turns out that the behavior of gases near the critical point is in some sense universal, in that certain quantities are the same no matter which gas is studied.\n\nCorresponding States\nLet’s go back to the van der Waals equation. Recall the critical points are given by the following equations, \\[\nk_B T_c = \\frac{8a}{27b} , \\qquad v_c = 3b , \\qquad P_c = \\frac{a}{27b^2} \\ .\n\\]\nHere we’ve expressed things in terms of the volume per particle \\(v \\equiv \\frac{V}{N}\\) to keep everything intensive. We’ll re-express the van der Waals equation in dimensionless form by defining \\[\n\\tilde P \\equiv \\frac{P}{P_c}, \\qquad \\tilde T \\equiv \\frac{T}{T_c}, \\qquad \\tilde v \\equiv \\frac{v}{v_c} \\ .\n\\] With these variables we can write the equation in a universal form that doesn’t depend on which gas we’re talking about. It’s sometimes called the law of corresponding states, given by \\[\n\\tilde P = \\frac{8}{3} \\frac{\\tilde T}{\\tilde v - \\frac{1}{3}} - \\frac{3}{\\tilde v^2} \\ .\n\\] First, notice the quantity \\[\n\\frac{P_c v_c}{k_B T_c} = \\frac{8}{3} = 0.375\n\\] doesn’t depend on \\(a\\) or \\(b\\). It seems to be some kind of universal constant for all gases, at least to the extent the above equation is correct. In fact this ratio isn’t right for real gases. It’s slightly too high. Real values tend to be in the range of \\(0.25\\) to \\(0.3\\). Given that the van der Waals equation is only accurate for fairly dilute gases this discrepancy shouldn’t be that surprising.\n\n\nCritical Exponents\nWe’ll look briefly at the behavior of three different quantities to get an idea how a gas behaves near the critical point:\n\nThe behavior of pressure as a function of volume.\nThe behavior of the coexistence volume difference as a function of temperature.\nThe behavior of the compressibility as a function of temperature.\n\nFirst, let’s get an idea how the pressure depends on volume near the critical point. Recall that thermodynamic stability requires that the pressure \\(P(V)\\) along the critical isotherm has no first or second order volume dependence, meaning \\(P(v) = O(v^3)\\). It’s worth asking if pressure in fact has a third order dependence rather than a fifth or odd higher order dependence. At least according to the van der Waals equation there does indeed seems to be a third order dependence. Near the critical point we can Taylor expand the equation and write \\[\nP-P_c \\sim (v-v_c)^3 \\ .\n\\] What’s important here is the prediction that pressure depends on volume to the third power near the critical point. Again, it’s fair to ask if this is exactly true for real gases, and again it turns out the answer is not quite. The true relationship is more like \\(P-P_c \\sim (v-v_c)^{\\delta}\\) where \\(\\delta \\approx 4.8\\). That is, the real critical isotherm is almost a quintic near the critical point, not a cubic.\nSecond, let’s look at how the volume difference \\(\\delta v = v_{gas}-v_{liq}\\) depends on the temperature near the critical point. We expect \\(\\delta v\\) to shrink to zero as \\(T\\) approaches \\(T_c\\), since that must happen for the coexistence behavior to cease. But how fast does it shrink? When \\(T &lt; T_c\\) the van der Waals equation must have two stable solutions to \\(P(v)\\), one with \\(v_{liq}\\) and the other with \\(v_{gas}\\). In dimensionless form, this means \\[\n\\tilde P = \\frac{8}{3} \\frac{\\tilde T}{\\tilde v_{liq} - \\frac{1}{3}} - \\frac{3}{\\tilde v_{liq}^2} = \\frac{8}{3} \\frac{\\tilde T}{\\tilde v_{gas} - \\frac{1}{3}} - \\frac{3}{\\tilde v_{gas}^2} \\ .\n\\] Solving the equation for \\(\\tilde T\\) and Taylor expanding in terms of \\(\\delta v\\), we can then write \\[\n\\tilde T = \\frac{(3v_{liq}-1)(3v_{gas}-1)(v_{liq} + v_{gas})}{8v_{liq}^2 v_{gas}^2} \\approx 1 - \\frac{1}{16} \\delta v^2 + \\cdots \\ .\n\\] Evidently then the temperature near the critical point goes like the velocity difference squared, or inverting, \\[\n\\delta v \\sim (T-T_c)^{1/2} \\ .\n\\] This dependence doesn’t depend on the type of gas under consideration. But is this relationship exact for real gases? Again, not quite. Experimentally, it turns out that \\(\\delta v \\sim (T-T_c)^{\\beta}\\) where \\(\\beta \\approx 0.32\\).\nThird, let’s ask how the compressibility \\(\\kappa\\) depends on the temperature near the critical point. We can express \\(\\kappa\\) as \\[\n\\kappa = -\\frac{1}{v} \\frac{\\partial v}{\\partial P} \\bigg |_T \\ .\n\\] As \\(T \\rightarrow T_c\\) we must have that \\(\\frac{\\partial P}{\\partial v} \\rightarrow 0\\) to be at the critical point. We’d thus expect that the compressibility of a gas diverges at the critical point. Applying the smallest amount of pressure should change the volume a huge amount as the gas undergoes a phase transition. If we expand \\(\\frac{\\partial P}{\\partial v}\\) in powers of \\(T-T_c\\) we expect to get \\[\n\\frac{\\partial P}{\\partial v} = -a(T-T_c) + \\cdots \\ .\n\\] Inverting this equation when \\(T \\approx T_c\\), this then says \\[\n\\kappa \\sim (T-T_c)^{-1} \\ .\n\\] Again, this dependence is apparently independent of the gas. And again, it’s fair to ask if this dependence is truly correct for real gases. As we’d expect by now, it’s not exactly correct. The true relationship is \\(\\kappa \\sim (T-T_c)^{-\\gamma}\\) where \\(\\gamma \\approx 1.2\\).\nThese interesting exponent relationships seem to apply to all gases, at least near the critical point. The exponents themselves are called critical exponents. They’re universal. In fact, they apply to even more than gases. The results obtained even apply to the Ising Model when \\(d=3\\). In that case we’d just replace the volume \\(v\\) with the magnetization \\(m\\), the pressure \\(P\\) with the external field \\(h\\), and the compressibility \\(\\kappa\\) with the susceptibility \\(\\chi \\equiv N\\frac{\\partial m}{\\partial h} \\big |_T\\). All of the previous results can be obtained in an analogous manner to give the critical relations \\[\nh \\sim m^3, \\qquad m_0 \\sim \\pm (T-T_c)^{1/2}, \\qquad \\chi \\sim (T-T_c)^{-1} \\ .\n\\] But why aren’t these results exact? After all the real critical exponents are slightly off in all cases. Fundamentally, the issue is that we’re trying to do an analytic expansion of an equation of state about the critical point. But we can’t really do that since there’s a discontinuity at the critical point, which is why we even get phase transitions at all. To get more accurate estimates of the critical exponents we should approach the problem in a very differently, using more advanced techniques like group renormalization. This gets into the more modern topic of critical phenomena, something we’ll see more in a future lesson.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Classical Gases</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/quantum-stat-mech.html",
    "href": "statistical-mechanics/quantum-stat-mech.html",
    "title": "Quantum Statistical Mechanics",
    "section": "",
    "text": "Quantum Mechanics\nLet’s briefly recall how we initiated the theory of classical statistical mechanics. We started by supposing a system had some huge number of microstates \\(\\mu = \\{\\mathbf{x}_i, \\mathbf{p}_i\\}\\). We then wanted to figure out how many of these microstates corresponded to any one individual macrostate \\(M=(E,X,N)\\). This led us to a definition of the of the equilibrium probability density as the phase space density under the macroscopic constraints. From this we were then able to specify the various statistical ensembles and derive the laws of thermodynamics.\nWe can do something similar in the quantum version, except we need to rethink what exactly it is we mean by a microstate. In classical mechanics we define a state as a point \\((\\mathbf{x},\\mathbf{p})\\) in the phase space. In quantum mechanics, however, we have to contend with the uncertainty principle, which forbids knowing both \\(\\mathbf{x}\\) and \\(\\mathbf{p}\\) simultaneously too precisely. More correctly, for each component we have the uncertainty relation \\[\n\\Delta x_i \\Delta p_j \\geq \\frac{\\hbar}{2} \\delta_{ij} \\ ,\n\\] where \\(\\hbar \\approx 10^{-34} \\text{ J s}\\) is the reduced Planck constant. This really tiny number limits how closely we can resolve points in phase space, since we’re disallowed by the uncertainty principle from localizing points at finer scales than \\(\\hbar\\). We can really only imagine defining smooth functions on phase space at scales much larger than \\(\\hbar\\). Below that we have to transition to quantum mechanics.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Quantum Statistical Mechanics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/quantum-stat-mech.html#quantum-mechanics",
    "href": "statistical-mechanics/quantum-stat-mech.html#quantum-mechanics",
    "title": "Quantum Statistical Mechanics",
    "section": "",
    "text": "Quantum Microstates\nIn quantum mechanics, a microstate \\(\\mu\\) is specified by an abstract ket vector \\(| \\psi\\rangle\\) that lives in a complex Hilbert space which can be of any dimension, finite or infinite. We assume all the rules of the linear algebra for complex vectors applies to Hilbert spaces. For example, we assume we can decompose any ket in the Hilbert space into a linear combination of basis kets, e.g. \\[\n|\\psi\\rangle = \\sum_{n} \\langle n | \\psi\\rangle |n \\rangle \\equiv \\sum_{n} \\psi_n |n \\rangle \\ .\n\\] Here \\(\\psi_n \\equiv \\langle n | \\psi\\rangle\\) is the complex-valued inner product between the kets \\(|n\\rangle\\) and \\(|\\psi \\rangle\\). Notice the ket \\(|n\\rangle\\) gets converted first into a bra vector \\(\\langle n |\\), which can be thought of as the conjugate transpose of the ket \\(|n\\rangle\\). This implies we can write the inner product between any two vectors by applying the bra of one to the ket of the other, \\[\n\\langle \\phi | \\psi \\rangle = \\sum_n \\phi_n^* \\psi_n \\ .\n\\] We typically require that kets in the Hilbert space be normalized, i.e. \\(\\langle \\psi | \\psi \\rangle = 1\\) for any \\(|\\psi \\rangle\\). This means that the length of a vector in quantum mechanics contains no physical information. The reason we normalize them to one is so we can use them to represent probability densities, or amplitudes. This is done using the Born rule, which says that the norm of a vector represents the probability of that state being observed. For example, the inner product \\(|\\psi_n|^2 = \\langle n|\\psi \\rangle^2\\) represents the probability amplitude that \\(|\\psi\\rangle\\) is found exactly in the state \\(|n\\rangle\\). If \\(|n\\rangle\\) represents a state with energy \\(E_n\\), then \\(|\\psi_n|^2\\) represents the probability density of \\(|\\psi\\rangle\\) having energy \\(E_n\\). That is, \\(p_\\psi(E=E_n) = |\\psi_n|^2\\).\nIt’s important to note that this is a fundamentally different kind of probability than that of statistical mechanics. It’s an irreducible probability, not one arising from our ignorance about the system. No matter how much knowledge we have of the system, or how well we can measure it, we still have to contend with these sorts of quantum probabilities.\nIn practice, it’s often useful to think of states using wavefunctions, which are the components \\(\\psi(\\mathbf{x})\\) of kets in the position basis, \\[\n|\\psi \\rangle = \\int d^3 \\mathbf{x} \\ \\langle \\mathbf{x} | \\psi\\rangle |\\mathbf{x} \\rangle \\equiv \\int d^3 \\mathbf{x} \\  \\psi(\\mathbf{x}) |\\mathbf{x} \\rangle \\ .\n\\] By the Born rule, if \\(|\\psi\\rangle\\) represents the state of some particle, we can think of the amplitude \\(|\\psi(\\mathbf{x})|^2\\) as the probability density of observing that particle in space near the point \\(\\mathbf{x}\\). We can imagine wavefunctions in other bases as well. For example, the momentum space wavefunction is defined in a similar way by \\(\\psi(\\mathbf{p}) \\equiv \\langle \\mathbf{p}|\\psi \\rangle\\).\nIn classical mechanics, we can think of observables like energy, momentum, etc. as functions \\(Q(\\mathbf{x},\\mathbf{p})\\) on the phase space. We could then proceed to study the dynamics of those observables by looking at their Poisson bracket with the Hamiltonian, \\[\n\\frac{dQ}{dt} = \\{Q, H\\} \\ .\n\\] By the uncertainty principle this is again disallowed in quantum mechanics. Instead, we think of observables as operators \\(Q\\) that map kets to other kets in the Hilbert space, e.g. \\(Q|\\psi\\rangle = |\\psi\\rangle\\). We also require that observables be Hermitian, meaning \\(Q\\) must equal its conjugate transpose \\(Q^\\dagger\\). This ensures the spectrum of eigenvalues of \\(Q\\) are all real-valued and the eigenvectors are all orthogonal, or can be chosen to be orthogonal.\nIn classical mechanics we can imagine measuring some observable \\(Q\\) to as high a precision as we like by tuning the apparatus to make better and better measurements. In quantum mechanics this is again disallowed by the uncertainty principle. Instead, attempts to measure \\(Q\\) will force it to randomly take on one of a set of fixed values, its spectrum of eigenvalues. Mathematically, if \\(Q\\) is some observable and we attempt to measure it in some state \\(|\\psi\\rangle\\), we imagine measurement as sampling some \\(q\\) from the distribution defined by the density \\(p_\\psi(q)=|\\psi_q|^2\\). This also means we can define an expected value for \\(Q\\) in the usual way, \\[\n\\langle Q \\rangle_\\psi \\equiv \\sum_q q \\ p_\\psi(q) = \\langle \\psi | Q | \\psi \\rangle \\ .\n\\] Notice the probability density and expected value both depend on the state \\(|\\psi\\rangle\\). If the state changes, so will these functions. Again, there is nothing statistical about this probability. Even with a single particle we’d still have to worry about it.\nTo study the dynamics of observables in quantum mechanics we should replace the Poisson bracket with the commutator \\[\n[A,B] \\equiv AB - BA,\n\\] a measure of how much the operators \\(A\\) and \\(B\\) fail to commute with each other. If two observables commute we can in principle measure them simultaneously with no uncertainty. Otherwise they obey an uncertainty principle. For example, we already know the position operator \\(\\mathbf{x}\\) doesn’t commute with the momentum operator \\(\\mathbf{p}\\) since they have an uncertainty principle. In fact, their components satisfy the commutation relation \\[\n[x_i, p_j] = i\\hbar\\delta_{ij} \\ .\n\\] Comparing this with the Poisson bracket relation \\(\\{x_i, p_j\\} = \\delta_{ij}\\) we can establish a crude identification between the two brackets, \\[\n[A,B] \\quad \\longleftrightarrow \\quad -\\frac{i}{\\hbar} \\{A,B\\} \\ .\n\\] This suggests that the time evolution of any observable \\(Q\\) in quantum mechanics is given by \\[\n\\frac{dQ}{dt} = -\\frac{i}{\\hbar} [Q, H] \\ ,\n\\] where the Hamiltonian is now thought of as an operator. This relation is indeed true, at least in the Heisenberg picture of quantum mechanics, where operators are allowed to evolve in time. In the more elementary Schrödinger picture it’s the states that are allowed to evolve, not the operators. In this picture it’s the expectation of the operators that are allowed to time evolve this way. The time evolution of states can be found by using the requirement that the time evolution of kets must be given by a unitary operator \\(U(t) \\equiv e^{-\\frac{i}{\\hbar} Ht}\\), where \\(H\\) is the Hamiltonian, \\[\n|\\psi(t)\\rangle = U(t) |\\psi(0)\\rangle \\ .\n\\] A unitary operator satisfies the condition that \\(U U^\\dagger = 1\\). This implies that unitary operations conserve quantum probabilities, since \\(U|\\psi\\rangle\\) will have the same probability amplitude as \\(|\\psi\\rangle\\). Requiring that time evolution be unitary in this way leads us to the time-dependent Schrödinger equation. If we assume \\(t\\) is infinitesimal we can write \\(U(t) \\approx I - \\frac{i}{\\hbar} Ht\\). Plugging this in and rearranging then gives the more familiar result for the time evolution of states, \\[\nH |\\psi(t)\\rangle = i\\hbar \\frac{\\partial}{\\partial t} |\\psi(t) \\rangle \\ .\n\\] The eigenvalues of the Hamiltonian are the allowed energies the system can take on. If \\(E_n\\) is an eigenvalue of \\(H\\) with eigenvector \\(|n\\rangle\\), we can trivially write \\(H|n\\rangle = E_n |n\\rangle\\). This is often called the time-independent Schrödinger equation.\nAn important set of relationships to be aware of in quantum mechanics is that between position and momentum. We already saw that the position and momentum operators satisfy the commutation relation \\([x_i, p_j] = i\\hbar\\delta_{ij}\\). This means that it’s impossible to simultaneously diagonalize the two operators and get product states like \\(|\\mathbf{x},\\mathbf{p}\\rangle\\). If we could do that we could just use the classical theory of Hamiltonian dynamics. Instead, we have to think about the position basis and momentum basis as being distinct representations. It’s possible to show, however, that the two representations are Fourier transforms of each other, \\[\n|\\mathbf{p} \\rangle = \\int \\frac{d^3 \\mathbf{x}}{(2\\pi\\hbar)^{3/2}} \\ e^{\\frac{i}{\\hbar} \\mathbf{x} \\cdot \\mathbf{p}} |\\mathbf{x}\\rangle \\ .\n\\] This relation essentially encodes the uncertainty principle. For example, if \\(|\\mathbf{x}\\rangle\\) were known exactly in position space, then its wavefunction would be a delta function. But the Fourier transform of a delta function is a constant, which means that in momentum space we’d have to allow for the system to have any possible momentum with equal probability.\nThe Fourier relation above is particularly useful when solving the Schrödinger equation for a free particle. For these kinds of problems it’s more convenient to work rescale units to get rid of factors of \\(\\hbar\\). We can do that by using the DeBroglie relation \\(\\mathbf{p} = \\hbar \\mathbf{k}\\), where \\(\\mathbf{k}\\) is the wavevector defined by \\(|\\mathbf{k}| = \\frac{2\\pi}{\\lambda}\\). Here \\(\\lambda\\) is the wavelength of a wavefunction moving with momentum \\(\\mathbf{p}\\). In this slight rescaling of units the factors of \\(\\hbar\\) disappear and the Fourier transform becomes \\[\n|\\mathbf{k} \\rangle = \\int \\frac{d^3 \\mathbf{x}}{(2\\pi)^{3/2}} \\ e^{i \\mathbf{x} \\cdot \\mathbf{k}} |\\mathbf{x}\\rangle \\ .\n\\] Since we’ll end up using it later, let’s go ahead and work it out the quantum dynamics of the free particle.\n\n\nExample: Free Particle\nConsider a particle moving in free space. We’ve seen many times such a particle has Hamiltonian \\(H = \\frac{\\mathbf{p}^2}{2m}\\), except in this case we should think of \\(H\\) as an operator that depends solely on the momentum operator \\(\\mathbf{p}\\). For convenience we’ll rescale and work in units of the wavevector \\(\\mathbf{k}\\). This means that the eigenvectors of \\(H\\) are also the eigenvectors of \\(\\mathbf{k}\\), hence \\[\nH | \\mathbf{k} \\rangle = E(\\mathbf{k}) | \\mathbf{k} \\rangle = \\frac{\\hbar^2 \\mathbf{k}^2}{2m} |\\mathbf{k} \\rangle \\ .\n\\] We thus have an expression for the energy in terms of the wavevector as \\(E(\\mathbf{k}) = \\frac{\\hbar^2 \\mathbf{k}^2}{2m}\\). Suppose we’re interested in the energy wavefunctions \\(\\psi_\\mathbf{k}(\\mathbf{x}) = \\langle \\mathbf{x} |\\mathbf{k} \\rangle\\) as well. These are just the wavefunctions associated with the Fourier transform for \\(|\\mathbf{k}\\rangle\\), \\[\n\\begin{align*}\n\\psi_\\mathbf{k}(\\mathbf{x}) &= \\langle \\mathbf{x} |\\mathbf{k} \\rangle \\\\\n&= \\int \\frac{d^3 \\mathbf{x}'}{(2\\pi)^{3/2}} \\ e^{i \\mathbf{x}' \\cdot \\mathbf{k}} \\langle \\mathbf{x}|\\mathbf{x}'\\rangle \\\\\n&= \\int \\frac{d^3 \\mathbf{x}'}{(2\\pi)^{3/2}} \\ e^{i \\mathbf{x}' \\cdot \\mathbf{k}} \\delta(\\mathbf{x} - \\mathbf{x}') \\\\\n&= \\frac{1}{(2\\pi)^{3/2}} e^{i \\mathbf{x} \\cdot \\mathbf{k}} \\ .\n\\end{align*}\n\\] Thus, the energy eigenfunctions are just complex plane waves in position space. In fact, they’re plane waves in both position in time, since the time-dependent energy eigenfunctions are just the static wavefunctions multiplied by \\(e^{-i\\omega t}\\) where \\(E=\\hbar \\omega\\), \\[\n\\psi_\\mathbf{k}(\\mathbf{x}, t) = \\frac{1}{(2\\pi)^{3/2}} e^{i (\\mathbf{x} \\cdot \\mathbf{k}-\\omega t)} \\ .\n\\] The true wavefunction \\(\\psi(\\mathbf{x}, t)\\) of the particle can be found by superimposing all the energy eigenfunctions together, \\[\n\\psi(\\mathbf{x},t) = \\langle \\mathbf{x} | \\psi \\rangle\n= \\int d^3 \\mathbf{k} \\langle \\mathbf{x} | \\mathbf{k} \\rangle \\langle \\mathbf{k} | \\psi \\rangle\n= \\int d^3 \\mathbf{k} \\ \\psi_\\mathbf{k}(\\mathbf{x}, t) \\phi(\\mathbf{k}) \\ .\n\\] Here the coefficients \\(\\phi(\\mathbf{k}) = \\langle \\mathbf{k} | \\psi \\rangle\\) are determined by the initial conditions. If the particle is reasonably well localized, \\(\\phi(\\mathbf{k})\\) will tend to have a reasonably narrow peak around some particular \\(\\mathbf{k}\\). This will tend to result in \\(\\psi(\\mathbf{x},t)\\) having a shape where the waves are confined inside of a larger wave packet, whose group velocity is given from the dispersion relation \\(\\omega(\\mathbf{k}) = \\frac{\\hbar \\mathbf{k}^2}{2m}\\) as \\[\n\\mathbf{v}_g \\equiv \\frac{d\\omega}{d\\mathbf{k}} = \\frac{\\hbar \\mathbf{k}}{m} = \\frac{\\mathbf{p}}{m} \\ .\n\\] The group velocity of the wave packet can be thought of as the quantum origin of the velocity of a classical particle, \\(\\mathbf{v} = \\frac{\\mathbf{p}}{m}\\). Note that since \\(\\omega(\\mathbf{k})\\) isn’t linear in \\(\\mathbf{k}\\) the wave will also be dispersive, with a phase velocity \\(v_p \\equiv \\frac{\\omega}{|\\mathbf{k}|}\\) that’s half the group velocity.\n\n\nExample: Particle in a Box\nWhat if now we impose the requirement that the particle be confined to a box of dimensions \\(L_x \\times L_y \\times L_z\\) with volume \\(V\\)? In this case we have to be careful to impose the correct boundary conditions on the wavefunctions. We’ll assume that the wavefunction is periodic at the walls of the box. That is, \\[\n\\begin{align*}\n\\psi(x,y,z,t) &= \\psi(x+L_x,y,z,t), \\\\\n\\quad \\psi(x,y,z,t) &= \\psi(x,y+L_y,z,t), \\\\\n\\quad \\psi(x,y,z,t) &= \\psi(x,y,z+L_z,t) \\ .\n\\end{align*}\n\\] We should expect the energy eigenfunctions to have the same form as for a free particle, with \\(\\psi_\\mathbf{k}(\\mathbf{x}, t) \\propto e^{i (\\mathbf{x} \\cdot \\mathbf{k}-\\omega t)}\\), except that now the boundary conditions will impose constraints on the wavevector \\(\\mathbf{k}\\). Periodicity of the boundary conditions require \\[\nA e^{i (xk_x + yk_y + zk_z-\\omega t)} = A e^{i \\big((x+L_x)k_x + yk_y + zk_z-\\omega t\\big)} \\quad \\Longrightarrow \\quad e^{ik_x L_x} = 1 \\ ,\n\\] and similarly for the \\(y\\) and \\(z\\) components. This condition requires that each component of \\(\\mathbf{k}\\) be discrete, with \\[\nk_x = \\frac{2\\pi n_x}{L_x}, \\quad k_y = \\frac{2\\pi n_y}{L_y}, \\quad k_z = \\frac{2\\pi n_z}{L_z} \\ ,\n\\] where each of \\(n_x, n_y, n_z\\) are independent positive integers. This also forces the energy eigenvalues to be discrete, with \\[\nE_\\mathbf{n} = \\frac{\\hbar^2}{2m} \\bigg(\\frac{n_x^2}{L_x^2} + \\frac{n_y^2}{L_y^2} + \\frac{n_y^2}{L_y^2}\\bigg) \\ .\n\\] That is, \\(H|\\mathbf{n}\\rangle = E_\\mathbf{n} |\\mathbf{n}\\rangle\\). The energy eigenfunctions can be found by plugging in the expressions for \\(\\mathbf{k}_\\mathbf{n}\\) and renormalizing, \\[\n\\psi_\\mathbf{n}(\\mathbf{x}, t) = \\frac{1}{\\sqrt{V}} e^{i \\big(\\mathbf{k}_\\mathbf{n} \\cdot \\mathbf{x} - \\omega_\\mathbf{n} t\\big)} \\ .\n\\] As we might expect, rather than plane waves in space and time, the bounded solutions represent standing waves inside the box, where each \\(\\mathbf{n}\\) represents some specific configuration of harmonics. The full wavefunction \\(\\psi(\\mathbf{x},t)\\) is again given by a superposition of these standing waves, except this time a discrete sum of them, \\[\n\\psi(\\mathbf{x},t) = \\langle \\mathbf{x} | \\psi \\rangle = \\sum_{\\mathbf{n}} \\langle\\mathbf{n} | \\psi \\rangle \\langle \\mathbf{x} | \\mathbf{n} \\rangle = \\sum_{\\mathbf{n}} c_\\mathbf{n}\\psi_\\mathbf{n}(\\mathbf{x}, t) \\ .\n\\] Here, \\(c_\\mathbf{n} = \\langle \\mathbf{n} | \\psi \\rangle\\) are just the usual complex Fourier series coefficients, which are determined by the initial conditions.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Quantum Statistical Mechanics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/quantum-stat-mech.html#density-operator",
    "href": "statistical-mechanics/quantum-stat-mech.html#density-operator",
    "title": "Quantum Statistical Mechanics",
    "section": "Density Operator",
    "text": "Density Operator\nNow that we’ve reviewed the essentials of quantum mechanics we can proceed to setup the apparatus of quantum statistical mechanics. We’ve setup the framework for thinking of the microstates as kets in a Hilbert space, \\(\\mu = \\{|\\psi\\rangle\\}\\). The macrostates remain the same, \\(M = (E,X,N)\\). We now just need to find a way to connect the two via some sort of probability density. It’s not clear though how to think about what a density is in quantum mechanics. We can’t define a density on phase space since we can’t have diagonalizable functions of both position and momentum.\nTo do that we need to think more carefully about what we mean by a quantum mechanical state. Strictly speaking when we say a state is a ket \\(|\\psi\\rangle\\), what we really mean is that \\(|\\psi\\rangle\\) is the state of the system in the idealized situation where we have exact knowledge of the system. These are called pure states. We can think of pure states not only as kets, but as outer products \\[\n\\rho \\equiv |\\psi\\rangle \\langle \\psi| \\ .\n\\] In this form pure states are no longer kets but operators. When operating on their ket equivalent they give back the ket, \\[\n\\rho |\\psi \\rangle = |\\psi\\rangle \\langle \\psi| \\psi \\rangle = |\\psi \\rangle \\ .\n\\] In practice we usually don’t observe exact knowledge of the system. Instead we have to look at the system as an ensemble of states, e.g. by looking at a large number of particles instead of a single particle. In this situation we have to think of a state as a statistical mixture of pure states, \\[\n\\rho \\equiv \\sum_\\alpha p_\\alpha |\\psi_\\alpha\\rangle \\langle \\psi_\\alpha| \\ .\n\\] Here \\(p_\\alpha\\) is a classical probability weight indicating our lack of knowledge about the system. It’s statistical in nature, not quantum mechanical. States like this are called mixed state, because they’re a statistical mixture of pure states. Unlike pure states, we can’t think of mixed states as a ket in Hilbert space. We have to think of them as operators.\nWhat’s most important for our purposes is the nature of this operator \\(\\rho\\), called the density operator. As the notation and name suggests, this is our likely candidate for the quantum mechanical version of the phase space density. To verify this, we first need to show that \\(\\rho\\) represents the operator equivalent of a probability density. It should be:\n\nPositive semi-definite: That is, \\(\\langle \\psi | \\rho | \\psi \\rangle \\geq 0\\) for any ket \\(|\\psi\\rangle\\). To verify this, observe \\[\n\\langle \\psi | \\rho | \\psi \\rangle = \\sum_\\alpha p_\\alpha \\langle \\psi|\\psi_\\alpha\\rangle \\langle \\psi_\\alpha|\\psi\\rangle = \\sum_\\alpha p_\\alpha |\\langle \\psi|\\psi_\\alpha\\rangle|^2 \\geq 0 \\ .\n\\]\nHermitian: The probability density should be observable, which means \\(\\rho = \\rho^\\dagger\\). This is easy to verify, \\[\n\\rho^\\dagger = \\sum_\\alpha p_\\alpha \\bigg(|\\psi_\\alpha\\rangle \\langle \\psi_\\alpha|\\bigg)^\\dagger = \\sum_\\alpha p_\\alpha |\\psi_\\alpha\\rangle \\langle \\psi_\\alpha| = \\rho \\ .\n\\]\nUnit Trace: That is, \\(\\tr \\rho = 1\\). This is the generalization of probabilities summing to one. To verify we’ll pick a basis and sum, \\[\n\\tr \\rho = \\sum_n \\langle n | \\rho | n \\rangle = \\sum_\\alpha p_\\alpha \\sum_n \\langle n | \\psi_\\alpha \\rangle \\langle \\psi_\\alpha | n \\rangle = \\sum_\\alpha p_\\alpha = 1 \\ .\n\\] Here we used the fact that \\(p_\\alpha\\) is a valid classical probability that sums to one, and that each \\(|\\psi_\\alpha\\rangle\\) must be normalized.\n\nWe’ve thus shown that the density operator is a valid operator generalization of the probability density. Given this fact we can also proceed to define what we mean by an expected value in quantum statistical mechanics. Now we’re taking not just an average, but a classical ensemble average of a quantum average. It’s not hard to show that we can indeed naturally define \\[\n\\langle Q \\rangle \\equiv \\sum_\\alpha p_\\alpha \\langle Q \\rangle_{\\psi_\\alpha} = \\tr \\rho Q \\ .\n\\] We still need to show that it has the same dynamical character as the phase space density. Recall the classical density must satisfy Liouville’s equation \\(\\frac{\\partial\\rho}{\\partial t} = -\\{\\rho, H\\}\\). According to the replacement rules between Poisson brackets and commutators, we should expect something similar here. Using the definition of the density operator and the Schrödinger equation, we have \\[\n\\begin{align*}\n\\frac{\\partial\\rho}{\\partial t} &= \\frac{\\partial}{\\partial t} \\sum_\\alpha p_\\alpha |\\psi_\\alpha\\rangle \\langle \\psi_\\alpha| \\\\\n&= \\sum_\\alpha p_\\alpha \\bigg(|\\psi_\\alpha\\rangle\\frac{\\partial \\langle \\psi_\\alpha|}{\\partial t} + \\frac{\\partial|\\psi_\\alpha\\rangle}{\\partial t}\\langle \\psi_\\alpha|\\bigg) \\\\\n&= \\sum_\\alpha p_\\alpha \\bigg(\\frac{i}{\\hbar}|\\psi_\\alpha\\rangle \\langle \\psi_\\alpha| H - \\frac{i}{\\hbar}H|\\psi_\\alpha\\rangle \\langle \\psi_\\alpha|  \\bigg) \\\\\n&= \\frac{i}{\\hbar} \\bigg[\\bigg(\\sum_\\alpha p_\\alpha |\\psi_\\alpha\\rangle \\langle \\psi_\\alpha| \\bigg) H - H \\bigg(\\sum_\\alpha p_\\alpha |\\psi_\\alpha\\rangle \\langle \\psi_\\alpha| \\bigg)\\bigg] \\\\\n&= \\frac{i}{\\hbar} [\\rho, H] \\ .\n\\end{align*}\n\\] We’ve thus proved the quantum mechanical equivalent of Liouville’s equation, known as the von-Neumann equation, \\[\n\\boxed{\n\\frac{\\partial\\rho}{\\partial t} = \\frac{i}{\\hbar} [\\rho, H]\n} \\ .\n\\]\nFor an ensemble in equilibrium, we require the density be time-independent, i.e. \\[\n\\frac{\\partial\\rho}{\\partial t} = \\frac{i}{\\hbar} [\\rho, H] = 0 \\ .\n\\] This means that in equilibrium \\(\\rho\\) must commute with \\(H\\) and any other conserved quantities that also commute with \\(H\\). In the simplest case where only energy is conserved, this means in equilibrium we must again have \\(\\rho = \\rho(H)\\).",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Quantum Statistical Mechanics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/quantum-stat-mech.html#statistical-mechanics",
    "href": "statistical-mechanics/quantum-stat-mech.html#statistical-mechanics",
    "title": "Quantum Statistical Mechanics",
    "section": "Statistical Mechanics",
    "text": "Statistical Mechanics\nWe can now proceed as usual to define all of the statistical ensembles, except with the caveat that we have to think in terms of operators. We typically think of the density operator as a mixture of energy states, \\[\n\\rho = \\sum_n p_n |n\\rangle \\langle n | \\ .\n\\] This choice of states is convenient because we want \\(\\rho\\) to be time-independent at equilibrium, and we know that in the energy basis the pure states will remain time-independent. To get the probability of the system being in a particular energy eigenstate we just need to pick out one of these elements to get \\[\np_n = \\langle n | \\rho | n \\rangle \\ .\n\\] Since it’s easy, we’ll typically work in this energy basis when solving problems in quantum statistical mechanics.\n\nMicrocanonical Ensemble\nWe started the classical theory by looking at the microcanonical ensemble where \\(M = (E,X,N)\\). In that setting we have \\[\n\\rho = \\frac{\\delta(H-E)}{\\Omega} \\ .\n\\] In the energy basis, this says \\[\np_n = \\langle n|\\rho |n \\rangle = \\frac{1}{\\Omega} \\delta(E-E_n) \\ .\n\\] This is a reflection of the usual assumption of equal a priori probabilities, where each microstate with energy \\(E\\) can occur with the same uniform probability \\(p_n = \\frac{1}{\\Omega}\\). It’s also illuminating to look at the off-diagonal elements of the density operator. Observe \\[\n\\langle m | \\rho | n  \\rangle = \\frac{\\delta(E-E_n)}{\\Omega} \\delta_{mn} \\ .\n\\] These terms are non-zero only when both \\(E=E_n\\) and \\(m=n\\). That is, only the diagonal elements are non-zero. The fact that the off-diagonal elements are zero is often called the assumption of random phases. Essentially, it means the system has had time to fully mix with its environment, leading to quantum decoherence. When a quantum system has fully decohered, its wave packets have become very well localized, its density operator is diagonal, and it becomes well approximated by classical dynamics.\nWe can also find an explicit expression for the multiplicity \\(\\Omega\\) by tracing over \\(\\rho\\) and solving to get \\[\n\\Omega = \\text{tr} \\ \\delta(H-E) = \\sum_n \\delta(E-E_n) \\ .\n\\] This factor again represents the number of microstates with energy \\(E\\). From this expression we can again derive the entropy and write it in the familiar form \\[\nS = -\\sum_n p_n \\log p_n = k_B \\log \\Omega \\ .\n\\] With the entropy in hand we can proceed to derive all the thermodynamic variables of interest as usual. For example, we can find the temperature by solving the equation \\[\n\\frac{1}{T} = \\frac{\\partial S}{\\partial E} \\bigg |_{X,N} \\ .\n\\] Just as in the classical theory, the microcanonical is often not the most convenient ensemble to work with, so we should cover the more convenient ones too.\n\n\nCanonical Ensemble\nWe can similarly look at the canonical ensemble where \\(M=(T,X,N)\\). In that setting we have \\[\n\\rho = \\frac{1}{Z} e^{-\\beta H} \\ ,\n\\] where \\(Z\\) is the quantum canonical partition function. In the energy basis this means the probability of any given eigenstate is \\[\np_n = \\frac{1}{Z} e^{-\\beta E_n} \\ .\n\\] By tracing over \\(\\rho\\) we can express \\(Z\\) using the useful formula \\[\n\\boxed{\nZ = \\text{tr} \\ e^{-\\beta H}\n} \\ .\n\\] In terms of the energy basis this just says \\[\nZ = \\sum_n e^{-\\beta E_n} \\ .\n\\] From the partition function we can again proceed to find all thermodynamic variables of interest. For example, the average energy \\(E\\) of the system is given by \\[\nE = \\langle H \\rangle = \\text{tr} \\ \\rho H = -\\frac{\\partial \\log Z}{\\partial \\beta} \\ .\n\\]\n\n\nHigher Ensembles\nIn a similar fashion of course we can also look at the two higher ensembles. In the Gibbs canonical ensemble we take as macrostates \\(M = (T,J,N)\\). The density operator becomes \\[\n\\rho = \\frac{1}{Z_G} e^{-\\beta (H-J \\cdot X)} \\ ,\n\\] where the Gibbs canonical partition function \\(Z_G\\) is given by \\[\nZ_G = \\int dX \\ \\tr e^{-\\beta (H-J \\cdot X)} = \\int dX \\  e^{\\beta J \\cdot X} Z \\ .\n\\] Notice that while \\(H\\) is thought of as an operator, the displacement \\(X\\) and force \\(J\\) are not. They’re just ordinary vectors. We can find the mean displacement \\(\\langle X \\rangle\\) in the usual way by \\[\n\\langle X \\rangle = \\frac{\\partial \\log Z_G}{\\partial (\\beta J)} \\ .\n\\] Similarly, in the grand canonical ensemble we take as macrostates \\(M=(T,X,\\mu)\\) where \\(\\mu\\) is the chemical potential. Then \\[\n\\rho = \\frac{1}{\\mathcal{Z}} e^{-\\beta (H-\\mu \\cdot N)} \\ ,\n\\] where the Grand canonical partition function \\(\\mathcal{Z}\\) can be found by the formula \\[\n\\mathcal{Z} = \\sum_{N=0}^\\infty \\text{tr} \\ e^{-\\beta (H-\\mu \\cdot N)} = \\sum_{N=0}^\\infty  e^{\\beta \\mu \\cdot N} Z \\ .\n\\] Again, here we should think of \\(\\mu\\) and \\(N\\) as ordinary vectors, not operators. We can find the mean particle number \\(\\langle N \\rangle\\) in the usual way as well by \\[\n\\langle N \\rangle = \\frac{\\partial \\log\\mathcal{Z}}{\\partial (\\beta \\mu)} \\ .\n\\] Both formulations reduce to their obvious form when working in the energy basis.\n\n\nClassical Limit\nIt’s worth briefly mentioning here in what sense classical statistical mechanics is a limit of quantum statistical mechanics. Clearly in the classical world of large energies the laws of classical statistical mechanics are perfectly valid, yet we know that quantum statistical mechanics should be the true theory in all cases. To see how the classical limit arises let’s look at the canonical partition function \\(Z\\) and see how we can go from the quantum to the classical version via some kind of limiting procedure.\nLet’s suppose for simplicity we want to find \\(Z\\) for a single particle with a Hamiltonian operator given by \\[\nH = \\frac{\\mathbf{p}^2}{2m} + V(\\mathbf{x}) \\ .\n\\] In the position basis, this means the single-particle partition function can be written \\[\nZ = \\text{tr} \\ e^{-\\beta H} = \\int d^3 \\mathbf{x} \\ \\big\\langle \\mathbf{x} \\big| e^{-\\beta \\big(\\frac{\\mathbf{p}^2}{2m} + V(\\mathbf{x})\\big)} \\big| \\mathbf{x} \\big\\rangle \\ .\n\\] Now, we’d like to factor the exponential, except we have to be careful because the exponents here are operators. For two arbitrary operators \\(A\\) and \\(B\\) we can’t generally say \\(e^{A+B} = e^A e^B\\). This is only true if \\(A\\) and \\(B\\) commute. We already know position and momentum don’t commute. The more general result requires a series in terms of the iterated commutators of \\(A\\) and \\(B\\). To first few terms written out look like \\[\ne^{A} e^{B} = e^{A + B + \\frac{1}{2} [A,B] + \\cdots} \\ .\n\\] Since \\([x_i, p_j] = i\\hbar\\delta_{ij}\\) the first order correction to the classical result is of order \\(\\hbar\\), which means we can rearrange and write \\[\ne^{-\\beta \\big(\\frac{\\mathbf{p}^2}{2m} + V(\\mathbf{x})\\big)} = e^{-\\beta \\frac{\\mathbf{p}^2}{2m}} e^{-\\beta V(\\mathbf{x})}\\big(1 + \\beta O(\\hbar)\\big) \\ .\n\\] In the classical limit we typically imagine sending \\(\\hbar \\rightarrow 0\\), in which case the classical factorization becomes exact.\nLet’s now plug this result into the partition function traced over the position states. We have \\[\n\\begin{align*}\nZ &= \\text{tr} \\ e^{-\\beta H} \\\\\n&\\approx \\int d^3 \\mathbf{x} \\ \\big\\langle \\mathbf{x} \\big| e^{-\\beta \\frac{\\mathbf{p}^2}{2m}} e^{-\\beta V(\\mathbf{x})} \\big| \\mathbf{x} \\big\\rangle \\\\\n&\\approx \\int d^3 \\mathbf{x} \\ d^3 \\mathbf{p} \\ \\big\\langle \\mathbf{x} \\big| e^{-\\beta \\frac{\\mathbf{p}^2}{2m}} \\big| \\mathbf{p} \\big\\rangle \\big\\langle \\mathbf{p} \\big| e^{-\\beta V(\\mathbf{x})} \\big| \\mathbf{x} \\big\\rangle \\\\\n&\\approx \\int d^3 \\mathbf{x} \\ d^3 \\mathbf{p} \\ e^{-\\beta \\big(\\frac{\\mathbf{p}^2}{2m} + V(\\mathbf{x})\\big)} \\big| \\langle \\mathbf{x} | \\mathbf{p} \\rangle \\big|^2 \\\\\n&\\approx \\int \\frac{d^3 \\mathbf{x} \\ d^3 \\mathbf{p}}{(2\\pi\\hbar)^3} \\ e^{-\\beta H(\\mathbf{x},\\mathbf{p})} \\ .\n\\end{align*}\n\\] In the third line we inserted a resolution of the identity over the momentum states. In the fourth line we used the fact that for any operator \\(Q\\) we have \\(f(Q) |q\\rangle = f(q)|q\\rangle\\). This allows us to pull the exponentials out and combine them to get the classical Boltzmann scalar factor \\(e^{-\\beta H(\\mathbf{x},\\mathbf{p})}\\). Last, we used the fact that \\(\\big| \\langle \\mathbf{x} | \\mathbf{p} \\rangle \\big|^2 = (2\\pi\\hbar)^{-3}\\).\nNow, recall that in the classical partition function we had to insert a factor of \\(h\\) that had units of action. We didn’t know what it was, and it turned out not to affect any of the classical results. But now we know exactly what it is. As the notation always suggested, it’s the classical Planck’s constant \\(h = 2\\pi\\hbar\\). Inserting this identity we’ve shown how the classical limit arises.\nNotice our derivation of the classical limit just assumed that we could send \\(\\hbar \\rightarrow 0\\). But \\(\\hbar\\) is constant, so what do we really mean when we say something like this? In the case of statistical mechanics, what we really mean is that we’re in the high temperature limit. As \\(T \\rightarrow \\infty\\), \\(\\beta \\rightarrow 0\\). This means that even ignoring \\(\\hbar\\) we still can factorize \\(e^{-\\beta H}\\) in the high temperature limit as \\[\ne^{-\\beta H} = e^{-\\beta \\frac{\\mathbf{p}^2}{2m}} e^{-\\beta V(\\mathbf{x})}\\big(1 + \\beta O(\\hbar)\\big) \\approx e^{-\\beta \\frac{\\mathbf{p}^2}{2m}} e^{-\\beta V(\\mathbf{x})} \\ .\n\\] We’ll see this tendency towards the classical limit at high temperatures again and again as we work examples.\n\n\nDensity of States\nLet’s go ahead and mention an important concept we’ll need in our study of quantum statistical mechanics, the idea of the density of states. We’ll frequently find that we want to do is replace a discrete sum over states with an integral over some weighted measure \\(g(\\chi)d\\chi\\). The weight \\(g(\\chi)\\) is called a density of states. The density of states is basically a count of the number of states in the range \\(\\chi\\) to \\(\\chi + d\\chi\\). The hardest part is actually calculating what \\(g(\\chi)\\) should be.\nFor most quantities \\(\\chi\\) of interest the density of states will depend on the problem itself. But there’s one that’s pretty general, namely when \\(\\chi = \\mathbf{k}\\). In that case we imagine an enclosed system with periodic boundary conditions, so that we can write \\[\n\\mathbf{k} \\approx \\frac{2\\pi}{V^{1/3}} \\mathbf{n} \\ .\n\\] If we assume the number of states per unit area is extremely dense we can write \\(\\sum_{\\mathbf{n}} \\approx \\int d^3 \\mathbf{n}\\). Then using the multivariate change of variables formula, we have \\[\nd^3 \\mathbf{n} = d \\bigg(\\frac{V^{1/3} k_x}{2\\pi}\\bigg) d \\bigg(\\frac{V^{1/3} k_y}{2\\pi}\\bigg) d \\bigg(\\frac{V^{1/3} k_z}{2\\pi}\\bigg)  = \\frac{V}{(2\\pi)^3} d^3 \\mathbf{k} \\ .\n\\] The function out front of the differential is then the density of states, namely \\(g(\\mathbf{k}) = \\frac{V}{(2\\pi)^3}\\). This relation will be useful all across statistical mechanics, where we assume \\(\\lambda = \\frac{2\\pi}{|\\mathbf{k}|} \\ll V^{1/3}\\), meaning that each \\(d^3 \\mathbf{k}\\) of volume contains a huge number of states.\nTwo other densities of states we’ll be interested in are the ones for energy \\(E\\) and frequency \\(\\omega\\). To calculate these we just need to use whatever dispersion relation \\(\\omega(\\mathbf{k})\\) a given system has to calculate \\(g(\\omega)\\), and then use \\(E=\\hbar\\omega\\) to calculate \\(g(E)\\). Anytime we calculate densities, we need to be careful to do so using the full measures, not just the densities themselves. For example, for the particle in the box we saw that the energy had the form \\(E = \\frac{\\hbar^2 |\\mathbf{k}|^2}{2m}\\), or equivalently that \\(\\omega = \\frac{\\hbar |\\mathbf{k}|^2}{2m}\\). We’d thus have \\[\ng(\\mathbf{k}) d^3 \\mathbf{k} = \\frac{V}{(2\\pi)^3} 4\\pi d\\bigg(\\sqrt{\\frac{2m\\omega}{\\hbar}}\\bigg) = \\frac{V}{4\\pi^2} \\bigg(\\frac{2m}{\\hbar}\\bigg)^{3/2} \\sqrt{\\omega} d\\omega = g(\\omega) d\\omega \\ .\n\\] That is, for the particle in a box, the density of states for frequency is \\(g(\\omega) = \\frac{V}{4\\pi^2} \\big(\\frac{2m}{\\hbar}\\big)^{3/2} \\sqrt{\\omega}\\). The density of states for energy can then be found by using the relation \\(E=\\hbar\\omega\\) in the change of variables formula to get \\[\ng(E) = \\frac{(2m)^{3/2} V}{4\\pi^2\\hbar^3} \\sqrt{E} \\ .\n\\] The energy density of states \\(g(E)\\) also happens to be the Laplace transform of the canonical partition function \\(Z(\\beta)\\), since \\[\nZ(\\beta) = \\int_0^\\infty dE \\ g(E) e^{-\\beta E} \\ .\n\\] It’s also possible to show that \\(g(E)\\) can be related to the multiplicity \\(\\Omega\\) via the relation \\(g(E) = \\frac{1}{V} \\frac{\\partial \\Omega}{\\partial E}\\).\n\n\nExample: Particle in a Box\nLet’s go ahead and calculate the partition function and equation of state for the particle in a box. For now we’ll assume the particles are distinguishable. The reason for this has to do with a subtlety with identical particles in quantum mechanics that we’ll come to later on. We already saw that in the energy basis states are discrete with energy eigenvalues \\[\nE_\\mathbf{n} = \\frac{\\hbar^2}{2m} \\bigg(\\frac{n_x^2}{L_x^2} + \\frac{n_y^2}{L_y^2} + \\frac{n_y^2}{L_y^2}\\bigg) \\ , \\quad n_x, n_y, n_z = 1, 2, \\cdots \\ .\n\\] For convenience we’ll assume \\(L \\equiv L_x = L_y = L_z\\). Defining the energy constant \\(\\varepsilon \\equiv \\frac{\\hbar^2  \\pi^2}{2mL^2}\\), we can then write \\[\nE_{\\mathbf{n}} = \\varepsilon (n_x^2 + n_y^2 + n_z^2) \\ .\n\\] In the energy basis the partition function for a single particle is given by \\[\nZ_1 = \\sum_{n_x,n_y,n_z=1}^\\infty e^{-\\beta \\varepsilon (n_x^2 + n_y^2 + n_z^2)} = \\bigg(\\sum_{n=1}^\\infty e^{-\\beta \\varepsilon n^2} \\bigg)^3 \\ .\n\\] Functions of this form are related to a type of special function known as a theta function. Specifically they’re related to the \\(\\theta_3\\) functions defined by \\[\n\\theta_3(x) \\equiv 1 + 2\\sum_{n=1}^\\infty x^{n^2} = 1 + 2x + 2x^4 + 2x^9 + \\cdots \\ .\n\\] Substituting this in for each component using \\(x=e^{-\\beta\\varepsilon}\\), the exact partition function for a single particle is then \\[\nZ_1 = \\frac{1}{8} \\bigg(\\theta_3\\big(e^{-\\beta\\varepsilon}\\big) - 1\\bigg)^3 \\ .\n\\] As will usually be the case in quantum statistical mechanics, having the exact partition function rarely helps us understand the physics. They’ll often be expressed in terms of arcane special functions like this. Instead, what we’ll usually do in practice is look at two limits: the high temperature limit where we should recover the classical result, and the low temperature limit where we should see the limiting quantum mechanical behavior near absolute zero.\nStarting with the high temperature limit, we’re looking at what happens as \\(\\beta \\rightarrow 0\\). In that case each \\(e^{-\\beta\\varepsilon}\\) is roughly flat and we can replace the sums by integrals. It’s not hard to see that for a flat function, a sum from \\(1\\) to \\(N\\) is approximately the same as its integral from \\(0\\) to \\(N\\). We can thus to high accuracy write \\[\n\\sum_{n=1}^\\infty e^{-\\beta \\varepsilon n^2} \\approx \\int_0^\\infty dn \\ e^{-\\beta \\varepsilon n^2} = \\frac{1}{2} \\sqrt{\\frac{\\pi}{\\beta \\varepsilon}} = \\frac{L}{\\lambda_{T}} \\ ,\n\\] where \\(\\lambda_T = \\frac{h}{\\sqrt{2\\pi m k_B T}}\\) is the thermal DeBroglie wavelength. Plugging these into the partition function gives exactly what we’d expect for a non-interacting classical particle in a container, \\[\nZ_1 \\approx \\frac{L^3}{\\lambda_T^3} = \\frac{V}{\\lambda_T^3} \\ .\n\\] From this we can immediately read off the equations of state as the ones for an ideal gas. Nothing new here though. What about the low temperature limit? In that region we can no longer approximate the sum with an integral since it’s nowhere near flat anymore, but instead rapidly decaying. Instead we can approximate each series with its first few terms, \\[\n\\sum_{n=1}^\\infty e^{-\\beta \\varepsilon n^2} = e^{-\\beta \\varepsilon} + \\big(e^{-\\beta \\varepsilon}\\big)^4 + \\big(e^{-\\beta \\varepsilon}\\big)^9 + \\cdots \\ .\n\\] For temperatures very close to zero it’s easy to see that we can keep only the first term. Then the partition function is just \\[\nZ_1 \\approx e^{-3\\beta\\varepsilon} = \\exp\\bigg[-3\\beta\\frac{\\hbar^2\\pi^2}{2mL^2}\\bigg] \\ .\n\\] Notice this is just the energy we get when \\(n_x=n_y=n_z=1\\). That is, it’s the ground state energy \\(E_0=3\\varepsilon\\). This makes sense. We’d expect that at the lowest temperatures the particle would fall down into its ground state, with mean energy \\(E \\approx E_0\\).\nIf we like we can attempt to fit a curve between the high and low temperature regions by calculating the next correction to the partition function. The partition function with the next term in the series included would be \\[\nZ_1 \\approx \\bigg(e^{-\\beta \\varepsilon} + \\big(e^{-\\beta \\varepsilon}\\big)^4\\bigg)^3 \\approx e^{-\\beta E_0} \\big(1 + 3e^{-\\beta E_0}\\big) \\ .\n\\] Here we used the fact that if \\(\\beta\\) is large then \\(e^{-\\beta E_0}\\) must be small. Using the same fact again we get \\[\n\\log Z_1 = -\\beta E_0 + \\log(1+3e^{-\\beta E_0}) \\approx -\\beta E_0 + 3e^{-\\beta E_0} \\ .\n\\] We can then calculate the energy per particle to this correction as \\[\nE_1 = -\\frac{\\partial \\log Z_1}{\\partial\\beta} \\approx E_0 (1 + e^{-E_0/k_B T}) \\ .\n\\] Typically we’re more interested in the curve of the heat capacity as a function of temperature. To get that we need to calculate the heat capacity \\(C\\) from the energy. We have \\[\nC_1 \\approx \\frac{\\partial E_1}{\\partial T} = k_B \\bigg(\\frac{E_0}{k_B T}\\bigg)^2 e^{-E_0/k_B T} \\ .\n\\] If we join this with the classical heat capacity line \\(C_1 = \\frac{3}{2}\\) at high temperatures we get a plot something like the one below. Notice that \\(C_1 \\rightarrow 0\\) as \\(T \\rightarrow 0\\) in agreement with the third law of thermodynamics. In fact, it goes to zero exponentially. The interpolation region seems to occur around a characteristic temperature \\(\\theta\\) given by \\(k_B \\theta \\equiv E_0\\).\n\n\n\n\n\nWe can also calculate the density operator in some basis. Let’s look at the diagonal and off diagonal elements of \\(\\rho\\) in the position basis. We’ll assume we’re at temperatures \\(T \\gg \\theta\\) so that we can approximate \\(Z_1 \\approx \\frac{V}{\\lambda_T^3}\\). In that case, we have \\[\n\\begin{align*}\n\\langle \\mathbf{x} | \\rho | \\mathbf{x}' \\rangle &= \\frac{1}{Z_1} \\langle \\mathbf{x} | e^{-\\beta H} | \\mathbf{x}' \\rangle \\\\\n&= \\frac{1}{Z_1} \\sum_{\\mathbf{n},\\mathbf{n}'} \\langle \\mathbf{x} | \\mathbf{n} \\rangle \\langle \\mathbf{n} | e^{-\\beta \\frac{\\hbar^2}{2m} \\mathbf{k}^2} | \\mathbf{n}' \\rangle \\langle \\mathbf{n}' | \\mathbf{x}' \\rangle  \\\\\n&= \\frac{1}{Z_1} \\sum_{\\mathbf{n}} e^{-\\beta \\frac{\\hbar^2}{2m} \\mathbf{k}_\\mathbf{n}^2} \\langle \\mathbf{x} | \\mathbf{n} \\rangle \\langle \\mathbf{n} | \\mathbf{x}' \\rangle  \\\\\n&\\approx \\frac{1}{Z_1} \\frac{V}{(2\\pi)^3} \\int \\frac{d^3 \\mathbf{k}}{V} \\ e^{i \\mathbf{k} \\cdot (\\mathbf{x} - \\mathbf{x}')} e^{-\\beta \\frac{\\hbar^2}{2m} \\mathbf{k}^2} \\\\\n&\\approx \\frac{\\lambda_T^3}{V} \\frac{1}{\\lambda_T^3} \\exp\\bigg(-\\frac{(\\mathbf{x}-\\mathbf{x}')^2}{2m/ \\beta\\hbar^2}\\bigg) \\\\\n&\\approx \\frac{1}{V} \\exp\\bigg(-\\frac{(\\mathbf{x}-\\mathbf{x}')^2}{\\lambda_T^2 / \\pi} \\bigg) \\ .\n\\end{align*}\n\\] So what is this saying? First, let’s look at the diagonal elements by setting \\(\\mathbf{x}=\\mathbf{x}'\\). In that case we get \\(p(\\mathbf{x}) = \\frac{1}{V}\\). This just says that the particle is uniformly likely to be anywhere in the box. But what about when \\(\\mathbf{x}\\neq\\mathbf{x}'\\)? In this case, the density operator is telling us how much the presence of a particle at \\(\\mathbf{x}\\) quantum mechanically interferes with the presence of another particle at \\(\\mathbf{x}'\\). The two particle’s wavefunctions would overlap inside a Gaussian envelope with a spread proportional to \\(\\lambda_T\\). At higher temperatures, \\(\\lambda_T\\) will be smaller, meaning it’s less likely two nearby particles interfere with each other. At high temperatures the system has effectively decohered, in which case it’s usually a good approximation to treat the system classically.\nEvidently, it’s when \\(v \\sim \\lambda_T^3\\) that quantum effects start to become important at a given temperature. For most particles at typical temperatures, \\(\\lambda_T\\) will be on the order of a few Angstroms, which is roughly the atomic spacing. This means quantum effects will tend to be far more important for liquids and solids than for dilute gases, except at temperatures very near absolute zero.\n\n\nExample: Harmonic Oscillator\nThe next example we’ll consider is the quantum harmonic oscillator. Suppose we have a one-particle Hamiltonian given by \\[\nH_1 = \\frac{p^2}{2m} + \\frac{1}{2} m \\omega^2 x^2 \\ .\n\\] This represents a particle connected to a one-dimensional spring with spring constant \\(k = m\\omega^2\\). In quantum mechanics we have to treat this as an operator. It turns out we can factor this Hamiltonian in the form \\(H_1 = \\hbar\\omega(N+\\frac{1}{2})\\), where \\(N\\) is a number operator. When acted on the energy eigenstates it gives \\(N|n\\rangle = n|n\\rangle\\). From this, we conclude the energy eigenvalues are \\[\nE_n = \\hbar \\omega \\bigg(n + \\frac{1}{2}\\bigg) \\ , \\quad n = 0,1,\\cdots \\ .\n\\] From here we can calculate the single-particle partition function, and in this case actually get a closed form for it. We have \\[\n\\begin{align*}\nZ_1 &= \\sum_{n=0}^\\infty e^{-\\beta\\hbar\\omega\\big(n+\\frac{1}{2}\\big)} \\\\\n&= e^{-\\frac{\\beta\\hbar\\omega}{2}} \\sum_{n=0}^\\infty \\big(e^{-\\beta\\hbar\\omega}\\big)^n \\\\\n&= \\frac{e^{-\\frac{\\beta\\hbar\\omega}{2}}}{1 - e^{-\\beta\\hbar\\omega}} \\ .\n\\end{align*}\n\\] The logarithm of \\(Z_1\\) is then given by \\[\n\\log Z_1 = -\\frac{\\beta\\hbar\\omega}{2} - \\log\\big(1 - e^{-\\beta\\hbar\\omega}\\big) \\ .\n\\] From here we can calculate the energy per particle to get \\[\nE_1 = \\frac{\\hbar\\omega}{2} + \\frac{\\hbar\\omega}{e^{\\hbar\\omega/k_B T}-1} \\ .\n\\] Again, let’s investigate the behavior of the energy in the high and low temperature limits. In the high temperature limit we can approximate the exponential by \\(e^{\\hbar\\omega/k_B T} \\approx 1 + \\frac{\\hbar\\omega}{k_B T}\\) to get the classical result we’d expect from the equipartition theorem, \\[\nE_1 \\approx \\frac{\\hbar\\omega}{2} + k_B T \\approx k_B T \\ .\n\\] Here we used the fact that at high temperatures \\(k_B T \\gg \\hbar\\omega\\). At zero temperature we can see the energy is just the ground state energy exactly, \\(E_1 = \\frac{1}{2} \\hbar\\omega\\), which is again what we’d expect.\nSince we’ll need it later, let’s go ahead and look at the heat capacity per particle too. We have \\[\nC_1 = k_B \\bigg(\\frac{\\hbar\\omega}{k_B T}\\bigg)^2 \\frac{e^{\\hbar\\omega/k_B T}}{\\big(e^{\\hbar\\omega/k_B T}-1\\big)^2} \\ .\n\\] At high temperatures we again use the Taylor expansion of \\(e^{\\hbar\\omega/k_B T}\\) to get \\[\nC_1 \\approx k_B \\bigg(\\frac{\\hbar\\omega}{k_B T}\\bigg)^2 \\frac{1-\\frac{\\hbar\\omega}{k_B T}}{\\big(\\frac{\\hbar\\omega}{k_B T}\\big)^2} \\approx k_B \\bigg(1-\\frac{\\hbar\\omega}{k_B T}\\bigg) \\ .\n\\] For temperatures where \\(k_B T \\gg \\hbar\\omega\\) we can neglect the last term to get \\(C_1 \\approx k_B\\), which is what we’d expect classically. At low temperatures we can use the fact that \\(e^{\\hbar\\omega/k_B T} \\ll 1\\) along with the binomial expansion \\((1-x)^{-2} \\approx 1+2x\\) to write \\[\nC_1 \\approx k_B \\bigg(\\frac{\\hbar\\omega}{k_B T}\\bigg)^2 \\frac{e^{-\\hbar\\omega/k_B T}}{\\big(1-e^{-\\hbar\\omega/k_B T}\\big)^2} \\approx k_B \\bigg(\\frac{\\hbar\\omega}{k_B T}\\bigg)^2 e^{-\\hbar\\omega/k_B T} \\big(1 + 2e^{-\\hbar\\omega/k_B T}\\big) \\ .\n\\] Again, we can see that the heat capacity goes to zero exponentially in accordance with the third law. Connecting the two limits, we get a similar curve to the particle in the box heat capacity, except with a characteristic temperature given by \\(k_B \\theta = \\hbar\\omega\\).",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Quantum Statistical Mechanics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/quantum-stat-mech.html#three-classic-problems",
    "href": "statistical-mechanics/quantum-stat-mech.html#three-classic-problems",
    "title": "Quantum Statistical Mechanics",
    "section": "Three Classic Problems",
    "text": "Three Classic Problems\nWe’ll now turn our attention to addressing the three problems mentioned at the start of this chapter. Namely the resolution of the heat capacity of diatomic gases, the heat capacity of solids, and blackbody radiation. We’ll show that for each of these problems classical statistical mechanics gave results that disagreed with experiments of the time, and then we’ll show precisely how it is that quantum statistical mechanics was able to resolve all of these problems.\n\nDiatomic Gases\nRecall that a diatomic gas is a gas in which each particle can be thought of as two masses connected to a spring. Such particles are not only allowed to translate in space like point particles. They’re also allowed to rotate and vibrate, essentially giving them new degrees of freedom. We saw previously that the Hamiltonian for a single diatomic particle can be written \\[\n\\begin{align*}\nH_1 &= \\frac{\\mathbf{p}_1^2}{2m} + \\frac{\\mathbf{p}_2^2}{2m} + u(|\\mathbf{x}_1-\\mathbf{x}_2|) \\\\\n&= \\frac{\\mathbf{P}^2}{2M} + \\frac{\\mathbf{p}^2}{2\\mu} + \\frac{1}{2}\\mu\\omega^2r^2 + u(d) \\ ,\n\\end{align*}\n\\] where in the last line we switched to center of mass and relative coordinates and approximated the interaction potential between the two masses by a harmonic oscillator with equilibrium distance \\(d\\), i.e. \\(u(r) \\approx \\frac{1}{2}\\mu\\omega^2r^2 + u(d)\\). By integrating over each coordinate, we were able to show the classical single particle partition function had the form \\[\nZ_1 = \\frac{16\\pi^4 M^{3/2}}{h^6} \\frac{V}{\\beta^{7/2}} \\ .\n\\] From here, we were able to show the diatomic gas had average energy \\(E=\\frac{7}{2} Nk_B T\\) and heat capacity \\(C = \\frac{7}{2}Nk_B\\).\nGreat, so what’s the problem? It turns out that if we were to go out and actually measure the ratio \\(\\frac{C}{k_B}\\) for a gas of some given diatomic molecule, most of the time we won’t get \\(\\frac{7}{2}\\). In fact, around room temperature we’ll usually get something closer to \\(\\frac{5}{2}\\). If we reduce the temperature to around \\(10 \\ ^\\circ \\text{K}\\) and measure again, we instead get something close to \\(\\frac{3}{2}\\). If we increase the temperature to around \\(1000 \\ ^\\circ \\text{K}\\) and measure again, we get the \\(\\frac{7}{2}\\) factor that the classical theory predicts. It’s almost as if degrees of freedom are frozen out at lower temperatures, and only activate one by one as the temperature increases. This gives heat capacity curves that looks something like the following.\n\n\n\n\n\nClearly the classical theory isn’t able to account for such a strange heat capacity curve. It’s not able to predict this freezing out of degrees of freedom. We’ll show that the quantum theory can by looking at each mode one by one. Let’s first rewrite the diatomic gas Hamiltonian in a slightly different form. We’ll ignore the added constant \\(u(d)\\) from now on since it contributes nothing to the dynamics. We can explicitly split off the rotational contribution to the relative coordinates by factoring the \\(\\mathbf{p}^2\\) to get \\[\nH_1 = \\frac{\\mathbf{P}^2}{2M} + \\frac{\\mathbf{L}^2}{2I} + \\frac{p^2}{2\\mu} + \\frac{1}{2}\\mu\\omega^2r^2 \\equiv H_{\\text{trans}} + H_{\\text{rot}} + H_{\\text{vib}} \\ ,\n\\] where \\(\\mathbf{L}\\) is the angular momentum and \\(I=\\mu r^2\\) is the scalar moment of inertia. Note that even though \\(\\mathbf{L}\\) is a vector it only contributes two degrees of freedom. In this form, we can think of the Hamiltonian as composed of three distinct pieces, a translational piece \\(H_{\\text{trans}}\\) depending only on the center of mass coordinates, a rotational piece \\(H_{\\text{rot}}\\) depending only on the angular coordinates, and the vibrational piece \\(H_{\\text{vib}}\\) depending only on the radial coordinates. Let’s look at the heat capacity curves for each of these pieces one-by-one.\nFirst we have the translational piece \\(H_{\\text{trans}} = \\frac{\\mathbf{P}^2}{2M}\\). But this is just the Hamiltonian for the free particle. We already know what its solutions look like. At high temperatures we recover the classical result for the ideal gas, \\(C \\approx \\frac{3}{2} N k_B\\). At low temperatures we get a curve that goes to zero exponentially fast, \\[\nC \\approx Nk_B \\bigg(\\frac{E_0}{k_B T}\\bigg)^2 e^{-E_0/k_B T} \\ .\n\\] The transition region between the low and high temperature regions occurs when \\(k_B T \\approx E_0\\). For a \\(1 \\ \\text{m}^3\\) box of diatomic oxygen, this occurs at a temperature of around \\(\\theta \\approx 10^{-20} \\ ^\\circ\\text{K}\\). In fact this isn’t exactly right due to the fact that we’re not treating identical particles in quantum mechanics correctly yet. But the rough idea is right. The heat capacity goes to zero in accordance with the third law, and translational modes indeed activate very quickly at non-zero temperatures. This resolves the first part of the plot.\nSecond, we have the rotational piece \\(H_{\\text{rot}} = \\frac{\\mathbf{L}^2}{2I}\\). On its face this one looks the same as the translational piece, but there’s an important subtlety here. Angular momentum is also quantized separately from the energy. In quantum mechanics we can think about angular momentum states as two combined states \\(|\\ell m\\rangle\\), one representing the eigenvalues of \\(\\mathbf{L}^2\\) and the other representing the eigenvalues of the \\(z\\)-component \\(\\mathbf{L}_z\\). It turns out that both \\(\\mathbf{L}^2\\) and \\(\\mathbf{L}_z\\) commute, which means they’re simultaneously diagonalizable, and hence their eigenvectors can be chosen to be identical, namely \\(|\\ell m\\rangle\\), where \\[\n\\begin{align*}\n\\mathbf{L}^2 |\\ell m\\rangle &= \\hbar^2 \\ell(\\ell+1)|\\ell m\\rangle \\\\\n\\mathbf{L}_z |\\ell m\\rangle &= \\hbar m|\\ell m\\rangle \\ .\n\\end{align*}\n\\] Here \\(\\ell = 0,1,2, \\cdots\\) and \\(m = -\\ell, \\cdots, \\ell\\) are both integers. Notice that for each given \\(\\ell\\) there are \\(2m+1\\) eigenstates due to degeneracy in \\(\\mathbf{L}_z\\). Using these relations, in the \\(|\\ell m\\rangle\\) basis we can easily see that \\(H_{\\text{rot}}\\) diagonalizes too. Thus, we have \\[\nH_{\\text{rot}} |\\ell m\\rangle = \\frac{\\hbar^2\\ell(\\ell+1)}{2I} |\\ell m\\rangle \\quad \\Longrightarrow \\quad E_\\ell = \\frac{\\hbar^2\\ell(\\ell+1)}{2I} \\ .\n\\] From here we can proceed to calculate the partition function in the \\(|\\ell m \\rangle\\) basis. We have \\[\n\\begin{align*}\nZ_{\\text{rot}} &= \\text{tr} \\ e^{-\\beta H_{\\text{rot}}} \\\\\n&= \\sum_{\\ell=0}^\\infty \\sum_{m=-\\ell}^\\ell \\exp\\bigg(-\\frac{\\beta\\hbar^2\\ell(\\ell+1)}{2I}\\bigg) \\\\\n&= \\sum_{\\ell=0}^\\infty (2\\ell+1) \\exp\\bigg(-\\frac{\\beta\\hbar^2\\ell(\\ell+1)}{2I}\\bigg) \\ .\n\\end{align*}\n\\] As sort of expected, we yet again have a partition function with no obvious closed form solution. Instead we’ll proceed as we have been by looking at things in the high and low temperature limits. In the high temperature limit the states are so close together that we can approximate the sum with an integral. Using the substitution \\(x=\\ell(\\ell+1)\\) we get \\[\n\\begin{align*}\nZ_{\\text{rot}} &\\approx \\int_0^\\infty d\\ell \\ (2\\ell+1) \\exp\\bigg(-\\frac{\\beta\\hbar^2\\ell(\\ell+1)}{2I}\\bigg) \\\\\n&\\approx \\int_0^\\infty dx \\ \\exp\\bigg(-\\frac{\\beta\\hbar^2}{2I}x\\bigg) \\\\\n&\\approx \\frac{2I}{\\hbar^2\\beta} \\ .\n\\end{align*}\n\\] From here we can read off that \\(E_{\\text{rot}} \\approx Nk_B T\\), which means \\(C\\approx Nk_B\\). That is, the rotational modes contribute exactly two degree of freedom, just as we’d expect from the equipartition theorem.\nIn the low temperature limit we’ll instead approximate the partition function with its first two terms as \\[\nZ_{\\text{rot}} \\approx 1 + 3 e^{-\\frac{\\beta\\hbar^2}{I}} \\ .\n\\] From here we can see the energy is given by \\(E_{\\text{rot}} \\approx 6Nk_B \\big(\\frac{\\hbar^2}{2Ik_B}\\big) e^{-\\hbar^2/Ik_BT}\\), and thus \\[\nC \\approx 3Nk_B \\bigg(\\frac{\\hbar^2}{Ik_BT}\\bigg)^2 e^{-\\hbar^2/Ik_BT} \\ .\n\\] Again, we see the heat capacity levels off at temperatures above some temperature \\(\\theta = \\frac{\\hbar^2}{2Ik_B}\\) and goes to zero at temperatures below \\(\\theta\\). For diatomic oxygen this temperature turns out to be about \\(\\theta \\approx 2 \\ ^\\circ \\text{K}\\). This means that for all but temperatures very near zero the rotational modes of oxygen and most substances are also activated. This explains the second part of the plot.\nLast, we have to look at the vibrational modes \\(H_{\\text{vib}} \\equiv \\frac{p^2}{2\\mu} + \\frac{1}{2}\\mu\\omega^2r^2\\). We can quickly recognize this Hamiltonian as the quantum harmonic oscillator, which we already know has discrete energy eigenvalues of the form \\(E_n = \\hbar\\omega \\big(n + \\frac{1}{2}\\big)\\). The partition function for a single particle is given by \\[\nZ_1 = \\frac{e^{-\\frac{\\beta\\hbar\\omega}{2}}}{1 - e^{-\\beta\\hbar\\omega}} \\ .\n\\] From this, we read off the energy as \\(E = \\frac{N\\hbar\\omega}{2} + \\frac{N\\hbar\\omega}{e^{\\hbar\\omega/k_B T}-1}\\), and from there calculate the heat capacity as \\[\nC = Nk_B \\bigg(\\frac{\\hbar\\omega}{k_B T}\\bigg)^2 \\frac{e^{\\hbar\\omega/k_B T}}{\\big(e^{\\hbar\\omega/k_B T}-1\\big)^2} \\ .\n\\] We’ve already seen that this heat capacity also goes to zero exponentially at low temperatures, and levels off to \\(C \\approx Nk_B\\) at high temperatures. The transition region is at a temperature \\(\\theta = \\frac{\\hbar\\omega}{k_B}\\). For diatomic oxygen this is about \\(\\theta \\approx  2256 \\ ^\\circ \\text{K}\\). This covers the last part of the plot. We’ve been able to explain each of the three transition regions by finding the heat capacity for each of the three types of modes and identifying their characteristic temperatures.\n\n\nHeat Capacity of Solids\nWe’ve thus far pretty much completely ignored solids in this course. The main reason for this is that understanding the behavior of solids tends to require a lot more quantum mechanics. Nevertheless, we can at least address one relatively simply but historically important problem dealing with solids, which is the behavior of their heat capacities. Unlike most properties of solids, we can understand their heat capacities by assuming little more than that solids are a set of particles locked in a lattice. We’ll assume in this section that a solid is merely a cubic lattice of \\(N\\) identical particles, each interacting with its nearest neighbors.\nThe first attempt to understand heat capacity of solids is to model the lattice of particles as a coupled spring system. This is known as the Boltzmann model of a solid. We suppose each particle is attached to its nearest neighbors with a spring and allowed to oscillate at the same constant frequency \\(\\omega\\). From classical mechanics, we know we can always diagonalize a system of coupled harmonic oscillators into their fundamental modes and write the Hamiltonian in decoupled form as \\[\nH = \\sum_{i=1}^{3N} \\frac{p_i^2}{2m} + \\frac{1}{2} m\\omega^2 x_i^2 \\ .\n\\] Here strictly speaking, each \\(x_i\\) and \\(p_i\\) should be thought of as generalized coordinates, but for our purposes that won’t matter. Since this Hamiltonian decouples into \\(3N\\) degrees of freedom, we can use the equipartition theorem to state the average energy in the solid is \\(E = 3Nk_B T\\). From this, we can infer the heat capacity of a solid is just \\[\nC = 3Nk_B \\ .\n\\] This is classically known as the law of Dulong-Petit. This law says the heat capacity of a solid should be constant for all \\(T\\). Indeed, it turns out to hold well at high \\(T\\). But, of course, we shouldn’t expect this to really be true at all temperatures, since the third law requires \\(C \\rightarrow 0\\) as \\(T \\rightarrow 0\\). But maybe we can fix this by again trying to quantize the harmonic oscillators.\nWe’ll now model a solid not as \\(3N\\) classical harmonic oscillators, but with \\(3N\\) quantum harmonic oscillators again all oscillating at the same constant frequency \\(\\omega\\). This is known as the Einstein model of a solid. The heat capacity is given by \\[\nC = 3Nk_B \\bigg(\\frac{\\hbar\\omega}{k_B T}\\bigg)^2 \\frac{e^{\\hbar\\omega/k_B T}}{\\big(e^{\\hbar\\omega/k_B T}-1\\big)^2} \\ .\n\\] This is the same heat capacity we saw for the vibrational modes of a diatomic gas, except with \\(3N\\) degrees of freedom instead of \\(N\\) degrees of freedom. This means in the high temperature limit \\(C \\approx 3Nk_B T\\) in accordance with the law of Dulong-Petit, while in the low temperature limit \\(C \\sim e^{-\\hbar\\omega / T}\\). So now \\(C \\rightarrow 0\\) like we’d expect. But is this right? It turns out not. Experimentally it turns out the heat capacity of a solid goes to zero like \\(C \\sim T^3\\), not like an exponential. This is illustrated in the figure below.\n\n\n\n\n\nHow can we change our model of a solid to get this cubic heat capacity behavior? We’re already using quantum mechanics. We need something more. In fact, the main thing we’re missing is that solids have sound modes. When you bang on a solid, each particle in the lattice jiggles in a wave pattern, creating sound waves that propagate through the solid at some speed. This modification of the Einstein model produces what’s known as the Debye model of a solid.\nWe can allow for sound modes by assuming the frequency \\(\\omega\\) is no longer constant, but instead has a linear dispersion relation \\[\n\\omega(\\mathbf{k}) = v |\\mathbf{k}| \\ .\n\\] Here we assume for simplicity all frequencies have the same speed of sound \\(v\\), though each direction along the lattice could have a different speed and the main results of this section won’t really change. If we again model each particle as a quantum harmonic oscillator, at each frequency we have an energy of the form \\[\nE(\\omega) = 3 \\bigg(\\frac{\\hbar\\omega}{2} + \\frac{\\hbar\\omega}{e^{\\hbar\\omega/k_B T}-1}\\bigg) \\ .\n\\] The factor of \\(3\\) can be thought of as belonging here for multiple reasons. One reason is that we’re effectively considering \\(3N\\) decoupled harmonic oscillators. Another reason is that a solid has three polarizations, two for the transverse directions of each wave and one for the longitudinal direction. To get the total energy \\(E\\) over all frequencies we can integrate over all frequencies weighted by the density of states. Rather than rewrite everything in terms of \\(\\mathbf{k}\\) let’s find an expression for \\(g(\\omega)\\). Using the dispersion relation \\(\\omega=vk\\) we can write \\[\ng(\\mathbf{k}) d^3 \\mathbf{k} = \\frac{Vn^3}{4\\pi^2} \\omega^2 d\\omega \\equiv g(\\omega) d\\omega \\ .\n\\] Note we can define a natural frequency from this expression via \\(\\omega_D^3 \\equiv 6\\pi^2 v^3 n\\) and rewrite \\(g(\\omega) = \\frac{3N\\omega^2}{\\omega_D^3}\\). This special frequency \\(\\omega_D\\) is called the Debye frequency. It turns out to be important for reasons we’ll see shortly. The total energy is thus \\[\nE = \\int d\\omega \\ g(\\omega) E(\\omega) = \\frac{9N}{\\omega_D^3} \\int d\\omega \\ \\bigg(\\frac{\\hbar\\omega^3}{2} + \\frac{\\hbar\\omega^3}{e^{\\hbar \\omega/k_B T}-1}\\bigg) \\ .\n\\] There’s still the question of what frequencies we’re allowed to integrate over. For sound waves we could in principle have wavelengths \\(\\lambda\\) as high as we like. But having small wavelengths is limited by the atomic spacing inside the lattice. Suppose each particle in the lattice is a distance \\(a\\) from its nearest neighbors, meaning \\(V=Na^3\\) or \\(na^3=1\\). Then we should expect \\(\\lambda \\sim a\\) to be about the smallest allowed wavelength for sound waves to propagate through the solid. This implies there should be some highest frequency that’s roughly around \\(\\omega^* \\sim \\frac{2\\pi v}{a}\\). In fact \\(\\omega^* = \\omega_D\\) exactly. This gives us a new interpretation of the Debye frequency. It’s the smallest allowed frequency for sound waves to propagate in the Debye model.\nRather than evaluate the above integral exactly, let’s look at the two limits. First, in the high temperature limit, we can again use the Taylor expansion \\(e^{\\hbar\\omega / k_B T} - 1 \\approx \\frac{\\hbar\\omega}{k_B T}\\) to write \\[\nE \\approx \\frac{9N}{\\omega_D^3} \\int_0^{\\omega_D} d\\omega \\ \\bigg(\\frac{\\hbar\\omega^3}{2} + \\frac{\\hbar\\omega^3}{\\hbar \\omega/k_B T}\\bigg) \\approx E_0 + 3 N k_B T \\ .\n\\] The first term \\(E_0 = \\frac{9N}{8} \\hbar\\omega_D\\) is just a constant. For all practical purposes we can ignore it. The second term we recognize. If we differentiate with respect to energy we just get the Dulong-Petit law again as expected, \\(C \\approx 3 N k_B\\).\nWhat about the low temperature limit? After all, that’s the whole reason we’re still here. In this limit we can use the fact that the integrand of the second term is a negative exponential, and hence a rapidly decaying function of \\(\\omega\\). This means for all practical purposes we can allow the upper limit to go to infinity. If we make the substitution \\(x = \\hbar \\omega / k_B T\\), we can write \\[\nE \\approx E_0 + \\frac{9N}{\\omega_D^3} \\bigg(\\frac{k_B T}{\\hbar}\\bigg)^4 \\int_0^\\infty dx \\ \\frac{x^3}{e^{x} - 1} \\ .\n\\] Now we make use of the fact that this integral over \\(x\\) is a well-known integral with value \\(\\pi^4 / 15\\). Plugging this in, we have \\[\nE \\approx E_0 + \\frac{9\\pi^4 N}{15\\omega_D^3} \\bigg(\\frac{k_B T}{\\hbar}\\bigg)^4 \\ .\n\\] What’s important here is that \\(E \\sim T^4\\), meaning when we differentiate we get \\(C \\sim T^3\\). The transition region between high and low temperature behaviors seems to occur when \\(\\hbar \\omega_D \\sim k_B T\\). This defines a characteristic temperature \\(T_D \\equiv \\frac{\\hbar \\omega_D}{k_B}\\) known as the Debye temperature that separates the behavior of the two regimes. We can then write the heat capacity at low temperatures as \\[\nC = N k_B \\frac{12\\pi^4}{5} \\bigg(\\frac{T}{T_D}\\bigg)^3 + O(T^4) \\ .\n\\] As a brief aside, it’s natural to ask if this heat capacity relationship truly holds for all solids. The answer is almost. For insulating materials this law holds just fine, but for metals it turns out the low temperature limit needs to be slightly modified to \\[\nC \\sim \\gamma T + \\alpha T^3 \\ ,\n\\] where \\(\\alpha\\) and \\(\\gamma\\) are constant with temperature. That is, the heat capacity of metals goes to zero linearly, not cubically. The reason for this essentially comes from the fact that in metals the electrons are allowed to move around freely throughout the solid, creating a composite of a solid and a Fermi gas of electrons. We’ll study this more in the next chapter on quantum gases.\n\n\nBlackbody Radiation\nPretty much all of our applications so far have been of matter. We’ve seen applications involving solids, liquids, and gases of particles that have definite mass. We’ve yet to really study the thermodynamics of light, or electromagnetic radiation. We saw that we could model the thermodynamics of light classically as an ultra-relativistic gas. Let’s now study a more interesting and historically important application to light, the problem of blackbody radiation.\nSuppose some amount of light is allowed to be emitted and absorbed inside some cavity. The particles in the walls of the cavity undergo small oscillations in the presence of the light. In equilibrium the oscillation frequencies of these particles are the same as the frequencies of radiation. Said differently, the walls glow at the same color as the light itself, where the color depends on the temperature. Our goal is to understand the behavior of the color spectrum of this light, like which colors are most likely to be emitted or absorbed at a given temperature.\nLet’s first look at the problem classically. We’ll suppose for simplicity that the cavity is a hollow cube with side lengths \\(L\\) and volume \\(V=L^3\\), though it turns out the shape of the cavity doesn’t impact the results. We’ll also assume the interior of the cavity can be treated as a vacuum with periodic boundary conditions, so we can treat the electromagnetic waves as periodic plane waves. This means the wavevector \\(\\mathbf{k}\\) is again periodic with only allowed discrete values \\(\\mathbf{k} = \\frac{2\\pi}{L} \\mathbf{n}\\). Since the particles in the wall undergo small oscillations, we can model them as harmonic oscillators with average energy \\(k_B T\\) per oscillator, and then use the condition that the walls and light are in equilibrium to state the same formulas hold for the light in the cavity as well.\nUsing the fact that each photon has an energy \\(E = \\hbar \\omega\\) we get \\[\ng(E) dE = \\frac{VE^2}{\\pi^2\\hbar^3 c^3} dE =  \\frac{V\\omega^2}{\\pi^2 c^3} d\\omega \\equiv g(\\omega) d\\omega \\ .\n\\] At equilibrium we now use our oscillator assumption to write \\(E(\\omega) d\\omega = k_B T g(\\omega)d\\omega\\). What we’re really interested in though is the energy as a function of wavelength \\(\\lambda\\). To get this, we use the fact that \\(\\lambda = \\frac{2\\pi c}{\\omega}\\) for light to write \\[\nE(\\omega) d\\omega = \\frac{Vk_B T}{\\pi^2 c^3} \\omega^2d\\omega = \\frac{2Vk_B T}{\\pi^2 c^3} \\bigg(\\frac{2\\pi c}{\\lambda}\\bigg)^2 \\bigg |-\\frac{2\\pi cd\\lambda}{\\lambda^2} \\bigg | = E(\\lambda) d\\lambda \\ .\n\\] The spectrum light is typically understood by plotting wavelength against the spectral radiance \\(I(\\lambda)\\), which is defined as the amount of energy flux per unit time per given wavelength. For light, it’s possible to show \\(I(\\lambda) = \\frac{c}{4} \\varepsilon(\\lambda)\\), where \\(\\varepsilon(\\lambda) \\equiv \\frac{E(\\lambda)}{V}\\) is the energy density. We’ve thus derived the classical formula for the radiance of blackbody radiation, called the Rayleigh-Jeans law, \\[\nI(\\lambda) = \\frac{2\\pi c k_B T}{\\lambda^4} \\ .\n\\] Let’s take a look at this expression. Remember, it’s a plot of the color spectrum of light. We should thus expect it to behave kind of like a probability density. The conservation of energy requires there to be a finite area under the curve. But if we attempt to integrate the Rayleigh-Jeans law what do we get for the total radiance? Infinity! The integral diverges as \\(\\lambda \\rightarrow 0\\). Since lower wavelengths fall on the ultraviolet side of visible light, this blowing up of the spectrum is called the ultraviolet catastrophe. Simply put, there’s no physical reason it can happen for a system with finite energy. It was already known in the 19th century via spectral measurements that the actual blackbody spectrum turns over and goes to zero as \\(\\lambda \\rightarrow 0\\) like the solid line in the figure below.\n\n\n\n\n\nIt was Planck who realized originally that we could get the correct blackbody spectrum by making use of the fact that energy be quantized in units of \\(E = \\hbar\\omega\\). As we’ve seen over and over, the way to fix things is to treat the classical harmonic oscillators quantum mechanically. Instead of assuming each particle has an average energy \\(k_B T\\), we assume each has the average energy given by a quantum harmonic oscillator, i.e. \\(\\frac{\\hbar \\omega}{2} + \\frac{\\hbar \\omega}{e^{\\hbar \\omega / k_B T} - 1}\\). Since the first term doesn’t depend on temperature it can be thought of as an added constant to the energy. If we ignore this term and focus only on the temperature dependent part, we can write \\[\nE(\\omega) d\\omega = \\frac{V\\hbar \\omega^3 / \\pi^2 c^3}{e^{\\hbar \\omega / k_B T} - 1} d\\omega = \\frac{V\\hbar / \\pi^2 c^3}{e^{2\\pi\\hbar / k_B T \\lambda} - 1} \\bigg(\\frac{2\\pi c}{\\lambda}\\bigg)^3  \\bigg |-\\frac{2\\pi cd\\lambda}{\\lambda^2} \\bigg | = E(\\lambda) d\\lambda \\ .\n\\] Plugging this expression for \\(E(\\lambda)\\) into the radiance \\(I(\\lambda) = \\frac{c}{4} \\varepsilon(\\lambda)\\) and using the relation \\(h=2\\pi\\hbar\\), we finally have \\[\n\\boxed{\nI(\\lambda) = \\frac{2\\pi hc^2}{\\lambda^5} \\frac{1}{e^{hc/k_B T \\lambda} - 1}\n} \\ .\n\\] It’s easy to see that this spectrum indeed vanishes at both limits. At small wavelengths the spectrum exponentially decays like \\(I(\\lambda) \\sim e^{-hc/k_B T\\lambda}\\), while at large wavelengths the spectrum decays like \\(I(\\lambda) \\sim \\lambda^{-4}\\) in accordance with the Rayleigh-Jeans law.\nThe spectrum evidently seems to peak at a wavelength \\(\\lambda_W\\) satisfying \\(\\frac{dI}{d\\lambda} \\big |_{\\lambda_W} = 0\\). This can be solved to give \\(\\lambda_W = \\frac{b}{T}\\), where \\(b \\approx 3 \\cdot 10^{-3} \\ ^\\circ \\text{K m}\\) in SI units. This relationship between peak wavelength and temperature is known as Wien’s displacement law. It’s this simple law that tells us which color we’re most likely to see a cavity full of radiation glow at at a given temperature.\nIf we like, we can integrate \\(E(\\omega)\\) over all frequencies and find the total energy inside the cavity. Since light can in principle take on all frequencies, we have to integrate to infinity. There is no logical frequency cutoff anymore. Lumping the non-temperature dependent piece into one integral we’ll call \\(E_0\\) and again using the substitution \\(x = \\frac{\\hbar\\omega}{k_B T}\\) and integrating, we have \\[\n\\begin{align*}\nE &= E_0 + \\frac{V\\hbar}{\\pi^2 c^3} \\int_0^\\infty d\\omega \\ \\frac{\\omega^3}{e^{\\hbar \\omega / k_B T} - 1} \\\\\n&= E_0 + \\frac{V\\hbar}{\\pi^2 c^3} \\bigg(\\frac{k_B T}{\\hbar}\\bigg)^4 \\int_0^\\infty dx \\ \\frac{x^3}{e^{x} - 1} \\\\\n&= V\\bigg[\\varepsilon_0 + \\frac{\\hbar \\pi^2}{15 c^3} \\bigg(\\frac{k_B T}{\\hbar}\\bigg)^4\\bigg] \\ .\n\\end{align*}\n\\] Here we pulled out a factor of volume at the end so we can express things in terms of the total energy density \\(\\varepsilon\\), which is more commonly done when dealing with light. It’s worth taking a minute to address the constant term \\(\\varepsilon_0\\). Had we actually done this integral, we’d realize that in fact \\(\\varepsilon_0\\) is infinite. We can hand-wave and argue that since \\(\\varepsilon_0\\) constant, and physics only cares about energy differences, we can ignore \\(\\varepsilon_0\\) and only focus on the temperature dependent part. At a deeper level, it’s fair to speculate whether this infinite energy arises from some deeper physics, e.g. the vacuum energy or cosmological constant, but at present this is a topic of ongoing research.\nIt’s typical to lump most of the constants in the second term of the previous equation into a single constant \\(\\sigma\\). This is known as the Stefan-Boltzmann constant, defined by \\[\n\\boxed{\n\\sigma \\equiv \\frac{\\pi^2 k_B^4}{60c^2 \\hbar^3} \\approx 5.67 \\cdot 10^{-8} \\ \\frac{\\text{W}}{\\text{m}^2 \\ ^\\circ \\text{K}^4}\n} \\ .\n\\] In terms of this new constant \\(\\sigma\\) we can then write \\[\n\\varepsilon = \\varepsilon_0 + \\frac{4 \\sigma}{c} T^4 \\ .\n\\] The most important thing to notice for our purposes though is that the energy density relates to temperature as \\(\\varepsilon \\propto T^4\\). Since energy density and energy flux are proportional, we have \\[\nI = \\sigma T^4 \\ .\n\\] This statement that the total radiance, i.e. the total power radiated by the blackbody, is proportional to \\(T^4\\) is known as the Stefan-Boltzmann law. Last, it’s possible to use the partition function for this system to show that the radiation inside the cavity also creates a pressure. In fact, that radiation pressure is simply given by \\[\nP = P_0 + \\frac{1}{3} \\varepsilon = P_0 + \\frac{4\\sigma}{c} T^4 \\ .\n\\] Here, the pressure \\(P_0\\) arises from the constant energy density \\(\\varepsilon_0\\). This means \\(P_0\\) will also be infinite. However, it turns out \\(P_0\\) does have a potential physical interpretation. It’s believed to result from the Casimir force, which arises when two conducting plates are put very close together, resulting in an attraction due to the pressure differences inside and outside the plates.\nAs academic as the problem of blackbody radiation may sound, these results turn out to be extremely useful in astrophysics. Typically in astronomy we’re very limited in what we can directly measure about a far away star or galaxy. In particular, we’re limited to observing the spectra of light being emitted by those stars. However, to an excellent approximation, it turns out stars can be well modeled as blackbodies. This means we can use measured information about their spectra to deduce other physical facts, like what their energies or pressures are.\nAs a simple example of this, it’s observed that the sun has a spectrum that peaks in the green part of the visible spectrum. Since green light occurs at wavelengths around \\(\\lambda \\approx 5.2 \\ \\mu\\text{m}\\), using Wien’s displacement law we find that the temperature at the surface of the Sun must be about \\(T \\approx 5800 \\ ^\\circ \\text{K}\\). Given the surface temperature, we can immediately find the total energy flux as well, and from that the total power radiated by the sun, which turns out to be about \\(\\mathcal{P} \\approx 3 \\cdot 10^{26} \\ \\text{W}\\). However, the predicted pressure is much lower than the true pressure observed, which is about \\(P \\approx 0.1 \\ \\text{atm}\\). This discrepancy arises from the fact that we’re ignoring other more significant contributions to the pressure, particularly the hydrostatic pressure.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Quantum Statistical Mechanics</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/quantum-gases.html",
    "href": "statistical-mechanics/quantum-gases.html",
    "title": "Quantum Gases",
    "section": "",
    "text": "Identical Particles\nRecall the distinction we made in classical statistical mechanics between distinguishable particles and identical particles. A collection of particles was distinguishable if we could label each particle and in principle tell them apart. They were identical if this wasn’t true, if there was no way even in principle to tell apart one particle from another. We found it was very easy to account for this fact in classical statistical mechanics. If \\(N\\) particles were identical, we just needed to be sure to divide the partition function by \\(N!\\) to account for all possible permutations of those particles.\nIn quantum mechanics, the nature of identical particles is baked deep into the theory itself. There’s nothing arbitrary about them, since in quantum mechanics there really is no way even in principle to label a tiny particle without changing its state. Every fundamental particle is identical. From a theoretical perspective, identical particles arise due to the exchange postulate. Consider two particles. Suppose \\(|\\psi \\rangle\\) is the state of particle one, and \\(|\\phi \\rangle\\) is the state of particle two. Then we should expect the joint state where both of these occur is given by the tensor product of the two, namely \\(|\\psi \\rangle |\\phi \\rangle \\equiv |\\psi \\rangle \\otimes |\\phi \\rangle\\). The exchange postulate states that the only tensor product states allowed for real particles are those that are eigenvectors of the exchange operator \\(P_\\sigma\\) defined by the relation \\[\nP_\\sigma |\\psi \\rangle |\\phi \\rangle \\equiv |\\phi \\rangle |\\psi \\rangle \\ .\n\\] Since exchange two particles twice gives the original state back, we must have \\(P_\\sigma^2 = 1\\), meaning its eigenvalues must be \\(\\eta \\equiv \\pm 1\\). Calling these eigenvectors \\(|\\Psi\\rangle_\\eta\\), this means \\[\nP_\\sigma |\\Psi\\rangle_\\eta = \\eta |\\Psi\\rangle_\\eta \\ .\n\\] Any tensor product state of two particles must be one of these two eigenstates. It’s easy to see that these eigenstates are just the symmetric and antisymmetric parts of the tensor product state, \\[\n\\begin{align*}\n|\\Psi\\rangle_{+} &= \\frac{1}{\\sqrt{2}} \\big(|\\psi \\rangle |\\phi \\rangle + |\\phi \\rangle |\\psi \\rangle \\big) \\ , \\\\\n|\\Psi\\rangle_{-} &= \\frac{1}{\\sqrt{2}} \\big(|\\psi \\rangle |\\phi \\rangle - |\\phi \\rangle |\\psi \\rangle \\big) \\ .\n\\end{align*}\n\\] Particles whose exchange eigenstates are \\(|\\Psi\\rangle_{+}\\) are called bosons, while particles whose exchange eigenstates are \\(|\\Psi\\rangle_{-}\\) are called fermions. Notice that fermions satisfy the important condition that both particles can never been in the same state, since then we’d have \\(|\\Psi\\rangle_{-} = 0\\), a non-normalizable state. This is a general reflection of the Pauli exclusion principle, which states that no two fermions can occupy the same state. They must always be distinct. Bosons, however, don’t have to satisfy the exclusion principle. This one distinction makes the behavior of bosons and fermions very different from each other.\nBut how do we know which of the two eigenstates a given pair of particles should have? It turns out this comes down to their spin. If each particle has integer total spin, then that particle is a boson. If each particle instead has half-integer total spin, then that particle is a fermion. This fact is consequence of the spin-statistics theorem, an important theorem of relativistic quantum field theory. We won’t bother to prove it here. Electrons are the canonical example of fermions, with spin \\(1/2\\). Photons are the canonical example of bosons, with spin \\(1\\). There are many more of each of course. In fact all particles in nature can be broken down into these two classes depending on whether they have integer or half-integer total spin.\nThis is all true for two particle systems, but in statistical mechanics we’re interested in \\(N\\)-particle systems, where \\(N\\) is typically a huge number. We’ll just state the result for \\(N\\)-particle systems of bosons or fermions without proving anything.\nLet \\(P_\\sigma\\) be the permutation operator that permutes the indexes \\(1, 2, \\cdots, N\\) to some permutation \\(\\sigma(1), \\sigma(2), \\cdots, \\sigma(N)\\). There will generally be \\(N!\\) such permutations. For a set of \\(N\\) bosons, we have \\[\n|\\Psi\\rangle_{+} = \\frac{1}{\\sqrt{N_{+}}} \\sum_\\sigma P_\\sigma | \\psi_1 \\rangle | \\psi_2 \\rangle \\cdots | \\psi_N \\rangle = \\frac{1}{\\sqrt{N_{+}}} \\sum_\\sigma | \\psi_{\\sigma(1)} \\rangle | \\psi_{\\sigma(2)} \\rangle \\cdots | \\psi_{\\sigma(N)} \\rangle \\ .\n\\] For a set of \\(N\\) fermions, we have \\[\n|\\Psi\\rangle_{-} = \\frac{1}{\\sqrt{N_{-}}} \\sum_\\sigma (-1)^{p(\\sigma)} P_\\sigma | \\psi_1 \\rangle | \\psi_2 \\rangle \\cdots | \\psi_N \\rangle = \\frac{1}{\\sqrt{N_{-}}} \\sum_\\sigma (-1)^{p(\\sigma)} | \\psi_{\\sigma(1)} \\rangle | \\psi_{\\sigma(2)} \\rangle \\cdots | \\psi_{\\sigma(N)} \\rangle \\ .\n\\] Here \\(p(\\sigma)\\) denotes the parity of the permutation \\(\\sigma\\). For even permutations \\(p(\\sigma)\\) is some even number, meaning \\((-1)^{p(\\sigma)} = 1\\). For odd permutations \\(p(\\sigma)\\) is some odd number, meaning \\((-1)^\\sigma = -1\\).\nIt’s easy to see that we can combine both equations into one by using \\(\\eta = \\pm 1\\) to write \\[\n\\boxed{\n|\\Psi\\rangle_\\eta = \\frac{1}{\\sqrt{N_\\eta}} \\sum_\\sigma \\eta^{p(\\sigma)} P_\\sigma | \\psi_1 \\rangle | \\psi_2 \\rangle \\cdots | \\psi_N \\rangle\n} \\ .\n\\] The factors \\(N_\\eta\\) are whatever normalization factors are needed so that \\(\\langle\\Psi|\\Psi\\rangle_\\eta=1\\). Intuitively, we’d expect that \\(N_\\eta = N!\\) given there are \\(N!\\) permutations. This is true for fermions provided we insist all states \\(\\psi_k\\) be unique to satisfy the exclusion principle. That is, \\(N_{-} = N!\\) for fermions, provided the sum is over distinct states only.\nHowever, for bosons taking \\(N_{+} = N!\\) would mean we’re overcounting due to the fact that some of the states in the sum are equivalent. To correct for this, we also have to divide by \\(\\prod_k n_k!\\), where \\(n_k\\) is the number of particles in state \\(\\psi_k\\). To see why this is true, take the case of 3 bosons. Symmetrizing we’d have \\[\n|\\psi_1 \\psi_2 \\psi_3 \\rangle_{+} = \\mathcal{N} \\big(|\\psi_1 \\psi_2 \\psi_3 \\rangle + |\\psi_2 \\psi_3 \\psi_1 \\rangle + |\\psi_1 \\psi_3 \\psi_2 \\rangle + |\\psi_2 \\psi_1 \\psi_3 \\rangle + |\\psi_3 \\psi_2 \\psi_1 \\rangle + |\\psi_3 \\psi_1 \\psi_2 \\rangle\\big) \\ ,\n\\] where \\(\\mathcal{N}\\) is whatever normalization constant is needed so that \\(\\langle \\psi_1 \\psi_2 \\psi_3 | \\psi_1 \\psi_2 \\psi_3 \\rangle_{+} = 1\\). In this case, it’s clear we have \\(\\mathcal{N}=\\frac{1}{\\sqrt{6}}\\). Now suppose two of the states are the same, say \\(\\psi_1=\\psi_2\\). Then the above sum reduces to \\[\n\\begin{align*}\n|\\psi_1 \\psi_1 \\psi_3 \\rangle_{+} &= \\mathcal{N} \\big(|\\psi_1 \\psi_1 \\psi_3 \\rangle + |\\psi_1 \\psi_3 \\psi_1 \\rangle + |\\psi_1 \\psi_3 \\psi_1 \\rangle + |\\psi_1 \\psi_1 \\psi_3 \\rangle + |\\psi_3 \\psi_1 \\psi_1 \\rangle + |\\psi_3 \\psi_1 \\psi_1 \\rangle\\big) \\\\\n&= 2\\mathcal{N} \\big(|\\psi_1 \\psi_1 \\psi_3 \\rangle + |\\psi_1 \\psi_3 \\psi_1 \\rangle + |\\psi_3 \\psi_1 \\psi_1 \\rangle\\big) \\\\\n&= \\frac{1}{\\sqrt{3}} \\big(|\\psi_1 \\psi_1 \\psi_3 \\rangle + |\\psi_1 \\psi_3 \\psi_1 \\rangle + |\\psi_3 \\psi_1 \\psi_1 \\rangle\\big) \\ .\n\\end{align*}\n\\] For this sum to normalize properly, we’d instead need to take \\(\\mathcal{N} = \\frac{1}{\\sqrt{12}} = \\frac{1}{\\sqrt{3!2!1!}}\\), which means \\(N_{+} = N! \\prod n_k!\\). The set \\(\\{n_k\\}\\) of all such \\(n_k\\) are called occupation numbers since they represent the number of particles that occupy a given state.\nFor bosons, each particle can occupy whichever states it likes. All we require is that the total number of bosons stay conserved. This means bosons should satisfy the constraint \\(\\sum_k n_k = N\\). We can think of occupation numbers as applying to fermions too. In that case, the exclusion principle requires each \\(n_k=0,1\\) only. They should still satisfy the constraint \\(\\sum_k n_k = N\\). This means we can streamline notation if we like and express the normalization constant in both cases by \\[\nN_\\eta \\equiv N! \\prod_k n_k! \\ .\n\\] It turns out we can even use occupation numbers to characterize the states of identical particles as well. Instead of representing \\(|\\Psi\\rangle_\\eta\\) as a combination of product states \\(| \\psi_1 \\rangle | \\psi_2 \\rangle \\cdots | \\psi_N \\rangle\\), we could represent the state \\(|\\Psi\\rangle_\\eta\\) by indicating what the occupation numbers are for each state \\(\\psi_k\\). That is, \\(|\\Psi\\rangle_\\eta = \\big|\\{n_k\\} \\big\\rangle\\).\nFor example, if all states are distinct we could represent \\(|\\psi_1 \\psi_2 \\psi_3 \\rangle_{+}\\) by the ket \\(|1,1,1 \\rangle\\). If exactly two of the three states are equal, say \\(\\psi_1=\\psi_2 \\neq \\psi_3\\) then we could represent the state by \\(|\\psi_1 \\psi_2 \\psi_3 \\rangle_{+} \\equiv |2,1 \\rangle\\). In both cases each ket sums to the total particle number. This representation of a joint state is called a Fock space representation. Fock space representations of identical particles are often nice since we avoid the need to explicitly sum over all valid permutations.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Quantum Gases</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/quantum-gases.html#quantum-ideal-gas",
    "href": "statistical-mechanics/quantum-gases.html#quantum-ideal-gas",
    "title": "Quantum Gases",
    "section": "Quantum Ideal Gas",
    "text": "Quantum Ideal Gas\nWith a discussion of identical particles out of the way we can now attempt to give a proper treatment to the quantum ideal gas. Recall in our prior treatment of the quantum ideal gas we had to assume all particles were distinguishable. In quantum mechanics this is generally forbidden, since even in principle we can’t imagine labeling any small particles without violating the uncertainty principle. We’ll now attempt to find the partition function for the quantum mechanical gas of identical particles. Since there is more subtlety involved in the quantum case than in the classical case, we’ll derive the partition function in two different representations, starting with the position representation.\n\nPosition Representation\nRather than calculate the partition function \\(Z\\) directly, we’ll start by finding the density matrix in the position representation. Recall for a single non-interacting particle in a box of volume \\(V \\gg \\lambda_T^3\\) we derived the formula \\[\n\\langle \\mathbf{x} | \\rho_1 | \\mathbf{x}' \\rangle = \\frac{1}{V} \\exp\\bigg(-\\frac{(\\mathbf{x}-\\mathbf{x}')^2}{\\lambda_T^2 / \\pi} \\bigg) \\ .\n\\] We’ll now attempt to derive a formula for the density matrix \\(\\big\\langle \\{\\mathbf{x}\\} | \\rho_1 | \\{\\mathbf{x}'\\} \\big\\rangle_\\eta\\) of \\(N\\) non-interacting particles in a box. The Hamiltonian is then \\(H = \\sum \\frac{\\mathbf{p}_i^2}{2m}\\), which again means the basis of wavevector kets \\(\\big|\\{\\mathbf{k}\\} \\big\\rangle\\) diagonalizes the \\(H\\), with \\[\nH \\big|\\{\\mathbf{k}\\} \\big\\rangle = \\sum_{i=1}^N \\frac{\\hbar^2 \\mathbf{k}_i^2}{2m} \\big|\\{\\mathbf{k}\\} \\big\\rangle \\ .\n\\] Inserting two resolutions of the identity over both \\(\\{\\mathbf{k}\\}\\) and \\(\\{\\mathbf{k}'\\}\\) and simplifying, we have \\[\n\\begin{align*}\n\\big\\langle \\{\\mathbf{x}\\} | \\rho | \\{\\mathbf{x}'\\} \\big\\rangle_\\eta &= \\sideset{}{'}\\sum_{\\{\\mathbf{k}\\}} \\sideset{}{'}\\sum_{\\{\\mathbf{k}'\\}} \\big\\langle \\{\\mathbf{x}\\} | \\{\\mathbf{k}\\} \\big\\rangle_\\eta \\ \\big\\langle\\{\\mathbf{k}\\} |\\rho| \\{\\mathbf{k}'\\} \\big\\rangle \\ \\big\\langle\\{\\mathbf{k}'\\} | \\{\\mathbf{x}'\\} \\big\\rangle_\\eta \\\\\n&= \\frac{1}{Z}\\sideset{}{'}\\sum_{\\{\\mathbf{k}\\}} \\sideset{}{'}\\sum_{\\{\\mathbf{k}'\\}} \\exp\\bigg(-\\frac{\\beta\\hbar^2}{2m} \\sum_{j=1}^N \\mathbf{k}_j^2 \\bigg) \\big\\langle \\{\\mathbf{x}\\} | \\{\\mathbf{k}\\} \\big\\rangle_\\eta \\ \\big\\langle\\{\\mathbf{k}\\} | \\{\\mathbf{k}'\\} \\big\\rangle \\ \\big\\langle\\{\\mathbf{k}'\\} | \\{\\mathbf{x}'\\} \\big\\rangle_\\eta \\\\\n&= \\frac{1}{Z}\\sideset{}{'}\\sum_{\\{\\mathbf{k}\\}} \\exp\\bigg(-\\frac{\\beta\\hbar^2}{2m} \\sum_{j=1}^N \\mathbf{k}_j^2 \\bigg) \\big\\langle \\{\\mathbf{x}\\} | \\{\\mathbf{k}\\} \\big\\rangle_\\eta \\ \\big\\langle\\{\\mathbf{k}\\} | \\{\\mathbf{x}'\\} \\big\\rangle_\\eta  \\ .\\\\\n\\end{align*}\n\\] Note the use of the restricted sum here. We’re constrained by the fact that there must be exactly \\(N\\) particles in the box, whether for fermions or bosons. To get rid of the constraint we just need to figure out how much we’re overcounting by in the sum. It turns out that overcounting factor is just \\(\\prod_{\\mathbf{k}} n_{\\mathbf{k}}! / N!\\), so we can just do the substitution \\[\n\\sideset{}{'}\\sum_{\\{\\mathbf{k}\\}} \\rightarrow \\sum_{\\{\\mathbf{k}\\}} \\frac{\\prod_{\\mathbf{k}} n_{\\mathbf{k}}!}{N!} \\ .\n\\] We also need to make sure to sum over all permutations for each term \\(\\big\\langle \\{\\mathbf{x}\\} | \\{\\mathbf{k}\\} \\big\\rangle_\\eta\\) and \\(\\big\\langle\\{\\mathbf{k}\\} | \\{\\mathbf{x}'\\} \\big\\rangle_\\eta\\). This will give a double sum over permutations with different parities \\(p\\) and \\(p'\\), contributing a normalization factor \\(N_\\eta = N! \\prod_{\\mathbf{k}} n_{\\mathbf{k}}!\\) that fortunately happens to cancel the \\(\\prod_{\\mathbf{k}} n_{\\mathbf{k}}!\\) prefactor from the constrained sum, \\[\n\\begin{align*}\n\\big\\langle \\{\\mathbf{x}\\} | \\rho | \\{\\mathbf{x}'\\} \\big\\rangle_\\eta &= \\frac{1}{Z}\\sum_{\\{\\mathbf{k}\\}} \\frac{\\prod_{\\mathbf{k}} n_{\\mathbf{k}}!}{N!} \\exp\\bigg(-\\frac{\\beta\\hbar^2}{2m} \\sum_{j=1}^N \\mathbf{k}_j^2 \\bigg) \\big\\langle \\{\\mathbf{x}\\} | \\{\\mathbf{k}\\} \\big\\rangle_\\eta \\ \\big\\langle\\{\\mathbf{k}\\} | \\{\\mathbf{x}'\\} \\big\\rangle_\\eta \\\\\n&= \\frac{1}{Z}\\sum_{\\{\\mathbf{k}\\}} \\frac{\\prod_{\\mathbf{k}} n_{\\mathbf{k}}!}{N!} \\exp\\bigg(-\\frac{\\beta\\hbar^2}{2m} \\sum_{j=1}^N \\mathbf{k}_j^2 \\bigg) \\sum_{\\sigma,\\sigma'} \\frac{\\eta^p \\eta^{p'}}{N! \\prod_{\\mathbf{k}} n_{\\mathbf{k}}!} \\big\\langle \\{\\mathbf{x}\\} | P_\\sigma \\{\\mathbf{k}\\} \\big\\rangle \\ \\big\\langle P_{\\sigma'} \\{\\mathbf{k}\\} | \\{\\mathbf{x}'\\} \\big\\rangle \\\\\n&= \\frac{1}{Z(N!)^2} \\sum_{\\sigma,\\sigma'} \\eta^p \\eta^{p'} \\sum_{\\{\\mathbf{k}\\}} \\exp\\bigg(-\\frac{\\beta\\hbar^2}{2m} \\sum_{j=1}^N \\mathbf{k}_j^2 \\bigg) \\big\\langle \\{\\mathbf{x}\\} | P_\\sigma \\{\\mathbf{k}\\} \\big\\rangle \\ \\big\\langle P_{\\sigma'} \\{\\mathbf{k}\\} | \\{\\mathbf{x}'\\} \\big\\rangle \\ .\\\\\n\\end{align*}\n\\] We’ll now use the usual density of states approximation for the sums over all \\(\\{\\mathbf{k}\\}\\). This of course assumes \\(V \\gg \\lambda_T^3\\) so that particle quantum interactions are relatively weak. Replacing the sum by an integral, and using the fact that \\(\\big\\langle \\{\\mathbf{x}\\} | P_\\sigma \\{\\mathbf{k}\\} \\big\\rangle\\) is just the Fourier transform weighting factor in \\(3N\\) dimensions, we have \\[\n\\big\\langle \\{\\mathbf{x}\\} | \\rho | \\{\\mathbf{x}'\\} \\big\\rangle_\\eta\n\\approx \\frac{1}{Z(N!)^2} \\sum_{\\sigma,\\sigma'} \\eta^p \\eta^{p'} \\int \\frac{d^{3N}\\mathbf{k}}{(2\\pi)^{3N}} \\exp\\bigg[\\sum_{j=1}^N \\bigg(-\\frac{\\beta\\hbar^2}{2m}\\mathbf{k}_j^2 + i\\big(\\mathbf{k}_{\\sigma(j)} \\cdot \\mathbf{x}_j - \\mathbf{k}_{\\sigma'(j)} \\cdot \\mathbf{x}'_j\\big) \\bigg)\\bigg] \\ .\n\\] This integral seems like another Gaussian integral, but we have to be careful here since the integration variables are over \\(\\{\\mathbf{k}\\}\\) and not \\(P_\\sigma \\{\\mathbf{k}\\}\\) or \\(P_{\\sigma'} \\{\\mathbf{k}\\}\\). We can move the permutations onto the position vectors instead by simply inverting them to get \\[\n\\begin{align*}\n\\big\\langle \\{\\mathbf{x}\\} | \\rho | \\{\\mathbf{x}'\\} \\big\\rangle_\\eta\n&= \\frac{1}{Z(N!)^2} \\sum_{\\sigma,\\sigma'} \\eta^p \\eta^{p'} \\int \\frac{d^{3N}\\mathbf{k}}{(2\\pi)^{3N}} \\ \\exp\\bigg[\\sum_{j=1}^N \\bigg(-\\frac{\\beta\\hbar^2}{2m}\\mathbf{k}_j^2 + i\\big(\\mathbf{k}_j \\cdot \\mathbf{x}_{\\sigma^{-1}(j)} - \\mathbf{k}_j \\cdot \\mathbf{x}'_{\\sigma'^{-1}(j)}\\big) \\bigg)\\bigg] \\\\\n&= \\frac{1}{Z(N!)^2} \\sum_{\\sigma,\\sigma'} \\eta^p \\eta^{p'} \\prod_{j=1}^N \\int \\frac{d^{3}\\mathbf{k}_j}{(2\\pi)^{3N}} \\ \\exp\\bigg[-\\frac{\\beta\\hbar^2}{2m}\\mathbf{k}_j^2 + i \\mathbf{k}_j \\cdot \\big(\\mathbf{x}_{\\sigma^{-1}(j)} - \\mathbf{x}'_{\\sigma'^{-1}(j)}\\big)\\bigg] \\\\\n&= \\frac{1}{Z(N!)^2} \\sum_{\\sigma,\\sigma'} \\eta^p \\eta^{p'} \\prod_{j=1}^N \\bigg(\\frac{1}{\\lambda_T^3} \\exp\\bigg[-\\frac{(\\mathbf{x}_{\\sigma^{-1}(j)} - \\mathbf{x}'_{\\sigma'^{-1}(j)})^2}{\\lambda_T^2/\\pi}\\bigg] \\bigg) \\ .\n\\end{align*}\n\\] Now, we can use the fact that the two permutations are now redundant by rewriting the double sum as a free sum over all \\(N!\\) permutations plus a sum over the relative permutations \\(Q \\equiv P'^{-1}P\\) to get \\[\n\\big\\langle \\{\\mathbf{x}\\} | \\rho | \\{\\mathbf{x}'\\} \\big\\rangle_\\eta = \\frac{1}{ZN!\\lambda_T^{3N}} \\sum_\\tau \\eta^q \\exp\\bigg[-\\sum_{j=1}^N\\frac{(\\mathbf{x}_j - \\mathbf{x}'_{\\tau(j)})^2}{\\lambda_T^2/\\pi}\\bigg] \\ .\n\\] Finally, to get the partition function, we can use the relation \\(\\text{tr } \\rho = 1\\) and solve for \\(Z\\) by integrating over all \\(\\{\\mathbf{x}\\}\\) to get \\[\n\\boxed{\nZ = \\frac{1}{N!\\lambda_T^{3N}} \\int d^{3N} \\mathbf{x} \\ \\sum_\\tau \\eta^q \\exp\\bigg[-\\sum_{j=1}^N\\frac{(\\mathbf{x}_j - \\mathbf{x}_{\\tau(j)})^2}{\\lambda_T^2/\\pi}\\bigg]\n} \\ .\n\\] It’s hard to parse what this is saying as is. To make it easier to analyze let’s write out the permutations in order of increasing parity. The zero-parity term involves no permutations at all, that is \\(Q=1\\). In that case the exponential vanishes to give \\(V^N\\), which implies \\(Z \\approx \\frac{1}{N!} \\big(\\frac{V}{\\lambda_T^3})^N\\). This is just the partition function for the classical ideal gas. We can also see right off where that \\(N!\\) term for identical particles came from in classical statistical mechanics. It falls right out of the quantum theory.\nThe next permutations involve one-parity terms of pairwise swaps. In this case, all but two of the exponentials vanish, giving a factor of \\(V^{N-2}\\). The remaining two terms we can convert to relative coordinates and integrate out another factor of \\(V\\). Since there are \\(\\binom{N}{2} = \\frac{N(N-1)}{2}\\) such terms, we get \\[\nZ \\approx \\frac{V^N}{N!\\lambda_T^{3N}} \\bigg(1 + \\frac{N^2}{2V} \\int d^3 \\boldsymbol{x} \\ \\eta e^{- 2\\pi r^2 / \\lambda_T^2} \\bigg) \\approx \\frac{V^N}{N!\\lambda_T^{3N}} \\bigg[1 + \\frac{\\eta N^2}{2V} \\bigg(\\frac{\\lambda_T^2}{2}\\bigg)^{3/2} + O\\bigg(\\frac{N^3}{V^2}\\bigg)\\bigg] \\ .\n\\] To see what’s going on let’s calculate the pressure. Letting \\(n=\\frac{N}{V}\\) be the density, the expression for \\(\\beta P\\) is evidently \\[\n\\beta P = \\frac{\\partial \\log Z}{\\partial V} = n - \\frac{\\eta}{2} \\bigg(\\frac{\\lambda_T^2}{2}\\bigg)^{3/2} n^2 + O(n^3) \\ .\n\\] This is clearly a virial expansion in terms of some kind of interaction potential \\(u(r)\\). The second virial coefficient in this case is \\[\nB_2(T) = -\\frac{\\eta}{2} \\bigg(\\frac{\\lambda_T^2}{2}\\bigg)^{3/2} \\ .\n\\] For bosons this coefficient is negative, meaning the pressure is reduced from that of the classical ideal gas due to bosonic attraction. For fermions the opposite is true, meaning the pressure is increased due to fermionic repulsion. As \\(T\\) increases these effects become less and less important since \\(\\lambda_T \\rightarrow 0\\), becoming essentially negligible in the classical limit.\nNow, recall from our discussion of classically interacting gases that virial expansions can be thought of as arising from a cluster expansion in terms of powers of the Mayer f-function \\(f(r) \\equiv e^{-\\beta u(r)}-1\\). This means we can think of the above expansion as arising from the presence of an effective potential \\(u(r) = -k_B T \\log (1 + f(r))\\). In our case we can read off from the expansion for \\(Z\\) that \\(f(r) = e^{-2\\pi r^2 / \\lambda_T^2}\\), hence we have \\[\nu(r) \\approx - k_B T \\log\\big( 1 + \\eta e^{-2\\pi r^2 / \\lambda_T^2}\\big) \\ .\n\\] This effective potential \\(u(r)\\) arises purely from the quantum mechanical behavior of identical particles, even if we assume they’re completely non-interacting as we would for the ideal gas. If we plot \\(u(r)\\) for \\(\\eta = \\pm 1\\) we get two potential curves like the ones shown in the following figure.\n\n\n\n\n\nFor fermions, \\(u(r)\\) goes to zero exponentially fast as \\(r \\rightarrow \\infty\\) and blows up as \\(r \\rightarrow 0\\). This reflects the exclusion principle, which essentially forbids fermions from getting too close to each other. As the particles get farther apart this fermionic repulsion dies off exponentially fast.\nFor bosons, \\(u(r)\\) still dies off exponentially fast as \\(r \\rightarrow \\infty\\), except now from below due to the attractive nature of bosons. Instead of blowing up as \\(r \\rightarrow 0\\) we instead get a finite value of \\(u(0) \\approx -k_B T \\log 2\\). The shape of this curve represents the fact that bosons prefer to be in the same state, yet they only feel this effect when very close to each other.\nOf course, this only a valid potential when the density is sufficiently small. For denser gases we’d need to include higher order corrections arising from multi-body quantum exchange interactions. This further complicates what the potential for identical particles looks like, but the rough idea is basically the same. Qualitatively speaking, bosons attract, while fermions repel.\n\n\nEnergy Representation\nWhile insightful, it’s pretty clear that the position representation is an unnatural way to compute the partition function for an ideal gas. We’ve already seen that the natural basis for this is the basis of wavevector states \\(|\\{\\mathbf{k}\\}\\rangle\\). In this basis, we have\n\\[\nZ = \\text{tr} \\ e^{-\\beta H} = \\sideset{}{'}\\sum_{\\{\\mathbf{k}\\}} \\langle \\{\\mathbf{k}\\} | e^{-\\beta \\sum_{i=1}^N \\varepsilon_{\\mathbf{k}_i}} | \\{\\mathbf{k}\\} \\rangle_\\eta \\ ,\n\\]\nwhere we’ve introduced the shorthand \\(\\varepsilon_\\mathbf{k}\\) to refer to the energy eigenvalue of a given particle with wavevector \\(\\mathbf{k}\\). In the usual case of an ideal non-relativistic particle in a box, we’d have \\(\\varepsilon_\\mathbf{k} = \\frac{\\hbar^2 \\mathbf{k}^2}{2m}\\). But in other cases it may differ. For example, we could also be describing a gas of ultra-relativistic particles in a box, where we’d have \\(\\varepsilon_\\mathbf{k} = \\hbar c |\\mathbf{k}|\\).\nAgain we’re dealing with a constrained sum due to the requirement that \\(N = \\sum n_\\mathbf{k}\\). Rather than write out the permutations explicitly as we did before, let’s instead work in Fock space this time by setting \\(| \\{\\mathbf{k}\\} \\rangle_\\eta = | \\{n_\\mathbf{k}\\} \\rangle\\). We then have \\[\nZ = \\sideset{}{'}\\sum_{\\{n_\\mathbf{k}\\}} \\langle \\{n_\\mathbf{k}\\} | e^{-\\beta \\sum_\\mathbf{k} n_\\mathbf{k} \\varepsilon_\\mathbf{k}} | \\{n_\\mathbf{k}\\} \\rangle = \\sideset{}{'}\\sum_{\\{n_\\mathbf{k}\\}} e^{-\\beta \\sum_\\mathbf{k} n_\\mathbf{k} \\varepsilon_\\mathbf{k}} \\ .\n\\] Of course, we still haven’t removed the constraint. To do that we’ll use a trick we’ve seen before. Namely, we’ll switch to the grand canonical formulation where \\(N\\) is allowed to take on any positive integer. Doing that removes the constraint, giving \\[\n\\mathcal{Z} = \\sum_{N=0}^\\infty e^{\\beta\\mu N} Z = \\sum_{\\{n_\\mathbf{k}\\}} e^{\\beta\\mu \\sum_\\mathbf{k} n_\\mathbf{k}} e^{-\\beta \\sum_\\mathbf{k} n_\\mathbf{k} \\varepsilon_\\mathbf{k}} = \\prod_\\mathbf{k} \\sum_{n_\\mathbf{k}} e^{-\\beta n_\\mathbf{k}\\big(\\varepsilon_\\mathbf{k} - \\mu\\big)} \\ .\n\\] Now, to do the sum over \\(n_\\mathbf{k}\\) we have to distinguish between the case for bosons and fermions. For fermions \\(n_\\mathbf{k}=0,1\\), which means we’re just summing two terms. For bosons \\(n_\\mathbf{k}=0,1,\\cdots\\), which gives a geometric series. We can combine both expressions into one by writing \\[\n\\mathcal{Z}_\\eta = \\prod_\\mathbf{k} \\bigg(1 + \\eta e^{-\\beta \\big(\\varepsilon_\\mathbf{k} - \\mu\\big)}\\bigg)^{-\\eta} \\ .\n\\] This means the log grand partition function is given by \\[\n\\log\\mathcal{Z}_\\eta = -\\eta \\sum_{\\mathbf{k}} \\log \\bigg(1 + \\eta e^{-\\beta \\big(\\varepsilon_\\mathbf{k} - \\mu\\big)}\\bigg) \\ .\n\\]\n\n\nQuantum Distributions\nAs is typical with the grand canonical formulation, one of the first things we want to do is calculate \\(N\\). Since the sum over all occupation numbers must equal \\(N\\), we have \\[\nN = \\frac{\\partial \\log\\mathcal{Z}_\\eta}{\\partial (\\beta\\mu)} = -\\eta \\sum_{\\mathbf{k}} \\frac{\\partial}{\\partial(\\beta\\mu)} \\log \\bigg(1 + \\eta e^{-\\beta \\big(\\varepsilon_\\mathbf{k} - \\mu\\big)}\\bigg)  = \\sum_{\\mathbf{k}} \\frac{1}{e^{\\beta(\\varepsilon_\\mathbf{k}-\\mu)} - \\eta} = \\sum_{\\mathbf{k}} \\langle n_\\mathbf{k} \\rangle \\ .\n\\] Evidently then, the mean occupation numbers are given by the formula \\[\n\\boxed{\n\\langle n_\\mathbf{k} \\rangle = \\frac{1}{e^{\\beta(\\varepsilon_\\mathbf{k}-\\mu)} - \\eta}\n} \\ .\n\\] This formula defines two distributions describing how many particles we can expect to occupy a given state when those particles are identical. For bosons this distribution is called the Bose-Einstein distribution, given by \\[\n\\langle n_\\mathbf{k} \\rangle = \\frac{1}{e^{\\beta(\\varepsilon_\\mathbf{k}-\\mu)} - 1} \\ ,\n\\] while for fermions the distribution is called the Fermi-Dirac distribution, given by \\[\n\\langle n_\\mathbf{k} \\rangle = \\frac{1}{e^{\\beta(\\varepsilon_\\mathbf{k}-\\mu)} + 1} \\ .\n\\] In the dilute limit we expect each \\(\\langle n \\rangle \\ll 1\\), which means \\(e^{\\beta(\\varepsilon_\\mathbf{k}-\\mu)} \\gg 1\\). In that limit, both distributions reduce to the classical distribution we expect for a particle of energy \\(\\varepsilon_\\mathbf{k}\\), namely the Maxwell-Boltzmann distribution given by \\[\n\\langle n_\\mathbf{k} \\rangle = e^{-\\beta(\\varepsilon_\\mathbf{k}-\\mu)} \\ .\n\\] We have seen how the Maxwell-Boltzmann distribution behaves already when we studied classical statistical mechanics. In the next few sections we’ll focus on the study of the Fermi-Dirac and Bose-Einstein distributions and their implications.\n\n\nEquations of State\nNow that we have the partition function we can proceed to calculate the equations of state for the quantum ideal gas. We’ll again assume that \\(V \\gg \\lambda_T^3\\) so that we can use the density of states to rewrite the log partition function as \\[\n\\log\\mathcal{Z}_\\eta \\approx -\\eta\\frac{g V}{(2\\pi)^3} \\int d^3 \\mathbf{k} \\  \\log \\bigg(1 + \\eta e^{-\\beta \\big(\\varepsilon_\\mathbf{k} - \\mu\\big)}\\bigg) \\ .\n\\]\nNotice we’ve now introduced a factor \\(g\\) in the density of state conversion. This constant is there to reflect the fact that at the quantum level particles also contain a spin state \\(s\\), which gives an extra \\(g=s(s+1)\\) degeneracy to each state. For example, for spin-half fermions like electrons we’d have \\(s=\\frac{1}{2}\\) and hence \\(g=2\\).\nFrom here on we’ll again assume the energy states \\(\\varepsilon_\\mathbf{k}\\) are those for the particle in the box, \\(\\varepsilon_\\mathbf{k} = \\frac{\\hbar^2\\mathbf{k}^2}{2m}\\). Let’s first calculate the expected particle number \\(N\\), or more conveniently the number density \\(n \\approx \\frac{N}{V}\\). Plugging in this choice of \\(\\varepsilon_\\mathbf{k}\\) and using the density of states conversion along with the fact that the integral is spherically symmetric, we have \\[\nn = \\frac{1}{V} \\sum_{\\mathbf{k}} \\langle n_\\mathbf{k} \\rangle\n\\approx \\frac{g}{(2\\pi)^3} \\int_0^\\infty 4\\pi k^2 dk \\ \\frac{1}{e^{-\\beta\\mu} e^{\\beta\\frac{\\hbar^2 k^2}{2m}} - \\eta} \\ .\n\\] Here it benefits to perform a change of variables. First we’ll reintroduce the fugacity \\(z \\equiv e^{\\beta\\mu}\\) to provide a more convenient variable to tune than the chemical potential \\(\\mu\\). Next we’ll use thermal deBroglie wavelength \\(\\lambda_T = \\frac{h}{(2\\pi m k_B T)^{1/2}}\\) to rewrite the expression \\(\\frac{\\beta\\hbar^2}{m} = \\frac{\\lambda_T^2}{2\\pi}\\). Last, we’ll define a change of variable from \\(k\\) to a new variable \\(x\\) defined by \\[\nx \\equiv \\frac{\\beta\\hbar^2}{2m} k^2 = \\frac{\\lambda_T^2}{4\\pi} k^2 \\quad \\Longrightarrow \\quad\n\\begin{cases}\nk = \\frac{2\\pi^{1/2}}{\\lambda_T} x^{1/2} \\\\\ndk = \\frac{\\pi^{1/2}}{\\lambda_T} x^{-1/2} dx \\\\\n\\end{cases} \\ .\n\\] Plugging each of these expressions back into the integral and simplifying, we get \\[\nn = \\frac{g}{(2\\pi)^3} \\frac{(2\\pi^{1/2})^5}{2\\lambda_T^3} \\int_0^\\infty dx \\ \\frac{x^{1/2}}{z^{-1} e^{x} - \\eta} = \\frac{g}{\\lambda_T^3} \\frac{1}{(1/2)!} \\int_0^\\infty dx \\ \\frac{x^{1/2}}{z^{-1} e^{x} - \\eta} \\ .\n\\] Here we used the fact that \\((1/2)! = \\sqrt{\\pi}/2\\) for reasons we’ll understand shortly. Let’s now calculate the energy \\(E\\), or more conveniently \\(\\beta\\varepsilon\\), where the energy density \\(\\varepsilon \\equiv \\frac{E}{V}\\), using a similar method. Using the same definitions, we have \\[\n\\begin{align*}\n\\beta\\varepsilon &= \\frac{\\beta}{V} \\sum_{\\mathbf{k}} \\varepsilon_\\mathbf{k} \\langle n_\\mathbf{k} \\rangle \\\\\n&\\approx \\beta\\frac{g}{(2\\pi)^3} \\int_0^\\infty 4\\pi k^2 dk \\ \\frac{\\frac{\\hbar^2 k^2}{2m}}{e^{-\\beta\\mu} e^{\\beta\\frac{\\hbar^2 k^2}{2m}} - \\eta} \\\\\n&= \\frac{g}{(2\\pi)^3} \\frac{(2\\pi^{1/2})^3}{2\\lambda_T^3} \\int_0^\\infty dx \\ \\frac{x^{3/2}}{z^{-1} e^{x} - \\eta} \\\\\n&= \\frac{3}{2} \\frac{g}{\\lambda_T^3} \\frac{1}{(3/2)!} \\int_0^\\infty dx \\ \\frac{x^{3/2}}{z^{-1} e^{x} - \\eta} \\ .\n\\end{align*}\n\\]\nFinally, let’s calculate the pressure, or really \\(\\beta P\\) again for simplicity. Recall by extensivity that we can write \\(\\log \\mathcal{Z} = \\beta P V\\). Thus, \\[\n\\begin{align*}\n\\beta P &= \\frac{1}{V} \\log\\mathcal{Z} \\\\\n&\\approx \\frac{-\\eta g}{(2\\pi)^3} \\int d^3 \\mathbf{k} \\  \\log \\bigg(1 + \\eta e^{-\\beta \\big(\\varepsilon_\\mathbf{k} - \\mu\\big)}\\bigg) \\\\\n&= \\frac{-\\eta g}{(2\\pi)^3} \\int_0^\\infty 4\\pi k^2 dk \\  \\log \\bigg(1 + \\eta z e^{-\\frac{\\beta\\hbar^2 k^2}{2m}}\\bigg) \\\\\n&= \\frac{-\\eta g}{(2\\pi)^3} \\frac{(2\\pi^{1/2})^5}{2\\lambda_T^3} \\int_0^\\infty dx \\ x^{1/2} \\log \\bigg(1 + \\eta z e^{-x}\\bigg) \\\\\n&= \\frac{g}{\\lambda_T^3} \\frac{1}{(3/2)!} \\int_0^\\infty dx \\ \\frac{x^{3/2}}{z^{-1} e^x - \\eta} \\ .\n\\end{align*}\n\\] In the last line we used integration by parts to move the derivative from \\(\\log \\big(1 + \\eta z e^{-x}\\big)\\) to \\(x^{1/2}\\) and made use of the fact that the boundary terms vanish. The reason we did this was to show how all of the above expressions involve an integral that more or less looks alike apart from some parameter. Let’s give this class of integrals a name by defining \\[\n\\boxed{\nf_s^\\eta (z) \\equiv \\frac{1}{(s-1)!} \\int_0^\\infty dx \\ \\frac{x^{s-1}}{z^{-1} e^x - \\eta}\n} \\ .\n\\] We’ll study the properties of these functions in the next section. For now just observe that if we make this substitution, we can simplify the above expressions by writing \\[\n\\boxed{\n\\begin{align*}\nn &= \\frac{g}{\\lambda_T^3} f_{3/2}^\\eta(z) \\\\\n\\beta \\varepsilon &= \\frac{3}{2} \\frac{g}{\\lambda_T^3} f_{5/2}^\\eta(z) \\\\\n\\beta P &= \\frac{g}{\\lambda_T^3} f_{5/2}^\\eta(z) \\\\\n\\end{align*}\n} \\ .\n\\] We can immediately read off the important relation \\(\\varepsilon = \\frac{3}{2} P\\), which just says \\(E = \\frac{3}{2} PV\\). We’ve seen this before for the classical ideal gas. Evidently the relationship holds for the quantum ideal gas as well, both for fermions and bosons. However, the relation between \\(P\\) and \\(n\\) is no longer as straightforward as it was in the classical case. To figure that relationship out we’ll need to get a series expansion for \\(f_s^\\eta(z)\\) so we can express \\(z\\) as a function of \\(n\\) and hence get a virial expansion of \\(P\\) as a function of \\(n\\).\n\n\nSpecial Functions\nGiven these special functions \\(f_s^\\eta(z)\\) seem to occur so frequently in quantum statistics, perhaps we should study their properties a little bit before proceeding to a more detailed study of the quantum ideal gas. These special functions are a well-known class of mathematical functions known as polylogarithms. They’re a generalization of yet another class of special functions called zeta functions. Zeta functions, denoted \\(\\zeta_s\\) are defined by the arithmetic series expression \\[\n\\zeta_s \\equiv \\sum_{n=1}^\\infty \\frac{1}{n^s} = 1 + \\frac{1}{2^s} + \\frac{1}{3^s} + \\cdots \\ .\n\\] For real-valued \\(s\\), zeta functions converge whenever \\(s &gt; 1\\) and diverge otherwise. However, even when these functions do converge we can’t generally find \\(\\zeta_s\\) in closed form for most values of \\(s\\). In fact we only have closed-form expressions for even integer values of \\(s\\). For example, it’s known that \\(\\zeta_2 = \\frac{\\pi^2}{6}\\) and \\(\\zeta_4 = \\frac{\\pi^4}{90}\\). Even \\(\\zeta_3 \\approx 1.202\\) doesn’t have a closed-form expression and has to be found numerically. It’s evidently a new irrational number now known as Apery’s constant.\nPolylogarithms, usually denoted \\(\\text{Li}_s(z)\\), generalize zeta functions by turning them into a power series in some variable \\(z\\), \\[\n\\text{Li}_s(z) \\equiv \\sum_{n=1}^\\infty \\frac{z^n}{n^s} = z + \\frac{z^2}{2^s} + \\frac{z^3}{3^s} + \\cdots \\ .\n\\] Evidently when \\(z=1\\) we just get back the zeta functions, i.e. \\(\\text{Li}_s(1) = \\zeta_s\\). Polylogarithms only converge in general when \\(|z| &lt; 1\\), though they can be analytically continued to cover almost all of real \\(z\\). When \\(z &gt; 0\\) the functions asymptote at \\(z=1\\) when \\(s \\leq 1\\), otherwise they meet the \\(z=1\\) line at some finite value, which is of course \\(\\zeta_s\\). Here’s a plot of the polylogarithms for a few different values of \\(s\\). The curves for \\(s=0,\\frac{1}{2},1\\) go to infinity at \\(z=1\\), while those for \\(s=\\frac{3}{2},2,\\frac{5}{2}\\) are finite-valued at \\(z=1\\).\n\n\n\n\n\nSince there’s no constant term in the series it evidently must be the case that \\(\\text{Li}_s(0)=0\\). Moreover, when \\(z\\) is small we must have \\(\\text{Li}_s(z) \\approx z\\), which as we’ll soon see turns out to be important to us.\nThe name “polylogarithm” comes from the fact that the functions satisfy the differentiation ladder relationship \\[\n\\frac{d}{dz} \\text{Li}_s(z) = \\frac{\\text{Li}_{s-1}(z)}{z} \\ ,\n\\] which combined with the fact that \\(\\text{Li}_1(z) = -\\log (1-z)\\) implies that when \\(s\\) is an integer these functions are just successive derivatives of logarithms. This ladder relation gives us an easy way to find other values of \\(\\text{Li}_s(z)\\) provided we know the functional form for some \\(s\\), though it only works for finding integer steps of \\(s\\).\nPerhaps most importantly for our purposes, polylogarithms can be re-expressed in an integral form that we’ll recognize. Observe that by using the expression for a geometric series plus the integral representation of the factorial function that we can rewrite the polylogarithm as \\[\n\\begin{align*}\n\\text{Li}_s(z) &= \\sum_{n=1}^\\infty \\frac{z^n}{n^s} \\\\\n&= \\sum_{n=1}^\\infty \\frac{z^n}{(s-1)!} \\frac{(s-1)!}{n^s}\\\\\n&= \\sum_{n=1}^\\infty \\frac{z^n}{(s-1)!} \\int_0^{\\infty} dx \\ x^{s-1} e^{-nx} \\\\\n&= \\frac{1}{(s-1)!} \\int_0^{\\infty} dx \\ x^{s-1} \\sum_{n=1}^\\infty \\big(z e^{-x}\\big)^n \\\\\n&= \\frac{1}{(s-1)!} \\int_0^{\\infty} dx \\ \\frac{x^{s-1}}{z^{-1} e^x - 1} \\ .\n\\end{align*}\n\\] Note this also means we instantly have an integral expression for the zeta function as well by setting \\(z=1\\), \\[\n\\zeta_s = \\frac{1}{(s-1)!} \\int_0^{\\infty} dx \\ \\frac{x^{s-1}}{e^x - 1} \\ .\n\\] Evidently the integral form for \\(\\text{Li}_s(z)\\) is just the expression for \\(f_s^\\eta(z)\\) that we saw before when \\(\\eta = 1\\)! That is, \\(f_s^{+}(s) = \\text{Li}_s(z)\\) exactly. What about when \\(\\eta = -1\\) though? We can get a similar relationship by just replacing \\(z\\) with \\(-z\\) in the series to get \\(\\text{Li}_s(z)=-\\text{Li}_s(-z)\\). We can combine the two expressions into one by writing \\[\nf_s^\\eta(z) = \\eta \\text{Li}_s(\\eta z) = \\sum_{n=1}^\\infty \\frac{\\eta^{n+1} z^n}{n^s} = z + \\frac{\\eta z^2}{2^s} + \\frac{z^3}{3^s} + \\frac{\\eta z^4}{4^s} + \\cdots \\ .\n\\] That is, the functions \\(f_s^\\eta(z)\\) we’re seeing fall out of quantum statistics are just polylogarithms, with the caveat that when \\(\\eta=-1\\) the series is alternating on even powers. This alternating behavior for \\(\\eta=-1\\) means that those functions turn out to be defined for all \\(z\\), not just when \\(|z| &lt; 1\\). In fact, we’ll see later that \\(f_s^{-}(z) \\sim \\frac{1}{s!} (\\log z)^s\\) when \\(z\\) is really large.\n\n\n\n\n\nIn either case, we can see that \\(f_s^\\eta(z) \\approx z\\) when \\(z\\) is small. Treating \\(z\\) as the fugacity, \\(z\\) will be small at high temperatures, meaning in the high temperature limit our equation of state becomes \\(\\beta P \\approx n\\). This expression is of course none other the classical ideal gas law \\(PV = N k_B T\\). Evidently the quantum ideal gases reduces to the classical ideal gas in the high temperature limit, as we’d expect, both for fermions as well as bosons. The distinction between the two types of particles washes out in a sense with higher temperatures.\nBut what about at lower temperatures? First let’s define \\(d \\equiv \\frac{n \\lambda_T^3}{g}\\), which we’ll call the degeneracy factor for reasons we’ll see later. If we again want pressure as a function of density we’d need to invert the power series for \\(d = d(z)\\) to find \\(z = z(d)\\). We’ve seen before how to systematically do this. Starting with the power series for \\(d = f_{3/2}^\\eta (z)\\) we have \\[\nd = z + \\frac{\\eta z^2}{2^{3/2}} + \\frac{z^3}{3^{3/2}} + O(z^4) \\ .\n\\] Now suppose \\(z\\) can be expanded in a power series in \\(d\\) as \\[\nz = a_1 d + a_2 d^2 + a_3 d^3 + O(d^4) \\ .\n\\] When \\(z\\) is infinitesimal we see \\(d \\approx z\\), which means \\(a_1 = 1\\). To get the higher order coefficients we’ll substitute this expression into the formula for \\(d=d(z)\\) and match powers. We have \\[\n\\begin{align*}\nd &= \\big(d + a_2 d^2 + a_3 d^3\\big) + \\frac{\\eta}{2^{3/2}} \\big(d + a_2 d^2 + a_3 d^3\\big)^2 + \\frac{1}{3^{3/2}} \\big(d + a_2 d^2 + a_3 d^3\\big)^3 + O(d^4) \\\\\n&= \\big(d + a_2 d^2 + a_3 d^3\\big) + \\frac{\\eta}{2^{3/2}} (d^2 + 2 a_2 d^3) + \\frac{1}{3^{3/2}} d^3 + O(d^4) \\\\\n&= d + \\bigg(a_2 + \\frac{\\eta}{2^{3/2}}\\bigg) d^2 + \\bigg(a_3 + 2 \\frac{\\eta}{2^{3/2}} a_2 + \\frac{1}{3^{3/2}}\\bigg) d^3 + O(d^4) \\ .\n\\end{align*}\n\\] Setting the higher-order coefficients to zero, we get \\(a_2 = - \\frac{\\eta}{2^{3/2}}\\) and \\(a_3 = \\frac{1}{4}  -\\frac{1}{3^{3/2}}\\). Thus, up to \\(O(d^3)\\) we have \\[\nz = d - \\frac{\\eta}{2^{3/2}} d^2 + \\bigg(\\frac{1}{4}  -\\frac{1}{3^{3/2}}\\bigg) d^3 + O(d^4) \\ .\n\\] Plugging this expression back into \\(\\beta P\\) and simplifying, we get \\[\n\\begin{align*}\n\\beta P &= \\frac{g}{\\lambda_T^3} \\bigg(z + \\frac{\\eta}{2^{5/2}} z^2 + \\frac{1}{3^{5/2}} z^3 + O(z^4)\\bigg) \\\\\n&= \\frac{g}{\\lambda_T^3} \\bigg\\{\\bigg[d - \\frac{\\eta}{2^{3/2}} d^2 + \\bigg(\\frac{1}{4}  -\\frac{1}{3^{3/2}}\\bigg) d^3\\bigg] + \\frac{\\eta}{2^{5/2}} \\bigg[d - \\frac{\\eta}{2^{3/2}} d^2 + \\bigg(\\frac{1}{4}  -\\frac{1}{3^{3/2}}\\bigg) d^3\\bigg]^2 \\\\\n&+ \\frac{1}{3^{5/2}} \\bigg[d - \\frac{\\eta}{2^{3/2}} d^2 + \\bigg(\\frac{1}{4}  -\\frac{1}{3^{3/2}}\\bigg) d^3\\bigg]^3 + O(d^4)\\bigg\\} \\\\\n&= \\frac{g}{\\lambda_T^3} \\bigg[d - \\frac{\\eta}{2^{5/2}} d^2 + \\bigg(\\frac{1}{8} - \\frac{2}{3^{5/2}}\\bigg) d^3 + O(d^4) \\bigg] \\ .\n\\end{align*}\n\\] Finally, to get a virial expansion up to \\(O(n^3)\\) we substitute \\(d = \\frac{n \\lambda_T^3}{g}\\) to get \\[\n\\beta P = n - \\frac{\\lambda_T^3}{g} \\frac{\\eta}{2^{5/2}} n^2 + \\frac{\\lambda_T^6}{g^2} \\bigg(\\frac{1}{8} - \\frac{2}{3^{5/2}}\\bigg) n^3 + O(n^4) \\ .\n\\] Notice how even with no interactions present in the quantum ideal gas we still get a virial expansion. In particular, notice the second virial coefficient \\(B_2(T) = -\\frac{\\lambda_T^3}{g} \\frac{\\eta}{2^{5/2}}\\). For bosons \\(B_2\\) is negative, meaning the pressure is reduced from that of the classical ideal gas. On the other hand, for fermions \\(B_2\\) is positive, meaning the pressure is increased from that of the classical ideal gas. It’s as if there are interactions present arising from quantum statistics, which we also saw more explicitly before using the position representation. In either case, since \\(\\lambda_T \\rightarrow 0\\) in the high temperature limit, \\(\\beta P \\rightarrow n\\) as we’d expect.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Quantum Gases</span>"
    ]
  },
  {
    "objectID": "statistical-mechanics/quantum-gases.html#degenerate-gases",
    "href": "statistical-mechanics/quantum-gases.html#degenerate-gases",
    "title": "Quantum Gases",
    "section": "Degenerate Gases",
    "text": "Degenerate Gases\nWe’ve largely gone as far as we can by treating bosons and fermions together. We’ve shown that in the classical limit of \\(d=f_{3/2}^\\eta (z) \\ll 1\\) the quantum ideal gas becomes the classical ideal gas, both for fermions and bosons. We’ve also shown how we can add in quantum corrections to the pressure at lower temperatures via a kind of virial expansion.\nBut what about in the other limit, the low temperature limit where \\(d=f_{3/2}^\\eta (z) \\gg 1\\)? In this degenerate limit expansions in powers of \\(z\\) no longer hold and we need to approach things differently. We’ll start by examining the degenerate limit for fermions, the so-called degenerate fermi gas. Afterwards we’ll separately look at the degenerate limit for bosons, the degenerate boson gas.\n\nDegenerate Fermi Gas\nTo understand the behavior of fermions at low temperatures we need a different kind of representation for the polylogarithm, namely an asymptotic series that’s valid when \\(z\\) becomes infinitely large. We’ll need to derive an asymptotic series for \\(f_s^{-}(z)\\). We’ll derive a full expansion later. But for now we’ll focus on the extreme low temperature limit where \\(T \\approx 0\\), meaning \\(\\log z \\gg 1\\). Recall that by definition we have \\[\nf_s^{-}(z) = \\frac{1}{(s-1)!} \\int_0^{\\infty} dx \\ \\frac{x^{s-1}}{z^{-1} e^x + 1} \\ .\n\\] Now, observe that the integrand has the form \\(x^{s-1} \\langle n \\rangle\\) where \\(\\langle n \\rangle = (z^{-1} e^x + 1)^{-1}\\) is the expected occupation number. We know that for fermions the occupation number should change abruptly from one to zero at low temperatures. If we plot \\(\\langle n \\rangle\\)as a function of \\(x\\) we get something like the figure shown below. As \\(z\\) gets larger the curve of \\(\\langle n \\rangle\\) approaches more and more of a step function that goes rapidly to zero around \\(x \\approx \\log z\\).\n\n\n\n\n\nThis means that to a crude approximation we can treat \\(\\langle n \\rangle\\) as a step function that jumps from one to zero at \\(x = \\log z\\), which means near zero temperature we can approximately say \\[\nf_s^{-}(z) = \\frac{1}{(s-1)!} \\int_0^{\\infty} dx \\ \\frac{x^{s-1}}{z^{-1} e^x + 1} \\approx \\frac{1}{(s-1)!} \\int_0^{\\log z} dx \\ x^{s-1} = \\frac{(\\log z)^s}{s!} \\ .\n\\] Using the identity \\(\\log z = \\beta\\mu\\), we then get \\[\n\\begin{align*}\nN &= \\frac{gV}{\\lambda_T^3} \\frac{(\\beta\\mu)^{3/2}}{(3/2)!} \\ , \\\\\nE &= \\frac{3}{2 \\beta} \\frac{gV}{\\lambda_T^3} \\frac{(\\beta\\mu)^{5/2}}{(5/2)!} \\ .\n\\end{align*}\n\\] Note the chemical potential \\(\\mu\\) here should be thought of as a function of temperature \\(T\\). Near \\(T=0\\) the chemical potential should be some constant value. This value \\(\\varepsilon_F \\equiv \\mu_0\\) is a constant with units of energy. It’s called the Fermi energy, which in terms of the density \\(n\\) is apparently given by \\[\n\\varepsilon_F = \\frac{2\\pi\\hbar^2}{m} \\bigg(\\frac{3\\sqrt{\\pi}n}{4g}\\bigg)^{2/3} = \\frac{\\hbar^2}{2m} \\bigg(\\frac{6\\pi^2 n}{g}\\bigg)^{2/3} \\ .\n\\] Physically, we can think of the Fermi energy as the energy of the last occupied state in the Fermi gas. In a Fermi gas, at low temperatures the states will fill up from smallest to largest momentum in successive order. The state occupied by the final particle in the gas will have the highest momentum, which we call the Fermi momentum, given by \\[\n\\varepsilon_F \\equiv \\frac{\\hbar^2}{2m} \\mathbf{k}_F^2 \\ .\n\\] Curiously, we can derive the expression for the Fermi energy directly from its definition as the last occupied state. If this is indeed the highest momentum state, this means in \\(k\\)-space all other particles must lie in or on the sphere whose radius is \\(k_F=|\\mathbf{k}_F|\\). If we assume each particle can take on only their spin degrees of freedom \\(g=2s+1\\), this means we’d have \\[\nN = \\sum_{k \\leq k_F} g \\approx \\frac{gV}{(2\\pi)^3} \\int_0^{k_F} 4\\pi k^2 dk = \\frac{gVk_F^3}{6\\pi^2} \\ .\n\\] Substituting in \\(\\varepsilon_F = \\frac{\\hbar^2}{2m} k_F^2\\) into this formula and solving for \\(\\varepsilon_F\\) in terms of \\(n = \\frac{N}{V}\\) gives the expected result for \\(\\varepsilon_F\\).\nSince it’s useful we’ll go ahead and also define a Fermi temperature \\(T_F\\) using the relation \\(\\varepsilon_F \\equiv k_B T_F\\). If we now take the ratio \\(\\frac{E}{N}\\) to get the energy in terms of particle number like we’re used to, we get \\[\nE = \\frac{3}{5} N \\varepsilon_F = \\frac{3}{5} N k_B T_F \\ .\n\\] Interestingly, it seems the energy of a Fermi gas doesn’t go to zero at zero temperature. It tends to a positive constant. A Fermi gas always has energy due to the exclusion principle preventing the particles from falling into lower energy states. Similarly, a Fermi gas must have non-zero pressure at zero temperature as well since \\(E = \\frac{3}{2} PV\\) implies \\[\nP V = \\frac{2}{5} N \\varepsilon_F = \\frac{2}{5} N k_B T_F \\ .\n\\] This defines a Fermi pressure \\(P_F \\equiv \\frac{2}{5} n \\varepsilon_F\\), usually called degeneracy pressure. It again arises from the exclusion principle due to the fact that we can’t squeeze the fermions arbitrarily close together.\n\nSommerfeld Expansion\nThese expressions tell us what to expect exactly at zero temperature. But what about near zero temperature? How do the equations of state interpolate between these values and the expected classical ones? To investigate this we’ll need to consider more than just the first term in the asymptotic expansion. We need the full asymptotic series now, which we derive below.\nLet’s consider again the integral definition of \\(f_s^{-}(z)\\) and perform integration by parts by moving one of the derivatives from \\(x^{s-1}\\) to \\(\\langle n \\rangle = \\big(z^{-1} e^x + 1\\big)^{-1}\\). Then we have \\[\n\\begin{align*}\nf_s^{-}(z) &= \\frac{1}{(s-1)!} \\int_0^{\\infty} dx \\ \\frac{x^{s-1}}{z^{-1} e^x + 1} \\\\\n&= \\frac{1}{s!} \\int_0^{\\infty} dx \\ x^s \\frac{d}{dx} \\frac{-1}{z^{-1} e^x + 1} \\\\\n&\\approx \\frac{1}{s!} \\int_{-\\infty}^{\\infty} dx \\ x^s \\frac{d}{dx} \\frac{-1}{z^{-1} e^x + 1} \\ .\n\\end{align*}\n\\] The last step requires some justification. Since \\(\\langle n \\rangle\\) is approximately a step function when \\(z \\gg 1\\) its derivative must be approximately a delta function. This means the integrand will be sharply peaked around \\(\\log z\\) and so extending the limits of integration to the whole real line is essentially immaterial, though convenient.\nWe’ll now make a change of variable. Let \\(u = x - \\log z\\), meaning \\(x = \\log z + u\\) and \\(dx = du\\). Substituting, doing a binomial expansion on \\(x^s = (\\log z + u)^s\\), and then reversing the integration by parts, we get \\[\n\\begin{align*}\nf_s^{-}(z) &\\approx \\frac{1}{s!} \\int_{-\\infty}^{\\infty} du \\ (\\log z + u)^s \\frac{d}{du} \\frac{-1}{e^u + 1} \\\\\n&= \\frac{1}{s!} \\int_{-\\infty}^{\\infty} du \\sum_{\\alpha=0}^\\infty \\binom{s}{\\alpha} u^\\alpha (\\log z)^{s-\\alpha} \\frac{d}{du} \\frac{-1}{e^u + 1} \\\\\n&= \\frac{(\\log z)^s}{s!} \\sum_{\\alpha=0}^\\infty \\frac{s!}{\\alpha!(s-\\alpha)!} (\\log z)^{-\\alpha} \\int_{-\\infty}^{\\infty} du \\ u^\\alpha \\frac{d}{du} \\frac{-1}{e^u + 1} \\\\\n&= \\frac{(\\log z)^s}{s!} \\sum_{\\alpha=0}^\\infty \\frac{s!}{\\alpha!(s-\\alpha)!} (\\log z)^{-\\alpha} \\alpha \\int_{-\\infty}^{\\infty} du \\ \\frac{u^{\\alpha-1}}{e^u + 1} \\ .\n\\end{align*}\n\\] Now, the integrand in the last line, call it \\(g(u)\\), is always either an odd or even function depending on \\(\\alpha\\). When \\(\\alpha\\) is odd the integral must be zero, and when \\(\\alpha\\) is even the integral must be twice the positive part, both by symmetry. Moreover, the positive part of the integral is just \\((2\\alpha-1)! f_{2\\alpha}^{-}(1)\\) since \\(u\\) is a dummy variable and \\(z=1\\). This means we have\n\\[\n\\begin{align*}\nf_s^{-}(z) &= \\frac{(\\log z)^s}{s!} \\sum_{\\alpha=0}^\\infty \\frac{s!}{(s-\\alpha)!} (\\log z)^{-\\alpha} \\frac{1}{(\\alpha-1)!} \\int_{-\\infty}^{\\infty} du \\ \\frac{u^{\\alpha-1}}{e^u + 1} \\\\\n&= \\frac{(\\log z)^s}{s!} \\sum_{\\alpha=0}^\\infty \\frac{s!}{(s-2\\alpha)!} (\\log z)^{-2\\alpha} \\frac{2}{(2\\alpha-1)!} \\int_0^{\\infty} du \\ \\frac{u^{2\\alpha-1}}{e^u + 1} \\\\\n&= \\frac{(\\log z)^s}{s!} \\sum_{\\alpha=0}^\\infty \\frac{s!}{(s-2\\alpha)!} (\\log z)^{-2\\alpha} 2f_{2\\alpha}^{-}(1) \\\\\n\\end{align*}\n\\] Now, the terms \\(f_{2\\alpha}^{-}(1)\\) are kind of like zeta functions since \\[\nf_s^{-}(1) = -\\text{Li}_s (-1) = \\sum_{n=1}^\\infty \\frac{(-1)^n}{n^s} = 1 - \\frac{1}{2^s} + \\frac{1}{3^s} - \\cdots \\ .\n\\] These functions are called eta functions, denoted \\(\\eta_s\\), and are related to zeta functions via \\(\\eta_s = \\big(1-2^{1-s}\\big) \\zeta_s\\). This can be seen by separating the odd and even parts of the series and doing some factoring. Using this relationship along with the fact that zeta function values for even integers \\(s=2\\alpha\\) have closed form solutions, we finally have \\[\n\\begin{align*}\nf_s^{-}(z) &= \\frac{(\\log z)^s}{s!} \\sum_{\\alpha=0}^\\infty \\frac{s!}{(s-2\\alpha)!} (\\log z)^{-2\\alpha} 2\\big(1-2^{1-2\\alpha}\\big) \\zeta_{2\\alpha} \\\\\n&= \\frac{(\\log z)^s}{s!} \\bigg[1 + \\zeta_2 \\frac{s(s-1)}{(\\log z)^2} + \\frac{7\\zeta_4}{4}\\frac{s(s-1)(s-2)(s-3)}{(\\log z)^4} + O\\big((\\log z)^{-6}\\big) \\bigg] \\\\\n&= \\frac{(\\log z)^s}{s!} \\bigg[1 + \\frac{\\pi^2}{6} \\frac{s(s-1)}{(\\log z)^2} + \\frac{7\\pi^4}{360}\\frac{s(s-1)(s-2)(s-3)}{(\\log z)^4} + O\\big((\\log z)^{-6}\\big) \\bigg] \\ .\n\\end{align*}\n\\] This final series is known as the Sommerfeld expansion. Notice the leading term in the series is just \\(f_s^{-}(z) \\approx \\frac{(\\log z)^s}{s!}\\), which we already expect. This leads to the Fermi values derived before. The higher order terms in the expansion involve reciprocal powers of \\(\\log z\\), which act to give small corrections to the asymptotic expansion at large \\(z\\).\nWe can now use the Sommerfeld expansion to finally calculate the first few corrections to the equations of state at zero temperature. To do that we need to get the series for \\(s=\\frac{3}{2}\\) and \\(s=\\frac{5}{2}\\). Working only to the first correction, we have \\[\n\\begin{align*}\nf_{3/2}^{-}(z) &= \\frac{(\\log z)^{3/2}}{(3/2)!} \\bigg[1 + \\frac{\\pi^2/8}{(\\log z)^2} + O\\big((\\log z)^{-4}\\big) \\bigg] \\ , \\\\\nf_{5/2}^{-}(z) &= \\frac{(\\log z)^{5/2}}{(5/2)!} \\bigg[1 + \\frac{5\\pi^2/8}{(\\log z)^2} + O\\big((\\log z)^{-4}\\big) \\bigg] \\ .\n\\end{align*}\n\\] Again using the fact that \\(\\log z = \\beta\\mu\\) we can read off the corrections to the equations of state. First, we have \\[\nN = \\frac{gV}{\\lambda_T^3} f_{3/2}^\\eta(z) = \\frac{gV}{\\lambda_T^3} \\frac{(\\beta\\mu)^{3/2}}{(3/2)!} \\bigg[1 + \\frac{\\pi^2}{8} \\bigg(\\frac{k_B T}{\\varepsilon_F}\\bigg)^2 + O(T^4) \\bigg] \\ .\n\\] We can use this formula to solve for the chemical potential \\(\\mu\\) by rearranging terms to get \\[\n\\mu = \\frac{\\hbar^2}{2m} \\bigg(\\frac{6\\pi^2 N}{gV}\\bigg)^{2/3} \\bigg[1 + \\frac{\\pi^2}{8} \\bigg(\\frac{k_B T}{\\varepsilon_F}\\bigg)^2 + O(T^4) \\bigg]^{-2/3} = \\varepsilon_F \\bigg[1 - \\frac{\\pi^2}{12}\\bigg(\\frac{T}{T_F}\\bigg)^2 + O(T^4) \\bigg] \\ .\n\\] This means the chemical potential is evidently a downward-sloping parabola at low temperatures with a vertex at the Fermi energy \\(\\varepsilon_F\\). We also expect classically that \\(\\mu \\sim -T \\log T\\) at high temperatures, so the two curves should smoothly interpolate somehow, as shown in the figure below. The transition regime occurs somewhere around the Fermi temperature \\(T_F\\).\n\n\n\n\n\nNext up, we can find the pressure by using the above expansion for \\(\\mu\\) to get $$ \\[\\begin{align*}\nP &= \\frac{g}{\\beta\\lambda_T^3} f_{5/2}^\\eta(z) \\\\\n&= \\frac{g}{\\beta\\lambda_T^3} \\frac{(\\beta\\mu)^{5/2}}{(5/2)!} \\bigg[1 + \\frac{5\\pi^2}{8} \\bigg(\\frac{k_B T}{\\varepsilon_F}\\bigg)^2 + O(T^4) \\bigg] \\\\\n&= \\frac{g}{\\beta\\lambda_T^3} \\frac{(\\beta\\varepsilon_F)^{5/2}}{(5/2)!} \\bigg[1 - \\frac{\\pi^2}{12}\\bigg(\\frac{T}{T_F}\\bigg)^2 + O(T^4) \\bigg]^{5/2} \\bigg[1 + \\frac{5\\pi^2}{8} \\bigg(\\frac{T}{T_F}\\bigg)^2 + O(T^4) \\bigg] \\\\\n&= P_F \\bigg[1 + \\frac{5\\pi^2}{12}\\bigg(\\frac{T}{T_F}\\bigg)^2 + O(T^4) \\bigg] \\ .\n\n\\end{align*}\\] $$ Evidently the correction to the pressure is also quadratic, but this time the parabola is upward sloping, causing pressure to increase with temperature. In the classical limit of course we expect pressure to become linear \\(P \\sim T\\), with a turning point occurring again around the Fermi temperature \\(T_F\\). This is shown in the figure below.\n\n\n\n\n\nWith the pressure in hand we can now proceed to calculate the average internal energy using the formula \\(E = \\frac{3}{2} PV\\). We get \\[\nE = \\frac{3}{5} N k_B T_F \\bigg[1 + \\frac{5\\pi^2}{12}\\bigg(\\frac{T}{T_F}\\bigg)^2 + O(T^4) \\bigg] \\ .\n\\] Clearly the energy will also be an upward-sloping parabola at low temperatures and have \\(E \\sim T\\) at high temperatures. Having energy as a function of temperature we can proceed to calculate the heat capacity for the Fermi gas at low temperatures. Differentiating with respect to \\(T\\) we get \\[\nC = \\frac{\\partial E}{\\partial T} = N k_B \\frac{\\pi^2}{2} \\bigg(\\frac{T}{T_F}\\bigg) + O(T^3) \\ .\n\\] Importantly, notice that at low temperatures the heat capacity of a Fermi gas is linear with a cubic correction. As \\(T\\) approaches the Fermi temperature \\(T_F\\) the heat capacity turns over and starts to behave classically, as shown in the figure below.\n\n\n\n\n\nPerhaps the most important application of this result is to metals. Metals can be thought of as solids where internal electrons are allowed to move freely as an interacting Fermi gas. We already saw in a previous chapter that typical non-conducting solids are dominated by phonon effects at low temperatures, causing \\(C \\sim T^3\\) when \\(T \\ll T_D\\), where \\(T_D\\) is the solid’s Debeye temperature. Metals slightly modify this result by having \\[\nC \\sim \\gamma T + \\alpha T^3\n\\] at low temperatures. We can imagine the linear term arising from the Fermi gas effects of the free electrons. In fact this isn’t exactly true since electrons do interact with each other via Coulomb forces. They’re not free particles, hence not ideal. Nevertheless, if we imagine the Coulomb interactions as being adiabatic in the sense of being “turned on slowly”, then their energy at low temperatures turns out to be the same as if the gas were ideal. Since the heat capacity of a metal at low temperatures would go something like \\[\nC \\sim N k_B \\bigg[\\frac{\\pi^2}{2} \\bigg(\\frac{T}{T_F}\\bigg) + \\frac{12\\pi^4}{5} \\bigg(\\frac{T}{T_D}\\bigg)^3 \\bigg] \\ ,\n\\] we can see at what temperature the Fermi and phonon effects become comparable by equating terms and solving for \\(T\\) to get \\[\nT \\sim \\sqrt{\\frac{5T_D^3}{24\\pi T_F}} \\ .\n\\] For a typical metal we’d have something like \\(T_D \\sim 10^2 \\ ^\\circ \\text{K}\\) and \\(T_F \\sim 10^4 \\ ^\\circ \\text{K}\\), meaning the linear term would become important only when temperatures get down to around \\(T \\sim 1 \\ ^\\circ \\text{K}\\).\n\n\nExample: Paramagnetism\nAs another interesting application of the theory of Fermi gases, let’s consider the case of paramagnetism. A paramagnet is any material whose electron spins tend to align themselves parallel to an applied external magnetic field. Typically paramagnetic behavior is observed in materials whose atoms have an odd number of electrons so that some of them are left unpaired. Only these unpaired electrons contribute anything significant to the magnetization. Atoms with an even number of electrons experience a different and much weaker effect known as diamagnetism, where the electron spins tend to align themselves antiparallel to the external field. Both effects are significantly weaker than ferromagnetism, often by a factor of \\(10^4\\) or more.\nThe tendency of a material to respond to an external magnetic field \\(\\mathbf{B}\\) is captured via its magnetization vector \\(\\mathbf{M}\\). Its magnitude \\(M\\) is the average magnetic dipole moment per unit volume, which can be more usefully related to the difference between densities of up-spin to down-spin unpaired electrons by \\[\nM \\equiv \\frac{\\langle m \\rangle}{V} = \\mu_B \\frac{N_+ - N_-}{V} \\ ,\n\\] where \\(\\mu_B \\equiv \\frac{e\\hbar}{2m_ec} \\approx 5.8 \\cdot 10^{-9} \\ \\text{eV} \\cdot \\text{G}^{-1}\\) is a constant known as the Bohr magneton. The magnetization depends on the strength of the external field. We can relate the two via a constituency relation whose form depends both on the material as well as the strength of the external field. In the simplest case where the material is isotropic and \\(\\mathbf{B}\\) is sufficiently weak, \\(\\mathbf{M}\\) will be approximately linear in the auxiliary field \\(\\mathbf{H} \\equiv \\mathbf{B} - 4\\pi\\mathbf{M}\\), with \\(\\mathbf{M} \\approx \\chi \\mathbf{H}\\), where \\(\\chi\\) is a proportionality constant known as the magnetic susceptibility. In the limit of a weak field we can approximate \\(\\mathbf{H} \\approx \\mathbf{B}\\) and hence write \\(\\mathbf{M} \\approx \\chi \\mathbf{B}\\). Taking the derivative of the magnitude of both sides and reminding ourselves we’re in the weak field limit of \\(B \\rightarrow 0\\), we evidently thus have \\[\n\\chi = \\frac{\\partial M}{\\partial B} \\bigg |_{B=0} \\ .\n\\] The susceptibility \\(\\chi\\) expresses essentially all of the material-specific properties that contribute to the magnetization. It’s thus useful to study its properties, for instance its dependence on thermodynamic variables like temperature or density.\nFor paramagnetic materials, we can express the Hamiltonian for a single electron to a decent approximation by \\[\nH_1 = \\frac{\\mathbf{p}^2}{2m} + \\mu_B \\boldsymbol{\\sigma} \\cdot \\mathbf{B} \\ ,\n\\] where \\(m=m_e\\) is the mass of the electron and \\(\\boldsymbol{\\sigma}\\) is the Pauli operator. It’s not too hard to see that the eigenstates of the \\(\\boldsymbol{\\sigma} \\cdot \\mathbf{B}\\) operator alone are two states \\(|\\pm\\rangle\\) with energies \\(\\varepsilon_{\\pm} = \\pm B\\). To get the full energy eigenvalues we instead need to use the joint states \\(|\\mathbf{k}, \\pm\\rangle\\). In terms of the joint states, the energy eigenvalues are given by \\[\n\\varepsilon_{\\mathbf{k}, \\pm} = \\frac{\\hbar^2 \\mathbf{k}^2}{2m} \\pm \\mu_B B \\ .\n\\] Since electrons are fermions, if we’re interested in low temperature behaviors we’ll need to treat the problem as a Fermi gas. This means we’ll need to proceed from here by again calculating the grand partition function \\(\\mathcal{Z}\\) and going from there. We have \\[\n\\begin{align*}\n\\mathcal{Z} &= \\sum_{N=0}^\\infty e^{\\beta\\mu N} \\text{ tr } e^{-\\beta H} \\\\\n&= \\prod_\\mathbf{k} \\sum_{n_{\\mathbf{k}, \\pm}} e^{-\\beta n_{\\mathbf{k}, \\pm}\\big(\\varepsilon_{\\mathbf{k}, \\pm} - \\mu\\big)} \\\\\n&= \\prod_\\mathbf{k} \\bigg(1 + e^{-\\beta \\big(\\varepsilon_{\\mathbf{k}} - \\mu + \\mu_B B\\big)}\\bigg) \\bigg(1 + e^{-\\beta \\big(\\varepsilon_{\\mathbf{k}} - \\mu - \\mu_B B\\big)}\\bigg) \\\\\n&= \\prod_\\mathbf{k} \\bigg(1 + e^{-\\beta \\big(\\varepsilon_{\\mathbf{k}} - \\mu_+\\big)}\\bigg) \\bigg(1 + e^{-\\beta \\big(\\varepsilon_{\\mathbf{k}} - \\mu_-\\big)}\\bigg) \\\\\n\\end{align*}\n\\]\nHere we’ve define \\(\\mu_\\pm \\equiv \\mu \\mp \\mu_B B\\) to be effective chemical potentials and \\(z_\\pm \\equiv e^{\\beta\\mu_\\pm}\\) to be the effective fugacities. From here, we can take the logarithm and simplify by again using the density of states and the same substitutions to get \\[\n\\begin{align*}\n\\log \\mathcal{Z} &\\approx \\frac{2V}{(2\\pi)^3} \\int d^3 \\mathbf{k} \\ \\bigg[\\log \\bigg(1 + z e^{-\\frac{\\beta\\hbar^2}{2m} \\mathbf{k}^2} e^{-\\beta \\mu_B B}\\bigg) + \\log \\bigg(1 + z e^{-\\frac{\\beta\\hbar^2}{2m} \\mathbf{k}^2} e^{\\beta \\mu_B B}\\bigg)\\bigg] \\\\\n&= \\frac{2V}{\\lambda_T^3} \\frac{1}{(3/2)!} \\int_0^\\infty dx \\ \\bigg[\\frac{x^{3/2}}{z_{+}^{-1} e^x + 1} + \\frac{x^{3/2}}{z_{-}^{-1} e^x + 1}\\bigg] \\\\\n&= \\frac{2V}{\\lambda_T^3} \\big[f_{5/2}^{-}\\big(z_+\\big) + f_{5/2}^{-}\\big(z_-\\big)\\big] \\ .\n\\end{align*}\n\\] Note we used the fact that the spin degeneracy for an electron is \\(g=2\\). From here we can proceed to calculate the mean up-spin and down-spin densities \\(n_\\pm = \\frac{N_\\pm}{V}\\). Using the differentiation ladder relation for polylogarithms, we just have \\[\nn_\\pm = \\frac{1}{V} \\frac{\\partial \\log\\mathcal{Z}}{\\partial (\\beta\\mu_\\pm)} = \\frac{z_\\pm}{V} \\frac{\\partial \\log\\mathcal{Z}}{\\partial z_\\pm} = \\frac{2}{\\lambda_T^3} f_{3/2}^{-}\\big(z_\\pm\\big) \\ .\n\\] This means the magnetization \\(M\\) is just given by \\[\nM = \\frac{2}{\\lambda_T^3} \\big[f_{3/2}^{-}\\big(z_+\\big) + f_{3/2}^{-}\\big(z_-\\big)\\big] \\ ,\n\\] from which we can conclude the susceptibility \\(\\chi\\) is given by \\[\n\\chi = \\frac{\\partial M}{\\partial B} \\bigg |_{B=0} = \\frac{4\\beta\\mu_B^2}{\\lambda_T^3} f_{1/2}^{-}(z) \\ .\n\\] Since this expression isn’t all that informative as is let’s analyze the behavior of \\(\\chi(T)\\) in the high and low temperature limits. It’ll be useful to write things in terms of \\(N\\), which we can get from the relation \\[\nN = N_+ + N_- = \\frac{2V}{\\lambda_T^3} \\big[f_{3/2}^{-}\\big(z_+\\big) + f_{3/2}^{-}\\big(z_-\\big)\\big] \\ .\n\\] At high temperatures we can use the fact that \\(f_{1/2}^{-}(z) \\approx z\\) to get \\(N \\approx \\frac{4V}{\\lambda_T^3} z\\) and hence \\[\n\\chi(T) \\approx \\frac{n\\mu_B^2}{k_B T} \\equiv \\frac{C}{T} \\ .\n\\] This is a well-known result for paramagnetic materials, known as Curie’s Law. As the temperature of the material increases its susceptibility decreases in constant proportion. Of course, this law fails in the low temperature limit.\nIn the low temperature limit we can use the Sommerfeld expansion in the weak field limit to write \\(f_s^{-}(z_\\pm) \\approx \\frac{\\beta^s\\mu^s}{s!}\\). From here, we can express \\(N \\approx \\frac{4V}{(3/2)!} \\frac{\\beta^{3/2}}{\\lambda_T^3} \\varepsilon_F^{3/2}\\) and plug this back into \\(\\chi\\) to get the following relation in the low temperature limit, \\[\n\\chi(T) \\approx \\frac{3\\mu_B^2 n}{2k_B T_F} \\bigg[1 - \\frac{\\pi^2}{12} \\bigg(\\frac{T}{T_F}\\bigg)^2 + O(T^4) \\bigg] \\ .\n\\] As we’d expect, the susceptibility goes to a positive constant \\(\\chi_F\\) in the low temperature limit. The first quadratic correction is negative, meaning \\(\\chi(T)\\) will decrease and eventually go like \\(\\chi(T) \\sim \\frac{C}{T}\\) in the high temperature limit, as shown below.\n\n\n\n\n\n\n\n\nDegenerate Bose Gas\nWe’ll now consider the case of the degenerate Bose gas at low temperatures. Bosons at low temperatures behave quite differently from fermions. While fermions form a Fermi sphere of states of ever-increasing momentum, bosons instead eventually all pile into their ground state in a phenomenon known as Bose-Einstein Condensation.\nUnlike with the fermi function \\(f_s^{-}(z)\\) which is well-defined for all \\(z\\), the boson function \\(f_s^{+}(z)\\) is only well-defined when \\(|z| \\leq 1\\). To see why this is the case physically and not just mathematically, consider again the Bose-Einstein distribution \\[\n\\langle n_\\mathbf{k} \\rangle = \\frac{1}{e^{\\beta(\\varepsilon_\\mathbf{k}-\\mu)} - 1} \\ .\n\\] Since \\(\\langle n_\\mathbf{k} \\rangle\\) is an occupation number it must be non-negative. This can only happen if \\(\\mu \\leq \\varepsilon_\\mathbf{k}\\) for any value of \\(\\varepsilon_\\mathbf{k}\\). Since \\(\\min \\varepsilon_\\mathbf{k} = 0\\) is the smallest energy possible, this means we must have \\(\\mu \\leq 0\\). Since we expect \\(\\mu\\) to increase as \\(T\\) decreases, it’s reasonable to expect that \\(\\mu \\rightarrow 0\\) as \\(T \\rightarrow 0\\). And since \\(\\mu\\) goes to zero like \\(\\mu \\sim k_B T \\log \\frac{n\\lambda_T^3}{g}\\), this means we must have \\(z \\rightarrow 1\\) as \\(T \\rightarrow 0\\). Thus, studying the low temperature limit for bosons is essentially equivalent to studying the behavior of \\(f_s^{+}(z)\\) as \\(z \\rightarrow 1\\) from below.\nAs we saw before, the polylogarithm increases monotonically with \\(z\\), hitting the finite value of \\(\\zeta_s = f_s^{+}(1)\\) at \\(z=1\\) provided \\(s &gt; 1\\), or blowing up to infinity at \\(z=1\\) otherwise. Together these imply we should have \\[\n\\frac{n\\lambda_T^3}{g} = f_{3/2}^{+}(z) \\leq \\zeta_{3/2} \\approx 2.61 \\ .\n\\] But physically this doesn’t quite make sense at low temperatures. We generally think of \\(n=\\frac{N}{V}\\) as being fixed, reflecting in essence the conservation of mass. But the only way \\(n\\) can stay fixed as \\(T \\rightarrow 0\\) is for \\(f_{3/2}^{+}(z) \\rightarrow \\infty\\) as \\(\\lambda_T \\rightarrow \\infty\\). But this isn’t happening here since \\(f_{3/2}^{+}(z) \\rightarrow \\zeta_{3/2}\\) instead. So what’s going on?\nIf we step back and think about the quantum mechanics of the situation, we should realize that the lowest energy state each particle can occupy is its ground state. It would thus make sense at the lowest temperatures for particles to start to move into their ground states. Though non-obvious, our formulas aren’t keeping track of the particles in the ground state at all due to the subtleties in the density of states approximation, which expressed in terms of the energy is given by \\[\n\\sum_{\\mathbf{k}} \\approx \\frac{(2m)^{3/2} V}{4\\pi^2\\hbar^3} \\int dE \\ \\sqrt{E} \\ .\n\\] Because of the \\(\\sqrt{E}\\) weight inside the integrand, the ground state energy \\(E=0\\) doesn’t contribute at all to the integral. When temperatures are away from zero this isn’t a major issue since comparatively few particles are in their ground states. But very near zero temperature it becomes a much bigger deal.\nWe can attempt to correct for this efficiency by counting the ground state contributions separately from the excited states. For the excited states we’ll continue to use the density of states approximations, which gives the results we saw before. For the ground states, all we have to do is observe that the Bose-Einstein distribution says the expected number of particles in the ground state at a given fugacity \\(z\\) is just \\[\nN_0 \\approx \\langle n_0 \\rangle = \\frac{1}{z^{-1} - 1} = \\frac{z}{1-z} \\ .\n\\] All we have to do is break the density up into two pieces, the ground state density \\(n_0\\) and the excited state density \\(n_&gt;\\), \\[\nN = N_0 + N_&gt; = \\frac{z}{1-z} + \\frac{gV}{\\lambda_T^3} f_{3/2}^{+}(z) \\ .\n\\] We can define a useful critical temperature \\(T_c\\) by seeing at what temperature \\(\\frac{N\\lambda_T^3}{gV} = \\zeta_{3/2}\\), which turns out to be \\[\nT_c \\equiv \\frac{2\\pi\\hbar^2}{mk_B} \\bigg(\\frac{N}{\\zeta_{3/2} gV}\\bigg)^{2/3} \\ .\n\\] The critical temperature evidently tells us something about how many particles occupy the ground state. The fraction of total particles in the ground state or excited states at a given temperature is evidently \\[\n\\frac{N_0}{N} = 1 - \\frac{gV}{N\\lambda_T^3} \\zeta_{3/2} = 1 - \\bigg(\\frac{T}{T_c}\\bigg)^{3/2} \\quad , \\quad \\frac{N_&gt;}{N} = \\frac{gV}{N\\lambda_T^3} \\zeta_{3/2} = \\bigg(\\frac{T}{T_c}\\bigg)^{3/2} \\ .\n\\] Notice \\(N_&gt; \\approx N\\) when \\(T \\geq T_c\\), so we need only worry about the excited states. But when \\(T \\approx 0\\) the opposite is true, with all particles crowding into the ground state to give \\(N \\approx N_0\\). We can see this tradeoff between occupied states in the figure below.\n\n\n\n\n\nThis phenomenon where bosons all pile into their ground state below some temperature is called Bose-Einstein Condensation or BEC. Note that critical temperatures are generally very close to zero, for example water has a critical temperature of about \\(T_c \\approx 0.06 \\ ^\\circ\\text{K}\\). This means for BEC to be seen at all a gas needs to be cooled to almost exactly \\(T=0\\).\nIn a similar vein, we can find formulas for the pressure and energy at low temperatures. In these cases, the contribution from the ground state is negligible in the thermodynamic limit since they’re a factor of \\(N\\) less than the excited state contributions. This means for all \\(T\\) we can safely write \\[\nP = k_B T \\frac{g}{\\lambda_T^3} f_{5/2}^{+}(z) \\quad , \\quad E = \\frac{3}{2} k_B T\\frac{gV}{\\lambda_T^3} f_{5/2}^{+}(z) \\ .\n\\] When \\(T &lt; T_c\\) we just need to replace \\(f_{5/2}^{+}(z)\\) by \\(\\zeta_{5/2} \\approx 1.41\\) to get the correct results near \\(T=0\\), \\[\nP = k_B T \\frac{g}{\\lambda_T^3} \\zeta_{5/2} \\quad , \\quad E = \\frac{3}{2} k_B T \\frac{gV}{\\lambda_T^3} \\zeta_{5/2} \\ .\n\\] In particular, notice that when \\(T &lt; T_c\\) both the pressure and energy go like \\(T^{5/2}\\), while perhaps strangely the pressure doesn’t depend at all on the density \\(n=\\frac{N}{V}\\) anymore since the ground state particles no longer contribute to the pressure. This means even though \\(P = n k_B T\\) in the high temperature limit, at low temperatures it always follows the same curve, as shown below.\n\n\n\n\n\nAs is pretty much custom by now, we’ll differentiate energy with respect to temperature to get the heat capacity. To do this we need to keep the \\(f_{5/2}^{+}(z)\\) in the formula even below \\(T_c\\) since \\(z\\) itself depends implicitly on temperature. One can then show using the relation \\(N = \\frac{gV}{\\lambda_T^3} f_{3/2}^{+}(z)\\) and the ladder relationship \\(\\frac{d}{dz} f_s^{+}(z) = \\frac{1}{z} f_{s-1}^{+}(z)\\) that \\[\n\\begin{align*}\nC = \\frac{\\partial E}{\\partial T} &= \\frac{15}{4} \\frac{gV}{\\lambda_T^3} k_B f_{5/2}^{+}(z) + \\frac{3}{2} \\frac{gV}{\\lambda_T^3} k_B T \\frac{df_{5/2}^{+}(z)}{dz} \\frac{\\partial z}{\\partial T} \\\\\n&= \\frac{3}{2} k_B \\frac{gV}{\\lambda_T^3} \\bigg[\\frac{5}{2} f_{5/2}^{+}(z) - \\frac{3}{2} \\frac{\\big(f_{3/2}^{+}(z)\\big)^2}{f_{1/2}^{+}(z)}\\bigg] \\ .\n\\end{align*}\n\\] When \\(T \\gg T_c\\) we can use the approximation \\(f_s^{+}(z) \\approx z\\) to recover the classical result of \\(C = \\frac{3}{2} N k_B\\). When \\(T &lt; T_c\\) the second term goes to zero since \\(f_{1/2}^{+}(z) \\rightarrow \\infty\\) as \\(z \\rightarrow 1\\). In that limit we evidently have \\[\nC = \\frac{15}{4} k_B \\frac{gV}{\\lambda_T^3} \\zeta_{5/2} = \\frac{15}{4} \\frac{\\zeta_{5/2}}{\\zeta_{3/2}} \\bigg(\\frac{T}{T_c}\\bigg)^{3/2} \\ .\n\\] Evidently near zero temperature the heat capacity of a boson goes like \\(T^{3/2}\\), which is very different from fermions. The way the two limits join in this case though is particularly interesting. It turns out they join at a kink above \\(\\frac{3}{2} Nk_B\\) as shown below.\n\n\n\n\n\nTo see why this is true we need to study the behavior when \\(T &gt; T_c\\) but \\(T \\approx T_c\\). This can be seen by expanding the heat capacity when \\(T &gt; T_c\\) and observing that the corrections increase the heat capacity from \\(\\frac{3}{2} N k_B\\). This expansion turns out to be \\[\nC = \\frac{3}{2} N k_B \\bigg[1 + \\frac{\\lambda_T^3}{2^{7/2}} n + O(n^2) \\bigg] \\ .\n\\] This lack of smoothness in the heat capacity can be thought of as a phase transition at \\(T=T_c\\). Bosons below the critical temperature can be thought of as a distinct state of matter. We can further see this by looking at the compressibility \\(\\kappa_T\\), \\[\n\\kappa_T = \\frac{1}{V} \\frac{\\partial V}{\\partial P} \\bigg |_{T,N} = \\frac{1}{n} \\frac{\\partial n / \\partial z}{\\partial P / \\partial z} \\bigg |_{T,N} = \\frac{1}{nk_BT} \\frac{f_{1/2}^{+}(z)}{f_{3/2}^{+}(z)} \\ .\n\\] Notice as \\(z \\rightarrow 1\\) at the critical temperature that \\(f_{1/2}^{+}(z) \\rightarrow \\infty\\) and so \\(\\kappa_T \\rightarrow \\infty\\) as well. This means the isotherms of the \\(PV\\)-diagram become flat when \\(T&lt;T_c\\) similar to the way they do for the van der Waals interaction, indicating coexistence.\nAnother example of a low-temperature phase transition for bosons is a different phenomenon known as superfluidity. For example, helium is known to come in two common isotopes, helium-3 and helium-4. Helium-3 is a fermion since it contains 2 protons, 2 electrons, and a single neutron. Meanwhile, helium-4 is a boson since it contains 2 protons, 2 electrons, and 2 neutrons. At typical pressures helium never forms a solid at low temperatures. It instead forms a superfluid, which is a liquid with many similar properties to BEC. Superfluids have the interesting property that they have zero viscosity, meaning they can seep through whatever container they’re in when the temperature gets below some critical temperature \\(T_c\\). For helium-4 this temperature is known to be about \\(T_c \\approx 2.2 \\ ^\\circ\\text{K}\\) at standard pressure.",
    "crumbs": [
      "Statistical Mechanics",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Quantum Gases</span>"
    ]
  }
]