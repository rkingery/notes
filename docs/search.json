[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Personal Notes",
    "section": "",
    "text": "Preface\nThis page contains notes I’ve taken over time for several different subjects of interest. Currently these subjects include\n\nClassical Mechanics\nElectrodynamics\nCircuit Analysis\nQuantum Mechanics\nStatistical Mechanics\n\nFeel free to use whatever you find helpful."
  },
  {
    "objectID": "classical-mechanics/newtonian-mechanics.html#point-particles",
    "href": "classical-mechanics/newtonian-mechanics.html#point-particles",
    "title": "Newtonian Mechanics",
    "section": "Point Particles",
    "text": "Point Particles\nIn nature, an object is made of matter. It can be composed of many different molecules arranged in intricate and complicated ways. Further, each molecule is itself made of atoms, and each atom is itself made up of subatomic particles. Trying to model the motion of an object would be extremely cumbersome if we insisted on modeling the dynamics of each subatomic particle.\nInstead, it’s convenient to make abstractions. The most convenient abstraction to make is that we can describe the global behavior of an object as if it were a point object with no width. It can’t spin or deform. It’s one indivisible thing. We call these point particles.\nWe’ll think of a point particle as following some trajectory in the 3-dimensional Euclidean space \\(\\mathbb{R}^{3}\\). The trajectory or position is a time-dependent vector\n\\[\n\\mathbf{x}(t) = x(t)\\mathbf{e}_x + y(t)\\mathbf{e}_y + z(t)\\mathbf{e}_z.\n\\] A moving particle also has associated to it a velocity vector given by\n\\[\n\\mathbf{v} = \\mathbf{\\dot x} = \\frac{d\\mathbf{x}}{dt}.\n\\] Perhaps the most fundamental goal of classical mechanics is to find these two vectors as a function of time. In the Newtonian formulation, if we want to find a particle’s trajectory, we start with the particle’s acceleration vector \\[\n\\mathbf{a} = \\mathbf{\\dot v} = \\mathbf{\\ddot x} = \\frac{d^2\\mathbf{x}}{dt^2},\n\\] and match it with the force vector \\(\\mathbf{F}\\) via Newton’s Second Law to get a second-order differential equation for \\(\\mathbf{x}(t)\\)."
  },
  {
    "objectID": "classical-mechanics/newtonian-mechanics.html#newtons-laws",
    "href": "classical-mechanics/newtonian-mechanics.html#newtons-laws",
    "title": "Newtonian Mechanics",
    "section": "Newton’s Laws",
    "text": "Newton’s Laws\nNewton’s Laws efficiently encapsulate the fundamental physics of classical mechanics. They’re stated below specifically for a point particle, or body, but can be extended to more complex systems as well.\n\nA body remains at rest, or in motion at a constant speed in a straight line, unless acted upon by a force. That is,\n\\[\n\\mathbf{F} = \\mathbf{0} \\Rightarrow \\mathbf{v}=const.\n\\]\nWhen a body is acted upon by a force, the time rate of change of its acceleration is proportional to the force. That is, \\[\n\\mathbf{F} = m \\mathbf{a}.\n\\]\nIf two bodies exert forces on each other, these forces have the same magnitude but opposite directions. That is, \\[\n\\mathbf{F}_{12} = \\mathbf{F}_{21}.\n\\]\n\n\n\n\n\n\nForces are vectors, which means they obey the superposition principle, and can be analyzed in components. Position, velocity, and acceleration are vectors as well. The proportionality constant between \\(\\mathbf{F}\\) and \\(\\mathbf{a}\\) is called the mass \\(m\\). Loosely speaking, the mass of an object is a measure of its inertia or resistance to motion.\nThe functional form of the forces themselves depend on the particular type of forces applied. Some common forces are:\n\nGravitational Force: \\(\\mathbf{F} = -\\frac{GMm}{r^2} \\mathbf{e}_r\\)\nCoulomb Force: \\(\\mathbf{F} = k_e \\frac{Qq}{r^2} \\mathbf{e}_r\\)\nHarmonic Oscillator: \\(\\mathbf{F} = -k\\mathbf{x}\\)\nLorentz Force: \\(\\mathbf{F} = q\\mathbf{E} + \\frac{q}{c}\\mathbf{v} \\times \\mathbf{B}\\)\nThrust: \\(\\mathbf{F} = - |\\mathbf{v}_{ex}| \\dot m \\mathbf{e}_v\\)\n\n\n\n\n\nNormal Forces: \\(\\mathbf{F} = \\mathbf{N}\\)\nTension Forces: \\(\\mathbf{F} = \\mathbf{T}\\)\nFrictional Forces: \\(\\mathbf{F} = -\\mu |\\mathbf{N}| \\mathbf{e}_v\\)\nDrag Forces: \\(\\mathbf{F} = -f(\\mathbf{v}) \\mathbf{e}_v \\approx -a\\mathbf{v} -b|\\mathbf{v}|^2\\mathbf{e}_v\\)\nCentrifugal Forces: \\(\\mathbf{F} = m\\boldsymbol{\\omega} \\times (\\mathbf{x} \\times \\boldsymbol{\\omega})\\)\nCoriolis Forces: \\(\\mathbf{F} = 2m \\mathbf{v} \\times \\boldsymbol{\\omega}\\)\nBuoyant Forces: \\(\\mathbf{F} = - \\rho_{liq} V_{sub} \\mathbf{g}\\)"
  },
  {
    "objectID": "classical-mechanics/newtonian-mechanics.html#conservation-laws",
    "href": "classical-mechanics/newtonian-mechanics.html#conservation-laws",
    "title": "Newtonian Mechanics",
    "section": "Conservation Laws",
    "text": "Conservation Laws\nA quantity Q is said to be conserved if its time derivative is zero, \\(\\dot Q = 0\\). That is, Q is conserved it it’s constant in time.\n\nMomentum\nFor an object moving at velocity \\(\\mathbf{v}\\), define its linear momentum \\(\\mathbf{p}\\) by\n\\[\n\\mathbf{p} = m \\mathbf{v}.\n\\] If the mass \\(m\\) is constant, we evidently have \\[\n\\mathbf{F} = \\mathbf{\\dot p}.\n\\] If \\(\\mathbf{F} = \\mathbf{0}\\), then \\(\\mathbf{p}=const\\), hence momentum is conserved if there are no forces applied. This is the conservation of momentum.\n\n\nAngular Momentum\nDefine the angular momentum \\(\\mathbf{L}\\) of an object by \\[\n\\mathbf{L} = \\mathbf{x} \\times \\mathbf{p}.\n\\] Similarly, define the torque or moment \\(\\mathbf{N}\\) by \\[\\mathbf{N} = \\mathbf{x} \\times \\mathbf{F}.\\]\nNote both angular momentum and torque depend on the choice of coordinate system used since the position vector \\(\\mathbf{x}\\) depends on choice of origin. Now, observe that \\[\n\\mathbf{\\dot L} = \\mathbf{\\dot x} \\times \\mathbf{p} + \\mathbf{x} \\times \\mathbf{\\dot p} = m \\mathbf{v} \\times \\mathbf{v} + \\mathbf{x} \\times \\mathbf{F} = \\mathbf{N}.\n\\] Thus, \\(\\mathbf{N} = \\mathbf{\\dot L}\\). If \\(\\mathbf{N} = \\mathbf{0}\\), then \\(\\mathbf{L}=const\\), hence angular momentum must be conserved if there are no torques applied. This is the conservation of angular momentum.\n\n\nWork and Energy\nDefine the work done on an object as it moves along a path \\(\\gamma\\) from \\(A\\) to \\(B\\) by\n\\[\nW = \\int_A^B \\mathbf{F} \\cdot d\\mathbf{x}.\n\\]\n\n\n\n\n\nIn general, work depends on the path taken to get from \\(A\\) to \\(B\\), hence it isn’t a unique property of the system.\nObserve that \\[\ndW = \\mathbf{F} \\cdot d\\mathbf{x} = \\mathbf{F} \\cdot \\mathbf{v} dt = d\\bigg(\\frac{1}{2}m\\mathbf{v}^2 \\bigg).\n\\] Define the kinetic energy of the system by \\(T = \\frac{1}{2} m \\mathbf{v}^2\\). Then we evidently have \\(dW=dT\\). That is, the work done on the system to get from \\(A\\) to \\(B\\) via \\(\\gamma\\) is just the change in kinetic energy between \\(A\\) and \\(B\\), \\[\nW = \\Delta T = T_B - T_A.\n\\] When the work done is independent of the path taken it’s a state function of the kinetic energy. In this case, the force \\(\\mathbf{F}\\) is said to be conservative.\nBy the Helmholtz theorem, the following conditions are all equivalent:\n\n\\(\\mathbf{F}\\) is conservative,\n\\(W\\) is path-independent,\n\\(\\nabla \\times \\mathbf{F} = \\mathbf{0}\\),\nThere is a scalar potential \\(V=V(\\mathbf{x})\\) such that \\(\\mathbf{F} = -\\nabla V\\).\n\nThe scalar potential \\(V\\) is called the potential energy of the system. Evidently, if \\(\\mathbf{F}\\) is conservative, we have \\[\nW = \\int_A^B \\mathbf{F} \\cdot d\\mathbf{x} = -\\int_A^B \\nabla V \\cdot d\\mathbf{x} = -\\int_A^B dV = V_A - V_B = -\\Delta V = \\Delta T.\n\\] That is, \\(\\Delta T + \\Delta V = 0\\). Define the total mechanical energy \\(E\\) of the system by \\[\nE = T + V.\n\\] Then \\(\\Delta E = \\Delta (T + V) = 0\\). That is, energy is conserved when the forces on the system are conservative. This is the conservation of energy.\nEnergy isn’t generally conserved if the forces aren’t conservative. Examples of non-conservative forces include any force that’s a function of velocity. These include dissipative forces like friction or drag, as well as magnetic forces."
  },
  {
    "objectID": "classical-mechanics/newtonian-mechanics.html#using-newtons-laws",
    "href": "classical-mechanics/newtonian-mechanics.html#using-newtons-laws",
    "title": "Newtonian Mechanics",
    "section": "Using Newton’s Laws",
    "text": "Using Newton’s Laws\nThe primary goal of mechanics is to understand how systems evolve with time. To understand a particle’s given trajectory in Newtonian Mechanics, we need to\n\nWrite down all the forces acting on the particle,\nUse \\(\\mathbf{F} = m \\mathbf{a}\\) to set up the equations of motion,\nSolve the equations of motion for the trajectory \\(\\mathbf{x}(t)\\), either analytically or (usually) numerically.\n\nHere are some examples.\n\n\nExample: Projectile motion\nSuppose a cannon is launched from the origin at an angle \\(\\theta\\) above the ground with initial velocity \\(\\mathbf{v}_0\\).\n\n\n\n\n\n\nWrite down the equations of motion. Assume drag is negligible.\nThe forces are \\(\\mathbf{F} = \\mathbf{g} = -g\\mathbf{e}_y\\). Then, \\[\n\\mathbf{a} = \\ddot x\\mathbf{e}_x + \\ddot y\\mathbf{e}_y = -g\\mathbf{e}_y \\quad \\Longrightarrow \\quad   \\ddot x = 0, \\ \\ \\ddot y = -mg.\n\\]\nFind the trajectory \\(\\mathbf{x}(t) = x(t)\\mathbf{e}_x + y(t)\\mathbf{e}_y\\).\nIntegrating each element twice gives \\[\n\\begin{align*}\nx(t) &= x_0 + v_{0x}t = v_0t \\cos \\theta, \\\\\ny(t) &= y_0 + v_{0y}t - \\frac{1}{2} gt^2 = v_{0}t\\sin \\theta - \\frac{1}{2} gt^2.\n\\end{align*}\n\\]\nFind the range, i.e. the value \\(R=x(T)\\) when the cannon hits the ground. Which launch angle maximizes the range?\nFirst, we need to find the time \\(T\\) when \\(y(T) = 0\\). Setting \\[\ny(T) = 0 = v_0 T \\sin \\theta - \\frac{1}{2} gT^2 \\Longrightarrow T = 0, \\frac{2v_0 \\sin \\theta}{g}.\n\\] The \\(T=0\\) case is trivial. Plugging the other one in to \\(x(T)\\) finally gives the range, \\[\nR = x(T) = v_0T \\cos \\theta = \\frac{2v_0^2 \\sin \\theta}{g} \\cos \\theta = \\frac{v_0^2 \\sin 2\\theta}{g}.\n\\] Note that the range is maximized when \\(\\sin 2 \\theta = 1\\), which is when the launch angle is \\(\\theta = 45^\\circ\\).\nFind the shape of the motion \\(y = y(x)\\).\nWe need to eliminate \\(t\\) in both equations and solve for \\(y=y(x(t))\\). Solving \\(x(t)\\) for \\(t\\) gives, \\[\nx = v_0 t\\cos \\theta \\Longrightarrow t = \\frac{x}{v_0 \\cos \\theta}.\n\\] Plugging this into \\(y\\) then gives \\[\ny = v_{0}\\frac{x}{v_0 \\cos \\theta}\\sin \\theta - \\frac{1}{2} g\\bigg(\\frac{x}{v_0 \\cos \\theta}\\bigg)^2 =  \\tan \\theta \\cdot x - \\frac{g}{2v_0^2 \\cos^2 \\theta} x^2.\n\\] This is a downward sloping parabola with vertex at \\(\\big(\\frac{v_0^2 \\sin 2\\theta}{2g}, \\frac{v_0^2 \\sin^2 \\theta}{g}\\big)\\).\nFind any conserved quantities.\n\nMomentum: Since \\(\\mathbf{F} \\neq \\mathbf{0}\\), momentum isn’t conserved. However, \\(p_x\\) is conserved.\nAngular Momentum: Since \\(\\mathbf{N} = \\mathbf{x} \\times \\mathbf{F} = \\mathbf{x} \\times m\\mathbf{g} \\neq 0\\), angular momentum is not conserved.\nEnergy: Since \\(V=mgy\\), the force \\(\\mathbf{F}\\) is conservative, hence energy is conserved.\n\n\n\n\n\nExample: Block sliding on a ramp with friction\nA block of mass \\(m\\) is sliding down a ramp inclined from the horizontal at an angle \\(\\theta\\). Assume the system has a coefficient of friction \\(\\mu\\), and that the block starts from rest at the top of the ramp.\n\n\n\n\n\n\nWrite down the equations of motion.\nChoose a coordinate system such that \\(x\\) is pointing downwards parallel to the ramp and \\(y\\) is pointing outwards perpendicular to the ramp. There are three forces acting, gravity, the normal force, and the frictional force, so \\[\n\\mathbf{F} = \\mathbf{N} + m\\mathbf{g} - \\mu \\mathbf{N} \\mathbf{e}_v = N\\mathbf{e}_y + mg(\\sin\\theta\\mathbf{e}_x - \\cos\\theta\\mathbf{e}_y) - \\mu N \\mathbf{e}_x.\n\\] Resolving into components, we have \\[\n\\begin{align*}\nm \\ddot x &= mg\\sin\\theta - \\mu N, \\\\\nm \\ddot y &= N - mg\\cos\\theta = 0.\n\\end{align*}\n\\] The second equation follows from the assumption that the block is constrained to stay on the ramp.\nFind the trajectory \\(\\mathbf{x}(t) = x(t)\\mathbf{e}_x + y(t)\\mathbf{e}_y\\).\nTo solve, we need to eliminate the normal force \\(N\\). Using the EOM for \\(\\ddot y\\), we get \\(N = mg\\cos\\theta\\). Plugging this into the equation for \\(\\ddot x\\) then gives\n\\[\n\\begin{align*}\n\\ddot x &= g(\\sin\\theta - \\mu\\cos\\theta) = const, \\\\\n\\ddot y &= 0.\n\\end{align*}\n\\] Suppose the block starts at the top of the ramp, which we’ll call the origin. Then integrating, we get,\n\\[\n\\begin{align*}\nx(t) &= v_0 t + \\frac{1}{2}g(\\sin\\theta - \\mu\\cos\\theta)t^2, \\\\\ny(t) &= 0.\n\\end{align*}\n\\] Notice \\(x(t)\\) is just the equation of an object falling under a modified gravity \\[\n\\mathbf{g}'=-g(\\sin\\theta - \\mu\\cos\\theta)\\mathbf{e}_x.\n\\]\nFind the angle \\(\\theta\\) at which the block will start sliding.\nThe block will move if \\(\\ddot x \\geq 0\\), i.e. when \\(\\mu \\leq \\tan\\theta\\). It will start moving at the angle when \\(\\tan\\theta=\\mu\\) exactly, i.e. when \\[\n\\theta = \\arctan\\mu.\n\\]\nFind any conserved quantities.\n\nMomentum: Since \\(\\mathbf{F} \\neq \\mathbf{0}\\), momentum is not conserved. However, \\(p_y\\) is conserved.\nAngular momentum: Since \\(\\mathbf{N} = \\mathbf{x} \\times \\mathbf{F} \\neq \\mathbf{0}\\), angular momentum is not conserved.\nEnergy: Since friction is present, \\(\\mathbf{F}\\) is a dissipative force, hence it’s not conservative, and energy is not conserved.\n\nFind the rate of energy dissipation as the block slides down the ramp.\nFriction dissipates as a heat \\(Q\\). If the block slides a distance \\(L\\), this means \\(E(0) = E(L) + Q\\). Since the block starts from rest, \\(E(0) = 0\\). At \\(x=L\\), the work done is \\[\nW = \\int_0^L F_x dx = \\int_0^L mg(\\sin\\theta - \\mu\\cos\\theta)dx = mgL(\\sin\\theta - \\mu\\cos\\theta) = T(L) - 0 = T(L),\n\\] so the energy when the block gets to the bottom is \\[\nE(L) = T(L) + V(L,0) = mgL(\\sin\\theta - \\mu\\cos\\theta) - mgL\\sin\\theta = -\\mu mgL\\cos\\theta.\n\\] Finally, using this to solve for \\(Q\\), the heat dissipated over the entire trajectory, we get \\[\nQ = E(0) - E(L) = \\mu mgL\\cos\\theta.\n\\] The most important sanity check here is to notice there’s no heat dissipation if there is no friction."
  },
  {
    "objectID": "classical-mechanics/newtonian-mechanics.html#curvilinear-coordinates",
    "href": "classical-mechanics/newtonian-mechanics.html#curvilinear-coordinates",
    "title": "Newtonian Mechanics",
    "section": "Curvilinear Coordinates",
    "text": "Curvilinear Coordinates\nFor many problems, it’s more convenient to take advantage of the underlying symmetry by using special coordinate systems. Other than rectangular coordinates \\((x,y,z)\\), the most common coordinate systems worth being familiar with are polar coordinates \\((r,\\varphi)\\), cylindrical coordinates \\((\\rho,\\varphi,z)\\), and spherical coordinates \\((r,\\theta,\\varphi)\\).\n\nPolar Coordinates\nFor problems with circular symmetry it’s convenient to use polar coordinates \\((r,\\varphi)\\), defined by\n\\[\n\\begin{align*}\nx &=  r\\cos\\varphi, \\\\\ny &=  r\\sin\\varphi. \\\\\n\\end{align*}\n\\] where \\(r \\geq 0\\) and \\(0 \\leq \\varphi \\leq 2\\pi\\). We can assign basis vectors to polar coordinates \\(\\mathbf{e}_r, \\mathbf{e}_\\varphi\\) to each point as usual.\n\n\n\n\n\nThe thing to keep in mind is that these curvilinear basis vectors are now functions of position,\n\\[\n\\begin{align*}\n\\mathbf{e}_r &= \\mathbf{e}_r(r, \\varphi), \\\\\n\\mathbf{e}_\\varphi &= \\mathbf{e}_\\varphi(r, \\varphi).\n\\end{align*}\n\\] We can figure out how these basis vectors change by taking their differentials, which follow from the figure above,\n\\[\n\\begin{align*}\nd\\mathbf{e}_r &= \\mathbf{e}_\\varphi d\\varphi, \\\\\nd\\mathbf{e}_\\varphi &= -\\mathbf{e}_r d\\varphi.\n\\end{align*}\n\\] Using these differential forms, we can conclude that the motion vectors change as follows,\n\\[\n\\begin{align*}\n\\mathbf{x} &= r\\mathbf{e}_r, \\\\\n\\mathbf{v} &= \\dot r \\mathbf{e}_r + r\\dot \\varphi \\mathbf{e}_\\varphi, \\\\\n\\mathbf{a} &= (\\ddot r - r\\dot \\varphi^2)\\mathbf{e}_r + (2\\dot r \\dot \\varphi + r\\ddot \\varphi)\\mathbf{e}_\\varphi.\n\\end{align*}\n\\]\n\n\nExample: Circular orbits\nSuppose an object moves in a circular orbit of radius \\(r\\) at a constant angular velocity \\(\\omega\\) due to a central force \\(\\mathbf{F} = -F\\mathbf{e}_r\\).\n\n\n\n\n\n\nFind the equations of motion. Since the object moves at constant \\(\\omega\\), we have \\(\\dot \\varphi = \\omega = const\\). Using the polar equations for velocity and acceleration, we have \\[\n\\begin{align*}\n\\mathbf{v} &= \\dot r \\mathbf{e}_r, \\\\\n\\mathbf{a} &= -r\\omega^2\\mathbf{e}_r + r \\dot \\omega\\mathbf{e}_\\varphi = - \\frac{F}{m}\\mathbf{e}_r.\n\\end{align*}\n\\] Note we can re-write these equations to get \\(F = m\\omega^2 r\\).\nFind the period \\(\\tau\\) of the orbit.\nWe want the time it takes for \\(\\Delta \\varphi = 2\\pi\\). Since \\(\\Delta \\varphi = \\omega\\tau\\), solving for \\(\\tau\\) gives \\[\\tau = \\frac{2\\pi}{\\omega}.\\]\nSuppose the central force is the gravitational force, \\(F = \\frac{GMm}{r^2}\\). Find the angular velocity, the period, and the orbital velocity as a function of \\(G, M, r\\).\nWe have \\[\nF = \\frac{GMm}{r^2} = m\\omega^2 r \\ \\Longrightarrow \\ \\omega = \\sqrt{\\frac{GM}{r^3}} \\ \\Longrightarrow \\ \\tau = \\frac{2\\pi}{\\sqrt{GM}} r^{3/2}.\n\\] This is just a special case of Kepler’s third law, \\(\\tau^2 \\propto r^3\\). The orbital velocity is given by \\[\nv = r\\omega = \\sqrt{\\frac{GM}{r}}.\n\\]\n\n\n\n\nExample: Simple pendulum\nConsider the problem of the simple pendulum, where a mass \\(m\\) swings on a massless string of length \\(\\ell\\) under the force of gravity. The string is fixed at one point. Assume no damping is present.\n\n\n\n\n\n\nFind the equations of motion from the forces directly.\nThere are two forces in this problem, gravity and the tension in the string, \\[\n\\mathbf{F} = \\mathbf{T} + m\\mathbf{g} = -T\\mathbf{e}_r + mg(\\cos\\theta \\mathbf{e}_r - \\sin\\theta\\mathbf{e}_\\theta).\n\\] Dividing by \\(m\\) and setting equal to the polar form of \\(\\mathbf{a}\\), we have \\[\n\\mathbf{a} = (-T+mg\\cos\\theta)\\mathbf{e}_r - mg\\sin\\theta\\mathbf{e}_\\theta = -m\\ell^2 \\dot \\theta^2 \\mathbf{e}_r + m\\ell^2 \\ddot \\theta \\mathbf{e}_\\theta.\n\\] This gives two equations of motion, one for the tension and one for the angular acceleration, \\[\n\\begin{align*}\nT &= m\\ell^2 \\dot\\theta^2 + mg\\cos\\theta, \\\\\n\\ddot \\theta &= -\\frac{g}{\\ell} \\sin\\theta. \\\\\n\\end{align*}\n\\]\nFind the equations of motion again, but this time using torques.\nRecall \\(\\mathbf{N} = I \\boldsymbol{\\dot \\omega}\\), where \\(I\\) is the scalar moment of inertia and \\(\\boldsymbol{\\omega}\\) is the angular velocity vector. In this case, \\(I=m\\ell^2\\) and \\(\\boldsymbol{\\dot \\omega} = \\ddot \\theta \\mathbf{e}_z\\). Then we have \\[\nI \\boldsymbol{\\dot \\omega} = m\\ell^2 \\ddot \\theta \\mathbf{e}_z \\equiv \\ell\\mathbf{e}_r \\times m\\mathbf{g} = -mg\\ell\\sin\\theta \\mathbf{e}_z = \\mathbf{N},\n\\] which can be solve to get \\(\\ddot \\theta = -\\frac{g}{\\ell}\\sin\\theta\\). Notice how in this approach we don’t need to worry about the tension at all.\nSuppose \\(\\theta\\) is small. Write down the equations of motion, solve them, and find the period.\nWhen \\(\\theta \\ll 1\\) the small angle approximation applies, \\(\\sin\\theta \\approx \\theta\\). In this case, the equation of motion reduces to \\[\\ddot \\theta = -\\frac{g}{\\ell} \\theta,\\] which is just simple harmonic oscillation with angular frequency \\(\\omega = \\sqrt{\\frac{g}{\\ell}}\\). The solution to SHO is \\[\n\\theta(t) = A\\sin(\\omega t + \\phi),\n\\] where \\(A\\) is some amplitude and \\(\\phi\\) is some phase determined by the initial conditions. Finally, solving for the period, we have \\[\n\\tau = \\frac{2\\pi}{\\omega} = 2\\pi\\sqrt{\\frac{\\ell}{g}}.\n\\]\n\n\n\n\n\nCylindrical Coordinates\nCylindrical coordinates extend polar coodinates by adding in the z-axis from the rectangular system,\n\\[\n\\begin{align*}\nx &=  r\\cos\\varphi, \\\\\ny &=  r\\sin\\varphi, \\\\\nz &= z.\n\\end{align*}\n\\] The basis vectors are \\(\\mathbf{e}_r, \\mathbf{e}_\\varphi, \\mathbf{e}_z\\). Their differential forms are just \\[\n\\begin{align*}\nd\\mathbf{e}_r &= \\mathbf{e}_\\varphi d\\varphi, \\\\\nd\\mathbf{e}_\\varphi &= -\\mathbf{e}_r d\\varphi \\\\\nd\\mathbf{e}_z &= 0.\n\\end{align*}\n\\] The motion vectors in cylindrical coordinates are thus given by, \\[\n\\begin{align*}\n\\mathbf{x} &= r\\mathbf{e}_r, \\\\\n\\mathbf{v} &= \\dot r \\mathbf{e}_r + r\\dot \\varphi \\mathbf{e}_\\varphi + \\dot z \\mathbf{e}_z , \\\\\n\\mathbf{a} &= (\\ddot r - r\\dot \\varphi^2)\\mathbf{e}_r + (2\\dot r \\dot \\varphi + r\\ddot \\varphi)\\mathbf{e}_\\varphi + \\ddot z \\mathbf{e}_z.\n\\end{align*}\n\\]\n\n\nSpherical Coordinates\nSpherical coordinates extend polar coordinates in a slightly different way. The radius \\(r\\) is now 3-dimensional, and there are two angles, a polar angle \\(0 \\leq \\theta \\leq \\pi\\) and an azimuthal angle \\(0 \\leq \\varphi \\leq 2\\pi\\). The conversion to rectangular coordinates is given by, \\[\n\\begin{align*}\nx &=  r\\sin\\theta\\cos\\varphi, \\\\\ny &=  r\\sin\\theta\\sin\\varphi, \\\\\nz &= r\\cos\\theta. \\\\\n\\end{align*}\n\\] The basis vectors are \\(\\mathbf{e}_r, \\mathbf{e}_\\theta, \\mathbf{e}_\\varphi\\). Deriving the differential forms of these is a good bit more complex. Here they are, \\[\n\\begin{aligned}\nd\\mathbf{e}_r &= \\dot\\theta \\sin\\varphi d\\mathbf{e}_\\theta + \\dot\\varphi d\\mathbf{e}_\\varphi, \\\\\nd\\mathbf{e}_\\theta &= - \\dot\\theta \\sin\\varphi d\\mathbf{e}_r - \\dot\\theta \\cos\\varphi d\\mathbf{e}_\\varphi, \\\\\nd\\mathbf{e}_\\varphi &= - \\dot\\varphi \\mathbf{e}_r + \\dot\\theta \\cos\\varphi \\mathbf{e}_\\theta. \\\\\n\\end{aligned}\n\\] These can then be used to get the motion vectors in spherical coordinates, \\[\n\\begin{align*}\n\\mathbf{r} &= r \\mathbf{e}_r, \\\\\n\\mathbf{v} &= \\dot{r} \\mathbf{e}_r + r \\dot\\theta \\sin\\varphi \\mathbf{e}_{\\theta} + r \\dot\\varphi \\mathbf{e}_{\\varphi}, \\\\\n\\mathbf{a} &= (\\ddot{r} - r \\dot{\\theta}^2 \\sin^2\\varphi - r \\dot{\\varphi}^2) \\mathbf{e}_r \\\\\n&\\quad + (r \\ddot\\theta \\sin\\varphi + 2 \\dot{r} \\dot\\theta \\sin\\varphi + 2 r \\dot\\theta \\dot\\varphi \\cos\\varphi) \\mathbf{e}_{\\theta} \\\\\n&\\quad + (r \\ddot\\varphi + 2 \\dot{r} \\dot\\varphi - r \\dot{\\theta}^2 \\sin\\varphi \\cos\\varphi) \\mathbf{e}_{\\varphi}. \\\\\n\\end{align*}\n\\]"
  },
  {
    "objectID": "classical-mechanics/newtonian-mechanics.html#many-particle-systems",
    "href": "classical-mechanics/newtonian-mechanics.html#many-particle-systems",
    "title": "Newtonian Mechanics",
    "section": "Many-Particle Systems",
    "text": "Many-Particle Systems\nThus far we’ve worked with single-particle systems. Let’s now consider a system of \\(N\\) particles with positions \\(\\mathbf{x}_1, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N\\) respectively. We can use the principle of superposition to extend the laws derived above for single particles.\nFor \\(N\\)-particle systems it’s convenient to characterize the system’s position using the center of mass vector \\(\\mathbf{R}\\), \\[\n\\mathbf{R} \\equiv \\frac{1}{M}\\sum_{i=1}^N m_i \\mathbf{x}_i,\n\\] where \\(M\\) is just the total mass of the system, \\(M \\equiv \\sum m_i\\). The center of mass is just the mass-weighted average of all the particle position vectors.\nSuppose an external force \\(\\mathbf{F}^{ext}\\) is acting on the system, and suppose each particle \\(i\\) imparts a force \\(\\mathbf{F}_{ij}\\) on particle \\(j \\neq i\\). Here’s what this would look like for \\(N=3\\) particles.\n\n\n\n\n\nBy superposition, the total force acting on the entire system is thus, \\[\n\\mathbf{F} = \\mathbf{F}^{ext} + \\sum_{i \\neq j} \\mathbf{F}_{ij} = \\sum m_i \\mathbf{a}_i = M\\mathbf{\\ddot R}.\n\\] Now, by Newton’s third law, \\(\\mathbf{F}_{ij} = -\\mathbf{F}_{ji}\\). This means all the internal forces cancel in pairs, so we have \\[\n\\mathbf{F}^{ext} = M\\mathbf{\\ddot R}.\n\\] That is, the system as a whole moves as if it were a point mass \\(M\\) with an external force \\(\\mathbf{F}^{ext}\\) acting on its center of mass \\(\\mathbf{R}\\).\nIf the total momentum is defined as \\(\\mathbf{P} = M \\mathbf{\\dot R}\\), this expression then says \\(\\mathbf{F}^{ext} = \\mathbf{\\dot P}\\). Thus, if no external forces act on the system, then its total linear momentum \\(\\mathbf{P}\\) is conserved.\nLet’s now consider the total torques on the system. Suppose the system experiences an external torque \\(\\mathbf{N}^{ext}\\), and that each particle \\(i\\) exerts a torque \\(\\mathbf{N}_{ij}\\) on particle \\(j\\). Then by superposition, the total torque on the system is \\[\n\\mathbf{N} = \\mathbf{N}^{ext} + \\sum_{i \\neq j} \\mathbf{N}_{ij} = \\mathbf{N}^{ext} + \\sum_{i \\neq j} \\mathbf{x}_i \\times \\mathbf{F}_{ij},\n\\] Again, we can use the fact that each \\(\\mathbf{F}_{ij} = -\\mathbf{F}_{ji}\\). If we do this, we can re-write the total torque as\n\\[\n\\mathbf{N} = \\mathbf{N}^{ext} + \\sum_{i<j} (\\mathbf{x}_{i}-\\mathbf{x}_{j}) \\times \\mathbf{F}_{ij} = \\mathbf{N}^{ext}.\n\\] Now, if we further assume that each internal force acts centrally, i.e. \\(\\mathbf{F}_{ij} = \\mathbf{F}_{ij}(\\mathbf{x}_{i}-\\mathbf{x}_{j})\\), then the internal cross products all vanish, and we just get \\(\\mathbf{N} = \\mathbf{N}^{ext}\\). That is, if all the internal forces are central, then the total torque on the system is just the external torque.\nIf the total angular momentum on the system is defined as \\(\\mathbf{L} = \\mathbf{R} \\times \\mathbf{P}\\), this expression says \\(\\mathbf{\\dot L} = \\mathbf{N}^{ext}\\). Thus, if no external torques act on the system, then its total angular momentum \\(\\mathbf{L}\\) is conserved.\nIt’s insightful to separate each particle’s motion vectors explicitly into a center of mass component and a relative component,\n\\[\n\\begin{align*}\n\\mathbf{x}_i &= \\mathbf{R} + \\boldsymbol{\\mathscr{r}}_i, \\\\\n\\mathbf{v}_i &= \\mathbf{V} + \\boldsymbol{\\mathscr{v}}_i. \\\\\n\\end{align*}\n\\]\n\n\n\n\n\nLet’s re-write the total angular momentum \\(\\mathbf{L}\\) in terms of these vectors,\n\\[\n\\begin{align*}\n\\mathbf{L} &= \\sum \\mathbf{x}_i \\times \\mathbf{p}_i = \\sum (\\mathbf{R} + \\boldsymbol{\\mathscr{r}}_i) \\times m_i(\\mathbf{V} + \\boldsymbol{\\mathscr{v}}_i) \\\\\n&= M\\mathbf{R} \\times \\mathbf{V} + \\sum m_i \\boldsymbol{\\mathscr{r}}_i \\times \\boldsymbol{\\mathscr{v}}_i + \\mathbf{R} \\times \\bigg(\\sum m_i \\boldsymbol{\\mathscr{v}}_i \\bigg) + \\bigg(\\sum m_i \\boldsymbol{\\mathscr{r}}_i \\bigg)\\times \\mathbf{V} \\\\\n&= \\mathbf{R} \\times \\mathbf{P} + \\sum m_i \\boldsymbol{\\mathscr{r}}_i \\times \\boldsymbol{\\mathscr{v}}_i \\\\\n&\\equiv \\mathbf{L}^{orb} + \\mathbf{L}^{spin}. \\\\\n\\end{align*}\n\\] We’ve thus been able to separate the angular momentum into two components, an orbital angular momentum \\(\\mathbf{L}^{orb} = \\mathbf{R} \\times \\mathbf{P}\\), and a spin angular momentum \\(\\mathbf{L}^{spin} = \\sum m_i \\boldsymbol{\\mathscr{r}}_i \\times \\boldsymbol{\\mathscr{v}}_i\\). The orbital angular momentum describes how the center of mass of the object tends to rotate about some external point. The spin angular momentum describes how the system itself tends to rotate about its center of mass.\n\n\n\n\n\nLast, let’s look at the total energies of the system. For a system with \\(N\\) particles, the potential energy will be a function of all the position vectors, \\(V = V(\\mathbf{x}_1, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N)\\). It won’t generally simplify. But the kinetic energy we can simplify. Writing it in terms of its relative and center of mass velocities, we have\n\\[\n\\begin{align*}\nT &= \\frac{1}{2}\\sum m_i \\mathbf{v}_i^2 = \\sum m_i (\\mathbf{V} + \\boldsymbol{\\mathscr{v}}_i)^2 \\\\\n&= \\frac{1}{2}M\\mathbf{V}^2 + \\frac{1}{2}\\sum m_i\\boldsymbol{\\mathscr{v}}_i^2 + \\mathbf{V} \\cdot \\bigg(\\sum m_i \\boldsymbol{\\mathscr{v}}_i\\bigg) \\\\\n&= \\frac{1}{2}M\\mathbf{V}^2 + \\frac{1}{2}\\sum m_i\\boldsymbol{\\mathscr{v}}_i^2 \\\\\n&= T^{CM} + T^{rel}.\n\\end{align*}\n\\] Thus, the kinetic energy separates into a sum of the kinetic energy on the center of mass \\(T^{CM} = \\frac{1}{2}M\\mathbf{V}^2\\), and the kinetic energy of the relative components \\(T^{rel} = \\frac{1}{2}\\sum m_i\\boldsymbol{\\mathscr{v}}_i^2\\). Evidently, the total energy is \\[\nE = T + V = T^{CM} + T^{rel} + V(\\mathbf{x}_1, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N).\n\\] It’s conserved provided the external force \\(\\mathbf{F}^{ext}\\) is conservative.\n\n\nExample: Rockets\nSuppose a rocket of mass \\(m_0=m(t) + m_{ex}(t)\\) is moving through free space with no external forces acting on it. It’s expelling fuel for trust at some constant speed \\(v_{ex}\\) with respect to the rocket.\n\n\n\n\n\n\nWhat is the force of thrust on the rocket?\nNo external forces are present, so \\(\\mathbf{F}^{ext} = \\mathbf{0}\\). The internal forces are the thrust of the rocket, and the force of the exhaust. In the frame of the rocket they cancel out, \\(\\mathbf{F}_{th} = \\mathbf{F}_{ex}\\), so we have \\[\n\\mathbf{F}_{th} = -\\mathbf{F}_{ex} = -\\mathbf{\\dot p}_{ex} = -\\frac{d}{dt}(m_{ex} \\mathbf{v}_{ex}) = -\\dot m_{ex} \\mathbf{v}_{ex}.\n\\] Now, since \\(m_0 = m + m_{ex}\\), \\(\\dot m = -\\dot m_{ex}\\), and \\(\\mathbf{v}_{ex} = -v_{ex}\\mathbf{e}_v\\), we have \\[\n\\mathbf{F}_{th} = -\\dot m v_{ex} \\mathbf{e}_v.\n\\]\nFind the velocity \\(\\mathbf{v}(t)\\) of the rocket.\nUsing the fact that \\(\\mathbf{F}_{th} = m\\mathbf{a}\\), we have \\(-\\dot m v_{ex} = m \\dot v\\), a first-order differential equation in \\(v(t)\\), \\[\n\\dot v + v_{ex} \\frac{\\dot m}{m} = 0.\n\\] Integrating both sides and solving for \\(v(t)\\), we get \\[\nv(t) = v_0 - v_{ex} \\int_{m_0}^m \\frac{dm}{m} = -v_{ex} \\log \\frac{m(t)}{m_0}.\n\\] Or, expressing in the form of the well-known rocket equation, \\[\n\\Delta v = v_{ex} \\log\\frac{m_0}{m(t)}.\n\\]\nFind the position \\(\\mathbf{x}(t)\\) of the rocket, assuming fuel is expelled form the rocket at a constant rate.\nAssume \\(\\dot m = -k = const\\). Since there are no external forces, the rocket must be traveling along some line. Suppose without loss of generality then that \\(\\mathbf{x}(t) = z(t)\\mathbf{e}_z\\). Then we have, \\[\n\\begin{align*}\nz(t) &= \\int_0^t v(t) dt = v_{ex} \\int_0^t dt \\log\\frac{m_0}{m_0-kt} \\\\\n&= v_{ex} \\bigg[t - \\bigg(\\frac{m_0-kt}{k} \\bigg) \\log \\bigg(\\frac{m_0}{m_0-kt} \\bigg) \\bigg] \\\\\n&= v_{ex} t - \\frac{v_{ex}}{k}(m_0 - kt)\\log\\bigg(\\frac{m_0}{m_0-kt} \\bigg).\n\\end{align*}\n\\]"
  },
  {
    "objectID": "classical-mechanics/simple-systems.html#independent-forces",
    "href": "classical-mechanics/simple-systems.html#independent-forces",
    "title": "Simple Systems",
    "section": "Independent Forces",
    "text": "Independent Forces\nThe first and simplest case we’ll consider are forces that don’t depend on position or velocity, \\[\nm \\mathbf{a} = \\mathbf{F}_0(t).\n\\] We can solve these systems directly by integrating both sides, i.e. reducing to quadrature. We have,\n\\[\n\\begin{align*}\n\\mathbf{a}(t) &= \\frac{1}{m}\\mathbf{F}_0(t), \\\\\n\\mathbf{v}(t) &= \\mathbf{v}_0 + \\frac{1}{m}\\int_0^t dt'\\mathbf{F}_0(t'), \\\\\n\\mathbf{x}(t) &= \\mathbf{x}_0 + \\mathbf{v}_0t + \\frac{1}{m}\\int_0^t dt' \\int_0^{t'} dt''\\mathbf{F}_0(t''). \\\\\n\\end{align*}\n\\] The simplest of these cases are when there are no forces at all, and when the forces are constant. If there are no forces at all acting on the system, \\(\\mathbf{F}_0 = \\mathbf{0}\\), in which case the equations of motion reduce to\n\\[\n\\begin{align*}\n\\mathbf{a}(t) &= 0, \\\\\n\\mathbf{v}(t) &= \\mathbf{v}_0, \\\\\n\\mathbf{x}(t) &= \\mathbf{x}_0 + \\mathbf{v}_0t. \\\\\n\\end{align*}\n\\] This is just a statement of Newton’s First Law. If no forces act on a particle, it continues linearly along its path at constant velocity. The next simplest case is when \\(\\mathbf{F}_0=const\\). In this case, the equations of motion become\n\\[\n\\begin{align*}\n\\mathbf{a}(t) &= \\frac{1}{m}\\mathbf{F}_0, \\\\\n\\mathbf{v}(t) &= \\mathbf{v}_0 + \\frac{1}{m}\\mathbf{F}_0 t, \\\\\n\\mathbf{x}(t) &= \\mathbf{x}_0 + \\mathbf{v}_0t + \\frac{1}{2m^2}\\mathbf{F}_0^2. \\\\\n\\end{align*}\n\\] This case includes the gravitional force near the surface of the Earth, in which case \\(\\mathbf{F}_0=m\\mathbf{g}\\). It also includes the problem of an electric charge placed close to a large conducting sheet with a uniform electric field, where \\(\\mathbf{F}_0=q\\mathbf{E}_0\\).\nIn these problems, the motion will always be along a parabolic arc. The parabola will slope toward the force if the force is attractive, and away from the force if it’s repulsive.\n\n\nExample: Free-fall near Earth\nSuppose an object of mass \\(m\\) is falling freely near the Earth’s surface. In this case, \\(\\mathbf{F}_0 = m\\mathbf{g}\\), so\n\\[\n\\begin{align*}\n\\mathbf{a}(t) &= \\mathbf{g}, \\\\\n\\mathbf{v}(t) &= \\mathbf{v}_0 - \\mathbf{g}t, \\\\\n\\mathbf{x}(t) &= \\mathbf{x}_0 + \\mathbf{v}_0t + \\frac{1}{2}\\mathbf{g}t^2.\n\\end{align*}\n\\] The motion in this case will always lie in the plane spanned by \\(\\mathbf{v}_0\\) and \\(\\mathbf{g}\\). This means without loss of generality we can assume motion lies in the xy-plane with \\(\\mathbf{g} = -g\\mathbf{e}_y\\). Then \\(y\\) can be solved as a function of \\(x\\) to give \\[\ny(x) = v_{0}\\frac{x}{v_0 \\cos \\theta}\\sin \\theta - \\frac{1}{2} g\\bigg(\\frac{x}{v_0 \\cos \\theta}\\bigg)^2,\n\\] which is of course a downward-sloping parabola centered at the vertex \\(\\big(\\frac{v_0^2 \\sin 2\\theta}{2g}, \\frac{v_0^2 \\sin^2 \\theta}{g}\\big)\\)."
  },
  {
    "objectID": "classical-mechanics/simple-systems.html#drag-forces",
    "href": "classical-mechanics/simple-systems.html#drag-forces",
    "title": "Simple Systems",
    "section": "Drag Forces",
    "text": "Drag Forces\nThe next type of forces we’ll consider are those which are functions of velocity,\n\\[\nm\\mathbf{a} = \\mathbf{F}(\\mathbf{v}).\n\\] In the 1-dimensional case, this reduces to,\n\\[\nma = F(v).\n\\] Provided \\(v\\) is small, we can approximate \\(F(v)\\) by its first few terms. I’ll write it as,\n\\[\nF(v) \\approx a - bv - cv^2.\n\\] Typically, drag forces shouldn’t apply a force when the particle is at rest, which means \\(a=0\\). The remaining two terms cover two distinct regimes of drag:\n\nLinear or viscous drag: \\(F(v) = -bv\\), where \\(b > 0\\).\nQuadratic or air drag: \\(F(v) = -cv^2\\), where \\(c > 0\\).\n\n\nLinear Drag\nIt’s convenient to analyze these two distinct cases separately. Let’s first look at linear drag. In that case \\(c=0\\), and we end up with the linear differential equation \\[\nm \\ddot x + b \\dot x = 0.\n\\] To solve this equation, re-write it in terms of \\(v = \\dot x\\),\n\\[\n\\frac{dv}{dt} = -\\frac{b}{m} v.\n\\] Integrating both sides, we get\n\\[\nv(t) = v_0 e^{-\\frac{b}{m} t}.\n\\] For \\(x(t)\\) just integrate both sides again to get\n\\[\nx(t) = x_0 + \\int_0^t v_0 e^{-\\frac{b}{m} t'} dt' = x_0 + \\frac{mv_0}{b}\\big(1 - e^{-\\frac{b}{m} t}\\big).\n\\] Evidently, such forces cause a moving particle to slowly come to rest, since \\(v \\rightarrow 0\\) as \\(t \\rightarrow \\infty\\). The position where the particle comes to rest is evidently \\(x_f = x_0 + \\frac{mv_0}{b}\\). The \\(\\frac{1}{e}\\) decay time is \\(\\tau = \\frac{m}{b}\\). This suggests that \\(b\\) functions as a sort of drag coefficient, since a large \\(b\\) causes the system to dissipate faster.\n\n\n\n\n\nLinear drag is frequently used to model objects moving through a viscous medium at low speeds. Suppose a spherical object of radius \\(R\\) is moving slowly in a viscous medium with viscosity \\(\\eta\\). Then the drag force on the object is given by Stokes’ Law,\n\\[\n\\mathbf{F}_d = -6\\pi\\eta R \\mathbf{v}.\n\\] This force is linear in velocity, hence we can write \\(F_d = -6\\pi\\eta R v\\), which says the drag constant \\(b\\) is just\n\\[\nb = 6\\pi\\eta R.\n\\]\n\n\nExample: Dropping a ball in syrup\nSuppose a ball of radius \\(R\\) and mass \\(m\\) is dropped in a viscous syrup from rest at \\(x=0\\). Find the velocity and position of the ball as it moves through the fluid.\n\n\n\n\n\nThis is a 1-dimensional motion problem since the ball is dropped from rest under gravity, with \\(F=F_d + mg\\). Here Stoke’s law applies, so the drag force is \\(F_d = -bv = -b\\dot x\\). Plugging into Newton’s Second Law, we have \\[\nm\\ddot x + b \\dot x = g.\n\\] Re-writing this in terms of \\(v = \\dot x\\), we get \\[\nm \\dot v + bv = g,\n\\] which is a first order linear differential equation for the velocity \\(v(t)\\). Its general solution is given by \\[\nv(t) = v_0 e^{-\\frac{b}{m}t} + \\frac{mg}{b}(1-e^{-\\frac{b}{m}t}).\n\\] Notice that as \\(t \\rightarrow \\infty\\), \\(v(t) \\rightarrow \\frac{mg}{b}\\). That is, \\(v(t)\\) tends toward a terminal velocity \\[\nv_t = \\frac{mg}{b} = \\frac{mg}{6\\pi\\eta R}.\n\\] Since the ball is dropped from rest, \\(v_0=0\\). The velocity of the ball is thus given by \\[\nv(t) = v_t(1-e^{-\\frac{b}{m}t}).\n\\] Using this we can solve for the position to get \\[\nx(t) = v_t\\bigg(t - \\frac{b}{m}(1 - e^{-\\frac{b}{m}t})\\bigg).\n\\] Notice that drag causes the ball to fall much slower than it would in free-fall. Instead of being a quadratic function of time, \\(x(t)\\) is now approximately a linear function of time, with \\(x(t) \\sim v_t t\\) for large \\(t\\).\n\n\n\n\n\n\n\n\n\nQuadratic Drag\nWe’ll now look at quadratic drag, where \\(b=0\\). Then we get the differential equation, \\[\nm\\ddot x + c \\dot x^2 = 0.\n\\] This is no longer a linear differential equation due to the appearance of \\(\\dot x^2\\), but surprisingly we can still solve it using separation of variables. Again, let \\(v = \\dot x\\). Then we get \\[\nm\\dot v + cv^2 = 0.\n\\] Rearranging and solving for \\(v(t)\\), we have \\[\n\\frac{dv}{dt} = -\\frac{c}{m}v^2 \\quad \\Longrightarrow \\quad\n\\int_{v_0}^{v} \\frac{dv}{v^2} = -\\frac{c}{m} t \\quad \\Longrightarrow \\quad\nv(t) = \\frac{1}{\\frac{1}{v_0} + \\frac{c}{m}t}.\n\\] Integrating both sides and solving for the position, we get \\[\nx(t) = x_0 + \\int_0^t \\frac{dt}{\\frac{1}{v_0} + \\frac{c}{m}t} = x_0 + \\frac{m}{c}\\log\\bigg( 1 + \\frac{cv_0}{m}t \\bigg).\n\\] In this case, \\(v \\rightarrow 0\\), but \\(x \\rightarrow \\infty\\) as \\(t \\rightarrow \\infty\\). Evidently, while linear drag is strong enough to slow a moving particle back down to rest, quadratic drag is not.\n\n\n\n\n\nQuadratic drag is often used to model the drag experienced by objects moving through air or other media where pressure is more important than viscosity. For an object moving through air, drag is well-modeled by the drag equation, \\[\n\\mathbf{F}_d = -\\frac{1}{2}C \\rho A v^2 \\mathbf{e}_v,\n\\] where \\(\\rho\\) is the density of air, \\(A\\) is the cross-sectional area of the object in the direction of motion, and \\(C\\) is the drag coefficient. Since this force is proportional to \\(v^2\\), we evidently have \\[\nc = \\frac{1}{2}C \\rho A.\n\\]\n\n\nReynold’s Number\nIn practice, how can we tell if drag is in the linear or quadratic situation? A simple way to do this is by looking at the Reynold’s Number. Let’s go back to the full quadratic equation for drag, with \\(a\\) set to \\(0\\), \\[\nF_d = -bv - cv^2.\n\\] Notice that the ratio \\(\\frac{cv}{b}\\) gives the relative importance of the two drag terms. Using Stoke’s Law and the Drag Equation for the drag constants, we can re-write this expression as \\[\n\\frac{cv}{b} = \\frac{\\frac{1}{2}C \\rho Av}{6\\pi\\eta R} = \\frac{C \\rho Rv}{3\\eta}.\n\\] This ratio is usually rescaled by a factor of \\(\\frac{3}{C}\\) to get the Reynold’s number \\(r\\), \\[\nr = \\frac{\\rho Rv}{\\eta}.\n\\] The Reynold’s number is usually what’s used in practice to decide whether we’re in the linear or quadratic drag regime.\n\nWhen the Reynold’s number is low, \\(r \\ll 1\\), \\(v \\ll \\frac{\\eta}{R\\rho}\\), and we’re in the linear regime.\nWhen the Reynold’s number is high, \\(r \\gg 1\\), \\(v \\gg \\frac{\\eta}{R\\rho}\\), and we’re in the quadratic regime.\nThe edge case is when \\(r \\approx 1\\), or \\(v \\approx \\frac{\\eta}{R\\rho}\\). Then, we have to include both the linear and quadratic drag terms in the equation of motion. In this general case, there’s no analytic solution and we have to solve things numerically.\n\nThe Reynold’s number is usually easy to calculate since we can often at least roughly estimate the object’s velocity and radius, and we can usually look up the medium’s viscosity and density. For example, a baseball thrown in air at 100 mph would have a Reynold’s number of about \\(r \\approx 3 \\cdot 10^5 \\gg 1\\), which is solidly in the quadratic drag regime."
  },
  {
    "objectID": "classical-mechanics/simple-systems.html#harmonic-oscillation",
    "href": "classical-mechanics/simple-systems.html#harmonic-oscillation",
    "title": "Simple Systems",
    "section": "Harmonic Oscillation",
    "text": "Harmonic Oscillation\nThe next case we’ll consider is when the force is linear in position, \\[\n\\mathbf{F} = -k \\mathbf{x}.\n\\] This relationship is called Hooke’s Law. In the 1-dimensional case, it reduces to the equation of motion \\[\nm \\ddot x + kx = 0.\n\\] This is a second-order linear differential equation for \\(x(t)\\). The general solution to this differential equation depends on the sign of \\(k\\). If \\(k < 0\\), we have \\[\nx(t) = c_1 e^{\\frac{k}{m}t} + c_2 e^{-\\frac{k}{m}t}.\n\\] Since \\(x \\rightarrow \\infty\\) pretty quickly as \\(t \\rightarrow \\infty\\), this kind of solution is usually non-physical, except perhaps in situations where \\(x\\) is bounded between some known range.\nThe most important case by far is when \\(k > 0\\). In this setting, it’s typical to define \\(\\omega^2 \\equiv \\frac{k}{m}\\) and re-rewrite the equation as \\[\n\\ddot x + \\omega^2 x = 0.\n\\] This is called the simple harmonic oscillator or SHO. The canonical example of SHO is of course the motion of a mass attached to an ideal spring with spring constant \\(k\\).\nThe general solution to SHO is a linear combination of sine and cosine functions, \\[\nx(t) = c_1 \\cos \\omega t + c_2 \\sin \\omega t.\n\\] This trajectory is oscillatory and stable since it only involves sines and cosines, both of which are bounded periodic functions. It’s custom to re-write this equation in a more useful form using trig identities,\n\n\n\n\n\n\\[\n\\begin{align*}\nx(t) &= c_1 \\cos \\omega t + c_2 \\sin \\omega t \\\\\n&= A\\bigg(\\frac{c_1}{A}\\cos \\omega t + \\frac{c_2}{A}\\sin\\omega t \\bigg) \\\\\n&= A(\\cos\\delta \\cos \\omega t + \\sin\\delta\\sin\\omega t) \\\\\n&= A\\cos(\\omega t - \\delta). \\\\\n\\end{align*}\n\\] In this form, \\(A\\) is the amplitude of oscillation and \\(\\delta\\) is the phase of oscillation. The period of oscillation is given by \\[\n\\tau = \\frac{2\\pi}{\\omega} = 2\\pi\\sqrt{\\frac{m}{k}}.\n\\]\n\n\n\n\n\nIt’s usually convenient when dealing with harmonic oscillators to work in the complex plane. Consider the complex form of SHO, given by the differential equation \\[\n\\ddot z + \\omega^2 z = 0,\n\\] where \\(z = x+iy = |z|e^{i\\theta}\\) is a complex variable. Its general solution is given as a linear combination of complex exponentials, \\[\nz(t) = \\tilde c_1 e^{i\\omega t} + \\tilde c_2 e^{-i\\omega t}.\n\\] If we demand that the real solution we seek be given by \\(x(t) = \\text{Re}(z(t))\\), then\n\\[\n\\begin{align*}\nx(t) &= \\Re(c_1 e^{i \\omega t}) + \\Re(c_2 e^{-i \\omega t}) \\\\\n&= \\frac{1}{2}(c_1 + c_2^*)e^{i \\omega t} + \\frac{1}{2}(c_1^* + c_2)e^{-i \\omega t} \\\\\n&= \\frac{1}{2} C e^{i \\omega t} + \\frac{1}{2} C^* e^{-i \\omega t} \\\\\n&= A \\cdot \\Re(e^{i(\\omega t - \\delta)}) \\\\\n&= A \\cos(\\omega t - \\delta),\n\\end{align*}\n\\] where \\(C \\equiv Ae^{i \\delta}\\) is some complex number whose real and imaginary parts are \\(c_1+c_2^*\\) and \\(c_1^*+c_2\\) respectively. For the full complex solution we can similarly write \\[\nz(t) = A e^{i(\\omega t - \\delta)}\n\\] Evidently then, SHO is just a CCW circular rotation in the complex plane with radius \\(A\\).\n\n\n\n\n\n\n\nExample: Bottle sloshing in a bucket\nSuppose a bottle of mass \\(m\\) floats calmly in a bucket of water of density \\(\\rho\\) at some equilibrium depth of \\(d=d_0\\). Suppose we push down slightly on the bottle, perturbing its depth to \\(d = d_0 + x\\). The bottle will begin to oscillate. Find its period of oscillation \\(\\tau\\).\n\n\n\n\n\nThe forces on the bottle are gravity downward and an opposing buoyant force upward, \\[\nF = mg - \\rho g V_{sub} = mg - \\rho g A(d_0 + x).\n\\] At equilibrium, the forces must balance, so \\(0 = mg - \\rho g A d_0\\), which means \\(d_0 = \\frac{m}{\\rho A}\\) is the equilibrium depth. Simplifying, this says the equation of motion is given by \\[\nm \\ddot x = mg - \\rho g A(d_0 + x) = -\\rho g A x = -\\frac{mg}{d_0} x.\n\\] This is just SHO with spring constant \\(k = \\frac{mg}{d_0}\\), or angular frequency \\(\\omega = \\frac{g}{d}\\). Thus, the period of the bottle’s oscillation when \\(x\\) is small is given by \\[\n\\tau = \\frac{2 \\pi}{\\omega} = 2\\pi\\sqrt{\\frac{d_0}{g}}.\n\\]\n\n\n\nTwo-Dimensional Harmonic Oscillation\nSuppose now we allow a mass to move in two dimensions. Hooke’s Law becomes\n\\[\n\\begin{align*}\nm \\ddot x &= -k_x x, \\\\\nm \\ddot y &= -k_y y.\n\\end{align*}\n\\] Since the equation of motions are uncoupled, the solutions are simply given by\n\\[\n\\begin{align*}\nx(t) &= A_x \\cos(\\omega_x t - \\delta_x), \\\\\ny(t) &= A_y \\cos(\\omega_y t - \\delta_y).\n\\end{align*}\n\\] Despite what intuition might suggest, the motion of the mass is now quite non-trivial. In fact, the behavior of the trajectory depends entirely on the ratio of the frequencies \\(\\frac{\\omega_x}{\\omega_y}\\) and the relative phase between the two oscillations \\(\\delta = \\delta_x - \\delta_y\\).\nThe motion will only be periodic if \\(\\frac{\\omega_x}{\\omega_y}\\) is rational, i.e. if the frequencies are integer multiples of each other. The curves traced out by \\((x(t), y(t))\\) when \\(\\frac{\\omega_x}{\\omega_y}\\) is rational are called Lissajous curves. They can get quite complicated, but they’ll always be periodic. Here’s what a few of them look like for different\\(\\frac{\\omega_x}{\\omega_y}\\) and \\(\\delta\\).\n\n\n\n\n\n\n\nExample: Charged particle in a uniform magnetic field\nSuppose a particle with charge \\(q\\) and mass \\(m\\) is moving in the presence of a constant magnetic field \\(\\mathbf{B}\\). Find its equations of motion, solve for the trajectory, and describe what it looks like.\n\n\n\n\n\nIf \\(\\mathbf{v}\\) is the velocity of the particle, the magnetic force is given by \\(\\mathbf{F} = \\frac{q}{c} \\mathbf{v} \\times \\mathbf{B}\\). Suppose \\(\\mathbf{B} = B \\mathbf{e}_z\\). Then \\[\n\\mathbf{F} = \\frac{q}{c}\\mathbf{v} \\times \\mathbf{B} = \\frac{qB}{c}(\\dot y \\mathbf{e}_x - \\dot x \\mathbf{e}_y),\n\\] The equations of motion are thus\n\\[\n\\begin{align*}\nm \\ddot x &= \\frac{qB}{c} \\dot y , \\\\\nm \\ddot y &= -\\frac{qB}{c} \\dot x , \\\\\nm \\ddot z &=  0. \\\\\n\\end{align*}\n\\] Define \\(\\omega \\equiv \\frac{qB}{c}\\). The first two equations can be decoupled to give two independent SHO equations in the velocities,\n\\[\n\\begin{align*}\n\\ddot v_x &= -\\omega^2 v_x , \\\\\n\\ddot v_y &= -\\omega^2 v_y , \\\\\n\\end{align*}\n\\] with solutions\n\\[\n\\begin{align*}\nv_x(t) &= V_x \\cos(\\omega t - \\delta_x) , \\\\\nv_y(t) &= V_y \\cos(\\omega t - \\delta_y)  , \\\\\n\\end{align*}\n\\] Now, since \\(\\ddot v_x = \\omega \\dot v_y\\), we must have \\(V_x = V_y\\) and \\(\\delta_y = \\delta_x - \\frac{\\pi}{2}\\). Taking \\(\\delta_x=0\\) and \\(V_x = R\\omega\\) for convenience, we get\n\\[\n\\begin{align*}\nv_x(t) &= R\\omega \\cos(\\omega t) , \\\\\nv_y(t) &= -R\\omega \\sin(\\omega t)  , \\\\\n\\end{align*}\n\\] Finally, integrating the velocity equations gives the trajectory,\n\\[\n\\begin{align*}\nx(t) &=  x_0 + R \\sin(\\omega t), \\\\\ny(t) &= (y_0 - R) + R \\cos(\\omega t) , \\\\\nz(t) &=  z_0 + v_{0z} t. \\\\\n\\end{align*}\n\\] This is just a helix of radius \\(R\\) directed along the z-axis. That is, the particle will just spiral around in a helix directed along the line of the magnetic field. The frequency \\(\\omega\\) is called the cyclotron frequency. Since charge can be positive or negative, it carries a sign, which determines which way the particle will spiral. Notice that \\(R\\) is just the radius of orbit. It’s customarily expressed in terms of the tangential velocity \\(v_\\perp = \\sqrt{v_x^2 + v_y^2} = R\\omega\\), \\[\nR = \\frac{mcv_\\perp}{qB}.\n\\]"
  },
  {
    "objectID": "classical-mechanics/simple-systems.html#damped-harmonic-oscillation",
    "href": "classical-mechanics/simple-systems.html#damped-harmonic-oscillation",
    "title": "Simple Systems",
    "section": "Damped Harmonic Oscillation",
    "text": "Damped Harmonic Oscillation\nLet’s now combine the forces of linear drag with the forces of harmonic oscillation. In the 1-dimensional case, this gives the damped harmonic oscillator or DHO, \\[\nm \\ddot x + bx + kx = 0.\n\\] Define \\(\\beta \\equiv \\frac{b}{2m}\\) and \\(\\omega_0 \\equiv \\sqrt{\\frac{k}{m}}\\), called the damping constant and the natural frequency respectively. Then we can write the DHO equation of motion as \\[\n\\ddot x + 2\\beta x + \\omega_0^2 x = 0.\n\\] It’ll be insightful to solve this in its complex form. Consider instead the equation \\[\n\\ddot z + 2\\beta z + \\omega_0^2 z = 0,\n\\] where \\(z\\) is complex-valued. Let’s try and assume a trial solution of the form \\(z = A e^{i\\omega t - \\delta}\\). Plugging this into the differential equation, we get \\[\n(-\\omega^2 + 2\\beta + \\omega_0^2)A e^{i\\omega t - \\delta} = 0.\n\\] In the non-trivial case \\(A \\neq 0\\), this implies \\((-\\omega^2 + 2\\beta + \\omega_0^2) = 0\\), which we can solve for \\(\\omega\\) to get \\[\n\\omega = i\\beta \\pm \\sqrt{\\omega_0^2 - \\beta^2} \\equiv i\\beta \\pm \\omega',\n\\] where \\(\\omega' \\equiv \\sqrt{\\omega_0^2 - \\beta^2}\\). Plugging this into \\(z\\) then gives \\[\nz(t) = e^{-\\beta t}(c_1 e^{i\\omega' t} + c_2 e^{-i\\omega' t}).\n\\] When dealing with damped systems, it’s customary to define a quality factor \\(Q \\equiv \\frac{\\omega_0}{2\\beta}\\), which expresses in relative terms how much the system is being damped. We can re-write \\(\\omega'\\) in terms of the Q-factor as \\[\n\\omega' = \\omega_0 \\sqrt{1 - \\bigg(\\frac{1}{2Q}\\bigg)^2}.\n\\] Evidently, the form of the solutions divide into three cases depending on the sign of \\(\\omega'\\):\n\nUnderdamping (\\(\\omega' > 0\\) or \\(Q < \\frac{1}{2}\\)): In this case, \\(\\omega'\\) is real, which means we have a real solution \\[\nx(t) = A e^{-\\beta t} \\cos(\\omega't - \\delta).\n\\] This is an exponentially damped sinusoidal oscillation, where \\(x \\rightarrow 0\\) with time constant \\(\\tau = \\frac{1}{\\beta}\\). Notice \\(\\omega' < \\omega_0\\), which means the actual frequency of the oscillation is less than the natural frequency. When \\(Q \\gg 1\\) this distinction disappears, since \\(\\omega' \\approx \\omega_0\\). In practice this occurs frequently for underdamped solutions, and \\(Q\\) need not even be large for \\(\\omega' \\approx \\omega_0\\).\n\n\n\n\n\nOverdamping (\\(\\omega' < 0\\) or \\(Q > \\frac{1}{2}\\)): In this case, \\(\\omega'\\) is complex. Define \\(\\kappa \\equiv i\\omega'\\), which is real-valued. Then we have a solution of the form \\[\nx(t) = e^{-\\beta t}(c_1 e^{\\kappa t} + c_2 e^{-\\kappa t}).\n\\] Since \\(\\kappa < \\beta\\), \\(x \\rightarrow 0\\) monotonically, with time constant \\(\\tau = \\frac{1}{\\beta - \\kappa}\\).\n\n\n\n\n\nCritical damping (\\(\\omega' = 0\\) or \\(Q = \\frac{1}{2}\\)): This is the edge case where \\(\\omega_0 = \\beta\\) exactly. Here the solution is degenerate, with \\[\nx(t) = (c_1 + c_2 t) e^{-\\beta t}.\n\\] Again, \\(x \\rightarrow 0\\), but with time constant \\(\\tau = \\frac{1}{\\beta}\\). Evidently, the critically damped solution decays faster than the overdamped solution.\n\n\n\n\n\n\nIn all three cases the system must eventually come to rest due to the presence of damping. Only the “high Q” systems are allowed to oscillate. Note that as \\(\\beta \\rightarrow 0\\), \\(Q \\rightarrow \\infty\\). In this limit the solution turns into regular SHO, with \\(\\omega' \\rightarrow \\omega_0\\)."
  },
  {
    "objectID": "classical-mechanics/simple-systems.html#driven-damped-harmonic-oscillation",
    "href": "classical-mechanics/simple-systems.html#driven-damped-harmonic-oscillation",
    "title": "Simple Systems",
    "section": "Driven Damped Harmonic Oscillation",
    "text": "Driven Damped Harmonic Oscillation\nLet’s now add in the independent force term to the mix. In the 1-dimensional case, we get the equation of motion \\[\nm \\ddot x + b \\dot x + kx = F_0(t).\n\\] This is called the driven damped harmonic oscillator or DDHO. We imagine \\(F_0(t)\\) to be some external driving force acting on the system. It’s again convenient to rewrite things by defining \\(\\beta = \\frac{b}{2m}\\), \\(\\omega_0^2 = \\frac{k}{m}\\), and \\(f(t) = \\frac{F_0(t)}{m}\\). Then we have the linear differential equation \\[\n\\ddot x + 2\\beta\\dot x + \\omega_0^2 x = f(t).\n\\] Recall that the solutions of linear differential equations can be decomposed into two pieces, a homogenous solution and a particular solution. The homogenous solution is the general solution to \\[\n\\ddot x_h + 2\\beta\\dot x_h + \\omega_0^2 x_h = 0.\n\\] But this is just a DHO. We solved that part already. All we need to do now is find any particular solution that will solve \\[\n\\ddot x_p + 2\\beta\\dot x_p + \\omega_0^2 x_p = f(t).\n\\] Provided we do that, the full, general solution will be \\(x(t) = x_h(t) + x_p(t)\\). There are several ways to find a particular solution, including guessing methods and more systematic methods like Green functions and Fourier transforms. We’ll briefly touch on some of these.\n\n\nExample: Underdamped hanging spring\nSuppose a spring is suspended vertically from a ceiling under the presence of gravity. Find the position \\(x=x(t)\\). Also, find the amount that gravity changes the spring’s equilibrium length.\n\n\n\n\n\nThe forces in this problem are gravity, linear drag, and a spring force, so if \\(x\\) points downward, \\[\nF = mg - bv - kx.\n\\] The equation of motion is thus given by \\[\nm \\ddot x + b \\dot x + kx = mg.\n\\] This is just DDHO with \\(f(t) = g\\). We thus seek a particular solution \\(x_p(t)\\) such that \\[\n\\ddot x_p + 2\\beta\\dot x_p + \\omega_0^2 x_p = g.\n\\] Assume a trial solution of the form \\(x_p = c\\). Then, \\[\n\\omega_0^2 c = g \\Longrightarrow c = \\frac{g}{\\omega_0^2} = \\frac{gm}{k}.\n\\] Supposing the spring is underdamped, then \\[\nx(t) = Ae^{-\\beta t} \\cos(\\omega' t - \\delta) + \\frac{gm}{k}.\n\\] The new equilibrium occurs when the object is at rest, i.e. when \\(\\ddot x = \\dot x = 0\\). This occurs at \\(x = \\frac{gm}{k}\\) relative to the free equilibrium \\(x=0\\).\n\n\n\nSinusoidal Driving Forces\nThe most interesting driving forces in practice are ones that are periodic. Periodic driving functions lead to the important concept of resonance, which is a phenomenon that occurs when the driving frequency matches the natural frequency.\nConsider a sinusoidal driving force of the form \\(f(t) = f_0 \\cos\\omega t\\). In complex form, we can then write \\[\n\\ddot z + 2\\beta\\dot z + \\omega_0^2 z = f_0 e^{i \\omega t}.\n\\] Assume a particular solution of the form \\(z(t) = \\tilde A e^{i \\omega t}\\) where \\(\\tilde A = Ae^{-i\\delta}\\). Plugging this in, we have \\[\n(-\\omega^2 + 2\\beta\\omega i + \\omega_0^2)\\tilde A e^{-i\\omega t} = f_0 e^{i\\omega t},\n\\] which we can solve for the complex amplitude \\(\\tilde A\\) to get \\[\n\\tilde A = \\frac{f_0}{(\\omega_0^2-\\omega^2) + 2\\beta\\omega i}.\n\\] With the help of little trig, we can decompose this solution to get the real amplitude and phase,\n\n\n\n\n\n\\[\nA = \\frac{f_0}{\\sqrt{(\\omega_0^2-\\omega^2)^2 + 4\\beta^2\\omega^2}}, \\quad \\delta = \\tan^{-1} \\frac{2\\beta\\omega}{\\omega_0^2-\\omega^2}.\n\\]\nWith these, the real particular solution is given by \\(x_p(t) = A \\cos(\\omega t - \\delta)\\). Since the homogenous solution decays to zero exponentially, \\(x \\rightarrow x_p\\) as \\(t \\rightarrow \\infty\\). That is, \\(x_p(t)\\) describes the steady state solution of the DDHO. In this sense, the system evidently “forgets” its own natural frequency and starts to oscillate at the driving frequency as time goes on and the transient state dies off.\n\n\n\n\n\nInterestingly, the memory of the transient dynamics is preserved in the amplitude and phase. As a rule of thumb, the number of oscillations \\(N\\) until \\(x \\approx x_p\\) is basically just the Q-factor, \\[\nN \\approx \\frac{Q}{\\pi}.\n\\] Let’s now look more deeply at the amplitude and phase. It’s worth asking how they depend on the external driving frequency \\(\\omega\\).\n\nWhen \\(\\omega \\ll \\omega_0\\), \\(A \\approx \\frac{f_0}{\\omega_0^2}\\) and \\(\\delta \\approx 0\\).\nWhen \\(\\omega \\gg \\omega_0\\), \\(A \\approx 0\\) and \\(\\delta \\approx \\pi\\).\nWhen \\(\\omega \\approx \\omega_0\\), \\(A \\approx \\frac{f_0}{2\\beta\\omega_0}\\) and \\(\\delta \\approx \\frac{\\pi}{2}\\).\n\n\n\n\n\n\nEvidently, \\(A\\) is maximized at \\(\\omega_R = \\sqrt{\\omega_0^2-2\\beta^2} = \\omega_0 \\sqrt{1-\\frac{1}{2Q^2}}\\). When \\(Q>1\\), \\(\\omega_R \\approx \\omega_0\\), so this distinction doesn’t really matter. This frequency \\(\\omega_R \\approx \\omega_0\\) is called the resonance frequency of the system. When the driver is operating near the resonance frequency, the system responds extremely well to the driving force. It turns out that when a spectrum of frequencies is dumped on an oscillating system, the system tends to pick out the resonance frequencies and respond to those. This fact makes resonance a very important topic in physics and engineering.\nIn practice, high-Q systems are very common. In those cases, \\(A\\) dies off quickly when the driving frequencies aren’t close to \\(\\omega_0\\). That means practically all the interesting behavior of a high-Q systems is in the band around the resonance frequency. Suppose \\(\\Delta \\equiv \\omega - \\omega_0\\) is small. Then we can write \\[\n(\\omega_0^2-\\omega^2) = (\\omega_0-\\omega)(\\omega_0+\\omega) = -\\Delta(2\\omega_0+\\Delta) \\approx -2\\omega_0 \\Delta.\n\\] That means we can write the complex amplitude \\(\\tilde A\\) as \\[\n\\tilde A = \\frac{f_0}{(\\omega_0^2-\\omega^2) + 2\\beta\\omega i} \\approx -\\frac{\\frac{f_0}{2\\omega_0}}{\\Delta-\\beta i} = \\frac{f_0}{2\\omega_0}\\bigg(-\\frac{\\Delta}{\\Delta^2+\\beta^2} + i\\frac{\\beta}{\\Delta^2+\\beta^2} \\bigg).\n\\] This function on the right is called the Lorentzian. Using this, we can see \\[\nA \\approx \\frac{f_0}{2\\omega_0} \\frac{1}{\\sqrt{\\Delta^2 + \\beta^2}} \\quad \\Longrightarrow \\quad A^2 \\approx \\bigg(\\frac{f_0}{2\\omega_0}\\bigg)^2 \\frac{1}{\\Delta^2 + \\beta^2}.\n\\] Since the energy in a harmonic oscillator is just \\(E = \\frac{1}{2}kA^2 \\propto A^2\\), it’s common to look at plots of \\(A^2\\) when plotting these resonance curves. Evidently, \\(A^2 \\rightarrow 0\\) as \\(\\Delta \\rightarrow \\infty\\), and it’s maximized when \\(\\Delta = 0\\), which is when \\(\\omega = \\omega_0\\) and \\(A_{max}^2 = \\big(\\frac{f_0}{2\\omega_0 \\beta}\\big)^2\\).\nIt’s common to measure the width of the resonance curve by using the full width at half maximum or FWHM. The FWHM is defined as the difference between the left and right points around the maximum whose height is half the maximum, \\[\nFWHM \\equiv \\Delta \\omega \\equiv \\omega_R - \\omega_L, \\quad \\text{where} \\quad A^2(\\omega_L) = A^2(\\omega_R) = \\frac{1}{2}A_{max}.\n\\] Solving for these left and right points gives \\(\\omega_L = \\omega_0 - \\beta\\) and \\(\\omega_R = \\omega_0 + \\beta\\), so \\[\n\\Delta \\omega = (\\omega_0 + \\beta) - (\\omega_0 - \\beta) = 2\\beta.\n\\] The resolving power of the resonance curve is then \\[\n\\frac{\\omega_0}{\\Delta} = \\frac{\\omega_0}{2\\beta} = Q.\n\\] Evidently then, \\(Q\\) represents the resolving power of the resonance curve. The higher the Q-factor is, the more sharply peaked the resonance curve is, and the easier we can pinpoint the resonance frequency exactly. Indeed, this is why \\(Q\\) is called a quality factor.\n\n\n\n\n\nOne very important system where we want a high-Q is a clock. To keep precise time, we need to make sure that it’s oscillating pretty much exactly at its resonance frequencies. This is because we need to keep a regular period, so \\(\\tau = \\frac{2\\pi}{\\omega}\\) can’t be allowed to vary very much from the true period \\(\\tau_0 = \\frac{2\\pi}{\\omega_0}\\). There’s a tradeoff though. Since the decay time of the transient behavior is \\(N\\tau_0 \\equiv \\frac{1}{\\beta}\\), it takes about \\(N=\\frac{Q}{\\pi}\\) cycles of ringing for the system to come to steady state. So the better precision we want, the longer we’ll have to wait for the system to come to steady state.\nNote that \\(Q\\) also affects the phase curve of the system, since \\[\n\\delta = \\tan^{-1} \\frac{2\\beta\\omega}{\\omega_0^2-\\omega^2} \\approx \\tan^{-1} \\frac{2\\omega}{Q\\Delta}.\n\\] Evidently as \\(Q\\) increases, the system becomes more responsive to sudden changes in phase around \\(\\omega_0\\).\n\n\n\n\n\n\n\nArbitrary Driving Forces\nThe situation where resonance occurs in a DDHO system is not just confined to sinusoidal driving forces. Using Fourier analysis, we can decompose more arbitrary driving forces into a sum of sinusoidal driving forces of different frequencies. The simplest of these cases is when the driving force is periodic with some period \\(\\tau\\). Even if the driver isn’t sinusoidal, we can decompose it into a linear combination of cosines of different frequencies, i.e. a Fourier Series, \\[\nf(t) = \\sum_{n=-\\infty}^{\\infty} f_n e^{i \\omega n t},\n\\] where each \\(f_n\\) can be found via the formula \\[\nf_n = \\langle f(t), e^{i \\omega n t} \\rangle = \\frac{\\omega}{\\pi} \\int_0^{\\tau} f(t) e^{i \\omega n t} dt.\n\\] Using the principle of superposition, we could then find the solution for each of the sinusoidal drivers term by term, and then sum them together to get the full solution. Each term will have amplitude and phase \\[\nA_n = \\frac{f_n}{\\sqrt{(\\omega_0^2-\\omega^2 n^2)^2 + (2\\beta\\omega n)^2}}, \\quad \\delta_n = \\tan^{-1} \\frac{2\\beta\\omega n}{\\omega_0^2-\\omega^2n^2}.\n\\] Plugging these in will yield a general solution of the form \\[\nx(t) = x_h(t) + \\sum_{n=1}^{\\infty} A_n \\cos(\\omega n t - \\delta_n).\n\\] Each component will yield its own resonance frequency where \\(\\omega n \\approx -\\omega_0\\). As a function of the main driving frequency, this means there will resonances at each \\(\\omega_n = \\frac{\\omega_0}{n}\\). The resonance curve for \\(A^2\\) can be found via Parseval’s Theorem, which says \\[\nA^2 = \\langle x^2(t) \\rangle = \\frac{1}{2} \\sum_{n=0}^\\infty A_n^2.\n\\] The peaks evidently go to zero as \\(n \\rightarrow \\infty\\) since each \\(A_n^2 \\propto f_n^2\\) and each \\(f_n \\rightarrow 0\\) by the Riemann–Lebesgue lemma.\n\n\n\n\n\nWhat if the driving force isn’t periodic? In this case we have a few options. One would be to decompose it into its Fourier transform, \\[\nf(t) = \\int_{-\\infty}^{\\infty} f(\\omega) e^{i\\omega t} dt.\n\\] Then each term gives a set of complex amplitudes and phases that can be solved for and stitched back together to get \\(x(t)\\). Another solution that’s perhaps more common is to use Green’s functions. Instead of decomposing the driver into a linear combination of periodic functions, we’ll decompose it into a linear combination of impulse responses or delta functions, \\[\nf(t) = \\int_{-\\infty}^{\\infty} f(t') \\delta(t-t') dt'.\n\\] To find the solution \\(x(t)\\), we first need to find the particular solution \\(G(t-t')\\) to the DDHO with an impulse response, \\[\n\\ddot G + 2\\beta\\dot G + \\omega_0^2 G = \\delta(t - t').\n\\] Once this is found, we can stitch together the full solution as \\[\nx(t) = \\int_{-\\infty}^{\\infty} f(t') G(t-t') dt'.\n\\] Note the Green’s function solution already incorporates in the homogeneous solution since \\(G(t-t')\\) must itself satisfy the initial conditions."
  },
  {
    "objectID": "classical-mechanics/reference-frames.html#orthogonal-transformations",
    "href": "classical-mechanics/reference-frames.html#orthogonal-transformations",
    "title": "Reference Frames",
    "section": "Orthogonal Transformations",
    "text": "Orthogonal Transformations\nSuppose \\(\\mathbf{x}\\) is some vector, and \\(\\{\\mathbf{e}_i\\}\\) and \\(\\{\\mathbf{e}_i'\\}\\) are two orthonormal bases for \\(\\mathbb{R}^3\\), then \\[\n\\mathbf{x} = \\sum_{j=1}^3 x_j \\mathbf{e}_j = \\sum_{i'=1}^3 x_{i'} \\mathbf{e}_{i'},\n\\] where \\(x_i = \\mathbf{x} \\cdot \\mathbf{e}_i\\) and \\(x_i' = \\mathbf{x} \\cdot \\mathbf{e}_i'\\).\nNotation: From now on we’ll use the Einstein summation convention. If a repeated index occurs in a sum, we’ll omit the \\(\\sum\\) symbol. For example, we can re-write the above line as the following, where it’s understood we’re summing over \\(j\\) and \\(i'\\) in each case, \\[\n\\mathbf{x} = x_j \\mathbf{e}_j = x_{i'} \\mathbf{e}_{i'}.\n\\] Now, observe we can write one component in terms of the other as \\[\nx_i' = \\mathbf{x} \\cdot \\mathbf{e}_{i'} = (\\mathbf{e}_j \\cdot \\mathbf{e}_{i'}) x_j \\equiv R_{i'j} x_j,\n\\] where \\(R_{i'j} = \\mathbf{e}_j \\cdot \\mathbf{e}_i'\\) defines a matrix \\(\\mathbf{R}\\) called an orthogonal transformation.\nNotice that if we take the inner product of two vectors \\(\\mathbf{x}\\) and \\(\\mathbf{y}\\), we get \\[\n\\mathbf{x} \\cdot \\mathbf{y} = x_{i'} \\delta_{i' j'} x_{j'} = R_{ii'} \\delta_{i'j'} R_{j'j} x_i x_j = \\mathbf{x} \\cdot (\\mathbf{R}^\\top \\mathbf{R}) \\mathbf{y}.\n\\] Thus, an orthogonal transformation \\(\\mathbf{R}\\) satisfies the property that \\[\n\\mathbf{R}^\\top \\mathbf{R} = \\mathbf{I}, \\quad \\text{or} \\quad R_{ij} R_{jk} = \\delta_{ik}.\n\\] Due to the inner product preserving nature of orthogonal transformations, they can in a sense be used to define what we mean by a scalar or vector or tensor in classical mechanics. They’re objects that transform a certain way under an orthogonal transformation:\n\nA scalar is any object \\(\\alpha\\) that is invariant under an orthogonal transformation, \\[\n\\alpha' = \\alpha.\n\\]\nA vector is any object \\(\\mathbf{v}\\) that transforms under an orthogonal transformation as, \\[\nv_{i'} = R_{i'i} v_i.\n\\]\nA tensor of order \\(k\\) is any object \\(\\mathbf{T}\\) that transforms under an orthogonal transformation as, \\[\nT_{i_1' i_2' \\cdots i_k'} = R_{i_1' i_1} R_{i_2' i_2} \\cdots R_{i_k' i_k} T_{i_1 i_2 \\cdots i_k}.\n\\]\n\nNotice since \\(\\mathbf{R}^\\top \\mathbf{R} = \\mathbf{I}\\), we can take the determinant of both sides to get \\(\\det(\\mathbf{R}^\\top \\mathbf{R}) = \\det^2(\\mathbf{R}) = 1\\), which implies that \\(\\det(\\mathbf{R}) = \\pm 1\\). This fact divides orthogonal transformations into two distinct classes:\n\nProper Rotations (\\(\\det(\\mathbf{R}) = 1\\)): These correspond to pure rotations in space. They preserve the handedness of the underlying coordinate system.\nImproper Rotations (\\(\\det(\\mathbf{R}) = -1\\)): These correspond to reflections in space, which are transformations \\(\\mathbf{v} \\Rightarrow -\\mathbf{v}\\) combined with a pure rotation. These transformations permute the handedness of the underlying coordinate system.\n\n\n\n\n\n\nMost vector operations are proper, in the sense that they preserve the handedness of the underlying coordinate system. If \\(\\mathbf{v}\\) is a vector, they’ll transform under a reflection to \\(-\\mathbf{v}\\). The one major exception is the cross product, which reverses the handedness. Under a reflection, it keeps its sign, \\[\n\\mathbf{v} \\times \\mathbf{w} \\Rightarrow (-\\mathbf{v}) \\times (-\\mathbf{w}) = \\mathbf{v} \\times \\mathbf{w}.\n\\] For this reason, cross products are sometimes called pseudovectors or axial vectors to distinguish them from ordinary vectors that transform under a reflection as \\(\\mathbf{v} \\Rightarrow -\\mathbf{v}\\).\nAside: It turns out that the set of all orthogonal transformations on \\(\\mathbb{R}^3\\) form a group \\(G\\), in the sense that it satisfies the following special “symmetry” properties:\n\nClosure: If \\(A, B \\in G\\) , then \\(AB \\in G\\) also.\nAssociativity: For any \\(A,B,C \\in G\\), we have \\((AB)C = A(BC)\\).\nIdentity: There is a unique element \\(I \\in G\\) satisfying \\(IA = AI\\) for any \\(A \\in G\\).\nInvertibility: For any \\(A \\in G\\), there is an inverse element \\(A^{-1}\\) such that \\(A^{-1} A = A A^{-1} = I\\).\n\nThe group of orthogonal transformations under matrix multiplication is called the orthogonal group, denoted \\(O(3)\\). The subset of \\(O(3)\\) where \\(\\det(\\mathbf{R})=1\\) happens to form a subgroup, i.e. a subset of \\(O(3)\\) that’s closed under group operations. It’s called the special orthogonal group, denoted \\(SO(3)\\). This is essentially the group of all rotations in 3 dimensions. The orthogonal groups turn out to be very important in understanding the theory of angular momentum, especially in quantum mechanics.\n\nExample: Rotations in two dimensions\nWe can easily figure out what proper rotations look like in 2D space by looking at how to relate one basis with another. Suppose \\(\\{\\mathbf{e}_x, \\mathbf{e}_y \\}\\) is the standard basis for \\(\\mathbb{R}^2\\), and \\(\\{\\mathbf{e}_{x'}, \\mathbf{e}_{y'}\\}\\) is some other orthonormal basis. Suppose \\(\\varphi\\) is the angle between \\(\\mathbf{e}_x\\) and \\(\\mathbf{e}_{x'}\\). Using a little geometry, we have,\n\n\n\n\n\n\\[\n\\begin{align*}\nR_{x'x} &= \\mathbf{e}_{x'} \\cdot \\mathbf{e}_x = \\cos\\varphi,\n&R_{x'y} &= \\mathbf{e}_{x'} \\cdot \\mathbf{e}_y = \\sin\\varphi, \\\\\nR_{y'x} &= \\mathbf{e}_{y'} \\cdot \\mathbf{e}_x = -\\sin\\varphi,\n&R_{y'y} &= \\mathbf{e}_{y'} \\cdot \\mathbf{e}_y = \\cos\\varphi. \\\\\n\\end{align*}\n\\] We can thus express any proper rotation in \\(\\mathbb{R}^2\\) using a \\(2 \\times 2\\) matrix of the form \\[\n\\mathbf{R}(\\varphi) =\n\\begin{pmatrix}\n\\cos\\varphi & \\sin\\varphi \\\\\n-\\sin\\varphi & \\cos\\varphi\n\\end{pmatrix}.\n\\] This is the matrix that rotates the underlying basis \\(\\{\\mathbf{e}_x, \\mathbf{e}_y \\}\\) to the new, rotated basis \\(\\{\\mathbf{e}_{x'}, \\mathbf{e}_{y'} \\}\\).\n\n\nActive vs Passive Transformations\nThe previous example suggests that we can think about a rotation in space two different ways. One way is to rotate the underlying basis and keep the vector \\(\\mathbf{v}\\) fixed. That is, \\(\\mathbf{e}_i \\Rightarrow R_{i'i} \\mathbf{e}_i\\).. This way of looking at a rotation is called a passive transformation. It rotates the coordinate system under \\(\\mathbf{v}\\), not \\(\\mathbf{v}\\) itself.\nAnother way of looking at a rotation is to imagine keeping the coordinate system fixed, but rotating the components of the vector \\(\\mathbf{v}\\) directly. That is, \\(v_i \\Rightarrow R_{i'i}v_i\\). This way of looking at a rotation is called an active transformation. Despite sounding semantically different, these two ways are physically equivalent. Note though that if a vector rotates actively under \\(\\mathbf{R}(-\\varphi)\\), it will rotate passively under \\(\\mathbf{R}(\\varphi)\\).\n\n\n\n\n\nIt’s usually more convenient to assume rotations are active transformations. The major exception is when dealing with rigid bodies, where it’s more convenient to passively transform to body coordinates. Note the same logic applies to 3D transformations. In that case, there are now three angles of rotation to deal with, not just one."
  },
  {
    "objectID": "classical-mechanics/reference-frames.html#linearly-accelerating-frames",
    "href": "classical-mechanics/reference-frames.html#linearly-accelerating-frames",
    "title": "Reference Frames",
    "section": "Linearly Accelerating Frames",
    "text": "Linearly Accelerating Frames\nLet’s now examine the motion of systems in non-inertial reference frames. In examining accelerating frames, we’ll treat them as static coordinate systems, completely ignoring the forces that cause the reference frame to accelerate in the first place. We’ll start with linearly accelerating frames.\nSuppose a system is “locked into” a reference frame \\(S_{rel}\\), which is itself moving at a velocity \\(\\mathbf{v}_0\\) with respect to an inertial lab frame \\(S\\). We’ll seek out the equations of motion with respect to the non-inertial frame \\(S_{rel}\\).\n\n\n\n\n\nEvidently, \\(\\mathbf{x} = \\mathbf{x}_{rel} + \\mathbf{v}_0t\\), which means \\(\\mathbf{v} = \\mathbf{v}_{rel} + \\mathbf{v}_0\\), and \\(\\mathbf{a} = \\mathbf{a}_{rel} + \\mathbf{a}_0\\). When \\(\\mathbf{a}_0=\\mathbf{0}\\) we recover the special case of a Galilean transformation. In that case, \\(\\mathbf{F} = m \\mathbf{a} = m \\mathbf{a}_{rel}\\), which means \\(S_{rel}\\) is by definition an inertial frame.\nIf \\(\\mathbf{a}_0 \\neq \\mathbf{0}\\), we get \\(\\mathbf{F} = m(\\mathbf{a}_0 + \\mathbf{a}_{rel})\\), or \\(m\\mathbf{a}_{rel} = \\mathbf{F} - m \\mathbf{a}_0\\). We can think about this in another way, by defining a relative force \\(\\mathbf{F}_{rel} = m\\mathbf{a}_{rel}\\) and thinking of it as being composed of an inertial force \\(\\mathbf{F}\\) along with a fictitious force \\(\\mathbf{F}_{lin} = -m\\mathbf{a}_0\\), \\[\n\\mathbf{F}_{rel} = \\mathbf{F} + \\mathbf{F}_{lin} = \\mathbf{F} - m \\mathbf{a}_0.\n\\] One special case of a linear accelerating frame is an object free-falling under gravity. In that case, \\(\\mathbf{a}_0=-\\mathbf{g}\\) is constant. In some sense, this means we can treat gravity as a kind of generalized coordinate transformation that shifts the acceleration from \\(\\mathbf{a}\\) to \\(\\mathbf{a}_{rel} = \\mathbf{a} + \\mathbf{g}\\). This curious fact arises due to the equivalence principle, which says the gravitational force is proportional to the inertial mass \\(m\\). This curious fact causes the \\(m\\) to cancel from both sides of \\(m\\mathbf{a} = m\\mathbf{g}\\). As far as we know, gravity is the only force in nature with this special property. The equivalence principle is essentially the launch point to Einstein’s general theory of relativity.\n\n\n\n\n\n\n\nExample: Pendulum in an accelerating railcar\nA railcar is moving along the x-axis at a constant acceleration \\(\\mathbf{a}_0\\) with respect to the lab frame. Inside the railcar, a pendulum with mass \\(m\\) and length \\(\\ell\\) is attached to the ceiling and allowed to swing freely. Find the equations of motion for the swinging pendulum. Also, find the equilibrium position of the pendulum.\n\n\n\n\n\nWorking in the frame of the railcar, we have \\(\\mathbf{F}_{rel} = \\mathbf{F} + \\mathbf{F}_{lin}\\). The inertial forces on the pendulum are the string tension \\(\\mathbf{T}\\) and gravity \\(m\\mathbf{g}\\). We thus have \\[\nm\\mathbf{a}_{rel} = \\mathbf{T} + m\\mathbf{g} - m\\mathbf{a}_0 \\equiv \\mathbf{T} + m\\mathbf{g}_{eff},\n\\] where \\(\\mathbf{g}_{eff} \\equiv \\mathbf{g} - \\mathbf{a}_0\\) acts as an effective gravity on the pendulum inside the moving railcar. We can thus use the standard method to solve for the pendulum, but replacing \\(\\mathbf{g}\\) with \\(\\mathbf{g}_{eff}\\), to get \\[\n\\ddot \\theta = -\\omega^2 \\sin \\theta, \\quad \\text{where} \\quad \\omega^2 \\equiv \\frac{|\\mathbf{g}_{eff}|}{\\ell} = \\frac{\\sqrt{g^2 + a_0^2}}{\\ell}.\n\\] The equilibrium position occurs when \\(\\mathbf{F}_{rel}=\\mathbf{0}\\), which is when \\(\\mathbf{T} = -m\\mathbf{g}_{eff}\\). Using a little trig, we can see the equilibrium angle will be shifted to the angle \\(\\theta_{eq}\\) given by\n\n\n\n\n\n\\[\n\\theta_{eq} = \\tan^{-1} \\frac{g}{a_0}.\n\\]\nNotice when \\(a_0\\) we get \\(\\theta_{eq}=0\\), which is what we’d expect if the railcar weren’t accelerating."
  },
  {
    "objectID": "classical-mechanics/reference-frames.html#rotating-frames",
    "href": "classical-mechanics/reference-frames.html#rotating-frames",
    "title": "Reference Frames",
    "section": "Rotating Frames",
    "text": "Rotating Frames\nLet’s now look at reference frames that are rotating about some axis. Without loss of generality, we’ll consider a reference frame \\(S_{rot}\\) that’s rotating about the z-axis with respect to the lab frame \\(S\\) at some angular velocity \\(\\boldsymbol{\\omega} = \\dot \\varphi \\mathbf{e}_z\\).\n\n\n\n\n\nLet \\(\\mathbf{A}\\) be some vector in this rotating frame that’s at an angle \\(\\theta\\) with the axis of rotation. The amount that \\(\\mathbf{A}\\) changes due to the frame’s rotation by an amount \\(\\delta\\varphi\\) is given by \\[\n\\delta A = A_\\perp \\delta\\varphi = A\\sin\\theta\\delta\\varphi = |\\mathbf{A} \\times \\delta\\boldsymbol{\\varphi}|,\n\\] so by the right-hand rule we have \\(\\delta\\mathbf{A} = \\delta\\boldsymbol{\\varphi} \\times \\mathbf{A}\\). Dividing both sides by \\(dt\\), we finally have \\[\n\\frac{d\\mathbf{A}}{dt} = \\boldsymbol{\\omega} \\times \\mathbf{A}.\n\\] Remark:  Since velocities add as vectors, so too do angular velocities. This means if \\(S'\\) is a frame rotating relative \\(S\\), and \\(S''\\) is yet another frame that’s rotating to \\(S'\\), then we have \\[\n\\mathbf{v}_S'' = \\mathbf{v}_S' + \\mathbf{v}_{S'}'' \\quad \\Longrightarrow \\quad  \\boldsymbol{\\omega}_S'' \\times \\mathbf{r}_S = \\boldsymbol{\\omega}' \\times \\mathbf{r}_S + \\boldsymbol{\\omega}'' \\times \\mathbf{r}_{S'} \\quad \\Longrightarrow \\quad  \\boldsymbol{\\omega}_S'' = \\boldsymbol{\\omega}_S' + \\boldsymbol{\\omega}_{S'}''.\n\\] This fact allows us to easily solve problems involving complex hierarchies of rotations.\nNow, suppose \\(S_{rot}\\) is rotating with angular velocity \\(\\boldsymbol{\\omega}\\) with respect to the origin of \\(S\\). With respect to an observer in each frame, a vector \\(\\mathbf{A} = A_i \\mathbf{e}_i = A_i^{rot}\\mathbf{e}_i = \\mathbf{A}_{rel}\\) changes as\n\\[\n\\begin{align*}\n\\frac{d\\mathbf{A}}{dt}\\bigg|_{rot} &= \\dot A_i^{rot} \\mathbf{e}_i^{rot}, \\\\\n\\frac{d\\mathbf{A}}{dt}\\bigg|_{lab} &= \\dot A_i^{rot} \\mathbf{e}_i^{rot} + A_i^{rot} \\mathbf{\\dot e}_i^{rot}, \\\\\n\\frac{d\\mathbf{e}_i^{rot}}{dt}\\bigg|_{lab} &= \\boldsymbol{\\omega} \\times \\mathbf{e}_i^{rot}.\n\\end{align*}\n\\] Thus, we have \\[\n\\frac{d\\mathbf{A}}{dt}\\bigg|_{lab} = \\frac{d\\mathbf{A}}{dt}\\bigg|_{rot} + \\boldsymbol{\\omega} \\times \\mathbf{A}_{rot}\n\\] This evidently defines a transport operation between the lab frame and the rotating frame. Namely, time derivatives in the lab frame are related to time derivatives in the rotating frame via \\[\n\\frac{d}{dt}\\bigg|_{lab} = \\frac{d}{dt}\\bigg|_{rot} + \\boldsymbol{\\omega} \\times.\n\\] This result is sometimes called the transport theorem.\nUsing the transport theorem we can now derive what the equations of motion look like inside the rotating frame. Plugging \\(\\mathbf{x}\\) into the transport equation, we get \\[\n\\frac{d\\mathbf{x}}{dt}\\bigg|_{lab} = \\frac{d\\mathbf{x}}{dt}\\bigg|_{rot} + \\boldsymbol{\\omega} \\times \\mathbf{x}_{rot},\n\\] or \\[\n\\mathbf{v} = \\mathbf{v}_{rot} + \\boldsymbol{\\omega} \\times \\mathbf{x}_{rot}.\n\\] To get the acceleration \\(\\mathbf{a}\\), we need to apply the transport equation again to the velocity vector,\n\\[\n\\begin{align*}\n\\frac{d\\mathbf{v}}{dt}\\bigg|_{lab} &= \\bigg(\\frac{d}{dt}\\bigg|_{rot} + \\boldsymbol{\\omega} \\times \\bigg) (\\mathbf{v}_{rot} + \\boldsymbol{\\omega} \\times \\mathbf{x}_{rot}) \\\\\n&= \\mathbf{\\dot v}_{rot} + \\boldsymbol{\\omega} \\times \\mathbf{v}_{rot} + \\boldsymbol{\\dot \\omega} \\times \\mathbf{x}_{rot} + \\boldsymbol{\\omega} \\times \\mathbf{v}_{rot} + \\boldsymbol{\\omega} \\times (\\boldsymbol{\\omega} \\times \\mathbf{x}_{rot}).\n\\end{align*}\n\\] Or after cleaning up a bit, \\[\n\\mathbf{a} = \\mathbf{a}_{rot} + 2 \\boldsymbol{\\omega} \\times \\mathbf{v}_{rot} + \\boldsymbol{\\dot \\omega} \\times \\mathbf{x}_{rot} + \\boldsymbol{\\omega} \\times (\\boldsymbol{\\omega} \\times \\mathbf{x}_{rot}).\n\\]\nSince \\(\\mathbf{F} = m \\mathbf{a}\\) in the lab frame, we can multiply both sides by \\(m\\) and re-arrange terms to get the force vector \\(\\mathbf{F}_{rot}\\), \\[\n\\mathbf{F}_{rot} = \\mathbf{F} + m \\boldsymbol{\\omega} \\times (\\mathbf{x}_{rot} \\times \\boldsymbol{\\omega}) + 2m \\mathbf{v}_{rot} \\times \\boldsymbol{\\omega} + m \\mathbf{x}_{rot} \\times \\boldsymbol{\\dot \\omega}.\n\\] Evidently, there are three distinct fictitious force terms. Naturally, they each have special names:\n\nCentrifugal Force: \\(\\mathbf{F}_{cf} = m \\boldsymbol{\\omega} \\times (\\mathbf{x}_{rot} \\times \\boldsymbol{\\omega}) = m(\\boldsymbol{\\omega} \\cdot \\mathbf{x}_{rot})\\mathbf{x}_{rot} - m\\omega^2 \\mathbf{x}_{rot}\\).\nCoriolis Force: \\(\\mathbf{F}_{cor} = 2m \\mathbf{v}_{rot} \\times \\boldsymbol{\\omega}\\).\nEuler Force: \\(\\mathbf{F}_{eul} = m \\mathbf{x}_{rot} \\times \\boldsymbol{\\dot \\omega}\\).\n\nIn terms of these forces, we can finally write the force experienced in the rotating frame as \\[\n\\mathbf{F}_{rot} = \\mathbf{F} + \\mathbf{F}_{cf} + \\mathbf{F}_{cor} + \\mathbf{F}_{eul}.\n\\] The centrifugal force tends to push a rotating object outward radially from the origin, similar to how a centrifuge works. In the simple case when the position is perpendicular to the axis of rotation, the centrifugal force reduces to the more familiar form from elementary physics, \\[\n\\mathbf{F}_{cf} = - m\\omega^2 \\mathbf{x}_{rot} = -\\frac{mv_{rot}^2}{r_{rot}} \\mathbf{e}_r.\n\\] The Coriolis force tends to deflect a moving object away from its line of motion. It arises due to the fact that as the object moves, the frame under it is rotating underneath, which causes an apparent deflection sideward.\n\n\nExample: Throwing a baseball from the North Pole\nSuppose a baseball is thrown from the North Pole for a distance \\(\\ell\\) and a constant velocity \\(\\mathbf{v}_0\\) with respect to the lab frame. Find the deflection angle \\(\\delta\\theta\\) of the ball caused by the Coriolis force.\n\n\n\n\n\nThe rotating frame in this case is the Earth itself. The Earth rotates counterclockwise about the North Pole with an angular velocity of \\(\\omega_\\oplus = \\frac{2\\pi}{\\text{1 day}} \\approx 7 \\cdot 10^{-5} \\frac{\\text{rad}}{\\text{sec}}\\). Suppose \\(\\mathbf{e}_z\\) is the direction pointing skyward, with the origin at the North Pole. Then \\(\\boldsymbol{\\omega} = \\omega_{\\oplus} \\mathbf{e}_z\\). Suppose the ball is thrown initially along the positive x-axis, so \\(\\mathbf{x} = \\ell \\mathbf{e}_x\\). Since \\(\\mathbf{v} = \\mathbf{v}_{rot} + \\boldsymbol{\\omega} \\times \\mathbf{x}_{rot}\\), we have \\[\n\\mathbf{v}_0 = \\mathbf{v}_{rot} + \\omega_{\\oplus} v_0 t (\\mathbf{e}_z \\times \\mathbf{e}_x) = \\mathbf{v}_{rot} + \\omega_{\\oplus} v_0 t \\mathbf{e}_y.\n\\] On time scales \\(t \\ll \\text{1 day}\\), we can say \\(\\mathbf{v}_{rot} \\approx \\mathbf{v}_0\\) since in that case \\(\\omega_{\\oplus} t\\) becomes small. Then we have \\[\n\\mathbf{F}_{cor} = 2m \\mathbf{v}_{rot} \\times \\boldsymbol{\\omega} \\approx 2m v_0 \\omega_{\\oplus} (\\mathbf{e}_x \\times \\mathbf{e}_z) = -2m v_0 \\omega_{\\oplus} \\mathbf{e}_y,\n\\] Evidently, the Coriolis force in this case is constant, which means the acceleration \\(\\mathbf{a}_{cor}\\) is constant too. We thus get a simple constant equation of motion in \\(y\\), \\[\n\\ddot y = -2v_0 \\omega_{\\oplus}.\n\\] Solving this EOM gives a deflection distance of \\[\nd = |y| = \\frac{1}{2}(2v_0 \\omega_{\\oplus})^2 = v_0 \\omega_{\\oplus} t^2.\n\\] Finally, we can use this to calculate the deflection angle \\(\\delta\\theta\\), \\[\n\\delta\\theta \\approx \\frac{d}{\\ell} = \\frac{\\omega_{\\oplus}v_0 t^2}{v_0 t} = \\omega_{\\oplus} t.\n\\] To plug in some numbers, suppose the ball stays in the air for \\(t = \\text{100 sec}\\). Then we’d get \\(\\delta\\theta \\approx 0.4^\\circ\\), indeed a very small deflection.\n\n\n\nExample: Hurricanes\nIt turns out that hurricanes rotate the direction they do due to the Coriolis force of the Earth. Pressure gradients cause water currents flowing east-west to spiral inward. In the Northern hemisphere, water deflects rightward, causing the gradients (or “hurricanes”) to spiral counterclockwise. Whereas in the Southern hemisphere, water deflects leftward, causing gradients (or “typhoons”) to spiral clockwise.\n\n\n\n\n\n\n\n\nExample: The Foucalt pendulum\nThe Foucalt pendulum is a classic problem that’s often used to demonstrate that the Earth rotates. Suppose a very long pendulum of length \\(l\\) and mass \\(m\\) is fixed near the Earth’s surface at some latitude \\(\\lambda\\) above the equator. Here’s a picture of what’s going on.\n\n\n\n\n\nIt’s reasonable to assume that \\(\\omega_{\\oplus}\\) is constant, so the Euler force is zero. It’s also reasonable to assume the centrifugal force is zero since \\(\\omega_{\\oplus}\\) is small. Thus, in the frame of the rotating Earth, we’re left with the inertial forces on the pendulum and the Coriolis force, \\[\nm\\mathbf{a}_{rot} = m\\mathbf{g} + \\mathbf{T} - 2m\\boldsymbol{\\omega} \\times \\mathbf{v}_{rot}.\n\\] Choose the axes such that the z-axis is pointing outward from the Earth’s surface at the pendulum and the other axes are planar to the surface. Now, we can write \\(\\mathbf{g} = -g \\mathbf{e}_z\\), and using some trig it’s not too hard to show that \\[\n\\mathbf{T} \\approx -\\frac{T}{\\ell} (x \\mathbf{e}_x + y \\mathbf{e}_y + \\ell \\mathbf{z}).\n\\] Using the latitude angle \\(\\lambda\\) we can also express the angular velocity \\(\\boldsymbol{\\omega}\\) as \\[\n\\boldsymbol{\\omega} = -\\omega_{\\oplus}\\cos\\lambda\\mathbf{e}_x + \\omega_{\\oplus}\\sin\\lambda\\mathbf{e}_z.\n\\] Since the pendulum approximately speaking only moves in the xy-plane, we also have \\[\n\\mathbf{v}_{rot} = \\dot x \\mathbf{e}_x + \\dot y \\mathbf{e}_y.\n\\] Together, these together imply \\[\n\\boldsymbol{\\omega} \\times \\mathbf{v}_{rot} \\approx -\\dot y \\omega_{\\oplus} \\sin\\lambda \\mathbf{e}_x + \\dot x \\omega_{\\oplus} \\sin\\lambda \\mathbf{e}_y - \\dot y \\omega_{\\oplus} \\cos\\lambda \\mathbf{e}_z.\n\\] This means \\[\n\\mathbf{a}_{rot} = \\bigg(-\\frac{Tx}{m\\ell} + 2\\dot y \\omega_{\\oplus} \\sin\\lambda \\bigg) \\mathbf{e}_x + \\bigg(-\\frac{Ty}{m\\ell} - 2\\dot x \\omega_{\\oplus} \\sin\\lambda \\bigg) \\mathbf{e}_x,\n\\] which gives equations of motion\n\\[\n\\begin{align*}\n\\ddot x &= -\\frac{T}{m\\ell} \\cdot x + 2\\omega_{\\oplus}\\sin\\lambda \\cdot \\dot y \\\\\n\\ddot y &= -\\frac{T}{m\\ell} \\cdot y - 2\\omega_{\\oplus}\\sin\\lambda \\cdot \\dot x. \\\\\n\\end{align*}\n\\] If we define \\(\\omega_0^2 \\equiv \\frac{T}{m\\ell} = \\frac{g}{\\ell}\\), we can re-arrange and write the equations of motion in the form\n\\[\n\\begin{align*}\n\\ddot x + \\omega_0^2 \\cdot x &= 2\\omega_z \\dot y \\\\\n\\ddot y + \\omega_0^2 \\frac{T}{m\\ell} \\cdot y &= -2\\omega_z \\dot x, \\\\\n\\end{align*}\n\\] where \\(\\omega_z = \\omega_{\\oplus}\\sin\\lambda\\). If we combine these two equations, this is equivalent to a complex DHO problem with imaginary damping, \\[\n\\ddot z + 2i\\omega_z \\dot z + \\omega_0^2 z = 0.\n\\] This means solutions will have the form \\[\nz(t) = e^{-i\\omega_z t}(A e^{i\\omega't} + B e^{-i\\omega't}).\n\\] where \\(\\omega' \\equiv \\sqrt{\\omega_z^2 + \\omega_0^2}\\). If we assume the pendulum swings much faster than the Earth rotates, we have \\(\\omega_0 \\gg \\omega_{\\oplus}\\), which means we can approximate \\(z(t)\\) as \\[\nz(t) \\approx e^{-i\\omega_z t}(A e^{i\\omega_0 t} + B e^{-i\\omega_0 t}).\n\\] If we define \\(z'(t) \\equiv A e^{i\\omega_0 t} + B e^{-i\\omega_0 t}\\), then \\(z(t) = e^{-i\\omega_z t} z'(t)\\), and we can write the real solutions as\n\\[\n\\begin{align*}\nx(t) &= x'(t) \\cos\\omega_z t + y'(t) \\sin\\omega_z t, \\\\\ny(t) &= -x'(t) \\sin\\omega_z t + y'(t) \\cos\\omega_z t. \\\\\n\\end{align*}\n\\] This says that the plane of oscillation itself undergoes a rotation in the xy-plane. That is, the plane of the pendulum’s orbit precesses with a frequency given by \\[\n\\omega_z = \\omega_{\\oplus} \\sin\\lambda = 2\\pi\\frac{\\sin\\lambda}{\\text{1 day}}.\n\\] For example, at a latitude of \\(\\lambda = 34.5^\\circ\\), the pendulum precesses counterclockwise with a frequency of \\(\\omega_z \\approx \\text{3.86 rad/sec}\\), or about \\(8.5^\\circ\\) per hour. It appears precession is non-existent at the equator and highest at the poles, where precession happens exactly with the Earth’s rotation."
  },
  {
    "objectID": "classical-mechanics/reference-frames.html#general-non-inertial-frames",
    "href": "classical-mechanics/reference-frames.html#general-non-inertial-frames",
    "title": "Reference Frames",
    "section": "General Non-Inertial Frames",
    "text": "General Non-Inertial Frames\nMore generally, we can combine linearly accelerating and rotating frames by just adding the fictitious forces together. If \\(S_{rel}\\) is both accelerating and rotating about some axis with respect to \\(S\\), we’d have \\[\n\\mathbf{F}_{rel} = \\mathbf{F} + \\mathbf{F}_{lin} + \\mathbf{F}_{cf} + \\mathbf{F}_{cor} + \\mathbf{F}_{eul}.\n\\] This general form for a force in a non-inertial frame can be used to analyze a surprisingly large number of practical problems, where complicated forces can often be decomposed into a sum of linear forces and rotational forces.\nOne fact to be aware of about non-inertial frames is that energy need not be conserved. It’s only true in inertial frames that energy must be conserved. This has to do with the fact that in the relative frame we’re ignoring the forces on the relative frame itself, i.e. the forces that cause the frame to accelerate or rotate. We can generally recover the conservation of energy by transforming back to an inertial frame."
  },
  {
    "objectID": "classical-mechanics/lagrangian-mechanics.html#configuration-space",
    "href": "classical-mechanics/lagrangian-mechanics.html#configuration-space",
    "title": "Lagrangian Mechanics",
    "section": "Configuration Space",
    "text": "Configuration Space\nMany forces acting on a system do no work. They serve only to keep particles confined to some surface in space. Such forces are called forces of constraint. Examples of forces of constraint include the tension in a string and the normal force keeping an object on a physical surface.\nSuppose we have a system of \\(N\\) particles with positions \\(\\mathbf{x}_1, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N\\) respectively. Taken together, these positions can be thought of as defining a trajectory in the \\(3N\\)-dimensional space \\(\\mathbb{R}^{3N}\\). A holonomic constraint is a constraint that keeps the \\(N\\) particles confined to some lower-dimensional sub-manifold \\(\\mathcal{Q}\\) of \\(\\mathbb{R}^{3N}\\). Equivalently, it’s a (possibly time-dependent) function of the form \\[\nf(\\mathbf{x}_1, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N, t) = 0.\n\\] The dimension of \\(\\mathcal{Q}\\) is \\(n=3N-C\\), where \\(C\\) is the total number of constraints on the system. These are the number of degrees of freedom of the system. This sub-manifold is called the configuration space of the system. Since \\(\\mathcal{Q}\\) is \\(n\\)-dimensional, we should be able to parametrize it with \\(n\\) coordinates \\(q_1, q_2, \\cdots, q_n\\). We call these generalized coordinates. They’re not ordinary coordinates in real space. They’re a way of describing where in configuration space the system is at a given point in time.\n\n\n\n\n\nHolonomicity requires that we be able to find a 1-1 map going back and forth between generalized coordinates and the position vectors, \\[\nq_i = q_i(\\mathbf{x}_1, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N, t), \\quad \\mathbf{x}_\\alpha = \\mathbf{x}_\\alpha(q_1, q_2, \\cdots, q_n, t).\n\\] When the holonomic constraint isn’t time-dependent, they’re called scleronomic constraints. Otherwise they’re called rheonomic constraints. A system that’s not holonomic is called non-holonomic.\n\n\nExample: Simple Pendulum\nAs an easy example, consider the simple pendulum. Since there’s only one particle, \\(N=1\\). Since the length of the pendulum is fixed, that’s one constraint. Since the motion is confined to a plane, that’s another constraint. We thus have \\(n=3N-C=3-2=1\\) degrees of freedom, which we can of course take to be the angle \\(\\theta\\).\n\n\n\nExample: Rigid Bodies\nA more interesting example is the rigid body. A rigid body is a system of \\(N\\) particles whose particles are always a fixed distance apart, i.e. \\(d_{ij} = |\\mathbf{x}_i - \\mathbf{x}_j|\\) is fixed for all \\(i, j\\). This fixed distance requirement introduces a lot of constraints on the system. To see this, suppose \\(N=4\\). Then there are \\(C=6\\) constraints, since each particle must connect to each other particle. This means there are \\(n=3N-C=6\\) degrees of freedom.\n\n\n\n\n\nIt turns out this fact extends to rigid bodies with arbitrarily many particles as well since adding a new particle gives 3 more coordinates, but also 3 more constraints. A rigid body will always have exactly 6 degrees of freedom, which we usually take to be the 3 center of mass coordinates and the three Euler angles."
  },
  {
    "objectID": "classical-mechanics/lagrangian-mechanics.html#principle-of-virtual-work",
    "href": "classical-mechanics/lagrangian-mechanics.html#principle-of-virtual-work",
    "title": "Lagrangian Mechanics",
    "section": "Principle of Virtual Work",
    "text": "Principle of Virtual Work\nSuppose we have a system of \\(N\\) particles in mechanical equilibrium, so \\(\\mathbf{F}_i=\\mathbf{0}\\) for all \\(i\\). Let’s imagine we perturb each particle \\(\\mathbf{x}_i\\) by some amount \\(\\delta \\mathbf{x}_i\\), but only in a way that doesn’t change the configuration space. This means each perturbation must be a function of the generalized coordinates, \\(\\delta \\mathbf{x}_i = \\delta \\mathbf{x}_i(q_1, q_2, \\cdots, q_n, t)\\). Define the virtual work done on the system by, \\[\n\\delta W \\equiv \\sum \\mathbf{F}_i \\cdot \\delta\\mathbf{x}_i\n\\] Now, let’s decompose each force \\(\\mathbf{F}_i\\) into a sum of two components, an applied force \\(\\mathbf{F}_i^{app}\\) and a constraint force \\(\\mathbf{F}_i^{con}\\). The applied forces are the ones that do work on each particle, while the constraint forces are the ones that keep them confined to the configuration space. If the system is exactly in equilibrium, then \\(\\mathbf{F}_i = \\mathbf{F}_i^{app} + \\mathbf{F}_i^{con} = \\mathbf{0}\\), which means \\(\\delta W = 0\\) in equilibrium. But since constraint forces do no work, we get \\[\n\\delta W = \\sum \\mathbf{F}_i^{app} \\cdot \\delta\\mathbf{x}_i = 0\n\\] This is called the principle of virtual work.\nNote: Sometimes constraint forces do in fact do work on a system. One major example is a system in rolling motion, e.g. a wheel rolling down a ramp. We’ll mostly ignore these situations in this lesson.\nMore generally, if a system is not in equilibrium, we have \\(\\mathbf{F}_i = m_i \\mathbf{\\dot v}_i\\). If we insist the principle of virtual work must apply to these situations as well, we have \\[\n\\begin{align*}\n0 = \\delta W &= \\sum_i (\\mathbf{F}_i^{app} - m_i \\mathbf{\\dot v}_i) \\cdot \\delta \\mathbf{x}_i \\\\\n&= \\sum_i (\\mathbf{F}_i^{app} - m_i \\mathbf{\\dot v}_i) \\cdot \\sum_j\\frac{\\partial \\mathbf{x}_i}{\\partial q_j} \\delta q_j \\\\\n&= \\sum_j \\bigg(\\sum_i \\mathbf{F}_i^{app} \\cdot \\frac{\\partial \\mathbf{x}_i}{\\partial q_j}  - m_i \\mathbf{\\dot v}_i \\cdot \\frac{\\partial \\mathbf{x}_i}{\\partial q_j} \\bigg) \\delta q_j \\\\\n&= \\sum_j \\bigg[ Q_j - \\bigg(\\frac{d}{dt} \\frac{\\partial T}{\\partial \\dot q_j} - \\frac{\\partial T}{\\partial q_j} \\bigg) \\bigg] \\delta q_j.\n\\end{align*}\n\\] Here I defined \\(Q_j \\equiv \\mathbf{F}_i^{app} \\cdot \\frac{\\partial \\mathbf{x}_i}{\\partial q_j}\\). This term is called the generalized force. It acts as a force, but on the generalized coordinates instead of the position vectors directly. The other thing I did was re-wrote the momentum term by using the total kinetic energy \\(T = \\frac{1}{2} \\sum_i m_i \\mathbf{v}_i^2\\). Now, if we insist that all the \\(q_i\\) are independent of each other, then the terms in the sum must vanish individually, which means for all \\(j=1,\\cdots,n\\) we have \\[\nQ_j = \\frac{d}{dt} \\frac{\\partial T}{\\partial \\dot q_j} - \\frac{\\partial T}{\\partial q_j}.\n\\] In the special case where the forces on the system are conservative, we can use the potential energy \\(V\\) to express the generalized forces as \\(Q_j = -\\frac{\\partial V}{\\partial q_i}\\). Defining a function \\(L \\equiv T - V\\) called the Lagrangian and re-arranging terms, we finally have \\[\n\\frac{\\partial L}{\\partial q_j} - \\frac{d}{dt} \\frac{\\partial L}{\\partial \\dot q_j} = 0.\n\\] This gives a set of \\(n\\) equations for the generalized coordinates, called Lagrange’s equations.\nTo see why Lagrange’s equations are useful, consider the case when \\(T=\\frac{1}{2} \\sum_i m_i \\dot x_i^2\\) and \\(V = V(x_1, x_2, \\cdots, x_n)\\). Then we have a Lagrangian of the form \\[\nL = T - V = \\frac{1}{2} \\sum_i m_i \\dot x_i^2 - V(x_1, x_2, \\cdots, x_n),\n\\] which we can plug into the Euler-Lagrange Equations to get \\[\nm \\ddot x_i = - \\frac{\\partial V}{\\partial x_i} \\quad \\forall i=1,2,\\cdots,n.\n\\] But this is just \\(\\mathbf{F} = m \\mathbf{a}\\)! Evidently we’ve managed to reproduce Newton’s Laws from Lagrange’s equations. This in some sense suggest that Lagrange’s equations might be more general than Newton’s Laws, and in fact they are as we’ll see later."
  },
  {
    "objectID": "classical-mechanics/lagrangian-mechanics.html#solving-lagranges-equations",
    "href": "classical-mechanics/lagrangian-mechanics.html#solving-lagranges-equations",
    "title": "Lagrangian Mechanics",
    "section": "Solving Lagrange’s Equations",
    "text": "Solving Lagrange’s Equations\nThe Lagrangian formulation is very useful for solving problems that would be very complicated to solve using Newtonian approaches. This is particular true when there are complex constraints present. It’s thus very helpful to see a bunch of examples showing how to solve problems using Lagrangian methods.\nTo solve a problem using Lagrange’s equations we need to do the following steps:\n\nFigure out how many degrees of freedom the system has using \\(n=3N-C\\).\nIdentify the generalized coordinates \\(q_1,q_2,\\cdots,q_n\\).\nExpress the velocity vectors as a function of the generalized coordinates, \\(\\mathbf{v}_i = \\mathbf{v}_i(q_1,q_2,\\cdots,q_n)\\).\nWrite down the kinetic energy \\(T = \\frac{1}{2}\\sum_i m_i \\mathbf{v_i}^2(q_1,q_2,\\cdots,q_n)\\), the potential energy \\(V=V(q_1,q_2,\\cdots,q_n)\\), and finally the Lagrangian \\[\nL = T - V.\n\\]\nUse Lagrange’s equations to derive the equations of motion for the generalized coordinates, \\[\n\\frac{\\partial L}{\\partial q_j} - \\frac{d}{dt} \\frac{\\partial L}{\\partial \\dot q_j} = 0 \\quad \\forall j=1,2\\cdots,n.\n\\]\nIntegrate the equations of motion to get the generalized trajectories \\(q_1(t),q_2(t),\\cdots,q_n(t)\\).\nIf desired, convert back to real space coordinates via \\(\\mathbf{x}_\\alpha = \\mathbf{x}_\\alpha(q_1,q_2,\\cdots,q_n)\\).\n\n\n\nExample: The Simple Spring\nSuppose a mass \\(m\\) is attached to an ideal spring with spring constant \\(k\\).\n\n\n\n\n\nIn this case, \\(N = 1\\), and the spring is constrained to move along, say, the x-axis, so \\(C=2\\), and there’s just \\(n=3N-C=1\\) degree of freedom (as expected). If the generalized coordinate is just \\(q=x\\), we have \\[\nT = \\frac{1}{2} m \\dot q^2, \\quad V = \\frac{1}{2}kq^2,\n\\] which means the Lagrangian is \\[\nL = \\frac{1}{2} m \\dot q^2 - \\frac{1}{2}kq^2.\n\\] Solving Lagrange’s equation in this case gives \\[\n-\\frac{\\partial}{\\partial q} \\frac{k q^2}{2} - \\frac{d}{dt} \\frac{\\partial}{\\partial \\dot q} \\frac{m\\dot q^2}{2} = 0 \\quad \\Rightarrow \\quad m\\ddot q = -k q.\n\\] We’ve already seen the solution to this equation is just the SHO solution \\[\nq(t) = A\\cos(\\omega t - \\delta), \\quad \\omega^2 \\equiv \\frac{k}{m}.\n\\] If desired, in this case we could convert back to real coordinates via \\[\n\\mathbf{x}(t) = q(t) \\mathbf{e}_x = A\\cos(\\omega t - \\delta)\\mathbf{e}_x.\n\\]\n\n\n\nExample: Simple Pendulum\nSuppose a mass \\(m\\) is attached to a massless string of fixed length \\(\\ell\\) and allowed to swing.\n\n\n\n\n\nIn this problem, there’s \\(N=1\\) particle. The string being fixed adds one constraint, and motion being confined to the plane adds another, so we have \\(n=1\\) degrees of freedom here, which we’ll take to be the angle \\(q=\\theta\\). Using polar coordinates, we can write the kinetic and potential energies as \\[\nT = \\frac{1}{2} m\\ell^2 \\dot q^2, \\quad V = -mg\\ell\\cos q,\n\\] which gives a Lagrangian \\[\nL = \\frac{1}{2} m\\ell^2 \\dot q^2 + mg\\ell\\cos q.\n\\] Solving Lagrange’s equation, we get the equation of motion \\[\nm\\ell^2 \\ddot q + mg\\ell\\sin q = 0,\n\\] which is of course the usual equation of motion for the pendulum when \\(q=\\theta\\).\n\n\n\nExample: Central Potential\nSuppose a particle of mass \\(m\\) is in the presence of a central force field \\(V=V(r)\\). There’s one constraint since the problem must be spherically symmetric, which means we have \\(n=2\\) degrees of freedom. Working in spherical coordinates, the kinetic and potential energies are given by \\[\nT = \\frac{1}{2} m (\\dot r^2 + r \\dot \\varphi^2), \\quad V = V(r).\n\\] Plugging these into Lagrange’s equation and solving gives two equations of motion for \\(r\\) and \\(\\varphi\\), \\[\nm \\ddot r = mr \\dot\\varphi^2 - \\frac{dV}{dr}\\\\\n\\frac{d}{dt} mr^2 \\dot\\varphi = 0.\n\\] The second equation is interesting. It says the quantity \\(\\ell = mr^2 \\dot\\varphi\\) must be conserved. But this is just the angular momentum of the system! Evidently, conservation laws somehow fall out of Lagrange’s equations provided the right generalized coordinates are chosen.\n\n\n\nExample: Double Pendulum\nThe examples considered so far are pretty easy to solve using Newtonian methods. Here’s an example where it’s far easier to write down the equations of motion in the Lagrangian formulation. Consider the double pendulum, where a mass is attached to the end of another pendulum and both are allowed to swing. Suppose both masses have mass \\(m\\) and both strings are a fixed length \\(\\ell\\).\n\n\n\n\n\nHere there are \\(N=2\\) particles, each of which has two constraints. That means there are \\(n=2\\) total degrees of freedom in this system. From the above diagram we can see \\[\n\\begin{align*}\n&x_1 = \\ell \\sin\\theta_1, \\quad &&x_2 = \\ell(\\sin\\theta_1 + \\sin\\theta_2), \\\\\n&y_1 = -\\ell \\cos\\theta_1, \\quad &&y_2 = -\\ell(\\cos\\theta_1 + \\cos\\theta_2). \\\\\n\\end{align*}\n\\] We’ll choose the two angles \\(\\theta_1, \\theta_2\\) to be the generalized coordinates. The energies for each mass are given by \\[\n\\begin{align*}\nT_1 &= \\frac{1}{2}m (\\dot x_1^2 + \\dot y_1^2) = \\frac{1}{2}m \\ell^2 \\dot \\theta_1^2, \\quad &&\nT_2 = \\frac{1}{2}m (\\dot x_2^2 + \\dot y_2^2) = \\frac{1}{2}m \\ell^2\\big(\\dot\\theta_1^2 + \\dot\\theta_2^2 + 2\\cos(\\theta_1-\\theta_2)\\dot\\theta_1\\dot\\theta_2\\big), \\\\\nV_1 &= mgy_1 = -mg\\ell\\cos\\theta_1, \\quad && V_2 = mgy_2 = -mg\\ell(\\cos\\theta_1 + \\cos\\theta_2).\\\\\n\\end{align*}\n\\]\nPutting these all into the Lagrangian and simplifying, we evidently get \\[\nL = \\frac{1}{2}m\\ell^2\\big(2\\dot \\theta_1^2 + \\dot \\theta_2^2 + 2\\dot\\theta_1\\dot\\theta_2\\cos(\\theta_1-\\theta_2) \\big) + mg\\ell(2\\cos\\theta_1 + \\cos\\theta_2).\n\\] This then gives the following two equations of motion \\[\n\\begin{align*}\n-m\\ell^2\\dot\\theta_1\\dot\\theta_2\\sin(\\theta_1-\\theta_2) - 2mg\\ell\\sin\\theta_1 &= m\\ell^2 \\frac{d}{dt} \\big(\\dot\\theta_1 + 2\\dot\\theta_2\\cos(\\theta_1-\\theta_2)\\big), \\\\\nm\\ell^2\\dot\\theta_1\\dot\\theta_2\\sin(\\theta_1-\\theta_2) - mg\\ell\\sin\\theta_2 &= m\\ell^2 \\frac{d}{dt} \\big(\\dot\\theta_2 + 2\\dot\\theta_1\\cos(\\theta_1-\\theta_2) \\big). \\\\\n\\end{align*}\n\\]"
  },
  {
    "objectID": "classical-mechanics/lagrangian-mechanics.html#principle-of-least-action",
    "href": "classical-mechanics/lagrangian-mechanics.html#principle-of-least-action",
    "title": "Lagrangian Mechanics",
    "section": "Principle of Least Action",
    "text": "Principle of Least Action\nA more general, first principles way to derive Lagrange’s equations is via an action principle. Action principles are a very general and powerful tool that applies across pretty much all of modern physics. Suppose we have \\(n\\) generalized coordinates \\(q_1,q_2,\\cdots,q_n\\). For simplicity I’ll write these as a vector, \\[\n\\mathbf{q} = (q_1,q_2,\\cdots,q_n).\n\\] Define the action \\(S\\) as a functional of \\(\\mathbf{q}\\) of the form \\[\nS[\\mathbf{q}] \\equiv \\int_{t_1}^{t_2} L(\\mathbf{q}, \\mathbf{\\dot q}, t) dt.\n\\] We assume the times \\(t_1\\) and \\(t_2\\) are fixed. The integrand function \\(L(\\mathbf{q}, \\mathbf{\\dot q}, t)\\) is called the Lagrangian. Note in general the Lagrangian can depend explicitly on time.\n\n\n\n\n\nSimilar to how it’s useful to analyze a function by looking at its behavior around its minima, we’ll want to analyze the functional \\(S\\) by looking at its behavior around the stationary points of \\(\\mathbf{q}\\). To do so, consider a small perturbation \\(\\delta\\mathbf{q} \\equiv \\varepsilon\\boldsymbol{\\eta}\\) of the coordinates, where \\(\\boldsymbol{\\eta} = \\boldsymbol{\\eta}(t)\\) is a function that vanishes at the endpoints \\(t_1\\) and \\(t_2\\), and \\(\\varepsilon \\ll 1\\). To proceed, we’ll assume the following fundamental principle:\nPrinciple of Least Action:  Physical trajectories evolve in such a way that the action remains stationary, i.e. \\[\n\\delta S[\\mathbf{q}] \\equiv \\frac{\\partial S}{\\partial \\varepsilon} \\bigg|_{\\varepsilon=0} = 0.\n\\] This means if we want to figure out how physical trajectories evolve, we need to find the optimal \\(\\mathbf{q}\\) that make the action \\(S\\) stationary. To do that, let’s set \\(\\delta S[\\mathbf{q}] = 0\\) and solve. We have \\[\n0 = \\delta S[\\mathbf{q}] = \\int_{t_1}^{t_2} \\delta L(\\mathbf{q}, \\mathbf{\\dot q}, t) dt = \\int_{t_1}^{t_2}\\bigg(\\frac{\\partial L}{\\partial\\mathbf{q}} \\cdot \\delta \\mathbf{q} + \\frac{\\partial L}{\\partial\\mathbf{\\dot q}} \\cdot \\delta \\mathbf{\\dot q} \\bigg) \\cdot \\delta\\mathbf{q} dt\n\\] Now, if we perform integration by parts on the second term, we can move the time derivative from \\(\\delta\\mathbf{\\dot q}\\) to the derivative \\(\\frac{\\partial L}{\\partial\\mathbf{\\dot q}}\\) at the cost of a minus sign, so we have \\[\n0 = \\delta S[\\mathbf{q}] = \\int_{t_1}^{t_2}\\bigg(\\frac{\\partial L}{\\partial\\mathbf{q}} - \\frac{d}{dt}\\frac{\\partial L}{\\partial\\mathbf{\\dot q}} \\bigg) \\cdot \\delta \\mathbf{q} dt.\n\\] Note the boundary terms vanish since we require \\(\\boldsymbol{\\eta}\\) to vanish at the endpoints. Assuming each of the coordinates in \\(\\mathbf{q}\\) are functionally independent the integrand must vanish identically, so we have \\[\n\\frac{\\partial L}{\\partial\\mathbf{q}} - \\frac{d}{dt}\\frac{\\partial L}{\\partial\\mathbf{\\dot q}} = \\mathbf{0}.\n\\] Of course, this is just the vector formulation of Lagrange’s equations. We’ve thus fully recovered Lagrange’s equations, and by extension Newton’s Laws for conservative systems, purely from the Principle of Least Action.\nNotice how general this derivation was. We didn’t even assume any specific form of the Lagrangian like \\(L = T-V\\). We only assumed it was a function of the generalized positions, velocities, and time. If we believe the Principle of Least Action, evidently any Lagrangian \\(L(\\mathbf{q}, \\mathbf{\\dot q}, t)\\) will produce equations of motion for some system, not necessarily mechanical, or even classical."
  },
  {
    "objectID": "classical-mechanics/lagrangian-mechanics.html#symmetries-and-conservation-laws",
    "href": "classical-mechanics/lagrangian-mechanics.html#symmetries-and-conservation-laws",
    "title": "Lagrangian Mechanics",
    "section": "Symmetries and Conservation Laws",
    "text": "Symmetries and Conservation Laws\nIt’s a deep fact of physics that the symmetries of a system are intimately connected with its conservation laws. It’s both practically and theoretically useful to better understand this connection.\n\nCyclic Coordinates\nConsider a general Lagrangian of the form \\(L = L(\\mathbf{q}, \\mathbf{\\dot q}, t)\\). Without loss of generality, suppose the Lagrangian happens to not be a function of the coordinate \\(q_1\\), so \\[\nL = L(q_2,\\cdots,q_n,\\dot q_1,\\dot q_2, \\cdots, \\dot q_n, t).\n\\] Note it can still be a function of the first coordinate’s velocity \\(\\dot q_1\\). In this situation, we’d say the coordinate \\(q_1\\) is a cyclic coordinate or ignorable coordinate. Evidently, it follows that \\[\n\\frac{\\partial L}{\\partial q_1} = 0 \\quad \\Longrightarrow \\quad 0 = \\frac{d}{dt} \\frac{\\partial L}{\\partial \\dot q_1} \\quad \\Longrightarrow \\quad p_1 \\equiv \\frac{\\partial L}{\\partial \\dot q_1} = const.\n\\] We call \\(p_1\\) the conjugate momentum to \\(q_1\\). We’ve thus shown that if \\(q_1\\) is cyclic, then its conjugate momentum \\(p_1\\) is conserved.\n\n\nExample: Free Particle\nFor a free particle, we have \\(L = \\frac{1}{2}m \\dot x^2\\). Since \\(L\\) is not a function of \\(x\\), evidently \\(x\\) is cyclic, which means its conjugate momentum \\(p_x\\) is conserved, \\[\np_x = \\frac{\\partial L}{\\partial \\dot x} = m \\dot x = const.\n\\] Notice in this case the conjugate momentum is the same thing as the ordinary linear momentum. This need not always be true. The conjugate momentum is more general than this.\n\n\n\nExample: Central Force in a Plane\nIn this case the Lagrangian is given by \\[\nL = \\frac{1}{2} m (\\dot r^2 + r^2 \\dot\\varphi^2) - V(r).\n\\] Since \\(\\varphi\\) is cyclic, its conjugate momentum \\(p_\\varphi\\) must evidently be conserved, \\[\np_\\varphi = \\frac{\\partial L}{\\partial \\dot \\varphi} = mr^2\\dot\\varphi = const.\n\\] Notice this is just the \\(z\\)-component of angular momentum \\(L_z = \\ell\\).\n\n\n\n\nNoether’s Theorem\nWe can still have conserved quantities in a given system even if none of its generalized coordinates are explicitly cyclic. This will happen, for example, if we didn’t happen to choose the natural choice of coordinates for some given problem, the ones that take advantage of the system’s symmetries.\nTo find conserved quantities, we need to find the symmetries. Formally, we’ll say a symmetry is any continuous transformation on the generalized coordinates that leaves the Lagrangian invariant. That is, for some parameter \\(s\\), if \\(\\mathbf{q}\\) is continuously transformed to \\(\\mathbf{q}_s\\), then \\(s\\) is a symmetry provided \\[\nL(\\mathbf{q}_s, \\mathbf{\\dot q}_s, t) = L(\\mathbf{q}, \\mathbf{\\dot q}, t).\n\\] Noether’s Theorem: If \\(s\\) is a symmetry of a system, then the quantity given by \\[\nQ \\equiv \\mathbf{p} \\cdot \\frac{\\partial \\mathbf{q}}{\\partial s} = p_i \\frac{\\partial q_i}{\\partial s}\n\\] must be conserved under transformation by \\(s\\). We call \\(Q\\) the Noether charge associated with \\(s\\).\n\nProof: To prove this theorem we need to show that \\(\\dot Q = 0\\). Since \\(s\\) is a symmetry, we must have \\[\n\\frac{\\partial}{\\partial s} L(\\mathbf{q}_s, \\mathbf{\\dot q}_s, t) = \\frac{\\partial}{\\partial s} L(\\mathbf{q}, \\mathbf{\\dot q}, t) = 0.\n\\] Using the chain rule together with Lagrange’s equations on \\(L(\\mathbf{q}_s, \\mathbf{\\dot q}_s, t)\\), we finally get \\[\n\\begin{align*}\n\\mathbf{0} &= \\frac{\\partial}{\\partial s} L(\\mathbf{q}_s, \\mathbf{\\dot q}_s, t) \\\\\n&= \\frac{\\partial L}{\\partial \\mathbf{q}_s} \\cdot \\frac{\\partial \\mathbf{q}_s}{\\partial s} + \\frac{\\partial L}{\\partial \\mathbf{\\dot q}_s} \\cdot \\frac{\\partial \\mathbf{\\dot q}_s}{\\partial s} \\\\\n&= \\frac{d}{dt} \\frac{\\partial L}{\\partial \\mathbf{\\dot q}_s} \\cdot \\frac{\\partial \\mathbf{q}_s}{\\partial s} + \\frac{\\partial L}{\\partial \\mathbf{\\dot q}_s} \\cdot \\frac{d}{dt} \\frac{\\partial \\mathbf{q}_s}{\\partial s} \\\\\n&= \\frac{d}{dt} \\bigg(\\frac{\\partial L}{\\partial \\mathbf{\\dot q}_s} \\cdot \\frac{\\partial \\mathbf{q}_s}{\\partial s}\\bigg) \\\\\n&= \\frac{d}{dt} \\bigg(\\mathbf{p} \\cdot \\frac{\\partial \\mathbf{q}}{\\partial s}\\bigg). \\tag*{$\\square$}\n\\end{align*}\n\\]\n\n\nExample: Conservation of Linear Momentum\nSuppose a single particle is moving through space. Suppose the space is homogeneous, that is, the particle’s Lagrangian is invariant to translations in space, \\[\nL(\\mathbf{x}, \\mathbf{\\dot x}, t) = L(\\mathbf{x} + \\delta\\mathbf{x}, \\mathbf{\\dot x}, t).\n\\] This is equivalent to saying the particle has a symmetry of the form \\(\\mathbf{x}(s) = \\mathbf{x} + s\\boldsymbol{\\varepsilon}\\), where \\(\\boldsymbol{\\varepsilon}\\) is constant. In this case, we’d evidently have \\[\nQ = \\mathbf{p} \\cdot \\frac{\\partial \\mathbf{x}}{\\partial s} = \\mathbf{p} \\cdot \\boldsymbol{\\varepsilon} = const.\n\\] Since \\(\\boldsymbol{\\varepsilon}\\) is an arbitrary constant, we must have \\(\\mathbf{p} = m \\mathbf{\\dot x} = const\\). That is, the linear momentum of the particle is conserved. Equivalently, if space is homogeneous, then the total linear momentum will be conserved.\n\n\n\nExample: Conservation of Angular Momentum\nSuppose again a single particle is moving through space. Suppose this time that space is isotropic, that is, the particle’s Lagrangian is invariant to rotations in space, \\[\nL(\\mathbf{x}, \\mathbf{\\dot x}, t) = L\\big(\\delta\\mathbf{R}\\mathbf{x}, \\mathbf{\\dot x}, t\\big).\n\\] Now, we can always think of a rotation in space as a rotation about some axis. For simplicity we’ll choose that axis to be the \\(z\\)-axis, in which case we can think of \\(\\delta\\mathbf{R}\\) as rotating \\(\\mathbf{x}\\) by some azimuthal angle \\(\\delta\\varphi\\). Take as generalized coordinates the spherical coordinates \\(r, \\theta, \\varphi\\). Then rotational invariance is equivalent to saying the particle has a symmetry of the form \\(\\varphi(s) = \\varphi + s\\). We thus have \\[\nQ = p_r \\frac{\\partial r}{\\partial s} + p_\\theta \\frac{\\partial \\theta}{\\partial s} + p_\\varphi \\frac{\\partial \\varphi}{\\partial s} = p_\\varphi = const.\n\\] That is, the angular momentum \\(L_z = mr^2 \\dot \\varphi = const\\). Since choosing the \\(z\\)-axis as the rotation axis was arbitrary, this says the total angular momentum \\(\\mathbf{L} = const\\). That is, the angular momentum of the particle is conserved. Equivalently, if space is isotropic, then the total angular momentum will be conserved.\n\nWhat about energy though? When is it conserved? It turns out that energy conservation is connected to time translation invariance, which is a little bit more subtle. Suppose a Lagrangian had a time translational symmetry of the form \\(t(s) = t + s\\). Since all of \\(L\\), \\(\\mathbf{q}\\), and \\(\\mathbf{\\dot q}\\) depend explicitly on time, this means we’d have \\[\nL\\big(\\mathbf{q}(t), \\mathbf{\\dot q}(t), t\\big) = L\\big(\\mathbf{q}(t + s), \\mathbf{\\dot q}(t + s), t + s\\big).\n\\] Following along the proof of Noether’s Theorem, we’d have \\[\n0 = \\frac{\\partial L}{\\partial s} = \\frac{\\partial L}{\\partial t} \\frac{\\partial t}{\\partial s} = \\frac{\\partial L}{\\partial t}.\n\\] That is, \\(\\frac{\\partial L}{\\partial t} = 0\\), which means now time is cyclic, and the Lagrangian doesn’t have any explicit time dependence. Now, if we take the total time derivative of the Lagrangian, we get \\[\n\\begin{align*}\n\\frac{dL}{dt} &= \\frac{\\partial L}{\\partial \\mathbf{q}} \\cdot \\mathbf{\\dot q} + \\frac{\\partial L}{\\partial \\mathbf{\\dot q}} \\cdot \\mathbf{\\ddot q} + \\frac{\\partial L}{\\partial t} \\\\\n&= \\frac{d}{dt} \\frac{\\partial L}{\\partial \\mathbf{\\dot q}} \\cdot \\mathbf{\\dot q} + \\frac{\\partial L}{\\partial \\mathbf{\\dot q}} \\cdot \\mathbf{\\ddot q} + \\frac{\\partial L}{\\partial t} \\\\\n&= \\mathbf{\\dot p} \\cdot \\mathbf{\\dot q} + \\mathbf{p} \\cdot \\mathbf{\\ddot q} + \\frac{\\partial L}{\\partial t} \\\\\n&= \\frac{d}{dt} \\mathbf{p} \\cdot \\mathbf{\\dot q} + \\frac{\\partial L}{\\partial t}.\n\\end{align*}\n\\] When time is cyclic, we must have \\[\nH \\equiv \\mathbf{p} \\cdot \\mathbf{\\dot q} - L = const.\n\\] This function is called the Hamiltonian. We’ve just shown that when a system is time translation invariant, its Hamiltonian must be conserved, whatever that is.\nTo see what exactly \\(H\\) is, let’s consider a Lagrangian of the form \\[\nL = T - V = \\frac{1}{2} \\mathbf{\\dot q} \\cdot \\mathbf{T}(\\mathbf{q}) \\cdot \\mathbf{\\dot q} - V(\\mathbf{q}).\n\\] In this case, the Hamiltonian would be \\[\n\\begin{align*}\nH &= \\frac{\\partial L}{\\partial \\mathbf{\\dot q}} \\cdot \\mathbf{\\dot q} - L \\\\\n&= \\mathbf{\\dot q} \\cdot \\mathbf{T}(\\mathbf{q}) \\cdot \\mathbf{\\dot q} - \\frac{1}{2} \\mathbf{\\dot q} \\cdot \\mathbf{T}(\\mathbf{q}) \\cdot \\mathbf{\\dot q} + V(\\mathbf{q}) \\\\\n&= \\frac{1}{2} \\mathbf{\\dot q} \\cdot \\mathbf{T}(\\mathbf{q}) \\cdot \\mathbf{\\dot q} + V(\\mathbf{q}) \\\\\n&= T + V. \\\\\n\\end{align*}\n\\] That is, if \\(L = T-V\\), then \\(H=T+V\\). But \\(T+V\\) is just the total energy \\(E\\). We thus finally have the conservation of energy. If \\(L = T-V\\) and time is homogeneous, then the total energy \\(E\\) is conserved."
  },
  {
    "objectID": "classical-mechanics/lagrangian-mechanics.html#non-conservative-forces",
    "href": "classical-mechanics/lagrangian-mechanics.html#non-conservative-forces",
    "title": "Lagrangian Mechanics",
    "section": "Non-Conservative Forces",
    "text": "Non-Conservative Forces\nAs we’ve derived them, Lagrange’s equations only hold for systems with conservative forces. In some special cases, we can augment non-conservative forces into Lagrange’s equations as well. Suppose for example we had \\(L = T - U\\), where \\(U = U(\\mathbf{q}, \\mathbf{\\dot q}, t)\\) is some kind of generalized potential energy. Then the generalized forces have the form \\[\n\\mathbf{Q} = - \\frac{\\partial U}{\\partial \\mathbf{q}} + \\frac{d}{dt} \\frac{\\partial U}{\\partial \\mathbf{\\dot q}}.\n\\] In this case, we can solve Lagrange’s equations for \\(L = T-U\\) and everything would work fine even though \\(U\\) is not a proper potential energy anymore.\n\n\nExample: Charged Particle in an Electromagnetic Field\nSuppose a particle of mass \\(m\\) and charge \\(q\\) is moving in the presence of an electromagnetic field. We already know that such a particle obeys the Lorentz force law \\[\n\\mathbf{F} = q \\mathbf{E}(\\mathbf{x},t) + \\frac{q}{c} \\mathbf{v} \\times \\mathbf{B}(\\mathbf{x},t).\n\\] Can we derive this from a Lagrangian? Notice that this force isn’t conservative since it’s a function of the particle’s velocity. However, we can still derive a generalized potential energy \\(U=U(\\mathbf{x},\\mathbf{v},t)\\) as follows. We know from electrodynamics that we can express the electric field \\(\\mathbf{E}\\) and magnetic field \\(\\mathbf{B}\\) as derivatives of a scalar potential \\(\\phi\\) and a vector potential \\(\\mathbf{A}\\), \\[\n\\begin{align*}\n\\mathbf{E}(\\mathbf{x},t) &= - \\nabla \\phi(\\mathbf{x},t) - \\frac{1}{c} \\frac{\\partial}{\\partial t} \\mathbf{A}(\\mathbf{x},t), \\\\\n\\mathbf{B}(\\mathbf{x},t) &= \\nabla \\times \\mathbf{A}(\\mathbf{x},t). \\\\\n\\end{align*}\n\\] Let’s define \\[\nU(\\mathbf{x},\\mathbf{v},t) = q \\phi(\\mathbf{x},t) - \\frac{q}{c} \\mathbf{v} \\cdot \\mathbf{A}(\\mathbf{x},t).\n\\] Then the Lagrangian for this system is then given by \\(L=T-U\\), or \\[\nL = \\frac{1}{2} m \\mathbf{v}^2 - q \\phi + \\frac{q}{c} \\mathbf{v} \\cdot \\mathbf{A}.\n\\] Though a little painful, it’s not hard to show that solving Lagrange’s equations reproduces the above Lorentz force law.\n\nMore generally, we can always just manually add in any non-conservative forces to the equations of motion after Lagrange’s equations have been solved, but they’d need to be converted to generalized forces first. Given some force \\(\\mathbf{F}\\), we can augment Lagrange’s equations by writing \\[\n\\frac{\\partial L}{\\partial\\mathbf{q}} - \\frac{d}{dt}\\frac{\\partial L}{\\partial\\mathbf{\\dot q}} = \\mathbf{Q},\n\\] where \\(\\mathbf{Q} = \\mathbf{F} \\cdot \\frac{\\partial \\mathbf{x}}{\\partial \\mathbf{q}}\\) is the associated generalized force.\nIn the special case that a non-conservative force is linear in the generalized velocities, we can augment the Lagrangian by defining the Rayleigh dissipation function \\(\\mathcal{F}\\) given by \\[\n\\mathcal{F} \\equiv \\frac{1}{2} \\mathbf{\\dot q} \\cdot \\mathbf{B}(\\mathbf{q}) \\cdot \\mathbf{\\dot q} = \\sum_{i,j} b_{ij}(\\mathbf{q}) \\dot q_i \\dot q_j.\n\\] In this case, the generalized forces are just the gradients of \\(\\mathcal{F}\\), \\[\n\\mathbf{Q} = -\\frac{\\partial \\mathcal{F}}{\\partial \\mathbf{q}} = -\\mathbf{B} \\cdot \\mathbf{\\dot q},\n\\] which we can plug into the modified Lagrange’s equations to give \\[\n\\frac{\\partial L}{\\partial\\mathbf{q}} - \\frac{d}{dt}\\frac{\\partial L}{\\partial\\mathbf{\\dot q}} = \\frac{\\partial \\mathcal{F}}{\\partial\\mathbf{\\dot q}}.\n\\]\n\n\n\nExample: Damped Hanging Spring\nSuppose we have a spring with mass \\(m\\) and spring constant \\(k\\) allowed to hang from the top of a closed lid of thick syrup. Assume the viscosity of the syrup is high enough that Stoke’s Law holds.\nIn this case, we simply have \\[\n\\begin{align*}\nT &= \\frac{1}{2} m \\dot x^2, \\\\\nV &= -mgx - \\frac{1}{2} kx^2, \\\\\nL &= \\frac{1}{2} m \\dot x^2 + mgx + \\frac{1}{2} kx^2, \\\\\n\\mathcal{F} &= \\frac{1}{2} b \\dot x^2. \\\\\n\\end{align*}\n\\] Plugging these into the modified Lagrange’s equations finally gives the DDHO equation of motion \\[\nm \\ddot x + b \\dot x + kx = mg.\n\\]"
  },
  {
    "objectID": "classical-mechanics/lagrangian-mechanics.html#invariant-transformations",
    "href": "classical-mechanics/lagrangian-mechanics.html#invariant-transformations",
    "title": "Lagrangian Mechanics",
    "section": "Invariant Transformations",
    "text": "Invariant Transformations\nIt’s natural to ask what kinds of transformations of a Lagrangian leave it invariant. We already saw that when a system has certain symmetries that the Lagrangian will be invariant under those symmetry transformations. In that case, the Lagrangian itself didn’t change. More general, we could ask what kinds of transformations will leave the equations of motion unchanged, even if the Lagrangian itself did change.\nOne natural question to ask is how the Lagrangian behaves under a coordinate transformation. After all, the choice of coordinates should not affect the physical behavior of the system. Suppose we have two sets of coordinates to describe the system, \\(\\mathbf{q}\\) and \\(\\mathbf{Q}\\). They’re related by a transformation \\(\\mathbf{Q} = \\mathbf{Q}(\\mathbf{q})\\), called a point transformation. The transformed velocities \\(\\mathbf{\\dot Q}\\) are a function of both \\(\\mathbf{q}\\) and \\(\\mathbf{\\dot q}\\), since \\[\n\\mathbf{\\dot Q} = \\mathbf{\\dot Q}(\\mathbf{q}, \\mathbf{\\dot q}) = \\mathbf{\\dot q}\\frac{\\partial \\mathbf{Q}}{\\partial \\mathbf{q}}.\n\\] Suppose the Lagrangian in each coordinate system is given by \\(L_q = L(\\mathbf{q}, \\mathbf{\\dot q}, t)\\) and \\(L_Q = L(\\mathbf{Q}, \\mathbf{\\dot Q}, t)\\) respectively. Assume that \\(L_q\\) satisfies Lagrange’s equations, so \\[\n\\frac{\\partial L_q}{\\partial \\mathbf{q}} + \\frac{d}{dt} \\frac{\\partial L_q}{\\partial \\mathbf{\\dot q}} = \\mathbf{0}.\n\\] What then can we conclude about \\(L_Q\\)? If we express \\(L_Q\\) in terms of \\(\\mathbf{q}\\), we’d have \\[\nL_Q = L\\big(\\mathbf{q}(\\mathbf{Q}), \\mathbf{\\dot q}(\\mathbf{Q}, \\mathbf{\\dot Q}), t\\big).\n\\] Taking derivatives of \\(L_Q\\) with respect to \\(\\mathbf{Q}\\), then \\[\n\\begin{align*}\n\\frac{\\partial L_Q}{\\partial \\mathbf{Q}} &=  \\frac{\\partial \\mathbf{q}}{\\partial \\mathbf{Q}} \\cdot \\frac{\\partial L_q}{\\partial \\mathbf{q}} + \\frac{\\partial \\mathbf{\\dot q}}{\\partial \\mathbf{Q}} \\cdot \\frac{\\partial L_q}{\\partial \\mathbf{\\dot q}} \\\\\n&= \\frac{\\partial \\mathbf{q}}{\\partial \\mathbf{Q}} \\cdot \\frac{d}{dt} \\frac{\\partial L_q}{\\partial \\mathbf{\\dot q}} + \\frac{d}{dt} \\frac{\\partial \\mathbf{q}}{\\partial \\mathbf{Q}} \\cdot \\frac{\\partial L_q}{\\partial \\mathbf{\\dot q}} \\\\\n&= \\frac{d}{dt} \\bigg(\\frac{\\partial \\mathbf{q}}{\\partial \\mathbf{Q}} \\cdot \\frac{\\partial L_q}{\\partial \\mathbf{\\dot q}}\\bigg) \\\\\n&= \\frac{d}{dt} \\bigg(\\frac{\\partial \\mathbf{\\dot q}}{\\partial \\mathbf{\\dot Q}} \\cdot \\frac{\\partial L_q}{\\partial \\mathbf{\\dot q}}\\bigg) \\\\\n&= \\frac{d}{dt} \\frac{\\partial L_Q}{\\partial \\mathbf{\\dot Q}}.\n\\end{align*}\n\\] Thus, if \\(L_q\\) satisfies Lagrange’s equations with respect to \\(\\mathbf{q}\\), then \\(L_Q\\) satisfies Lagrange’s equations with respect to \\(\\mathbf{Q}\\). That is, the equations of motion are invariant to point transformations of the coordinates.\nThis fact means we’re essentially free to write the Lagrangian of a system in whatever set of coordinates we wish. The underlying physics will stay the same. In relativistic language, this result says that the Lagrangian is a proper scalar. It doesn’t transform under coordinate transformations.\nIt’s also natural to ask if we can add functions to a Lagrangian in a way that leave the equations of motion invariant. This leads to the notion of a gauge transformation. To leave the equations of motion invariant, it’s important that any such transformation leave the action stationary.\nSuppose we transformed a valid Lagrangian by adding a total time derivative to it, \\[\n\\tilde L(\\mathbf{q}, \\mathbf{\\dot q}, t) = L(\\mathbf{q}, \\mathbf{\\dot q}, t) + \\frac{d}{dt} F(t).\n\\] If we assume the original equations of motion satisfy the principle of least action, we have \\(\\delta S=0\\), where \\[\nS = \\int_{t_1}^{t_2} L(\\mathbf{q}, \\mathbf{\\dot q}, t) dt.\n\\] Evidently, the modified action \\(\\tilde S\\) has the form \\[\n\\begin{align*}\n\\tilde S &= \\int_{t_1}^{t_2} \\tilde L(\\mathbf{q}, \\mathbf{\\dot q}, t) dt \\\\\n&= \\int_{t_1}^{t_2} \\bigg(L(\\mathbf{q}, \\mathbf{\\dot q}, t) +  \\frac{d}{dt} F(t) \\bigg)dt \\\\\n&= \\int_{t_1}^{t_2} L(\\mathbf{q}, \\mathbf{\\dot q}, t)dt + F(t) \\bigg|_{t_1}^{t_2} \\\\\n&= S + \\Delta F.\n\\end{align*}\n\\] Since \\(\\Delta F\\) is a constant that depends only on the endpoints, we must have \\[\n\\delta S = 0 \\quad \\Longleftrightarrow \\quad \\delta\\tilde S = 0.\n\\] That is, adding a total time derivative to the Lagrangian leaves the equations of motion invariant.\n\n\nExample: Gauge Transformations\nIn electrodynamics, Maxwell’s Equations are known to be invariant under a change of gauge. We can add the derivative of any scalar field \\(\\lambda(\\mathbf{x},t)\\) to the electromagnetic potentials in the following way and leave Maxwell’s Equations invariant, \\[\n\\begin{align*}\n\\phi'(\\mathbf{x},t) &= \\phi(\\mathbf{x},t) - \\frac{1}{c} \\frac{\\partial}{\\partial t} \\lambda(\\mathbf{x},t), \\\\\n\\mathbf{A}'(\\mathbf{x},t) &= \\mathbf{A}(\\mathbf{x},t) + \\nabla \\lambda(\\mathbf{x},t). \\\\\n\\end{align*}\n\\] Suppose we had a particle moving in the presence of an electromagnetic field. We already showed such a Lagrangian would have the form \\[\nL = \\frac{1}{2} m \\mathbf{v}^2 - q \\phi(\\mathbf{x},t) + \\frac{q}{c} \\mathbf{v} \\cdot \\mathbf{A}(\\mathbf{x},t).\n\\] Let’s ask what happens to the Lagrangian if we gauge-transform the potentials. Evidently, \\[\n\\begin{align*}\nL' &= \\frac{1}{2} m \\mathbf{v}^2 - q \\phi' + \\frac{q}{c} \\mathbf{v} \\cdot \\mathbf{A}' \\\\\n&= \\frac{1}{2} m \\mathbf{v}^2 - q \\bigg(\\phi - \\frac{1}{c} \\frac{\\partial \\lambda}{\\partial t} \\bigg) + \\frac{q}{c} \\mathbf{v} \\cdot (\\mathbf{A} + \\nabla \\lambda) \\\\\n&= \\bigg(\\frac{1}{2} m \\mathbf{v}^2 - q\\phi + \\frac{q}{c}\\mathbf{v} \\cdot \\mathbf{A}\\bigg) + \\frac{q}{c} \\bigg(\\mathbf{v} \\cdot \\nabla \\lambda + \\frac{\\partial \\lambda}{\\partial t}\\bigg) \\\\\n&= L + \\frac{q}{c} \\frac{d\\lambda}{dt}.\n\\end{align*}\n\\] Since the gauge-transformed Lagrangian is just the original Lagrangian plus a total time derivative, we can conclude the the Lorentz force law must be gauge invariant as well. Of course, this was already obvious from the fact that \\(\\mathbf{E}\\) and \\(\\mathbf{B}\\) were gauge invariant in Maxwell’s equations."
  },
  {
    "objectID": "classical-mechanics/lagrangian-mechanics.html#examples",
    "href": "classical-mechanics/lagrangian-mechanics.html#examples",
    "title": "Lagrangian Mechanics",
    "section": "Examples",
    "text": "Examples\nIt’s good to get very comfortable being able to find the equations of motion of systems using Lagrange’s equations. Here are some more complicated examples, many of which would be highly non-trival to solve using Newton’s Laws.\n\n\nExample: Uniform Rod on a Frictionless Table\n\n\n\n\n\n\n\n\nExample: Atwood Machine\n\n\n\n\n\n\n\n\nExample: Particle on a Cylinder\n\n\n\n\n\n\n\n\nExample: Block Sliding on Moving Wedge\n\n\n\n\n\n\n\n\nExample: Bead on a Wire"
  },
  {
    "objectID": "classical-mechanics/coupled-oscillations.html#one-dimensional-systems",
    "href": "classical-mechanics/coupled-oscillations.html#one-dimensional-systems",
    "title": "Coupled Oscillations",
    "section": "One-Dimensional Systems",
    "text": "One-Dimensional Systems\nConsider a system with one degree of freedom \\(q\\) in the presence of a potential energy \\(V(q)\\). We say such a system has an equilibrium point at \\(q=q_0\\) provided \\[\nF = -\\frac{dV}{dq} \\bigg|_{q=q_0} = 0.\n\\] Equivalently, \\(q_0\\) is an equilibrium point if it’s a stationary point of \\(V(q)\\). We say \\(q_0\\) is stable if it’s a local minimum of \\(V(q)\\), unstable if it’s a local maximum of \\(V(q)\\), and semi-stable if it’s a saddlepoint. In general, a potential energy \\(V(q)\\) may have many different equilibrium points.\n\n\n\n\n\nNow, if we expand \\(V(q)\\) in a Taylor Series about \\(q_0\\), we get \\[\nV(q) = V(q_0) + \\frac{dV}{dq}\\bigg|_{q_0} (q - q_0) + \\frac{1}{2} \\frac{d^2 V}{dq^2}\\bigg|_{q_0} (q - q_0)^2 + O\\big((q-q_0)^3\\big).\n\\] Since only differences in potential energy can affect the dynamics of a system, we can suppose without loss of generality that \\(V(q_0) = 0\\). Since \\(q_0\\) is an equilibrium point, we must also have \\(\\frac{dV}{dq}\\big|_{q_0} = 0\\). We’re thus left with \\[\nV(q) = \\frac{1}{2} \\frac{d^2 V}{dq^2}\\bigg|_{q_0} (q - q_0)^2 + O\\big((q-q_0)^3\\big).\n\\] We can always re-center the system so that \\(q_0=0\\). If we define \\(k \\equiv \\frac{d^2 V}{dq^2}\\big|_{q_0}\\), we evidently have \\[\nV(q) = \\frac{1}{2} k q^2.\n\\] But this is just the potential energy for Hooke’s Law, since \\(F = -\\frac{dV}{dq} = -kq\\). We’ve thus evidently defined Hooke’s Law from the assumption that a system is undergoing small motions near an equilibrium point.\nMotions will only be small oscillations if the equilibrium point \\(q_0\\) is stable, which is equivalent to requiring that \\(k > 0\\) since \\(V(q_0)\\) is locally convex. If \\(k < 0\\) the motion will be unstable since \\(V(q_0)\\) is locally concave. If \\(k=0\\) we run into a special case where we have to consider higher orders in the Taylor Series expansion. In this case, motion will be very near constant around \\(q_0\\), but can either grow or decay as \\(q\\) gets farther from \\(q_0\\).\nWe can also plug \\(V(q)\\) into the Lagrangian and get \\[\nL \\approx \\frac{1}{2}m \\dot q^2 - \\frac{1}{2} k q^2,\n\\] which is of course just the Lagrangian for SHO. We’ve thus derived the following important fact: Any 1-dimensional system undergoing small oscillations near a stable equilibrium point can be well-approximated by a simple harmonic oscillator.\n\n\nExample: Kepler Orbits\nRecall for Kepler orbits we have a Lagrangian \\(L = \\frac{1}{2}m\\dot r^2 - V_{eff}(r)\\), where \\[\nV_{eff}(r) = \\frac{\\ell^2}{2mr^2} - \\frac{GMm}{r}.\n\\] This effective potential has a stable equilibrium when the orbits are circular, i.e. \\(r=r_0\\).\nSetting the first derivative of \\(V_{eff}(q)\\) to zero gives \\[\n\\frac{dV_{eff}}{dr}\\bigg|_{r_0} = -\\frac{\\ell^2}{mr_0^3} + \\frac{GMm}{r_0^2} = 0 \\quad \\Longrightarrow \\quad r_0 = \\frac{\\ell^2}{GMm^2}.\n\\] Setting the second derivative to \\(k\\) gives \\[\nk = \\frac{d^2V_{eff}}{dr^2}\\bigg|_{r_0} = 3\\frac{\\ell^2}{mr_0^4} - 2\\frac{GMm}{r_0^3} = \\frac{GMm}{r_0^3} > 0.\n\\] Thus, the Kepler orbit undergoes stable oscillations about the point \\(r=r_0\\), with a force law \\(F(r) \\approx -k(r-r_0)\\). The oscillation frequency and period are given by \\[\n\\omega = \\sqrt{\\frac{k}{m}} = \\sqrt{GM}{r_0^3} \\quad \\Longrightarrow \\quad \\tau = \\frac{2\\pi}{\\sqrt{GM}} r_0^{3/2},\n\\] which is just Kepler’s Third Law for circular orbits.\n\n\n\nExample: Two Coupled Springs\nBefore deriving the general form for the solution of coupled linear systems, let’s try to solve the problem of two springs attached to each other in sequence. Assume both masses have mass \\(m\\). Assume the springs attached to the walls have spring constant \\(k\\), and the coupling spring constant between the two masses is \\(k_{12}\\).\n\n\n\n\n\nDenote the position of mass one relative to its equilibrium as \\(x_1\\), and the position of mass two relative to its equilibrium by \\(x_2\\). Then the Lagrangian is \\[\nL = \\frac{1}{2} m (\\dot x_1^2 + \\dot x_2^2) - \\frac{1}{2}(kx_1^2 + k_{12}(x_2-x_1)^2 + kx_2^2).\n\\] The equations of motion are thus given by \\[\n\\begin{align*}\nm \\ddot x_1 &= -kx_1 + k_{12}(x_2 - x_1), \\\\\nm \\ddot x_2 &= -kx_1 - k_{12}(x_2 - x_1).\n\\end{align*}\n\\] This is a coupled system of two linear differential equations. To solve, let’s suppose that both solutions are sinusoidal with the same frequency \\(\\omega\\), say \\(x_1 = A_1 \\cos\\omega t\\) and \\(x_2 = A_2 \\cos\\omega t\\). Then we have"
  },
  {
    "objectID": "classical-mechanics/coupled-oscillations.html#general-problem",
    "href": "classical-mechanics/coupled-oscillations.html#general-problem",
    "title": "Coupled Oscillations",
    "section": "General Problem",
    "text": "General Problem\nLet’s now consider a system with \\(n\\) degrees of freedom \\(q_1, q_2, \\cdots, q_n\\) given by a Lagrangian \\[\nL = \\frac{1}{2} \\dot q_i T_{ij}(q_1,\\cdots,q_n) \\dot q_j - V(q_1,\\cdots,q_n).\n\\] Let’s re-write this in vector notation by defining \\(\\mathbf{q} \\equiv (q_1,q_2,\\cdots,q_n)\\) and \\(\\mathbf{T} \\equiv (T_{ij})\\). Then we have \\[\nL = \\frac{1}{2}\\mathbf{\\dot q}^\\top \\mathbf{T}(\\mathbf{q}) \\mathbf{\\dot q} - V(\\mathbf{q}).\n\\] Now, suppose \\(\\mathbf{q}_0\\) is an equilibrium point of the system. Since the kinetic energy depends on \\(\\mathbf{q}\\) we’ll have to Taylor expand the entire Lagrangian about \\(\\mathbf{q}_0\\). For \\(V(\\mathbf{q})\\) we have \\[\nV(\\mathbf{q}) = V(\\mathbf{q}_0) + \\nabla V^\\top(\\mathbf{q}_0) (\\mathbf{q}-\\mathbf{q}_0) + \\frac{1}{2} (\\mathbf{q}-\\mathbf{q}_0)^\\top \\mathbf{H}(\\mathbf{q_0}) (\\mathbf{q}-\\mathbf{q}_0) + O\\big(||\\mathbf{q}-\\mathbf{q}_0||^3\\big).\n\\] Again, only differences in potential energy matter, so we can define \\(V(\\mathbf{q}_0) = 0\\). Furthermore, since \\(\\mathbf{q}_0\\) is an equilibrium point, we must have \\(\\nabla V(\\mathbf{q}_0) = \\mathbf{0}\\). Let’s define \\(\\mathbf{K} \\equiv \\mathbf{H}(\\mathbf{q}_0)\\). Then, to second-order in \\(\\mathbf{q}-\\mathbf{q}_0\\) we have \\[\nV(\\mathbf{q}) \\approx \\frac{1}{2} (\\mathbf{q}-\\mathbf{q}_0)^\\top \\mathbf{K} (\\mathbf{q}-\\mathbf{q}_0).\n\\] For the kinetic energy term, expanding \\(\\mathbf{T}(\\mathbf{q})\\) about \\(\\mathbf{q}_0\\) in a similar manner gives \\[\n\\mathbf{T}(\\mathbf{q}) = \\mathbf{T}(\\mathbf{q}_0) + O\\big(||\\mathbf{q}-\\mathbf{q}_0|| \\big).\n\\] Defining \\(\\mathbf{M} \\equiv \\mathbf{T}(\\mathbf{q}_0)\\) and dropping terms of higher order, we have \\(\\mathbf{T}(\\mathbf{q}) \\approx \\mathbf{M}\\). Plugging both of these terms into the Lagrangian and keeping only terms quadratic in \\(\\mathbf{q}\\) and \\(\\mathbf{q}_0\\), we finally have, \\[\nL \\approx \\frac{1}{2} \\mathbf{\\dot q}^\\top \\mathbf{M} \\mathbf{\\dot q} - \\frac{1}{2} (\\mathbf{q}-\\mathbf{q}_0)^\\top \\mathbf{K} (\\mathbf{q}-\\mathbf{q}_0).\n\\] This is the most general form of the Lagrangian for a many-body mechanical system when expanded to quadratic order about an equilibrium point. Most of the time we’ll want to re-center so that \\(\\mathbf{q}_0 = \\mathbf{0}\\). In that case, the Lagrangian reduces to just \\[\nL \\approx \\frac{1}{2} \\mathbf{\\dot q}^\\top \\mathbf{M} \\mathbf{\\dot q} - \\frac{1}{2} \\mathbf{q}^\\top \\mathbf{K} \\mathbf{q}.\n\\] Notice this looks exactly like the scalar Lagrangian for SHO, \\(L = \\frac{1}{2}m \\dot q^2 - \\frac{1}{2} k q^2\\), except everything is in matrix-vector notation now.\nWe can solve Lagrange’s equations in matrix-vector notation now, \\[\n\\frac{dL}{d\\mathbf{q}} + \\frac{d}{dt}\\frac{dL}{d\\mathbf{\\dot q}} = \\mathbf{0}.\n\\] Solving this system simply gives the vector equations of motion \\[\n\\mathbf{M}\\mathbf{\\ddot q} = -\\mathbf{K}\\mathbf{q},\n\\] which is the \\(n\\)-dimensional generalization of Hooke’s Law.\nAssuming \\(\\mathbf{M}\\) is invertible, we can define \\(\\mathbf{\\Omega}^2 \\equiv \\mathbf{M}^{-1} \\mathbf{K}\\), and write \\[\n\\mathbf{\\ddot q} = -\\mathbf{\\Omega}^2 \\mathbf{q}.\n\\] The nature of the solutions will depend on the definiteness of \\(\\mathbf{\\Omega}^2\\). Evidently, if \\(\\mathbf{\\Omega}^2\\) is positive definite, the solutions will be stable. If \\(\\mathbf{\\Omega}^2\\) is negative definite, the solutions will be unstable.\nSkip to the rest of the theory before doing more examples…\nPer ChatGPT: The general solution to the coupled oscillator \\(M \\ddot x = -K x\\) in closed form can be written as \\[\nx(t) = V \\cos(\\Omega t) c + V \\sin(\\Omega t) d,\n\\] where \\(V\\) is the matrix of eigenvectors of \\(\\Omega^2 = M^{-1} K\\), and \\(c, d\\) are initial condition vectors.\nVerify this!!!"
  },
  {
    "objectID": "circuits/circuit-abstraction.html#maxwells-equations",
    "href": "circuits/circuit-abstraction.html#maxwells-equations",
    "title": "The Lumped Circuit Abstraction",
    "section": "Maxwell’s Equations",
    "text": "Maxwell’s Equations\nMaxwell’s Equations are taught in electrodynamics courses. In SI units, they’re given as follows.\n\n\n\n\n\n\n\n\nName\nDifferential Form\nIntegral Form\n\n\n\n\nGauss’s Law\n\\(\\nabla \\cdot \\mathbf{E} = \\frac{\\rho}{\\varepsilon_0}\\)\n\\(\\oint \\mathbf{E} \\cdot d\\mathbf{a} = \\frac{q}{\\varepsilon_0}\\)\n\n\nFaraday’s Law\n\\(\\nabla \\times \\mathbf{E} = -\\frac{\\partial \\mathbf{B}}{\\partial t}\\)\n\\(\\oint \\mathbf{E} \\cdot d\\boldsymbol{\\ell} = -\\frac{\\partial \\Phi_M}{\\partial t}\\)\n\n\nNo Magnetic Monopoles\n\\(\\nabla \\cdot \\mathbf{B} = 0\\)\n\\(\\oint \\mathbf{B} \\cdot d\\mathbf{a} = 0\\)\n\n\nAmpere’s Law\n\\(\\nabla \\times \\mathbf{B} = \\mu_0 \\mathbf{J} + \\frac{1}{\\varepsilon_0 \\mu_0} \\frac{\\partial \\mathbf{E}}{\\partial t}\\)\n\\(\\oint \\mathbf{B} \\cdot d\\boldsymbol{\\ell} = \\mu_0 I + \\frac{1}{\\varepsilon_0 \\mu_0} \\frac{\\partial \\Phi_E}{\\partial t}\\)\n\n\nContinuity Equation\n\\(\\frac{\\partial \\rho}{\\partial t} - \\nabla \\cdot \\mathbf{J} = 0\\)\n\\(\\frac{\\partial q}{\\partial t} - \\oint \\mathbf{J} \\cdot d\\mathbf{a} = 0\\)\n\n\n\nRather than use these equations directly we’ll derive three simpler laws that hold for circuits:\n\nOhm’s Law: \\(v = iR\\).\nKirchoff’s Voltage Law (KVL): \\(\\sum_{loop} v = 0\\).\nKirchoff’s Current Law (KCL): \\(\\sum_{node} i = 0\\)."
  },
  {
    "objectID": "circuits/circuit-abstraction.html#ohms-law",
    "href": "circuits/circuit-abstraction.html#ohms-law",
    "title": "The Lumped Circuit Abstraction",
    "section": "Ohm’s Law",
    "text": "Ohm’s Law\nFor many materials, a linear relation holds between the electric field \\(\\mathbf{E}\\) inside the material and its current density \\(\\mathbf{J}\\). This is the Generalized Ohm’s Law: \\[\\mathbf{E} = \\rho \\mathbf{J},\\] where \\(\\rho\\) is the material’s resistivity. Consider a piece of cylindrical material, called a resistor, with a current \\(i\\) pumped through its ends.\n\n\n\n\n\nSince \\(\\mathbf{E} = E \\mathbf{e}_y\\) and \\(\\mathbf{J} = J \\mathbf{e}_y\\), and \\(A\\) and \\(\\ell\\) are constant, we have\n\\[\\begin{align*}\n\ni &= \\oint \\mathbf{J} \\cdot d\\mathbf{a} = J \\cdot A, \\\\\\\n\nv &= \\oint \\mathbf{E} \\cdot d\\mathbf{\\ell} = E \\cdot l.\n\n\\end{align*}\\]\nThus, we have \\(v = \\frac{\\rho \\ell}{A}i \\equiv Ri\\), where \\(R \\equiv \\frac{\\rho \\ell}{A}\\) is a constant, called the resistence of the material. The relation then becomes \\[v = iR,\\] which is the standard Ohm’s Law. Note Ohm’s Law as stated is only true for resistive materials."
  },
  {
    "objectID": "circuits/circuit-abstraction.html#the-lumped-circuit-abstraction",
    "href": "circuits/circuit-abstraction.html#the-lumped-circuit-abstraction",
    "title": "The Lumped Circuit Abstraction",
    "section": "The Lumped Circuit Abstraction",
    "text": "The Lumped Circuit Abstraction\nTo easily and reliably analyze circuits we make a number of simplifying assumptions, or abstractions. By restricting ourselves to situations where these abstractions hold, we set up a simpler playground in which to work.\nThe most fundamental abstraction in circuit analysis is the lumped circuit abstraction or LCA. In the LCA, we assume a circuit is made of a set of lumped elements that are connected to each other with ideal wires (i.e. wires with no voltage drop across any two points and a uniform current throughout).\nAs an example, let’s consider a lightbulb connected to a battery supplying a voltage \\(v\\), which causes a current \\(i\\) to flow across the bulb from the positive terminal of the battery to the negative terminal.\n\n\n\n\n\nWe’d like to solve for the current \\(i\\) as a function of the input voltage \\(v\\). How should we do this? The hard way would be to just use Maxwell’s Equations. But this is unnecessary.\nNotice that we don’t care about many of the physical properties of the circuit, including the bulb’s shape, temperature, filament design, or what the wires are made of. We only care about the bulb’s resistance, since Ohm’s law says \\(v=iR\\). We can thus abstract the details of the bulb and the battery away, treating the bulb as a resistor and the battery as a voltage source.\n\n\n\n\n\nOnce we’ve done this, we can simply solve for the current in terms of the voltage simply as \\[i = \\frac{v}{R}.\\]\nA more abstract way to express this simple circuit is to use special symbols for the resistor and the voltage source. We’d write the exact same setup like this.\n\n\n\n\n\nNow, how do we know we can do this? How do we even know that \\(v\\) and \\(i\\) are even defined? After all, neither voltage nor current need exist in a well-defined way. However, under certain conditions, they do exist. Consider the following setup, where a current \\(i\\) flows through a wire from \\(A\\) to \\(B\\). The voltage across the wire is \\(v\\). The cross-sectional areas through \\(A\\) and \\(B\\) are \\(s_A\\) and \\(s_B\\), respectively.\n\n\n\n\n\nBy the continuity equation, we have \\[i_A - i_B \\equiv \\int_{s_A} \\mathbf{J} \\cdot d\\mathbf{a} - \\int_{s_B} \\mathbf{J} \\cdot d\\mathbf{a} = \\frac{\\partial q}{\\partial t}.\\] Provided no charge can build up inside the wire, we have \\[\\frac{\\partial q}{\\partial t} = 0 \\Rightarrow i_A = i_B \\equiv i.\\] That is, we have a well-defined current \\(i\\) flowing through the wire provided we forbid a buildup of charge inside the wire.\nBy Faraday’s Law, we also have \\[v_A - v_B \\equiv \\int_A^B \\mathbf{E} \\cdot d \\boldsymbol{\\ell} = -\\frac{\\partial \\Phi_M}{\\partial t}.\\] Provided magnetic flux is constant outside the wires, we can conclude \\[\\frac{\\partial \\Phi_M}{\\partial t} = 0 \\Rightarrow v_A = v_b \\equiv v.\\] That is, we have a well-defined voltage \\(v\\) across the wire provided we forbid any change in magnetic flux outside the wire.\nThe last condition we must require is that currents move much slower than the speed of light. This says that currents aren’t allowed to radiate.\nThe requirement that circuits obey each of these properties is called the lumped matter discipline:\n\nElements are discrete and independent of each other.\nNo charge can build up inside of wires.\nMagnetic flux is constant outside of the circuit.\nCurrents must move much slower than the speed of light."
  },
  {
    "objectID": "circuits/circuit-abstraction.html#lumped-elements",
    "href": "circuits/circuit-abstraction.html#lumped-elements",
    "title": "The Lumped Circuit Abstraction",
    "section": "Lumped Elements",
    "text": "Lumped Elements"
  },
  {
    "objectID": "statistical-mechanics/thermodynamics.html#thermodynamic-systems",
    "href": "statistical-mechanics/thermodynamics.html#thermodynamic-systems",
    "title": "Thermodynamics",
    "section": "Thermodynamic Systems",
    "text": "Thermodynamic Systems\nIn thermodynamics we seek to describe the macroscopic properties of a thermodynamic system. Unlike in classical mechanics, we won’t think of a system as a particle or a collection of particles, but rather as an object describable by a set of macroscopic properties. By macroscopic we mean properties that describe the state of the entire system, like its temperature, pressure, volume, etc. These properties are called state variables or thermodynamic coordinates.\nIn thermodynamics we’re interested in studying a few different kinds of systems, depending on what is allowed to flow into and out of the system. We assume the system is submerged in some external environment, called a heat bath.\n\nAn isolated system is a system in which no energy exchange is allowed with the heat bath, either through heat or work. Isolated systems have the property that total energy is conserved.\nAn adiabatic system is a system in which no heat exchange is allowed with the heat bath. An exchange of work is still allowed, which means total energy isn’t conserved.\nA closed system is a system in which energy is allowed to be exchanged with the heat bath, either through heat or work. The total energy of the closed system plus the heat bath is conserved.\nA diathermic system is a system in which heat is allowed to be exchanged with the heat bath, but work may or may not be exchanged.\n\nWe say a system is in equilibrium when its internal temperature has had sufficient time to relax to some steady state value. More precisely, the internal temperature doesn’t change appreciably over some given observation time. In a large sense, thermodynamics is about the study of equilibrium. We require that an equilibrium state exist for the system before we can even talk about thermodynamic variables. Of course, we haven’t even defined what temperature is, or shown that it must exist. We’ll do that in the next section.\nThe specific variables we seek to measure depend on the type of system under consideration. Here are some examples of mechanical variables that might depend on the system:\n\nGas in a container: We might be interested in its volume or the pressure it exerts on the container.\nA wire under tension: We might be interested in its length or the tension forces exerted on it.\nA magnet in a field: We might be interested in its magnetization or its external magnetic field.\n\nOn top of these mechanical variables that vary by system, we also may be interested in a system’s thermal variables, i.e. variables that arise due to the system’s internal interactions. The macroscopic thermal variables might be temperature, entropy, or heat."
  },
  {
    "objectID": "statistical-mechanics/thermodynamics.html#zeroth-law",
    "href": "statistical-mechanics/thermodynamics.html#zeroth-law",
    "title": "Thermodynamics",
    "section": "Zeroth Law",
    "text": "Zeroth Law\nSuppose we have three distinct systems \\(A\\), \\(B\\), and \\(C\\). The zeroth law of thermodynamics states that if \\(A\\) is in equilibrium with \\(B\\), and \\(B\\) is in equilibrium with \\(C\\), then \\(A\\) is in equilibrium with \\(C\\). That is, the property of equilibrium is transitive.\n\n\n\n\n\nNotice that for any two systems to be in equilibrium with each other they must be allowed to exchange heat. If they were isolated, even the smallest change to one system wouldn’t affect the other. The zeroth law evidently implies that this holds for any number of systems in equilibrium. You can’t isolate any one from the other, since heat can always flow through any two pairs of systems in equilibrium with each other.\nThe zeroth law implies the existence of a thermal quantity called the empirical temperature that’s the same among systems in equilibrium, a quantity that doesn’t change when no net heat is flowing between any two systems.\nTheorem: Suppose two systems \\(A\\) and \\(B\\) are in thermodynamic equilibrium with each other. Suppose \\(A\\) has thermodynamic coordinates \\(A_1, A_2, \\cdots, A_n\\) and \\(B\\) has thermodynamic coordinates \\(B_1, B_2, \\cdots, B_m\\). Then there exists a value \\(\\theta\\), called the empirical temperature, that depends only on the state of each system, and in equilibrium satisfies the property that for some functions of the coordinates \\[\n\\theta = \\theta_A(A_1, A_2, \\cdots, A_n) = \\theta_B(B_1, B_2, \\cdots, B_m).\n\\] Proof: Suppose a third system \\(C\\) is in equilibrium with \\(A\\) and \\(B\\) with coordinates \\(C_1, C_2, \\cdots, C_k\\). Since \\(A\\) is in equilibrium with \\(C\\), there must be some function of constraint \\(f_{AC}\\) such that \\[\nf_{AC}(A_1, A_2, \\cdots, A_n, C_1, C_2, \\cdots, C_k) = 0.\n\\] Similarly, if \\(B\\) is in thermal equilibrium with \\(C\\) then there is some other constraint function \\(f_{BC}\\) such that \\[\nf_{BC}(B_1, B_2, \\cdots, B_m, C_1, C_2, \\cdots, C_k) = 0.\n\\] Now, we can imagine solving for each function in terms of a common variable \\(C_1\\) to get new functions \\[\n\\begin{align*}\nC_1 &= g_{AC}(A_1, A_2, \\cdots, A_n, C_2, \\cdots, C_k), \\\\\nC_1 &= g_{BC}(B_1, B_2, \\cdots, B_m, C_2, \\cdots, C_k). \\\\\n\\end{align*}\n\\] Setting these two functions equal thus says that \\[\ng_{AC}(A_1, A_2, \\cdots, A_n, C_2, \\cdots, C_k) - g_{BC}(B_1, B_2, \\cdots, B_m, C_2, \\cdots, C_k) = 0.\n\\] By the zeroth law, we also know that \\(A\\) must be in thermal equilibrium with \\(B\\). This means there’s yet another function \\(f_{AB}\\) such that \\[\nf_{AB}(A_1, A_2, \\cdots, A_n, B_1, B_2, \\cdots, B_m) = 0.\n\\] Taken together, this says that we can take \\(f_{AB}\\) and spread it out into two functions \\(g_{AC}\\) and \\(g_{BC}\\), where \\(g_{AC}\\) depends only on the coordinates of \\(A\\) and \\(C\\), and \\(g_{BC}\\) depends only on the coordinates \\(B\\) and \\(C\\). If we imagine using the coordinates of \\(C\\) as some kind of reference values we can treat them as constants. That means we’re left with an expression of the form \\[\ng_{AC}(A_1, A_2, \\cdots, A_n, \\text{const}) - g_{BC}(B_1, B_2, \\cdots, B_k, \\text{const}) = 0.\n\\] This says we have a function of \\(A\\) that must equal a similar function of \\(B\\) at thermal equilibrium, \\[\n\\theta \\equiv \\theta_A(A_1, A_2, \\cdots, A_n) = \\theta_B(B_1, B_2, \\cdots, B_m). \\qquad \\text{Q.E.D.}\n\\] The empirical temperature is evidently reference dependent since we had to fix values for some third system \\(C\\) just to properly define it. We can choose \\(C\\) to be anything we like as long as we agree on a convention. The most common is the triple point of water, the state where water coexists in its gas, liquid, and solid forms simultaneously. This occurs at a temperature of about \\(T = 273.16 \\ \\degree \\text{K}\\) and pressure of about \\(p = 0.006 \\text{ atm}\\).\n\n\n\n\n\nThe condition that \\(\\theta = \\theta_A\\) says that in the space of coordinates of \\(A\\), in thermal equilibrium the system must be constrained to a surface of constant \\(\\theta_A = \\theta\\). This surface is called an isotherm, a surface of constant temperature. Similarly for \\(B\\).\nAnalogy: Think of defining temperature similarly to how one might empirically define mass by using a scale. You first establish a reference mass \\(C\\), for example some standard block of metal in a vault, and then use that to talk about how much the masses \\(A\\) and \\(B\\) weigh in units of \\(C\\).\n\nIdeal Gas\nOne practically useful way to define an empirical temperature scale uses the properties of the ideal gas. An ideal gas is a large number of dilute particles that satisfy the property that the product of the gas’s pressure \\(P\\) and volume \\(V\\) is proportional temperature in the dilute limit, i.e. \\[\n\\lim_{V \\rightarrow \\infty} PV = \\lim_{P \\rightarrow 0} PV \\propto \\theta.\n\\] We’ll assume the gas is allowed to interact diathermally with the heat bath. That is, the gas is allowed to exchange energy with its environment, but nothing else.\nSuppose now that we submerge the gas in one heat bath and record values for \\(P, V, \\theta\\) once the system has reached equilibrium. Then, we take the gas and submerge it again in a different reference heat bath. Once the system has again reached equilibrium, we again record the new values \\(P_0, V_0, \\theta_0\\). Now, since the gas is ideal, we must have \\[\n\\frac{\\theta}{\\theta_0} = \\frac{PV}{P_0 V_0}.\n\\] Provided we’ve fixed a value for \\(\\theta_0\\), we can thus define the temperature \\(T\\) of the system by \\[\nT \\equiv \\theta \\equiv \\theta_0 \\frac{PV}{P_0 V_0} = \\frac{\\theta_0}{P_0} \\frac{PV}{V_0}.\n\\] In the Kelvin scale, \\(\\theta_0\\) and \\(P_0\\) are again defined by the triple point of water. This means that to measure the temperature, we’d need to first measure the pressure and volume of the gas in the heat bath of interest, and then compare that with the volume the same gas would have at the triple point.\nFor an ideal gas, we evidently have the relation then that \\(PV \\propto T\\). It turns out that \\(PV\\) is also proportional to the number of particles \\(N\\) in the gas, \\(PV \\propto N\\). We can write the full ideal gas law in the form \\[\n\\boxed{PV = Nk_B T} \\ ,\n\\] where \\(k_B\\) is a proportionality constant, called the Boltzmann constant. Its value is measured to be \\[\n\\boxed{k_B = 1.381 \\cdot 10^{-23} \\frac{\\text{J}}{\\degree \\text{K}} \\approx \\frac{1}{40} \\frac{\\text{eV}}{\\degree \\text{K}}} \\ .\n\\]"
  },
  {
    "objectID": "statistical-mechanics/thermodynamics.html#first-law",
    "href": "statistical-mechanics/thermodynamics.html#first-law",
    "title": "Thermodynamics",
    "section": "First Law",
    "text": "First Law\nIn classical mechanics the conservation of energy is a fundamental principle of a microscopic system. We’d like to extend this idea to thermodynamics as well. Observations indicate that a similar principle operates at the level of macroscopic systems provided that the system is properly insulated, that is, when the only sources of energy are of mechanical origin.\n\nWork, Energy, Heat\nSuppose a thermodynamic system \\(A\\) is adiabatically isolated from its environment. If such a system is changed by some amount of work \\(\\Delta W\\), then the amount of work is only dependent on its initial and final state. That is, if \\(a_i=(A_{1,i}, \\cdots, A_{n,i})\\) is the initial state and \\(a_f=(A_{1,f}, \\cdots, A_{n,f})\\), then \\[\n\\Delta W = \\Delta E = E(a_f) - E(a_i),\n\\] where \\(E = E(a)\\) is some scalar function of state called the internal energy of the system. It’s the total energy of the system \\(A\\) when it’s adiabatically isolated.\nHaving a system be adiabatically isolated is a strong assumption that we’d like to relax, but doing so then means the system can exchange energy with its environment, which means \\(\\Delta W \\neq \\Delta E\\). There’s a flow of energy \\(\\Delta Q\\) in and out of the system now, called the heat. It’s the heat plus the work that’s conserved, \\[\n\\Delta E = \\Delta Q + \\Delta W.\n\\] This experimental fact is called the first law of thermodynamics. We assume this quantity called heat exists in such a fashion that the internal energy stays conserved. It’s not a theorem.\nAside: Note the work \\(\\Delta W\\) is done on the system, not by the system. Many engineering texts adopt the opposite convention, where they like to think of work being done by the system (e.g. by an engine). In that case, the \\(\\Delta W\\) would change its sign, in which case we’d write \\(\\Delta E = \\Delta Q - \\Delta W\\).\nSince thermodynamic state variables only make sense when a system is in equilibrium, if we want to think about the first law in differential form we have to imagine we can change the system differentially in such a way that it stays in equilibrium. Doing so is called a quasi-static process. We vary the system very slowly from its initial to its final state, allowing the system to come to equilibrium again at each point. This allows us to fill in the path continuously with points so we can then talk about differential changes.\nIn differential form, the first law of thermodynamics has the form \\[\n\\boxed{dE = \\delta Q + \\delta W} \\ .\n\\] The notation \\(\\delta Q\\) and \\(\\delta W\\) is used to make it explicit that those variables are path dependent. That is, they’re not a function of only the initial and final states. This means we can’t integrate them directly to get the total heat or work done. However, the energy is a state variable, it is a function only of its end points, and so we can integrate \\(dE\\) to get the total internal energy \\(\\Delta E\\), \\[\n\\Delta E = \\int dE = \\int (\\delta Q + \\delta W).\n\\]\n\n\nTypes of Work\nThe work done on the system is inherently mechanical in that it’s a sum of forces times displacements. Since we want to imagine generalized forces and generalized displacements, we’ll write it in the notation \\[\n\\delta W = \\sum_i J_i d X_i,\n\\] where \\(J_i\\) is a generalized force conjugate to some generalized displacement variable \\(X_i\\). Here are some of the most common conjugate force-displacement pairs:\n\n\n\n\n\n\n\n\nSystem\nGeneralized Force: \\(J\\)\nGeneralized Displacement: \\(X\\)\n\n\n\n\nWire\nTension: \\(F\\)\nLength: \\(L\\)\n\n\nFilm\nSurface Tension: \\(\\sigma\\)\nArea: \\(A\\)\n\n\nFluid\nPressure: \\(-P\\)\nVolume: \\(V\\)\n\n\nMagnet\nMagnetic Field: \\(B\\)\nMagnetization: \\(M\\)\n\n\nDielectric\nElectric Field: \\(E\\)\nPolarization: \\(P\\)\n\n\nChemical Reaction\nChemical Potential: \\(\\mu\\)\nParticle Number: \\(N\\)\n\n\n\nThe generalized forces have the property that their values are independent of the size of the system. Doubling the size of the system doesn’t double the forces acting on it. These are called intensive variables. Conversely, the generalized displacements are directly proportional to the size of the system. If the system’s size is doubled, so too are the displacements. These are called extensive variables. Intensive and extensive variables always tend to occur in conjugate pairs like this.\nUsing the new notation, we can re-write the work in the form \\[\n\\delta W = \\sum_{i=1}^k J_i dX_i.\n\\] For reasons we’ll get into soon, it’s also convenient to break up the work component into non-chemical and chemical work components. If we explicitly split off the chemical work terms, we’d instead write \\[\n\\delta W = \\sum_{i=1}^n J_i dX_i + \\sum_{j=1}^m \\mu_i dN_i.\n\\] Of course, we still don’t know how to simplify \\(\\delta Q\\) into a useful form. We’ll deal with that soon. For simplicity, in the rest of this section we’ll express things in vector notation by letting \\(J, dX, \\mu, dN\\) represent the vectorized forms of their component terms. Then we can just write the total work as just \\[\n\\delta W = J \\cdot dX + \\mu \\cdot dN.\n\\]\n\n\nHeat Capacities\nSuppose we pump some amount of heat \\(\\delta Q\\) into the system. Provided heat is a function of temperature, we’d have \\(\\Delta Q = C \\Delta T\\), where \\(C = C(T)\\) is some function of temperature, called the heat capacity. The functional form of \\(C\\) depends on the nature of the system. Evidently, the heat capacity is given by \\[\n\\boxed{C(T) \\equiv \\frac{\\delta Q}{dT}} \\ .\n\\] Since heat is path dependent, the heat capacity must be too. If \\(\\gamma\\) is some path taken to get from the initial to the final point in state space, then we might write \\(C = C_\\gamma\\) to be explicit about this. The most important case is when we’re dealing with a gas. If a gas is only has work done \\(\\delta W = -PdV\\), then we can think of the gas as only being a function of two state variables, \\(P\\) and \\(V\\). Two paths of interest in \\(pV\\)-space are paths of constant \\(P\\) or \\(V\\). Using the first law, the heat capacity \\(C_V\\) at constant volume is evidently \\[\nC_V = \\frac{\\delta Q_V}{dT} = \\frac{dE + PdV}{dT} \\bigg |_V = \\frac{\\partial E}{\\partial T}\\bigg |_V.\n\\] Similarly, the heat capacity \\(C_P\\) at constant pressure is evidently \\[\nC_P = \\frac{\\delta Q_P}{dT} = \\frac{dE + PdV}{dT} \\bigg |_P =  \\frac{\\partial E}{\\partial T}\\bigg |_P + P \\frac{\\partial V}{\\partial T} \\bigg |_P.\n\\] It turns out that the two \\(\\frac{\\partial E}{\\partial T}\\) derivatives are the same. This follows empirically from the Joule Free Expansion Experiment. Suppose we have two chambers connected by a thin hole that’s initially closed. Initially, all the gas is in the left chamber at an equilibrium temperature \\(T\\). Suppose the hole is then suddenly opened, allowing the gas to adiabatically expand into the right chamber.\n\n\n\n\n\nSince the gas isn’t pushing on anything, it can’t do any work. Since the process is adiabatic, no heat is flowing either. This means the total energy isn’t changing either. Once the system has settle down to equilibrium, the temperature in the two chambers must be the same. This evidently implies the energy must be a function of temperature alone, i.e. \\[\nE = E(T) = E(PV).\n\\] Using this fact, for an ideal gas we can evidently write \\[\nC_p - C_V = P \\frac{\\partial V}{\\partial T} \\bigg |_P.\n\\] Since \\(V = \\frac{Nk_B T}{P}\\), this reduces to just \\[\nC_P - C_V = N k_B.\n\\] It turns out that in fact \\(E \\propto PV\\). This result is called the equipartition theorem. It must be taken as an empirical law in thermodynamics, but it can be proven with statistical mechanics. The equipartition theorem says that an ideal gas whose individual particles each have \\(n\\) degrees of freedom will have a total energy given by \\[\n\\boxed{E = \\frac{n}{2} Nk_B T = \\frac{n}{2} PV} \\ .\n\\] For example, a monoatomic gas is a gas whose particles only have \\(n=3\\) translational degree of freedom. In that case, we’d have \\(E = \\frac{3}{2} PV\\). A diatomic gas is a gas whose particles also have two rotational degrees of freedom, giving \\(n=3+2=5\\) total degrees of freedom, and \\(E = \\frac{5}{2} PV\\).\nUsing the equipartition theorem, we can find the heat capacity of an ideal gas directly. Since \\[\n\\frac{d E}{d T} = \\frac{n}{2} Nk_B,\n\\] we evidently have \\[\nC_V = \\frac{n}{2} Nk_B, \\quad C_P = \\bigg(\\frac{n}{2}+1\\bigg) Nk_B.\n\\] Notice that these heat capacities are extensive since they’re both proportional to \\(N\\). In practice we’re interested in an intensive measure of how responsive heat is to changes in temperature. We can achieve this by dividing by \\(N\\) to get a specific heat. More commonly, specific heats are measured per unit mass, not per particle. If the system has mass \\(m\\), its specific heat capacity is defined by \\(c \\equiv \\frac{C}{m}\\).\nUsually it’s the specific heats that are tabulated for various substances. We’d need to look them up to do any kind of numerical calculations. The most useful specific heat to remember is the specific heat of water at standard temperature and pressure or STP, i.e. when \\(P \\approx 1 \\text{ atm}, T \\approx 300 \\ \\degree K\\). In energy units of calories, the specific heat of water at STP is just \\(c_P = 1 \\ \\frac{\\mathrm{cal}}{\\mathrm{g} \\mathrm{\\degree K}}\\). Note that the specific heat does depend on the phase of a substance. For example, ice has a specific heat of \\(c_P = 0.5 \\ \\frac{\\mathrm{cal}}{\\mathrm{g} \\mathrm{\\degree K}}\\).\nAnother important quantity that’s similar to the specific heat is the latent heat. It’s an intensive measure of how much heat is needed for a system to fully undergo a phase change. The most common definition is the change in heat per unit mass, \\[\n\\boxed{L \\equiv \\frac{\\Delta Q}{m}} \\ .\n\\] In general, latent heat values will be different than the specific heat values. They’ll also be different for different phase changes. For example, the latent heat of melting ice is \\(L = 80 \\ \\frac{\\text{cal}}{g}\\), while the latent heat of boiling water is \\(L = 540 \\ \\frac{\\text{cal}}{g}\\). Again, we’d look these up in tables when we need them."
  },
  {
    "objectID": "statistical-mechanics/thermodynamics.html#second-law",
    "href": "statistical-mechanics/thermodynamics.html#second-law",
    "title": "Thermodynamics",
    "section": "Second Law",
    "text": "Second Law\nWe saw that were able to break the work \\(\\delta W\\) up into a sum of generalized force-displacement pairs as \\(\\delta W = \\sum J_i dX_i\\). We’d like to be able to break up the heat \\(\\delta Q\\) somehow. It’s reasonable to assume that \\(T\\) is the generalized force for heat, but what is the generalized displacement? This leads us to the second law and the concept of entropy.\n\nEngines\nThe second law of thermodynamics arose historically out of an interest among engineers in converting back and forth between heat and mechanical work. A device that converts heat into mechanical work is called an engine. A device that converts mechanical work into heat is called a heat pump or a refrigerator (the difference between the two being whether we want to pump heat into or out of a system).\nSuppose an engine takes in heat \\(Q_H\\) from a heat reservoir, outputs some amount of work \\(W\\), and dumps any remaining output heat \\(Q_C\\) into a cold reservoir. By the first law, \\(Q_H = Q_C + W\\). Define the efficiency \\(\\eta\\) of the engine as the ratio of work extracted to the total amount of heat put in, \\[\n\\boxed{\\eta \\equiv \\frac{W}{Q_H}} \\ .\n\\] Since \\(W = Q_H - Q_C\\), we can also write the efficiency as \\[\n\\eta = 1 - \\frac{Q_C}{Q_H}.\n\\] Since we must have \\(Q_C \\leq Q_H\\) by the first law, this means \\(0 \\leq \\eta \\leq 1\\) generally speaking. A perfectly efficient engine would convert all heat into work, in which case \\(\\eta = 1\\).\nWe can define a similar measure of efficiency for a heat pump or a refrigerator. In that case, we’re interested in how much heat we can extract per unit work put in. This measure is called the coefficient of performance \\(\\omega\\), given by \\(\\omega_{fr} \\equiv \\frac{Q_C}{W}\\) for a refrigerator, and \\(\\omega_{hp} \\equiv \\frac{Q_H}{W}\\) for a heat pump. Again using the fact that \\(Q_H = Q_C + W\\), it’s easy to show that \\(\\omega_{fr} \\geq 1\\) and \\(0 \\leq \\omega_{hp} \\leq 1\\).\nHere’s a diagram showing the difference between an engine and a refrigerator. Notice that the refrigerator is just an engine with the arrows reversed. We’ll exploit this fact a good bit shortly.\n\n\n\n\n\n\n\nStatement of Second Law\nThe second law of thermodynamics can be stated in several ways that are all equivalent. I’ll state it first using the definition given by Kelvin, and then use that to prove it’s equivalent to a different statement made by Clausius.\nSecond Law (Kelvin): No thermodynamic process is possible whose sole result is the complete conversion of heat to work or work to heat. Equivalently, there is no ideal engine with efficiency \\(\\eta = 1\\).\nSecond Law (Clausius): No thermodynamic process is possible whose sole result is the transfer of heat from a colder body to a hotter body. Equivalently, there is no ideal refrigerator with performance \\(\\omega = \\infty\\).\nProof: We’ll prove these are equivalent by showing if Kelvin is false, then so is Clausius, and vice versa.\n\nIf Kelvin is false, so is Clausius: If Kelvin is false, then there exists an engine with that outputs heat \\(Q\\) to work \\(W\\) with 100% efficiency. We can use this \\(W\\) to then power a refrigerator. Suppose the refrigerator pumps heat \\(Q_C\\) from a cold reservoir to a new heat \\(Q_H\\) that dumps into the same hot reservoir as the engine. Then on net we have a system that pumps in a heat \\(Q_C\\) and pumps out a heat \\(Q_H-Q\\). That is, we’ve built a refrigerator that pumps heat from a cold body to a warm body, violating Clausius. \\(\\text{Q.E.D.}\\)\n\n\n\n\n\nIf Clausius is false, so is Kelvin: If Clausius is false, then it’s possible to build a heat pump to pump heat from a cold reservoir to a hot reservoir with no input work required. Let’s hook an engine up to the same reservoir, taking an input heat \\(Q_H\\) from the hot reservoir and converting it to some combination of work \\(W\\) and output heat \\(Q_C\\). Then on net we have a system that takes in heat \\(Q_H-Q\\) and converts it purely into work, i.e. \\(W = Q_H - Q\\), which violates Kelvin. \\(\\text{Q.E.D.}\\)\n\n\n\n\n\n\n\n\nCarnot Engines\nIf we can’t have an engine with perfect efficiency, what’s the highest possible efficiency we can possibly have? As we’ll soon prove, the highest efficiency engine is a Carnot engine. A Carnot engine is defined to be any engine that’s reversible, runs in a cycle, and whose reservoir temperatures are held fixed, with the hot reservoir at \\(T_H\\) and the cold reservoir at \\(T_C\\).\n\n\n\n\n\nA thermodynamic process is called reversible if it can be run backward in time by simply reversing the inputs and outputs. It’s the thermodynamic equivalent of frictionless motion in classical mechanics. Since reversibility implies the system stays in equilibrium, reversible processes must be quasi-static. However, not all quasi-static processes need be reversible. Any process that dissipates energy to its environment, even if done quasi-statically, is not reversible.\nTheorem: Of all engines operating between two reservoir temperatures \\(T_H\\) and \\(T_C\\), the Carnot engine is the most efficient.\nProof: Suppose we had some arbitrary non-Carnot engine with efficiency \\(\\eta\\) that takes in heat \\(Q_H'\\) from the hot reservoir, generates work \\(W\\), and dumps the remaining heat \\(Q_C'\\) into the cold reservoir. Using the same trick, hook a reversed Carnot engine (i.e. a Carnot refrigerator) up to take in the output work \\(W\\) and use it to pump heat \\(Q_C\\) from the cold reservoir to a heat \\(Q_H\\) in the hot reservoir. On net, this gives a cycle that takes in heat \\(Q_H'-Q_H\\) and converts it to heat \\(Q_C'-Q_C\\) .\n\n\n\n\n\nBut by the second law, we must have \\(Q_H'-Q_H \\geq Q_C'-Q_C\\). Dividing both sides by \\(W\\) and reorganizing, we get \\[\n\\eta = \\frac{W}{Q_H'} \\leq \\frac{W}{Q_H} = \\eta_{carnot}.\n\\] That is, the Carnot engine is more efficient. \\(Q.E.D.\\)\nCorollary: All Carnot engines between \\(T_H\\) and \\(T_C\\) have the same efficiency.\nProof: Follow the previous proof, but this time hook up another Carnot engine to the Carnot refrigerator to get \\(\\eta = \\eta_{carnot}\\). \\(Q.E.D.\\)\nWe can use the Carnot engine to construct yet another temperature scale, except this time we can do it without reference to any material properties at all. This is called the thermodynamic temperature scale. What we can do is hook two Carnot engines up in series as follows. Suppose a Carnot engine \\(CE_1\\) takes heat from \\(T_1\\) to \\(T_2\\), and Carnot engine \\(CE_2\\) takes heat from \\(T_2\\) to \\(T_3\\). We can also think of the whole thing as a single Carnot engine \\(CE\\) that takes heat from \\(T_1\\) to \\(T_3\\).\n\n\n\n\n\nNow, if we look at the heat output for each engine, we have \\[\n\\begin{align*}\nCE_1: Q_2 &= Q_1 - W_{12} = Q_1(1 - \\eta_{12}), \\\\\nCE_2: Q_3 &= Q_2 - W_{23} = Q_2(1 - \\eta_{23}), \\\\\nCE: Q_3 &= Q_1 - W_{13} = Q_1(1 - \\eta_{13}). \\\\\n\\end{align*}\n\\] We can equate both terms for \\(Q_3\\) and simplify to get \\[\n1 - \\eta_{13} = (1 - \\eta_{12})(1 - \\eta_{23}).\n\\] Now, if we divide both sides by \\(1 - \\eta_{23}\\) we get \\[\n1 - \\eta_{12} = \\frac{Q_2}{Q_1} = \\frac{f(T_1)}{f(T_2)}.\n\\] The system must satisfy this constraint for any function \\(f(T)\\) we choose. We might as well just choose \\(f(T) \\equiv T\\), in which case we get \\[\n\\eta_{12} = 1 - \\frac{T_2}{T_1}.\n\\] That is, any Carnot engine between \\(T_H\\) and \\(T_C\\) must have a Carnot efficiency given by \\[\n\\boxed{\\eta_c \\equiv 1 - \\frac{T_C}{T_H}} \\ .\n\\] Notice that since \\(T_C < T_H\\), the Carnot efficiency can never be \\(1\\). For reasonable temperature ranges, say from freezing to boiling at STP, we’d have \\(\\eta_c \\approx 0.268\\). That’s under 27% efficiency! In fact, the Carnot engine, while the best we can do efficiency-wise, it’s not practical for real engines. One major reason for this is that isothermal processes are really slow, meaning it takes too impractically long to complete a single cycle.\nSince the Carnot efficiency \\(\\eta_c\\) between two temperatures is fixed, we can use it to define a temperature scale provided we fix a base temperature \\(T_0\\). We can define the temperature \\(T\\) as the value that gives a Carnot efficiency \\(\\eta_c\\) between \\(T\\) and \\(T_0\\). That is, \\[\nT \\equiv T_0 (1 - \\eta_c).\n\\] The thermodynamic definition also implies that temperature \\(T\\) must be positive. If we had \\(T < 0\\), then an engine operating between it and a positive temperature could extract heat from both reservoirs and convert the sum total to work, in violating of the second law.\n\nExample: Carnot Cycle of an Ideal Gas\nTo make the topic somewhat more concrete, suppose we have an ideal gas inside a piston, consisting of a single type of molecule with no exchange of particles taking place. Then the only work being done is the work done by the piston to change the volume \\(V\\) and pressure \\(P\\) of the gas. Then by the first law, \\[\ndE = \\delta Q + \\delta W = \\delta Q - PdV.\n\\] This means the state variables are \\((P, V)\\). In \\(PV\\)-space, the Carnot engine will be a cycle consisting of two isotherms at \\(T_H\\) and \\(T_C\\) that are connected by curves where \\(\\delta Q = 0\\), called adiabatics.\nSuppose a cycle starts on the upper left point, say \\((P_A, V_A)\\). It expands isothermally to \\((P_B, V_B)\\), then adiabatically expands to \\((P_C, V_C)\\), then isothermally compresses to \\((P_D, V_D)\\), before finally adiabatically compressing back to \\((P_A, V_A)\\).\n\n\n\n\n\nAlong the isotherms, the ideal gas law says the curves must be hyperbolas, \\[\nPV = N k_B T_H, \\quad PV = N k_B T_C.\n\\] Along the adiabatics, the condition \\(\\delta Q = 0\\) along with the equipartition theorem implies \\[\ndE = \\frac{n}{2} d(PV) = -PdV \\quad \\Longrightarrow \\quad \\bigg(\\frac{n}{2}+1\\bigg) PdV = -\\frac{n}{2} VdP.\n\\] This is a differential equation for \\(P(V)\\). Using separation of variables on both sides gives \\[\nPV^\\gamma = P_0 V_0^\\gamma = const, \\quad \\text{where} \\quad \\gamma \\equiv \\frac{2}{n}\\bigg(\\frac{n}{2}+1\\bigg).\n\\] For example, with a monoatomic gas we’d have \\(\\gamma = \\frac{5}{3}\\), so the adiabatics are \\(PV^{5/3} = const\\). For the two adiabatic curves in the cycle, taking \\((P_0, V_0)\\) to be the two initial points along the curves gives \\[\nPV^\\gamma = P_B V_B^\\gamma, \\quad PV^\\gamma = P_D V_D^\\gamma.\n\\] Note that since the Carnot cycle is reversible, the total work done during a full cycle is zero.\n\n\n\nEntropy\nWe’re finally ready to construct the state function that’s conjugate to temperature. Let’s look again at the previous theorem that said \\(\\eta \\leq \\eta_c\\) for any engine between \\(T_H\\) and \\(T_C\\). We can rewrite this inequality in the form \\[\n\\frac{W}{Q_H} = 1 - \\frac{Q_C}{Q_H} \\leq 1 - \\frac{T_C}{T_H}.\n\\] Rearranging both sides, we get \\[\n\\frac{Q_H}{T_H} - \\frac{Q_C}{T_C} \\leq 0.\n\\] What’s interesting to notice here is that the quantity \\(\\frac{Q}{T}\\), whatever it is, depends only on the initial and final points. That is, it’s a state function. In fact, the above statement is extremely general.\nClausius’ Theorem: For any cyclic process (not necessarily quasi-static), if \\(\\delta Q\\) is an increment of heat delivered to a system at some temperature \\(T\\), then the sum total ratio of heat to temperature across the entire cycle is negative, i.e. \\[\n\\boxed{\\oint \\frac{\\delta Q}{T} \\leq 0} \\ .\n\\] Proof: What we’ll do is imagine pumping a heat increment \\(\\delta Q\\) into the system by hook a Carnot engine with hot reservoir temperature \\(T_0\\) , which takes input heat \\(\\delta Q_0\\) and uses that to generate some amount of work \\(\\delta W\\), expelling the remaining heat into the system as \\(\\delta Q\\) at a cold reservoir temperature \\(T\\).\n\n\n\n\n\nNow, since the engine is a Carnot engine, we have \\[\n1 - \\eta = \\frac{\\delta Q}{\\delta Q_0} = \\frac{T}{T_0} \\quad \\Longrightarrow \\quad \\delta Q_0 = T_0 \\frac{\\delta Q}{T}.\n\\] At the end of a full cycle, the net effect of the combined process is the extraction of heat \\(Q_0 = \\oint \\delta Q_0\\) from the hot reservoir, which is converted purely to external work \\(W = \\oint \\delta W\\). The total work \\(W\\) is the sum of the work done by the engine and the work done by the system. Now, by the second law, we must have \\(Q_0 = W \\leq 0\\), i.e. \\[\nQ_0 = T_0 \\oint \\frac{\\delta Q}{T} \\leq 0 \\quad \\Longrightarrow \\quad \\oint \\frac{\\delta Q}{T} \\leq 0. \\quad \\text{Q.E.D.}\n\\] Corollary: For a reversible process, we must have exact equality, i.e. \\[\n\\oint \\frac{\\delta Q_{rev}}{T} = 0.\n\\] Proof: This is easy to see. If we run the process forward we get \\(\\frac{\\delta Q_{rev}}{T} \\leq 0\\). By reversibility though, we can also run the process backwards, in which case \\(\\delta Q_{rev} \\rightarrow -\\delta Q_{rev}\\), and so \\(\\frac{\\delta Q_{rev}}{T} \\geq 0\\). This implies the integral between any two points \\(A\\) and \\(B\\) must be path independent, since for any two paths \\(\\mathcal{C}\\) and \\(\\mathcal{C}'\\), we have \\[\n\\int_A^B \\frac{\\delta Q_{rev}^{{\\mathcal{C}}}}{T_{{\\mathcal{C}}}} + \\int_B^A \\frac{\\delta Q_{rev}^{{\\mathcal{C}'}}}{T_{{\\mathcal{C}'}}} = 0 \\quad \\Longrightarrow \\quad \\oint \\frac{\\delta Q_{rev}}{T} = 0. \\quad \\text{Q.E.D.}\n\\] This corollary implies the existence a state function \\(S\\), defined by the path integral \\[\n\\boxed{\\Delta S \\equiv \\int_A^B \\frac{\\delta Q_{rev}}{T}} \\ .\n\\] This state function is called the entropy of the system. Since \\(\\delta Q_{rev} = TdS\\), we’ve finally found the conjugate variable to temperature . It’s just the entropy. Plugging this into the first law, we finally have that for any quasi-static, reversible process in equilibrium, \\[\n\\boxed{dE = TdS + J \\cdot dX + \\mu \\cdot dN} \\ .\n\\] This formula is without doubt the most useful identity in thermodynamics. Notice that this implies that we only need \\(n+m+1\\) total quantities to completely specify the state of the system. We can obtain the rest by partial differentiation. Assuming the mechanical displacements are independent, we have \\[\nT = \\frac{\\partial E}{\\partial S} \\bigg |_{X,N} \\ , \\quad J_i = \\frac{\\partial E}{\\partial X_i} \\bigg |_{S, \\ \\{X_k: \\ k \\neq i\\}, \\ N} \\ , \\quad \\mu_j = \\frac{\\partial E}{\\partial X_i} \\bigg |_{S, \\ X, \\ \\{N_k: \\ k \\neq j\\}} \\ .\n\\] Corollary: For an irreversible process, we have the inequality \\[\n\\int_A^B \\frac{\\delta Q}{T} \\leq \\Delta S.\n\\] Proof: This proof is similar to the previous corollary. What we’ll do is close the cycle by taking a reversible process backwards, which by Clausius’ theorem gives \\[\n\\int_A^B \\frac{\\delta Q}{T} + \\int_B^A \\frac{\\delta Q_{rev}}{T} \\leq 0. \\quad \\text{Q.E.D.}\n\\] In differential form, this corollary implies that \\(dS \\geq \\frac{\\delta Q}{T}\\) for any transformation. Suppose we take some number of adiabatically isolated systems each in equilibrium and bring them all together to thermally interact. Such a system is called a closed system, in that the subsystems are allowed to interact thermally, but not exchange matter. Once the joint system has settled down to equilibrium, the total heat must still be \\(\\delta Q = 0\\), which means that \\(\\delta S \\geq 0\\).\nThis result implies that the net adiabatic system attains its maximum entropy at equilibrium, since any spontaneous change can only act to further increase \\(S\\). This implies that the second law is not time reversible. The direction of increasing entropy points out the arrow of time in its path to equilibrium.\nAnalogy: Compare the statement that entropy increases up to thermal equilibrium with a mechanical statement. Suppose we drop an object some distance above the Earth’s surface, allowing it to free fall under gravity. As the object falls, it will only settle down once it’s reached its mechanical equilibrium, when the total forces are zero. This happens when the potential energy is minimized. In this sense, the statement that entropy increases is no more mysterious than the observation that objects tend to fall downwards under gravity so as to minimize their potential energy.\n\nExample: Entropy of a Monatomic Ideal Gas\nSuppose we have a monatomic ideal gas in a closed system with work \\(\\delta W = -PdV\\). Then \\[\ndE = TdS - PdV.\n\\] What is the change \\(\\Delta S\\) in the entropy along any path in \\(PV\\)-space?\nSolving for \\(dS\\) and using the fact that \\(dE = \\frac{3}{2} Nk_B dT\\) gives \\[\ndS = \\frac{1}{T}dE - \\frac{P}{T} dV = Nk_B \\bigg[\\frac{3}{2} \\frac{dT}{T} + \\frac{dV}{V} \\bigg].\n\\] Integrating both sides and simplifying terms, we finally have \\[\n\\Delta S = Nk_B \\bigg[\\frac{3}{2} \\log \\frac{T}{T_0} + \\log \\frac{V}{V_0} \\bigg] = Nk_B \\log\\bigg[ \\frac{V}{V_0} \\bigg(\\frac{T}{T_0}\\bigg)^{3/2} \\bigg].\n\\] It’s interesting to note from this formula that the entropy is extensive since it depends linearly on \\(N\\). It also seems to increase logarithmically with the volume and the temperature. Since \\(k_B\\) has units of energy over temperature, so too does the entropy."
  },
  {
    "objectID": "statistical-mechanics/thermodynamics.html#thermodynamic-potentials",
    "href": "statistical-mechanics/thermodynamics.html#thermodynamic-potentials",
    "title": "Thermodynamics",
    "section": "Thermodynamic Potentials",
    "text": "Thermodynamic Potentials\nLet’s look more closely again at the differential of the energy. We have \\[\ndE = TdS + J \\cdot dX + \\mu \\cdot dN.\n\\] This differential implies that \\(E = E(S, X, N)\\) explicitly, with \\(T, J, \\mu\\) determined implicitly by partial differentiation. Suppose, however, that we wanted the energy as an explicit function of other variables instead. For example, it may be easier to control the temperature or pressure of a gas in the lab than entropy or volume. We can go back and forth between conjugate pairs using Legendre transformations.\nSuppose we have some function \\(f(x, y)\\). Suppose \\(x\\) is conjugate to another variable \\(p\\) in the sense that \\[\ndf = pdx + vdy.\n\\] Notice if we add and subtract \\(xdp\\) to both sides and rearrange, we get a new differential of the form \\[\ndg \\equiv d(f-px) = -xdp + vdy.\n\\] This evidently defines a new function \\(g(p,y) = f(x,y) - px\\) that’s now an explicit function of \\(p\\) and \\(y\\). This new function is called a Legendre transformation of \\(f(x,y)\\). We created a new dual function by swapping \\(x\\) with its conjugate variable \\(p\\). This dual function is completely equivalent in content to the original function since we can always go back and forth between the two via the same kind of transformation.\nWe can apply the Legendre transformation to the energy \\(E=E(S,J,N)\\) to get the energy as a function of the other state variables. The only thing is that these new functions won’t be the original energy exactly, but rather shifted versions of the energy called thermodynamic potentials. In total there are four valid thermodynamic potentials other than the energy: enthalpy, Helmholtz free energy, Gibbs free energy, and the grand potential. Note that all of these potentials still have units of energy.\n\nEnthalpy\nSuppose we wanted to swap \\(J\\) with \\(X\\) to express the energy as a function \\(H = H(S, X, N)\\). We can figure out the form of \\(H\\) by doing a Legendre transformation between \\(J\\) and \\(X\\). Adding \\(X \\cdot dJ\\) to both sides of the first law and rearranging gives \\[\ndH = d(E - J \\cdot X) = TdS - X \\cdot dJ + \\mu \\cdot dN.\n\\] That is, the equation for \\(H\\) is evidently \\[\n\\boxed{H \\equiv E - J \\cdot X} \\ .\n\\] This function is called the enthalpy. We can think of it as a form of energy where the mechanical work gets subtracted out. When dealing with a gas, we’d have \\(J \\cdot dX = -PdV\\), in which case the enthalpy would be \\[\nH = E + pV.\n\\] The enthalpy is perhaps most useful when dealing with adiabatic systems. In that case, \\(\\delta Q = 0\\) means the enthalpy is just the work done, i.e. \\(dH = -X \\cdot dJ + \\mu \\cdot dN\\). Adiabatic processes tend to happen very quickly, like the combustion of gas in a cylinder.\n\n\nHelmholtz Free Energy\nSuppose now we wanted to instead swap \\(T\\) with \\(S\\) to get a function \\(F = F(T, X, N)\\). If we add and subtract \\(SdT\\) to both sides of \\(dE\\) and rearrange, we get \\[\ndF = -SdT + J \\cdot dX + \\mu \\cdot dN.\n\\] The function \\(F\\) is called the Helmholtz free energy, evidently given by \\[\n\\boxed{F = E - TS} \\ .\n\\] We can think of the Helmholtz free energy as a kind of energy in which the heat has been subtracted out of the system. The Helmholtz free energy is perhaps most useful when dealing with isothermal processes, in which case \\(dF\\) reduces to just \\(dF = J \\cdot dX + \\mu \\cdot dN\\). Isothermal processes happen very slowly, so slowly they’re impractical for real-world engines.\n\n\nGibbs Free Energy\nSuppose now we wanted to swap both \\(q\\) with \\(J\\) as well as \\(T\\) with \\(S\\) to get a function \\(G = G(T, J, N)\\). If we start with the enthalpy \\(dH\\) and add and subtract \\(SdT\\) to both sides and rearrange, we get \\[\ndG = d(H - TS) = -SdT - X \\cdot dJ + \\mu \\cdot dN.\n\\] The function \\(G\\) is called the Gibbs free energy, evidently given by \\[\n\\boxed{G = H - TS = E - TS - J \\cdot X} \\ .\n\\] We can think of the Gibbs free energy as a kind of energy in which both the mechanical work done as well as the heat have been subtracted out of the system. When dealing with a gas, \\(G\\) takes the form \\[\nG = E - TS + PV.\n\\] The Helmholtz free energy is perhaps most useful when dealing with processes that take place at fixed temperature and pressure, e.g. processes that take place at STP. These often include, for example, biological processes, like the thermodynamics in and around a cell.\n\n\nGrand Potential\nSo far we haven’t touched the chemical work terms at all. Suppose now though that we want a kind of Gibbs free energy that swaps \\(\\mu\\) with \\(N\\) instead of \\(J\\) with \\(X\\) to get a function \\(\\mathcal{G} = \\mathcal{G}(T,X,\\mu)\\). If we this time start with the Helmholtz free energy and add and subtract \\(N \\cdot d\\mu\\) to both sides and re-arrange, we get \\[\nd\\mathcal{G} = d(F - \\mu \\cdot N) = -SdT + J \\cdot dX - N \\cdot d\\mu.\n\\] This function \\(\\mathcal{G}\\) is called the grand potential, evidently given by \\[\n\\boxed{\\mathcal{G} = F - \\mu \\cdot N = E - TS - \\mu \\cdot N} \\ .\n\\] We can think of the grand potential as a kind of energy in which both the heat and the chemical work have been subtracted out of the system.\n\n\nExtensivity\nIf you look carefully, you’ll see that all of the thermodynamic potentials we defined are a function of at least one extensive variable. It’s fair to ask why we didn’t consider a potential function of all the intensive variables, i.e. some \\(L = L(T,J,\\mu)\\). The reason for this has to do with a mathematical relationship known as extensivity. We say a system is extensive if its energy satisfies the property of homogeneity. That is, for any scalar \\(\\lambda\\), we must have \\[\nE(\\lambda S, \\lambda X, \\lambda N) = \\lambda E(S, X, N).\n\\] Note that extensivity is not a required property of every thermodynamic system. It doesn’t follows from the laws of thermodynamics. It’s in fact an extra constraint that’s satisfied by most systems of real world interest. One example of a system that’s not extensive is a star where gravitational work is being done.\nWe can derive a useful relationship by differentiating both sides of this definition with respect to \\(\\lambda\\), \\[\n\\begin{align*}\n\\frac{\\partial}{\\partial\\lambda} \\lambda E(S, X, N) &= \\frac{\\partial}{\\partial\\lambda} E(\\lambda S, \\lambda X, \\lambda N), \\\\\n\\Longrightarrow E(S, X, N) &= \\frac{\\partial E}{\\partial S} \\bigg |_{X,N} S + \\frac{\\partial E}{\\partial X} \\bigg |_{S,N} \\cdot X + \\frac{\\partial E}{\\partial N} \\bigg |_{S,X} \\cdot N, \\\\\n\\Longrightarrow E(S, X, N) &= TS + J \\cdot X + \\mu \\cdot N. \\\\\n\\end{align*}\n\\] That is, for an extensive system, the energy is just given directly by \\[\n\\boxed{E = TS + J \\cdot X + \\mu \\cdot N} \\ .\n\\] If we take the differential of both sides and apply the first law, we get \\[\n\\begin{align*}\ndE &= d(TS) + d(J \\cdot X) + d(\\mu \\cdot N) \\\\\n&= (TdS + J \\cdot dX + \\mu \\cdot dN) + (SdT + X \\cdot dJ + N \\cdot d\\mu) \\\\\n&= TdS + J \\cdot dX + \\mu \\cdot dN. \\\\\n\\end{align*}\n\\] This means the second term must be zero for an extensive system, \\[\n\\boxed{SdT + X \\cdot dJ + N \\cdot d\\mu = 0} \\ .\n\\] This relation is called the Gibbs-Dunham relation. Notice it’s just the differential of a function \\(L = L(T,J,\\mu)\\) of the intensive variables. We’ve thus shown that no thermodynamic potential of the intensive variables alone can exist for an extensive system.\nExtensivity gives us a new constraint that we can often use to solve problems. Here’s an example.\nThe Gibbs free energy can be used to give a useful interpretation of the chemical potential \\(\\mu\\) of a gas. By extensivity, we must have \\[\nG = E - TS - J \\cdot X = \\mu N.\n\\] That is, the chemical potential of a gas can be thought of as the Gibbs free energy per particle. If there is a mixture of \\(m\\) types of particles in the gas, then \\(\\mu_i\\) is the Gibbs free energy per particle \\(i\\).\n\nExample: Chemical potential along isotherms\nSuppose we wanted to find \\(\\mu\\) for an ideal gas consisting of a single molecule. Since an ideal gas is extensive, along an isotherm we must have the simplified constraint \\[\n-VdP + N d\\mu = 0.\n\\] Now, by the ideal gas law, \\(\\frac{V}{N} = \\frac{k_B T}{P}\\). We can thus re-write this expression as \\[\nd\\mu = \\frac{k_B T}{P} dP.\n\\] Integrating both sides and solve for \\(\\mu\\), we finally have that along an isotherm \\[\n\\mu = \\mu_0 + k_B T \\log \\frac{P}{P_0}.\n\\] Evidently, the chemical potential is an increasing function of temperature, pressure, and volume."
  },
  {
    "objectID": "statistical-mechanics/thermodynamics.html#maxwell-relations",
    "href": "statistical-mechanics/thermodynamics.html#maxwell-relations",
    "title": "Thermodynamics",
    "section": "Maxwell Relations",
    "text": "Maxwell Relations\nRecall from calculus that for any function with continuous second partial derivatives, the mixed second partial derivatives commute. For example, a function \\(z = f(x,y)\\) would have \\[\n\\frac{\\partial^2 z}{\\partial x \\partial y} = \\frac{\\partial^2 z}{\\partial y \\partial x}.\n\\] We generally assume that the state functions in thermodynamics are sufficiently smooth enough that their mixed partial derivatives all commute like this. This condition imposes another set of constraints on the potentials, which we can use to find interesting, non-trivial relationships between various state variables. They’re called the Maxwell relations. If \\(dE = TdS + J \\cdot dX + \\mu \\cdot dN\\), then there are in total 3 Maxwell relations per potential, which means there are \\(3 \\cdot 5 = 15\\) relations across all 5 potentials, though some of these are duplicates. Here are the differential forms of all 5 potentials again, \\[\n\\boxed{\n\\begin{align*}\ndE &= \\quad TdS + J \\cdot dX + \\mu \\cdot dN \\\\\ndH &= \\quad TdS - X \\cdot dJ + \\mu \\cdot dN \\\\\ndF &= \\;-SdT + J \\cdot dX + \\mu \\cdot dN \\\\\ndG &= \\;-SdT - X \\cdot dJ + \\mu \\cdot dN \\\\\nd\\mathcal{G} &= \\;-SdT + J \\cdot dX - N \\cdot d\\mu \\\\\n\\end{align*}\n} \\ .\n\\]\nIn the simple case of a closed system, we’d have \\(dN=0\\), which reduces the total number of relations to \\(1 \\cdot 4 = 4\\). Those 4 Maxwell relations are evidently \\[\n\\boxed{\n\\begin{align*}\n&\\frac{\\partial^2 E}{\\partial S \\partial X}& &=& &\\frac{\\partial T}{\\partial X} \\bigg |_{S,N}& &=& &\\frac{\\partial J}{\\partial S} \\bigg |_{X,N}& \\\\\n&\\frac{\\partial^2 H}{\\partial S \\partial J}& &=& -&\\frac{\\partial T}{\\partial J} \\bigg |_{S,N}& &=& &\\frac{\\partial X}{\\partial S} \\bigg |_{J,N}& \\\\\n&\\frac{\\partial^2 F}{\\partial T \\partial X}& &=& -&\\frac{\\partial S}{\\partial X} \\bigg |_{T,N}& &=& &\\frac{\\partial J}{\\partial T} \\bigg |_{X,N}& \\\\\n&\\frac{\\partial^2 G}{\\partial T \\partial J}& &=& &\\frac{\\partial S}{\\partial J} \\bigg |_{T,N}& &=& &\\frac{\\partial X}{\\partial T} \\bigg |_{J,N}& \\\\\n\\end{align*}\n} \\ .\n\\] Though the relations themselves are non-intuitive, the process for deriving them is straight forward. Suppose for example we wanted to find a Maxwell relation for \\[\n\\frac{\\partial \\mu}{\\partial P} \\bigg |_{T,N}.\n\\] To get a relation like this, we’d need a potential that’s an explicit function of \\(P, T, N\\). That’s of course the Gibbs free energy. In this case, we’d have \\[\n\\frac{\\partial \\mu}{\\partial P} \\bigg |_{T,N} = \\frac{\\partial}{\\partial P} \\bigg |_{T,N} \\frac{\\partial G}{\\partial N} \\bigg |_{T,P} = \\frac{\\partial}{\\partial N} \\bigg |_{T,P} \\frac{\\partial G}{\\partial P} \\bigg |_{T,N} = \\frac{\\partial V}{\\partial N} \\bigg |_{T,P}.\n\\] Compare this relation with the one for an extensive system that we saw in a previous example, \\[\n\\frac{\\partial \\mu}{\\partial P} \\bigg |_{T,N} = \\frac{V}{N}.\n\\]"
  },
  {
    "objectID": "statistical-mechanics/thermodynamics.html#stability-conditions",
    "href": "statistical-mechanics/thermodynamics.html#stability-conditions",
    "title": "Thermodynamics",
    "section": "Stability Conditions",
    "text": "Stability Conditions\nThermodynamics depends on systems being in equilibrium. We already know that systems at equilibrium with each other will have the same temperature, but what else can we say?\n\nMechanical Stability\nRecall from classical mechanics what it means for a classical system to be in mechanical equilibrium. A classical system is said to be in mechanical equilibrium when the total forces acting on the system are zero, i.e. \\(\\mathbf{F} = \\mathbf{0}\\). For conservative systems, that’s equivalent to saying the potential \\(V=V(\\mathbf{x})\\) has gradient zero, i.e. \\(\\nabla V(\\mathbf{x}) = \\mathbf{0}\\).\nThe equilibrium point \\(\\mathbf{x}^*\\) is a stable equilibrium if \\(V(\\mathbf{x}^* )\\) is a local minimum. A sufficient condition for this to be true is that the second-order deviations around \\(V(\\mathbf{x}^* )\\) are positive, or equivalently that the Hessian of \\(V(\\mathbf{x})\\) is positive definite about \\(\\mathbf{x}^*\\), i.e. \\[\n\\delta^2 V \\equiv \\delta\\mathbf{x} \\cdot \\frac{d^2}{d\\mathbf{x}^2} V(\\mathbf{x}^*) \\cdot \\delta\\mathbf{x} = \\sum_{i,j=1}^3\\frac{\\partial^2 V}{\\partial x_i \\partial x_j}\\delta x_i \\delta x_j > 0 \\quad \\forall\\delta\\mathbf{x} \\neq \\mathbf{0}.\n\\] Intuitively, a stable equilibrium means that if the system is nudged by a small displacement it will experience a tension force pulling it back to equilibrium. Think of a spring as the canonical example.\n\n\nThermodynamic Stability\nWe’d like to derive an analogue of this formula to characterize what it means for a thermodynamic system to be in a stable equilibrium. To do that, it’s convenient to symmetrize the positive definite expression with respect to \\(\\mathbf{F}\\) and \\(\\mathbf{x}\\). Notice that if we let \\[\n\\delta \\mathbf{F} \\equiv \\frac{d^2 V}{d\\mathbf{x}^2} \\cdot \\delta\\mathbf{x} = \\sum_{j=1}^3 \\frac{\\partial^2 V}{\\partial x_i \\partial x_j} \\delta x_j,\n\\] then we can re-write the condition for mechanical stability as \\[\n\\delta \\mathbf{F} \\cdot \\delta\\mathbf{x} = \\sum_{i=1}^3 \\delta F_i \\delta x_i > 0.\n\\] We can extend this same idea to thermodynamical systems, except there we require that all equilibrium points be stable. That is, the stability condition is required to be in thermodynamic equilibrium.\nTheorem: Any thermodynamic system in equilibrium must satisfy the stability condition \\[\n\\boxed{\\delta T \\delta S + \\delta J \\cdot \\delta X + \\delta \\mu \\cdot \\delta N \\geq 0} \\ .\n\\] Proof: Consider an isolated system in equilibrium. Then any two subsystems \\(A\\) and \\(B\\) must be in equilibrium with each other. It must be the case then that their intensive quantities are identical, i.e. \\[\nT \\equiv T_A = T_B, \\quad J \\equiv J_A = J_B, \\quad \\mu \\equiv \\mu_A = \\mu_B.\n\\] It must also be the case that their extensive quantities add to give the ones for the full system, \\[\nE \\equiv E_A + E_B, \\quad S \\equiv S_A + S_B, \\quad X \\equiv X_A + X_B, \\quad N \\equiv N_A + N_B.\n\\] Suppose that \\(B\\) spontaneously transfers energy to \\(A\\) in the form of both heat and work. Let’s look at the first order change in the system’s total entropy. Evidently, we’d have \\[\n\\begin{align*}\n\\delta S &= \\delta S_A + \\delta S_B \\\\\n&= \\delta\\bigg(\\frac{E_A}{T_A} - \\frac{J_A}{T_A} \\cdot X_A - \\frac{\\mu_A}{T_A} \\cdot N_A \\bigg) + \\delta\\bigg(\\frac{E_B}{T_B} - \\frac{J_B}{T_B} \\cdot X_B - \\frac{\\mu_B}{T_B} \\cdot N_B \\bigg) \\\\\n&= 2\\bigg[\\delta\\bigg(\\frac{1}{T_A}\\bigg) \\delta E_A - \\delta\\bigg(\\frac{J_A}{T_A}\\bigg)\\cdot \\delta X_A - \\delta\\bigg(\\frac{\\mu_A}{T_A}\\bigg)\\cdot \\delta N_A \\bigg] \\\\\n&= -\\frac{2}{T_A}\\bigg[\\delta T_A \\bigg(\\frac{\\delta E_A - J_A \\cdot \\delta X_A - \\mu_A \\cdot \\delta N_A}{T_A}\\bigg) + \\delta J_A \\cdot \\delta X_A + \\delta\\mu_A \\cdot \\delta N_A\\bigg] \\\\\n&= -\\frac{2}{T_A}\\big[\\delta T_A \\delta S_A + \\delta J_A \\cdot \\delta X_A + \\delta \\mu_A \\cdot \\delta N_A\\big].\n\\end{align*}\n\\] To be in equilibrium, any change to the system should lead to a decrease in entropy since entropy is maximized at equilibrium. This implies that \\(\\delta S \\leq 0\\), or equivalently that \\[\n\\delta T_A \\delta S_A + \\delta J_A \\cdot \\delta X_A + \\delta \\mu_A \\cdot \\delta N_A \\geq 0.\n\\] This condition should apply for any subsystem, which means it should apply to the whole system as well, \\[\n\\delta T \\delta S + \\delta J \\cdot \\delta X + \\delta \\mu \\cdot \\delta N \\geq 0.\n\\] The above condition was obtained assuming the system’s extensive variables \\(E,q,N\\) were held constant. In fact, since all coordinates appear symmetrically in the expression, the same result is obtained for any other set of constraints as well. \\(\\text{Q.E.D.}\\)\nAnother way of expressing the stability condition is that any second order deviations in the energy around equilibrium must be positive, i.e. \\(\\delta^2 E \\geq 0\\). This also means that the energy function should be convex about its equilibrium states.\n\n\nClosed Systems\nSuppose a system is closed, so \\(dN = 0\\). Then the first law says \\(dE = TdS + J \\cdot dX\\), and the stability condition says \\(\\delta T \\delta S + \\delta J \\cdot \\delta X \\geq 0\\). We can always solve for any two variables in terms of the rest. For example, we can write \\[\n\\begin{align*}\n\\delta S &= \\frac{\\partial S}{\\partial T} \\bigg |_{X,N} \\delta T + \\frac{\\partial S}{\\partial X} \\bigg |_{T,N} \\delta X, \\\\\n\\delta J &= \\frac{\\partial J}{\\partial T} \\bigg |_{X,N} \\delta T + \\frac{\\partial J}{\\partial X} \\bigg |_{T,N} \\delta X. \\\\\n\\end{align*}\n\\] Substituting these into the stability condition, we can write \\[\n\\begin{align*}\n0 &\\leq \\delta T \\bigg(\\frac{\\partial S}{\\partial T} \\bigg |_{X,N} \\delta T + \\frac{\\partial S}{\\partial X} \\bigg |_{T,N} \\delta X\\bigg) + \\bigg(\\frac{\\partial J}{\\partial T} \\bigg |_{X,N} \\delta T + \\frac{\\partial J}{\\partial X} \\bigg |_{T,N} \\delta X\\bigg) \\delta X \\\\\n&\\leq \\frac{\\partial S}{\\partial T} \\bigg |_{X,N} \\delta T^2 + \\bigg(\\frac{\\partial S}{\\partial X} \\bigg |_{T,N} + \\frac{\\partial J}{\\partial T} \\bigg |_{X,N} \\bigg) \\delta T \\delta X + \\frac{\\partial J}{\\partial X} \\bigg |_{T,N} \\delta X^2 \\\\\n&\\leq \\frac{\\partial S}{\\partial T} \\bigg |_{X,N} \\delta T^2 + \\frac{\\partial J}{\\partial X} \\bigg |_{T,N} \\delta X^2. \\\\\n\\end{align*}\n\\] The last line follows from the fact that \\(\\frac{\\partial S}{\\partial X} \\big |_{T,N} = -\\frac{\\partial J}{\\partial T} \\big |_{X,N}\\) via a Maxwell relation. Let’s look at this in two cases, first when along curves of constant \\(X\\), and then along curves of constant \\(T\\). In the first case we’d have \\(\\delta X = 0\\), which says \\[\n\\frac{\\partial S}{\\partial T} \\bigg |_{X,N} \\delta T^2 \\geq 0.\n\\] This says that along curves of constant \\(X\\), the entropy must be an increasing function of temperature. This evidently implies that the heat capacity along constant \\(X\\) must be non-negative, since \\[\nC_q = \\frac{\\delta Q}{\\partial T} \\bigg |_{X,N} = T \\frac{\\partial S}{\\partial T} \\bigg |_{X,N} \\geq 0.\n\\] Let’s now look at curves of constant \\(T\\), i.e. the isotherms. In that case we’d have \\[\n\\frac{\\partial J}{\\partial X} \\bigg |_{T,N} \\delta X^2 \\geq 0,\n\\] which evidently implies \\(J\\) must be an increasing function of \\(X\\) along the isotherms. In the case of a gas, this condition just says that pressure \\(p\\) must be a decreasing function of \\(V\\) along isotherms, which we’ve already seen.\n\nExample: Stability of Gases\nSuppose we have some gas that’s kept a constant temperature \\(T\\) and particle number \\(N\\). If we apply the stability condition to a gas, in general we’d have \\[\n\\delta T \\delta S - \\delta P \\delta V + \\delta \\mu \\delta N \\geq 0.\n\\] Since \\(\\delta T = \\delta N = 0\\), this simplifies to just \\(-\\delta P \\delta V \\geq 0\\), or equivalently \\[\n\\delta P = \\frac{\\partial P}{\\partial V} \\bigg |_{T,N} \\delta V \\leq 0.\n\\] This says that evidently \\(P\\) must be a decreasing function of \\(V\\). If we define the compressibility \\(\\kappa\\) of a gas by \\[\n\\kappa \\equiv -\\frac{1}{V} \\frac{\\partial V}{\\partial P} \\bigg |_{T,N},\n\\] then the stability condition evidently says that \\(\\kappa \\geq 0\\) at equilibrium. That is, the gas must be compressible, i.e. increasing the pressure on the gas should decrease its volume.\nIt’s interesting to examine the special isotherm \\(T=T_c\\) where \\(\\frac{\\partial P}{\\partial V} \\big |_{T,N} = 0\\). Along this isotherm there’s a flat spot near some critical point \\((P_c,V_c)\\). Around this point \\(\\delta P = 0\\), which means we need to look at the higher-order deviations in \\(P(V)\\). If we expand to third order about \\(V_c\\), we’d have \\[\n\\delta P \\approx \\frac{\\partial P}{\\partial V} \\bigg |_{T_c,N} \\delta V + \\frac{1}{2} \\frac{\\partial^2 P}{\\partial V^2} \\bigg |_{T_c,N} \\delta V^2 + \\frac{1}{6} \\frac{\\partial^3 P}{\\partial V^3} \\bigg |_{T_c,N} \\delta V^3.\n\\] To satisfy the stability condition we can only keep terms with odd powers in \\(\\delta V\\), since otherwise \\(\\delta P \\delta V\\) wouldn’t be non-negative. Evidently then, to maintain stability, about the critical point we must have \\[\n\\delta P \\approx \\frac{1}{6} \\frac{\\partial^3 P}{\\partial V^3} \\bigg |_{T_c,N} \\delta V^3, \\quad \\text{where} \\quad \\frac{\\partial^3 P}{\\partial V^3} \\bigg |_{T_c,N} \\geq 0.\n\\] This means that the isotherm along \\(T=T_c\\) must be a decreasing cubic with stationary point at \\((P_c,V_c)\\).\nIn reality, this condition requires that \\(P(V)\\) be an analytic function around \\(T_c\\). But it turns out that it’s not analytic around this point. There’s a phase transition. In fact, near \\(T_c\\) it’s the case that \\(\\delta P \\propto \\delta V^\\gamma\\), where \\(\\gamma \\approx 4.7\\) is an experimentally determined constant. To understand this better we’d need field theory."
  },
  {
    "objectID": "statistical-mechanics/thermodynamics.html#third-law",
    "href": "statistical-mechanics/thermodynamics.html#third-law",
    "title": "Thermodynamics",
    "section": "Third Law",
    "text": "Third Law\nSuppose we take a reversible system and change its state from \\(x_1\\) to \\(x_2\\). Then its entropy changes by \\[\n\\Delta S = S_2 - S_1 = \\int_{x_1}^{x_2} \\frac{\\delta Q_{rev}}{T}.\n\\] We can say this for any positive temperature \\(T\\). Now suppose we allow \\(T \\rightarrow 0\\). What happens to \\(\\Delta S\\)? It turns out experimentally that \\(\\Delta S \\rightarrow 0\\). This is an independent fact due to Nernst, which gives us a narrow statement of the third law of thermodynamics.\nThird Law (Nernst): The entropy of all systems at zero absolute temperature is a universal constant that can be taken to be zero. That is, between any two states we must have \\[\n\\boxed{\\lim_{T \\rightarrow 0} \\Delta S = 0} \\ .\n\\] This statement turns out to be experimentally equivalent to an even stronger statement. Not only does \\(\\Delta S \\rightarrow 0\\), but in fact \\(S \\rightarrow 0\\) for any substance.\nThird Law (General): The entropy of all substances at zero absolute temperature is the same universal constant, which can be defined to be zero. That is, for any system, \\[\n\\boxed{\\lim_{T \\rightarrow 0} S = S_0 \\equiv 0} \\ .\n\\] This extended version of the third law can be experimentally tested by looking at the behavior of certain materials like sulfur or phosphine, which can exist near absolute zero in multiple crystalline structures called allotropes. Each allotrope has its own heat capacity \\(C(T)\\). It’s been shown that as \\(T \\rightarrow 0\\), each of these paths sends \\(C \\rightarrow 0\\), which implies \\(S \\rightarrow 0\\) as well.\n\n\n\n\n\nHere are a few notable consequences that follow from the third law. First, since \\(S \\rightarrow 0\\) as \\(T \\rightarrow 0\\), it must also be true that any partial derivative of \\(S\\) must go to zero as well, \\[\n\\lim_{T \\rightarrow 0} \\frac{\\partial S}{\\partial X} \\bigg |_T = 0.\n\\] The heat capacities must go to zero as well since \\[\n\\Delta S = \\int_0^T \\frac{C(T')}{T'} dT' \\rightarrow 0.\n\\] This integral would diverge as \\(T \\rightarrow 0\\) unless \\(C \\rightarrow 0\\) as well.\nThe thermal expansion coefficients must also go to zero since by a Maxwell relation we have \\[\n\\alpha \\equiv \\frac{1}{X} \\frac{\\partial X}{\\partial T} \\bigg |_J = \\frac{1}{X} \\frac{\\partial S}{\\partial J} \\bigg |_T \\rightarrow 0.\n\\] The last consequence of note is that it must be impossible to cool any system to absolute zero in a finite number of steps, which for practical purposes means it’s impossible to cool a system to zero exactly. For example, suppose we tried to cool a gas by adiabatically reducing its pressure. Since all \\(S(T)\\) curves must intersect at \\(0\\), any successive step would involve progressively smaller changes in \\(S\\) and \\(T\\) as \\(T \\rightarrow 0\\).\n\n\n\n\n\nIt’s worth mentioning that in a certain sense the third law is less reliable than the other laws of thermodynamics since at its root its validity rests entirely on quantum mechanics, and the quantum mechanical behavior of different systems can vary wildly near absolute zero. This contrasts with the other laws, which at a microscopic level only depend on things like the conservation of energy, or the emergent effect of a large number of degrees of freedom. We’ll see a microscopic derivation of each of these laws in future chapters."
  },
  {
    "objectID": "statistical-mechanics/probability.html#univariate-probability",
    "href": "statistical-mechanics/probability.html#univariate-probability",
    "title": "Probability",
    "section": "Univariate Probability",
    "text": "Univariate Probability\n\nProbability Measures\nAt its root, probability is based on the study of events or random variables. Suppose \\(\\mathcal{S}\\) is the set of all possible outcomes of an experiment, called the sample space. Any subset \\(E \\subset \\mathcal{S}\\) is called an event. A probability measure is a set function \\(\\mathbb{Pr}(E)\\) that maps events to numerical values between zero and one. It’s meant to formalize the concept of chance. If an event has probability one, we think of that event as being 100% certain to occur. If it has probability zero, we think of the event as having 0% chance to occur. Any values in between mean we’re uncertain whether the event will occur.\nFormally, a probability measure on a sample space \\(\\mathcal{S}\\) satisfies the following properties:\n\nPositivity: For any event \\(E \\subset \\mathcal{S}\\), \\(\\mathbb{Pr}(E) \\geq 0\\).\nAdditivity: If \\(A \\subset \\mathcal{S}\\) and \\(B \\subset \\mathcal{S}\\) are distinct, disjoint events, then \\(\\mathbb{Pr}(A \\text{ or } B) = \\mathbb{Pr}(A) + \\mathbb{Pr}(B)\\).\nNormalization: For the entire sample space \\(\\mathcal{S}\\), \\(\\mathbb{Pr}(\\mathcal{S}) = 1\\).\n\nWhile this is a nice formal definition of probability, it’s not practically useful for saying how we should design a probability measure in a practical setting. There are two common approaches for designing probability measures:\n\nThe objective approach: In this approach, we imagine running a bunch of experiments and counting the frequency of occurrences of an event. That is, if we run a large number \\(N\\) of experiments and observe an event \\(A\\) occurs exactly \\(N_A\\) times, then we define \\(\\mathbb{Pr}(A)\\) by the ratio \\[\n\\boxed{\\mathbb{Pr}(A) \\equiv \\lim_{N \\rightarrow \\infty} \\frac{N_A}{N}} \\ .\n\\] The fact that the ratio \\(\\frac{N_A}{N}\\) stabilizes to a fixed value as \\(N\\) gets infinitely large follows from the law of large numbers, which we’ll take as a kind of experimental fact.\nThe subjective approach: In this approach we take a more theoretical view by looking for a “maximally random” probability distribution that matches what we know to be true. That is, we seek to find the maximum entropy probability distribution that satisfies some given set of known constraints. We’ll talk more about the principle of maximum entropy when we get to information theory. The subjective approach is the one used most heavily in statistical mechanics.\n\n\n\nRandom Variables\nA random variable is a variable \\(X\\) that doesn’t take on a fixed value, but rather a random value determined by a probability distribution. If \\(E \\subset \\mathcal{S}\\) is an event, a random variable encodes that event using a numerical variable \\(X=X(E)\\). More formally, \\(X(E)\\) is a function that maps events to a numerical value. It could be a real number, a complex number, or a real or complex vector, for example.\nA one-dimensional random variable is a mapping \\(X(E)\\) from events \\(E \\subset \\mathcal{S}\\) into the real numbers \\(\\mathbb{R}\\). In this case, we can define a cumulative distribution function or CDF as the function \\[\n\\boxed{P(x) \\equiv \\mathbb{Pr}\\big(\\{X \\leq x\\}\\big)} \\ .\n\\] That is, the CDF is the probability that the random variable \\(X \\leq x\\), where \\(x\\) is just some real number. To obey the laws of probability, the CDF must satisfy the following properties:\n\nIt’s an increasing function of \\(x\\). That is, if \\(x_1 \\leq x_2\\) then \\(P(x_1) \\leq P(x_2)\\).\nIt has probability zero at \\(x=-\\infty\\). That is, \\(\\lim_{x \\rightarrow -\\infty} P(x) = 0\\).\nIt has probability one at \\(x=\\infty\\). That is, \\(\\lim_{x \\rightarrow \\infty} P(x) = 1\\).\n\nIf the set of all values \\(X\\) can take on are discrete, we say \\(X\\) is a discrete random variable. In this case, we can define a probability mass function or PMF as the function \\[\n\\boxed{p(x) \\equiv \\mathbb{Pr}(X = n)} \\ .\n\\] By the laws of probability the PMF must satisfy the following properties:\n\nIt’s between zero and one: \\(0 \\leq p(n) \\leq 1\\).\nIt sums to one over all values, i.e. \\(\\sum_{n \\in \\mathcal{S}} \\ p(n) = 1\\).\nIt’s related to the CDF by \\(P(x) = \\sum_{n \\leq x} \\ p(n)\\).\n\nIf the set of all values it can take on are continuous, we say \\(X\\) is a continuous random variable. In this case, we can define a probability density function or PDF by the function \\[\n\\boxed{p(x) = \\mathbb{Pr}(x \\leq X \\leq x + dx)} \\ .\n\\] By the laws of probability, the PDF must satisfy the following properties:\n\nIt’s a positive function \\(p(x) \\geq 0\\).\nIt integrates to one over all values, \\(\\int_\\mathcal{S} p(x) dx = 1\\).\nIt’s related to the CDF by differentiation, \\(p(x) = \\frac{d}{dx} P(x)\\).\n\nNote that in physics the PDF has units. If \\(x\\) has units of \\([x]\\), then evidently \\(p(x)\\) must have units of \\(\\frac{1}{[x]}\\). This is why we think of the PDF as a density. It’s a probability per unit \\(x\\).\nBy convention, if \\(S \\subset \\mathbb{R}\\) we’ll assume \\(p(x) = 0\\) on values of \\(x\\) outside of \\(S\\). This means we can treat the PMF as a PDF by using delta functions to indicate where each discrete value of \\(x\\) has non-zero \\(p(x)\\). That is, \\[\np(k) = p(x) \\delta (x - k).\n\\] For this reason, we’ll generally state results in the form of a continuous random variable.\nWhere there’s no risk of confusion, we’ll frequently abuse notation by using the lower case letter \\(x\\) for both the random variable as well as the value it can take on.\n\n\nMoments and Cumulants\nFor both discrete and continuous random variables we can define the expected value of a random function \\(F(x)\\) by summing or integrating the function, weighted by the PMF or PDF. In the continuous case, we’d define the expected value \\(\\langle F(x) \\rangle\\) by \\[\n\\boxed{\\langle F(x) \\rangle \\equiv \\int_{\\mathbb{R}} dx \\ F(x) p(x)} \\ .\n\\] Some of the functions \\(F(x)\\) have special names:\n\nWe call \\(\\mu \\equiv \\langle x \\rangle\\) the mean of \\(x\\).\nWe call \\(\\mu_n \\equiv \\langle x^n \\rangle\\) the nth moment of \\(x\\).\nWe call \\(\\langle e^{-ikx} \\rangle\\) the characteristic function or CF of \\(x\\).\n\nNote the characteristic function is just the Fourier transform of the PDF since \\[\n\\langle e^{-ikx} \\rangle = \\tilde p(k) = \\int_{\\mathbb{R}} dx \\ e^{-ikx} p(x).\n\\] This means we can always go from the CF back to the PDF by taking the inverse Fourier transform, \\[\np(x) = \\int_{\\mathbb{R}} \\frac{dx}{2\\pi} \\ e^{ikx} \\tilde p(k).\n\\] If we Taylor expand the CF, we can also evidently write \\[\n\\langle e^{-ikx} \\rangle = \\bigg\\langle \\sum_{n=0}^\\infty \\frac{(-ik)^n}{n!} x^n \\bigg\\rangle = \\sum_{n=0}^\\infty \\frac{(-ik)^n}{n!} \\mu_n.\n\\] This means that the CF can be used to generate moments for a given distribution. Once we have a closed form for the CF, just expand it into a series and pick off each \\(\\mu_n = \\langle x^n \\rangle\\) term by term.\nWe can translate the CF to any other point \\(x_0\\) by observing that \\[\n\\langle e^{-ik(x-x_0)} \\rangle = \\int_{\\mathbb{R}} dx \\ e^{-ik(x-x_0)} p(x) = e^{ikx_0} \\tilde p(k).\n\\] More useful to us in practice is not the characteristic function, but its logarithm, called the cumulant function. We’ll assume we can expand \\(\\log \\tilde p(k)\\) as a Taylor Series about \\(k=0\\) weighted by some coefficients \\(\\kappa_n\\). By expanding out the MGF inside the log, we can evidently then write \\[\n\\log \\tilde p(k) = \\sum_{n=1}^\\infty \\frac{(-ik)^n}{n!} \\kappa_n = \\log\\bigg(1 + \\sum_{n=1}^\\infty \\frac{(-ik)^n}{n!} \\mu_n \\bigg).\n\\] The sum inside the log is of the form \\(1+\\varepsilon\\). We can thus expand the log in powers of \\(\\varepsilon\\) to get \\[\n\\log\\big(1 + \\varepsilon \\big) = 1 + \\varepsilon - \\frac{1}{2} \\varepsilon^2 + \\frac{1}{3} \\varepsilon^3 - \\frac{1}{4} \\varepsilon^4 + \\cdots\n\\] Using this expansion and matching term-by-term to the original expansion of \\(\\log \\tilde p(k)\\) we can find expressions for the coefficients \\(\\kappa_n\\) in terms of the moments \\(\\mu_n\\). These coefficients are called the nth cumulants of \\(x\\). The first cumulant turns out to be the mean of \\(x\\), \\[\n\\kappa_1 = \\langle x \\rangle.\n\\] Intuitively, the mean \\(\\mu\\) of a distribution represents its center of mass or average value. To see why, suppose \\(x\\) is a discrete random variable taking on values \\(1, 2, \\cdots, n\\) each with probability \\(p(x) = \\frac{1}{n}\\). Then we’d have \\[\n\\mu = \\sum_{x=1}^n x p(x) = \\frac{1}{n} \\sum_{x=1}^n x = \\overline x.\n\\] That is, the mean is just the unweighted average \\(\\overline x\\) from elementary math. In general each \\(x\\) will be weighted by its probability \\(p(x)\\) giving a weighted average.\nThe second cumulant is evidently given by \\[\n\\kappa_2 = \\langle x^2 \\rangle - \\langle x \\rangle^2.\n\\] This is called the variance of \\(x\\), usually denoted \\(\\sigma^2\\). By rearranging the right-hand side a little bit we can also write the variance in the form \\[\n\\boxed{\\sigma^2 \\equiv \\langle x^2 \\rangle - \\langle x \\rangle^2 = \\langle (x-\\mu) \\rangle^2} \\ .\n\\] This gives an intuitive interpretation of the variance. It’s the mean squared difference from the mean. It’s a squared measure of the spread of the distribution. For this reason we often prefer to take its square root to get a measure of the spread in units of \\(x\\) itself. This is called the standard deviation, \\(\\sigma \\equiv \\sqrt{\\sigma^2}\\).\nThe third cumulant is evidently given by \\[\n\\kappa_3 = \\langle x^3 \\rangle - 3\\langle x^2 \\rangle\\langle x \\rangle + 2 \\langle x \\rangle^3.\n\\] It’s not obvious what this represents, but it turns out to represent the skewness of \\(x\\). That is, the tendency for the distribution to skew left or right by some amount. A distribution symmetric about its mean will have zero skew since all of the odd moments will vanish, hence \\(\\kappa_3 = 0\\). Strictly speaking, the skewness is often normalized by dividing by \\(\\sigma^3\\).\nThere’s a useful graphical trick that can be used to quickly find the relationship between cumulants and moments. The idea is to represent the nth cumulant \\(\\kappa_n\\) is a bag of \\(n\\) points. Then we can get the nth moment by summing over all possible ways of distributing \\(n\\) points among all possible bags \\(1, 2, \\cdots, n\\). It’s easiest to show this by example. Here’s how to get the first few moments from the first few cumulants:\n\n\n\n\n\n\n\nChange of Variables\nOccasionally we’ll want to make a change of variables from one random variable to another. To do that we need to figure out how the probabilities change under the change of variables. Suppose \\(F=F(X)\\) is a random function of a random variable \\(X\\). If \\(f = F(x)\\), then probability that \\(X \\in [x, x+dx]\\) must be the same as the probability that \\(F \\in [f, f+df]\\). Provided \\(F(x)\\) is single-valued, that means we’d have \\[\np_F(f) df = p_X(x) dx.\n\\] Dividing both sides by \\(df\\) and noting that probabilities have to be positive, we have \\[\np_F(f) = p_X(x) \\bigg|\\frac{dx}{df}\\bigg|.\n\\] In general \\(F(x)\\) need not be single-valued. This means we have to sum over all possible values \\(x_i\\) such that \\(f=F(x_i)\\). In this case, we’d instead have \\[\n\\boxed{p_F(f) = \\sum p_X(x_i) \\bigg|\\bigg(\\frac{dx}{df}\\bigg)_{x=x_i}\\bigg|} \\ .\n\\]\n\n\n\n\n\n\nExample: The Laplace Distribution\nSuppose \\(p(x) \\propto e^{-\\lambda |x|}\\) where \\(\\lambda > 0\\) is some scale parameter.\n\nFind the normalization constant \\(\\mathcal{N}\\) such that \\(p(x) = \\mathcal{N} e^{-\\lambda |x|}\\).\nThe PDF must integrate to one from \\(-\\infty\\) to \\(\\infty\\). We have \\[\n1 = \\int_{-\\infty}^\\infty dx \\ p(x) = \\int_{-\\infty}^\\infty dx \\  \\mathcal{N} e^{-\\lambda |x|} = \\frac{2\\mathcal{N}}{\\lambda}.\n\\] Thus, \\(\\mathcal{N} = \\frac{\\lambda}{2}\\), so we finally just have \\(p(x) = \\frac{\\lambda}{2} e^{-\\lambda x}\\). This is called the Laplace distribution.\nSuppose \\(f = x^2\\). Find the new PDF \\(p_F(f)\\) using a change of variables.\nThis transformation is multi-valued, with \\(x = \\pm \\sqrt{f}\\). Using the change of variables, we have \\[\n\\begin{align*}\np_F(f) &= p(\\sqrt{f}) \\bigg|\\frac{d}{df} \\sqrt{f}\\bigg| + p(-\\sqrt{f}) \\bigg|-\\frac{d}{df} \\sqrt{f}\\bigg| \\\\\n&= \\frac{\\lambda}{2} e^{-\\lambda \\sqrt{f}} \\bigg(\\frac{1}{2\\sqrt{f}} +  \\frac{1}{2\\sqrt{f}} \\bigg) \\\\\n&= \\frac{\\lambda}{2\\sqrt{f}} e^{-\\lambda \\sqrt{f}}. \\\\\n\\end{align*}\n\\] Note that this new PDF is only defined when \\(f \\geq 0\\) due to the square root."
  },
  {
    "objectID": "statistical-mechanics/probability.html#probability-distributions",
    "href": "statistical-mechanics/probability.html#probability-distributions",
    "title": "Probability",
    "section": "Probability Distributions",
    "text": "Probability Distributions\nSo far I’ve used the term distribution rather loosely. More formally, given a random variable \\(x\\), a probability distribution is a specific functional form for \\(p(x)\\). We’d write \\(x \\sim p(x)\\) to indicate that \\(x\\) is distributed as \\(p(x)\\). Usually \\(p(x)\\) will be parametric, meaning it will have external parameters that tune the shape of the distribution. Here are some common univariate distributions we’ll see in statistical mechanics:\n\nUniform Distribution\nThe uniform distribution is perhaps the simplest distribution of all, with \\(p(x) = const\\) on some set \\(x \\in \\mathcal{S}\\). As a shorthand we might write \\(x \\sim U(\\mathcal{S})\\) to say \\(x\\) is uniform on the set \\(\\mathcal{S}\\). In the discrete case, \\(x\\) takes on some number of values \\(N\\) each with equal probability, for example if \\(\\mathcal{S} = \\{1, 2, \\cdots, n\\}\\) we have \\[\n\\boxed{p(x) = \\frac{1}{N}} \\ .\n\\] We can easily calculate the moments of a uniform random variable directly. In the discrete case, we’d have \\[\n\\langle x^n \\rangle = \\sum_{x=1}^N \\ x^n \\ p(x) = \\frac{1}{N} (1^n + 2^n + \\cdots + N^n).\n\\] This is just an arithmetic sum in powers of \\(n\\). For example, the first two moments are \\[\n\\begin{align*}\n\\langle x \\rangle &= \\frac{(N+1)}{2}, \\\\\n\\langle x^2 \\rangle &= \\frac{(N+1)(2N+1)}{6}. \\\\\n\\end{align*}\n\\] Using these we can directly calculate the mean and variance, which are \\[\n\\begin{align*}\n\\mu &= \\langle x \\rangle = \\frac{(N+1)}{2}, \\\\\n\\sigma^2 &= \\langle x^2 \\rangle - \\langle x \\rangle^2 = \\frac{N^2-1}{12}. \\\\\n\\end{align*}\n\\] The characteristic function is just given by a geometric series in powers of \\(e^{-ik}\\), \\[\n\\tilde p(k) = \\sum_{x=1}^N p(x) e^{-ikx} = \\sum_{x=1}^N \\frac{1}{N} \\big(e^{-ik}\\big)^n = \\frac{e^{-ik}-e^{-ik(N+1)}}{1-e^{-ik}}.\n\\] We could in principle calculate the cumulant function \\(\\log \\tilde p(k)\\) as well, though it’s clearly not going to be as useful for finding the cumulants here. We’ll see later that the uniform distribution is the maximum entropy distribution when the only known constraints are that \\(x\\) lies in some set \\(S\\).\n\n\nGaussian Distribution\nThe Gaussian distribution is one of the most fundamental distributions in physics. In statistical mechanics, for example, it describes the velocity of gases in a box. Suppose \\(x\\) is a continuous random variable defined on the whole real line. We say it’s Gaussian distributed if its PDF is given by \\[\n\\boxed{p(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\bigg(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\bigg)} \\ .\n\\] The Gaussian distribution has two parameters, a real number \\(\\mu\\) and a positive number \\(\\sigma^2\\). As a shorthand we’ll sometimes say \\(x\\) is Gaussian distributed by writing \\(x \\sim \\mathcal{N}(\\mu, \\sigma^2)\\). The PDF’s curve is the distinctive bell-shaped curve that falls off exponentially fast symmetrically around \\(\\mu\\). For practical purposes, almost all of the probability mass lies in the range \\(-3\\sigma \\leq x \\leq 3\\sigma\\).\nWe can calculate the characteristic function by taking the Fourier transform of \\(p(x)\\). By using a couple of changes of variables and completing the square inside the exponent, we have, \\[\n\\begin{align*}\n\\tilde p(k) &= \\int_\\mathbb{R} dx \\ p(x) e^{-ikx} \\\\\n&= \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\int_\\mathbb{R} dx \\ e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}-ikx} \\\\\n&= \\frac{e^{-ik\\mu}}{\\sqrt{2\\pi\\sigma^2}} \\int_\\mathbb{R} dy \\ e^{-\\frac{y^2}{2\\sigma^2}-ikx} \\quad &y \\equiv& \\ x - \\mu \\\\\n&= e^{-ik\\mu-\\frac{1}{2}k^2 \\sigma^2} \\int_\\mathbb{R} \\frac{dz}{\\sqrt{2\\pi\\sigma^2}} \\ e^{-\\frac{z^2}{2\\sigma^2}} \\quad &z \\equiv& \\ y + ik\\sigma^2 \\\\\n&= e^{-ik\\mu-\\frac{1}{2}k^2 \\sigma^2}. \\\\\n\\end{align*}\n\\] Notice the characteristic function is also itself a Gaussian, just with an imaginary shift. Taking the log immediately gives the cumulant function, which is just the exponent terms, \\[\n\\log \\tilde p(k) = -ik\\mu-\\frac{1}{2}k^2 \\sigma^2.\n\\] Notice only the first two powers of \\(k\\) appear in the cumulant. This means \\(\\kappa_1 = \\mu\\), \\(\\kappa_2 = \\sigma^2\\), and all higher cumulants are zero. Evidently, the parameter \\(\\mu\\) is just the mean and the parameter \\(\\sigma^2\\) is just the variance.\nIf we like, we can use the graphical trick to read off the moments as well. In this case, there can’t be any bags with more than two points, which greatly simplifies terms. The first few moments are, \\[\n\\begin{align*}\n\\langle x \\rangle &= \\kappa_1 = \\mu, \\\\\n\\langle x^2 \\rangle &= \\kappa_2 + \\kappa_1^2 = \\sigma^2 + \\mu^2, \\\\\n\\langle x^3 \\rangle &= 3 \\kappa_2 \\kappa_1 + \\kappa_1^3 = 3\\sigma^2 \\mu + \\mu^3, \\\\\n\\langle x^4 \\rangle &= 3 \\kappa_2^2 + 6 \\kappa_2 \\kappa_1^2 + \\kappa_1^4 = 3\\sigma^4 + 6 \\sigma^2 \\mu^2 + \\mu^4.\n\\end{align*}\n\\] ### Binomial Distribution\nSuppose we have a binary random variable \\(x = 0, 1\\) that takes on the value one with a fixed probability \\(p\\). We can express its PMF simply as \\[\np(x) = p^x (1-p)^{1-x}.\n\\] We’d call such an \\(x\\) a Bernoulli random variable. A common example would be flipping a coin, where heads occurs with a fixed probability \\(p=0.5\\). Now suppose we allow the binary outcome to repeat \\(n\\) times independently. It turns out that the sum of those \\(n\\) outcomes is distributed in a similar way, except now \\(x\\) can take on any value in the range \\(x = 0, 1, \\cdots, n\\). Accounting for normalization, we have \\[\n\\boxed{p(x) = \\binom{n}{x} p^x (1-p)^{n-x}} \\ .\n\\] We’d say \\(x\\) is binomially distributed with parameters \\(p\\) and \\(n\\), sometimes written as \\(x \\sim \\text{Bin}(n,p)\\). The normalization constant is the binomial coefficient, \\[\n\\binom{n}{x} \\equiv \\frac{n!}{x!(n-x)!}.\n\\] The binomial coefficient represents the number of ways to choose \\(x\\) points from a total of \\(n\\) points, assuming the order the points are chosen is irrelevant.\nThe characteristic function of the binomial distribution can be found using the binomial theorem, \\[\n\\begin{align*}\n\\tilde p(k) &= \\sum_{x=0}^n \\binom{n}{x} p^x (1-p)^{n-x} e^{-ikx} \\\\\n&= \\sum_{x=0}^n \\binom{n}{x} \\big(p e^{-ik}\\big)^x (1-p)^{n-x} \\\\\n&= \\big(pe^{-ik} + (1-p) \\big)^n.\n\\end{align*}\n\\] Notice the parameter \\(n\\) appears only in the exponent. This means the cumulant function is just \\(n\\) times the cumulant function for the Bernoulli distribution, \\[\n\\log \\tilde p_n(k) = n \\log \\tilde p_1(k).\n\\] In particular, the cumulants are all proportional to \\(n\\) times the Bernoulli cumulants. Expanding out \\(\\log \\tilde p_1(k)\\), we have \\[\n\\begin{align*}\n\\log \\tilde p_1(k) &= \\log\\big(pe^{-ik} + (1-p)\\big) \\\\\n&= \\log\\big(1 + p(e^{-ik}-1)\\big) \\\\\n&= p(e^{-ik}-1) - \\frac{1}{2} p^2(e^{-ik}-1)^2 + \\cdots \\\\\n&= p\\bigg(-ik + \\frac{(-ik)^2}{2} + \\cdots\\bigg) - \\frac{1}{2} p^2 \\bigg(-ik + \\frac{(-ik)^2}{2} + \\cdots\\bigg)^2 + \\cdots \\\\\n&= -ik p + \\frac{(-ik)^2}{2} p(1-p) + \\cdots\n\\end{align*}\n\\] Thus, the mean and variance of the binomial distribution are just \\[\n\\mu = np, \\quad \\sigma^2 = np(1-p).\n\\] These distributions can be straight-forwardly generalized to situations with more than binomial outcomes. The Bernoulli distribution generalizes to the categorical distribution, where \\(x\\) is allowed to be one of \\(k\\) categories, each with a fixed probability \\(p_j\\). Clearly those probabilities must sum to one. If the categories are \\(x = 1, 2, \\cdots, k\\) the PMF would be given by \\[\np(x) = p_1^{\\delta_{1x}} p_2^{\\delta_{2x}} \\cdots p_k^{\\delta_{kx}}, \\quad x = 1, 2, \\cdots, k.\n\\] The binomial distribution generalizes to the multinomial distribution, where \\(x\\) is now a vector whose jth component is the number of times category \\(j\\) occurred in \\(n\\) total trials. Each \\(x_j = 0, 1, \\cdots, n_j\\) is essentially its own binomial distribution, except we require \\(n = n_1 + n_2 + \\cdots n_k\\). The PMF is given by \\[\np(x) = \\frac{n!}{n_1!n_2!\\cdots n_k!} p_1^{n_1} p_2^{n_2} \\cdots p_2^{n_2}.\n\\] The coefficient \\(\\frac{n!}{n_1!n_2!\\cdots n_k!}\\) is called a multinomial coefficient. It’s a count of the number of ways to distribute \\(n\\) points into \\(k\\) bins such that each bin \\(j\\) contains exactly \\(n_j\\) points. We might say \\(x\\) is multinomially distributed by writing \\(x \\sim \\text{Multinomial}(n_1,n_2,\\cdots,n_k; p_1, p_2, \\cdots, p_k)\\).\n\n\nPoisson Distribution\nSuppose we’re interested in answering the following question: What is the probability that \\(x\\) events occur inside a time interval \\([0,T]\\) provided each event is independent of the others, and that the probability of any one event occurring in an infinitesimal interval \\([0,dt]\\) is a constant \\(\\alpha dt\\). To figure out what \\(p(x)\\) is, let’s imagine subdividing \\([0,T]\\) up into \\(N = \\frac{T}{dt}\\) subintervals. In each subinterval, any single event is a Bernoulli random variable that either occurs with probability \\(\\alpha dt\\) or doesn’t occur with probability \\((1-\\alpha)dt\\). If we assume each subinterval is independent of the others, the characteristic function of \\(p(x)\\) is just \\[\n\\begin{align*}\n\\tilde p(k) &= (\\tilde p_1(k))^N \\\\\n&= \\big(\\alpha e^{-ik}dt + (1-\\alpha)dt\\big)^N \\\\\n&= \\big(1 + \\alpha dt(e^{-ik}-1)\\big)^{T/dt} \\\\\n&\\approx e^{\\alpha T(e^{-ik} - 1)}. \\\\\n\\end{align*}\n\\] The last equality becomes exact when \\(dt\\) is infinitesimal. Let’s define \\(\\lambda \\equiv \\alpha T\\) as a dimensionless rate parameter. Then we can write the characteristic function as \\[\n\\tilde p(k) = e^{\\lambda(e^{-ik} - 1)}.\n\\] To get the sought after PDF \\(p(x)\\) we just need to take the inverse Fourier transform of \\(\\tilde p(k)\\). We have \\[\n\\begin{align*}\np(x) &= \\int_{\\mathbb{R}} \\frac{dk}{2\\pi} \\ \\tilde p(k) e^{ikx} \\\\\n&= \\int_{\\mathbb{R}} \\frac{dk}{2\\pi} \\ e^{\\lambda (e^{-ik}-1)}e^{ikx} \\\\\n&= e^{-\\lambda} \\int_{\\mathbb{R}} \\frac{dk}{2\\pi} \\  e^{ikx} \\sum_{n=0}^\\infty \\frac{(\\lambda e^{-ik})^n}{n!} \\\\\n&= e^{-\\lambda} \\sum_{n=0}^\\infty \\frac{\\lambda^n}{n!} \\int_{\\mathbb{R}} \\frac{dk}{2\\pi} e^{-ik(x-n)} \\\\\n&= e^{-\\lambda} \\sum_{n=0}^\\infty \\frac{\\lambda^n}{n!} \\delta(x-n). \\\\\n\\end{align*}\n\\] The delta function forces \\(x\\) to be a positive integer for \\(p(x)\\) to be non-zero. That is, \\(p(x)\\) is actually a PMF \\[\n\\boxed{p(x) = e^{-\\lambda} \\frac{\\lambda^x}{x!}} \\ .\n\\] This is called the Poisson distribution. The Poisson distribution is used to model counts of events, where each event is allowed to occur independently with some fixed rate \\(\\lambda = \\alpha T\\). We can denote that \\(x\\) is Poisson distributed by writing \\(x \\sim \\text{Poisson}(\\lambda)\\).\nThis distribution has the unusual property that all its cumulants are equal. Indeed, observe we have \\[\n\\log \\tilde p(k) = \\lambda (e^{-ik} - 1) = \\sum_{n=1}^\\infty \\frac{(-ik)^n}{n!} \\lambda.\n\\] That is, all the cumulants are just \\(\\lambda\\). In particular, \\(\\mu = \\sigma^2 = \\lambda\\)."
  },
  {
    "objectID": "statistical-mechanics/probability.html#multivariate-probability",
    "href": "statistical-mechanics/probability.html#multivariate-probability",
    "title": "Probability",
    "section": "Multivariate Probability",
    "text": "Multivariate Probability\n\nRandom Vectors\nLet’s now look at the situation where we have \\(N\\) random variables \\(X_1, X_2, \\cdots, X_N\\). The vector of all such random variables is called a random vector, i.e. a vector \\(\\mathbf{X} = (X_1, X_2, \\cdots, X_N)\\). To each random vector we can assign a joint CDF of the form \\[\nP(\\mathbf{x}) \\equiv \\mathbb{Pr}(\\{\\mathbf{X} \\leq \\mathbf{x}\\}) = \\mathbb{Pr}(\\{X_1 \\leq x_1, X_2 \\leq x_2, \\cdots, X_N \\leq x_N\\}).\n\\] The CDF must be an increasing function in each \\(x_i\\), go to \\(0\\) as all \\(x_i \\rightarrow -\\infty\\), and go to \\(1\\) as all the \\(x_i \\rightarrow \\infty\\).\nIf \\(\\mathbf{X}\\) is discrete, we can assign a joint PMF to each value in the support \\(S \\in \\mathbb{R}^N\\) by defining \\[\n\\boxed{p(\\mathbf{x}) \\equiv \\mathbb{Pr}(\\{\\mathbf{X} = \\mathbf{x}\\})} \\ .\n\\] The joint PMF is a valid probability, meaning it must satisfy \\(0 \\leq p(\\mathbf{n}) \\leq 1\\) and \\(\\sum_{\\mathbf{n} \\in S} p(\\mathbf{n}) = 1\\).\nSimilarly, if \\(\\mathbf{X}\\) is continuous, we can assign a joint PDF to each value in \\(S \\in \\mathbb{R}^N\\) by defining \\[\np(\\mathbf{x}) d^Nx \\equiv \\mathbb{Pr}(\\{x_1 \\leq X_1 \\leq x_1 + dx_1, x_2 \\leq X_2 \\leq x_2 + dx_2, \\cdots, x_N \\leq X_N \\leq x_N + dx_N\\}),\n\\] where \\(d^N x = dx_1dx_2\\cdots dx_N\\) is the \\(N\\)-dimensional volume element. The joint PMF must satisfy both \\(p(\\mathbf{x}) \\geq 0\\), and \\(\\int_S d^N x \\ p(\\mathbf{x}) = 1\\). Clearly the joint PMF is just a special case of the joint PDF, since we can always just use delta functions to express a PMF as a PDF.\nAs with ordinary random variables, we’ll frequently abuse notation by using \\(\\mathbf{x}\\) for both the random vector itself as well as its value where there’s no risk of confusion.\n\n\nJoint Moments and Cumulants\nFor any function \\(F(\\mathbf{x})\\) of a random vector \\(\\mathbf{x}\\) we can define its expectation value as \\[\n\\boxed{\\langle \\mathbf{x} \\rangle \\equiv \\int_S d^N x \\ F(\\mathbf{x}) p(\\mathbf{x})} \\ .\n\\] For both discrete and continuous random vectors we can define the joint characteristic function \\[\n\\boxed{\\tilde p(\\mathbf{k}) \\equiv \\langle e^{-i\\mathbf{k} \\cdot \\mathbf{x}} \\rangle \\equiv \\int_{\\mathbb{R}^N} d^Nx \\ p(\\mathbf{x}) e^{-i\\mathbf{k} \\cdot \\mathbf{x}}} \\ .\n\\] By taking the logarithm of the joint CF, we can also define the joint cumulant function \\(\\log \\tilde p(\\mathbf{k})\\). From these two functions we can extract the joint moments and cumulants. The \\(n_1, n_2, \\cdots, n_N\\) joint moment \\(\\mu_{n_1,n_2,\\cdots,n_N} \\equiv \\langle x_1^{n_1} x_2^{n_2} \\cdots x_N^{n_N} \\rangle\\) of \\(\\mathbf{X}\\) is given by taking partial derivatives of the joint characteristic function, \\[\n\\langle x_1^{n_1} x_2^{n_2} \\cdots x_N^{n_N} \\rangle \\equiv \\frac{\\partial^{n_1}}{\\partial (-i k_1)^{n_1}} \\frac{\\partial^{n_2}}{\\partial (-i k_2)^{n_2}} \\cdots \\frac{\\partial^{n_N}}{\\partial (-i k_N)^{n_N}} \\tilde p(k_1, k_2, \\cdots, k_N) \\bigg |_{k_1=k_2=\\cdots=k_N=0}.\n\\] Similarly, the \\(n_1, n_2, \\cdots, n_N\\) joint cumulant \\(\\kappa_{n_1,n_2,\\cdots,n_N}\\) is given by taking partial derivatives of the joint cumulant function, \\[\n\\kappa_{n_1,n_2,\\cdots,n_N} \\equiv \\frac{\\partial^{n_1}}{\\partial (-i k_1)^{n_1}} \\frac{\\partial^{n_2}}{\\partial (-i k_2)^{n_2}} \\cdots \\frac{\\partial^{n_N}}{\\partial (-i k_N)^{n_N}} \\log \\tilde p(k_1, k_2, \\cdots, k_N) \\bigg |_{k_1=k_2=\\cdots=k_N=0}.\n\\] The sum \\(n \\equiv n_1 + n_2 + \\cdots n_N\\) determines the order of the moment or cumulant. Of particular interest are the first and second cumulants. The first cumulants are the means \\(\\mu_i \\equiv \\langle x_i \\rangle\\). We can think of these together by putting them all into a mean vector \\(\\boldsymbol{\\mu} \\equiv \\langle \\mathbf{x} \\rangle \\equiv \\big(\\mu_1, \\mu_2, \\cdots, \\mu_N\\big)\\). The second cumulants are the covariances, \\(\\sigma_{ij} \\equiv \\kappa_{ij}\\). We can put all these into an \\(N \\times N\\) matrix to get the covariance matrix \\(\\mathbf{\\Sigma} \\equiv \\big(\\sigma_{ij}\\big)_{i,j=1,\\cdots,N}\\). The diagonal entries of the covariance matrix correspond to the usual variances \\(\\sigma_i^2 = \\sigma_{ii}\\). The off diagonal terms are the covariances, capturing the dependence or correlation between \\(x_i\\) and \\(x_j\\).\nWe can use the same graphical trick to express joint cumulants in terms of joint moments. The only difference is we need to label each point by its index and bag them appropriately. We can use this to show that the covariance \\(\\sigma_{ij} \\equiv \\kappa_{ij}\\) can be written as \\[\n\\sigma_{ij} = \\langle x_i x_j \\rangle - \\langle x_i \\rangle \\langle x_j \\rangle = \\langle (x_i - \\mu_i)(x_j - \\mu_j) \\rangle.\n\\] In matrix notation, the entire covariance matrix can be expressed using moments as \\[\n\\boxed{\\mathbf{\\Sigma} = \\langle \\mathbf{x}\\mathbf{x}^\\top \\rangle - \\langle \\mathbf{x} \\rangle \\langle \\mathbf{x} \\rangle^\\top = \\langle (\\mathbf{x}-\\boldsymbol{\\mu})(\\mathbf{x}-\\boldsymbol{\\mu})^\\top \\rangle} \\ .\n\\] This implies the covariance matrix must in fact be a positive semi-definite matrix. That is, \\[\n\\mathbf{\\Sigma} = \\mathbf{\\Sigma}^\\top, \\quad \\mathbf{v}^\\top\\mathbf{\\Sigma}\\mathbf{v} \\geq 0 \\quad \\forall \\mathbf{v} \\neq \\mathbf{0}.\n\\]\n\n\nConditional and Marginal Probability\nWe can get smaller joint probabilities by “summing out” the random variables we don’t need. These are called marginal probabilities or unconditional probabilities. For example, if we have two random variables \\(x\\) and \\(y\\), the marginal PDF \\(p(y)\\) is given by integrating \\(x\\) out of the joint PDF \\(p(x,y)\\), \\[\n\\boxed{p(y) \\equiv \\int_\\mathbb{R} dx \\ p(x,y)} \\ .\n\\] If we have \\(N\\) random variables \\(x_1,x_2,\\cdots, x_s, x_{s+1},\\cdots,x_N\\) and integrate out the last \\(N-s\\) variables \\(x_s, x_{s+1},\\cdots,x_N\\), then we get the marginal PDF \\(p(x_1,x_2,\\cdots, x_s)\\), \\[\np(x_1,x_2,\\cdots, x_s) \\equiv \\int_{\\mathbb{R}^{N-s}} dx_s, dx_{s+1},dx_N \\ p(x_1,x_2,\\cdots, x_s, x_s, x_{s+1},\\cdots,x_N).\n\\] Similarly, we can define the conditional probabilities, which allow for random variables to depend on the outcome of other random variables directly. For example, for two random variables \\(x\\) and \\(y\\) with joint PDF \\(p(x,y)\\), we can define the conditional probability of \\(y\\) given \\(x\\) as \\[\n\\boxed{p(y|x) \\equiv \\frac{p(x,y)}{p(x)}} \\ .\n\\] We can think of \\(p(x,y)\\) as a kind of prior distribution and \\(p(x)\\) as a kind of normalization constant. Notice we can similarly write \\(p(x,y) = p(x|y) p(y)\\). If we plug this into the formula for \\(p(y|x)\\) we get the well-known Bayes’ Rule, which says that \\[\np(y|x) = \\frac{p(x|y)p(y)}{p(x)}.\n\\] If we have \\(N\\) random variables \\(x_1,x_2,\\cdots, x_s, x_{s+1},\\cdots,x_N\\) and want to condition the first \\(s\\) variables on the last \\(N-s\\) variables, we’d similarly write \\[\np(x_1,x_2,\\cdots, x_s) \\equiv \\frac{p(x_1,x_2,\\cdots, x_s, x_{s+1},\\cdots,x_N)}{p(x_{s+1},\\cdots,x_N)}.\n\\] We haven’t proven it, but it’s not hard to show that the marginal and conditional probabilities are indeed valid probabilities and PDFs.\nWhen conditioning a random variable \\(y\\) on another random variable \\(x\\) gives no information about \\(y\\), we say that \\(x\\) and \\(y\\) are independent, sometimes written \\(x \\perp y\\). If \\(x\\) gives no information about \\(y\\), that means we must have \\(p(y|x) = p(y)\\), which is equivalent to saying the joint PDF factors, \\(p(x,y) = p(x) p(y)\\). Clearly, if \\(x\\) gives no information about \\(y\\), then \\(y\\) gives no information about \\(x\\) either. Independence is symmetric.\nMore generally, we say \\(N\\) random variables \\(x_1,x_2,\\cdots,x_N\\) are mutually independent provided \\[\n\\boxed{p(x_1,x_2,\\cdots,x_N) = p_1(x_1) p_2(x_2) \\cdots p_N(x_N)} \\ .\n\\] In the special case where all \\(N\\) variables also happen to come from the same distribution \\(p(x)\\) we say they’re independent identically distributed or IID. In this simple case we just have \\[\np(x_1,x_2,\\cdots,x_N) = \\big(p(x)\\big)^N.\n\\] Independent random variables have the property that their mixed cumulants will always be zero. This is equivalent to saying that the joint expectation of any product of random variables value factors, \\[\n\\langle F_1(x_1) F_2(x_2) \\cdots F_N(x_N) \\rangle = \\langle F_1(x_1) \\rangle \\langle F_2(x_2) \\rangle \\cdots \\langle F_N(x_N) \\rangle.\n\\]\n\n\nThe Multivariate Gaussian Distribution\nWhile there are many joint probability distributions, the most important one to be aware of is the multivariate Gaussian distribution. Suppose \\(\\mathbf{x} = (x_1, x_2, \\cdots, x_N)\\) are independent, with each \\(x_i\\) Gaussian distributed with mean \\(\\mu_i\\) and variance \\(\\sigma_i^2\\). Then it’s easy to show their joint PDF is given by \\[\np(x_1, x_2, \\cdots, x_N) = \\bigg(\\frac{1}{(2\\pi)^N\\sigma_1^2\\sigma_2^2\\cdots\\sigma_N^2}\\bigg)^{1/2} \\exp\\bigg(-\\frac{1}{2} \\sum_{i=1}^N \\frac{(x_i-\\mu_i)^2}{\\sigma_i^2} \\bigg).\n\\] But what if \\(\\mathbf{x}\\) is not independent? All we have to do in that case is make a change of basis. Notice that joint PDF above is just the diagonalized form for the following joint PDF in vector form, \\[\n\\boxed{p(\\mathbf{x}) = \\bigg(\\frac{1}{(2\\pi)^N \\det(\\mathbf{\\Sigma})}\\bigg)^{1/2} \\exp\\bigg(-\\frac{1}{2} (\\mathbf{x} - \\boldsymbol{\\mu})^\\top \\mathbf{\\Sigma}^{-1}(\\mathbf{x} - \\boldsymbol{\\mu}) \\bigg)} \\ .\n\\] By making a change of basis or rotating \\(\\mathbf{\\Sigma}\\), this vectorized PDF gives the most general form of the Gaussian distribution for \\(N\\) variables. This is the multivariate Gaussian distribution, denoted \\(\\mathbf{x} \\sim \\mathcal{N}(\\boldsymbol{\\mu},\\mathbf{\\Sigma})\\).\nUsing the same diagonalization trick, it’s just as easy to show that the joint characteristic function is \\[\n\\boxed{\\tilde p(\\mathbf{k}) = \\exp(-i\\mathbf{k} \\cdot \\boldsymbol{\\mu} - \\frac{1}{2} \\mathbf{k}^\\top \\mathbf{\\Sigma} \\mathbf{k})} \\ ,\n\\] and the joint cumulant is just \\(\\log \\tilde p(\\mathbf{k}) = -i\\mathbf{k} \\cdot \\boldsymbol{\\mu} - \\frac{1}{2} \\mathbf{k}^\\top \\mathbf{\\Sigma} \\mathbf{k}\\). This again implies that only the first and second joint cumulants are non-zero for the multivariate Gaussian. All higher-order terms vanish. For this reason, multivariate Gaussian random variables satisfy a special condition known as Wick’s Theorem.\nWick’s Theorem: Suppose \\(\\mathbf{x} = (x_1, x_2, \\cdots, x_N)\\) is a Gaussian random vector with mean \\(\\boldsymbol{\\mu} = \\mathbf{0}\\). Then the \\(n\\)th joint moments are given by \\[\n\\boxed{\n\\langle x_1^{n_1} x_2^{n_2} \\cdots x_N^{n_N} \\rangle =\n\\begin{cases}\n0 & n = \\text{odd} \\\\\n\\text{sum of all pairwise contractions} & n = \\text{even} \\\\\n\\end{cases}\n} \\ .\n\\] For example, suppose we wanted to calculate \\(\\langle x_1^2 x_2 x_3 \\rangle\\). In this case, the possible pairwise contractions are\n\n\\(x_1 x_1\\) and \\(x_2 x_3\\) , which gives a term \\(\\sigma_{11} \\sigma_{23}\\),\n\\(x_1 x_2\\) and \\(x_1 x_3\\) , which gives a term \\(\\sigma_{12} \\sigma_{13}\\),\n\\(x_1 x_3\\) and \\(x_1 x_2\\) , which gives a term \\(\\sigma_{13} \\sigma_{12}\\).\n\nSumming each of these pairwise contractions together, we just have \\[\n\\langle x_1^2 x_2 x_3 \\rangle = \\sigma_{11} \\sigma_{23} + 2 \\sigma_{12} \\sigma_{13}.\n\\]"
  },
  {
    "objectID": "statistical-mechanics/probability.html#asymptotic-analysis",
    "href": "statistical-mechanics/probability.html#asymptotic-analysis",
    "title": "Probability",
    "section": "Asymptotic Analysis",
    "text": "Asymptotic Analysis\nIn this section we’ll focus on important results that apply for large numbers of random variables \\(N \\gg 1\\).\n\nThe Central Limit Theorem\nIt turns out that the sum of random variables will often by approximately Gaussian distributed provided some minor regularity assumptions are met. This important result is called the central limit theorem.\nCentral Limit Theorem: Suppose \\(x = \\sum_{i=1}^N x_i\\) is a sum of \\(N\\) IID random variables with finite mean \\(\\mu\\) and variance \\(\\sigma^2\\). Then when \\(N \\gg 1\\) the probability density satisfies \\[\n\\boxed{p\\bigg(\\frac{x-N\\mu}{\\sqrt{N\\sigma^2}}\\bigg) \\approx \\frac{1}{\\sqrt{2 \\pi}} \\exp\\bigg(-\\frac{1}{2}\\bigg(\\frac{x-N\\mu}{\\sqrt{N\\sigma^2}}\\bigg)^2\\bigg)} \\ .\n\\] Proof: Suppose each \\(x_i\\) is IID with distribution \\(p_1(x_1)\\). The characteristic function for \\(p(x)\\) must then be \\[\n\\tilde p(k) = \\langle e^{-i kx} \\rangle = \\langle e^{-i k\\sum_{i=1}^N x_i} \\rangle = \\prod_{i=1}^N \\langle e^{-i k x_i} \\rangle = \\tilde p(k_1, k_2, \\cdots, k_N) \\bigg |_{k_1=k_2=\\cdots=k_N=k}.\n\\] If we take the cumulant function \\(\\log \\tilde p(k)\\) and expand it out directly, we have \\[\n\\log \\tilde p(k) = \\sum_{n=1}^\\infty \\frac{(-ik)^n}{n!} \\kappa_n(x) = -ik \\kappa_1(x) + \\frac{(-ik)^2}{2} \\kappa_2(x) + \\cdots\n\\] Expanding out the cumulant function \\(\\log \\tilde p(k_1, k_2, \\cdots, k_N)\\) and setting all \\(k_i=k\\), we have \\[\n\\begin{align*}\n\\log \\tilde p(k_1, k_2, \\cdots, k_N) &= \\sum_{n=0}^\\infty \\sum_{\\sum n_j=n} \\frac{(-ik_1)^{n_1} (-ik_2)^{n_2} \\cdots (-ik_N)^{n_N}}{n!} \\kappa_{n_1 n_2 \\cdots n_N} \\bigg |_{k_1=k_2=\\cdots=k_N=k} \\\\\n&= \\sum_{n=0}^\\infty \\sum_{\\sum n_j=n} \\frac{(-ik)^n}{n!} \\kappa_{n_1 n_2 \\cdots n_N} \\\\\n&= (-ik) \\sum_{\\sum n_j=1} \\kappa_{n_1 n_2 \\cdots n_N} + \\frac{(-ik)^2}{2} \\sum_{\\sum n_j=2} \\kappa_{n_1 n_2 \\cdots n_N} + \\cdots\n\\end{align*}\n\\] Equating the two equations, we thus have \\[\n\\kappa_n(x) = \\sum_{\\sum n_j=n} \\kappa_{n_1 n_2 \\cdots n_N}.\n\\] That is, the \\(n\\)th cumulant of the sum is the sum of all the joint \\(n\\)th cumulants. Now, suppose all the \\(x_i\\) are independent. Then their joint PDF must factor as \\[\np(x_1,x_2,\\cdots,x_N) = p_1(x_1) p_2(x_2) \\cdots p_N(x_N).\n\\] Moreover, since their mixed cumulants must be zero, the cumulants of the sum further reduce to \\[\n\\kappa_n(x) = \\sum_{i=1}^N \\kappa_n(x_i),\n\\] Now suppose all the \\(x_i\\) are identically distributed with the same PDF \\(p_1(x_i)\\). Then we further have just \\[\n\\kappa_n = N \\kappa_{n,i}.\n\\] Define another random variable \\(y\\) by re-centering and rescaling \\(x\\) as \\[\nz \\equiv \\frac{x - N\\mu}{\\sqrt{N\\sigma^2}}.\n\\] Then the cumulants of \\(z\\) are given by \\[\n\\begin{align*}\n\\kappa_1(z) &= 0, \\\\\n\\kappa_2(z) &= 1, \\\\\n\\kappa_n(z) &= \\frac{N\\kappa_n(x_1)}{(N\\sigma^2)^{n/2}} = O\\big(N^{1-n/2}\\big). \\\\\n\\end{align*}\n\\] The higher order cumulants of \\(z\\) evidently go to zero when \\(N \\gg 1\\). But we already know the only distribution whose higher moments are zero is the Gaussian distribution. Thus, we’ve shown \\[\np(z) \\approx \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{z^2}{2}}. \\qquad \\text{Q.E.D.}\n\\] Note the central limit theorem is also true for non-IID random variables, provided the higher cumulants decay as \\(\\kappa_n(x) = O(N^{n/2})\\).\nIn the proof of the CLT we implicitly assumed that the cumulants were all finite. What if that weren’t the case? This will happen if the PDF of each \\(x_i\\) is heavy-tailed. Heavy-tailed distributions are commonly used to model rare events. It turns out then that the sum won’t in general converge to a Gaussian. In fact, if it does converge, it’ll converge to a Levy distribution, a general class of heavy-tailed distributions.\n\n\nThe Saddlepoint Approximation\nIn the section on thermodynamics, we saw both intensive variables and extensive variables. The intensive variables are ones that don’t depend on particle number at all, i.e. they’re \\(O(1)\\) functions of \\(N\\). The extensive variables are linear in particle number, i.e. they’re \\(O(N)\\). In principle we could imagine other functional dependences on \\(N\\) as well. For example, a variable could be polynomial in \\(N\\), i.e. \\(O(N^p)\\) for some \\(p\\). More importantly, a variable can be exponential in \\(N\\), i.e. \\(O(e^{N\\phi})\\) for some \\(\\phi\\). For example, the volume of a gas would be a variable that can scale exponentially with \\(N\\), since it often goes like \\(V^N\\).\nWhen \\(N \\gg 1\\), the sum of many exponential variables can be well approximated by the maximum term. Suppose we have \\(n\\) non-negative variables \\(x_1,x_2,\\cdots,x_n\\) of the form \\(x_i \\sim e^{N\\phi_i}\\) as \\(N \\rightarrow \\infty\\). Then their sum \\(S = \\sum x_i\\) satisfies \\[\nS \\sim x_{max} = \\max_{i=1,\\cdots,n} x_i, \\quad \\text{when} \\quad N \\rightarrow \\infty.\n\\] When each \\(x_i = A_i e^{N\\phi_i}\\), this just says \\(S \\approx A_{max} e^{N\\phi_{max}}\\) when \\(N \\gg 1\\). To see why this fact is true, note that since each \\(x_i \\geq 0\\), we must have \\(x_{max} \\leq S \\leq nx_{max}\\). Since the logarithm is monotonic, if we take the log of each term and divide by \\(N\\), we have \\[\n\\frac{\\log x_{max}}{N} \\leq \\frac{\\log S}{N} \\leq \\frac{\\log x_{max}}{N} + \\frac{\\log n}{N}.\n\\] If we take \\(N \\rightarrow \\infty\\) while holding \\(n\\) fixed, then the term \\(\\frac{\\log n}{N} \\rightarrow 0\\), which gives \\[\n\\frac{\\log S}{N} \\sim \\frac{\\log x_{max}}{N} = \\phi_i.\n\\]\nMore useful for our purposes will be the continuous analog of this result, the saddlepoint approximation.\nSaddlepoint Approximation: Suppose we have a function of the form \\(f(x) = e^{N\\phi(x)}\\) where \\(\\phi(x)\\) grows polynomially. Then we have \\[\n\\boxed{S = \\int_\\mathbb{R} dx \\ e^{N\\phi(x)} \\sim \\sqrt{\\frac{2\\pi}{N|\\phi''(x_{max})|}} e^{N\\phi_{max}}} \\ , \\quad \\text{as} \\ \\ N \\rightarrow \\infty.\n\\] Proof: To see why this is true let’s first Taylor expand \\(\\phi(x)\\) around its global maximum \\(x_{max}\\). Since \\(\\phi'(x_{max}) = 0\\) and \\(\\phi''(x_{max}) \\leq 0\\), we have \\[\n\\phi(x) = \\phi(x_{max}) - \\frac{1}{2} |\\phi''(x_{max})| (x-x_{max})^2 + O\\big((x-x_{max})^3\\big).\n\\] Plugging this into the integral and simplifying then gives \\[\n\\begin{align*}\nS &= \\int_\\mathbb{R} dx \\ \\exp\\bigg(N\\phi_{max} - \\frac{N}{2} |\\phi''(x_{max})| (x-x_{max})^2 + \\frac{N}{6} |\\phi'''(x_{max})| (x-x_{max})^3 + \\cdots\\bigg) \\\\\n&= \\int_\\mathbb{R} dx \\ \\exp\\bigg(N\\phi_{max} - \\frac{N}{2} |\\phi''(x_{max})| (x-x_{max})^2\\bigg) \\exp\\bigg(\\frac{N}{6} |\\phi'''(x_{max})| (x-x_{max})^3 + \\cdots\\bigg) \\\\\n&= e^{N\\phi_{max}} \\int_\\mathbb{R} dx \\ \\exp\\bigg(- \\frac{N}{2} |\\phi''(x_{max})| (x-x_{max})^2\\bigg) \\bigg(1 + \\frac{N}{6}|\\phi'''(x_{max})|(x-x_{max})^3 + \\cdots\\bigg) \\\\\n&= e^{N\\phi_{max}} \\sqrt{\\frac{2\\pi}{N|\\phi''(x_{max})|}} \\bigg(1 + O\\bigg(\\frac{1}{N}\\bigg)\\bigg).\n\\end{align*}\n\\] The last line follows from the fact that the integral with \\((x-x_{max})^3\\) vanishes since it’s an odd function, which means the next term \\((x-x_{max})^4\\) has to be considered, which integrates to order \\(O\\big(N^{-3/2}\\big)\\).\nNow, let’s again look at \\(\\frac{\\log S}{N}\\) as \\(N \\rightarrow \\infty\\). We have \\[\n\\frac{\\log S}{N} = \\phi_{max} - \\frac{1}{2N} \\log \\frac{N|\\phi''(x_{max})|}{2\\pi} + O\\bigg(\\frac{1}{N^2}\\bigg).\n\\] We can see that as \\(N \\rightarrow \\infty\\), \\(\\frac{\\log S}{N} \\rightarrow \\phi_{max}\\) with a correction of order \\(O\\big(\\frac{\\log N}{N}\\big)\\). \\(\\text{Q.E.D.}\\)\nIt’s interesting to observe that only the global maximum appears in this approximation. What if \\(\\phi(x)\\) had some other local maximum \\(\\phi(x_{max}')\\)? Strictly speaking we’d have to do the same approximation scheme about each of the maxima one-by-one. However, due to the presence of the exponential, if \\(\\phi(x_{max}') < \\phi(x_{max})\\), then for large \\(N\\) we’d have \\[\ne^{N\\phi(x_{max}')} \\ll e^{N\\phi(x_{max})}.\n\\] In the limit where \\(N \\rightarrow \\infty\\), the correction term \\(e^{-N\\big(\\phi(x_{max})-\\phi(x_{max}')\\big)} \\rightarrow 0\\). In this sense, we can indeed neglect the other local maxima as long as they’re less than \\(\\phi(x_{max})\\) and \\(N \\gg 1\\).\n\n\n\n\n\nBy far the most useful corollary to this result for our purposes is the Stirling Approximation.\nStirling Approximation: As \\(N \\rightarrow \\infty\\), we have \\[\n\\boxed{N! \\sim N^N e^{-N} \\sqrt{2\\pi N}} \\ .\n\\] Proof: Observe by induction that we can write \\(N!\\) as the following integral, \\[\nN! = \\int_0^\\infty dx \\ x^N e^{-x} = \\int_0^\\infty dx \\ \\exp\\bigg(N\\bigg(\\log x - \\frac{x}{N}\\bigg)\\bigg).\n\\] Take \\(\\phi(x) = \\log x - \\frac{x}{N}\\). This function is maximized when \\(x_{max} = N\\), where \\(\\phi_{max} = \\log N - 1\\). At this point we have \\(\\phi''(x_{max}) = - \\frac{1}{N^2}\\). Plugging all this into the saddlepoint approximation, we have \\[\n\\begin{align*}\nN! &= e^{N(\\log N - 1)} \\sqrt{\\frac{2\\pi}{N|-N^{-2}|}} \\bigg(1 + O\\bigg(\\frac{1}{N}\\bigg)\\bigg) \\\\\n&= N^N e^{-N} \\sqrt{2\\pi N} \\bigg(1 + O\\bigg(\\frac{1}{N}\\bigg)\\bigg). \\quad \\text{Q.E.D.}\n\\end{align*}\n\\] Usually we’ll be more interested in \\(\\log N!\\) rather than \\(N!\\) itself. In that case we just have \\[\n\\log N! = N \\log N - N + \\frac{1}{2} \\log 2\\pi N + O\\bigg(\\frac{1}{N}\\bigg).\n\\] We’ll typically imagine \\(N\\) to be really big, like \\(N \\sim 10^{23}\\). In that case we can generally neglect the sublinear terms and write \\[\n\\boxed{\\log N! \\approx N\\log N - N} \\ .\n\\] This will usually be the form of Stirling’s approximation that we use in statistical mechanics. We’ll often write Stirling’s approximation in exponentiated form like this as well, where it’s understood what we really mean is the two sides equal only logarithmically as above, \\[\nN! \\sim N^N e^{-N}.\n\\]"
  },
  {
    "objectID": "statistical-mechanics/probability.html#information-theory",
    "href": "statistical-mechanics/probability.html#information-theory",
    "title": "Probability",
    "section": "Information Theory",
    "text": "Information Theory\n\nInformation and Entropy\nWe can think about probabilities in a completely different sense by thinking about the information content contained in a system and how uncertain we are about what that information content is. Suppose we wanted to transmit a message containing \\(N\\) characters, where each character is sampled from some alphabet \\(\\Sigma\\) containing \\(M\\) total characters. We’d like to ask the following question: How many bits of information does a typical message of \\(N\\) characters from this alphabet contain?\nSuppose we had no information at all about how often any one particular character \\(x_m \\in \\Sigma\\) occurs in a message. In this case, we’d have to assume that all messages of length \\(N\\) are typical. Since there are \\(M^N\\) possible messages of length \\(N\\), we’d say there are \\(g = M^N\\) typical messages. Since \\(g\\) contains \\(\\log_2 g\\) bits of information, this means a typical message would contain \\(\\log g = N \\log_2 M\\) bits of information.\nSuppose now that we had an estimate of the frequency \\(p_m\\) that each character \\(x_m \\in \\Sigma\\) occurs in a message. That is, in a message of length \\(N\\), we expect each character \\(x_m\\) to occur \\(N_m \\approx Np_m\\) total times, or to be more precise \\(N_m = Np_m + O\\big(\\sqrt{N}\\big)\\) since each character is a Bernoulli random variable, hence a message of length \\(N\\) is a binomial random variable. In this case, the number of typical messages is just the number of ways of placing \\(N\\) random characters into \\(M\\) bins of sizes \\(N_1, N_2, \\cdots, N_M\\), which is \\[\ng = \\frac{N!}{\\prod_{m=1}^M N_m!}.\n\\] The total number of bits contained in a typical message would then be \\(\\log_2 g\\). If we assume the message length \\(N\\) is large compared to the alphabet size \\(M\\), then we can apply the Stirling approximation to each term containing a factorial. Using the fact \\(N_m = Np_m\\) and \\(\\sum N_m = N\\), we have \\[\n\\begin{align*}\n\\log_2 g &= \\log_2 N! - \\sum_{m=1}^M \\log_2 N_m! \\\\\n&\\approx \\big(N\\log_2 N - N\\big) - \\sum_{m=1}^M \\big(N_m \\log_2 N_m - N_m \\big) \\\\\n&\\approx N \\log_2 N - \\sum N_m \\log_2 N_m \\\\\n&\\approx - N \\sum_{m=1}^M p_m \\log_2 p_m.\n\\end{align*}\n\\] The term \\(-\\sum p_m \\log_2 p_m\\) is just a function of the underlying probability distribution of characters, not of the message length \\(N\\) itself. It captures our uncertainty or surprise in what message we’d receive. We call this term the information entropy or Shannon entropy. Since the choice of base for the logarithm merely adds a constant to this sum, in physics we more typically use the natural logarithm instead of the base-2 logarithm, which expresses entropy in nats instead of bits. In this form, the information entropy can be defined as \\[\n\\boxed{S \\equiv -\\sum_{m=1}^M p_m \\log p_m} \\ .\n\\] We’ve thus answered the question sought: a typical message of length \\(N\\) contains about \\(\\log_2 g \\approx NS\\) bits of information, up to an additive constant that depends on the base of logarithm. Notice that if we knew exactly which message to expect, that would mean \\(g = 1\\), which means \\(S = 0\\). Since we already know the most number of messages possible is \\(g=M^N\\), the information entropy must evidently satisfy \\[\n0 \\leq S \\leq N \\log M.\n\\] In thermodynamics, the information entropy corresponds to the mixing entropy up to a factor of Boltzmann’s constant \\(k_B\\). One implication of this is that while information entropy is dimensionless, thermodynamic entropy has units, namely units of \\(k_B\\), which is energy per degree.\nThe terms \\(I_m \\equiv -\\log p_m\\) capture the information content contained in any one particular character \\(x_m\\). If \\(p_m \\approx 0\\) then \\(I_m \\approx \\infty\\), meaning \\(x_m\\) contains an infinite number of bits of new information relative to what we already know. If \\(p_m \\approx 1\\) then \\(I_m \\approx 0\\), meaning \\(x_m\\) contains no new bits of information. We can thus also think of the entropy as the expected information content of a message, since \\[\nS = -\\sum_{m=1}^M p_m \\log p_m = -\\langle \\log p \\rangle = \\langle I \\rangle.\n\\] While information theory was built around the idea of transmitting messages, there’s nothing inherently limiting these ideas to messages alone. We can apply the concept of entropy as defined to any discrete probability distribution, where each \\(x_m\\) corresponds to some value taken on by a random variable.\nWhat about continuous distributions though? We can try to extend entropy to these as well, but we have to be careful. Since density functions needn’t be positive, the entropy will no longer in general be positive either, meaning it doesn’t make sense to think about it as a direct measure of information content. Nevertheless, we could define the information entropy of a continuous distribution as \\[\n\\boxed{S \\equiv -\\int_{\\mathbb{R}} dx \\ p(x) \\log p(x)} \\ .\n\\] From a physical perspective, a more troublesome problem with this definition is that in general \\(dx\\) will have units, which means \\(p(x)\\) will have units as well. But we can’t have a function with units inside a logarithm. The right way to deal with this will be to convert \\(dx\\) to some kind of dimensionless measure so that \\(p(x)\\) will also be dimensionless. For example, in statistical mechanics we’ll usually be looking at distributions over phase space, where the integration measure is \\(d\\Gamma \\propto d^3 x d^3 p\\). In this case, we’d need to divide by a constant that has units of \\([xp]\\). We’ll see from quantum mechanics that the correct constant is in fact Planck’s constant \\(h\\). That is, the right integration measure is \\[\nd\\Gamma = \\frac{d^3 x d^3 p}{h^3}.\n\\] ### The Principle of Maximum Entropy\nWe can use the idea of information entropy to finally answer the question regarding what the correct way is to define probabilities subjectively or theoretically. The idea is to use the principle of maximum entropy.\nPrinciple of Maximum Entropy: The unbiased assignment of probability is the one that maximizes the information entropy subject to known constraints. More formally, assign a probability distribution \\(p(x)\\) that maximizes the constrained problem \\[\n\\boxed{\n\\begin{align*}\n&\\max_{p(x)} S[p(x)] =  \\max_{p(x)} \\bigg(- \\sum_{x \\in \\mathcal{S}} p(x) \\log p(x) \\bigg) \\\\\n&\\text{subject to} \\ \\sum_{x \\in \\mathcal{S}} p(x) = 1 \\ \\text{and} \\ g(x) = 0 \\\\\n\\end{align*}\n} \\ .\n\\] where \\(g(x) = 0\\) is any set of known constraints on the probability distribution. The first constraint that probabilities sum to one will always be there so that \\(p(x)\\) yields a valid probability function.\nThis is in essence just a generalization of the principle of indifference. If we don’t have any information to go on, we should assume all outcomes have equal probability. The principle of maximum entropy extends this idea to general distributions where we might know some information, like what its mean or variance is, or what range it’s bounded to.\nUsing Lagrange multipliers, the principle of maximum entropy is equivalent to maximizing the Lagrange multiplier function \\[\nL(p(x),\\lambda) \\equiv - \\sum_{x \\in \\mathcal{S}} p(x) \\log p(x) - \\alpha \\bigg(\\sum_{x \\in \\mathcal{S}} p(x) - 1\\bigg) - \\beta \\cdot g(x).\n\\] subject to \\(p(x)\\) and \\(\\alpha\\) and \\(\\beta\\).\nExample: Let’s formally prove the principle of indifference using the principle of maximum entropy. That is, in the absence of no known information, the unbiased probabilities to assign are the ones where each outcome has an equal probability to occur. Suppose the random variable is discrete with \\(n\\) outcomes of probabilities \\(p_1, p_2, \\cdots, p_n\\). In this case, the problem to solve is \\[\n\\begin{align*}\n&\\max_{p} \\bigg(- \\sum_{i=1}^n p_i \\log p_i \\bigg) \\\\\n&\\text{subject to} \\ \\sum_{i=1}^n p_i = 1.\n\\end{align*}\n\\] This is equivalent to maximizing the Lagrange multiplier function \\[\nL(p,\\alpha) \\equiv - \\sum_{i=1}^n p_i \\log p_i - \\alpha \\bigg(\\sum_{i=1}^n p_i - 1\\bigg).\n\\] Differentiating with respect to each \\(p_j\\) and \\(\\alpha\\) and setting the derivatives to zero, we have \\[\n\\begin{align*}\n\\frac{\\partial L}{\\partial p_j} &= -\\log p_j - 1 - \\alpha \\equiv 0\\\\\n\\frac{\\partial L}{\\partial \\alpha} &= \\sum_{i=1}^n p_i - 1 \\equiv 0\\\\\n\\end{align*}\n\\] Solving this system of equations implies that \\[\n\\sum_{j=1}^n p_j = \\sum_{j=1}^n e^{-(1+\\alpha)} = 1 \\quad \\Longrightarrow \\quad e^{1+\\alpha} = n.\n\\] Thus, the maximum entropy probabilities are just \\(p_j = \\frac{1}{n}\\) for all \\(j\\), as expected.\nThe same method can be used in the continuous case as well by replacing the sums \\(\\sum_{i=1}^n p_i\\) by integrals \\(\\int_a^b dx \\ p(x)\\). The main subtlety to be aware of in the continuous case is that we’re no longer maximizing a function of \\(n\\) probabilities, but a functional of the form \\(S[p(x)]\\) over all possible functions \\(p(x)\\). These can be solved for \\(p(x)\\) by finding the choice of \\(p(x)\\) that extremizes the functional \\(S[p(x)]\\). In that case, the maximum entropy probabilities will turn out to be \\(p(x) = \\frac{1}{b-a}\\) as expected.\nExample: Here’s an interesting example involving continuous distributions. Suppose we knew that a random variable \\(x\\) on the real line had a given mean \\(\\mu\\) and variance \\(\\sigma^2\\). What is the maximum entropy distribution \\(p(x)\\) such that these two cumulants are known? The problem to solve is now \\[\n\\begin{align*}\n&\\max_{p(x)} \\bigg(- \\int_\\mathbb{R} dx \\ p(x) \\log p(x) \\bigg) \\\\\n&\\text{subject to} \\ \\int_\\mathbb{R} dx \\ p(x) = 1, \\\\\n&\\text{and} \\int_\\mathbb{R} dx \\ x p(x) = \\mu, \\ \\ \\int_\\mathbb{R} dx \\ x^2 p(x) - \\mu^2 = \\sigma^2. \\\\\n\\end{align*}\n\\] The Lagrange multiplier function is then \\[\n\\begin{align*}\nL(p(x),\\alpha,\\beta,\\gamma) = -&\\bigg(\\int_\\mathbb{R} dx \\ p(x) \\log p(x) \\bigg) - \\alpha\\bigg(\\int_\\mathbb{R} dx \\ p(x) - 1\\bigg) \\\\\n- \\beta&\\bigg(\\int_\\mathbb{R} dx \\ x p(x) - \\mu\\bigg) - \\gamma \\bigg(\\int_\\mathbb{R} dx \\ x^2 p(x) - \\mu^2 - \\sigma^2\\bigg).\n\\end{align*}\n\\] To maximize this function, consider a functional perturbation \\(p + \\delta p\\). Notice every term is linear in \\(p\\) except the first term, which is \\(p \\log p\\). In that term, we have \\[\n\\begin{align*}\n(p + \\delta p) \\log (p + \\delta p) &= (p + \\delta p) \\log(1 + \\frac{\\delta p}{p}) \\log p \\\\\n&= (p + \\delta p) \\bigg(1 + \\frac{\\delta p}{p}\\bigg) \\log p \\\\\n&= p \\log p + \\delta p (\\log p + 1) + O(\\delta p^2).\n\\end{align*}\n\\] If we ignore terms of order higher than \\(\\delta p\\), then solving for \\(\\delta L\\) and setting it to zero gives \\[\n\\begin{align*}\n\\delta L &= L(p + \\delta p,\\alpha,\\beta,\\gamma) - L(p,\\alpha,\\beta,\\gamma) \\\\\n&= -\\int_\\mathbb{R} dx \\delta p \\ \\bigg[\\log p + 1 + \\alpha + \\beta x + \\gamma(x^2 - 2\\mu x) \\bigg] \\equiv 0.\n\\end{align*}\n\\] Since this must be true for any perturbation \\(\\delta p\\), the integrand must be zero, \\[\n\\log p + 1 + \\alpha + \\beta x + \\gamma(x^2 - 2\\mu x) = 0.\n\\] Solving then for \\(p(x)\\) we have \\[\np(x) = \\exp\\big(-1 - \\alpha - \\beta x - \\gamma(x^2 - 2\\mu x)\\big).\n\\] The exponent is just a quadratic function of \\(x\\), hence we can rewrite \\(p(x)\\) in terms of new constants as \\[\np(x) = \\mathcal{N} \\exp\\bigg(-\\frac{(x-a\\mu)^2}{2b\\sigma^2}\\bigg).\n\\] Since this has the form of a Gaussian, integrating over the real line gives a normalization constant of the form \\(\\mathcal{N} = (2\\pi b \\sigma^2)^{-1/2}\\). Similarly, by shift invariance, integrating the mean function requires that \\(a=1\\). Last, the variance constraint requires that \\(b=1\\). We’ve thus shown that the continuous probability distribution whose mean and variance are known must be a Gaussian distribution.\nExample: Let’s do one more example that’s very relevant to statistical mechanics. Suppose we have a discrete random variable \\(x\\) that can take on a possibly countably infinite number of values. Suppose we know that some positive function \\(E(x) \\geq 0\\) of \\(x\\) has expectation \\(\\langle E(x) \\rangle = E\\). Then the problem to solve is \\[\n\\begin{align*}\n&\\max_p \\bigg(- \\sum_{i=0}^\\infty p_i \\log p_i \\bigg) \\\\\n&\\text{subject to} \\ \\sum_{i=0}^\\infty p_i = 1, \\ \\text{and} \\ \\sum_{i=0}^\\infty p_i E_i = E. \\\\\n\\end{align*}\n\\] The Lagrange multiplier function is then given by \\[\nL(p,\\alpha) \\equiv - \\sum_{i=0}^\\infty p_i \\log p_i - \\alpha \\bigg(\\sum_{i=0}^\\infty p_i - 1\\bigg) - \\beta \\bigg(\\sum_{i=0}^\\infty p_i E_i - E\\bigg).\n\\] Differentiating with respect to each \\(p_j\\), \\(\\alpha\\), and \\(\\beta\\) and setting all the derivatives to zero, we have \\[\n\\begin{align*}\n\\frac{\\partial L}{\\partial p_j} &= -\\log p_j - 1 - \\alpha - \\beta E_i \\equiv 0, \\\\\n\\frac{\\partial L}{\\partial \\alpha} &= \\sum_{i=0}^\\infty p_i - 1 \\equiv 0, \\\\\n\\frac{\\partial L}{\\partial \\alpha} &= \\sum_{i=0}^\\infty p_i E_i - E \\equiv 0. \\\\\n\\end{align*}\n\\] Together, these imply that the probabilities must have the form \\[\np_j = e^{-(1+\\alpha)} e^{-\\beta E_j}.\n\\] Again, the factor \\(e^{-(1+\\alpha)}\\) is just a normalization constant. If we redefine it to be \\(\\frac{1}{Z}\\), then we finally have \\[\np_j = \\frac{1}{Z} e^{-\\beta E_j},\n\\] where by normalization \\(Z\\) must satisfy the relation \\[\nZ = \\sum_{i=0}^\\infty e^{-\\beta E_i}.\n\\] More generally, we could imagine \\(\\mathbf{E}(x)\\) being a vector-valued function, in which case the same results apply just be replacing the scalars \\(\\beta E_i\\) with vectors \\(\\boldsymbol{\\beta} \\cdot \\mathbf{E}_i\\). We’ll see later that the normalization constant \\(Z\\) is very important to statistical mechanics. It’s called the partition function. In that case, \\(E_j\\) represents the energy of the system in the \\(j\\)th state and \\(E\\) represents the average internal energy of the system, i.e. the energy that satisfies the first law of thermodynamics."
  },
  {
    "objectID": "statistical-mechanics/kinetic-theory.html#hamiltonian-mechanics",
    "href": "statistical-mechanics/kinetic-theory.html#hamiltonian-mechanics",
    "title": "Kinetic Theory",
    "section": "Hamiltonian Mechanics",
    "text": "Hamiltonian Mechanics\nTo start, we’ll review the classical mechanics of particles via the Hamiltonian formulation.\n\nHamilton’s Equations\nConsider a system with \\(3N\\) degrees of freedom. For simplicity, we’ll assume the generalized coordinates are just the ordinary position vectors \\(\\mathbf{x}_i\\) and ordinary momentum vectors \\(\\mathbf{p}_i\\) for a given particle \\(i\\). In that case, \\(N\\) represents the number of particles in the system. Let \\(\\mathbf{x} \\equiv (\\mathbf{x}_1,\\mathbf{x}_2,\\cdots,\\mathbf{x}_N)\\) and \\(\\mathbf{p} \\equiv (\\mathbf{p}_1,\\mathbf{p}_2,\\cdots,\\mathbf{p}_N)\\). The \\(6N\\)-dimensional vector \\((\\mathbf{x}, \\mathbf{p})\\) characterizes the state of the system. The state is also a point in an abstract \\(6N\\)-dimensional space, called the phase space of the system.\nAssuming the system is conservative, the dynamics of the system are completely determined by the joint Hamiltonian \\(H = H(\\mathbf{x}, \\mathbf{p})\\). We can then in principle solve for the microscopic equations of motion \\(\\big(\\mathbf{x}(t), \\mathbf{p}(t)\\big)\\) by solving Hamilton’s equations, a system of \\(6N\\) differential equations given by \\[\n\\boxed{\\mathbf{\\dot x} = \\frac{\\partial H}{\\partial \\mathbf{p}}, \\quad \\mathbf{\\dot p} = -\\frac{\\partial H}{\\partial \\mathbf{x}}} \\ .\n\\] Said differently, the Hamiltonian induces a flow on the phase space, with the flow described by Hamilton’s equations. Each flow represents the time evolution of a particular state, determined by the initial conditions.\nIt’s important to note that the microscopic equations of motion are time reversal invariant. That is, if the momenta are reversed, \\(\\mathbf{p} \\rightarrow -\\mathbf{p}\\), then the trajectories also reverse, \\(\\mathbf{x}(t) \\rightarrow \\mathbf{x}(-t)\\). This is because the Hamiltonian \\(H(\\mathbf{x},\\mathbf{p})\\) is invariant to time reversal transformations \\((\\mathbf{x}, \\mathbf{p}) \\rightarrow (\\mathbf{x}, -\\mathbf{p})\\). Why is this important to note? Because thermodynamics is not time reversal invariant. Once an isolated system is in equilibrium it will stay in equilibrium. We thus need to figure out how this time reversal invariance property gets lost in the thermodynamic limit.\n\n\nPoisson Brackets\nFor two functions \\(F(\\mathbf{x}, \\mathbf{p})\\) and \\(G(\\mathbf{x}, \\mathbf{p})\\) defined on phase space, define their Poisson bracket by \\[\n\\boxed{\\{F, G\\} \\equiv \\frac{\\partial F}{\\partial \\mathbf{x}} \\cdot \\frac{\\partial G}{\\partial \\mathbf{p}} - \\frac{\\partial G}{\\partial \\mathbf{x}} \\cdot \\frac{\\partial F}{\\partial \\mathbf{p}}} \\ .\n\\] It’s easy to show that the Poisson bracket is anti-symmetric, i.e. \\(\\{F,G\\} = -\\{G,F\\}\\). It’s also bilinear, \\[\n\\begin{align*}\n\\{aF+bG,J\\} &= a\\{F,J\\} + b\\{G,J\\}, \\\\\n\\{F, aG + bJ\\} &= a\\{F,G\\} + b\\{F,J\\}. \\\\\n\\end{align*}\n\\] The Poisson bracket also satisfies the product rule, \\[\n\\frac{d}{dt} \\{F,G\\} = \\bigg\\{\\frac{dF}{dt}, G\\bigg\\} + \\bigg\\{F, \\frac{dG}{dt}\\bigg\\}.\n\\] The total time derivative of any function \\(F(\\mathbf{x}, \\mathbf{p})\\) is given by its Poisson bracket with the Hamiltonian, \\[\n\\frac{dF}{dt} = \\{F, H\\}.\n\\] Evidently, if \\(F\\) is a conserved quantity, its Poisson bracket with \\(H\\) must vanish, i.e. \\(\\{F,H\\} = 0\\). By Taylor expanding, it’s also possible to show that the Poisson bracket of any function of \\(F\\) with \\(H\\) must vanish, i.e. that \\(\\{f(F), H\\} = 0\\) for any analytic function \\(f(F)\\).\nOne result that we’ll frequently use is that the integral of a Poisson bracket \\(\\{F,H\\}\\) vanishes when integrated over an unbounded region of phase space (which is almost always the case). Denote the \\(3N\\)-dimensional phase space volume element by \\(d\\Gamma \\equiv d^{3N} \\mathbf{x} \\ d^{3N} \\mathbf{p}\\). Then we have \\[\n\\int d\\Gamma \\ \\{F,H\\} = 0.\n\\] To see why this is true we just use the definition of the Poisson bracket and integration by parts, \\[\n\\begin{align*}\n\\int d\\Gamma \\ \\{F,H\\} &= \\int d\\Gamma \\ \\bigg(\\frac{\\partial F}{\\partial \\mathbf{x}} \\cdot \\frac{\\partial H}{\\partial \\mathbf{p}} - \\frac{\\partial H}{\\partial \\mathbf{x}} \\cdot \\frac{\\partial F}{\\partial \\mathbf{p}}\\bigg) \\\\\n&= \\int d\\Gamma \\ \\frac{\\partial H}{\\partial \\mathbf{p}} \\cdot \\frac{\\partial F}{\\partial \\mathbf{x}} - \\int d\\Gamma \\ \\frac{\\partial H}{\\partial \\mathbf{x}} \\cdot \\frac{\\partial F}{\\partial \\mathbf{p}} \\\\\n&= -\\int d\\Gamma \\ \\frac{\\partial^2 H}{\\partial \\mathbf{x}\\partial \\mathbf{p}} F + \\int d\\Gamma \\ \\frac{\\partial^2 H}{\\partial \\mathbf{p}\\partial \\mathbf{x}} F + (\\text{boundary terms}). \\\\\n\\end{align*}\n\\] Since second partials commute, the two integrals cancel each other. Since \\(H\\) is a Hamiltonian describing a physical system, it must go to zero as \\(\\mathbf{p}\\) or \\(\\mathbf{x}\\) go to infinity, which means the boundary terms must also vanish as well. Note that for this to be true it’s also important that both \\(F\\) and \\(H\\) depend on all of the integration variables. If not then some of the terms can’t be exchanged. For example, if \\(F\\) is constant, we can pull the entire integral inside the Poisson bracket to get \\[\n\\int d\\Gamma \\ \\{F,H\\} = \\bigg\\{F, \\int d\\Gamma \\ H\\bigg\\} \\neq 0.\n\\]"
  },
  {
    "objectID": "statistical-mechanics/kinetic-theory.html#liouvilles-equation",
    "href": "statistical-mechanics/kinetic-theory.html#liouvilles-equation",
    "title": "Kinetic Theory",
    "section": "Liouville’s Equation",
    "text": "Liouville’s Equation\nThe Hamiltonian formulation of classical mechanics implies an important result called Liouville’s theorem, a statement about how phase space densities evolve in time. From this theorem we can derived Liouville’s equation, our starting point for kinetic theory.\n\nLiouville’s Theorem\nSuppose a system of \\(N\\) particles has some given thermodynamic macrostate \\(M\\), which will in general be a function of the thermodynamic variables \\(T, V, N\\), etc. The system will also have some microstate \\(\\mu\\) that’s a function of all the positions \\(\\mathbf{x}\\) and momenta \\(\\mathbf{p}\\). In general, there will be many possible microstates \\(\\mu\\) for any given macrostate \\(M\\). Each microstate corresponds to some point in the phase space, which evolves in time. Define a Gibbs ensemble as the set of all possible microstates \\(\\mu\\) that correspond to a given macrostate \\(M\\). An ensemble represents a cloud of points in phase space, with the cloud of points each evolving in time. Suppose there are \\(\\mathcal{N}\\) points in the ensemble. For a given infinitesimal phase space volume element \\(d\\Gamma\\), we can define an ensemble density \\(\\rho\\) as the limiting ratio of ensemble points inside of a cube \\(d\\Gamma\\) with the total number of ensemble points \\(\\mathcal{N}\\), \\[\n\\boxed{\\rho(\\mathbf{x}, \\mathbf{p}, t) d\\Gamma \\equiv \\lim_{\\mathcal{N} \\rightarrow \\infty} \\frac{d\\mathcal{N}}{\\mathcal{N}}} \\ .\n\\] The phase space density defines a proper probability density on the phase space since \\(\\rho \\geq 0\\) and \\[\n\\int d\\Gamma \\ \\rho = \\int \\frac{d\\mathcal{N}}{\\mathcal{N}} = \\frac{\\mathcal{N}}{\\mathcal{N}} = 1.\n\\] We can define an ensemble average for any function \\(F(\\mathbf{x}, \\mathbf{p},t)\\) on the phase space, \\[\n\\boxed{\\langle F(\\mathbf{x}, \\mathbf{p},t) \\rangle \\equiv \\int d\\Gamma \\ \\rho(\\mathbf{x}, \\mathbf{p},t) F(\\mathbf{x}, \\mathbf{p},t)} \\ .\n\\] Liouville’s Theorem: Phase space volumes are preserved under time evolution. That is, for any two times \\(t\\) and \\(t'\\), the differential volume element \\(d\\Gamma\\) must be the same, \\[\nd\\Gamma(\\mathbf{x}', \\mathbf{p}',t') = d\\Gamma(\\mathbf{x}, \\mathbf{p},t).\n\\] Proof: Let \\(d\\Gamma \\equiv d\\Gamma(\\mathbf{x}, \\mathbf{p},t)\\) and \\(d\\Gamma' \\equiv d\\Gamma(\\mathbf{x}', \\mathbf{p}',t+dt)\\), where \\(dt\\) is infinitesimal. Then we must have \\[\n\\begin{align*}\n\\mathbf{x}' &= \\mathbf{x} + \\mathbf{\\dot x} dt, \\\\\n\\mathbf{p}' &= \\mathbf{p} + \\mathbf{\\dot p} dt. \\\\\n\\end{align*}\n\\] The goal is to show that \\(d\\Gamma = d^{3N} \\mathbf{x} \\ d^{3N} \\mathbf{p}\\) is the same as \\(d\\Gamma' = d^{3N} \\mathbf{x}' \\ d^{3N} \\mathbf{p}'\\). Let’s focus on a particular component \\(\\alpha\\) and show \\(dx_\\alpha dp_\\alpha = dx'_{\\alpha} dp'_{\\alpha}\\). Taking the differentials of \\(x'_\\alpha\\) and \\(p'_\\alpha\\), we have \\[\n\\begin{align*}\ndx'_\\alpha &= dx_\\alpha + \\frac{\\partial \\dot x_\\alpha}{\\partial x_\\alpha} dt, \\\\\ndp'_\\alpha &= dp_\\alpha + \\frac{\\partial \\dot p_\\alpha}{\\partial p_\\alpha} dt. \\\\\n\\end{align*}\n\\] Then evidently \\[\ndx'_\\alpha dp'_\\alpha = dx_\\alpha dp_\\alpha \\bigg[1 + \\bigg(\\frac{\\partial \\dot x_\\alpha}{\\partial x_\\alpha} + \\frac{\\partial \\dot p_\\alpha}{\\partial p_\\alpha} \\bigg)  \\bigg].\n\\] Using Hamilton’s equations, however, we have that \\[\n\\frac{\\partial \\dot x_\\alpha}{\\partial x_\\alpha} + \\frac{\\partial \\dot p_\\alpha}{\\partial p_\\alpha} = \\frac{\\partial}{\\partial x_\\alpha} \\frac{\\partial H}{\\partial p_\\alpha} - \\frac{\\partial}{\\partial p_\\alpha} \\frac{\\partial H}{\\partial x_\\alpha} = 0.\n\\] Thus, to first order we have \\(dx_\\alpha dp_\\alpha = dx'_{\\alpha} dp'_{\\alpha}\\) for each \\(\\alpha\\). Multiplying them all together, we finally have \\(d\\Gamma' = d\\Gamma\\), as desired. \\(\\text{Q.E.D.}\\)\n\n\nDerivation\nLiouville’s theorem as stated is equivalent to saying that the phase space density is an incompressible fluid. That is, the flow velocity on phase space has zero divergence. Indeed, we have \\[\n\\nabla_{\\mathbf{x}, \\mathbf{p}} \\cdot (\\mathbf{\\dot x}, \\mathbf{\\dot p}) = \\frac{\\partial \\mathbf{\\dot x}}{\\partial \\mathbf{x}} + \\frac{\\partial \\mathbf{\\dot p}}{\\partial \\mathbf{p}} = \\frac{\\partial}{\\partial \\mathbf{x}} \\frac{\\partial H}{\\partial \\mathbf{p}} - \\frac{\\partial}{\\partial \\mathbf{p}} \\frac{\\partial H}{\\partial \\mathbf{x}} = 0.\n\\] Define the stream derivative or the material derivative of a function \\(f(\\mathbf{x}, \\mathbf{p},t)\\) as the total time derivative, \\[\n\\boxed{\\frac{Df}{Dt} \\equiv \\frac{df}{dt}} \\ .\n\\] The stream derivative represents how any given flow of \\(f\\) changes in time. If you follow any given set of points in time, they’ll evolve according to the stream derivative. This contrasts with the point derivative \\(\\frac{\\partial f}{\\partial t}\\), which represents how \\(f\\) changes at a fixed point \\(\\mathbf{x},\\mathbf{p}\\) in time.\nThe stream derivative of the phase space density can evidently be related to the point derivative by \\[\n\\begin{align*}\n\\frac{D\\rho}{Dt} &= (\\mathbf{\\dot x}, \\mathbf{\\dot p}) \\cdot \\nabla_{\\mathbf{x}, \\mathbf{p}} \\ \\rho \\ + \\frac{\\partial \\rho}{\\partial t} \\\\\n&= \\mathbf{\\dot x} \\cdot \\frac{\\partial \\rho}{\\partial \\mathbf{x}} + \\mathbf{\\dot p} \\cdot\\frac{\\partial \\rho}{\\partial \\mathbf{p}} + \\frac{\\partial \\rho}{\\partial t} \\\\\n&= \\frac{\\partial \\rho}{\\partial \\mathbf{x}} \\cdot \\frac{\\partial H}{\\partial \\mathbf{p}} - \\frac{\\partial \\rho}{\\partial \\mathbf{p}} \\cdot \\frac{\\partial H}{\\partial \\mathbf{x}} \\\\\n&= \\{\\rho, H\\} + \\frac{\\partial \\rho}{\\partial t}.\n\\end{align*}\n\\] Liouville’s theorem implies that the stream derivative of \\(\\rho\\) must vanish. Since \\(d\\Gamma' = d\\Gamma\\), we must have \\(\\rho' d\\Gamma' = \\rho d\\Gamma\\), or \\((\\rho'-\\rho) d\\Gamma = 0\\), which implies \\(\\rho'=\\rho\\). We’ve thus derived Liouville’s equation, which says how the density at any given point in phase space evolves in time, \\[\n\\boxed{\\frac{\\partial \\rho}{\\partial t} = -\\{\\rho, H\\} = \\{H,\\rho\\}} \\ .\n\\] For convenience, it’s also common to define a Liouville operator \\(\\mathcal{L}\\) by \\[\n\\boxed{\\mathcal{L}[\\rho] \\equiv \\{\\rho, H\\} + \\frac{\\partial \\rho}{\\partial t}} \\ .\n\\] In this language, Liouville’s equation can also be written as \\(\\mathcal{L}[\\rho] = 0\\).\nWe can use Liouville’s equation to find the time derivative of an ensemble average. If \\(F(\\mathbf{x},\\mathbf{p})\\) is some time-independent function on phase space. Using integration by parts, we have \\[\n\\frac{d}{dt} \\langle F \\rangle = \\int d\\Gamma \\ F \\frac{\\partial \\rho}{\\partial t} = -\\int d\\Gamma \\ F \\ \\{\\rho, H\\} = \\int d\\Gamma \\ \\rho \\ \\{F, H\\} = \\bigg\\langle \\frac{dF}{dt} \\bigg\\rangle.\n\\] That is, the time derivative of an ensemble average is the ensemble average of the time derivative.\n\n\nEquilibrium Conditions\nWhile all this is nice, our entire purpose is to figure out what happens at or near equilibrium. At equilibrium, the density can’t depend explicitly on time, i.e. \\(\\rho_{eq} = \\rho(\\mathbf{x}, \\mathbf{p})\\). This evidently implies \\[\n\\frac{\\partial \\rho_{eq}}{\\partial t} = -\\{\\rho_{eq}, H\\} = 0.\n\\] A sufficient condition for \\(\\{\\rho_{eq}, H\\}\\) to vanish is that \\(\\rho_{eq}\\) only be an explicit function of the conserved quantities in the system, since conserved quantities all have vanishing Poisson bracket with \\(H\\). This is called the basic assumption of statistical mechanics. If only energy is conserved, which is the typical case, we’d have \\[\n\\rho_{eq} = \\rho(H(\\mathbf{x}, \\mathbf{p})).\n\\] Recall that this requires the Poisson bracket to vanish since we can expand \\(\\rho\\) in powers of \\(H\\). The two most important equilibrium densities we’ll see in statistical mechanics are the microcanonical ensemble \\(\\rho_{eq} = \\delta(H(\\mathbf{x}, \\mathbf{p})-E)\\), and the canonical ensemble \\(\\rho_{eq} \\propto e^{-\\beta H(\\mathbf{x}, \\mathbf{p})}\\).\nNote that we still haven’t shown that it’s even possible that \\(\\rho \\rightarrow \\rho_{eq}\\) as \\(t \\rightarrow \\infty\\). This must happen for the basic assumption of statistical mechanics to be true. However, convergence to a stationary distribution contradicts time reversal symmetry, which \\(\\rho\\) itself must in principle satisfy. In fact, \\(\\rho \\nrightarrow \\rho_{eq}\\) exactly since such a process is irreversible. In principle, if we could follow every point in the ensemble exactly, we could trace the density both forward and backward in time. In practice, however, we can’t do this, meaning we lose information over time. Only in a coarse-grained sense will it be true \\(\\rho \\rightarrow \\rho_{eq}\\).\nTALK ABOUT ERGODICITY HERE"
  },
  {
    "objectID": "statistical-mechanics/kinetic-theory.html#the-bbgky-hierarchy",
    "href": "statistical-mechanics/kinetic-theory.html#the-bbgky-hierarchy",
    "title": "Kinetic Theory",
    "section": "The BBGKY Hierarchy",
    "text": "The BBGKY Hierarchy\nThe full phase space density of all \\(N\\) particles contains far more information than we need for thermodynamic purposes. In fact, we can often get away with looking at densities of a small number of particles in the background of all the other particles. We can derive a recursive expression for these densities that will be useful for making the approximations that will lead us into thermodynamics.\n\nParticle Densities\nDefine the (un-normalized) density of a single particle as the expected number of particles \\(f_1\\) that occur at some \\(\\mathbf{x},\\mathbf{p},t\\), i.e. \\[\nf_1(\\mathbf{x}, \\mathbf{p},t) \\equiv \\bigg\\langle \\sum_{i=1}^N \\delta^3(\\mathbf{x}_i-\\mathbf{x}) \\delta^3(\\mathbf{p}_i-\\mathbf{p}) \\bigg\\rangle.\n\\] Assuming each particle is identical, we can simplify the right-hand side by noting that the expected value of \\(N\\) identical particles is just \\(N\\) times the expectation of a single particle, \\[\n\\begin{align*}\nf_1(\\mathbf{x}, \\mathbf{p},t) &= N \\big\\langle \\delta^3(\\mathbf{x}_1-\\mathbf{x}) \\delta^3(\\mathbf{p}_1-\\mathbf{p}) \\big\\rangle \\\\\n&= N \\int d^3 \\mathbf{x}_1 d^3 \\mathbf{p}_1 \\ \\rho(\\mathbf{x}_1=\\mathbf{x}, \\mathbf{x}_2, \\cdots, \\mathbf{x}_N, \\mathbf{p}_1=\\mathbf{p}, \\mathbf{p}_2, \\cdots, \\mathbf{p}_N,t) \\\\\n&= N \\rho_1(\\mathbf{x}, \\mathbf{p}, t),\n\\end{align*}\n\\] where \\(\\rho_1(\\mathbf{x}, \\mathbf{p}, t)\\) is just the one-particle marginal PDF of the full density \\(\\rho\\). As expected, the expected number of particles at a point is just \\(N\\) times the normalized one-particle density. We can similarly ask about the expected number of tuples of particles. The density \\(f_s\\) of \\(s\\) particles occurring at some given set of \\(s\\) phase space points at some time \\(t\\) is given by \\[\n\\boxed{f_s(\\mathbf{x}_1, \\cdots, \\mathbf{x}_s,\\mathbf{p}_1, \\cdots, \\mathbf{p}_s,t) \\equiv \\frac{N!}{(N-s)!} \\rho_s(\\mathbf{x}_1, \\cdots, \\mathbf{x}_s,\\mathbf{p}_1, \\cdots, \\mathbf{p}_s,t)} \\ .\n\\] Clearly, \\(f_N\\) is just the un-normalized full density of finding all \\(N\\) particles at their given points, which is \\[\nf_N(\\mathbf{x}_1, \\cdots, \\mathbf{x}_N,\\mathbf{p}_1, \\cdots, \\mathbf{p}_N,t) = N! \\ \\rho(\\mathbf{x}_1, \\cdots, \\mathbf{x}_N,\\mathbf{p}_1, \\cdots, \\mathbf{p}_N,t).\n\\]\n\n\nDerivation\nWhat we’d like to try to do is to find a way of expressing \\(f_N\\) as a hierarchy of lower-particle densities. If we can get that then we can start approximating the full density using the much simpler one or two particle densities. This hierarchy of densities is called the BBGKY Hierarchy, which we’ll now derive.\nTo do that we need to make an assumption about the functional form of the full Hamiltonian \\(H\\). We’ll assume that it’s composed of the kinetic energy for each particle, where each particle has the same mass \\(m\\), some external potential energy \\(V\\) acting on each particle (e.g. the force resulting from the walls of the box of a container), and some interaction potential energy \\(\\nu\\) between particles, which we’ll approximate as being some central potential between all pairs of distinct particles (an adequate approximate for a weakly interacting gas). All together, we thus have \\[\nH = \\sum_{i=1}^N \\bigg(\\frac{\\mathbf{p}_i^2}{2m} + V(\\mathbf{x}_i)  + \\sum_{j < i} \\nu\\big(|\\mathbf{x}_i-\\mathbf{x}_j|\\big)\\bigg).\n\\] We need to figure out the time evolution of each \\(s\\)-particle density \\(f_s\\). To do that it’s convenient to split the full Hamiltonian up into three pieces: One piece \\(H_s\\) that only involves interactions between the \\(s\\) particles themselves. One piece \\(H_{N-s}\\) that only involves interactions between the remaining \\(N-s\\) particles. And finally one piece \\(H'\\) that completely specifies the interactions between the \\(s\\) particles with the other \\(N-s\\) particles. We can then write \\[\nH = H_s + H_{N-s} + H'.\n\\] The first two terms are just the full Hamiltonian, but with \\(i\\) running from \\(1\\) to \\(s\\) or \\(s+1\\) to \\(N\\) respectively. The interaction term only involves the interaction potential energies between the two sets, \\[\nH' = \\sum_{i=1}^s \\sum_{j=s+1}^N \\nu\\big(|\\mathbf{x}_i-\\mathbf{x}_j|\\big).\n\\] By Liouville’s equation, we have \\(\\frac{\\partial \\rho}{\\partial t} = -\\{\\rho, H\\}\\). But this is only true for the full density. Let’s try to see what Liouville’s equation for the marginal density \\(\\rho_s\\) might look like. Then we have \\[\n\\begin{align*}\n\\frac{\\partial \\rho_s}{\\partial t} &= \\int \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\frac{\\partial \\rho}{\\partial t} \\\\\n&= -\\int \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\ \\{\\rho, H\\} \\\\\n&= -\\int \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\ \\bigg(\\{\\rho, H_s\\} + \\{\\rho, H_{N-s}\\} + \\{\\rho, H'\\} \\bigg). \\\\\n\\end{align*}\n\\] Starting with the first term, the Hamiltonian \\(H_s\\) is constant with respect to the integration variables, so we just have \\[\n\\int \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\{\\rho, H_s\\} = \\bigg\\{ \\int \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\rho \\ , \\ H_s \\bigg\\} = \\{\\rho_s, H_s\\}.\n\\] That is, the first term is just Liouville’s equation for the first \\(s\\) particles. This makes sense, since we’re ignoring the presence of the other \\(N-s\\) particles in the dynamics of \\(\\rho_s\\) via \\(H_s\\). The second term is an integral over two functions that depend on the integration variables, which means it vanishes as usual, \\[\n\\int \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\{\\rho, H_{N-s}\\} = 0.\n\\] Finally we have the integral of the interaction terms. If we split the Poisson bracket \\(\\{\\rho, H'\\}\\) into a sum of two terms, one over the \\(s\\) variables and the other over the \\(N-s\\) variables, we have \\[\n\\{\\rho, H'\\} = \\{\\rho, H'\\}_s + \\{\\rho, H'\\}_{N-s.}\n\\] Integrating the second Poisson bracket again gives zero since it’s a bracket of the integration variables. The first bracket is more interesting. Noting that \\(H'\\) depends only on the positions, we have \\[\n\\begin{align*}\n\\int \\ \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\{\\rho, H'\\}_s &= \\int \\ \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\sum_{j=1}^s \\bigg(\\frac{\\partial \\rho}{\\partial \\mathbf{x}_j} \\cdot \\frac{\\partial H'}{\\partial \\mathbf{p}_j} - \\frac{\\partial H'}{\\partial \\mathbf{x}_j} \\cdot \\frac{\\partial \\rho}{\\partial \\mathbf{p}_j}\\bigg) \\\\\n&= - \\sum_{j=1}^s \\int \\ \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\frac{\\partial H'}{\\partial \\mathbf{x}_j} \\cdot \\frac{\\partial \\rho}{\\partial \\mathbf{p}_j} \\\\\n&= - \\sum_{j=1}^s \\int \\ \\prod_{i=s+1}^N d^3 \\mathbf{x}_i d^3 \\mathbf{p}_i \\ \\bigg(\\sum_{k=s+1}^N \\frac{\\partial \\nu}{\\partial \\mathbf{x}_j} \\bigg) \\cdot \\frac{\\partial \\rho}{\\partial \\mathbf{p}_j} \\\\\n&= (N-s) \\sum_{j=1}^s \\int \\ d^3 \\mathbf{x}_{s+1} d^3 \\mathbf{p}_{s+1} \\ \\mathbf{F}_{j,s+1} \\cdot \\frac{\\partial}{\\partial \\mathbf{p}_j} \\bigg(\\int \\ \\prod_{k=s+2}^N d^3 \\mathbf{x}_k d^3 \\mathbf{p}_k \\ \\rho \\bigg) \\\\\n&= (N-s) \\sum_{j=1}^s \\int \\ d^3 \\mathbf{x}_{s+1} d^3 \\mathbf{p}_{s+1} \\ \\mathbf{F}_{j,s+1} \\cdot \\frac{\\partial \\rho_{s+1}}{\\partial \\mathbf{p}_j}. \\\\\n\\end{align*}\n\\] The last equalities follow from the fact that the integral over the third line is just \\(N-s\\) copies of the same integral over particle \\(s+1\\), except we have to be careful to still integrate \\(\\rho\\) over the remaining terms from \\(s+2\\) to \\(N\\), which give the \\(s+1\\) particle density \\(\\rho_{s+1}\\). Since the negative gradient of a potential energy is a force, each term \\(\\mathbf{F}_{j,i} = -\\nabla_j \\nu(\\mathbf{x}_j-\\mathbf{x}_i)\\) represents the force on particle \\(j\\) due to its interaction with particle \\(s+1\\), which by Newton’s Third Law is of course the negative of the opposite force \\(\\mathbf{F}_{i,j}\\).\nWe thus finally have a modified form of Liouville’s equation for \\(\\rho_s\\), which adds a new term representing the collisions of the \\(s\\) particles with the other \\(N-s\\) particles. We have \\[\n\\frac{\\partial \\rho_s}{\\partial t} + \\{\\rho_s, H_s\\} = (N-s) \\sum_{j=1}^s \\int \\ d^3 \\mathbf{x}_{s+1} d^3 \\mathbf{p}_{s+1} \\ \\mathbf{F}_{s+1,j} \\cdot \\frac{\\partial \\rho_{s+1}}{\\partial \\mathbf{p}_j}.\n\\] It’s more common to express things in terms of the un-normalized densities \\(f_s\\) instead. Doing this eliminates the \\(N-s\\) factor in front of the collision term and replaces each \\(\\rho_s\\) with \\(f_s\\). We’ve thus finally arrived at the BBGKY Hierarchy we sought after, \\[\n\\boxed{\\frac{\\partial f_s}{\\partial t} + \\{f_s, H_s\\} = \\sum_{j=1}^s \\int \\ d^3 \\mathbf{x}_{s+1} d^3 \\mathbf{p}_{s+1} \\ \\mathbf{F}_{s+1,j} \\cdot \\frac{\\partial f_{s+1}}{\\partial \\mathbf{p}_j}} \\ .\n\\] We can think of this as a kind of ladder of densities. The one-particle density \\(f_1\\) depends via the collision integral on the two-particle density \\(f_2\\), which itself depends on \\(f_3\\), and so on until we get to the full density \\(f_N\\). It’s worth noting that the BBGKY Hierarchy is completely equivalent to Liouville’s equation for a box of \\(N\\) particles obeying the Hamiltonian specified above.\nOf most use to use will be the equations for \\(f_1\\) and \\(f_2\\). If we expand the Poisson brackets, they become \\[\n\\begin{align*}\n\\frac{\\partial f_1}{\\partial t} + &\\frac{\\mathbf{p}_1}{m} \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{x}_1} + \\mathbf{F}_1 \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{p}_1} = \\int d^3 \\mathbf{x}_2 d^3 \\mathbf{p}_2 \\ \\mathbf{F}_{2,1} \\cdot \\frac{\\partial f_2}{\\partial \\mathbf{p}_1}, \\\\\n\\frac{\\partial f_2}{\\partial t} + \\frac{\\mathbf{p}_1}{m} \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{x}_1} + &\\mathbf{F}_1 \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{p}_1} + \\frac{\\mathbf{p}_2}{m} \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{x}_2} + \\mathbf{F}_2 \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{p}_2} +\\mathbf{F}_{1,2} \\cdot \\bigg(\\frac{\\partial f_1}{\\partial \\mathbf{p}_1} - \\frac{\\partial f_1}{\\partial \\mathbf{p}_2}\\bigg) = \\\\ &\\int d^3 \\mathbf{x}_3 d^3 \\mathbf{p}_3 \\ \\bigg(\\mathbf{F}_{3,1} \\cdot \\frac{\\partial f_3}{\\partial \\mathbf{p}_1} + \\mathbf{F}_{3,2} \\cdot \\frac{\\partial f_3}{\\partial \\mathbf{p}_2}\\bigg). \\\\\n\\end{align*}\n\\]\nHere \\(\\mathbf{F}_i = -\\nabla V(\\mathbf{x}_i)\\) represents the force on particle \\(i\\) due to the external potential energy \\(V\\). The combination of derivatives in the \\(\\mathbf{F}_{1,2}\\) term is done by using Newton’s third law to get \\(\\mathbf{F}_{2,1} = -\\mathbf{F}_{1,2}\\). This is equivalent to assume that the interaction potential \\(\\nu\\) is symmetric in \\(i\\) and \\(j\\), which is true of central forces."
  },
  {
    "objectID": "statistical-mechanics/kinetic-theory.html#the-boltzmann-equation",
    "href": "statistical-mechanics/kinetic-theory.html#the-boltzmann-equation",
    "title": "Kinetic Theory",
    "section": "The Boltzmann Equation",
    "text": "The Boltzmann Equation\nThus far we really haven’t made much progress in studying the approach to equilibrium. Both Liouville’s equation and the BBGKY hierarchy are fully reversible, describing the microscopic behavior of the system. To study equilibrium we need to coarse grain things more, giving up the ability to track the exact dynamics of any given particle. We’ll start by looking at the time scales involved in the BBGKY hierarchy to get an idea of which terms in the equations are most important.\n\nCoarse-Graining\nSuppose the system involved is a box of gas whose sides are each of length of order \\(L\\). Suppose the particles in the box move with some average speed \\(v\\). Evidently then, it takes a given particle an average time \\(\\tau_{ext} \\equiv \\frac{L}{v}\\) to traverse the length of the box. This defines a time-scale for the external force terms, \\[\n\\mathbf{F}_i \\cdot \\frac{\\partial}{\\partial \\mathbf{p}_i} \\sim \\frac{v}{L} = \\frac{1}{\\tau_{ext}}.\n\\] In the box particles will collide with a certain frequency. Suppose interaction forces are felt when particles are within some distance \\(d \\ll L\\) of each other. The time that particles spend interacting in an interaction is then evidently on the order of \\(\\tau_{int} \\equiv \\frac{d}{v}\\). This defines another time-scale for the interaction force terms, \\[\n\\mathbf{F}_{i,j} \\cdot \\frac{\\partial}{\\partial \\mathbf{p}_i} \\sim \\frac{v}{d} = \\frac{1}{\\tau_{int}}.\n\\] Since \\(d \\ll L\\), we typically have \\(\\tau_{int} \\ll \\tau_{ext}\\), which means the interaction terms should typically dominate the external force terms on the left-hand side of the equations. For example, for a gas we might have \\(L \\sim 1 \\ \\text{m}\\) while \\(d \\sim 10^{-10} \\ \\text{m}\\), with \\(v \\sim 10^2 \\ \\text{m/s}\\) at room temperature. This gives time scales on the order of \\(\\tau_{ext} \\sim 10^{-3} \\ \\text{s}\\) and \\(\\tau_{int} \\sim 10^{-12} \\ \\text{s}\\).\nOn the right-hand side of these equations we have another set of time scales that say something about how long we have to wait for \\(s+1\\) particles to all come together and collide with each other. Call that time scale \\(\\tau_X\\). If we look at the ratio of \\(\\frac{f_{s+1}}{f_s}\\) as a ratio of densities, it goes roughly like the number density \\(n \\equiv \\frac{N}{d^3}\\) of particles inside a unit volume \\(d^3\\). Since the collisions only happen inside a volume \\(d^3\\), essentially the entire integral falls off to zero outside this region. Thus, we’d have \\[\n\\int \\ d^3 \\mathbf{x}_{s+1} \\ d^3 \\mathbf{p}_{s+1} \\ \\mathbf{F}_{s+1,j} \\cdot \\frac{\\partial }{\\partial \\mathbf{p}_j} \\frac{f_{s+1}}{f_s} \\sim \\frac{nd^3}{\\tau_{int}} \\equiv \\frac{1}{\\tau_X}.\n\\] This new time scale \\(\\tau_X = \\frac{1}{nvd^2}\\) is called the mean free time. It represents the typical time a particle will spend between collisions. Its relative size with respect to \\(\\tau_{col}\\) depends on \\(nd^3\\). This reflects the fact we have to wait for \\(s+1 \\sim N\\) particles to all come together and collide. The range of interactions between particles determines two limiting regions of consideration. When interactions short-range, we’d say we’re in the dilute limit where \\(nd^3 \\ll 1\\). This is the typical setting for gases, where we might have \\(nd^3 \\sim 10^{-4}\\), and so \\(\\tau_X \\sim 10^4 \\ \\tau_{int}\\). Conversely, when interactions are long-range, we’d say we’re in the dense limit where \\(nd^3 \\gg 1\\). This limit is the setting for studying plasmas, where \\(\\tau_X \\ll \\tau_{int}\\). We’ll see that the dilute limit leads us to the Boltzmann equation, and hence to thermodynamics, while the dense limit leads us to the Vlasov equation, and hence to plasma physics.\nAll the equations in the BBGKY hierarchy appear to look something like \\[\n\\text{(external interactions)} + \\text{(internal interactions)} = \\text{(collision terms)}.\n\\] In this situation the time scale comparisons look something like \\[\n\\frac{1}{\\tau_{ext}} + \\frac{1}{\\tau_{int}} = \\frac{nd^3}{\\tau_{int}}.\n\\] In the dilute limit the right-hand side is much smaller than the left-hand side, so we can evidently ignore the collision terms at least to zeroth order. This appears to be a problem though, since it says that we shouldn’t look at the background interactions at all and just treat each \\(f_s\\) as its own Liouvillian system. Fortunately, the equation for \\(f_1\\) does not look like this. In that case there are no internal interaction terms on the left-hand side, which means we can’t say much about how the left and right-hand sides compare. We have to keep both terms, which preserves the dependence of \\(f_1\\) on \\(f_2\\). But, we can treat \\(f_2\\) as having a right-hand side of zero, so we can ignore the dependence on \\(f_3\\) and higher terms and only focus on the relationship between \\(f_1\\) and \\(f_2\\).\n\n\nDerivation\nLet’s try to find a way under this approximation to combine the equations for \\(f_1\\) and \\(f_2\\) into a single equation. To do that we need to figure out how to substitute the \\(f_2\\) equation into the \\(f_1\\) equation. If we assume the collision term for \\(f_2\\) is zero, we have \\[\n\\begin{align*}\n\\frac{\\partial f_1}{\\partial t} + &\\frac{\\mathbf{p}_1}{m} \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{x}_1} + \\mathbf{F}_1 \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{p}_1} = \\int d^3 \\mathbf{x}_2 \\ d^3 \\mathbf{p}_2 \\ \\mathbf{F}_{2,1} \\cdot \\frac{\\partial f_2}{\\partial \\mathbf{p}_1}, \\\\\n\\frac{\\partial f_2}{\\partial t} + \\frac{\\mathbf{p}_1}{m} \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{x}_1} + &\\mathbf{F}_1 \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{p}_1} + \\frac{\\mathbf{p}_2}{m} \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{x}_2} + \\mathbf{F}_2 \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{p}_2} +\\mathbf{F}_{1,2} \\cdot \\bigg(\\frac{\\partial f_1}{\\partial \\mathbf{p}_1} - \\frac{\\partial f_1}{\\partial \\mathbf{p}_2}\\bigg) = 0. \\\\\n\\end{align*}\n\\] The second equation involves a density of two interaction particles. It’s convenient thus to express things in terms of center of mass and relative coordinates. Let \\(\\boldsymbol{\\mathcal{x}} \\equiv \\mathbf{x}_2 - \\mathbf{x}_1\\) represent coordinates between the two particles and \\(\\mathbf{X} \\equiv \\mathbf{x}_2 + \\mathbf{x}_1\\) represent the center of mass coordinates. Typically the center of mass coordinates will vary much slower than the relative coordinates, making the center of mass frame a good approximation of the lab frame dynamics as well. In this situation, we’d have \\(\\boldsymbol{\\mathcal{x}} = -\\mathbf{x}_1 = \\mathbf{x}_2\\). Near equilibrium we’d expect \\(\\frac{\\partial f_2}{\\partial t} \\approx 0\\). Changing variables in and writing \\(\\mathbf{F}_{2,1} = -\\mathbf{F}_{1,2}\\), the second equation becomes \\[\n\\frac{\\mathbf{p}}{m} \\cdot \\frac{\\partial f_2}{\\partial \\boldsymbol{\\mathcal{x}}} - \\mathbf{F}_{2,1} \\cdot  \\bigg(\\frac{\\partial f_2}{\\partial \\mathbf{p}_1} - \\frac{\\partial f_2}{\\partial \\mathbf{p}_2}\\bigg) \\approx 0.\n\\] Now, in the first equation, the right-hand side contains an integral over \\(d^3 \\mathbf{x}_2\\). We can evidently add any total derivative that depends on \\(\\mathbf{x}_2\\) to the integrand since its integral will vanish. Let’s thus re-write \\[\n\\int d^3 \\mathbf{x}_2 d^3 \\mathbf{p}_2 \\ \\mathbf{F}_{2,1} \\cdot \\frac{\\partial f_2}{\\partial \\mathbf{p}_1} = \\int d^3 \\mathbf{x}_2 \\ d^3 \\mathbf{p}_2 \\ \\mathbf{F}_{2,1} \\cdot \\bigg(\\frac{\\partial f_2}{\\partial \\mathbf{p}_1} - \\frac{\\partial f_2}{\\partial \\mathbf{p}_2}\\bigg).\n\\] Since \\(\\boldsymbol{\\mathcal{x}} = \\mathbf{x}_2\\) we also must have \\(d^3 \\boldsymbol{\\mathcal{x}} = d^3 \\mathbf{x}_2\\). We can now see how to substitute in the second equation into the first. We have \\[\n\\frac{\\partial f_1}{\\partial t} + \\frac{\\mathbf{p}_1}{m} \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{x}_1} + \\mathbf{F}_1 \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{p}_1} = \\int d^3 \\boldsymbol{\\mathcal{x}} \\ d^3 \\mathbf{p}_2 \\ \\frac{\\mathbf{p}_2 - \\mathbf{p}_1}{m} \\cdot \\frac{\\partial f_2}{\\partial \\boldsymbol{\\mathcal{x}}}.\n\\] Note this equation is only true when we’re near equilibrium since we neglected the time derivative \\(\\frac{\\partial f_2}{\\partial t}\\). More correctly, this equation is valid when \\(t\\) is much larger than the interaction time \\(\\tau_{int}\\).\nAt this point it’s helpful to re-express the integral in terms of collision coordinates. The collision forces are felt inside some sphere of interaction radius \\(d\\). In the center of mass frame, two particles collide along the same line. If two particles with momenta \\(\\mathbf{p}_1\\) and \\(\\mathbf{p}_2\\) come in and collide along some line, they’ll exit the collision with some new momenta \\(\\mathbf{p}'_1\\) and \\(\\mathbf{p}'_2\\) along some other line. In an elastic collision both kinetic energy and momentum must be conserved. Define a parameter \\(a \\equiv \\frac{1}{m} |\\mathbf{p}_2 - \\mathbf{p}_1|\\) to represent the relative velocity between the two particles. Perpendicular to the \\(a\\) is a plane that can be specified by another vector \\(\\mathbf{b} \\equiv (b,\\vartheta)\\). This vector has a magnitude \\(b\\), called the impact parameter, equal to the perpendicular distance between the incoming trajectories in the center of mass frame. It also has an angle \\(\\vartheta\\) representing how the incoming momenta get rotated to the outgoing momenta in the collision.\n\n\n\n\n\nNow, in collision coordinates we can write \\(d^3 \\boldsymbol{\\mathcal{x}} = d^2 \\mathbf{b} \\ da\\). It turns out that if momentum is conserved, the collision itself doesn’t depend on \\(a\\), only \\(\\mathbf{b}\\). This means the integral \\(\\int da\\) just gives \\(a\\). If we further assume the collision happens almost at a single point, we can think of the gradient of \\(f_2\\) as the instantaneous change if \\(f_2\\) before and after the collision, i.e. \\[\n\\Delta f_2 \\equiv f_2(\\mathbf{x}'_1, \\mathbf{x}'_2, \\mathbf{p}'_1, \\mathbf{p}'_2,t) - f_2(\\mathbf{x}_1, \\mathbf{x}_2, \\mathbf{p}_1, \\mathbf{p}_2,t).\n\\] Plugging all this in, we thus have \\[\n\\frac{\\partial f_1}{\\partial t} + \\frac{\\mathbf{p}_1}{m} \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{x}_1} + \\mathbf{F}_1 \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{p}_1} = \\int d^3 \\mathbf{p}_2 \\ d^2 \\mathbf{b} \\ \\frac{|\\mathbf{p}_2 - \\mathbf{p}_1|}{m} \\cdot \\Delta f_2.\n\\] The last assumption we’ll make is perhaps the most important, since it’s the coarse-graining that leads to the second law of thermodynamics: the assumption of molecular chaos. For short-range interactions the density \\(f_2\\) mixes coordinates only inside the interaction radius \\(d\\). For distances much greater than \\(d\\) it’s a good assumption to say that \\(f_2\\) is a product of two one-particle densities, i.e. that the two particles’ states are statistically independent of each other. The assumption of molecular chaos says we send \\(d \\rightarrow 0\\), meaning we lose information about the nature of collisions and just assume particles collide at a single point. In this setting, we can globally assume that \\(f_2\\) factors into a product of one-particle densities \\[\nf_2(\\mathbf{x}_1, \\mathbf{x}_2, \\mathbf{p}_1, \\mathbf{p}_2,t) = f_1(\\mathbf{x}_1, \\mathbf{p}_1, t) f_1(\\mathbf{x}_2, \\mathbf{p}_2, t).\n\\] This means we can factor \\(\\Delta f_2\\) as well to get \\[\n\\Delta f_2 = f_1(\\mathbf{x}_1, \\mathbf{p}'_1, t) f_1(\\mathbf{x}_2, \\mathbf{p}'_2, t) - f_1(\\mathbf{x}_1, \\mathbf{p}_1, t) f_1(\\mathbf{x}_2, \\mathbf{p}_2, t).\n\\] Notice how the coordinates after collision are now assumed to be the same as the coordinates before collision. This is another consequence of course-graining away \\(d \\rightarrow 0\\). Plugging this result into the previous equation for \\(f_1\\) finally gives us the Boltzmann Equation, \\[\n\\begin{align*}\n&\\frac{\\partial f_1}{\\partial t} + \\frac{\\mathbf{p}_1}{m} \\cdot \\frac{\\partial f}{\\partial \\mathbf{x}_1} + \\mathbf{F}_1 \\cdot \\frac{\\partial f_1}{\\partial \\mathbf{p}_1} = \\\\\n\\int d^3 \\mathbf{p}_2 \\ d^2 \\mathbf{b} \\ \\frac{|\\mathbf{p}_2 - \\mathbf{p}_1|}{m} &\\big[f_1(\\mathbf{x}_1, \\mathbf{p}'_1, t) f_1(\\mathbf{x}_2, \\mathbf{p}'_2, t) - f_1(\\mathbf{x}_1, \\mathbf{p}_1, t) f_1(\\mathbf{x}_2, \\mathbf{p}_2, t)\\big].\n\\end{align*}\n\\] Since we no longer need the higher particle densities we’ll from now on just write \\(f \\equiv f_1\\) and assume we’re working with one particle at a time. In this simplified notation we’ll write \\[\n\\boxed{\\frac{\\partial f}{\\partial t} + \\frac{\\mathbf{p}}{m} \\cdot \\frac{\\partial f}{\\partial \\mathbf{x}} + \\mathbf{F} \\cdot \\frac{\\partial f}{\\partial \\mathbf{p}} = \\frac{\\partial f}{\\partial t} \\bigg|_{\\text{col}}} \\ .\n\\] We can write the Boltzmann Equation even more succinctly by noting that the left-hand side is just a Liouville operator \\(L[f]\\) and defining a collision operator \\(C[f]\\) to represent the right-hand side. We then have \\[\n\\boxed{L[f] = C[f]} \\ .\n\\] Evidently, the Boltzmann equation looks like a modified Liouville equation with a non-zero right-hand side arising from a background of particles to collide with. The term \\(L[f]\\) characterizes the dynamics of particles with respect to the external forces alone, while \\(C[f]\\) characterizes the dynamics of particles due to their interactions with other particles.\n\n\nH-Theorem\nSince we’re neglecting dynamics on the scale of the interaction radius we’re losing information on the system’s microscopic dynamics. This means the Boltzmann equation also comes with a notion of increasing entropy. This result is called the H-Theorem (pronounced “Eta Theorem”).\nH-Theorem: Suppose \\(f(\\mathbf{x}, \\mathbf{p}, t)\\) satisfies the Boltzmann equation \\(L[f] = C[f]\\). Then there exists a quantity \\(\\mathrm{H}(t)\\) defined by \\[\n\\boxed{\\mathrm{H}(t) \\equiv \\int d^3 \\mathbf{x} \\ d^3 \\mathbf{p} \\ f(\\mathbf{x}, \\mathbf{p}, t) \\log f(\\mathbf{x}, \\mathbf{p}, t)}\n\\] such that \\(\\mathrm{H}(t)\\) is a decreasing function of time. That is, \\(\\frac{d\\mathrm{H}}{dt} \\leq 0\\).\nProof: We need to do is take the time derivative of \\(\\mathrm{H}(t)\\) and show its time derivative is negative. Differentiating both sides, we have \\[\n\\begin{align*}\n\\frac{d\\mathrm{H}}{dt} &= \\int d^3 \\mathbf{x} \\ d^3 \\mathbf{p} \\ \\frac{\\partial}{\\partial t}(f \\log f) \\\\\n&= \\int d^3 \\mathbf{x} \\ d^3 \\mathbf{p} \\ \\big(1 + \\log f \\big) \\frac{\\partial f}{\\partial t} \\\\\n&= \\int d^3 \\mathbf{x} \\ d^3 \\mathbf{p} \\ \\big(1 + \\log f \\big) \\big(C[f]-\\{f,H\\}\\big).\n\\end{align*}\n\\] The term involving \\(\\frac{\\partial}{\\partial t}(f \\log f)\\) just integrate to \\(N\\), a constant, and hence vanishes. Both integrals involving \\(\\{f,H\\}\\) vanish by the usual integration by parts argument. We’re thus left to calculate one term, \\[\n\\begin{align*}\n\\frac{d\\mathrm{H}}{dt} &= \\int d^3 \\mathbf{x} \\ d^3 \\mathbf{p} \\ \\log f \\ C[f] \\\\\n&= \\int d^3 \\mathbf{x}_1 \\ d^3 \\mathbf{p}_1 \\ d^3 \\mathbf{p}_2 d^2 \\mathbf{b} \\ \\frac{|\\mathbf{p}_2 - \\mathbf{p}_1|}{m} \\big[f(\\mathbf{p}'_1) f(\\mathbf{p}'_2) - f(\\mathbf{p}_1) f(\\mathbf{p}_2)\\big] \\log f(\\mathbf{p}_1).\n\\end{align*}\n\\] Here the dependence of \\(f\\) on position and time are suppressed for convenience. Now we’re going to make use of a trick. Notice the integral is symmetric in the momenta of particles \\(1\\) and \\(2\\). This means we can permute the indices and get the same answer. It also means we can average the two permutations. Though much less obvious, we can permute the primed and unprimed momenta as well since their Jacobian is \\(1\\). We can thus take the average of the primed and unprimed momenta as well. Using these facts, we have \\[\n\\begin{align*}\n\\frac{d\\Eta}{dt} &= \\int d^3 \\mathbf{x}_1 \\ d^3 \\mathbf{p}_1 d^3 \\mathbf{p}_2 d^2 \\mathbf{b} \\ \\frac{|\\mathbf{p}_2 - \\mathbf{p}_1|}{m} \\big[f(\\mathbf{p}'_1) f(\\mathbf{p}'_2) - f(\\mathbf{p}_1) f(\\mathbf{p}_2)\\big] \\log f(\\mathbf{p}_1) \\\\\n&= \\frac{1}{2}  \\int d^3 \\mathbf{x}_1 \\ d^3 \\mathbf{p}_1 d^3 \\mathbf{p}_2 d^2 \\mathbf{b} \\ \\frac{|\\mathbf{p}_2 - \\mathbf{p}_1|}{m} \\big[f(\\mathbf{p}'_1) f(\\mathbf{p}'_2) - f(\\mathbf{p}_1) f(\\mathbf{p}_2)\\big] \\log \\big(f(\\mathbf{p}_1) f(\\mathbf{p}_2)\\big) \\\\\n&= \\frac{1}{4} \\int d^3 \\mathbf{x}_1 \\ d^3 \\mathbf{p}_1 d^3 \\mathbf{p}_2 d^2 \\mathbf{b} \\ \\frac{|\\mathbf{p}_2 - \\mathbf{p}_1|}{m} \\big[f(\\mathbf{p}'_1) f(\\mathbf{p}'_2) - f(\\mathbf{p}_1) f(\\mathbf{p}_2)\\big] \\log \\bigg(\\frac{f(\\mathbf{p}_1)f(\\mathbf{p}_2)}{f(\\mathbf{p}'_1)f(\\mathbf{p}'_2)}\\bigg). \\\\\n\\end{align*}\n\\] Evidently, the integrand is proportional to a function of the form \\[\n-(f'_1 f'_2 - f_1 f_2) \\log \\bigg(\\frac{f'_1 f'_2}{f_1 f_2}\\bigg),\n\\] which is negative since the log is an increasing function of its arguments. This of course means the integral must be negative as well, i.e. \\(\\frac{d\\mathrm{H}}{dt} \\leq 0\\). \\(\\text{Q.E.D.}\\)\nThe quantity \\(\\mathrm{H}(t)\\) looks similar to the differential entropy of a continuous density function. It’s actually just a negative affine shift of the entropy of the one-particle density \\(f\\). In fact, for an \\(N\\)-particle system, we can relate the thermodynamic entropy of the system to \\(\\mathrm{H}\\) via \\(S \\equiv -k_B \\mathrm{H}\\). Thus, if \\(\\mathrm{H}\\) is a decreasing function, then \\(S\\) must be an increasing function, and vice versa.\n\n\nAside: Vlasov Equation\nWhat happens in the dense limit where \\(nd^3 \\gg 1\\)? In that case we can only say \\(\\tau_{\\text{int}} \\gg \\tau_X\\), which means we can drop the collision terms from the left-hand side of each BBGKY hierarchy. If we again assume each density \\(f_s\\) factors into a product of one-particle densities then it’ll turn out all the equations for \\(f_s\\) are equivalent, leaving a single equation to be satisfied, \\[\n\\boxed{\\frac{\\partial f}{\\partial t} + \\frac{\\mathbf{p}}{m} \\cdot \\frac{\\partial f}{\\partial \\mathbf{x}} + \\mathbf{F}_{\\text{eff}} \\cdot \\frac{\\partial f}{\\partial \\mathbf{p}} = 0} \\ ,\n\\] where \\(\\mathbf{F}_{\\text{eff}}\\) represents a kind of averaged background force on \\(f\\) given by \\[\n\\mathbf{F}_{\\text{eff}} \\equiv - \\frac{d}{d\\mathbf{x}} \\bigg(V(\\mathbf{x}) + \\int d^3\\mathbf{x}' d^3\\mathbf{p} \\ \\nu(\\mathbf{x}-\\mathbf{x}') f(\\mathbf{x}', \\mathbf{p}, t)\\bigg).\n\\] This is the Vlasov Equation. We can write the equation more succinctly by assuming an affective Hamiltonian \\(H_{\\text{eff}}\\) gives rise to the above dynamics. Then we’re back to Liouville’s equation, \\[\n\\frac{\\partial f}{\\partial t} + \\{f, H_{\\text{eff}}\\} = 0.\n\\] In this setting there’s in general no relaxation towards equilibrium. In fact, any function \\(f(\\mathbf{x},\\mathbf{p}) = g(\\mathbf{p})\\) is a valid steady state solution to the Vlasov equation. The Vlasov equation is used to characterize the behavior of plasmas. Typically when studying plasmas, one assumes the background forces are electromagnetic fields, in which case \\(\\mathbf{F}_{\\text{eff}}\\) just becomes the Lorentz force on each charged particle, \\[\n\\mathbf{F}_{\\text{eff}} = e\\mathbf{E} +  e\\frac{\\mathbf{v}}{c} \\times \\mathbf{B}.\n\\]"
  },
  {
    "objectID": "statistical-mechanics/kinetic-theory.html#equilibrium",
    "href": "statistical-mechanics/kinetic-theory.html#equilibrium",
    "title": "Kinetic Theory",
    "section": "Equilibrium",
    "text": "Equilibrium\nWe’re now in a position to find what the density \\(f\\) has to be at equilibrium. Recall that the equilibrium distribution \\(f_{eq}\\) must satisfy the property that \\[\n\\frac{\\partial}{\\partial t} f_{eq}(\\mathbf{x}, \\mathbf{p}) = 0.\n\\] Using the Boltzmann equation and the H-theorem we can figure out what \\(f_{eq}\\) must be.\n\nEquilibrium Distributions\nSuppose \\(f\\) satisfies the Boltzmann equation. Let’s see if we can try to figure out what distribution \\(f\\) must have at equilibrium. At equilibrium we said we must have \\(\\frac{\\partial f}{\\partial t} = 0\\). As we saw, this is equivalent to requiring \\(\\frac{d\\mathrm{H}}{dt} = 0\\). For that to be true over any region of phase space as \\(t \\rightarrow \\infty\\), we must have the steady state requirement that \\[\n\\log \\bigg(\\frac{f(\\mathbf{x},\\mathbf{p}_1)f(\\mathbf{x},\\mathbf{p}_2)}{f(\\mathbf{x},\\mathbf{p}'_1)f(\\mathbf{x},\\mathbf{p}'_2)}\\bigg) = 0.\n\\] That is, for any position \\(\\mathbf{x}\\), \\[\n\\log f(\\mathbf{x}, \\mathbf{p}_1) + \\log f(\\mathbf{x},\\mathbf{p}_2) = \\log f(\\mathbf{x},\\mathbf{p}'_1) + \\log f(\\mathbf{x},\\mathbf{p}'_2).\n\\] This is a law of detailed balance, in that it states that some quantity before a collision must equal the same quantity after collision. Detailed balance evidently implies that the sum \\(\\log f(\\mathbf{x}, \\mathbf{p}_1) + \\log f(\\mathbf{x},\\mathbf{p}_2)\\) must be conserved during collisions. In an elastic collision we require that particle number, momentum and kinetic energy be conserved, \\[\n\\begin{align*}\n1 + 1 &= 1' + 1',\\\\\n\\mathbf{p}_1 + \\mathbf{p}_2 &= \\mathbf{p}'_1 + \\mathbf{p}'_2, \\\\ \\frac{\\mathbf{p}^2_1}{2m} + \\frac{\\mathbf{p}^2_2}{2m} &= \\frac{\\mathbf{p}'^{2}_1}{2m} + \\frac{\\mathbf{p}'^{2}_2}{2m}.\n\\end{align*}\n\\] It thus makes sense to suppose that in equilibrium each \\(\\log f(\\mathbf{x}, \\mathbf{p},t)\\) is only a quadratic function in \\(\\mathbf{p}\\). Suppose then that \\[\n\\log f(\\mathbf{x},\\mathbf{p}) \\equiv \\nu(\\mathbf{x}) + \\boldsymbol{\\alpha}(\\mathbf{x}) \\cdot \\mathbf{p} - \\beta(\\mathbf{x}) \\frac{\\mathbf{p}^2}{2m}.\n\\] By completing the square and exponentiating, we can write the density in the form \\[\nf(\\mathbf{x}, \\mathbf{p}) = \\mathcal{N}(\\mathbf{x}) \\exp\\bigg(-\\frac{\\beta(\\mathbf{x})}{2m}(\\mathbf{p}-\\boldsymbol{\\pi}(\\mathbf{x}))^2\\bigg).\n\\] However, this equation doesn’t solve the entire Boltzmann equation. It only solves the equation \\(C[f] = 0\\). We still need to impose that \\(L[f] = 0\\) as well. If we like, we can add to the kinetic energy an external potential energy \\(V(\\mathbf{x})\\) that represents, for example, the walls of a box of fixed volume. Then \\[\nH(\\mathbf{x},\\mathbf{p}) = \\frac{\\mathbf{p}^2}{2m} + V(\\mathbf{x}).\n\\] To satisfy \\(L[f] = 0\\), we saw that \\(f\\) must be conserved under \\(H\\), i.e. \\(\\{f, H\\} = 0\\). This also must be true for any other quantity conserved under \\(H\\), in this case the momentum vector \\(\\mathbf{p}\\) and particle number \\(1\\). Enforcing that all these Poisson brackets vanish then forces \\(\\mathcal{N}\\), \\(\\beta\\), and \\(\\boldsymbol{\\pi}\\) to all be constant. The final equilibrium one-particle density for a gas is thus just a Gaussian in the momentum \\(\\mathbf{p}\\), \\[\n\\boxed{f_{eq}(\\mathbf{x}, \\mathbf{p}) = n(\\mathbf{x}, t) \\bigg(\\frac{\\beta}{2\\pi m}\\bigg)^{3/2} \\exp\\bigg(-\\frac{\\beta}{2m}(\\mathbf{p}-\\boldsymbol{\\pi})^2\\bigg)} \\ .\n\\] Here \\(n\\) is just the number density \\(n(\\mathbf{x}, t)\\), representing the fact that \\(f\\) isn’t normalized over the volume of the box. This can also be written in the form \\[\nf_{eq}(\\mathbf{x}, \\mathbf{p}) \\propto e^{-\\beta H(\\mathbf{x},\\mathbf{p})}.\n\\] This is called the Boltzmann Distribution. We’ll see it derived again when we get to statistical mechanics. This distribution describes how the energy of a closed system is distributed in equilibrium.\n\n\nIdeal Gas\nSuppose we’re dealing with a stationary gas of free particles, so \\(\\boldsymbol{\\pi} = \\mathbf{0}\\) and \\(V(\\mathbf{x}) = 0\\) inside the box. Then \\[\n\\rho_{eq}(\\mathbf{p}) = \\bigg(\\frac{\\beta}{2\\pi m}\\bigg)^{3/2} \\exp\\bigg(-\\frac{\\beta}{2m}\\mathbf{p}^2\\bigg).\n\\] Since this is an uncorrelated Gaussian, we can read off that each component of \\(\\mathbf{p}\\) has variance \\(\\langle p_i^2 \\rangle = \\frac{m}{\\beta}\\). The variance of \\(\\mathbf{p}\\) is thus evidently just \\[\n\\langle \\mathbf{\\mathbf{p}}^2 \\rangle = \\langle p_x^2 \\rangle + \\langle p_y^2 \\rangle + \\langle p_z^2 \\rangle = \\frac{3m}{\\beta}.\n\\] Plugging this into the Hamiltonian we can find an expression for the average internal kinetic energy of a free gas at equilibrium. We have \\[\nE \\equiv \\langle H \\rangle = \\frac{\\langle \\mathbf{p}^2 \\rangle}{2m} = \\frac{3}{2\\beta} = \\frac{3}{2} k_B T.\n\\] Evidently, a gas of free particles in a box is just the ideal gas, with \\(\\beta = \\frac{1}{k_B T}\\).\nIf we like we can also find the equation of state by calculating the force exerted on the walls of the box. To do that, let’s look at the force exerted on one of the walls of the box, say the wall on the positive x-axis. Evidently the number of particles \\(\\delta N_x\\) with momentum \\(p_x = mv_x\\) that collide with the wall in a time \\(\\delta t\\) is given by density times volume, i.e. \\[\n\\delta N_x = d^3 \\mathbf{p} \\ f(\\mathbf{p}) \\ A v_x \\delta t.\n\\] Assuming each collision is elastic, the momentum change in colliding with the wall is \\(\\Delta p_x = 2p_x\\). Then the force \\(F\\) exerted on the wall is \\[\nF = \\frac{1}{2\\delta t} \\int \\delta N_x \\ \\Delta p_x = \\int d^3 \\mathbf{p} \\ f(\\mathbf{p}) \\ A \\frac{p_x^2}{m}.\n\\] Using this force on the wall we can calculate the pressure of the gas by dividing by the wall area \\(A\\). Plugging in the distribution for momenta, we have \\[\nP = \\int d^3 \\mathbf{p} \\ f(\\mathbf{p}) \\ \\frac{p_x^2}{m} = \\int d^3 \\mathbf{p} \\ \\frac{p_x^2}{m} n\\bigg(\\frac{\\beta}{2\\pi m}\\bigg)^{3/2} \\exp\\bigg(-\\frac{\\beta}{2m}\\mathbf{p}^2\\bigg) = \\frac{n}{\\beta}.\n\\] Using the fact that \\(n = \\frac{N}{V}\\) and \\(\\beta = \\frac{1}{k_B T}\\), we’ve evidently derived the ideal gas law, \\[\nPV = N k_B T.\n\\] Insisting a free gas reduce to an ideal gas at equilibrium again supports that \\(\\beta = \\frac{1}{k_B T}\\).\nIf desired, one can calculate the entropy too by using \\(S \\equiv -k_B \\mathrm{H}\\) and doing the integral for \\(\\mathrm{H}\\). The result will be (up to an additive constant) the entropy for a monoatomic ideal gas. ### Maxwell-Boltzmann Distribution\nWe can also ask about the distribution for the speed \\(v\\) of an ideal gas at equilibrium. Using the relation \\(\\mathbf{p} = m \\mathbf{v}\\), we then have \\[\n\\rho_{eq}(\\mathbf{v}) = \\bigg(\\frac{m}{2\\pi k_B T}\\bigg)^{3/2} \\exp\\bigg(-\\frac{m\\mathbf{v}^2}{2k_B T}\\bigg).\n\\] This is the distribution for the velocity of a gas in the rest frame, not the speed. It’s evidently a mean-zero Gaussian distribution with variance \\(\\frac{k_B T}{m}\\). The ratio \\(v_{th}^2 \\equiv \\frac{k_B T}{m}\\) has dimensions of velocity squared. That velocity \\(v_{th}\\) is amply referred to as the root mean square (RMS) velocity. We’ve actually seen it already. It’s the velocity one gets from setting the kinetic energy equal to the mean thermal energy \\(k_B T\\). Practically all velocities of interest in thermodynamics are on the order of the RMS velocity.\nAnyway, notice the distribution depends only on the speed since \\(v^2 = \\mathbf{v}^2\\). It may seem like the distribution for \\(v\\) should be a Gaussian, but it’s not. The reason is we have to integrate over the volume element, \\[\n1 = \\int d^3 \\mathbf{v} \\ \\rho_{eq}(\\mathbf{v}) = \\int v^2 dv d\\Omega \\ \\rho_{eq}(|\\mathbf{v}|) = \\int dv \\ 4\\pi v^2\\rho_{eq}(|\\mathbf{v}|) \\equiv \\int dv \\ \\rho_{eq}(v).\n\\] This distribution for the particle speeds at equilibrium is called the Maxwell-Boltzmann Distribution, \\[\n\\boxed{\\rho_{eq}(v) = \\bigg(\\frac{m}{2\\pi k_B T}\\bigg)^{3/2} 4\\pi v^2 \\exp\\bigg(-\\frac{mv^2}{2k_B T}\\bigg)} \\ .\n\\] Since speeds are non-negative this is a rightward-skewed distribution. This means its mean won’t be zero like with the vector velocities. This makes sense, as a mean zero speed would imply the particles aren’t moving at all. In fact, the mean speed is proportional to the RMS velocity, \\[\n\\langle v \\rangle = 2\\sqrt{\\frac{2}{\\pi}} \\sqrt{\\frac{k_B T}{m}} \\approx 1.6 \\ v_{th}.\n\\]"
  },
  {
    "objectID": "statistical-mechanics/kinetic-theory.html#conservation-laws",
    "href": "statistical-mechanics/kinetic-theory.html#conservation-laws",
    "title": "Kinetic Theory",
    "section": "Conservation Laws",
    "text": "Conservation Laws\nSo far all we’ve done is derived the equilibrium distribution for a gas at equilibrium. But we don’t need kinetic theory to do this. As we’ll see, we can do that much more easily using statistical mechanics. What kinetic theory is really useful for is describing how the system approaches equilibrium. Specifically, what we really want to know is how the usual conserved quantities like particle number, energy, and momentum approach equilibrium. To do that we need to figure out what the dynamics are of conserved quantities.\n\nCollision-Conserved Quantities\nWe’ll specifically want to focus on collision conserved quantities. The ones that satisfy detailed balance conditions. We say \\(\\chi\\) is a collision conserved quantity if for any two colliding particles we have \\[\n\\chi_1 + \\chi_2 = \\chi'_1 + \\chi'_2.\n\\] A collision conserved quantity satisfies the useful property that the quantity \\(J(\\mathbf{x},t)\\) defined by \\[\nJ(\\mathbf{x},t) \\equiv \\int d^3 \\mathbf{p} \\ \\chi(\\mathbf{x}, \\mathbf{p},t) C[f]\n\\] vanishes. To see why, just substitute in the integral for \\(C[f]\\) and perform the same steps used in the proof of the H-theorem. Doing those manipulations with \\(\\log f\\) replaced by \\(\\chi\\) will give an integral of the form \\[\nJ(\\mathbf{x},t) = \\frac{1}{4} \\int d^3 \\mathbf{p}_1 \\ d^3 \\mathbf{p}_2 \\ \\frac{|\\mathbf{p}_2 - \\mathbf{p}_1|}{m} \\big[f(\\mathbf{p}_1)f(\\mathbf{p}_2)-f(\\mathbf{p}'_1)f(\\mathbf{p}'_2)\\big] \\big[\\chi(\\mathbf{p}_1) + \\chi(\\mathbf{p}_2) - \\chi(\\mathbf{p}'_1) - \\chi(\\mathbf{p}'_2)\\big].\n\\]\nProvided \\(\\chi\\) is a collision-conserved quantity the last term is zero, hence we get \\(J(\\mathbf{x},t) = 0\\).\nNow, notice if the system satisfies the Boltzmann equation we can replace \\(C[f]\\) with \\(L[f]\\) in the integral, \\[\n0 = \\int d^3 \\mathbf{p} \\ \\chi \\ L[f] = \\int d^3 \\mathbf{p} \\ \\chi \\ \\bigg(\\frac{\\partial}{\\partial t} + \\frac{\\mathbf{p}}{m} \\cdot \\frac{\\partial }{\\partial \\mathbf{x}} + \\mathbf{F} \\cdot \\frac{\\partial}{\\partial \\mathbf{p}} \\bigg) f.\n\\] We can manipulate this expression to get a useful differential equation for the field \\(\\chi(\\mathbf{x},t)\\). Since \\(L\\) is an operator of first derivatives we can apply the product rule to write \\[\n\\chi \\cdot L[f] = L[f \\cdot \\chi] - f \\cdot L[\\chi].\n\\] Plugging this in, we get \\[\n0 = \\int d^3 \\mathbf{p} \\ \\bigg[\\bigg(\\frac{\\partial (f \\cdot \\chi)}{\\partial t} + \\frac{\\mathbf{p}}{m} \\cdot \\frac{\\partial (f \\cdot \\chi)}{\\partial \\mathbf{x}} + \\mathbf{F} \\cdot \\frac{\\partial (f \\cdot \\chi)}{\\partial \\mathbf{p}} \\bigg) - \\bigg(\\frac{\\partial \\chi}{\\partial t} + \\frac{\\mathbf{p}}{m} \\cdot \\frac{\\partial \\chi}{\\partial \\mathbf{x}} + \\mathbf{F} \\cdot \\frac{\\partial \\chi}{\\partial \\mathbf{p}} \\bigg) f \\bigg].\n\\] At this point it’s useful to define a collision average. Notice the number density can be given by marginalizing out the momentum, \\[\nn(\\mathbf{x}, t) = \\int d^3 \\mathbf{p} \\ f(\\mathbf{x}, \\mathbf{p}, t).\n\\] Using this fact, we can define a collision average on any phase space function \\(\\chi\\) by \\[\n\\boxed{\\big\\langle \\chi(\\mathbf{x},t) \\big\\rangle_{c} \\equiv \\frac{1}{n(\\mathbf{x}, t)} \\int d^3 \\mathbf{p} \\ f(\\mathbf{x}, \\mathbf{p}, t) \\ \\chi(\\mathbf{x}, \\mathbf{p}, t)} \\ .\n\\] Going back to our expression for \\(J(\\mathbf{x},t)\\), notice we can pull any terms and derivatives that doesn’t depend on \\(\\mathbf{p}\\) out of the integral. The terms remaining under the integral can then be written as collision averages, \\[\n\\boxed{\\frac{\\partial}{\\partial t} n\\big\\langle \\chi \\big\\rangle_{c} + \\frac{\\partial}{\\partial \\mathbf{x}} \\cdot n\\bigg\\langle \\frac{\\mathbf{p}}{m} \\chi \\bigg\\rangle_{c} - \\ n \\bigg\\langle \\frac{\\partial \\chi}{\\partial t} \\bigg\\rangle_{c} - \\ n \\bigg\\langle \\frac{\\mathbf{p}}{m} \\cdot\\frac{\\partial \\chi}{\\partial \\mathbf{x}}\\bigg\\rangle_{c} - n \\mathbf{F} \\cdot \\bigg\\langle \\frac{\\partial \\chi}{\\partial \\mathbf{p}}\\bigg\\rangle_{c} = 0 } \\ .\n\\] Note the integral over \\(\\mathbf{F} \\cdot \\frac{\\partial (f \\cdot \\chi)}{\\partial \\mathbf{p}}\\) vanishes since it’s a total time derivative. The above equation is called the hydrodynamics equation or the conservation law for the field \\(\\chi(\\mathbf{x},t)\\). Unlike typical conservation laws in classical mechanics, these conservation laws are local.\n\n\nParticle Number\nThe particular conservation laws we’ll focus on are the usual ones for a gas: particle number (or mass), momentum, and kinetic energy. To find the conservation law for particle number or mass, take \\(\\chi = 1\\). In that case, all the derivatives of \\(\\chi\\) vanish, so we’re left with \\[\n\\frac{\\partial n}{\\partial t} + \\frac{\\partial}{\\partial \\mathbf{x}} n\\bigg\\langle \\frac{\\mathbf{p}}{m} \\bigg\\rangle_{c} = 0.\n\\] The collision average of \\(\\frac{\\mathbf{p}}{m}\\) gives some kind of velocity field \\(\\mathbf{u}(\\mathbf{x},t)\\). This is the flow velocity of the gas, treated as a kind of continuous fluid. We can thus write \\[\n\\boxed{\\frac{\\partial n}{\\partial t} + \\nabla \\cdot n \\mathbf{u}  = 0} \\ .\n\\] This is the well-known continuity equation, in this case for the particle number.\nThis says that at any region of space, particle number must be conserved. To see why, if we integrate the equation with respect to volume and use the divergence theorem, we have \\[\n\\frac{d}{dt} \\int_\\mathcal{V} d^3 \\mathbf{x} \\ n = \\int_\\mathcal{S} n \\mathbf{u} \\cdot d\\mathbf{a}.\n\\] That is, the only way particle number inside a region \\(\\mathcal{V}\\) can change is by flowing out of its surface \\(\\mathcal{S}\\). Over all space, the right-hand side must vanish for physical reasons, which just says total particle number is conserved, \\[\n\\frac{dN}{dt} = 0.\n\\] The same equation holds for mass density \\(\\rho \\equiv mn\\) by multiplying both sides of the continuity equation by the mass \\(m\\). In that language it expresses the conservation of mass for the gas. It’s sometimes useful to re-write the continuity equation in terms of the material derivative. To do that we need to factor out the \\(\\mathbf{u}\\) from the divergence using the product rule. We then get \\[\n\\boxed{\\frac{Dn}{Dt} = -n \\nabla \\cdot \\mathbf{u}} \\ .\n\\] This form is particularly useful when dealing with an incompressible fluid, since in that case \\(\\nabla \\cdot \\mathbf{u} = 0\\), implying the fluid has uniform density. Incompressible fluids are more characteristic of liquids than gases, however, since we can practically always compress a gas by applying pressure to it.\n\n\nMomentum\nThe next conservation law we’ll derive is conservation of momentum. Rather than take \\(\\chi\\) to be the momentum \\(\\mathbf{p}\\) directly, it’s more useful to take it to be the relative particle velocity \\[\n\\mathbf{c} \\equiv \\frac{\\mathbf{p}}{m} - \\mathbf{u}.\n\\] Let’s apply the conservation law to one of the components of \\(\\mathbf{c}\\) by taking \\(\\chi = c_\\alpha\\). This definition has the advantage that \\(\\langle c_\\alpha \\rangle_{c}\\) vanishes, which simplifies calculations somewhat. Noting that \\(\\frac{\\mathbf{p}}{m} = \\mathbf{c} + \\mathbf{u}\\), and using the summation convention, we have $$ \\[\\begin{align*}\n0 &= \\frac{\\partial}{\\partial x_\\beta} n\\bigg\\langle \\frac{p_\\beta}{m} c_\\alpha \\bigg\\rangle_c - \\ n \\bigg\\langle \\frac{\\partial c_\\alpha}{\\partial t} \\bigg\\rangle_c - \\ n \\bigg\\langle \\frac{p_\\beta}{m} \\frac{\\partial c_\\alpha}{\\partial x_\\beta}\\bigg\\rangle_c - n F_\\beta \\cdot \\bigg\\langle \\frac{\\partial c_\\alpha}{\\partial p_\\beta}\\bigg\\rangle_c \\\\\n\n&= \\frac{\\partial}{\\partial x_\\beta} n\\bigg\\langle (c_\\beta+u_\\beta) c_\\alpha \\bigg\\rangle_c - \\ n \\bigg\\langle \\frac{\\partial c_\\alpha}{\\partial t} \\bigg\\rangle_c - \\ n \\bigg\\langle (c_\\beta+u_\\beta) \\frac{\\partial c_\\alpha}{\\partial x_\\beta}\\bigg\\rangle_c - n F_\\beta \\cdot \\bigg\\langle \\frac{\\partial c_\\alpha}{\\partial p_\\beta}\\bigg\\rangle_c \\\\\n&= \\frac{\\partial}{\\partial x_\\beta} n \\big\\langle c_\\alpha c_\\beta \\big\\rangle_c + n \\frac{\\partial u_\\alpha}{\\partial t} + n u_\\beta \\frac{\\partial u_\\alpha}{\\partial x_\\beta} - n F_\\beta \\frac{\\delta_{\\alpha\\beta}}{m} \\\\\n&= \\frac{\\partial}{\\partial x_\\beta} nm \\big\\langle c_\\alpha c_\\beta \\big\\rangle_c + nm \\frac{\\partial u_\\alpha}{\\partial t} + nm u_\\beta \\frac{\\partial u_\\alpha}{\\partial x_\\beta} - n F_\\alpha.\n\\end{align*}\\] $$\nWe evidently have a differential equation for the flow velocity \\(\\mathbf{u}\\). The only unfamiliar term is the first one, which is evidently the gradient of a symmetric rank-two tensor. This is the pressure tensor, defined by \\[\nP_{\\alpha\\beta} \\equiv nm \\big\\langle c_\\alpha c_\\beta \\big\\rangle_c \\ , \\quad \\text{or} \\quad \\mathbf{P} \\equiv nm\\langle \\mathbf{c} \\otimes \\mathbf{c} \\rangle_c \\ .\n\\] Plugging the pressure tensor in and re-arranging, we see that each component of the flow velocity satisfies a conservation law of the form \\[\n\\frac{\\partial u_\\alpha}{\\partial t} + u_\\beta \\frac{\\partial u_\\alpha}{\\partial x_\\beta} = \\frac{F_\\alpha}{m} - \\frac{1}{nm} \\frac{\\partial P_{\\alpha\\beta}}{\\partial x_\\beta}.\n\\] If we think of the velocity gradient as being done component-wise and the divergence on the right as a contraction over one of the indices, then we can write this conservation law in vector notation as \\[\n\\boxed{nm \\frac{D \\mathbf{u}}{Dt} = n \\mathbf{F} - \\nabla \\cdot \\mathbf{P}} \\ .\n\\] This is called the Cauchy momentum equation. Notice how this conservation law looks something like Newton’s second law. On the left is a kind of mass times acceleration term, while on the right are the two kinds of forces acting on each gas particle, the external forces and the internal pressure-driven forces.\n\n\nEnergy\nThe final conservation law we’ll consider is the one for kinetic energy. Again, it’s convenient to look instead at the relative kinetic energy \\(\\chi = \\frac{1}{2} m \\mathbf{c}^2\\). Define the energy density or the heat flux \\(\\varepsilon\\) to be the collision average of the relative kinetic energy, \\[\n\\varepsilon \\equiv \\frac{1}{2} m \\big\\langle \\mathbf{c}^2 \\big\\rangle_c.\n\\] It’s also helpful to define a vector \\(\\mathbf{h}\\) called the heat flux given by \\[\n\\mathbf{h} \\equiv \\frac{1}{2} nm \\big\\langle \\mathbf{c}^2 \\mathbf{c} \\big\\rangle_c.\n\\] Last, it’s helpful to define another symmetric rank-two tensor \\(\\mathbf{U}\\) called the rate of strain tensor. Its components are the symmetrized gradients of \\(\\mathbf{c}\\), i.e. \\[\nU_{\\alpha\\beta} \\equiv \\frac{\\partial u_\\alpha}{\\partial x_\\beta} + \\frac{\\partial u_\\beta}{\\partial x_\\alpha}.\n\\] With these definitions, after a lot of tedious work we can express the conservation law for kinetic energy in component form (again using the summation convention) as \\[\n\\frac{\\partial \\varepsilon}{\\partial t} + u_\\alpha \\frac{\\partial \\varepsilon}{\\partial x_\\alpha}  = -\\frac{1}{n}\\frac{\\partial h_\\alpha}{\\partial x_\\alpha} - \\frac{1}{n}P_{\\alpha\\beta} U_{\\alpha\\beta} \\ .\n\\] The first term on the right is the divergence of the heat flux. The second term is the trace over the matrix product of the pressure tensor with the rate of strain. With this in mind, we can express this equation in vector notation as \\[\n\\boxed{n\\frac{D\\varepsilon}{Dt} = -\\nabla \\cdot \\mathbf{h} - \\text{tr}(\\mathbf{P} \\cdot \\mathbf{U})} \\ .\n\\] Roughly speaking, this conservation law expresses the first law of thermodynamics. The left-hand-side is the change in the total energy, while the right-hand side is the change in heat plus the change in work."
  },
  {
    "objectID": "statistical-mechanics/kinetic-theory.html#approach-to-equilibrium",
    "href": "statistical-mechanics/kinetic-theory.html#approach-to-equilibrium",
    "title": "Kinetic Theory",
    "section": "Approach to Equilibrium",
    "text": "Approach to Equilibrium\nAs was already mentioned, our whole purpose in deriving collision conserved quantities and conservation laws was to study how systems approach equilibrium. To do this we’ll want to study the solutions of the conservation laws as \\(t \\rightarrow \\infty\\). To approach equilibrium, each conserved quantity should approach a constant value, its equilibrium value.\n\nZeroth-Order Solutions\nWhile all these conservation equations are nice, we still don’t know how to solve them. To do that we’d need to know the pressure tensor and the heat flux, both of which require that we already know the density. Usually we don’t know the full density. What we’ll try to do instead is expand the density in terms of the parameter \\(\\frac{\\tau_X}{\\tau_{\\text{ext}}}\\), the characteristic inverse time scale of \\(L[f]\\). In the limit where external forces act on much larger time scales than the collision forces this parameter will be small.\nLet’s start by calculating the zeroth order density \\(f^0\\). In the zeroth order case we’re assuming \\(\\tau_{\\text{ext}} \\rightarrow \\infty\\), hence \\(C[f^0] = 0\\). We already saw using detailed balance that such a distribution is just a Gaussian in terms of the momenta or velocity. If we write \\[\n\\mathbf{c}(\\mathbf{x}, t) = \\mathbf{p} - m\\mathbf{u}(\\mathbf{x}, t) = \\mathbf{p} - \\boldsymbol{\\pi}(\\mathbf{x}, t),\n\\] and choose \\(\\beta = \\frac{1}{k_B T}\\) as before, then the zeroth order distribution can be written as \\[\nf^0(\\mathbf{x}, \\mathbf{p}, t) \\equiv n(\\mathbf{x}, t)\\bigg(\\frac{m}{2\\pi k_B T(\\mathbf{x}, t)}\\bigg)^{3/2} \\exp\\bigg(-\\frac{m\\mathbf{c}^2}{2k_B T(\\mathbf{x}, t)}\\bigg).\n\\] This is a mean-zero Gaussian distribution in \\(\\mathbf{c}\\) with variance \\(\\frac{k_B T}{m}\\). Let’s assume this is the density and see what we can deduce about the conservation laws and how they approach equilibrium.\nSince we’re dealing with a Gaussian, we can use Wick’s theorem to conclude the odd-power moments are zero. This means that the heat flux vanishes, since \\[\n\\mathbf{h} = \\frac{1}{2} nm \\big\\langle \\mathbf{c}^2 \\mathbf{c} \\big\\rangle_c = \\mathbf{0} .\n\\] The pressure tensor, however, is an even moment. Since the covariance of \\(f^0\\) is diagonal, we just have \\[\n\\mathbf{P} = nm \\big\\langle \\mathbf{c} \\otimes \\mathbf{c} \\big\\rangle_c = nm \\frac{k_B T}{m} \\ \\mathbf{1} = nk_B T \\ \\mathbf{1}.\n\\] Last, the energy density is just \\[\n\\varepsilon = \\frac{m}{2} \\big\\langle \\mathbf{c}^2 \\big\\rangle_c = \\frac{m}{2} \\frac{3k_B T}{m} = \\frac{3}{2} k_B T.\n\\]\nTogether, these mean that the three conservation laws can be written as \\[\n\\begin{align*}\n\\frac{Dn}{Dt} &= -n \\nabla \\cdot \\mathbf{u}  \\\\\n\\frac{D\\mathbf{u}}{Dt} &= \\frac{1}{m} \\mathbf{F} -\\frac{k_B}{nm} \\nabla nT  \\\\\n\\frac{DT}{Dt} &= -\\frac{2}{3} T \\ \\nabla \\cdot \\mathbf{u} \\ \\ . \\\\\n\\end{align*}\n\\] Let’s try to combine the first and last equation and see what we get. Notice both terms contain a divergence \\(\\nabla \\cdot \\mathbf{u}\\). If we solve for the divergence in the first equation and plug it into the third, we get \\[\n\\begin{align*}\n&\\frac{DT}{Dt} = -\\frac{2}{3} T \\ \\nabla \\cdot \\mathbf{u} = \\frac{2T}{3n} \\frac{Dn}{Dt} \\\\\n&\\Longrightarrow \\quad \\frac{3}{2} \\frac{D}{Dt} \\log T - \\frac{D}{Dt} \\log n = 0 \\\\\n&\\Longrightarrow \\quad \\frac{D}{Dt} \\log n T^{-3/2} = 0.\n\\end{align*}\n\\] That is, along any given streamline the quantity \\(\\log n T^{-3/2}\\) is constant. This quantity is a kind of local entropy since \\(dS \\sim \\log n T^{-3/2} d^3 \\mathbf{x}\\). We’ve thus shown that the zeroth order solution implies \\(dS=0\\), i.e. the entire process is adiabatic for all time. This in particular means entropy can’t increase to a maximum, which implies that the system will never come to equilibrium unless it starts out in equilibrium. Evidently the zeroth order approximation isn’t enough to get equilibrium. We’ll need to go further.\nLet’s look at this more formally first. For the system to always converge to equilibrium the solutions need to be stable. That is, if any conserved quantity is nudged from equilibrium it should relax back to equilibrium. Suppose the system is initially in equilibrium. Suppose we make the following first-order perturbations, \\[\n\\begin{align*}\nn(\\mathbf{x}, t) &= n_0 + \\nu(\\mathbf{x}, t) \\\\\nT(\\mathbf{x}, t) &= T_0 + \\theta(\\mathbf{x}, t) \\ . \\\\\n\\end{align*}\n\\] For simplicity, assume no external forces act inside the box and at equilibrium the box is at rest. In that case, to first order \\(\\frac{D}{Dt} \\approx \\frac{\\partial}{\\partial t}\\). Plugging these into the conservation laws and keeping only terms to first order, we get \\[\n\\begin{align*}\n\\frac{\\partial\\nu}{\\partial t} &\\approx -n_0 \\nabla \\cdot \\mathbf{u}  \\\\\n\\frac{\\partial\\mathbf{u}}{\\partial t} &\\approx -\\frac{k_B T_0}{mn_0} \\nabla \\nu - \\frac{k_B}{m} \\nabla \\theta \\\\\n\\frac{\\partial\\theta}{\\partial t} &\\approx -\\frac{2}{3} T_0 \\ \\nabla \\cdot \\mathbf{u} \\ \\ . \\\\\n\\end{align*}\n\\]\nNow let’s Fourier transform these first order quantities and look at their normal modes. The natural frequencies \\(\\omega(\\mathbf{k})\\) and the normal modes are the solutions to the following eigenvalue equation, \\[\n\\begin{pmatrix}\n0 & n_0 \\mathbf{k} & 0 \\\\\n\\frac{k_B T_0}{mn_0} \\mathbf{k} & 0 & \\frac{k_B}{m} \\mathbf{k}  \\\\\n0 & \\frac{2}{3} T_0 \\mathbf{k} & 0 \\\\\n\\end{pmatrix}\n\\begin{pmatrix}\n\\tilde \\nu \\\\\n\\mathbf{\\tilde u} \\\\\n\\tilde \\theta \\\\\n\\end{pmatrix} =\n\\omega\n\\begin{pmatrix}\n\\tilde \\nu \\\\\n\\mathbf{\\tilde u} \\\\\n\\tilde \\theta \\\\\n\\end{pmatrix}.\n\\] Note the block notation being used. This is really a \\(5 \\times 5\\) matrix multiplying a size \\(5\\) vector. There are thus \\(5\\) distinct normal modes that satisfy this equation. To get the modes we need to solve the characteristic equation, which turns out to be \\[\n\\text{det}(\\mathbf{A} - \\omega \\mathbf{I}) = \\omega^3\\bigg(\\omega^2 - \\frac{5k_B T_0}{3m} \\bigg) = 0.\n\\]\n\nThe first mode is a stationary mode, one of the zero modes with \\(\\omega = 0\\). The modes themselves are \\[\n\\tilde\\nu = \\text{const}, \\quad \\mathbf{\\tilde u} = \\mathbf{0}, \\quad \\tilde \\theta = \\text{const},\n\\] meaning that the fluid is essentially stationary for all frequencies. This implies the fluid maintains uniform pressure \\(P = n k_B T_0\\), which ensures that the fluid can’t start moving due to pressure variations since \\(\\Delta S \\sim nT_0\\) is constant.\nThe next two modes are sound modes, where \\(\\omega = \\pm v_s |\\mathbf{k}|\\). Here \\(v_s\\) is the speed of sound of the fluid, given by \\[\nv_s \\equiv \\sqrt{\\frac{\\gamma k_B T_0}{m}}, \\quad \\text{where} \\quad \\gamma = \\frac{5}{3}\n\\] is the adiabatic constant for a monoatomic ideal gas. Sound modes represent pressure waves propagating outward forever without damping. All of the conserved quantities propagate as longitudinal waves along the \\(\\mathbf{k}\\) direction, since \\[\n\\tilde\\nu = n_0 |\\mathbf{k}|, \\quad \\mathbf{\\tilde u} = \\pm v_s \\mathbf{k}, \\quad \\tilde\\theta = \\frac{2}{3} T_0 |\\mathbf{k}|.\n\\]\nThe last two modes are shearing modes. These are also zero modes with \\(\\omega = 0\\), but they correspond to motion in the transverse directions orthogonal to \\(\\mathbf{k}\\). This means we’d have \\[\n\\tilde \\nu = \\text{const}, \\quad \\mathbf{\\tilde u} \\cdot \\mathbf{k} = 0, \\quad \\tilde \\theta = \\text{const}.\n\\] Transverse motions in a fluid create a shearing effect. Since \\(\\mathbf{\\tilde u}\\) stays constant for shearing modes, each quantity will just continue forever without damping.\n\nWe thus find that none of the conserved quantities relax to equilibrium to zeroth-order. Shear flow and entropy modes persist forever, while the two sound modes have undamped oscillations. Since none of the normal modes in general relax to equilibrium, neither will any general solutions, which are themselves just superpositions of normal modes.\n\n\nFirst-Order Solutions\nWe thus have to move onto first order solutions. Instead of assuming an infinite \\(\\tau_{\\text{ext}}\\), we’ll assume it’s small to first order compared to \\(\\tau_X\\). This brings the left-hand side \\(L[f]\\) of Boltzmann’s equation back into the game. We’ll assume a first-order density of the form \\[\nf^1(\\mathbf{x}, \\mathbf{p}, t) = f^0(\\mathbf{x}, \\mathbf{p}, t) \\big(1 + g(\\mathbf{x}, \\mathbf{p}, t)\\big),\n\\] where \\(g(\\mathbf{x}, \\mathbf{p}, t)\\) is assumed to be related to the inverse time scale \\(\\frac{\\tau_X}{\\tau_{\\text{ext}}} \\ll 1\\). To evaluate \\(C[f^1]\\) we have to linearize the integral. To do so we’ll employ the single collision time approximation, which says that \\[\nC[f^1] \\approx -f^0 \\frac{g}{\\tau_X}.\n\\] If we assume \\(g\\) is in some sense small, then \\(L[f^1] = L[f^0]+L[f^0g]] \\approx L[f^0]\\). We thus have that \\[\nL[f^0] \\approx -f^0 \\frac{g}{\\tau_X},\n\\] Using the expression for \\(f^0\\) found already, this means \\[\ng = - \\tau_X L[\\log f^0] = - \\tau_X L\\bigg[\\log \\bigg(n\\bigg(\\frac{m}{2\\pi k_B T}\\bigg)^{3/2} \\exp\\bigg(-\\frac{m\\mathbf{c}^2}{2k_B T}\\bigg)\\bigg)\\bigg].\n\\] Now, observe we can re-write the Liouville operator in a more useful way in terms of \\(\\mathbf{u}\\) instead of \\(\\mathbf{p}\\) as \\[\nL[f] = \\frac{Df}{Dt} + \\mathbf{c} \\cdot \\frac{\\partial f}{\\partial \\mathbf{x}} + \\mathbf{F} \\cdot \\frac{\\partial f}{\\partial \\mathbf{p}}.\n\\] Combining all of these facts together and using the zeroth-order conservation laws we already derived, we finally get \\[\n\\begin{align*}\ng &= -\\tau_X \\ L[\\log f^0] \\\\\n&= -\\tau_X \\ L\\bigg[\\log n - \\frac{3}{2} \\log \\frac{2\\pi k_B T}{m} - \\frac{mc^2}{2 k_B T} \\bigg] \\\\\n&= -\\tau_X \\ \\bigg(\\frac{D}{Dt} + \\mathbf{c} \\cdot \\frac{\\partial}{\\partial \\mathbf{x}} + \\mathbf{F} \\cdot \\frac{\\partial}{\\partial \\mathbf{p}}\\bigg)\\bigg[\\log n - \\frac{3}{2} \\log \\frac{2\\pi k_B T}{m} - \\frac{mc^2}{2 k_B T} \\bigg] \\\\\n&= -\\tau_X \\bigg[\\frac{m}{k_B T} U_{ij} \\bigg(c_i c_j - \\frac{c^2}{3} \\delta_{ij}\\bigg) + \\bigg(\\frac{m c^2}{2k_B T} - \\frac{5}{2} \\bigg) \\frac{c_i}{T} \\frac{\\partial T}{\\partial x_i}\\bigg]. \\\\\n\\end{align*}\n\\] This means the first-order density in full is given in vector notation as \\[\n\\begin{align*}\nf^1(\\mathbf{x}, \\mathbf{p},t) = \\ &n\\bigg(\\frac{m}{2\\pi k_B T}\\bigg)^{3/2} \\exp\\bigg(-\\frac{m\\mathbf{c}^2}{2k_B T}\\bigg) \\ \\times \\\\\n&\\bigg\\{1 -\\tau_X \\bigg[\\frac{m}{k_B T}\\text{tr}\\bigg( \\mathbf{U} \\cdot \\bigg(\\mathbf{c} \\otimes \\mathbf{c} - \\frac{c^2}{3} \\mathbf{I}\\bigg)\\bigg) + \\bigg(\\frac{m c^2}{2k_B T} - \\frac{5}{2} \\bigg) \\mathbf{c} \\cdot \\frac{\\nabla T}{T} \\bigg]\\bigg\\}.\n\\end{align*}\n\\] The term involving the trace of velocities represents the correlation of particle velocity with the rate of strain tensor. It describes how velocities vary due to fluid strain. The term involving the temperature gradient says something about how velocities depend on temperature gradients across the fluid. Together, these effects give the density an anisotropic, multimodal behavior.\nAfter some work, it turns out that integrating \\(f^1\\) again gives the particle density, \\[\nn(\\mathbf{x},t) = \\int d^3 \\mathbf{p} \\ f^1(\\mathbf{x}, \\mathbf{p}, t).\n\\] We can more quickly calculate the first-order collision averages in terms of the zeroth-order averages as \\[\n\\langle \\chi(\\mathbf{x},t) \\rangle_c^1 = \\frac{1}{n(\\mathbf{x},t)} \\int d^3 \\mathbf{p} \\ \\chi(\\mathbf{x},t) f^0(\\mathbf{x}, \\mathbf{p}, t)\\big(1+g(\\mathbf{x}, \\mathbf{p}, t)\\big) = \\big\\langle \\chi(\\mathbf{x},t) \\big\\rangle_c^0 + \\big\\langle g(\\mathbf{x}, t) \\chi(\\mathbf{x},t) \\big\\rangle_c^0 \\ .\n\\] All quantities of interest involve calculating moments of \\(\\mathbf{c}\\). Notice that the first-order correction now contains terms proportional to both \\(c\\) and \\(c^3\\), which means the first and third moments no longer vanish. Together, these will imply the existence of a non-zero heat flux vector and a non-diagonal pressure tensor. We can use Wick’s theorem to calculate these values to eventually get \\[\n\\begin{align*}\n\\mathbf{P} &= nm \\langle \\mathbf{c}\\otimes\\mathbf{c} \\rangle_c^1 = nk_B T \\bigg[\\mathbf{1} - 2 \\tau_X \\bigg(\\mathbf{U} - \\frac{u^2}{3} \\mathbf{1}\\bigg)\\bigg], \\\\\n\\varepsilon &= \\frac{1}{2} m \\langle c^2 \\rangle_c^1 = \\frac{3}{2} k_B T, \\\\\n\\mathbf{h} &= \\frac{1}{2} mn \\langle c^2 \\mathbf{c} \\rangle_c^1 = -\\frac{5 \\tau_X nk_B^2 T}{2m} \\nabla T.\n\\end{align*}\n\\] The coefficient \\(\\mu \\equiv nk_B T \\tau_X\\) in the off diagonals of the pressure tensor is the viscosity coefficient. The off-diagonals cause the fluid to shear against opposing viscous forces that go like \\(\\mu \\nabla^2 \\mathbf{u}\\). Similarly, the coefficient \\(K \\equiv \\frac{5 \\tau_X nk_B^2 T}{2m}\\) is the thermal conductivity coefficient of the gas. In particular, when the gas is at rest and the pressure is uniform, we get \\[\n\\frac{\\partial T}{\\partial t} = \\alpha \\nabla^2 T,\n\\] which is a classic diffusion equation for the temperature, called the Fourier equation. Recall that solutions to diffusion equations will always settle down into an equilibrium state as \\(t \\rightarrow \\infty\\). The diffusion coefficient \\[\n\\alpha(T) \\equiv \\frac{2K}{3nk_B} = \\frac{5\\tau_X k_B T}{3m}\n\\] characterizes the inverse time scale over which the temperature relaxes to its equilibrium temperature. For variations on distance scales of \\(\\lambda\\), the heat equation relaxes on a time scale of \\[\n\\tau_{\\text{diff}} \\sim \\frac{\\lambda^2}{\\alpha}.\n\\] The fluid velocity relaxes according to a similar diffusion equation brought on by the shearing in the pressure tensor."
  },
  {
    "objectID": "statistical-mechanics/classical-stat-mech.html#formal-definition",
    "href": "statistical-mechanics/classical-stat-mech.html#formal-definition",
    "title": "Classical Statistical Mechanics",
    "section": "Formal Definition",
    "text": "Formal Definition\nMore formally, suppose we have a system of \\(N\\) particles in equilibrium whose phase space configuration is described by a microstate \\(\\boldsymbol{\\mu} \\equiv \\{\\mathbf{x}_i, \\mathbf{p}_i\\}\\) . Suppose we’re interested in studying some set of macroscopic equilibrium properties described by a macrostate \\(M=(E,X,N)\\). For a given macrostate \\(M\\), suppose the equilibrium phase space density for the system to be in some microstate \\(\\boldsymbol{\\mu}\\) is given by a probability distribution \\(p_M(\\boldsymbol{\\mu})\\). Let’s define statistical mechanics as the probabilistic study of the equilibrium macrostates \\(M\\) of a system with a large number of degrees of freedom \\(N \\gg 1\\) using the equilibrium probability distribution \\(p_M(\\boldsymbol{\\mu})\\).\nRecall that to be in equilibrium the phase space density should be time independent. By Liouville’s equation, this means \\[\n\\frac{\\partial}{\\partial t} p_M(\\boldsymbol{\\mu}) = -\\{p_M(\\boldsymbol{\\mu}), H\\} = 0.\n\\] In general this will be true so long as \\(p_M(\\boldsymbol{\\mu})\\) is an explicit function only of the Hamiltonian \\(H(\\boldsymbol{\\mu})\\) and possibly any other conserved quantities. If there are no other conserved quantities then the equilibrium distribution should be an explicit function of \\(H(\\boldsymbol{\\mu})\\) alone, i.e. \\[\np_M(\\boldsymbol{\\mu}) \\equiv p_M(H(\\boldsymbol{\\mu})).\n\\] In statistical mechanics we’re primarily interested in probability distributions corresponding to specific classes of system constraints, or ensembles. We’ll focus on the following ensembles, each of which corresponds to a conserved free energy.\n\nThe microcanonical ensemble: \\(p_M(\\boldsymbol{\\mu}) \\propto \\delta(H(\\boldsymbol{\\mu}) - E)\\). This corresponds to the energy \\(E\\) being conserved.\nThe canonical ensemble: \\(p_M(\\boldsymbol{\\mu}) \\propto e^{-\\beta H(\\boldsymbol{\\mu})}\\). This corresponds to the Hemlholtz free energy \\(F\\) being conserved.\nThe Gibbs canonical ensemble: \\(p_M(\\boldsymbol{\\mu}) \\propto e^{-\\beta (H(\\boldsymbol{\\mu}) - J \\cdot X)}\\). This corresponds to the Gibbs free energy \\(G\\) being conserved.\nThe grand canonical ensemble: \\(p_M(\\boldsymbol{\\mu}) \\propto e^{-\\beta (H(\\boldsymbol{\\mu}) - \\mu \\cdot N)}\\). This corresponds to the grand potential \\(\\mathcal{G}\\) being conserved.\n\nAll of these distributions arise from the principle of maximum entropy given certain known constraints, particularly the assumption that the expected values of zero or more quantities are given. We’ll study the implications of each ensemble one at a time and discuss when to use which for a given problem."
  },
  {
    "objectID": "statistical-mechanics/classical-stat-mech.html#microcanonical-ensemble",
    "href": "statistical-mechanics/classical-stat-mech.html#microcanonical-ensemble",
    "title": "Classical Statistical Mechanics",
    "section": "Microcanonical Ensemble",
    "text": "Microcanonical Ensemble\nSuppose we have an isolated system, where the macrostate \\(M=(E,X,N)\\) is assumed to be constant. This is called the microcanonical ensemble. The corresponding probability distribution is given by the assumption of a-priori probability. We assume all microstates are equally likely so long as \\(M\\) stays fixed. More specifically, the probability distribution is assumed to be uniform on phase space manifolds of constant energy, \\[\n\\boxed{\np(\\boldsymbol{\\mu}) = \\frac{1}{\\Omega(M)} \\delta\\big(H(\\boldsymbol{\\mu}) - E\\big)\n} \\ ,\n\\] The variable \\(\\Omega(M)\\) is some normalization constant ensuring the probability integrates to one. In fact, it’s just a count of the total number of microstates corresponding to the macrostate \\(M\\). We’ll call it the multiplicity. The multiplicity also corresponds to the surface area of the phase space manifold of constant energy \\(E\\), \\[\n\\boxed{\\Omega(M) = \\int_{H(\\boldsymbol{\\mu})=E} d \\boldsymbol{\\mu}} \\ .\n\\] Given the probability distribution, we can calculate the thermodynamic entropy using the formula \\(S = -k_B \\langle \\log p \\rangle\\), \\[\n\\begin{align*}\nS(M) &= -k_B \\int d \\boldsymbol{\\mu} \\ p(\\boldsymbol{\\mu}) \\log p(\\boldsymbol{\\mu}) \\\\\n&= k_B \\int_{H(\\mathbf{x},\\mathbf{p})=E} d \\boldsymbol{\\mu} \\ \\frac{\\log \\Omega(M)}{\\Omega(M)} \\\\\n&= k_B \\log \\Omega(M). \\\\\n\\end{align*}\n\\] That is, the entropy is simply proportional to the logarithm of the number of microstates, \\[\n\\boxed{\nS = k_B \\log \\Omega\n} \\ .\n\\]\n\nLaws of Thermodynamics\nWith a probability distribution and a definition of entropy in hand, we can proceed to derive almost all of the laws of thermodynamics from the assumption of a microcanonical ensemble. Let’s start with the zeroth law.\nZeroth Law: Suppose two otherwise isolated systems \\(A\\) and \\(B\\) are in thermal contact with each other and allowed to exchange energy. When they both reach equilibrium, there will be some temperature function such that \\(T = T_A = T_B\\).\nProof: Suppose system \\(A\\) has energy \\(E_A\\) and system \\(B\\) has energy \\(E_B\\). The entire system \\(A+B\\) is isolated, which means it has some constant energy that must be given by \\(E = E_A + E_B\\). The multiplicity of the full system is just the product of multiplicities of each subsystem, integrated over all energies that sum up to \\(E\\). That is, \\[\n\\Omega(E) = \\int_{E=E_A+E_B} dE \\ \\Omega(E_A) \\Omega(E_B) = \\int dE_A \\ \\Omega(E_A) \\Omega(E-E_A).\n\\] We can write this in terms of entropies as well. We have \\[\n\\Omega(E) = \\int dE_A \\ e^{\\frac{1}{k_B} S_A} e^{\\frac{1}{k_B} S-S_A} = \\int dE_A \\ e^{\\frac{1}{k_B}(S_A+S_B)}\n\\] Now, entropy is an extensive quantity, meaning \\(S \\propto N\\). Since \\(N\\) is large we can employ the saddlepoint approximation, evaluating the integrand at the energies \\(E_A^*\\) and \\(E_B^*\\) that maximize the total entropy to get \\[\n\\Omega(E) \\approx e^{\\frac{1}{k_B} \\big(S(E_A^*) + S(E_B^*)\\big)}.\n\\] This maximum must occur when the partial derivatives at the maximum energies vanish, i.e. \\[\n\\frac{\\partial }{\\partial E_A} S(E_A^*) \\bigg|_{X,N} - \\frac{\\partial }{\\partial E_B} S(E_B^*) \\bigg|_{X,N} = 0.\n\\] When \\(A\\) and \\(B\\) are in equilibrium, the total entropy \\(S\\) must be maximized, meaning the partial derivatives must be equal. This condition defines a function whose values must equal at equilibrium, which by convention is the inverse temperature, \\[\n\\frac{1}{T} \\equiv \\frac{\\partial S}{\\partial E_A} \\bigg|_{X,N} = \\frac{\\partial S}{\\partial E_B} \\bigg|_{X,N}. \\quad \\text{Q.E.D.}\n\\] Notice in the above proof that we paid no attention to how the system reached equilibrium, only that it did eventually reached equilibrium, meaning that it satisfies the microcanonical probability distribution. Let’s look now at the first law.\nFirst Law: Consider a system having some form of mechanical work done on it by a force \\(J\\). It’s also allowed to exchange particles with the environment via a chemical potential \\(\\mu\\). If the force causes a differential displacement \\(dX\\) and \\(dN\\) particles are exchanged, then the total change in energy is given in differential form by \\[\ndE = TdS + J \\cdot dX + \\mu \\cdot dN.\n\\] Proof: Let’s calculate the change in the system’s entropy when a differential amount of work is done on the system. The amount of work done on a system in response to a displacement \\(\\delta X\\) and particle exchange \\(\\delta N\\) is given by \\[\n\\delta E = J \\cdot \\delta X + \\mu \\cdot \\delta N.\n\\] Suppose the system is initially at a constant energy \\(E\\) and increased by \\(\\delta E\\). Then to first order we have \\[\n\\begin{align*}\n\\delta S &= S(E+\\delta E, X+\\delta X, N+\\delta N) - S(E,X,N) \\\\\n&= \\frac{\\partial S}{\\partial E} \\bigg|_{X,N} (J \\cdot \\delta X + \\mu \\cdot \\delta N) + \\frac{\\partial S}{\\partial X} \\bigg|_{E,N} \\delta X + \\frac{\\partial S}{\\partial N} \\bigg|_{E,X} \\delta N \\\\\n&= \\bigg(\\frac{J}{T} - \\frac{\\partial S}{\\partial X} \\bigg|_{E,N}\\bigg)\\delta X + \\bigg(\\frac{N}{T} - \\frac{\\partial S}{\\partial N} \\bigg|_{E,X}\\bigg)\\delta N. \\\\\n\\end{align*}\n\\] Now, at equilibrium we must have \\(\\delta S = 0\\) for any \\(\\delta X\\) and \\(\\delta N\\). This means each term must vanish, giving \\[\n\\delta S = \\frac{1}{T} \\delta E - \\frac{J}{T} \\delta X - \\frac{\\mu}{T} \\delta N. \\quad \\text{Q.E.D.}\n\\] Using the first law, we can now find any other thermodynamic quantity of interest once we have the entropy. We have \\[\n\\begin{align*}\n\\frac{1}{T} &= \\frac{\\partial S}{\\partial E} \\bigg |_{X,N} \\ , \\\\\n-\\frac{J}{T} &= \\frac{\\partial S}{\\partial X} \\bigg |_{E,N} \\ , \\\\\n-\\frac{\\mu}{T} &= \\frac{\\partial S}{\\partial N} \\bigg |_{E,X} \\ . \\\\\n\\end{align*}\n\\] This gives us a sort of recipe we can use to calculate equations of state for systems in the microcanonical ensemble:\n\nCalculate \\(\\Omega(E,X,N)\\) and use that to get the entropy via \\(S = k_B \\log \\Omega\\).\nUse the first law to get other thermodynamic variables of interest via \\[\ndS =  \\frac{1}{T} dE -  \\frac{J}{T} \\cdot dX - \\frac{\\mu}{T} \\cdot dN.\n\\]\n\nThe second law is trivial. We’ve essentially already proved it.\nSecond Law: The entropy of a system is non-decreasing over time.\nProof: We’ve already shown this. For any two subsystems \\(A\\) and \\(B\\), suppose they start with energies \\(E_A^0\\) and \\(E_B^0\\). Over time the system will move to equilibrium to reach a maximum entropy, with energies of \\(E_A^*\\) and \\(E_B^*\\). It must be the case then that \\[\nS(E_A) + S(E_B) \\leq S(E_A^*) + S(E_B^*). \\quad \\text{Q.E.D.}\n\\]\nIt turns out that we can’t derive the third law from classical statistical mechanics alone. For that we’ll need quantum statistical mechanics, a topic we’ll get to later. Let’s go ahead and also check the stability conditions though while we’re here. For entropy to be maximized at equilibrium, we require the entropy near equilibrium to be concave, i.e. \\[\n\\frac{\\partial^2}{\\partial E_A^2} S(E_A^*) \\bigg|_{X,N} - \\frac{\\partial^2}{\\partial E_B^2} S(E_B^*) \\bigg|_{X,N} \\leq 0.\n\\] Using the same logic as we did in the thermodynamics lesson, we can then show this implies the heat capacity of the system be non-negative. Moreover, the requirement that any second-order perturbations be non-positive requires \\(\\frac{\\partial^2 S}{\\partial X_i \\partial X_j}\\) to be positive-definite at any constant energy \\(E\\).\n\n\nExample: Two-State Systems\nLet’s consider a simple example of a system we can actually solve in the microcanonical ensemble, indeed one of the few we can solve. Suppose we have a collection of particles that can take on only one of two states. We can imagine only caring about the spin of an electron, for example, in which case the two states would be spin-up and spin-down for each electron. Since there are only two states we can’t really think in terms of phase space in this case, so we have to cheat a bit. We’ll just sum over all states instead of integrating over phase space.\nSuppose each particle can take on an energy of the form \\(\\varepsilon n_i\\) where \\(n_i=0,1\\). That is, the particle has no energy if the state is down and a constant \\(\\varepsilon\\) energy if the spin is up. Then for \\(N\\) particles the Hamiltonian will just be the sum of all these energies, \\[\nH = \\sum_{i=0}^N \\varepsilon n_i \\equiv \\varepsilon N_1.\n\\] On the right we just defined \\(N_1\\) to be the total number of all states that are up. In the microcanonical we assert that \\(H\\) is held to a constant energy \\(E\\). This means we can also write \\(N_1 = \\frac{E}{\\varepsilon}\\).\nNow, to find \\(\\Omega(E,N)\\) observe the following fact: The number of total states with energy \\(E\\) is equivalent to the number of ways of choosing exactly \\(N_1\\) particles with state up out of a total of \\(N\\) particles. Assuming both \\(N\\) and \\(N_1\\) are large, we have \\[\n\\Omega(E,N) = \\binom{N}{N_1} = \\frac{N_1!}{N_1!(N-N_1)!} \\approx \\frac{N^N}{N_1^{N_1}(N-N_1)^{N-N_1}} \\ .\n\\] The entropy of such a system is thus \\[\n\\begin{align*}\nS &= k_B \\log \\Omega(E) \\\\\n&= k_B \\bigg[\\log N - \\frac{N_1}{N}\\log N_1 - \\frac{N-N_1}{N}\\log (N-N_1) \\bigg] \\\\\n&= -Nk_B \\bigg[\\frac{E}{N\\varepsilon}\\log\\frac{E}{N\\varepsilon} + \\bigg(1-\\frac{E}{N\\varepsilon}\\bigg) \\log \\bigg(1-\\frac{E}{N\\varepsilon}\\bigg) \\bigg].\n\\end{align*}\n\\] From this we can get the temperature in terms of the energy, \\[\n\\frac{1}{T} = \\frac{\\partial S}{\\partial E} \\bigg |_N = \\frac{k_B}{\\varepsilon} \\log \\frac{E}{N\\varepsilon-E}.\n\\] If we like, we can then solve for the energy in terms of the temperature to get \\[\nE(T) = \\frac{N\\varepsilon}{1 + e^{\\frac{\\varepsilon}{k_B T}}}.\n\\] One interesting property of the two-state system is that it can in principle take on negative temperatures. This comes from the fact that the energy \\(E\\) can take on any value between \\(0\\) (all states down) and \\(N\\varepsilon\\) (all states up). Having \\(E \\leq \\frac{1}{2} N\\varepsilon\\) corresponds to positive temperatures, while having \\(E \\geq \\frac{1}{2} N\\varepsilon\\) corresponds to negative temperatures. Negative temperatures are counter-intuitive since they implies that entropy increases when energy is taken out of the system, not put in. In practice this isn’t an issue, since the system must always be in thermal contact with a heat bath, which forces it to have positive temperature.\nIf we like we can use \\(E(T)\\) to calculate the heat capacity by differentiating with respect to \\(T\\), \\[\nC(T) = \\frac{\\partial E}{\\partial T} \\bigg |_{N} = Nk_B \\bigg(\\frac{\\varepsilon}{k_B T}\\bigg)^2 \\frac{e^{\\frac{\\varepsilon}{k_B T}}}{\\big(1 + e^{\\frac{\\varepsilon}{k_B T}}\\big)^2}.\n\\] By looking at the limited cases where \\(\\varepsilon \\ll k_B T\\) and \\(\\varepsilon \\gg k_B T\\), it’s easy to see that \\(C(T) \\rightarrow 0\\) both as \\(T \\rightarrow 0\\) and as \\(T \\rightarrow \\infty\\). Vanishing at low temperatures has to do with the discrete energy gap for each particle, while vanishing at high temperatures has to do with energy saturation due to the finite number of states allowed.\nNotice that if we divide \\(E\\) by \\(\\varepsilon\\) what’s left is dimensionless. In fact, it’s just the mean number of particles with state up, i.e. \\[\n\\langle n \\rangle = \\frac{N}{1 + e^{\\frac{\\varepsilon}{k_B T}}}.\n\\] It’s also worth asking what \\(p(n)\\) is, the probability for a given particle to be up or down. Evidently that probability should be \\(p(0) = \\frac{N-N_1}{N}\\) and \\(p(1) = \\frac{N_1}{N}\\). Plugging in \\(N_1 = \\frac{E(T)}{\\varepsilon}\\), we can write the expression as \\[\np(n) = \\delta(n) \\frac{1}{1 + e^{-\\frac{\\varepsilon}{k_B T}}} + \\delta(n-1) \\frac{e^{-\\frac{\\varepsilon}{k_B T}}}{1 + e^{-\\frac{\\varepsilon}{k_B T}}}.\n\\] The shape of this curve depends on the temperature. At low temperatures \\(p(0) \\approx 1\\). At high temperatures \\(p(1) \\approx 1\\). And when \\(\\varepsilon \\approx k_B T\\) we get \\(p(0) \\approx p(1) \\approx \\frac{1}{2}\\).\n\n\nExample: Einstein Solids\nA similar example to the two-state system is the Einstein solid. An Einstein solid is a simple model of a solid that treats it as a lattice of \\(N\\) particles, where each particle is treated as a collection of 3 discrete harmonic oscillators, one for each orthogonal direction of space. Each oscillator can take on energies in discrete units of \\(\\varepsilon=\\hbar \\omega\\). We’ll assume each oscillator has the same frequency \\(\\omega\\).\nSince energies must be units of \\(\\varepsilon\\), for any fixed energy \\(E\\) there must be \\(n=n(E)\\) total states with that given energy, with \\(E=\\varepsilon n\\). We can ask how many states \\(\\Omega(E,N)\\) there are among \\(N\\) particles in a lattice with a given energy \\(E\\). Finding \\(\\Omega(E,N)\\) turns out to be equivalent to finding the number of ways to put \\(n\\) pebbles into \\(3N\\) containers, which turns out to be \\[\n\\Omega(E,N) = \\binom{3N+n-1}{n} \\approx \\frac{(3N+n)^{3N+n}}{(3N)^{3N} n^n}.\n\\] This looks similar to the two-state problem above, except with \\(N \\rightarrow 3N+n-1\\) and \\(N_1 \\rightarrow n\\). In this case though the energy as a function of temperature turns out to be given by \\[\nE(T) = \\frac{3N\\varepsilon}{e^{\\frac{\\varepsilon}{k_B T}}-1}.\n\\] In the low-temperature limit \\(E \\rightarrow 0\\). In the high-temperature limit we get \\(E \\approx 3Nk_B T\\). This is in fact what the equipartition theorem would predict, since each particle has 6 quadratic degrees of freedom, 3 kinetic and 3 potential.\nThe curve for the heat capacity changes somewhat as well. We get \\[\nC(T) = \\frac{\\partial E}{\\partial T} \\bigg |_{N} = 3Nk_B \\bigg(\\frac{\\varepsilon}{k_B T}\\bigg)^2 \\frac{e^{\\frac{\\varepsilon}{k_B T}}}{\\big(e^{\\frac{\\varepsilon}{k_B T}} - 1\\big)^2}.\n\\] For high temperatures the heat capacity evidently levels off to \\(C(T) \\approx 3Nk_B\\). This fact turns out to agree well with experiment, yielding the so-called Dulong-Petit Law. However, while the heat capacity should go to zero as \\(T \\rightarrow 0\\), the exact curve itself deviates from experiment at low temperatures. This discrepancy can be rectified by using more accurate models of a solid like the Debye model."
  },
  {
    "objectID": "statistical-mechanics/classical-stat-mech.html#distinguishability",
    "href": "statistical-mechanics/classical-stat-mech.html#distinguishability",
    "title": "Classical Statistical Mechanics",
    "section": "Distinguishability",
    "text": "Distinguishability\nWe’d like to use the microcanonical ensemble to work out the relations for a more interesting system, like an ideal gas. It turns out however that there’s some subtly involved that we need to address in applying statistical mechanics to realistic systems.\n\nExample: Ideal Gas\nLet’s start by trying to derive the ideal gas expressions using only what we’ve covered so far and seeing where things go wrong. Suppose an isolated system of gas particles has the non-interacting Hamiltonian for an ideal gas, namely \\[\nH(\\mathbf{x}_1,\\cdots,\\mathbf{x}_N,\\mathbf{p}_1,\\cdots,\\mathbf{p}_N) = \\sum_{i=1}^N \\frac{\\mathbf{p}_i^2}{2m} + V(\\mathbf{x}_1,\\cdots,\\mathbf{x}_N),\n\\] where the potential energy \\(V(\\mathbf{x}_1,\\cdots,\\mathbf{x}_N)\\) is zero inside a container of volume \\(V\\) and infinite otherwise. To calculate the equations of state we first need to find \\(\\Omega(E,V,N)\\). Integrating over the volume of the box and all valid momenta, we get \\[\n\\Omega(E,V,N) = \\int_{\\frac{\\mathbf{p}^2}{2m} = E} d^{3N} \\mathbf{x} \\ d^{3N} \\mathbf{p} = V^N  \\int_{|\\mathbf{p}| = \\sqrt{2mE}} d^{3N} \\mathbf{p} \\equiv V^N \\Sigma_{3N}.\n\\] The integral \\(\\Sigma_{3N}\\) is the surface area of a \\(3N\\)-dimensional hypersphere in momentum space of radius \\(R=\\sqrt{2mE}\\).\nTo make anymore progress we need to figure out what the surface area of a \\(d\\)-dimensional hypersphere is. Now, notice we can write the \\(d\\)-dimensional volume element as \\(d^d \\mathbf{x} = R^{d-1} dR \\ d\\Omega_{d-1}\\), where \\(d\\Omega_{d-1}\\) is the \\(d-1\\) dimensional solid angle. For a hypersphere we can factor the integral. If \\(S_d \\equiv \\int d\\Omega_{d-1}\\), then we have \\(\\Sigma_{d} = S_d R^{d-1}\\). Here \\(S_d\\) is a constant that depends only on the dimension \\(d\\). To find \\(S_d\\), the trick is to use the fact that the integral of a \\(d\\)-dimensional Gaussian is just \\[\nI_d \\equiv \\int d^d \\mathbf{x} \\ e^{-\\mathbf{x}^2} = \\bigg(\\int dx \\ e^{-x^2}\\bigg)^d = \\pi^{d/2}.\n\\] By changing variables to spherical coordinates, it’s easy to show \\[\nI_d = \\int R^{d-1} dR \\ d\\Omega_{d-1} \\ e^{-R^2} = \\frac{1}{2} \\bigg(\\frac{d}{2}-1\\bigg)! \\ S_d.\n\\] Equating the two expressions, we can solve for \\(S_d\\) and finally get the surface area of a \\(d\\)-dimensional hypersphere, \\[\n\\Sigma_d = \\frac{2\\pi^{d/2}}{\\big(\\frac{d}{2}-1\\big)!} R^{d-1}.\n\\] Back to the problem at hand. Plugging all this in, we finally get a multiplicity of \\[\n\\Omega(E,V,N) = \\frac{2\\pi^{\\frac{3N}{2}}}{\\big(\\frac{3N}{2}-1\\big)!} V^N (2mE)^{\\frac{3N-1}{2}} \\approx 2 V^N \\bigg(\\frac{4\\pi m E}{3N}\\bigg)^{3N/2}.\n\\] The right–hand side is simplified using Stirling’s approximation \\(N! \\sim N^N e{-N}\\). The entropy is then \\(S = k_B \\log \\Omega\\). If we ignore terms of order less than \\(O(N)\\), up to an added constant we get the same result we found using kinetic theory, namely \\[\nS = Nk_B \\log V\\bigg(\\frac{4\\pi emE}{3N}\\bigg)^{3/2}.\n\\] Aside: Suppose we didn’t know the energy \\(E\\) exactly, but only within some range \\(E \\pm \\delta E\\). In that case, the hypersphere radius would have an uncertainty \\(\\delta R = \\sqrt{\\frac{m}{2E}} \\delta E\\). The effect of this is that \\(\\Omega\\) now gains a multiplicative factor of \\(\\delta R\\). This causes the entropy to then gain an additive factor of \\(k_B \\log \\delta R \\propto \\log \\frac{\\delta E}{\\sqrt{E}}\\). Since energy is extensive, this new added factor will be \\(O(\\log N)\\), which is small compared to the original terms of \\(O(N)\\), and can hence be neglected. The net effect of all this is that none of the thermodynamic variables get materially affected by the uncertainty. For this reason we’ll ignore it from now on.\nUsing the entropy we can now proceed to calculate the temperature, pressure, and chemical potential. The equation for temperature gives the usual energy relation for a monoatomic ideal gas, \\[\n\\frac{1}{T} = \\frac{\\partial S}{\\partial E} \\bigg |_{X,N} = \\frac{3Nk_B}{2E} \\quad \\Longrightarrow \\quad E = \\frac{3}{2} Nk_B T.\n\\] The equation for the pressure gives the usual ideal gas law, \\[\nP = T \\frac{\\partial S}{\\partial V} \\bigg |_{E,N} = \\frac{Nk_B T}{V} \\quad \\Longrightarrow \\quad PV = Nk_B T.\n\\] Both of these seem perfectly fine. The problem, however, comes when we try to evaluate the chemical potential. We’d get \\[\n\\mu = -T \\frac{\\partial S}{\\partial N} \\bigg |_{E,V} = - k_B T \\bigg[\\log V\\bigg(\\frac{4\\pi mE}{3N}\\bigg)^{3/2} - \\frac{3}{2} \\bigg].\n\\] Now, the problem here is that the chemical potential should be intensive, but it’s not. It’s proportional to \\(\\log V\\). The same problem showed up in the entropy as well. The entropy should be extensive, yet it’s proportional to \\(V\\log N\\). It seems like we should have to divide by something else extensive inside the logarithm to cancel the effect of the \\(V\\).\n\n\nGibbs’ Paradox\nTo resolve this issue let’s look at another toy problem. Consider the mixing entropy of a container containing two distinct ideal gases of different types. Suppose the container initially split into two components, the first a gas with configuration \\((S_1,N_1,V_1)\\) and the second a gas with configuration \\((S_2,N_2,V_2)\\). Assume the system is at equilibrium, so both systems have the same temperature \\(T\\). An adiabatic wall is then removed, so the two gases are allowed to mix and come to a new equilibrium of the same temperature. The initial total entropy \\(S_i\\) in the container is evidently given by \\(S_i = S_1 + S_2\\), i.e. \\[\nS_i = k_B \\bigg( N_1 \\log V_1 + \\frac{3}{2} N_1 \\log 2\\pi e m_1 k_B T\\bigg) + k_B \\bigg(N_2 \\log V_2 + \\frac{3}{2} N_2 \\log 2\\pi e m_2 k_B T\\bigg),\n\\] where we’ve used the fact that \\(E = \\frac{3}{2} N k_B T\\). To find the final total entropy \\(S_f\\), observe that at the new equilibrium both gases should fill up the entire box uniformly, meaning \\(V_1 = V_2 = V\\), hence \\[\nS_f = k_B \\bigg( N_1 \\log V + \\frac{3}{2} N_1 \\log 2\\pi e m_1 k_B T\\bigg) + k_B \\bigg(N_2 \\log V + \\frac{3}{2} N_2 \\log 2\\pi e m_2 k_B T\\bigg).\n\\] All together, this means the change in total entropy is given by \\[\n\\Delta S = S_f - S_i = k_B \\bigg(N_1 \\log \\frac{V}{V_1} + N_2 \\log \\frac{V}{V_2}\\bigg).\n\\] So what’s the problem here? Well, suppose the two gases were the same, and we opened the adiabatic wall and allowed them to mix? What should happen physically? Nothing. They’re the same gas, at the same temperature. The thermodynamic variables shouldn’t change at all, meaning we should have \\(\\Delta S = 0\\). On the other hand, if the two gases were distinct, we should expect the total entropy of the system to increase like shown. This conundrum is known as the Gibbs Paradox.\nThe solution to this paradox is to notice that we have to treat identical systems separately from distinguishable systems. If a system is distinguishable we’re fine as is. But if a system is identical we have to account for the fact that we’re overcounting \\(\\Omega\\) any time we count two identical systems as distinct. The way to fix this is pretty easy. Just divide \\(\\Omega\\) by the number of ways to permute the particles in each identical system.\nTo resolve the above paradox and the issue with extensively, notice that if we have an ideal gas of \\(N\\) particles then we’re overcounting \\(\\Omega\\) by a factor of \\(N!\\), the number of ways to permute a set of \\(N\\) identical particles. Then \\(\\Omega\\) for an ideal gas becomes \\[\n\\Omega(E,V,N) = \\frac{V^N}{N!}\\frac{2\\pi^{\\frac{3N}{2}}}{\\big(\\frac{3N}{2}-1\\big)!} (2mE)^{\\frac{3N-1}{2}} \\approx 2\\bigg(\\frac{Ve}{N}\\bigg)^N \\bigg(\\frac{4\\pi m E}{3N}\\bigg)^{3N/2}.\n\\] This means the entropy \\(S\\) then becomes \\[\nS = Nk_B \\bigg[\\log \\frac{V}{N}\\bigg(\\frac{4\\pi mE}{3N}\\bigg)^{3/2} + \\frac{5}{2}\\bigg],\n\\] and hence that the chemical potential \\(\\mu\\) becomes \\[\n\\mu = - k_B T \\log \\frac{V}{N}\\bigg(\\frac{4\\pi mE}{3N}\\bigg)^{3/2}.\n\\] Now it appears that we’re dividing \\(V\\) by \\(\\frac{N}{e}\\) inside the logarithm, which makes \\(S\\) is properly extensive and \\(\\mu\\) properly intensive.\nTo resolve the Gibbs paradox, notice that if the two gases are distinct, we have to divide \\(\\Omega\\) by \\(N_1!N_2!\\). This ultimately gives \\[\n\\Delta S = k_B \\bigg(N_1 \\log \\frac{V}{V_1} + N_2 \\log \\frac{V}{V_2}\\bigg),\n\\] which is of course what we had before. If the two gases are identical, we instead have to divide \\(\\Omega\\) by \\(N!\\). This ultimately gives \\[\n\\Delta S = k_B \\bigg[(N_1+N_2) \\log \\frac{V}{N_1+N_2} - N_1 \\log \\frac{V_1}{N_1} - N_2 \\log \\frac{V_2}{N_2}\\bigg] = 0\n\\] since at equilibrium (both initially and finally) we must have \\(\\frac{V}{N}=\\frac{V_1}{N_1}=\\frac{V_2}{N_2}\\). The paradox is thus resolved.\nThis resolves one of the problems we had with the expressions for an ideal gas, but there’s one more. If we look careful, we can see that the expression inside the logarithm isn’t dimensionless, as it should be. In fact, it has units of action to some power. Recall that action has units of position times momentum, or energy times time. The dimensionality issue ultimately arises from the fact that we’re working with a continuous system and integrating over phase space. But phase space has units. To fix this problem, all we have to do is divide the phase space measure \\(d \\mathbf{x} d\\mathbf{p}\\) by some constant with units of action cubed. From quantum mechanics, it turns out the right constant to use is Planck’s constant \\(h\\). We thus need to make the substitution of measure \\[\nd^3 \\mathbf{x} d^3 \\mathbf{p} \\rightarrow \\frac{d^3 \\mathbf{x} d^3 \\mathbf{p}}{h^3}.\n\\] These two facts together resolve our problems. For \\(N\\) particles all of the same type, we substitute the following measures \\[\nd^{3N} \\mathbf{x} \\ d^{3N} \\mathbf{p} \\rightarrow\n\\begin{cases}\n\\frac{d^{3N} \\mathbf{x} \\ d^{3N} \\mathbf{p}}{h^{3N}} & N \\ \\text{distinguishable particles}, \\\\\n\\frac{d^{3N} \\mathbf{x} \\ d^{3N} \\mathbf{p}}{N! \\ h^{3N}} & N \\ \\text{identical particles}. \\\\\n\\end{cases}\n\\]\nFor an ideal gas, the right measure to use is the second one. Plugging this in, we finally get an entropy of \\[\nS = Nk_B \\bigg[\\log \\frac{V}{N}\\bigg(\\frac{4\\pi mE}{3Nh^2}\\bigg)^{3/2} + \\frac{5}{2}\\bigg].\n\\] This result, the correct entropy of a classical ideal gas, is known as the Sakur-Tetrode equation. The chemical potential is then \\[\n\\mu = - k_B T \\log \\frac{V}{N}\\bigg(\\frac{4\\pi mE}{3Nh^2}\\bigg)^{3/2}.\n\\] To finish up this section, it’s worth mentioning that statistical mechanics gives us even more information than thermodynamics gives us. Not only does it tell us what the variables are, but it can also tell us how variables are distributed. For example, we can derive the Maxwell-Boltzmann distribution for the momentum (or velocity) of a single gas particle. Indeed, we have \\[\n\\begin{align*}\np(\\mathbf{p}) &= \\frac{V^N}{\\Omega(E,V,N)} \\int_{|\\mathbf{p}| = \\sqrt{2mE}} d^{3N-1} \\mathbf{p} \\\\\n&= V\\frac{\\Omega\\big(E-\\frac{\\mathbf{p}^2}{2m},V,N-1\\big)}{\\Omega(E,V,N)} \\\\\n&= \\bigg(1 - \\frac{\\mathbf{p}^2}{2mE}\\bigg)^{3N/2-2} \\frac{1}{(2\\pi m E)^{3/2}} \\frac{(\\frac{3N}{2}-1)!}{(\\frac{3(N-1)}{2}-1)!} \\\\\n&\\approx \\bigg(\\frac{3N}{4\\pi m E}\\bigg)^{3/2} \\exp\\bigg(-\\frac{3N\\mathbf{p}^2}{4mE}\\bigg). \\\\\n\\end{align*}\n\\] The last line follows from the fact that \\(E\\) is extensive and \\(N \\gg 1\\), hence we can use the identity \\(e^x \\approx \\big(1+\\frac{x}{N}\\big)^{N}\\). Using the relation \\(E = \\frac{3}{2} N k_B T\\) then gives the usual form of the Maxwell-Boltzmann distribution.\n\n\nExample: Ultrarelativistic Ideal Gas\nA similar example is the ultrarelativistic ideal gas. Recall from special relativity that the kinetic energy of a particle is given by the relativistic energy formula \\[\nE^2 = m^2c^4 + \\mathbf{p}^2 c^2.\n\\] In the limit where \\(|\\mathbf{p}| \\ll mc\\) we recover the classical kinetic energy \\(E=\\frac{\\mathbf{p}^2}{2m}\\). We can also ask about the limit where \\(|\\mathbf{p}| \\gg mc\\). This is called the ultrarelativistic limit. This limit includes massless particles like photons or neutrinos that move at or near the speed of light. In this limit the kinetic energy is just \\(E=|\\mathbf{p}| c\\).\nLet’s again suppose we have a gas of \\(N\\) non-interacting particles, but that they’re ultrarelativistic. In that case, the Hamiltonian is \\[\nH(\\mathbf{x}_1,\\cdots,\\mathbf{x}_N,\\mathbf{p}_1,\\cdots,\\mathbf{p}_N) = \\sum_{i=1}^N |\\mathbf{p}_i| c + V(\\mathbf{x}_1,\\cdots,\\mathbf{x}_N).\n\\] We’ll again assume the potential is zero inside a container of volume \\(V\\) and infinite otherwise. We proceed as usual by trying to find \\(\\Omega(E,V,N)\\). Supposing we’re dealing with a gas of \\(N\\) identical particles, we have \\[\n\\Omega(E,V,N) = \\frac{1}{N!h^{3N}} \\int_{E=|\\mathbf{p}| c} d^{3N} \\mathbf{x} \\ d^{3N} \\mathbf{p} = \\frac{V^N}{N!h^{3N}} \\int_{E=|\\mathbf{p}| c} d^{3N} \\mathbf{p}.\n\\] Again note that the momentum space integral is over a \\(3N\\)-dimensional hypersphere, this time of radius \\(R=\\frac{E}{c}\\). Thus, \\[\n\\Omega(E,V,N) = \\frac{V^N}{N!h^{3N}} \\Sigma_{3N} \\approx 2 \\bigg[\\frac{eV}{N} \\bigg(\\frac{2\\pi e E^2}{3h^2c^2 N}\\bigg)^{3/2}\\bigg]^N.\n\\] Again keeping terms only to \\(O(N)\\), the entropy is thus given by \\[\nS = N k_B \\bigg[\\log \\frac{V}{N} \\bigg(\\frac{2\\pi E^2}{3h^2c^2 N}\\bigg)^{3/2} + \\frac{5}{2}\\bigg].\n\\] It’s worth noting that the entropy in this case is no longer properly extensive, as it contains a term of order \\(O(N \\log N)\\) due to the presence of the \\(E^2\\) in the logarithm. There’s no obvious way to fix this problem. In fact, an ultrarelativistic gas is super-extensive. It’s in a class of systems with so-called anonomous scaling behaviors. In practice this isn’t a huge deal.\nWe can calculate the temperature the usual way. We have \\[\n\\frac{1}{T} = \\frac{\\partial S}{\\partial E} \\bigg |_{V,N} = \\frac{3Nk_B}{E} \\quad \\Longrightarrow \\quad E = 3Nk_B T.\n\\] Notice the entropy depends on volume in the same way as it does for the classical ideal gas. Indeed, we have \\[\n\\frac{P}{T} = \\frac{\\partial S}{\\partial V} \\bigg |_{E,N} = \\frac{Nk_B}{V} \\quad \\Longrightarrow \\quad PV = Nk_B T.\n\\] The chemical potential follows similarly. Following the same kind of calculation as before, we get \\[\n\\mu = - k_B T \\log \\frac{V}{N}\\bigg(\\frac{2\\pi E^2}{3c^2h^2N}\\bigg)^{3/2}.\n\\] Since the entropy isn’t properly extensive, the chemical potential evidently isn’t properly intensive as we’d expect. It’s not hard to show that the distribution of momenta is now longer a Gaussian either. It’s in fact a Laplace distribution, with \\[\np(\\mathbf{p}) = \\frac{3Nc}{2E} \\exp\\bigg(-\\frac{3N|\\mathbf{p}|c}{E}\\bigg) = \\frac{c}{2k_B T} \\exp\\bigg(-\\frac{|\\mathbf{p}| c}{k_B T}\\bigg).\n\\]\n\n\nExample: Hard Sphere Gas\nLet’s look at another problem similar to the ideal gas. Suppose that we have a gas of \\(N\\) non-interacting solid spheres each of volume \\(\\omega \\ll V\\), where \\(V\\) is again the volume of the container. The Hamiltonian otherwise remains the same as for the ordinary ideal gas. If we assume the spheres are indistinguishable, following the same logic as for the ordinary ideal gas we can write the multiplicity as \\[\n\\Omega(E,V,N) = \\frac{1}{N!}\\frac{2\\pi^{\\frac{3N}{2}}}{\\big(\\frac{3N}{2}-1\\big)!} (2mE)^{\\frac{3N-1}{2}} \\mathcal{V}_{N}.\n\\] Here \\(\\mathcal{V}_{N}\\) represents the volume integral over all \\(N\\) particles. For the ordinary ideal gas we just had \\(\\mathcal{V}_{N} = V^N\\). Now, imagine putting the spheres into the container one at a time. The first one could occupy the volume \\(V\\). The second would be the full volume minus the volume of the first sphere, so \\(V-\\omega\\). The third would be the full volume minus the volumes of the first two spheres, so \\(V-2\\omega\\). And so on until the last sphere, which would have an available volume of \\(V-(N-1)\\omega\\). Assuming \\(\\omega \\ll V\\), we can approximate \\(\\mathcal{V}_N\\) as \\[\n\\begin{align*}\n\\mathcal{V}_N &= V\\big(V-\\omega\\big)\\big(V-2\\omega\\big)\\cdots\\big(V-(N-1)\\omega\\big) \\\\\n&= V^N \\prod_{j=1}^{N-1}\\bigg(1-j\\frac{\\omega}{V}\\bigg) \\\\\n&\\approx V^N \\bigg(1-\\frac{N(N-1)}{2}\\frac{\\omega}{V}\\bigg) \\\\\n&\\approx V^N \\bigg(1-\\frac{N^2}{2}\\frac{\\omega}{V}\\bigg) \\\\\n&\\approx \\bigg(V-\\frac{N\\omega}{2}\\bigg)^N. \\\\\n\\end{align*}\n\\] Effectively, this says the total available volume for each particle in the container to explore gets reduced from \\(V\\) to \\(V-\\frac{N\\omega}{2}\\). The term \\(\\frac{N\\omega}{2}\\) is called the excluded volume. The multiplicity is evidently then \\[\n\\Omega(E,V,N) = \\frac{\\big(V-\\frac{N\\omega}{2}\\big)}{N!}\\frac{2\\pi^{\\frac{3N}{2}}}{\\big(\\frac{3N}{2}-1\\big)!} (2mE)^{\\frac{3N-1}{2}} \\approx 2\\bigg(\\frac{\\big(V-\\frac{N\\omega}{2}\\big)e}{N}\\bigg)^N \\bigg(\\frac{4\\pi m E}{3N}\\bigg)^{3N/2}.\n\\] This is exactly what we had for the ordinary ideal gas, except with \\(V\\) replaced by \\(V-\\frac{1}{2}N\\omega\\). This means the entropy is just \\[\nS = Nk_B \\bigg[\\log \\frac{V-\\frac{N\\omega}{2}}{N}\\bigg(\\frac{4\\pi mE}{3N}\\bigg)^{3/2} + \\frac{5}{2}\\bigg].\n\\] Clearly the equation for temperature isn’t affected at all. We still have \\(E = \\frac{3}{2} N k_B T\\). The equation for pressure though does change though. Since we’re differentiating \\(S\\) with respect to \\(V\\) and not \\(V-\\frac{1}{2}N\\omega\\), we have \\[\n\\frac{P}{T} = \\frac{\\partial S}{\\partial V} \\bigg |_{E,N} = \\frac{Nk_B}{V-\\frac{N\\omega}{2}} \\quad \\Longrightarrow \\quad P\\bigg(V-\\frac{N\\omega}{2}\\bigg) = Nk_B T.\n\\] The ideal gas law is thus slightly modified by reducing the volume from \\(V\\) to the available volume \\(V-\\frac{N\\omega}{2}\\).\nIncidentally, the hard sphere gas is almost a good model of a real interacting gas away from the dense limit. One change that can make it even more accurate is to reduce not just the volume, but also the pressure, to account for the fact that interactions tend to make particles slightly less likely to be near the walls of the container instead of around the center. This slight generalization will give us the van der Waals equation, which we’ll derive when we get to interacting particles."
  },
  {
    "objectID": "statistical-mechanics/classical-stat-mech.html#canonical-ensemble",
    "href": "statistical-mechanics/classical-stat-mech.html#canonical-ensemble",
    "title": "Classical Statistical Mechanics",
    "section": "Canonical Ensemble",
    "text": "Canonical Ensemble\nWhile the microcanonical ensemble is easy to understand, it’s usually not the easiest ensemble to work with for most problems. Usually finding the multiplicity \\(\\Omega(M)\\) directly isn’t easy since it involves a high level of combinatorial insight. Another approach we can take is to not take \\(M=(E,X,N)\\), but to instead take \\(M=(T,X,N)\\). That is, we consider a system with a fixed temperature, not a fixed energy. Physically, this means considering not an isolated system, but a closed system. We assume our system of interest is placed in contact with a large environment, or heat bath, and allowed to come to equilibrium. The system inherits its temperature from the heat bath and is allowed to exchange heat with it.\n\nBoltzmann Distribution\nTo derive the probability distribution for a canonical system let’s first consider the combined system of our system of interest plus the heat bath. We’ll suppose the combined system is isolated, meaning it follows the microcanonical ensemble. Denote the system of interest as \\(S\\), the heat bath as \\(R\\), and the combined system as \\(RS\\). The total energy \\(E\\) is just the sum of the Hamiltonians of \\(S\\) and \\(R\\) at a given point in their respective phase spaces, \\[\nE = H_R(\\boldsymbol{\\mu}_R) + H_S(\\boldsymbol{\\mu}_S).\n\\] In the microcanonical ensemble the probability of any given state \\((\\boldsymbol{\\mu}_R,\\boldsymbol{\\mu}_S)\\) is then just \\[\np_{RS}(\\boldsymbol{\\mu}_R,\\boldsymbol{\\mu}_S) = \\frac{1}{\\Omega_{RS}} \\delta\\big(E-H_R(\\boldsymbol{\\mu}_R)-H_S(\\boldsymbol{\\mu}_S)\\big).\n\\] To get the probability we seek, the probability of system states we need to find \\(p_S(\\boldsymbol{\\mu}_S)\\). By marginalizing, we have \\[\n\\begin{align*}\np_S(\\boldsymbol{\\mu}_S) &= \\int d \\boldsymbol{\\mu}_R \\ p_{RS}(\\boldsymbol{\\mu}_R,\\boldsymbol{\\mu}_S) \\\\\n&= \\frac{1}{\\Omega_{RS}} \\Omega_R\\big(E-H_S(\\boldsymbol{\\mu}_S)\\big) \\\\\n&= \\frac{1}{\\Omega_{RS}}\\exp\\bigg(\\frac{1}{k_B}S_R\\big(E-H_S(\\boldsymbol{\\mu}_S)\\big)\\bigg).\n\\end{align*}\n\\] Now, we assume the heat bath is much larger than the system of interest. This means the \\(S_{RS} \\approx S_R\\) and the total energy \\(E \\gg H_S\\). If we Taylor expand \\(S_R\\) about \\(E\\), to first order we thus have \\[\nS_R\\big(E-H_S(\\boldsymbol{\\mu}_S)\\big) \\approx S_{RS}(E) - \\frac{\\partial S_{RS}}{\\partial E} H_S(\\boldsymbol{\\mu}_S).\n\\] Since the heat bath is fixed at a temperature \\(T\\), we can write the partial derivative as \\(\\frac{\\partial S_R}{\\partial E} = \\frac{1}{T}\\). Plugging back in, we have \\[\np_S(\\boldsymbol{\\mu}_S) \\approx \\frac{e^{\\frac{1}{k_B} S_{RS}(E)}}{\\Omega_{RS}}e^{-\\frac{1}{k_B T} H_S(\\boldsymbol{\\mu}_S)}.\n\\] For convenience we’ll define \\(\\beta \\equiv \\frac{1}{k_B T}\\). Notice the first term above is just some normalization constant that we’ll denote as \\(\\frac{1}{Z(\\beta)}\\). Dropping the explicit \\(S\\) subscripts and ignoring the presence of the heat bath we finally have our canonical ensemble probability, called the Boltzmann distribution, \\[\n\\boxed{p(\\boldsymbol{\\mu}) = \\frac{1}{Z(T,X,N)}e^{-\\beta H(\\boldsymbol{\\mu})}} \\ .\n\\]\n\n\nPartition Function\nThe normalization constant \\(Z(T,X,N)\\) is so important it has a special name. It’s called the canonical partition function. We can find an expression for it by asserting that the probability density integrate to one. Evidently, we get \\[\n\\boxed{Z(T,X,N) = \\int d \\boldsymbol{\\mu} \\ e^{-\\beta H(\\boldsymbol{\\mu})}} \\ .\n\\] The partition function turns out to be very important to statistical mechanics, as it essentially encodes all the statistical mechanical information contained in the system. To see why it’s helpful to re-write the partition function as an integral (or sum) over all possible system energies \\(E\\). To do that multiple microstates can have the same energy. That means we need to multiply the integrand by a multiplicity \\(\\Omega(E)\\). We thus have \\[\nZ = \\int dE \\ \\Omega(E) \\ e^{-\\beta E} = \\int dE \\ e^{\\frac{1}{k_B} S} e^{-\\frac{1}{k_B T} E} = \\int dE \\ e^{-\\frac{1}{k_B T}(E-TS)}.\n\\] Recall from thermodynamics though that \\(E-TS\\) is just the Helmholtz free energy \\(F\\). Now, since \\(F\\) is extensive we can again employ the saddlepoint approximation about the maximum energy \\(E^*\\) to get \\[\nZ = \\int dE \\ e^{-\\beta F} \\approx e^{-\\beta F(E^*)} \\sqrt{\\frac{2\\pi}{|F''(E^*)|}}.\n\\] Taking the logarithm of both sides and solving for \\(F\\), we evidently have \\[\nF = -k_B T \\log Z + O\\big(\\log N\\big).\n\\] Since \\(N\\) is large, we can neglect the dependence on \\(\\log N\\). We thus have a nice expression for the free energy as \\[\n\\boxed{F = -k_B T \\log Z} \\ .\n\\] Why is this important? We already know \\(F\\) encodes all of the thermodynamic information in the system because \\[\ndF = -S dT + J \\cdot dX + \\mu \\cdot dN.\n\\] This formula gives a way to find the entropy, force, and chemical potential of the system just from \\(\\log Z\\). For example, \\[\n\\begin{align*}\nJ &= \\frac{\\partial F}{\\partial X} \\bigg |_{T,N} = -\\frac{1}{\\beta} \\frac{\\partial \\log Z}{\\partial X}, \\\\\n\\mu &= \\frac{\\partial F}{\\partial N} \\bigg |_{T,X} = -\\frac{1}{\\beta} \\frac{\\partial \\log Z}{\\partial N}. \\\\\n\\end{align*}\n\\] We can also derive a convenient expression for the energy \\(E\\) by looking at the expected value of the Hamiltonian. We have \\[\n\\langle H \\rangle = \\int d \\boldsymbol{\\mu} \\ H(\\boldsymbol{\\mu}) p(\\boldsymbol{\\mu}) = \\int d \\boldsymbol{\\mu} \\ H(\\boldsymbol{\\mu}) \\frac{e^{-\\beta H(\\boldsymbol{\\mu})}}{Z} = -\\frac{1}{Z} \\frac{\\partial Z}{\\partial \\beta} = - \\frac{\\partial \\log Z}{\\partial \\beta}.\n\\] Assuming we can equate the macrostate energy \\(E\\) with \\(\\langle H \\rangle\\), an issue we’ll discuss in a moment, we can thus write \\[\n\\boxed{E = \\langle H \\rangle = - \\frac{\\partial \\log Z}{\\partial \\beta}} \\ .\n\\] Using the formula \\(F = E - TS\\) we can also get a convenient formula for the entropy. We have \\[\nS = \\frac{E}{T} - \\frac{F}{T} = k_B \\big(\\beta E + \\log Z \\big).\n\\]\n\n\nFluctuations\nBut why can we assert that the thermodynamic energy \\(E\\) is the same thing as the expected value of the Hamiltonian \\(\\langle H \\rangle\\)? The reason for this has to do almost entirely with the fact that \\(N\\) is really large. To see why, let’s ask the following question: How much can we expect the energy to fluctuate about its mean \\(\\langle H \\rangle\\)?\nTo answer this, we just need to find the variance \\(\\sigma_E^2\\). Using the same trick as before, the \\(k\\)th moment of \\(H\\) is given by \\[\n\\langle H^k \\rangle = \\int d \\boldsymbol{\\mu} \\ H^k(\\boldsymbol{\\mu}) p(\\boldsymbol{\\mu}) = \\int d \\boldsymbol{\\mu} \\ H^k(\\boldsymbol{\\mu}) \\frac{e^{-\\beta H(\\boldsymbol{\\mu})}}{Z} = (-1)^k\\frac{1}{Z} \\frac{\\partial^k Z}{\\partial \\beta^k}.\n\\] From this formula, it’s not hard to see the cumulants of \\(H\\) are simply given by \\[\n\\langle H^k \\rangle_c = (-1)^k \\frac{\\partial^k \\log Z}{\\partial \\beta^k}.\n\\] In particular, this means the variance is given by \\[\n\\sigma_E^2 = \\frac{\\partial^2 \\log Z}{\\partial \\beta^2} = - \\frac{\\partial \\langle H \\rangle}{\\partial \\beta} = k_B T^2 \\frac{\\partial \\langle H \\rangle}{\\partial T} \\bigg |_{X,N} \\ .\n\\] To the extent we can write \\(E \\approx \\langle H \\rangle\\), the right-hand derivative is just the heat capacity \\(C_X\\). The variance of \\(H\\) is thus \\[\n\\boxed{\\sigma_E^2 = k_B T^2 C_X} \\ .\n\\] Now, recall the heat capacity is in general extensive. This means the variance (and in fact all cumulants of \\(H\\)) are extensive as well. Thus, roughly speaking, we expect the energy \\(E\\) to fluctuation about the mean by an amount \\[\n\\sigma_E = \\sqrt{k_B T^2 C_X} = O(\\sqrt{N}).\n\\] This means that the energy \\(E\\) will with high probability lie within a few \\(\\sigma_E\\) of the mean, \\[\nE \\approx \\langle H \\rangle \\pm \\sigma_E = \\langle H \\rangle \\pm O(\\sqrt{N}).\n\\] Since \\(\\langle H \\rangle = O(N)\\) and \\(N\\) is large, we can neglect the \\(O(\\sqrt{N})\\) fluctuations in the thermodynamic limit and just write \\[\nE \\approx \\langle H \\rangle.\n\\] Note that the energy distribution can have pretty much any curve we like. All that matters is that it be extensive. It can even have multiple peaks. Due to extensivity, the global maximum \\(E^*\\) will always be exponentially larger than the other maxima. Around that maximum we can fit a Gaussian with mean \\(E^* \\approx \\langle H \\rangle\\) and variance \\(\\sigma_E^2\\). That Gaussian will be sharply peaked about \\(E^*\\) with a negligible fluctuation, meaning we can safely write \\(E \\approx E^* \\approx \\langle H \\rangle\\).\n\n\n\n\n\nThis is in essence the magic of thermodynamics. When \\(N\\) is really really large, at equilibrium we can pretty much ignore the shape of the distribution and just assume \\(E = E^* = \\langle H \\rangle\\). This holds for other extensive variables as well, not just energy. For all practical purposes, thermodynamic variables are deterministic due to the character of the thermodynamic limit.\nAs an example to see that fluctuations don’t really matter, if we looked at one mole of air at STP, we’d expect the energy to be about \\(E \\approx \\frac{5}{2} RT \\approx 6100 \\ \\text{J}\\). On the other hand, the energy is expected to fluctuate as \\(\\sigma_E = \\sqrt{k_B T^2 \\frac{5}{2} R} \\approx 3 \\cdot 10^{-10} \\ \\text{J}\\). That is, the fluctuations \\(\\sigma_E\\) are a full 13 orders of magnitude smaller than \\(E\\), hence completely negligible.\n\n\nExample: Ideal Gas\nFrequently, the canonical ensemble is much easier to work with than the microcanonical ensemble. Perhaps the best example of this is comparing both methods for solving the ideal gas problem. Consider again a gas with Hamiltonian \\[\nH(\\mathbf{x}_1,\\cdots,\\mathbf{x}_N,\\mathbf{p}_1,\\cdots,\\mathbf{p}_N) = \\sum_{i=1}^N \\frac{\\mathbf{p}_i^2}{2m} + V(\\mathbf{x}_1,\\cdots,\\mathbf{x}_N),\n\\] where \\(V(\\mathbf{x}_1,\\cdots,\\mathbf{x}_N)\\) is zero inside a container of volume \\(V\\) and infinite otherwise. In the canonical ensemble our goal is to find the partition function and then use that to derive the equations of state. As with the microcanonical ensemble, we have to be careful to use the right measure of integration, dividing by \\(N! h^{3N}\\). The space integrals again reduce to \\(V^N\\). The momentum integrals reduce to a product of independent Gaussians. We thus have \\[\n\\begin{align*}\nZ &= \\frac{1}{N! h^{3N}} \\int d^{3N} \\mathbf{x} \\ d^{3N} \\mathbf{p} \\ \\exp\\bigg[-\\beta \\bigg(\\sum_{i=1}^N \\frac{\\mathbf{p}_i^2}{2m} + V(\\mathbf{x}_1,\\cdots,\\mathbf{x}_N)\\bigg)\\bigg] \\\\\n&= \\frac{V^N}{N! h^{3N}} \\prod_{i=1}^N \\int d^3 \\mathbf{p}_i \\ \\exp\\bigg[-\\beta \\bigg(\\frac{\\mathbf{p}_i^2}{2m}\\bigg)\\bigg] \\\\\n&= \\frac{V^N}{N! h^{3N}} \\bigg(\\frac{2\\pi m}{\\beta}\\bigg)^{3N/2} \\\\\n&\\approx \\bigg[\\frac{Ve}{N} \\bigg(\\frac{2\\pi m}{\\beta h^2}\\bigg)^{3/2}\\bigg]^N.\n\\end{align*}\n\\] We can get everything of interest by looking at the logarithm of the partition function, \\[\n\\log Z = N \\log \\frac{Ve}{N} \\bigg(\\frac{2\\pi m}{\\beta h^2}\\bigg)^{3/2}.\n\\] From here we can calculate every thermodynamic variable of interest. For example, the energy is given by \\[\nE = - \\frac{\\partial \\log Z}{\\partial \\beta} = \\frac{3N}{\\beta} = \\frac{3}{2} N k_B T,\n\\] and the pressure is given by \\[\nP = \\frac{1}{\\beta} \\frac{\\partial \\log Z}{\\partial V} = \\frac{N}{\\beta V} = \\frac{Nk_B T}{V}.\n\\] Another way to see how much easier the canonical ensemble can be to use is to try to calculate the distribution of momentum in the gas. The Maxwell-Boltzmann distribution pretty much falls right out. For example, \\[\n\\begin{align*}\np(\\mathbf{p}_1) &= \\frac{1}{N! h^{3N}} \\int d^{3N} \\mathbf{x} \\ d^{3N-1} \\mathbf{p} \\ p(\\mathbf{x}_1,\\cdots,\\mathbf{x}_N,\\mathbf{p}_1,\\cdots,\\mathbf{p}_N)\n\\\\\n&= \\frac{1}{Z}\\frac{V^N}{N! h^{3N}} \\exp\\bigg[-\\beta \\bigg(\\frac{\\mathbf{p}_1^2}{2m}\\bigg)\\bigg] \\prod_{i=2}^N \\int d^3 \\mathbf{p}_i \\ \\exp\\bigg[-\\beta \\bigg(\\frac{\\mathbf{p}_i^2}{2m}\\bigg)\\bigg] \\\\\n&= \\frac{1}{Z}\\frac{V^N}{N! h^{3N}} \\big(2\\pi m k_B T\\big)^{3(N-1)/2} \\exp\\bigg[-\\bigg(\\frac{\\mathbf{p}_1^2}{2mk_B T}\\bigg) \\bigg] \\\\\n&= \\frac{1}{(2\\pi m k_B T)^{3/2}} \\exp\\bigg[-\\frac{1}{2}\\bigg(\\frac{\\mathbf{p}_1^2}{mk_B T}\\bigg) \\bigg].\n\\end{align*}\n\\] We’ll finish this example by mentioning that we can define a convenient characteristic length scale \\(\\lambda\\) called the thermal DeBroglie wavelength, given by \\[\n\\lambda(T) \\equiv \\frac{h}{\\sqrt{2\\pi m k_B T}}.\n\\] Using this length scale we can more conveniently express the ideal gas partition function in the form \\[\nZ = \\frac{1}{N!}\\bigg(\\frac{V}{\\lambda^3}\\bigg)^N \\approx \\bigg(\\frac{Ve}{N\\lambda^3}\\bigg)^N.\n\\] We’ll see later that the size of \\(\\lambda(T)\\) essentially determines at what point quantum effects become important in statistical mechanics. For now it’s just a convenient simplification for the ideal gas partition function.\n\n\nEquipartition Theorem\nRecall from thermodynamics that we have a quick rule of thumb for finding the energy of certain gases. Look at the Hamiltonian of the gas and count number of quadratic degrees of freedom (both momenta plus positions). If the gas has \\(d\\) quadratic degrees of freedom, then the energy of the gas is just \\[\nE = \\frac{d}{2} N k_B T.\n\\] For example, a monoatomic ideal gas has just \\(d=3\\) quadratic degrees of freedom per molecule, since each molecule has a total energy proportional to \\(p_x^2 + p_y^2 + p_z^2\\). This means the total energy is \\(E=\\frac{3}{2} Nk_B T\\), as we’ve already derived multiple times. Let’s use the canonical ensemble to quickly prove the most general case of the equipartition theorem.\nSuppose a system of \\(N\\) particles has a joint Hamiltonian \\(H\\) consisting of the sum of single-particle Hamiltonians \\(H_i\\). Each single-particle contains \\(d\\) degrees of freedom \\(\\boldsymbol{\\xi}=(\\xi_1,\\xi_2,\\cdots,\\xi_d)\\). Suppose each single-particle Hamiltonian has the same form \\(H_i = \\sum_{k=1}^d c_k |\\boldsymbol{\\xi}|^s\\) for some positive power \\(s\\). Then the joint Hamiltonian is given by \\[\nH = \\sum_{i=1}^N \\sum_{k=1}^d c_k |\\boldsymbol{\\xi}_{ik}|^s.\n\\] Equipartition Theorem: In equilibrium, the total thermodynamic energy \\(E = \\langle H \\rangle\\) is given by \\[\nE = \\frac{d}{s} N k_B T.\n\\] In particular, when \\(s=2\\) we recover the usual equipartition theorem for quadratic degrees of freedom.\nProof: Without loss of generality, suppose the system has all its degrees of freedom in the momenta, so we can write \\[\nH = \\sum_{i=1}^N \\sum_{k=1}^{d} c_k |\\mathbf{p}_{ik}|^s.\n\\] It’s convenient here to work in the canonical ensemble. Since all we’re interested in is the energy, for simplicity we’ll assume all particles are distinguishable and ignore factors of \\(h\\). The partition function is then \\[\nZ = \\int d^{dN} \\mathbf{x} \\ d^{dN} \\mathbf{p} \\ \\exp\\bigg[-\\beta \\sum_{i=1}^N \\sum_{k=1}^{d} c_k |\\mathbf{p}_{ik}|^s\\bigg].\n\\] Suppose the particles are confined to some \\(d\\)-dimensional hypervolume \\(V_d\\). Factoring the exponentials by particle, we have \\[\nZ = V_d^N \\bigg(\\prod_{k=1}^d \\int d^{d} \\mathbf{p} \\ e^{-\\beta c_k |\\mathbf{p}|^s}\\bigg)^N.\n\\] We can write the \\(d\\)-dimensional volume element \\(d^d \\mathbf{p}\\) as a product of the \\(d\\)-dimensional solid angle \\(d^d\\Omega\\) and a radial term \\(r^{d-1} dr\\), \\[\nd^d \\mathbf{p} = r^{d-1} dr d^d \\Omega.\n\\] Since the integral for \\(Z\\) is spherically symmetric, we can integrate each solid angle to just get the surface area of a \\(d\\)-dimensional hypersphere, which we’ll recall is given by \\(S_d\\). What remains inside the integral is just the factorial function up to a change of variable. We thus have \\[\n\\begin{align*}\nZ &= V_d^N \\bigg(\\prod_{k=1}^d \\int d^d\\Omega \\int_0^{\\infty} dp \\ p^{d-1} e^{-\\beta c_k p^s}\\bigg)^N \\\\\n&= V_d^N \\bigg(\\prod_{k=1}^d S_d \\int_0^{\\infty} dp \\ p^{d-1} e^{-\\beta c_k p^s}\\bigg)^N \\\\\n&= V_d^N \\bigg(\\prod_{k=1}^d\\frac{S_d\\big(\\frac{d}{s}-1\\big)!}{s(\\beta c_k)^{1/s}}\\bigg)^N. \\\\\n\\end{align*}\n\\] In particular, notice that \\(Z\\) is proportional to \\(\\beta^{-Nd/s}\\), which means \\(\\log Z \\sim -\\frac{Nd}{s} \\log \\beta\\). The energy is thus just \\[\nE = -\\frac{\\partial \\log Z}{\\partial \\beta} = \\frac{Nd}{s\\beta} = \\frac{d}{s} N k_B T. \\quad \\text{Q.E.D.}\n\\] The equipartition theorem is a useful shortcut for quickly figuring out how the partition function depends on temperature since we can use it to avoid having to do any integration, provided the degrees of freedom are all of the same power. For example, we saw for an ultrarelativistic ideal gas that \\(H = \\sum_{i=1}^N |\\mathbf{p}_i|c\\). In this case \\(s=1\\) and \\(d=3\\), so \\(E=3Nk_B T\\), which we’ve seen."
  },
  {
    "objectID": "statistical-mechanics/classical-stat-mech.html#higher-ensembles",
    "href": "statistical-mechanics/classical-stat-mech.html#higher-ensembles",
    "title": "Classical Statistical Mechanics",
    "section": "Higher Ensembles",
    "text": "Higher Ensembles\nWhile the microcanonical ensemble is perhaps the most intuitive, and the canonical ensemble is perhaps the most useful, there are other ensembles we can imagine as well. In fact, each free energy has its own ensemble. We’ve already seen the ensembles corresponding to the energy \\(E\\) and Helmholtz free energy \\(F\\). We’ll now look at two more ensembles corresponding to the last two free energies, the Gibbs free energy \\(G\\) and the grand potential \\(\\mathcal{G}\\). While all ensembles are in some sense equivalent, each ensemble has its advantages in certain situations. In particular, we’ll see the grand canonical ensemble arise in our treatment of quantum statistical mechanics.\n\nGibbs Canonical Ensemble\nSimilar to the canonical ensemble, the Gibbs canonical ensemble arises from considering a system in equilibrium with a much larger heat bath, except now we also allow for the possibility that work is done on the system as well. That is, we now take \\(M=(T,J,N)\\) and assume the total energy has the form \\(E = H(\\boldsymbol{\\mu}) + J \\cdot X\\). Then the probability of achieving a given microstate \\(\\boldsymbol{\\mu}\\) at a particular displacement \\(X\\) is given by \\[\np(\\boldsymbol{\\mu},X) = \\frac{1}{Z_G(T,J,N)}e^{-\\beta \\big(H(\\boldsymbol{\\mu})-J \\cdot X\\big)},\n\\] where \\(Z_G=Z_G(T,J,N)\\) is again a normalization constant, this time called the Gibbs partition function. It’s given by integrating over all microstates \\(\\boldsymbol{\\mu}\\) and displacements \\(X\\), \\[\nZ_G(T,J,N) \\equiv \\int dX \\ d \\boldsymbol{\\mu} \\ e^{-\\beta \\big(H(\\boldsymbol{\\mu})-J \\cdot X\\big)}.\n\\] By factoring the dependences on \\(\\boldsymbol{\\mu}\\) and \\(X\\) we can write the Gibbs partition function in terms of the canonical partition function \\(Z(T,X,N)\\) as \\[\nZ_G(T,J,N) = \\int dX \\ e^{-\\beta J \\cdot X} \\ Z(T,X,N).\n\\] Since the displacement \\(X\\) is now a random variable, we can ask how it varies about its mean \\(\\langle X \\rangle\\). Following the same logic as we did with the energy, it’s easy to see that \\[\n\\langle X \\rangle = \\frac{\\partial}{\\partial (\\beta J)} \\log Z_G.\n\\] The cumulants of \\(X\\) are similarly given by \\[\n\\langle X^k \\rangle_c = \\frac{\\partial^k \\log Z_G}{\\partial (\\beta J)^k} = \\frac{\\partial^{k-1} \\langle X \\rangle}{\\partial (\\beta J)^{k-1}}.\n\\] In particular, all cumulants of \\(X\\) are extensive. This means the variance is proportional to \\(\\langle X \\rangle\\), which means the fluctuations in \\(X\\) go like \\(\\sigma_X = \\sqrt{\\langle X \\rangle}\\). This means we can again assert that \\(X = X^* = \\langle X \\rangle\\) when \\(N\\) is really large.\nWe can relate the partition function to the Gibbs free energy by observing \\[\nZ_G = \\int dX \\ dE \\ e^{-\\beta(E-J \\cdot X)} \\Omega(E,X) = \\int dX \\ dE \\ e^{-\\beta(E-TS-J \\cdot X)}.\n\\] Here \\(G \\equiv E-TS-\\mu \\cdot N\\) is of course the Gibbs free energy. Using the saddlepoint approximation, in the thermodynamic limit we can write \\[\nZ_G \\approx e^{-\\beta G(E^*, \\ X^*)}.\n\\] Solving for \\(G\\) we have the familiar expression \\[\nG = -k_B T \\log Z_G.\n\\] From here all other thermodynamic variables we seek follow in the usual way using the identity \\[\ndG = -S dT - X \\cdot dJ + \\mu \\cdot dN.\n\\] In this ensemble the canonical energy formula no longer applies. Instead that formula gives the enthalpy \\(H = E - J \\cdot X\\), \\[\nH = -\\frac{\\partial \\log Z_G}{\\partial \\beta}.\n\\]\n\n\nGrand Canonical Ensemble\nThe grand canonical ensemble follows exactly the same logic as the Gibbs ensemble did, except now we imagine the system is in equilibrium with a heat bath and allowed to exchange particles with it via chemical work. That is, \\(M = (T,X,\\mu)\\) and the energy has the form \\(E = H(\\boldsymbol{\\mu}) + \\mu \\cdot N\\). Then the probability of a given microstate \\(\\boldsymbol{\\mu}\\) and a given particle number \\(N\\) is given as \\[\np(\\boldsymbol{\\mu},N) = \\frac{1}{\\mathcal{Z}(T,X,\\mu)}e^{-\\beta \\big(H(\\boldsymbol{\\mu})-\\mu \\cdot N\\big)},\n\\] where \\(\\mathcal{Z}(T,X,\\mu)\\) is another normalization constant gotten by integrating over all possible \\(\\boldsymbol{\\mu}\\) and summing over all possible \\(N\\). This is called the grand canonical partition function, given by \\[\n\\mathcal{Z}(T,X,\\mu) \\equiv \\sum_{N=0}^\\infty \\int d \\boldsymbol{\\mu} \\ e^{-\\beta \\big(H(\\boldsymbol{\\mu})-\\mu \\cdot N\\big)}.\n\\] We can again factor the \\(\\boldsymbol{\\mu}\\) and \\(N\\) dependences apart and write just \\[\n\\mathcal{Z}(T,X,\\mu) = \\sum_{N=0}^\\infty e^{\\beta\\mu \\cdot N} Z(T,X,N).\n\\] The dimensionless variable \\(\\log z \\equiv \\beta\\mu = \\frac{\\mu}{k_B T}\\) is sometimes called the log fugacity, where \\(z \\equiv e^{\\beta\\mu}\\) is the fugacity. The fugacity turns out to be important in quantum statistical mechanics since its size says something about the limiting behaviors of the equations of state at low temperatures.\nWhile not necessarily obvious, more mathematical care is needed to interpret the grand canonical ensemble due to the fact that \\(N\\) is no longer fixed, but allowed to vary. This means we can’t a priori just assume that \\(N\\) is large and the thermodynamic limit applies. Moreover, the phase spaces being integrated over aren’t even of the same dimensions since each \\(d=6N\\).\nInstead of interpreting things in terms of \\(N\\), a random variable, we instead need to interpret things in terms of \\(\\langle N \\rangle\\). Following the same logic as we did with the energy, it’s easy to see that \\[\n\\langle N \\rangle = \\frac{\\partial}{\\partial (\\beta\\mu)} \\log \\mathcal{Z}.\n\\] The cumulants of \\(N\\) are similarly given by \\[\n\\langle N^k \\rangle_c = \\frac{\\partial^k \\log \\mathcal{Z}}{\\partial (\\beta\\mu)^k} = \\frac{\\partial^{k-1} \\langle N \\rangle}{\\partial (\\beta\\mu)^{k-1}}.\n\\] In particular, all cumulants of \\(N\\) are proportional to \\(\\langle N \\rangle\\). In particular, this means the variance is proportional to \\(\\langle N \\rangle\\), which means the fluctuations in \\(N\\) go like \\(\\sigma_N = \\sqrt{\\langle N \\rangle}\\). By the same usual logic, this means we can assert that \\(N = N^* = \\langle N \\rangle\\) provided \\(N^*\\) is very large, which will typically be the case in thermodynamics.\nAgain using the same logic as before, we can relate the partition function to the free energy by observing \\[\n\\mathcal{Z} = \\sum_{N=0}^\\infty \\int dE \\ e^{-\\beta(E-\\mu \\cdot N)} \\Omega(E,N) = \\sum_{N=0}^\\infty \\int dE \\ e^{-\\beta(E-TS-\\mu \\cdot N)}.\n\\] Here \\(\\mathcal{G} \\equiv E-TS-\\mu \\cdot N\\) is of course the grand potential. Using the saddlepoint approximation, in the thermodynamic limit we can write \\[\n\\mathcal{Z} \\approx e^{-\\beta\\mathcal{G}(E^*,N^*)}.\n\\] Solving for \\(\\mathcal{G}\\) we again have the familiar expression \\[\n\\mathcal{G} = -k_B T \\log \\mathcal{Z}.\n\\] From here all other thermodynamic variables we seek follow in the usual way using the identity \\[\nd\\mathcal{G} = -S dT + J \\cdot dX - N \\cdot d\\mu.\n\\]\n\n\nExample: Ideal Gas\nAs an example, we’ll work out the equations of state again for the ideal gas, both in the Gibbs canonical and the grand canonical ensembles. Starting with the Gibbs canonical ensemble, the Gibbs partition function can be calculated by observing that the integral over \\(V\\) is almost a factorial function. We have \\[\n\\begin{align*}\nZ_G &= \\int_0^\\infty dV e^{-\\beta PV} Z \\\\\n&= \\frac{1}{N! h^{3N}} \\bigg(\\frac{2\\pi m}{\\beta}\\bigg)^{3N/2} \\int_0^\\infty dV e^{-\\beta PV} V^N \\\\\n&= \\frac{1}{N! h^{3N}} \\bigg(\\frac{2\\pi m}{\\beta}\\bigg)^{3N/2} \\frac{N!}{(\\beta P)^{N+1}} \\\\\n&= \\bigg(\\frac{2\\pi m}{h^2 \\beta}\\bigg)^{3N/2} (\\beta P)^{-(N+1)}. \\\\\n\\end{align*}\n\\] Taking the logarithm of both sides, we have \\[\n\\log Z_G \\approx \\frac{3N}{2} \\log \\frac{2\\pi m}{h^2 \\beta} - N \\log \\beta P.\n\\] We can get the mean volume \\(V \\approx \\langle V \\rangle\\) by differentiating both sides with respect to \\(-\\beta P\\), \\[\nV \\approx \\frac{\\partial \\log Z_G}{\\partial (-\\beta P)} = \\frac{N}{\\beta P} = \\frac{Nk_B T}{P}.\n\\] This is of course the usual equation of state, with \\(PV = N k_B T\\). We can easily find the enthalpy as well, \\[\nH = -\\frac{\\partial \\log Z_G}{\\partial \\beta} = \\frac{3N}{2\\beta} + \\frac{N}{\\beta} = \\frac{5}{2} N k_B T.\n\\] Since \\(H = E + PV\\), we can immediately read off the usual formula for energy, \\(E = \\frac{3}{2} N k_B T\\).\nMoving onto the grand canonical ensemble, the grand partition function is given by noting that the sum over \\(N\\) is just the Taylor series of an exponential function. We have \\[\n\\begin{align*}\n\\mathcal{Z} &= \\sum_{N=0}^\\infty dV e^{\\beta \\mu N} Z(\\beta) \\\\\n&= \\sum_{N=0}^\\infty e^{\\beta \\mu N} \\frac{V^N}{N! h^{3N}} \\bigg(\\frac{2\\pi m}{\\beta}\\bigg)^{3N/2} \\\\\n&= \\sum_{N=0}^\\infty \\frac{1}{N!} \\bigg[\\frac{Ve^{\\beta\\mu}}{h^3} \\bigg(\\frac{2\\pi m}{\\beta}\\bigg)^{3/2}\\bigg]^N \\\\\n&= \\exp \\bigg[\\frac{Ve^{\\beta\\mu}}{h^3} \\bigg(\\frac{2\\pi m}{\\beta}\\bigg)^{3/2}\\bigg]. \\\\\n\\end{align*}\n\\] This means \\(\\log \\mathcal{Z}\\) is just \\[\n\\log \\mathcal{Z} = \\frac{Ve^{\\beta\\mu}}{h^3} \\bigg(\\frac{2\\pi m}{\\beta}\\bigg)^{3/2}.\n\\] It’s helpful to first find \\(N \\approx \\langle N \\rangle\\). We have \\[\nN \\approx \\frac{\\partial \\log \\mathcal{Z}}{\\partial (\\beta\\mu)} = \\frac{Ve^{\\beta\\mu}}{h^3} \\bigg(\\frac{2\\pi m}{\\beta}\\bigg)^{3/2} = \\log \\mathcal{Z}.\n\\] This means all cumulants of \\(N\\) will be \\(\\log \\mathcal{Z}\\) as well. Recall all cumulants being equal implies that \\(N\\) must be Poisson distributed. The grand potential is evidently just \\(\\mathcal{G} = -N k_B T\\). But by extensivity \\(\\mathcal{G} = -PV\\). We thus get the ideal gas law, \\[\nPV = N k_B T.\n\\] Getting the energy is slightly trickier. It’s not too hard to show that \\[\nE - \\mu N = -\\frac{\\partial \\log \\mathcal{Z}}{\\partial \\beta} = N \\bigg(\\frac{3}{2} k_B T - \\mu\\bigg).\n\\] Cancelling \\(\\mu N\\) from both sides, we again get \\(E = \\frac{3}{2} N k_B T\\). Finally, if we like we can solve for the chemical potential by inverting the formula for \\(N\\). As expected, we have \\[\n\\mu = k_B T \\log \\frac{N}{V} \\bigg(\\frac{2\\pi m k_B T}{h^2}\\bigg)^{3/2}.\n\\]"
  }
]