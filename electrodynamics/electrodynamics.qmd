# Electrodynamics

In the previous chapter we started moving away from statics, and started our study of electrodynamics, the study of time-varying electric and magnetic fields. We finished that chapter with the following quasistatic field equations
$$
\begin{align*}
&\nabla \cdot \mathbf{E} = 4\pi \rho \ ,\\
&\nabla \times \mathbf{E} = -\frac{1}{c} \frac{\partial\mathbf{B}}{\partial t} \ ,\\
&\nabla \cdot \mathbf{B} = 0 \ ,\\
&\nabla \times \mathbf{B} = \frac{4\pi}{c} \mathbf{J} \ . \\
\end{align*}
$$
In this chapter we will continue on with the topic of electrodynamics by allowing the final equation for $\nabla \times \mathbf{B}$ to depend on a time-varying E-field, just as in the previous chapter we modifying $\nabla \times \mathbf{E}$ to depend on a time-varying B-field. This will lead us to the notion of displacement current, and finally to Maxwell's equations, the crown jewel of electromagnetism.

Once we finally derive Maxwell's equations we will study their implications pretty much for the rest of this course. We will start by studying the conservation laws they imply for charge, energy, and momentum. We will then to show how Maxwell's equations become wave equations, which leads to the topic of electromagnetic radiation, something that we'll see in a future chapter is the underlying theory of classical optics.

From now on in this course, we'll always assume that all fields and distributions depend explicitly on time unless otherwise stated. That is, we'll assume that $\mathbf{E} = \mathbf{E}(\mathbf{x},t)$ and $\mathbf{B} = \mathbf{B}(\mathbf{x},t)$, and that $\rho = \rho(\mathbf{x},t)$ and $\mathbf{J} = \mathbf{J}(\mathbf{x},t)$ as well. This pulls us away from statics and puts us squarely in the realm of electrodynamics. An immediate implication of this is that many of the expressions we derived before for the fields in terms of source distributions will no longer apply, in particular Coulomb's law and the Biot-Savart law. We'll see in later chapters how these formulas can be modified to account for electrodynamics.

## Maxwell's Equations

Before studying the implications of Maxwell's equations we first need to finalize them by introducing the *displacement current*, which modifies the equation for $\nabla \times \mathbf{B}$ to allow for a time-varying E-field. 

### Displacement Current

In the mid 19th century, Maxwell observed that the quasistatic equations as modified by Faraday were mathematically inconsistent with the most fundamental principle of electromagnetism, namely conservation of charge. Specifically, Maxwell noticed that Ampere's law was inconsistent with the continuity equation
$$
\frac{\partial \rho}{\partial t} + \nabla \cdot \mathbf{J} = 0 \ .
$$
To see why this is the case, recall that the differential form of Ampere's states that
$$
\nabla \times \mathbf{B} = \frac{4\pi}{c} \mathbf{J} \ .
$$
If we take the divergence of both sides of this equation, we get
$$
\nabla \cdot (\nabla \times \mathbf{B}) = \frac{4\pi}{c} \nabla \cdot \mathbf{J} \ .
$$
Now, the divergence of a curl must always vanish, which means the left-hand side must be zero. We thus must evidently conclude from Ampere's law that
$$
\nabla \cdot \mathbf{J} = 0 \ .
$$
But, as we saw in the chapter on magnetostatics, this can only be consistent with conservation of charge when the current density is time-independent. Of course, there's no reason at all to assume the current density must always be time-independent. In fact if it is we necessarily get a steady current, which means the B-field must be time-independent, which necessarily conflicts with Faraday's law.

To resolve this problem, Maxwell proposed adding a new term to Ampere's law, which he called the *displacement current*,
$$
\nabla \times \mathbf{B} = \frac{4\pi}{c} (\mathbf{J} + \mathbf{J}_d) \ .
$$
If we now take the divergence of both sides as we did above, we get
$$
0 = \nabla \cdot \mathbf{J} + \nabla \cdot \mathbf{J}_d \ .
$$
We can now make this equation consistent with the continuity equation by insisting that
$$
\nabla \cdot \mathbf{J}_d = \frac{\partial \rho}{\partial t} \ .
$$
But since Gauss's law requires that $\nabla \cdot \mathbf{E} = 4\pi\rho$, we also have
$$
\nabla \cdot \mathbf{J}_d = \frac{1}{4\pi} \frac{\partial}{\partial t} \nabla \cdot \mathbf{E} \ .
$$
This means, up to an additive constant that we can set to zero, the displacement current must then be
$$
\mathbf{J}_d = \frac{1}{4\pi} \frac{\partial \mathbf{E}}{\partial t} \ .
$$
Plugging this into the modified Ampere's law above, we finally have
$$
\boxed{
\nabla \times \mathbf{B} = \frac{4\pi}{c} \mathbf{J} + \frac{1}{c} \frac{\partial \mathbf{E}}{\partial t}
} \ .
$$
With this modification, we've thus managed to make the field equations consistent with the conservation of charge. Just as Faraday's law allows $\nabla \times \mathbf{E}$ to depend on a time-varying E-field, this modified Ampere's law allows $\nabla \times \mathbf{B}$ to depend on a time-varying E-field, thus coupling together the four field equations and making them self-consistent.

Of course, it's worth asking why the displacement current wasn't first detected in experiments like the other laws were? Why was it only found from theory alone? To understand why we need to analyze the displacement current a bit.

- Finish this part (see notes)

### Maxwell's Equations

With the final modification to Ampere's law in place, we're finally able to state *Maxwell's Equations*, the fundamental field equations of classical electromagnetism. In a nutshell, these equations say that E-fields are caused by exactly two things: charges and changing B-fields. Similarly, B-fields are caused by exactly two things: currents and changing E-fields. 

In differential form, Maxwell's equations are

$$
\boxed{
\begin{align*}
&\nabla \cdot \mathbf{E} = 4\pi \rho \\
&\nabla \times \mathbf{E} = -\frac{1}{c} \frac{\partial \mathbf{B}}{\partial t} \\
&\nabla \cdot \mathbf{B} = 0 \\
&\nabla \times \mathbf{B} = \frac{4\pi}{c} \mathbf{J} + \frac{1}{c} \frac{\partial \mathbf{E}}{\partial t} \\
\end{align*}
} \ .
$$



Aside from the Lorentz force law, Maxwell's equations encapsulate all of the theory of classical electromagnetism, at least in principle. The only thing missing at this point is how these equations change in the presence of electromagnetic materials, something we'll discuss in a future chapter.

We can also state Maxwell's equations in integral form if we like,
$$
\begin{align*}
&\oint \mathbf{E} \cdot d\mathbf{a} = 4\pi Q_{\text{enc}} \ , \\
&\oint \mathbf{E} \cdot d\boldsymbol{\ell} = -\frac{1}{c} \frac{d\Phi_B}{dt} \ , \\
&\oint \mathbf{B} \cdot d\mathbf{a} = 0 \ , \\
&\oint \mathbf{B} \cdot d\boldsymbol{\ell} = \frac{4\pi}{c} I_{\text{enc}} + \frac{1}{c} \frac{d\Phi_E}{dt} \ . \\
\end{align*}
$$
Here $Q_{\text{enc}}$ refers as usual to the charges enclosed in a closed surface, and $I_{\text{enc}}$ to the currents enclosed inside a closed loop, while $\Phi_E$ and $\Phi_B$ refers to the flux of electric and magnetic fields through any surfaces bounded by a closed loop.

## Electromagnetic Potentials

Just as in statics it was useful to express the EM fields in terms of potentials, it'll be useful to do the same in electrodynamics. Recall that we derived the scalar potential $\phi(\mathbf{x})$ from the assumption that $\nabla \times \mathbf{E} = \mathbf{0}$, and the vector potential $\mathbf{A}(\mathbf{x})$ from the assumption that $\nabla \cdot \mathbf{B} = 0$. Provided these equations hold, we can write
$$
\mathbf{E} = -\nabla \phi \quad , \quad \mathbf{B} = \nabla \times \mathbf{A} \ .
$$
As we'll see, we need to modify these relations somewhat in electrodynamics, which will lead to different behaviors.

### Modified Potentials

In electrodynamics it's still true that $\nabla \cdot \mathbf{B} = 0$ even for time-varying B-fields, which means we can still find a time-varying vector field $\mathbf{A}(\mathbf{x},t)$ such that $\mathbf{B} = \nabla \times \mathbf{A}$. We will still refer to $\mathbf{A}(\mathbf{x},t)$ as the *vector potential*.

However, it's no longer true that $\nabla \times \mathbf{E} = \mathbf{0}$ for time-varying E-fields, which means we no longer find a time-varying scalar field $\phi(\mathbf{x},t)$ such that $\mathbf{E} = -\nabla \phi$. However, we can still find a related vector field whose curl vanishes. Consider Faraday's law,
$$
\nabla \times \mathbf{E} = -\frac{1}{c} \frac{\partial \mathbf{B}}{\partial t} \ .
$$
If we write $\mathbf{B} = \nabla \times \mathbf{A}$ and move everything to the left-hand side, we have
$$
\nabla \times \bigg(\mathbf{E} + \frac{1}{c} \frac{\partial \mathbf{A}}{\partial t}\bigg) = 0 \ .
$$
Since we now have a vector field whose curl vanishes, we can find a scalar field $\phi(\mathbf{x},t)$ such that
$$
\mathbf{E} + \frac{1}{c} \frac{\partial \mathbf{A}}{\partial t} = -\nabla \phi \ .
$$
This means we can express $\mathbf{E}(\mathbf{x},t)$ in terms of the time-varying scalar and vector potentials as
$$
\mathbf{E} = -\nabla \phi - \frac{1}{c} \frac{\partial \mathbf{A}}{\partial t} \ .
$$
As before, we call $\phi(\mathbf{x},t)$ the *scalar potential*. Thus, in electrodynamics we relate the EM fields to the potentials by
$$
\boxed{
\begin{align*}
\mathbf{E} &= -\nabla \phi - \frac{1}{c} \frac{\partial \mathbf{A}}{\partial t} \\ 
\mathbf{B} &= \nabla \times \mathbf{A}
\end{align*}
} \ .
$$
The dynamical behavior of these potentials must then be satisfied by the remaining two Maxwell equations.

### Differential Equations

We still have two more of Maxwell's equations that the potentials need to satisfy, namely the inhomogeneous equations
$$
\nabla \cdot \mathbf{E} = 4\pi \rho \quad , \quad \nabla \times \mathbf{B} = \frac{4\pi}{c} \mathbf{J} + \frac{1}{c} \frac{\partial \mathbf{E}}{\partial t} \ .
$$
If we plug the expression for $\mathbf{E}$ in terms of the potentials into the first equation, we must have
$$
\nabla \cdot \bigg(\nabla \phi + \frac{1}{c} \frac{\partial \mathbf{A}}{\partial t}\bigg) = -4\pi \rho \ .
$$
Simplifying the left-hand side, this gives the following differential equation for the scalar potential,
$$
\nabla^2 \phi + \frac{1}{c} \frac{\partial}{\partial t} \nabla \cdot \mathbf{A} = -4\pi \rho \ .
$$
Similarly, if we plug the expressions for both $\mathbf{E}$ and $\mathbf{B}$ into the second inhomogeneous equation, we have
$$
\nabla \times (\nabla \times \mathbf{A}) = \frac{4\pi}{c} \mathbf{J} - \frac{1}{c} \frac{\partial}{\partial t} \bigg(\nabla \phi + \frac{1}{c} \frac{\partial \mathbf{A}}{\partial t}\bigg) \ .
$$
Since $\nabla \times (\nabla \times \mathbf{A}) = \nabla (\nabla \cdot \mathbf{A}) - \nabla^2 \mathbf{A}$, upon rearranging we get
$$
\nabla^2 \mathbf{A} - \frac{1}{c^2} \frac{\partial^2 \mathbf{A}}{\partial t^2} - \nabla \bigg(\nabla \cdot \mathbf{A} + \frac{1}{c} \frac{\partial \phi}{\partial t} \bigg) = -\frac{4\pi}{c} \mathbf{J} \ .
$$
As things stand, the differential equations for $\phi$ and $\mathbf{A}$ look quite different, but notice each equation contains a term proportional to $\nabla \cdot \mathbf{A}$, which means we can potentially make them have the same form by exploiting gauge invariance.

### Gauge Invariance

Recall that we can always add to the vector potential the gradient of any scalar field $\chi$ without changing the underlying B-field,
$$
\mathbf{A}' = \mathbf{A} + \nabla \chi \ .
$$
This is called a *gauge transformation*. This follows from the relation $\mathbf{B} = \nabla \times \mathbf{A}$ along with the fact that the curl of any gradient is always zero. This is still true in electrodynamics, except now when we do a gauge transformation we have to be careful not to alter the E-field as well. The only way we can ensure this is to require that $\phi$ also gauge transform simultaneously as
$$
\phi' = \phi - \frac{1}{c} \frac{\partial \chi}{\partial t} \ .
$$
Thus, in electrodynamics, a gauge transformation is any transformation on both the scalar and vector potentials of the form
$$
\begin{align*}
\phi' &= \phi -\frac{1}{c} \frac{\partial \chi}{\partial t} \ , \\ 
\mathbf{A}' &= \mathbf{A} + \nabla \chi \ .
\end{align*}
$$
As we mentioned in magnetostatics, we can uniquely specify a given gauge by fixing $\chi$, or equivalently by fixing $\nabla \cdot \mathbf{A}$. This ability to specify the divergence of the vector potential gives us a gauge freedom we can use to simplify various formulas without altering any of the underlying physics. We can fix $\nabla \cdot \mathbf{A}$ to be anything we like so long as we're consistent within a given theory.

In magnetostatics we fixed the gauge by choosing the *Coulomb gauge* $\nabla \cdot \mathbf{A} = 0$, which was a natural choice in that setting. We could still do that in electrodynamics as well if we like. If we did, the differential equations for the potentials could be written
$$
\begin{align*}
\nabla^2 \phi &= -4\pi \rho \ , \\
\nabla^2 \mathbf{A} - \frac{1}{c^2} \frac{\partial^2 \mathbf{A}}{\partial t^2} &= -\frac{4\pi}{c} \mathbf{J} + \frac{1}{c} \nabla \frac{\partial \phi}{\partial t} \ .
\end{align*}
$$
This choice of gauge makes the equation for the scalar potential especially simple. We just recover Poisson's equation, the same equation we saw in electrostatics. In the absence of boundary conditions, the solution to Poisson's equation is just given by
$$
\phi(\mathbf{x},t) = \int d^3\mathbf{x}' \frac{\rho(\mathbf{x},t)}{|\mathbf{x} - \mathbf{x}'|} \ .
$$
However, the equation for the vector potential $\mathbf{A}$ is much more complex. It's coupled to the scalar potential $\phi$, which means we need to first solve for $\phi$ before we can solve for $\mathbf{A}$. Assuming we've done so, we can treat $4\pi\mathbf{J}_\ell \equiv \nabla \partial_t \phi$ as a kind of current and solve for $\mathbf{A}$ that way.

While this is physically allowed though it's not intuitively pleasing. For one thing, we'd like the equations for $\phi$ and $\mathbf{A}$ to have the same form if possible. But more importantly, Poisson's equation when $\phi$ is time dependent is *instantaneous*. It suggests that the scalar potential can propagate at infinite speeds, which violates special relativity if we insist $\phi$ have any physical meaning at all.  Thus, in electrodynamics we'd prefer to choose a different gauge that fixes both of these issues.

By staring at the original differential equations for the potentials in the previous section one can identify such a gauge,
$$
\boxed{
\nabla \cdot \mathbf{A} = - \frac{1}{c} \frac{\partial \phi}{\partial t} 
} \ .
$$
This choice of gauge is called the *Lorentz gauge*, because it makes both potentials Lorentz invariant. That is, it ensures that both potentials can only propagate at finite speeds. In this gauge, the differential equations for the potentials can be written
$$
\boxed{
\begin{align*}
&\nabla^2 \phi - \frac{1}{c^2} \frac{\partial^2 \phi}{\partial t^2} = -4\pi \rho \\ 
&\nabla^2 \mathbf{A} - \frac{1}{c^2} \frac{\partial^2 \mathbf{A}}{\partial t^2} = -\frac{4\pi}{c} \mathbf{J}
\end{align*}
} \ .
$$
Differential equations of this form are known as *inhomogeneous wave equations*. As we'll soon see, functions satisfying this kind of partial differential equation necessarily must propagate at a finite speed, namely $c$.

To see what kind of condition the Lorentz gauge places on the gauge potential $\chi$, suppose
$$
\nabla \cdot \mathbf{A}' = - \frac{1}{c} \frac{\partial \phi'}{\partial t} \ ,
$$
where $\mathbf{A}' = \mathbf{A} + \nabla \chi$ and $\phi' = \phi - \partial_t \chi / c$ is some gauge transformation. Plugging in and simplifying, we get
$$
\nabla^2 \chi - \frac{1}{c^2} \frac{\partial^2 \chi}{\partial t^2} = -\nabla \cdot \mathbf{A} - \frac{1}{c} \frac{\partial \phi}{\partial t} \ .
$$
Thus, if we have potentials $\phi$ and $\mathbf{A}$ that don't satisfy the Lorentz gauge, we can always convert them into potentials that do by finding a gauge potential $\chi$ that solves this inhomogeneous wave equation.

## Wave Equation

We now want to better understand the solutions of the wave equation, both its homogeneous and inhomogeneous form. We'll see that this discussion applies not just to the potentials, but the fields as well in certain cases. Indeed, the wave equation shows up all over physics, so understanding its solutions is very important.

### Initial-Boundary Value Problem

Suppose $\phi(\mathbf{x},t)$ is some arbitrary scalar field that happens to satisfy the inhomogeneous wave equation
$$
\nabla^2 \phi - \frac{1}{c^2} \frac{\partial^2 \phi}{\partial t^2} = -4\pi \rho(\mathbf{x},t) \ ,
$$
where $\rho(\mathbf{x},t)$ is some arbitrary source function. Here we don't assume $\phi$ is scalar potential. It could be any scalar field, or even one of the components of some other vector (or tensor) field.

The wave equation is a second order linear partial differential equation. Since it involves time and not just space, the exact form of any particular solution depends on both the initial conditions of the field
$$
\phi(\mathbf{x}, 0) \quad , \quad \frac{\partial}{\partial t} \bigg|_{t=0} \phi(\mathbf{x}, t) \ ,
$$
as well as any imposed boundary conditions, be they Dirichlet, Neumann, or mixed boundary conditions. A PDE that satisfies both initial and boundary conditions is usually called an *initial-boundary value problem*, or *IBVP*.

As with any linear PDE, the general solution to the wave equation can be express as the sum of a homogeneous solution and a particular solution, where the particular solution $\phi_p(\mathbf{x},t)$ is the solution to the inhomogeneous wave equation in the absence of the boundary conditions, and the homogeneous solution $\phi_h(\mathbf{x},t)$ is any solution to the *homogeneous* wave equation
$$
\nabla^2 \phi - \frac{1}{c^2} \frac{\partial^2 \phi}{\partial t^2} = 0
$$
subject to the imposed boundary conditions.

Note that when dealing with the wave equation, one often defines the *wave operator* or *d'Alembertian* $\square$ by
$$
\square \equiv \nabla^2 - \frac{1}{c^2} \frac{\partial^2}{\partial t^2} \ .
$$
 In this notation the inhomogeneous wave equation is then written simply as
$$
\square \phi = -4\pi\rho(\mathbf{x}, t) \ .
$$
Let's now investigate the homogeneous and inhomogeneous solutions to the wave equation.

### Homogeneous Solution

Suppose that $\phi(\mathbf{x}, t)$ satisfies the homogeneous wave equation
$$
\nabla^2 \phi - \frac{1}{c^2} \frac{\partial^2 \phi}{\partial t^2} = 0
$$
subject to some set of initial conditions. For now we'll ignore any boundary conditions.

Using separation of variables, it's not difficult to show that the solutions to this PDE must have the form
$$
\phi(\mathbf{x}, t) = \phi_+(r - ct) + \phi_-(r + ct) \ ,
$$
where $\phi_\pm$ are arbitrary functions that depend only on the difference $r \pm ct$.


$$
\bigg(\nabla^2 + \frac{\omega^2}{c^2}\bigg) \phi(\mathbf{x}, \omega) = 0
$$

$$
\nabla^2 \phi = -\frac{\omega^2}{c^2} \phi
$$





### Green's Function

Just as we did with Poisson's equation, we can build a solution to this equation by first finding a Green's function $G(\mathbf{x}-\mathbf{x}', t-t')$ that solves the equation
$$
\nabla^2 G - \frac{1}{c^2} \frac{\partial^2 G}{\partial t^2} = -4\pi\delta(\mathbf{x}-\mathbf{x}')\delta(t-t') \ .
$$
As usual, we'll require that the Green's function go to zero at infinity, both in space and in time. Notice that now the Green's function depends on both position and time since the wave equation itself involves both position and time. 

Assuming we can find such a Green's function we can obtain a particular solution $\phi(\mathbf{x},t)$ via space-time convolution of the Green's function with the source function $\rho(\mathbf{x},t)$,
$$
\phi(\mathbf{x},t) = \int d^3\mathbf{x}' dt' \ \rho(\mathbf{x}', t') G(\mathbf{x}-\mathbf{x}', t-t') \ .
$$
To find the Green's function we'll use the same approach we did to find the Green's function for Poisson's equation in electrostatics. That is, we'll take the Fourier transform of both sides of the wave equation, solve for the Green's function in the frequency domain, and then inverse transform to get the original Green's function in the space-time domain.

To that end, suppose we wish to solve the following PDE for the Green's function $G(\mathbf{x},t)$ located at $\mathbf{x}'=0$ and $t='0$,
$$
\nabla^2 G - \frac{1}{c^2} \frac{\partial^2 G}{\partial t^2} = -4\pi\delta(\mathbf{x})\delta(t) \ .
$$
When working in space and time, we can get a suitable Fourier transform by multiplying both sides by $e^{-i (\mathbf{k} \cdot \mathbf{x} - \omega t)}$ and integrating with respect to both $\mathbf{x}$ and $t$. We'll denote the Fourier transform of $G(\mathbf{x},t)$ by
$$
G(\mathbf{k},\omega) \equiv \int d^3\mathbf{x} dt \ G(\mathbf{x},t) e^{-i (\mathbf{k} \cdot \mathbf{x} - \omega t)} \ .
$$
Now, if we apply this Fourier transform to both sides of the wave equation above, we end up with
$$
\bigg(-|\mathbf{k}|^2 + \frac{\omega^2}{c^2}\bigg) G(\mathbf{k}, \omega) = -4\pi \ .
$$
The left-hand side follows by using integration by parts inside the Fourier transform, and the right-hand side follows from the fact that the integral of a delta function over all space and time is one. Thus, the Green's function in frequency space is given by
$$
G(\mathbf{k}, \omega) = -\frac{4\pi}{(\omega/c)^2 - |\mathbf{k}|^2} = -\frac{4\pi c^2}{\omega^2 - c^2|\mathbf{k}|^2} \ .
$$
To recover the original Green's function we need to take the inverse Fourier transform of this function, which can be found by multiplying both sides by $1/(2\pi)^4 \ e^{i(\mathbf{k} \cdot \mathbf{x} - \omega t)}$ and integrating over all $\mathbf{k}$ and $\omega$,
$$
G(\mathbf{x},t) = \int \frac{d^3\mathbf{k}d\omega}{(2\pi)^4} \ G(\mathbf{k},\omega) e^{i(\mathbf{k} \cdot \mathbf{x} - \omega t)} \ .
$$
All that remains now is to perform this integration. We'll find it convenient to integrate over $\omega$ first. We'll thus write
$$
G(\mathbf{x},t) = -\frac{4\pi c^2}{(2\pi)^4} \int d^3\mathbf{k} \  e^{i\mathbf{k} \cdot \mathbf{x}} \int_{-\infty}^\infty d\omega \ \frac{e^{-i\omega t}}{\omega^2 - c^2|\mathbf{k}|^2} \ .
$$
Performing the integration over $\omega$ requires the tools of complex analysis. We showed in the appendix that
$$
\int_{-\infty}^\infty dx \ \frac{e^{-itx}}{x^2 - a^2} = -\frac{\pi}{a} \sin a|t| \ .
$$
Identifying $x \leftrightarrow \omega$ and $a \leftrightarrow c|\mathbf{k}|$, we can see that the solution to the $\omega$ integral is thus
$$
\int_{-\infty}^\infty d\omega \ \frac{e^{-i\omega t}}{\omega^2 - c^2|\mathbf{k}|^2} = -\frac{\pi}{c|\mathbf{k}|} \sin c|\mathbf{k}t| \ .
$$

Plugging this result back into the Green's function and simplifying, we have
$$
G(\mathbf{x},t) = \frac{c}{(2\pi)^2} \int d^3\mathbf{k} \  e^{i\mathbf{k} \cdot \mathbf{x}} \frac{\sin c|\mathbf{k}t|}{|\mathbf{k}|} \ .
$$
All that remains now is the integral over $\mathbf{k}$. We'll orient the axes in $\mathbf{k}$ space so that $\mathbf{x} = r\mathbf{e}_z$ and $\mathbf{k} \cdot \mathbf{x} = kr\cos\theta_k$, where $k = |\mathbf{k}|$. Writing the volume element in spherical coordinates $(k, \theta_k, \varphi_k)$ as $d^3 \mathbf{k} = k^2 \sin\theta_k dk d\theta_k d\varphi_k$ and integrating over $\varphi_k$, we get
$$
G(\mathbf{x},t) = \frac{c}{2\pi} \int_0^\infty k^2 dk \ \frac{\sin ck|t|}{k} \int_0^\pi d\theta_k \  \sin\theta_k e^{ikr\cos\theta_k} \ .
$$
We saw this same $\theta_k$ integral before when calculating the Green's function in electrostatics, where we showed
$$
\int_0^\pi d\theta_k \  \sin\theta_k e^{ikr\cos\theta_k} = \int_{-1}^1 d\mu \ e^{ikr\mu} = 2\frac{\sin kr}{kr} \ .
$$
All that remains now is the integral over $k$. Canceling the factors of $k^2$, we have
$$
G(\mathbf{x},t) = \frac{c}{\pi r} \int_0^\infty dk \ \sin ck|t| \sin kr \ .
$$
This integral can be done by writing the expanding the sines in terms of complex exponentials and exploiting the properties of the delta function. We have
$$
\begin{align*}
G(\mathbf{x},t) &= \frac{c}{\pi r} \int_0^\infty dk \ \frac{1}{2i} \big(e^{ick|t|} - e^{-ick|t|}\big) \frac{1}{2i} \big(e^{ikr} - e^{-ikr}\big) \\
&= -\frac{c}{4\pi r} \int_0^\infty dk \ \big[e^{ik(c|t| + r)} - e^{ik(c|t| - r)} - e^{ik(-c|t| + r)} + e^{ik(-c|t| - r)}\big] \\
&= -\frac{c}{4\pi r} \big[2\pi\delta(c|t| + r) - 2\pi\delta(c|t| - r) - 2\pi\delta(-c|t| + r) + 2\pi\delta(-c|t| - r)\big] \\
&= \frac{c}{2r} \big[\delta(c|t| - r) - \delta(c|t| + r)\big] \\
&= \frac{1}{2r} \big[\delta(|t| - r/c) - \delta(|t| + r/c)\big] \ .
\end{align*}
$$
Now, since $|t| > 0$ and $r > 0$, the second delta function must vanish since we can never have $|t| = -r/c$, which means
$$
G(\mathbf{x},t) = \frac{1}{2r} \delta(|t| - r/c) = \frac{1}{2r} [\delta(t - r/c) + \delta(t + r/c)] \ .
$$
While this result is strictly speaking mathematically correct, it turns out it's not yet physically correct, as we'll see.

### Causality

Strictly speaking, the Green's function we derived above is *symmetrized*. That is, it's an average of two functions,
$$
G_\pm(\mathbf{x},t) = \frac{\delta\big(t \mp r/c\big)}{r} \ .
$$
In fact, both $G_+(\mathbf{x},t)$ and $G_-(\mathbf{x},t)$ each individually satisfy the inhomogeneous wave equation
$$
\nabla^2 G - \frac{1}{c^2} \frac{\partial^2 G}{\partial t^2} = -4\pi\delta(\mathbf{x})\delta(t) \ .
$$
Since this is the case, by the superposition principle any sum of these two functions will also satisfy the inhomogeneous wave equation. Such a sum will also be a valid Green's function so long as their weights sum to one.

If we shift these functions back to the points $\mathbf{x}'$ and $t'$, we have
$$
G_\pm(\mathbf{x} - \mathbf{x}', t-t') = \frac{\delta\big(|t-t'| \mp |\mathbf{x} - \mathbf{x}'|/c\big)}{|\mathbf{x} - \mathbf{x}'|} \ .
$$
By convention, we call $G_+(\mathbf{x} - \mathbf{x}', t-t')$ the *retarded Green's function*, and $G_-(\mathbf{x} - \mathbf{x}', t-t')$ the *advanced Green's function*. It'll also be useful to give the arguments inside the delta functions a name. Define
$$
t_{\text{ret}} \equiv t' - \frac{1}{c}|\mathbf{x} - \mathbf{x}'| \quad , \quad t_{\text{adv}} \equiv t' + \frac{1}{c}|\mathbf{x} - \mathbf{x}'| \ .
$$





$$
\begin{align*}
&\phi(\mathbf{x},t) = \int d^3\mathbf{x}' \frac{\rho(\mathbf{x}',t_\text{ret})}{|\mathbf{x} - \mathbf{x}'|} \ , \\ 
&\mathbf{A}(\mathbf{x},t) = \frac{1}{c} \int d^3\mathbf{x}' \frac{\mathbf{J}(\mathbf{x}',t_\text{ret})}{|\mathbf{x} - \mathbf{x}'|}  \ .
\end{align*}
$$


## Conservation Laws

- Conservation of energy (Poynting's theorem), conservation of momentum

$$
\nabla \times (\nabla \times \mathbf{B}) = \frac{4\pi}{c} \nabla \times \mathbf{J} + \frac{1}{c} \frac{\partial}{\partial t} \nabla \times \mathbf{E}
$$

$$
\nabla(\nabla \cdot \mathbf{B}) - \nabla^2 \mathbf{B} = \frac{4\pi}{c} \nabla \times \mathbf{J} - \frac{1}{c^2} \frac{\partial^2 \mathbf{B}}{\partial t^2}
$$

$$
\frac{1}{c^2} \frac{\partial^2 \mathbf{B}}{\partial t^2} - \nabla^2 \mathbf{B} = \frac{4\pi}{c} \nabla \times \mathbf{J}
$$

- E-field

$$
\nabla \times (\nabla \times \mathbf{E}) = -\frac{1}{c} \frac{\partial}{\partial t} \nabla \times \mathbf{B}
$$

$$
\nabla(\nabla \cdot \mathbf{E}) - \nabla^2 \mathbf{E} = -\frac{1}{c} \frac{\partial}{\partial t} \bigg[\frac{4\pi}{c} \mathbf{J} + \frac{1}{c} \frac{\partial \mathbf{E}}{\partial t}\bigg]
$$

$$
\frac{1}{c^2} \frac{\partial^2 \mathbf{E}}{\partial t^2} - \nabla^2 \mathbf{E} = -\frac{4\pi}{c^2} \frac{\partial \mathbf{J}}{\partial t} - 4\pi \nabla \rho
$$

